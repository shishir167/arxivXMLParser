<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T03:34:42Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|64001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7305</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7305</id><created>2014-07-27</created><updated>2014-07-30</updated><authors><author><keyname>Spalazzi</keyname><forenames>Luca</forenames></author><author><keyname>Spegni</keyname><forenames>Francesco</forenames></author></authors><title>Parameterized Model-Checking for Timed-Systems with Conjunctive Guards
  (Extended Version)</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we extend the Emerson and Kahlon's cutoff theorems for process
skeletons with conjunctive guards to Parameterized Networks of Timed Automata,
i.e. systems obtained by an \emph{apriori} unknown number of Timed Automata
instantiated from a finite set $U_1, \dots, U_n$ of Timed Automata templates.
In this way we aim at giving a tool to universally verify software systems
where an unknown number of software components (i.e. processes) interact with
continuous time temporal constraints. It is often the case, indeed, that
distributed algorithms show an heterogeneous nature, combining dynamic aspects
with real-time aspects. In the paper we will also show how to model check a
protocol that uses special variables storing identifiers of the participating
processes (i.e. PIDs) in Timed Automata with conjunctive guards. This is
non-trivial, since solutions to the parameterized verification problem often
relies on the processes to be symmetric, i.e. indistinguishable. On the other
side, many popular distributed algorithms make use of PIDs and thus cannot
directly apply those solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7313</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7313</id><created>2014-07-27</created><authors><author><keyname>Patidar</keyname><forenames>Pawan</forenames></author><author><keyname>Raghuvanshi</keyname><forenames>Himanshu</forenames></author><author><keyname>Sarcar</keyname><forenames>Sayan</forenames></author></authors><title>Quickpie: An Interface for Fast and Accurate Eye Gazed based Text Entry</title><categories>cs.HC</categories><comments>This 6 page paper has been accepted as a student design contest paper
  at India HCI 2013 Conference, held at Bangalore, India during 24th to 27th
  September,2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pie menus are suggested as powerful tool for eye gaze based text entry among
various interfaces developed so far. If pie menus are used with multiple depth
layers then multiple saccades are required per selection of item, which is
inefficient because it consumes more time. Also dwell time selection method is
limited in performance because higher dwell time suffers from inefficiency
while lower one from inaccuracy. To overcome problems with multiple depth
layers and dwell time, we designed Quickpie, an interface for eye gaze based
text entry with only one depth layer of pie menu and selection border as
selection method instead of dwell time. We investigated various parameters like
number of slices in pie menu, width characters and safe region, enlarged angle
of slice and selection methods to achieve better performance. Our experiment
results indicates that six number of slices with width of characters area 120
px performs better as compared to other designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7314</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7314</id><created>2014-07-27</created><authors><author><keyname>Su</keyname><forenames>Wu-Chen</forenames></author></authors><title>A Preliminary Survey of Knowledge Discovery on Smartphone Applications
  (apps): Principles, Techniques and Research Directions for E-health</title><categories>cs.CY cs.HC cs.IR</categories><comments>6 pages, 2 figures, 2 tables, 2014 ICME International Conference on
  Complex Medical Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People usually seek out varied information to deal with their health
problems. However, the large volume of information available may present
challenges for the public to distinguish good from suboptimal advice. How to
ensure the right information for the right person at the right time and place
has always been a challenge. For example, smart phone application vendor
markets provide a varied selection of health applications for users. However,
there is a lack of substantive reference information for consumers to base
well-informed decisions about whether or not to adopt the applications they
review and to ascertain the validity of the information provided by these
e-health solutions. Thus, this study aims to review the existing relevant
research about smart phone applications and identify pertinent research
questions in the field of knowledge discovery for health applications that can
be addressed in future research. Therefore, this study can be seen as an
important step for researchers to explore this domain and extend our work for
the well-being of public.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7317</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7317</id><created>2014-07-28</created><authors><author><keyname>Ghiass</keyname><forenames>Reza Shoja</forenames></author><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author><author><keyname>Bendada</keyname><forenames>Hakim</forenames></author><author><keyname>Maldague</keyname><forenames>Xavier</forenames></author></authors><title>A unified framework for thermal face recognition</title><categories>cs.CV</categories><comments>International Conference on Neural Information Processing, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reduction of the cost of infrared (IR) cameras in recent years has made
IR imaging a highly viable modality for face recognition in practice. A
particularly attractive advantage of IR-based over conventional, visible
spectrum-based face recognition stems from its invariance to visible
illumination. In this paper we argue that the main limitation of previous work
on face recognition using IR lies in its ad hoc approach to treating different
nuisance factors which affect appearance, prohibiting a unified approach that
is capable of handling concurrent changes in multiple (or indeed all) major
extrinsic sources of variability, which is needed in practice. We describe the
first approach that attempts to achieve this - the framework we propose
achieves outstanding recognition performance in the presence of variable (i)
pose, (ii) facial expression, (iii) physiological state, (iv) partial occlusion
due to eye-wear, and (v) quasi-occlusion due to facial hair growth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7319</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7319</id><created>2014-07-28</created><authors><author><keyname>Chen</keyname><forenames>Xilun</forenames></author><author><keyname>Wu</keyname><forenames>Chenxia</forenames></author></authors><title>Price of Anarchy of Innovation Diffusion in Social Networks</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There have been great efforts in studying the cascading behavior in social
networks such as the innovation diffusion, etc. Game theoretically, in a social
network where individuals choose from two strategies: A (the innovation) and B
(the status quo) and get payoff from their neighbors for coordination, it has
long been known that the Price of Anarchy (PoA) of this game is not 1, since
the Nash equilibrium (NE) where all players take B (B Nash) is inferior to the
one all players taking A (A Nash). However, no quantitative analysis has been
performed to give an accurate upper bound of PoA in this game.
  In this paper, we adopt a widely used networked coordination game setting [3]
to study how bad a Nash equilibrium can be and give a tight upper bound of the
PoA of such games. We show that there is an NE that is slightly worse than the
B Nash. On the other hand, the PoA is bounded and the worst NE cannot be much
worse than the B Nash. In addition, we discuss how the PoA upper bound would
change when compatibility between A and B is introduced, and show an intuitive
result that the upper bound strictly decreases as the compatibility is
increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7330</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7330</id><created>2014-07-28</created><authors><author><keyname>Wiliem</keyname><forenames>Arnold</forenames></author><author><keyname>Hobson</keyname><forenames>Peter</forenames></author><author><keyname>Lovell</keyname><forenames>Brian C.</forenames></author></authors><title>Discovering Discriminative Cell Attributes for HEp-2 Specimen Image
  Classification</title><categories>cs.CV cs.CE</categories><comments>WACV 2014: IEEE Winter Conference on Applications of Computer Vision</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, there has been a growing interest in developing Computer Aided
Diagnostic (CAD) systems for improving the reliability and consistency of
pathology test results. This paper describes a novel CAD system for the
Anti-Nuclear Antibody (ANA) test via Indirect Immunofluorescence protocol on
Human Epithelial Type 2 (HEp-2) cells. While prior works have primarily focused
on classifying cell images extracted from ANA specimen images, this work takes
a further step by focussing on the specimen image classification problem
itself. Our system is able to efficiently classify specimen images as well as
producing meaningful descriptions of ANA pattern class which helps physicians
to understand the differences between various ANA patterns. We achieve this
goal by designing a specimen-level image descriptor that: (1) is highly
discriminative; (2) has small descriptor length and (3) is semantically
meaningful at the cell level. In our work, a specimen image descriptor is
represented by its overall cell attribute descriptors. As such, we propose two
max-margin based learning schemes to discover cell attributes whilst still
maintaining the discrimination of the specimen image descriptor. Our learning
schemes differ from the existing discriminative attribute learning approaches
as they primarily focus on discovering image-level attributes. Comparative
evaluations were undertaken to contrast the proposed approach to various
state-of-the-art approaches on a novel HEp-2 cell dataset which was
specifically proposed for the specimen-level classification. Finally, we
showcase the ability of the proposed approach to provide textual descriptions
to explain ANA patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7337</identifier>
 <datestamp>2015-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7337</id><created>2014-07-28</created><authors><author><keyname>Kang</keyname><forenames>Qingbo</forenames></author><author><keyname>Li</keyname><forenames>Ke</forenames></author><author><keyname>Yang</keyname><forenames>Jichun</forenames></author></authors><title>A Digital Watermarking Approach Based on DCT Domain Combining QR Code
  and Chaotic Theory</title><categories>cs.MM cs.CR</categories><comments>7 pages, 6 figures</comments><doi>10.1109/WOCN.2014.6923098</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a robust watermarking approach based on Discrete Cosine
Transform domain that combines Quick Response Code and chaotic system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7342</identifier>
 <datestamp>2014-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7342</id><created>2014-07-28</created><updated>2014-11-25</updated><authors><author><keyname>Zheng</keyname><forenames>Shenggen</forenames></author><author><keyname>Qiu</keyname><forenames>Daowen</forenames></author></authors><title>From Quantum Query Complexity to State Complexity</title><categories>cs.CC quant-ph</categories><comments>Some typos in references were fixed. To appear in Gruska Festschrift
  (2014). Comments are welcome. arXiv admin note: substantial text overlap with
  arXiv:1402.7254, arXiv:1309.7739</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State complexity of quantum finite automata is one of the interesting topics
in studying the power of quantum finite automata. It is therefore of importance
to develop general methods how to show state succinctness results for quantum
finite automata. One such method is presented and demonstrated in this paper.
In particular, we show that state succinctness results can be derived out of
query complexity results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7356</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7356</id><created>2014-07-28</created><updated>2014-09-09</updated><authors><author><keyname>Guck</keyname><forenames>Dennis</forenames><affiliation>University of Twente</affiliation></author><author><keyname>Hatefi</keyname><forenames>Hassan</forenames><affiliation>Saarland University</affiliation></author><author><keyname>Hermanns</keyname><forenames>Holger</forenames><affiliation>Saarland University</affiliation></author><author><keyname>Katoen</keyname><forenames>Joost-Pieter</forenames><affiliation>RWTH Aachen University</affiliation></author><author><keyname>Timmer</keyname><forenames>Mark</forenames><affiliation>University of Twente</affiliation></author></authors><title>Analysis of Timed and Long-Run Objectives for Markov Automata</title><categories>cs.LO cs.FL</categories><comments>arXiv admin note: substantial text overlap with arXiv:1305.7050</comments><proxy>LMCS</proxy><journal-ref>Logical Methods in Computer Science, Volume 10, Issue 3 (September
  10, 2014) lmcs:943</journal-ref><doi>10.2168/LMCS-10(3:17)2014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov automata (MAs) extend labelled transition systems with random delays
and probabilistic branching. Action-labelled transitions are instantaneous and
yield a distribution over states, whereas timed transitions impose a random
delay governed by an exponential distribution. MAs are thus a nondeterministic
variation of continuous-time Markov chains. MAs are compositional and are used
to provide a semantics for engineering frameworks such as (dynamic) fault
trees, (generalised) stochastic Petri nets, and the Architecture Analysis &amp;
Design Language (AADL). This paper considers the quantitative analysis of MAs.
We consider three objectives: expected time, long-run average, and timed
(interval) reachability. Expected time objectives focus on determining the
minimal (or maximal) expected time to reach a set of states. Long-run
objectives determine the fraction of time to be in a set of states when
considering an infinite time horizon. Timed reachability objectives are about
computing the probability to reach a set of states within a given time
interval. This paper presents the foundations and details of the algorithms and
their correctness proofs. We report on several case studies conducted using a
prototypical tool implementation of the algorithms, driven by the MAPA
modelling language for efficiently generating MAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7357</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7357</id><created>2014-07-28</created><authors><author><keyname>Haralambous</keyname><forenames>Yannis</forenames></author><author><keyname>Lenca</keyname><forenames>Philippe</forenames></author></authors><title>Text Classification Using Association Rules, Dependency Pruning and
  Hyperonymization</title><categories>cs.IR cs.CL</categories><comments>16 pages, 2 figures, presented at DMNLP 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new methods for pruning and enhancing item- sets for text
classification via association rule mining. Pruning methods are based on
dependency syntax and enhancing methods are based on replacing words by their
hyperonyms of various orders. We discuss the impact of these methods, compared
to pruning based on tfidf rank of words.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7360</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7360</id><created>2014-07-28</created><authors><author><keyname>Zhou</keyname><forenames>Amelie Chi</forenames></author><author><keyname>He</keyname><forenames>Bingsheng</forenames></author><author><keyname>Ibrahim</keyname><forenames>Shadi</forenames></author></authors><title>A Taxonomy and Survey on eScience as a Service in the Cloud</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud computing has recently evolved as a popular computing infrastructure
for many applications. Scientific computing, which was mainly hosted in private
clusters and grids, has started to migrate development and deployment to the
public cloud environment. eScience as a service becomes an emerging and
promising direction for science computing. We review recent efforts in
developing and deploying scientific computing applications in the cloud. In
particular, we introduce a taxonomy specifically designed for scientific
computing in the cloud, and further review the taxonomy with four major kinds
of science applications, including life sciences, physics sciences, social and
humanities sciences, and climate and earth sciences. Our major finding is that,
despite existing efforts in developing cloud-based eScience, eScience still has
a long way to go to fully unlock the power of cloud computing paradigm.
Therefore, we present the challenges and opportunities in the future
development of cloud-based eScience services, and call for collaborations and
innovations from both the scientific and computer system communities to address
those challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7368</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7368</id><created>2014-07-28</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Critical Independent Sets of a Graph</title><categories>cs.DM math.CO</categories><comments>15 pages; 12 figures. arXiv admin note: substantial text overlap with
  arXiv:1102.1138</comments><msc-class>05C69 (Primary) 05C70 (Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G$ be a simple graph with vertex set $V\left( G\right) $. A set
$S\subseteq V\left( G\right) $ is independent if no two vertices from $S$ are
adjacent, and by $\mathrm{Ind}(G)$ we mean the family of all independent sets
of $G$.
  The number $d\left( X\right) =$ $\left\vert X\right\vert -\left\vert
N(X)\right\vert $ is the difference of $X\subseteq V\left( G\right) $, and a
set $A\in\mathrm{Ind}(G)$ is critical if $d(A)=\max \{d\left( I\right)
:I\in\mathrm{Ind}(G)\}$ (Zhang, 1990).
  Let us recall the following definitions:
  $\mathrm{core}\left( G\right) $ = $\bigcap$ {S : S is a maximum independent
set}.
  $\mathrm{corona}\left( G\right)$ = $\bigcup$ {S :S is a maximum independent
set}.
  $\mathrm{\ker}(G)$ = $\bigcap$ {S : S is a critical independent set}.
  $\mathrm{diadem}(G)$ = $\bigcup$ {S : S is a critical independent set}.
  In this paper we present various structural properties of $\mathrm{\ker}(G)$,
in relation with $\mathrm{core}\left( G\right) $, $\mathrm{corona}\left(
G\right) $, and $\mathrm{diadem}(G)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7390</identifier>
 <datestamp>2015-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7390</id><created>2014-07-28</created><updated>2015-06-16</updated><authors><author><keyname>Padilla-L&#xf3;pez</keyname><forenames>Jos&#xe9; Ram&#xf3;n</forenames></author><author><keyname>Chaaraoui</keyname><forenames>Alexandros Andr&#xe9;</forenames></author><author><keyname>Fl&#xf3;rez-Revuelta</keyname><forenames>Francisco</forenames></author></authors><title>A discussion on the validation tests employed to compare human action
  recognition methods using the MSR Action3D dataset</title><categories>cs.CV</categories><comments>16 pages and 7 tables</comments><report-no>hdl:10045/39889</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper aims to determine which is the best human action recognition
method based on features extracted from RGB-D devices, such as the Microsoft
Kinect. A review of all the papers that make reference to MSR Action3D, the
most used dataset that includes depth information acquired from a RGB-D device,
has been performed. We found that the validation method used by each work
differs from the others. So, a direct comparison among works cannot be made.
However, almost all the works present their results comparing them without
taking into account this issue. Therefore, we present different rankings
according to the methodology used for the validation in orden to clarify the
existing confusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7399</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7399</id><created>2014-07-28</created><authors><author><keyname>Merrikh-Bayat</keyname><forenames>F.</forenames></author></authors><title>A Numerical Optimization Algorithm Inspired by the Strawberry Plant</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new numerical optimization algorithm inspired by the
strawberry plant for solving complicated engineering problems. Plants like
strawberry develop both runners and roots for propagation and search for water
resources and minerals. In these plants, runners and roots can be thought of as
tools for global and local searches, respectively. The proposed algorithm has
three main differences with the trivial nature-inspired optimization
algorithms: duplication-elimination of the computational agents at all
iterations, subjecting all agents to both small and large movements from the
beginning to end, and the lack of communication (information exchange) between
agents. Moreover, it has the advantage of using only three parameters to be
tuned by user. This algorithm is applied to standard test functions and the
results are compared with GA and PSO. The proposed algorithm is also used to
solve an open problem in the field of robust control theory. These simulations
show that the proposed algorithm can very effectively solve complicated
optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7402</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7402</id><created>2014-07-28</created><updated>2015-04-27</updated><authors><author><keyname>Kabanava</keyname><forenames>Maryia</forenames></author><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author><author><keyname>Zhang</keyname><forenames>Hui</forenames></author></authors><title>Robust analysis $\ell_1$-recovery from Gaussian measurements and total
  variation minimization</title><categories>cs.IT math.IT</categories><journal-ref>Eur. J. Appl. Math. 26 (2015) 917-929</journal-ref><doi>10.1017/S0956792515000236</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis $\ell_1$-recovery refers to a technique of recovering a signal that
is sparse in some transform domain from incomplete corrupted measurements. This
includes total variation minimization as an important special case when the
transform domain is generated by a difference operator. In the present paper we
provide a bound on the number of Gaussian measurements required for successful
recovery for total variation and for the case that the analysis operator is a
frame. The bounds are particularly suitable when the sparsity of the analysis
representation of the signal is not very small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7405</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7405</id><created>2014-07-28</created><authors><author><keyname>Chen</keyname><forenames>Qi</forenames></author><author><keyname>Yeung</keyname><forenames>Raymond W.</forenames></author></authors><title>Partition-Symmetrical Entropy Functions</title><categories>cs.IT math.IT</categories><comments>This paper was submitted to Transactions on Information Theory and in
  part presented at ITW2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\cal{N}=\{1,\cdots,n\}$. The entropy function $\bf h$ of a set of $n$
discrete random variables $\{X_i:i\in\cal N\}$ is a $2^n$-dimensional vector
whose entries are ${\bf{h}}({\cal{A}})\triangleq
H(X_{\cal{A}}),\cal{A}\subset{\cal N} $, the (joint) entropies of the subsets
of the set of $n$ random variables with $H(X_\emptyset)=0$ by convention. The
set of all entropy functions for $n$ discrete random variables, denoted by
$\Gamma^*_n$, is called the entropy function region for $n$. Characterization
of $\Gamma^*_n$ and its closure $\overline{\Gamma^*_n}$ are well-known open
problems in information theory. They are important not only because they play
key roles in information theory problems but also they are related to other
subjects in mathematics and physics.
  In this paper, we consider \emph{partition-symmetrical entropy
  functions}. Let $p=\{\cal{N}_1,\cdots, \cal{N}_t\}$ be a $t$-partition of
$\cal N$. An entropy function $\bf h$ is called $p$-symmetrical if for all
${\cal A},{\cal B} \subset {\cal N}$, $\bf{h}({\cal A}) = \bf{h}({\cal B})$
whenever $|{\cal A} \cap {\cal N}_i| = |{\cal B} \cap {\cal N}_i|$, $i = 1,
\cdots,t$. The set of all the $p$-symmetrical entropy functions, denoted by
$\Psi^*_p$, is called $p$-symmetrical entropy function region. We prove that
$\overline{\Psi^*_p}$, the closure of $\Psi^*_p$, is completely characterized
by Shannon-type information inequalities if and only if $p$ is the
$1$-partition or a $2$-partition with one of its blocks being a singleton.
  The characterization of the partition-symmetrical entropy functions can be
useful for solving some information theory and related problems where symmetry
exists in the structure of the problems.
  Keywords: entropy, entropy function, information inequality, polymatroid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7417</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7417</id><created>2014-07-28</created><authors><author><keyname>Mondal</keyname><forenames>Nabarun</forenames></author><author><keyname>Ghosh</keyname><forenames>Partha P.</forenames></author></authors><title>'Almost Sure' Chaotic Properties of Machine Learning Methods</title><categories>cs.LG cs.AI</categories><comments>10 pages : to be submitted to Theoretical Computer Science. arXiv
  admin note: text overlap with arXiv:1111.4949</comments><msc-class>Primary 03D10, Secondary 65P20, 68Q05, 68Q87, 68T05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been demonstrated earlier that universal computation is 'almost
surely' chaotic. Machine learning is a form of computational fixed point
iteration, iterating over the computable function space. We showcase some
properties of this iteration, and establish in general that the iteration is
'almost surely' of chaotic nature. This theory explains the observation in the
counter intuitive properties of deep learning methods. This paper demonstrates
that these properties are going to be universal to any learning method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7423</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7423</id><created>2014-07-28</created><authors><author><keyname>Karpi&#x144;ski</keyname><forenames>Micha&#x142;</forenames></author></authors><title>Vertex 2-coloring without monochromatic cycles</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a problem of vertex two-coloring of undirected graph
such that there is no monochromatic cycle of given length. We show that this
problem is hard to solve. We give a proof by presenting a reduction from
variation of satisfiability (SAT) problem. We show nice properties of coloring
cliques with two colors which plays pivotal role in the reduction construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7428</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7428</id><created>2014-07-28</created><authors><author><keyname>Cain</keyname><forenames>Alan J.</forenames></author><author><keyname>Gray</keyname><forenames>Robert</forenames></author><author><keyname>Malheiro</keyname><forenames>Ant&#xf3;nio</forenames></author></authors><title>On finite complete rewriting systems, finite derivation type, and
  automaticity for homogeneous monoids</title><categories>math.GR cs.FL</categories><comments>30 pages; 1 table; 2 figures</comments><msc-class>20M05 (Primary) 20M35, 68W30 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The class of finitely presented monoids defined by homogeneous
(length-preserving) relations is considered. The properties of admitting a
finite complete rewriting system, having finite derivation type, being
automatic, and being biautomatic, are investigated for monoids in this class.
The first main result shows that for any possible combination of these
properties and their negations there is a homoegenous monoid with exactly this
combination of properties. We then extend this result to show that the same
statement holds even if one restricts attention to the class of $n$-ary
multihomogeneous monoids (meaning every side of every relation has fixed length
$n$, and all relations are also content preserving).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7440</identifier>
 <datestamp>2015-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7440</id><created>2014-07-28</created><authors><author><keyname>Matthiesen</keyname><forenames>Bho</forenames></author><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author><author><keyname>Jorswieck</keyname><forenames>Eduard A.</forenames></author></authors><title>Spectral and Energy Efficiency in 3-Way Relay Channels with Circular
  Message Exchanges</title><categories>cs.IT math.IT</categories><comments>5 pages, to be presented at ISWCS 2014, Barcelona, Spain</comments><doi>10.1109/ISWCS.2014.6933325</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral and energy efficiency in 3-way relay channels are studied in this
paper. First, achievable sum rate expressions for 3-way relay channels are
derived for different relaying protocols. Moreover, an outer bound for the
capacity of the 3-way relay channel is presented. Next, leveraging the derived
achievable sum rate expressions, two algorithms for joint power allocation at
the users and at the relay are designed so as to maximize the system energy
efficiency. Numerical results are provided to corroborate and provide insight
on the theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7443</identifier>
 <datestamp>2015-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7443</id><created>2014-07-28</created><updated>2015-06-01</updated><authors><author><keyname>Joshi</keyname><forenames>Saurabh</forenames></author><author><keyname>Kroening</keyname><forenames>Daniel</forenames></author></authors><title>Property-Driven Fence Insertion using Reorder Bounded Model Checking</title><categories>cs.SE</categories><comments>18 pages, 3 figures, 4 algorithms. Version change reason : new set of
  results and publication ready version of FM 2015</comments><doi>10.1007/978-3-319-19249-9_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern architectures provide weaker memory consistency guarantees than
sequential consistency. These weaker guarantees allow programs to exhibit
behaviours where the program statements appear to have executed out of program
order. Fortunately, modern architectures provide memory barriers (fences) to
enforce the program order between a pair of statements if needed. Due to the
intricate semantics of weak memory models, the placement of fences is
challenging even for experienced programmers. Too few fences lead to bugs
whereas overuse of fences results in performance degradation. This motivates
automated placement of fences. Tools that restore sequential consistency in the
program may insert more fences than necessary for the program to be correct.
Therefore, we propose a property-driven technique that introduces
&quot;reorder-bounded exploration&quot; to identify the smallest number of program
locations for fence placement. We implemented our technique on top of CBMC;
however, in principle, our technique is generic enough to be used with any
model checker. Our experimental results show that our technique is faster and
solves more instances of relevant benchmarks as compared to earlier approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7448</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7448</id><created>2014-07-25</created><authors><author><keyname>Yun</keyname><forenames>Heechul</forenames></author></authors><title>Parallelism-Aware Memory Interference Delay Analysis for COTS Multicore
  Systems</title><categories>cs.DC cs.PF</categories><comments>Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In modern Commercial Off-The-Shelf (COTS) multicore systems, each core can
generate many parallel memory requests at a time. The processing of these
parallel requests in the DRAM controller greatly affects the memory
interference delay experienced by running tasks on the platform. In this paper,
we model a modern COTS multicore system which has a nonblocking last-level
cache (LLC) and a DRAM controller that prioritizes reads over writes. To
minimize interference, we focus on LLC and DRAM bank partitioned systems. Based
on the model, we propose an analysis that computes a safe upper bound for the
worst-case memory interference delay. We validated our analysis on a real COTS
multicore platform with a set of carefully designed synthetic benchmarks as
well as SPEC2006 benchmarks. Evaluation results show that our analysis is more
accurately capture the worst-case memory interference delay and provides safer
upper bounds compared to a recently proposed analysis which significantly
under-estimate the delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7449</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7449</id><created>2014-07-23</created><authors><author><keyname>Chen</keyname><forenames>Xinquan</forenames></author></authors><title>A Fast Synchronization Clustering Algorithm</title><categories>cs.LG</categories><comments>18 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a Fast Synchronization Clustering algorithm (FSynC),
which is an improved version of SynC algorithm. In order to decrease the time
complexity of the original SynC algorithm, we combine grid cell partitioning
method and Red-Black tree to construct the near neighbor point set of every
point. By simulated experiments of some artificial data sets and several real
data sets, we observe that FSynC algorithm can often get less time than SynC
algorithm for many kinds of data sets. At last, it gives some research
expectations to popularize this algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7459</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7459</id><created>2014-07-25</created><authors><author><keyname>Iliopoulos</keyname><forenames>Vasileios</forenames></author></authors><title>A note on multipivot Quicksort</title><categories>cs.DS math.CO</categories><comments>Preprint, 7 pages</comments><msc-class>68P10, 68W20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse a generalisation of the Quicksort algorithm, where k uniformly at
random chosen pivots are used for partitioning an array of n distinct keys.
Specifically, the expected cost of this scheme is obtained, under the
assumption of linearity of the cost needed for the partition process. The
integration constants of the expected cost are computed using Vandermonde
matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7464</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7464</id><created>2014-07-28</created><authors><author><keyname>Khaledi</keyname><forenames>Mehrdad</forenames></author><author><keyname>Khaledi</keyname><forenames>Mojgan</forenames></author><author><keyname>Rabiee</keyname><forenames>Hamidreza</forenames></author></authors><title>An Optimal Game Theoretical Framework for Mobility Aware Routing in
  Mobile Ad hoc Networks</title><categories>cs.NI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Selfish behaviors are common in self-organized Mobile Ad hoc Networks
(MANETs) where nodes belong to different authorities. Since cooperation of
nodes is essential for routing protocols, various methods have been proposed to
stimulate cooperation among selfish nodes. In order to provide sufficient
incentives, most of these methods pay nodes a premium over their actual costs
of participation. However, they lead to considerably large overpayments.
Moreover, existing methods ignore mobility of nodes, for simplicity. However,
owing to the mobile nature of MANETs, this assumption seems unrealistic. In
this paper, we propose an optimal game theoretical framework to ensure the
proper cooperation in mobility aware routing for MANETs. The proposed method is
based on the multi-dimensional optimal auctions which allows us to consider
path durations, in addition to the route costs. Path duration is a metric that
best reflects changes in topology caused by mobility of nodes and, it is widely
used in mobility aware routing protocols. Furthermore, the proposed mechanism
is optimal in that it minimizes the total expected payments. We provide
theoretical analysis to support our claims. In addition, simulation results
show significant improvements in terms of payments compared to the most popular
existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7468</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7468</id><created>2014-07-28</created><authors><author><keyname>Sethi</keyname><forenames>Divjyot</forenames></author><author><keyname>Talupur</keyname><forenames>Muralidhar</forenames></author><author><keyname>Malik</keyname><forenames>Sharad</forenames></author></authors><title>Using Flow Specifications of Parameterized Cache Coherence Protocols for
  Verifying Deadlock Freedom</title><categories>cs.DC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of verifying deadlock freedom for symmetric cache
coherence protocols. In particular, we focus on a specific form of deadlock
which is useful for the cache coherence protocol domain and consistent with the
internal definition of deadlock in the Murphi model checker: we refer to this
deadlock as a system- wide deadlock (s-deadlock). In s-deadlock, the entire
system gets blocked and is unable to make any transition. Cache coherence
protocols consist of N symmetric cache agents, where N is an unbounded
parameter; thus the verification of s-deadlock freedom is naturally a
parameterized verification problem. Parametrized verification techniques work
by using sound abstractions to reduce the unbounded model to a bounded model.
Efficient abstractions which work well for industrial scale protocols typically
bound the model by replacing the state of most of the agents by an abstract
environment, while keeping just one or two agents as is. However, leveraging
such efficient abstractions becomes a challenge for s-deadlock: a violation of
s-deadlock is a state in which the transitions of all of the unbounded number
of agents cannot occur and so a simple abstraction like the one above will not
preserve this violation. In this work we address this challenge by presenting a
technique which leverages high-level information about the protocols, in the
form of message sequence dia- grams referred to as flows, for constructing
invariants that are collectively stronger than s-deadlock. Efficient
abstractions can be constructed to verify these invariants. We successfully
verify the German and Flash protocols using our technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7498</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7498</id><created>2014-07-28</created><authors><author><keyname>Erbacher</keyname><forenames>Robert F.</forenames></author><author><keyname>Jaeger</keyname><forenames>Trent</forenames></author><author><keyname>Talele</keyname><forenames>Nirupama</forenames></author><author><keyname>Teutsch</keyname><forenames>Jason</forenames></author></authors><title>Directed Multicut with linearly ordered terminals</title><categories>cs.DS cs.CR</categories><comments>12 pages, 1 figure</comments><acm-class>D.4.6; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by an application in network security, we investigate the following
&quot;linear&quot; case of Directed Mutlicut. Let $G$ be a directed graph which includes
some distinguished vertices $t_1, \ldots, t_k$. What is the size of the
smallest edge cut which eliminates all paths from $t_i$ to $t_j$ for all $i &lt;
j$? We show that this problem is fixed-parameter tractable when parametrized in
the cutset size $p$ via an algorithm running in $O(4^p p n^4)$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7504</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7504</id><created>2014-07-28</created><authors><author><keyname>Gomez</keyname><forenames>Lluis</forenames></author><author><keyname>Karatzas</keyname><forenames>Dimosthenis</forenames></author></authors><title>A Fast Hierarchical Method for Multi-script and Arbitrary Oriented Scene
  Text Extraction</title><categories>cs.CV</categories><comments>Manuscript Preprint. 11 pages. This work has been submitted to the
  IEEE for possible publication. Copyright may be transferred without notice,
  after which this version may no longer be accessible</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Typography and layout lead to the hierarchical organisation of text in words,
text lines, paragraphs. This inherent structure is a key property of text in
any script and language, which has nonetheless been minimally leveraged by
existing text detection methods. This paper addresses the problem of text
segmentation in natural scenes from a hierarchical perspective. Contrary to
existing methods, we make explicit use of text structure, aiming directly to
the detection of region groupings corresponding to text within a hierarchy
produced by an agglomerative similarity clustering process over individual
regions. We propose an optimal way to construct such an hierarchy introducing a
feature space designed to produce text group hypotheses with high recall and a
novel stopping rule combining a discriminative classifier and a probabilistic
measure of group meaningfulness based in perceptual organization. Results
obtained over four standard datasets, covering text in variable orientations
and different languages, demonstrate that our algorithm, while being trained in
a single mixed dataset, outperforms state of the art methods in unconstrained
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7508</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7508</id><created>2014-07-28</created><authors><author><keyname>Liu</keyname><forenames>Zhenqiu</forenames></author><author><keyname>Li</keyname><forenames>Gang</forenames></author></authors><title>Efficient Regularized Regression for Variable Selection with L0 Penalty</title><categories>cs.LG stat.ML</categories><comments>26 pages and 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variable (feature, gene, model, which we use interchangeably) selections for
regression with high-dimensional BIGDATA have found many applications in
bioinformatics, computational biology, image processing, and engineering. One
appealing approach is the L0 regularized regression which penalizes the number
of nonzero features in the model directly. L0 is known as the most essential
sparsity measure and has nice theoretical properties, while the popular L1
regularization is only a best convex relaxation of L0. Therefore, it is natural
to expect that L0 regularized regression performs better than LASSO. However,
it is well-known that L0 optimization is NP-hard and computationally
challenging. Instead of solving the L0 problems directly, most publications so
far have tried to solve an approximation problem that closely resembles L0
regularization.
  In this paper, we propose an efficient EM algorithm (L0EM) that directly
solves the L0 optimization problem. $L_0$EM is efficient with high dimensional
data. It also provides a natural solution to all Lp p in [0,2] problems. The
regularized parameter can be either determined through cross-validation or AIC
and BIC. Theoretical properties of the L0-regularized estimator are given under
mild conditions that permit the number of variables to be much larger than the
sample size. We demonstrate our methods through simulation and high-dimensional
genomic data. The results indicate that L0 has better performance than LASSO
and L0 with AIC or BIC has similar performance as computationally intensive
cross-validation. The proposed algorithms are efficient in identifying the
non-zero variables with less-bias and selecting biologically important genes
and pathways with high dimensional BIGDATA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7514</identifier>
 <datestamp>2015-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7514</id><created>2014-07-28</created><authors><author><keyname>Wiens</keyname><forenames>Jeffrey K.</forenames></author><author><keyname>Stockie</keyname><forenames>John M.</forenames></author></authors><title>Simulating flexible fiber suspensions using a scalable immersed boundary
  algorithm</title><categories>physics.flu-dyn cs.CE</categories><msc-class>74F10, 76D05, 76M12, 65Y05</msc-class><journal-ref>Computer Methods in Applied Mechanics and Engineering, 290:1-18,
  2015</journal-ref><doi>10.1016/j.cma.2015.02.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach for numerically simulating the dynamics of flexible
fibers in a three-dimensional shear flow using a scalable immersed boundary
(IB) algorithm based on Guermond and Minev's pseudo-compressible fluid solver.
The fibers are treated as one-dimensional Kirchhoff rods that resist
stretching, bending, and twisting, within the generalized IB framework. We
perform a careful numerical comparison against experiments on single fibers
performed by S. G. Mason and co-workers, who categorized the fiber dynamics
into several distinct orbit classes. We show that the orbit class may be
determined using a single dimensionless parameter for low Reynolds flows.
Lastly, we simulate dilute suspensions containing up to hundreds of fibers
using a distributed- memory computer cluster. These simulations serve as a
stepping stone for studying more complex suspension dynamics including
non-dilute suspensions and aggregation of fibers (also known as flocculation).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7556</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7556</id><created>2014-07-28</created><updated>2015-01-11</updated><authors><author><keyname>Livi</keyname><forenames>Lorenzo</forenames></author><author><keyname>Sadeghian</keyname><forenames>Alireza</forenames></author><author><keyname>Pedrycz</keyname><forenames>Witold</forenames></author></authors><title>Entropic one-class classifiers</title><categories>cs.CV cs.LG stat.ML</categories><comments>To appear in IEEE-TNNLS</comments><acm-class>I.2.6; K.2.3</acm-class><doi>10.1109/TNNLS.2015.2418332</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The one-class classification problem is a well-known research endeavor in
pattern recognition. The problem is also known under different names, such as
outlier and novelty/anomaly detection. The core of the problem consists in
modeling and recognizing patterns belonging only to a so-called target class.
All other patterns are termed non-target, and therefore they should be
recognized as such. In this paper, we propose a novel one-class classification
system that is based on an interplay of different techniques. Primarily, we
follow a dissimilarity representation based approach; we embed the input data
into the dissimilarity space by means of an appropriate parametric
dissimilarity measure. This step allows us to process virtually any type of
data. The dissimilarity vectors are then represented through a weighted
Euclidean graphs, which we use to (i) determine the entropy of the data
distribution in the dissimilarity space, and at the same time (ii) derive
effective decision regions that are modeled as clusters of vertices. Since the
dissimilarity measure for the input data is parametric, we optimize its
parameters by means of a global optimization scheme, which considers both
mesoscopic and structural characteristics of the data represented through the
graphs. The proposed one-class classifier is designed to provide both hard
(Boolean) and soft decisions about the recognition of test patterns, allowing
an accurate description of the classification process. We evaluate the
performance of the system on different benchmarking datasets, containing either
feature-based or structured patterns. Experimental results demonstrate the
effectiveness of the proposed technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7559</identifier>
 <datestamp>2015-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7559</id><created>2014-07-28</created><updated>2015-04-29</updated><authors><author><keyname>Livi</keyname><forenames>Lorenzo</forenames></author><author><keyname>Giuliani</keyname><forenames>Alessandro</forenames></author><author><keyname>Rizzi</keyname><forenames>Antonello</forenames></author></authors><title>Toward a multilevel representation of protein molecules: comparative
  approaches to the aggregation/folding propensity problem</title><categories>cs.CE cs.LG q-bio.BM q-bio.MN</categories><comments>17 pages, 3 figures, 46 references</comments><acm-class>I.2.6; K.3.2</acm-class><doi>10.1016/j.ins.2015.07.043</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper builds upon the fundamental work of Niwa et al. [34], which
provides the unique possibility to analyze the relative aggregation/folding
propensity of the elements of the entire Escherichia coli (E. coli) proteome in
a cell-free standardized microenvironment. The hardness of the problem comes
from the superposition between the driving forces of intra- and inter-molecule
interactions and it is mirrored by the evidences of shift from folding to
aggregation phenotypes by single-point mutations [10]. Here we apply several
state-of-the-art classification methods coming from the field of structural
pattern recognition, with the aim to compare different representations of the
same proteins gathered from the Niwa et al. data base; such representations
include sequences and labeled (contact) graphs enriched with chemico-physical
attributes. By this comparison, we are able to identify also some interesting
general properties of proteins. Notably, (i) we suggest a threshold around 250
residues discriminating &quot;easily foldable&quot; from &quot;hardly foldable&quot; molecules
consistent with other independent experiments, and (ii) we highlight the
relevance of contact graph spectra for folding behavior discrimination and
characterization of the E. coli solubility data. The soundness of the
experimental results presented in this paper is proved by the statistically
relevant relationships discovered among the chemico-physical description of
proteins and the developed cost matrix of substitution used in the various
discrimination systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7560</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7560</id><created>2014-07-28</created><authors><author><keyname>Lange</keyname><forenames>Anders Blaabjerg</forenames></author><author><keyname>Schultz</keyname><forenames>Ulrik Pagh</forenames></author><author><keyname>Soerensen</keyname><forenames>Anders Stengaard</forenames></author></authors><title>Towards Automatic Migration of ROS Components from Software to Hardware</title><categories>cs.RO</categories><comments>Presented at DSLRob 2013 (arXiv:cs/1312.5952)</comments><report-no>Report-no: DSLRob/2013/06</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of the ROS middleware is a growing trend in robotics in general, ROS
and hard real-time embedded systems have however not been easily uniteable
while retaining the same overall communication and processing methodology at
all levels. In this paper we present an approach aimed at tackling the schism
between high-level, flexible software and low-level, real-time software. The
key idea of our approach is to enable software components written for a
high-level publish-subscribe software architecture to be automatically migrated
to a dedicated hardware architecture implemented using programmable logic. Our
approach is based on the Unity framework, a unified software/hardware framework
based on FPGAs for quickly interfacing high-level software to low-level
robotics hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7566</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7566</id><created>2014-07-28</created><authors><author><keyname>Strobl</keyname><forenames>Eric V.</forenames></author><author><keyname>Visweswaran</keyname><forenames>Shyam</forenames></author></authors><title>Dependence versus Conditional Dependence in Local Causal Discovery from
  Gene Expression Data</title><categories>q-bio.QM cs.LG stat.ML</categories><comments>11 pages, 2 algorithms, 4 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivation: Algorithms that discover variables which are causally related to
a target may inform the design of experiments. With observational gene
expression data, many methods discover causal variables by measuring each
variable's degree of statistical dependence with the target using dependence
measures (DMs). However, other methods measure each variable's ability to
explain the statistical dependence between the target and the remaining
variables in the data using conditional dependence measures (CDMs), since this
strategy is guaranteed to find the target's direct causes, direct effects, and
direct causes of the direct effects in the infinite sample limit. In this
paper, we design a new algorithm in order to systematically compare the
relative abilities of DMs and CDMs in discovering causal variables from gene
expression data.
  Results: The proposed algorithm using a CDM is sample efficient, since it
consistently outperforms other state-of-the-art local causal discovery
algorithms when samples sizes are small. However, the proposed algorithm using
a CDM outperforms the proposed algorithm using a DM only when sample sizes are
above several hundred. These results suggest that accurate causal discovery
from gene expression data using current CDM-based algorithms requires datasets
with at least several hundred samples.
  Availability: The proposed algorithm is freely available at
https://github.com/ericstrobl/DvCD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7582</identifier>
 <datestamp>2015-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7582</id><created>2014-07-28</created><updated>2015-04-28</updated><authors><author><keyname>Fern&#xe1;ndez-Duque</keyname><forenames>David</forenames></author><author><keyname>Goranko</keyname><forenames>Valentin</forenames></author></authors><title>Secure aggregation of distributed information: How a team of agents can
  safely share secrets in front of a spy</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the generic problem of Secure Aggregation of Distributed
Information (SADI), where several agents acting as a team have information
distributed among them, modeled by means of a publicly known deck of cards
distributed among the agents, so that each of them knows only her cards. The
agents have to exchange and aggregate the information about how the cards are
distributed among them by means of public announcements over insecure
communication channels, intercepted by an adversary &quot;eavesdropper&quot;, in such a
way that the adversary does not learn who holds any of the cards. We present a
combinatorial construction of protocols that provides a direct solution of a
class of SADI problems and develop a technique of iterated reduction of SADI
problems to smaller ones which are eventually solvable directly. We show that
our methods provide a solution to a large class of SADI problems, including all
SADI problems with sufficiently large size and sufficiently balanced card
distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7584</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7584</id><created>2014-07-28</created><authors><author><keyname>Bollegala</keyname><forenames>Danushka</forenames></author></authors><title>Dynamic Feature Scaling for Online Learning of Binary Classifiers</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scaling feature values is an important step in numerous machine learning
tasks. Different features can have different value ranges and some form of a
feature scaling is often required in order to learn an accurate classifier.
However, feature scaling is conducted as a preprocessing task prior to
learning. This is problematic in an online setting because of two reasons.
First, it might not be possible to accurately determine the value range of a
feature at the initial stages of learning when we have observed only a few
number of training instances. Second, the distribution of data can change over
the time, which render obsolete any feature scaling that we perform in a
pre-processing step. We propose a simple but an effective method to dynamically
scale features at train time, thereby quickly adapting to any changes in the
data stream. We compare the proposed dynamic feature scaling method against
more complex methods for estimating scaling parameters using several benchmark
datasets for binary classification. Our proposed feature scaling method
consistently outperforms more complex methods on all of the benchmark datasets
and improves classification accuracy of a state-of-the-art online binary
classifier algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7590</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7590</id><created>2014-07-28</created><authors><author><keyname>Chen</keyname><forenames>Jinyuan</forenames></author><author><keyname>Ozgur</keyname><forenames>Ayfer</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>Feedback through Overhearing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we examine the value of feedback that comes from overhearing,
without dedicated feedback resources. We focus on a simple model for this
purpose: a deterministic two-hop interference channel, where feedback comes
from overhearing the forward-links. A new aspect brought by this setup is the
dual-role of the relay signal. While the relay signal needs to convey the
source message to its corresponding destination, it can also provide a feedback
signal which can potentially increase the capacity of the first hop. We derive
inner and outer bounds on the sum capacity which match for a large range of the
parameter values. Our results identify the parameter ranges where overhearing
can provide non-negative capacity gain and can even achieve the performance
with dedicated-feedback resources. The results also provide insights into which
transmissions are most useful to overhear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7592</identifier>
 <datestamp>2014-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7592</id><created>2014-07-28</created><updated>2014-10-28</updated><authors><author><keyname>Zielenkiewicz</keyname><forenames>Maciej</forenames></author><author><keyname>Schubert</keyname><forenames>Aleksy</forenames></author><author><keyname>Chrz&#x105;szcz</keyname><forenames>Jacek</forenames></author></authors><title>On multiply-exponential write-once Turing machines</title><categories>cs.CC cs.FL</categories><acm-class>F.1.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we analyze the multiply-exponential complexity classes for
write-once Turing machines, i.e. machines that can write to a given tape cell
at most once. We show that $k$-DExpWOSpace = $k$-DExpWOTime = $k$-ExpTime and
the nondeterministic counterpart. For alternating machines we show that
$k$-AExpWOTime = $k$-AExpTime = $k-1$-ExpSpace.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7594</identifier>
 <datestamp>2015-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7594</id><created>2014-07-28</created><updated>2015-03-06</updated><authors><author><keyname>Kamble</keyname><forenames>Vijay</forenames></author><author><keyname>Walrand</keyname><forenames>Jean</forenames></author></authors><title>Monotonic Preference Aggregation Mechanisms for Purchasing a Shareable
  Resource</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Situations where a group of agents come together to jointly buy a resource
that they individually cannot afford to buy are commonly observed in markets.
For example in the US market for radio spectrum, a recent proposal invited
small firms who would benefit from gaining additional access to spectrum to
jointly submit bids for blocks of spectrum with the idea that its utilization
could be shared. In such a scenario, the problem is to design a mechanism that
truthfully elicits and aggregates the privately held preferences of these
agents, and enables them to act as a single decision-making body in order to
participate in the market. In this paper, we design a class of mechanisms
called monotonic aggregation mechanisms that achieves this under a specific
setting. We assume that the resource is being sold in a sealed-bid second-price
auction that solicits bids for the entire resource. Our mechanism truthfully
elicits utility functions from the buyers, prescribes a joint bid, and
prescribes a division of the payment and the resource in the event that they
win the resource in the auction. This mechanism further satisfies a popular
notion of collusion-resistance known as coalition-strategyproofness. We give
two explicit examples of this generic class for the case where the utility
functions of the buyers are non-decreasing and concave.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7598</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7598</id><created>2014-07-28</created><authors><author><keyname>Kaminaga</keyname><forenames>Masahiro</forenames></author><author><keyname>Yoshikawa</keyname><forenames>Hideki</forenames></author><author><keyname>Suzuki</keyname><forenames>Toshinori</forenames></author></authors><title>Double Counting in $2^t$-ary RSA Precomputation Reveals the Secret
  Exponent</title><categories>cs.CR</categories><acm-class>E.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new fault attack, double counting attack (DCA), on the precomputation of
$2^t$-ary modular exponentiation for a classical RSA digital signature (i.e.,
RSA without the Chinese remainder theorem) is proposed. The $2^t$-ary method is
the most popular and widely used algorithm to speed up the RSA signature
process. Developers can realize the fastest signature process by choosing
optimum $t$. For example, $t=6$ is optimum for a 1536-bit classical RSA
implementation. The $2^t$-ary method requires precomputation to generate small
exponentials of message. Conventional fault attack research has paid little
attention to precomputation, even though precomputation could be a target of a
fault attack. The proposed DCA induces faults in precomputation by using
instruction skip technique, which is equivalent to replacing an instruction
with a no operation in assembly language. This paper also presents a useful
&quot;position checker&quot; tool to determine the position of the $2^t$-ary coefficients
of the secret exponent from signatures based on faulted precomputations. The
DCA is demonstrated to be an effective attack method for some widely used
parameters. DCA can reconstruct an entire secret exponent using the position
checker with $63(=2^6-1)$ faulted signatures in a short time for a 1536-bit RSA
implementation using the $2^6$-ary method. The DCA process can be accelerated
for a small public exponent (e.g., 65537). The the best of our knowledge, the
proposed DCA is the first fault attack against classical RSA precomputation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7604</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7604</id><created>2014-07-28</created><authors><author><keyname>Nguyen</keyname><forenames>Viet Hang</forenames></author></authors><title>Induced matchings in graphs of degree at most 4</title><categories>cs.DM math.CO</categories><comments>14 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that if $G$ is a connected graph of maximum degree at most $4$, which
is not $C_{2,5}$, then the strong matching number of $G$ is at least
$\frac{1}{9}n(G)$. This bound is tight and the proof implies a polynomial time
algorithm to find an induced matching of this size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7618</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7618</id><created>2014-07-28</created><authors><author><keyname>Zahr</keyname><forenames>Matthew J.</forenames></author><author><keyname>Farhat</keyname><forenames>Charbel</forenames></author></authors><title>Progressive construction of a parametric reduced-order model for
  PDE-constrained optimization</title><categories>math.OC cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An adaptive approach to using reduced-order models as surrogates in
PDE-constrained optimization is introduced that breaks the traditional
offline-online framework of model order reduction. A sequence of optimization
problems constrained by a given Reduced-Order Model (ROM) is defined with the
goal of converging to the solution of a given PDE-constrained optimization
problem. For each reduced optimization problem, the constraining ROM is trained
from sampling the High-Dimensional Model (HDM) at the solution of some of the
previous problems in the sequence. The reduced optimization problems are
equipped with a nonlinear trust-region based on a residual error indicator to
keep the optimization trajectory in a region of the parameter space where the
ROM is accurate. A technique for incorporating sensitivities into a
Reduced-Order Basis (ROB) is also presented, along with a methodology for
computing sensitivities of the reduced-order model that minimizes the distance
to the corresponding HDM sensitivity, in a suitable norm. The proposed reduced
optimization framework is applied to subsonic aerodynamic shape optimization
and shown to reduce the number of queries to the HDM by a factor of 4-5,
compared to the optimization problem solved using only the HDM, with errors in
the optimal solution far less than 0.1%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7626</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7626</id><created>2014-07-29</created><authors><author><keyname>Nayak</keyname><forenames>Deepak Ranjan</forenames></author><author><keyname>Patra</keyname><forenames>Prashanta Kumar</forenames></author><author><keyname>Mahapatra</keyname><forenames>Amitav</forenames></author></authors><title>A Survey on Two Dimensional Cellular Automata and Its Application in
  Image Processing</title><categories>cs.CV</categories><comments>10 pages, 10 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel algorithms for solving any image processing task is a highly
demanded approach in the modern world. Cellular Automata (CA) are the most
common and simple models of parallel computation. So, CA has been successfully
used in the domain of image processing for the last couple of years. This paper
provides a survey of available literatures of some methodologies employed by
different researchers to utilize the cellular automata for solving some
important problems of image processing. The survey includes some important
image processing tasks such as rotation, zooming, translation, segmentation,
edge detection, compression and noise reduction of images. Finally, the
experimental results of some methodologies are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7629</identifier>
 <datestamp>2015-04-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7629</id><created>2014-07-29</created><updated>2015-04-03</updated><authors><author><keyname>Sutter</keyname><forenames>Tobias</forenames></author><author><keyname>Sutter</keyname><forenames>David</forenames></author><author><keyname>Esfahani</keyname><forenames>Peyman Mohajerin</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>Efficient Approximation of Channel Capacities</title><categories>cs.IT math.IT math.OC</categories><comments>32 pages, 3 figures, revised version</comments><msc-class>94A15, 90C25</msc-class><journal-ref>IEEE Transactions on Information Theory vol. 61, no 4, pages
  1649-1666, 2015</journal-ref><doi>10.1109/TIT.2015.2401002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an iterative method for approximately computing the capacity of
discrete memoryless channels, possibly under additional constraints on the
input distribution. Based on duality of convex programming, we derive explicit
upper and lower bounds for the capacity. The presented method requires $O(M^2 N
\sqrt{\log N}/\varepsilon)$ to provide an estimate of the capacity to within
$\varepsilon$, where $N$ and $M$ denote the input and output alphabet size; a
single iteration has a complexity $O(M N)$. We also show how to approximately
compute the capacity of memoryless channels having a bounded continuous input
alphabet and a countable output alphabet under some mild assumptions on the
decay rate of the channel's tail. It is shown that discrete-time Poisson
channels fall into this problem class. As an example, we compute sharp upper
and lower bounds for the capacity of a discrete-time Poisson channel with a
peak-power input constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7635</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7635</id><created>2014-07-29</created><authors><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Koren</keyname><forenames>Tomer</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Chasing Ghosts: Competing with Stateful Policies</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider sequential decision making in a setting where regret is measured
with respect to a set of stateful reference policies, and feedback is limited
to observing the rewards of the actions performed (the so called &quot;bandit&quot;
setting). If either the reference policies are stateless rather than stateful,
or the feedback includes the rewards of all actions (the so called &quot;expert&quot;
setting), previous work shows that the optimal regret grows like
$\Theta(\sqrt{T})$ in terms of the number of decision rounds $T$.
  The difficulty in our setting is that the decision maker unavoidably loses
track of the internal states of the reference policies, and thus cannot
reliably attribute rewards observed in a certain round to any of the reference
policies. In fact, in this setting it is impossible for the algorithm to
estimate which policy gives the highest (or even approximately highest) total
reward. Nevertheless, we design an algorithm that achieves expected regret that
is sublinear in $T$, of the form $O( T/\log^{1/4}{T})$. Our algorithm is based
on a certain local repetition lemma that may be of independent interest. We
also show that no algorithm can guarantee expected regret better than $O(
T/\log^{3/2} T)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7636</identifier>
 <datestamp>2014-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7636</id><created>2014-07-29</created><updated>2014-10-22</updated><authors><author><keyname>Xu</keyname><forenames>Qianqian</forenames></author><author><keyname>Yan</keyname><forenames>Ming</forenames></author><author><keyname>Yao</keyname><forenames>Yuan</forenames></author></authors><title>Fast Adaptive Algorithm for Robust Evaluation of Quality of Experience</title><categories>cs.MM</categories><comments>13 pages, 2 figures, 11 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Outlier detection is an integral part of robust evaluation for
crowdsourceable Quality of Experience (QoE) and has attracted much attention in
recent years. In QoE for multimedia, outliers happen because of different test
conditions, human errors, abnormal variations in context, {etc}. In this paper,
we propose a simple yet effective algorithm for outlier detection and robust
QoE evaluation named iterative Least Trimmed Squares (iLTS). The algorithm
assigns binary weights to samples, i.e., 0 or 1 indicating if a sample is an
outlier, then the outlier-trimmed subset least squares solutions give robust
ranking scores. An iterative optimization is carried alternatively between
updating weights and ranking scores which converges to a local optimizer in
finite steps. In our test setting, iLTS is up to 190 times faster than
LASSO-based methods with a comparable performance. Moreover, a varied version
of this method shows adaptation in outlier detection, which provides an
automatic detection to determine whether a data sample is an outlier without
\emph{a priori} knowledge about the amount of the outliers. The effectiveness
and efficiency of iLTS are demonstrated on both simulated examples and
real-world applications. A Matlab package is provided to researchers exploiting
crowdsourcing paired comparison data for robust ranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7644</identifier>
 <datestamp>2014-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7644</id><created>2014-07-29</created><updated>2014-10-30</updated><authors><author><keyname>Jaffe</keyname><forenames>Ariel</forenames></author><author><keyname>Nadler</keyname><forenames>Boaz</forenames></author><author><keyname>Kluger</keyname><forenames>Yuval</forenames></author></authors><title>Estimating the Accuracies of Multiple Classifiers Without Labeled Data</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In various situations one is given only the predictions of multiple
classifiers over a large unlabeled test data. This scenario raises the
following questions: Without any labeled data and without any a-priori
knowledge about the reliability of these different classifiers, is it possible
to consistently and computationally efficiently estimate their accuracies?
Furthermore, also in a completely unsupervised manner, can one construct a more
accurate unsupervised ensemble classifier? In this paper, focusing on the
binary case, we present simple, computationally efficient algorithms to solve
these questions. Furthermore, under standard classifier independence
assumptions, we prove our methods are consistent and study their asymptotic
error. Our approach is spectral, based on the fact that the off-diagonal
entries of the classifiers' covariance matrix and 3-d tensor are rank-one. We
illustrate the competitive performance of our algorithms via extensive
experiments on both artificial and real datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7650</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7650</id><created>2014-07-29</created><authors><author><keyname>Harks</keyname><forenames>Tobias</forenames></author><author><keyname>Klimm</keyname><forenames>Max</forenames></author><author><keyname>Peis</keyname><forenames>Britta</forenames></author></authors><title>Resource Competition on Integral Polymatroids</title><categories>cs.GT cs.DM math.OC</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study competitive resource allocation problems in which players distribute
their demands integrally on a set of resources subject to player-specific
submodular capacity constraints. Each player has to pay for each unit of demand
a cost that is a nondecreasing and convex function of the total allocation of
that resource. This general model of resource allocation generalizes both
singleton congestion games with integer-splittable demands and matroid
congestion games with player-specific costs. As our main result, we show that
in such general resource allocation problems a pure Nash equilibrium is
guaranteed to exist by giving a pseudo-polynomial algorithm computing a pure
Nash equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7654</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7654</id><created>2014-07-29</created><authors><author><keyname>Bampis</keyname><forenames>Evripidis</forenames></author><author><keyname>Letsios</keyname><forenames>Dimitrios</forenames></author><author><keyname>Lucarelli</keyname><forenames>Giorgio</forenames></author></authors><title>Speed-scaling with no Preemptions</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the non-preemptive speed-scaling problem, in which a set of jobs
have to be executed on a single or a set of parallel speed-scalable
processor(s) between their release dates and deadlines so that the energy
consumption to be minimized. We adopt the speed-scaling mechanism first
introduced in [Yao et al., FOCS 1995] according to which the power dissipated
is a convex function of the processor's speed. Intuitively, the higher is the
speed of a processor, the higher is the energy consumption. For the
single-processor case, we improve the best known approximation algorithm by
providing a $(1+\epsilon)^{\alpha}\tilde{B}_{\alpha}$-approximation algorithm,
where $\tilde{B}_{\alpha}$ is a generalization of the Bell number. For the
multiprocessor case, we present an approximation algorithm of ratio
$\tilde{B}_{\alpha}((1+\epsilon)(1+\frac{w_{\max}}{w_{\min}}))^{\alpha}$
improving the best known result by a factor of
$(\frac{5}{2})^{\alpha-1}(\frac{w_{\max}}{w_{\min}})^{\alpha}$. Notice that our
result holds for the fully heterogeneous environment while the previous known
result holds only in the more restricted case of parallel processors with
identical power functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7663</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7663</id><created>2014-07-29</created><authors><author><keyname>Corus</keyname><forenames>Dogan</forenames></author><author><keyname>Dang</keyname><forenames>Duc-Cuong</forenames></author><author><keyname>Eremeev</keyname><forenames>Anton V.</forenames></author><author><keyname>Lehre</keyname><forenames>Per Kristian</forenames></author></authors><title>Level-based Analysis of Genetic Algorithms and other Search Processes</title><categories>cs.NE q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fitness-level technique is a simple and old way to derive upper bounds
for the expected runtime of simple elitist evolutionary algorithms (EAs).
Recently, the technique has been adapted to deduce the runtime of algorithms
with non-elitist populations and unary variation operators. In this paper, we
show that the restriction to unary variation operators can be removed.
  This gives rise to a much more general analytical tool which is applicable to
a wide range of search processes. As introductory examples, we provide simple
runtime analyses of many variants of the Genetic Algorithm on well-known
benchmark functions, such as OneMax, LeadingOnes, and the sorting problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7667</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7667</id><created>2014-07-29</created><updated>2014-08-01</updated><authors><author><keyname>Zsak</keyname><forenames>Norbert</forenames></author><author><keyname>Wolff</keyname><forenames>Christian</forenames></author></authors><title>Impact of video quality and wireless network interface on power
  consumption of mobile devices</title><categories>cs.MM</categories><comments>2 pages, 1 figure, unpublished short paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last years, many improvements were made to the hardware capability
of mobile devices. As mobile software also became more interactive and data
processing intensive, the increased power demand could not be compensated by
the improvements on battery technology. Adaptive systems can help to balance
the demand of applications with the limitations of battery resources. For
effective systems, the influence of multimedia quality on power consumption of
the components of mobile devices needs to be better understood. In this paper,
we analyze the impact of video quality and wireless network type on the energy
consumption of a mobile device. We have found that the additional power
consumption is up to 38% higher when a movie is played over a WiFi network
instead from internal memory and 64% higher in case of a mobile network (3G).
We have also discovered that a higher movie quality not only affects the power
consumption of the CPU but also the power consumption of the WiFi unit by up to
58% and up to 72% respectively on mobile networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7671</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7671</id><created>2014-07-29</created><authors><author><keyname>Bo&#x161;na&#x10d;ki</keyname><forenames>Dragan</forenames><affiliation>Eindhoven University of Technology</affiliation></author><author><keyname>Edelkamp</keyname><forenames>Stefan</forenames><affiliation>University of Bremen</affiliation></author><author><keyname>Lafuente</keyname><forenames>Alberto Lluch</forenames><affiliation>Technical University of Denmark</affiliation></author><author><keyname>Wijs</keyname><forenames>Anton</forenames><affiliation>Eindhoven University of Technology</affiliation></author></authors><title>Proceedings 3rd Workshop on GRAPH Inspection and Traversal Engineering</title><categories>cs.LO cs.DS cs.FL</categories><proxy>EPTCS</proxy><acm-class>D.2.4; I.2.8</acm-class><journal-ref>EPTCS 159, 2014</journal-ref><doi>10.4204/EPTCS.159</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  These are the proceedings of the Third Workshop on GRAPH Inspection and
Traversal Engineering (GRAPHITE 2014), which took place on April 5, 2014 in
Grenoble, France, as a satellite event of the 17th European Joint Conferences
on Theory and Practice of Software (ETAPS 2014).
  The aim of GRAPHITE is to foster the convergence on research interests from
several communities dealing with graph analysis in all its forms in computer
science, with a particular attention to software development and analysis.
Graphs are used to represent data and processes in many application areas, and
they are subjected to various computational algorithms in order to analyze
them. Just restricting the attention to the analysis of software, graph
analysis algorithms are used, for instance, to verify properties using model
checking techniques that explore the system's state space graph or static
analysis techniques based on control flow graphs. Further application domains
include games, planning, and network analysis. Very often, graph problems and
their algorithmic solutions have common characteristics, independent of their
application domain. The goal of this event is to gather scientists from
different communities, who do research on graph analysis algorithms, such that
awareness of each others' work is increased. More information can be found at
http://sysma.imtlucca.it/graphite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7680</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7680</id><created>2014-07-29</created><authors><author><keyname>Ayaz</keyname><forenames>Ula&#x15f;</forenames></author><author><keyname>Dirksen</keyname><forenames>Sjoerd</forenames></author><author><keyname>Rauhut</keyname><forenames>Holger</forenames></author></authors><title>Uniform recovery of fusion frame structured sparse signals</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recovering fusion frame sparse signals from
incomplete measurements. These signals are composed of a small number of
nonzero blocks taken from a family of subspaces. First, we show that, by using
a-priori knowledge of a coherence parameter associated with the angles between
the subspaces, one can uniformly recover fusion frame sparse signals with a
significantly reduced number of vector-valued (sub-)Gaussian measurements via
mixed l^1/l^2-minimization. We prove this by establishing an appropriate
version of the restricted isometry property. Our result complements previous
nonuniform recovery results in this context, and provides stronger stability
guarantees for noisy measurements and approximately sparse signals. Second, we
determine the minimal number of scalar-valued measurements needed to uniformly
recover all fusion frame sparse signals via mixed l^1/l^2-minimization. This
bound is achieved by scalar-valued subgaussian measurements. In particular, our
result shows that the number of scalar-valued subgaussian measurements cannot
be further reduced using knowledge of the coherence parameter. As a special
case it implies that the best known uniform recovery result for block sparse
signals using subgaussian measurements is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7686</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7686</id><created>2014-07-29</created><authors><author><keyname>Khan</keyname><forenames>Zohaib</forenames></author></authors><title>Hyperspectral Imaging and Analysis for Sparse Reconstruction and
  Recognition</title><categories>cs.CV</categories><comments>PhD Thesis, School of Computer Science and Software Engineering, The
  University of Western Australia</comments><acm-class>I.4.1; I.4.5; I.4.7; I.4.10; I.5.4; I.7.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis proposes spatio-spectral techniques for hyperspectral image
analysis. Adaptive spatio-spectral support and variable exposure hyperspectral
imaging is demonstrated to improve spectral reflectance recovery from
hyperspectral images. Novel spectral dimensionality reduction techniques have
been proposed from the perspective of spectral only and spatio-spectral
information preservation. It was found that the joint sparse and joint group
sparse hyperspectral image models achieve lower reconstruction error and higher
recognition accuracy using only a small subset of bands. Hyperspectral image
databases have been developed and made publicly available for further research
in compressed hyperspectral imaging, forensic document analysis and spectral
reflectance recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7691</identifier>
 <datestamp>2014-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7691</id><created>2014-07-29</created><authors><author><keyname>Rapin</keyname><forenames>J&#xe9;r&#xe9;my</forenames></author><author><keyname>Bobin</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Larue</keyname><forenames>Anthony</forenames></author><author><keyname>Starck</keyname><forenames>Jean-Luc</forenames></author></authors><title>NMF with Sparse Regularizations in Transformed Domains</title><categories>stat.ML cs.LG</categories><comments>26 pages, 19 figures, accepted in SIAM Journal on Imaging Sciences</comments><msc-class>94A12</msc-class><acm-class>I.5.4</acm-class><journal-ref>SIAM J. Imaging Sci., 7(4), 2020-2047. (28 pages)</journal-ref><doi>10.1137/140952314</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-negative blind source separation (non-negative BSS), which is also
referred to as non-negative matrix factorization (NMF), is a very active field
in domains as different as astrophysics, audio processing or biomedical signal
processing. In this context, the efficient retrieval of the sources requires
the use of signal priors such as sparsity. If NMF has now been well studied
with sparse constraints in the direct domain, only very few algorithms can
encompass non-negativity together with sparsity in a transformed domain since
simultaneously dealing with two priors in two different domains is challenging.
In this article, we show how a sparse NMF algorithm coined non-negative
generalized morphological component analysis (nGMCA) can be extended to impose
non-negativity in the direct domain along with sparsity in a transformed
domain, with both analysis and synthesis formulations. To our knowledge, this
work presents the first comparison of analysis and synthesis priors ---as well
as their reweighted versions--- in the context of blind source separation.
Comparisons with state-of-the-art NMF algorithms on realistic data show the
efficiency as well as the robustness of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7693</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7693</id><created>2014-07-29</created><authors><author><keyname>Frontoni</keyname><forenames>Emanuele</forenames></author><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Zingaretti</keyname><forenames>Primo</forenames></author><author><keyname>Landro</keyname><forenames>Vincenzo</forenames></author><author><keyname>Misericordia</keyname><forenames>Paolo</forenames></author></authors><title>Security issues for data sharing and service interoperability in eHealth
  systems: the Nu.Sa. test bed</title><categories>cs.CR cs.CY</categories><comments>6 pages, 1 figure, to be presented at the International Carnahan
  Conference on Security Technology, Rome, Italy, 13-16 October 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of the Nu.Sa. project is the definition of national level data
standards to collect data coming from General Practitioners' Electronic Health
Records and to allow secure data sharing between them. This paper introduces
the Nu.Sa. framework and is mainly focused on security issues. A solution for
secure data sharing and service interoperability is presented and implemented
in the actual system used around Italy. The solution is strongly focused on
privacy and correct data sharing with a complete set of tools devoted to
authorization, encryption and decryption in a data sharing environment and a
distributed architecture. The implemented system with more than one year of
experiences in thousands of test cases shows a good feasibility of the approach
and a future scalability in a cloud based architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7715</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7715</id><created>2014-07-29</created><authors><author><keyname>Sellami</keyname><forenames>Lynda</forenames></author><author><keyname>Idoughi</keyname><forenames>Djilali</forenames></author><author><keyname>Baadache</keyname><forenames>Abderahmane</forenames></author></authors><title>Intrusions Detection System Based on Ubiquitous Network Nodes</title><categories>cs.CR cs.NI</categories><comments>6 pages, 3 figures, The Fourth International Conference on Advanced
  Communications and Computation. 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ubiquitous computing allows to make data and services within the reach of
users anytime and anywhere. This makes ubiquitous networks vulnerable to
attacks coming from either inside or outside the network. To ensure and enhance
networks security, several solutions have been implemented. These solutions are
inefficient and or incomplete. Solving these challenges in security with new
requirement of Ubicomp, could provide a potential future for such systems
towards better mobility and higher confidence level of end user services. We
investigate the possibility to detect network intrusions, based on security
nodes abilities. Specifically, we show how authentication can help build user
profiles in each network node. Authentication is based on permissions and
restrictions to access to information and services on ubiquitous network. As a
result, our idea realizes a protection of nodes and assures security of
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7722</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7722</id><created>2014-07-29</created><updated>2014-08-01</updated><authors><author><keyname>Vanschoren</keyname><forenames>Joaquin</forenames></author><author><keyname>van Rijn</keyname><forenames>Jan N.</forenames></author><author><keyname>Bischl</keyname><forenames>Bernd</forenames></author><author><keyname>Torgo</keyname><forenames>Luis</forenames></author></authors><title>OpenML: networked science in machine learning</title><categories>cs.LG cs.CY</categories><comments>12 pages, 10 figures</comments><journal-ref>SIGKDD Explor. Newsl. 15, 2 (June 2014), 49-60</journal-ref><doi>10.1145/2641190.2641198</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Many sciences have made significant breakthroughs by adopting online tools
that help organize, structure and mine information that is too detailed to be
printed in journals. In this paper, we introduce OpenML, a place for machine
learning researchers to share and organize data in fine detail, so that they
can work more effectively, be more visible, and collaborate with others to
tackle harder problems. We discuss how OpenML relates to other examples of
networked science and what benefits it brings for machine learning research,
individual scientists, as well as students and practitioners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7729</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7729</id><created>2014-07-29</created><updated>2014-09-15</updated><authors><author><keyname>Boldi</keyname><forenames>Paolo</forenames></author><author><keyname>Crimaldi</keyname><forenames>Irene</forenames></author><author><keyname>Monti</keyname><forenames>Corrado</forenames></author></authors><title>A Network Model characterized by a Latent Attribute Structure with
  Competition</title><categories>cs.SI math.PR physics.data-an physics.soc-ph</categories><comments>34 pages, second version (date of the first version: July, 2014).
  Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quest for a model that is able to explain, describe, analyze and simulate
real-world complex networks is of uttermost practical as well as theoretical
interest. In this paper we introduce and study a network model that is based on
a latent attribute structure: each node is characterized by a number of
features and the probability of the existence of an edge between two nodes
depends on the features they share. Features are chosen according to a process
of Indian-Buffet type but with an additional random &quot;fitness&quot; parameter
attached to each node, that determines its ability to transmit its own features
to other nodes. As a consequence, a node's connectivity does not depend on its
age alone, so also &quot;young&quot; nodes are able to compete and succeed in acquiring
links. One of the advantages of our model for the latent bipartite
&quot;node-attribute&quot; network is that it depends on few parameters with a
straightforward interpretation. We provide some theoretical, as well
experimental, results regarding the power-law behaviour of the model and the
estimation of the parameters. By experimental data, we also show how the
proposed model for the attribute structure naturally captures most local and
global properties (e.g., degree distributions, connectivity and distance
distributions) real networks exhibit. keyword: Complex network, social network,
attribute matrix, Indian Buffet process
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7733</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7733</id><created>2014-07-29</created><authors><author><keyname>Barousis</keyname><forenames>Vlasis I.</forenames></author><author><keyname>Sedaghat</keyname><forenames>Mohammad A.</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Ralf R.</forenames></author><author><keyname>Papadias</keyname><forenames>Constantinos B.</forenames></author></authors><title>Massive Antenna Arrays with Low Front-End Hardware Complexity: An
  Enabling Technology for the Emerging Small Cell and Distributed Network
  Architectures</title><categories>cs.NI cs.IT math.IT</categories><comments>10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the current state-of-the-art of massive antenna array
architectures with significant front-end hardware savings, as an enabler for
future small and powerful cell nodes that will be able to carry massive MIMO
technology. Radio frequency (RF) hardware architectures with a single power
amplifier are reviewed, compared, and found superior to conventional MIMO
implementations in terms of cost, dissipated heat, and physical size. This
progress on the RF-side allows to merge the two competing cellular concepts of
virtual and massive MIMO into a hybrid approach of remote radio heads with
massive MIMO arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7736</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7736</id><created>2014-07-29</created><authors><author><keyname>Qin</keyname><forenames>Xiangju</forenames></author><author><keyname>Greene</keyname><forenames>Derek</forenames></author><author><keyname>Cunningham</keyname><forenames>P&#xe1;draig</forenames></author></authors><title>A Latent Space Analysis of Editor Lifecycles in Wikipedia</title><categories>cs.SI cs.CL cs.CY physics.soc-ph</categories><comments>16 pages, In Proc. of 5th International Workshop on Mining Ubiquitous
  and Social Environments (MUSE) at ECML/PKDD 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborations such as Wikipedia are a key part of the value of the modern
Internet. At the same time there is concern that these collaborations are
threatened by high levels of member turnover. In this paper we borrow ideas
from topic analysis to editor activity on Wikipedia over time into a latent
space that offers an insight into the evolving patterns of editor behavior.
This latent space representation reveals a number of different categories of
editor (e.g. content experts, social networkers) and we show that it does
provide a signal that predicts an editor's departure from the community. We
also show that long term editors gradually diversify their participation by
shifting edit preference from one or two namespaces to multiple namespaces and
experience relatively soft evolution in their editor profiles, while short term
editors generally distribute their contribution randomly among the namespaces
and experience considerably fluctuated evolution in their editor profiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7737</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7737</id><created>2014-07-29</created><authors><author><keyname>Ding</keyname><forenames>Ke</forenames></author><author><keyname>Tan</keyname><forenames>Ying</forenames></author></authors><title>A CUDA-Based Real Parameter Optimization Benchmark</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Benchmarking is key for developing and comparing optimization algorithms. In
this paper, a CUDA-based real parameter optimization benchmark (cuROB) is
introduced. Test functions of diverse properties are included within cuROB and
implemented efficiently with CUDA. Speedup of one order of magnitude can be
achieved in comparison with CPU-based benchmark of CEC'14.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7740</identifier>
 <datestamp>2015-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7740</id><created>2014-07-29</created><updated>2015-02-24</updated><authors><author><keyname>Cummings</keyname><forenames>Rachel</forenames></author><author><keyname>Kearns</keyname><forenames>Michael</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Wu</keyname><forenames>Zhiwei Steven</forenames></author></authors><title>Privacy and Truthful Equilibrium Selection for Aggregative Games</title><categories>cs.DS cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a very general class of games --- multi-dimensional aggregative
games --- which in particular generalize both anonymous games and weighted
congestion games. For any such game that is also large, we solve the
equilibrium selection problem in a strong sense. In particular, we give an
efficient weak mediator: a mechanism which has only the power to listen to
reported types and provide non-binding suggested actions, such that (a) it is
an asymptotic Nash equilibrium for every player to truthfully report their type
to the mediator, and then follow its suggested action; and (b) that when
players do so, they end up coordinating on a particular asymptotic pure
strategy Nash equilibrium of the induced complete information game. In fact,
truthful reporting is an ex-post Nash equilibrium of the mediated game, so our
solution applies even in settings of incomplete information, and even when
player types are arbitrary or worst-case (i.e. not drawn from a common prior).
We achieve this by giving an efficient differentially private algorithm for
computing a Nash equilibrium in such games. The rates of convergence to
equilibrium in all of our results are inverse polynomial in the number of
players $n$. We also apply our main results to a multi-dimensional market game.
  Our results can be viewed as giving, for a rich class of games, a more robust
version of the Revelation Principle, in that we work with weaker informational
assumptions (no common prior), yet provide a stronger solution concept (ex-post
Nash versus Bayes Nash equilibrium). In comparison to previous work, our main
conceptual contribution is showing that weak mediators are a game theoretic
object that exist in a wide variety of games -- previously, they were only
known to exist in traffic routing games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7753</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7753</id><created>2014-07-29</created><authors><author><keyname>de Fran&#xe7;a</keyname><forenames>Fabricio Olivetti</forenames></author></authors><title>A Hash-based Co-Clustering Algorithm for Categorical Data</title><categories>cs.LG</categories><comments>This work was submitted to IEEE TKDE on July 29, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-life data are described by categorical attributes without a
pre-classification. A common data mining method used to extract information
from this type of data is clustering. This method group together the samples
from the data that are more similar than all other samples. But, categorical
data pose a challenge when extracting information because: the calculation of
two objects similarity is usually done by measuring the number of common
features, but ignore a possible importance weighting; if the data may be
divided differently according to different subsets of the features, the
algorithm may find clusters with different meanings from each other,
difficulting the post analysis. Data Co-Clustering of categorical data is the
technique that tries to find subsets of samples that share a subset of features
in common. By doing so, not only a sample may belong to more than one cluster
but, the feature selection of each cluster describe its own characteristics. In
this paper a novel Co-Clustering technique for categorical data is proposed by
using Locality Sensitive Hashing technique in order to preprocess a list of
Co-Clusters seeds based on a previous research. Results indicate this technique
is capable of finding high quality Co-Clusters in many different categorical
data sets and scales linearly with the data set size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7759</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7759</id><created>2014-07-29</created><authors><author><keyname>Bhangale</keyname><forenames>Amey</forenames></author><author><keyname>Kopparty</keyname><forenames>Swastik</forenames></author><author><keyname>Sachdeva</keyname><forenames>Sushant</forenames></author></authors><title>Simultaneous Approximation of Constraint Satisfaction Problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given $k$ collections of 2SAT clauses on the same set of variables $V$, can
we find one assignment that satisfies a large fraction of clauses from each
collection? We consider such simultaneous constraint satisfaction problems, and
design the first nontrivial approximation algorithms in this context.
  Our main result is that for every CSP $F$, for $k &lt; \tilde{O}(\log^{1/4} n)$,
there is a polynomial time constant factor Pareto approximation algorithm for
$k$ simultaneous Max-$F$-CSP instances. Our methods are quite general, and we
also use them to give an improved approximation factor for simultaneous
Max-w-SAT (for $k &lt;\tilde{O}(\log^{1/3} n)$). In contrast, for $k = \omega(\log
n)$, no nonzero approximation factor for $k$ simultaneous Max-$F$-CSP instances
can be achieved in polynomial time (assuming the Exponential Time Hypothesis).
  These problems are a natural meeting point for the theory of constraint
satisfaction problems and multiobjective optimization. We also suggest a number
of interesting directions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7763</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7763</id><created>2014-07-29</created><updated>2014-08-04</updated><authors><author><keyname>O'Donnell</keyname><forenames>Ryan</forenames></author></authors><title>Social choice, computational complexity, Gaussian geometry, and Boolean
  functions</title><categories>math.PR cs.CC cs.DM</categories><comments>In proceedings of the 2014 ICM. Corrected a few minor typos from
  previous version</comments><msc-class>91B14, 03D15, 94C10, 51M16, 60G15</msc-class><acm-class>G.1.6; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a web of connections between the following topics: the
mathematical theory of voting and social choice; the computational complexity
of the Maximum Cut problem; the Gaussian Isoperimetric Inequality and Borell's
generalization thereof; the Hypercontractive Inequality of Bonami; and, the
analysis of Boolean functions. A major theme is the technique of reducing
inequalities about Gaussian functions to inequalities about Boolean functions f
: {-1,1}^n -&gt; {-1,1}, and then using induction on n to further reduce to
inequalities about functions f : {-1,1} -&gt; {-1,1}. We especially highlight De,
Mossel, and Neeman's recent use of this technique to prove the Majority Is
Stablest Theorem and Borell's Isoperimetric Inequality simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7780</identifier>
 <datestamp>2014-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7780</id><created>2014-07-29</created><updated>2014-12-16</updated><authors><author><keyname>Han</keyname><forenames>Tao</forenames></author><author><keyname>Ansari</keyname><forenames>Nirwan</forenames></author></authors><title>A Traffic Load Balancing Framework for Software-defined Radio Access
  Networks Powered by Hybrid Energy Sources</title><categories>cs.NI</categories><report-no>TR-ANL-2014-05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dramatic mobile data traffic growth has spurred a dense deployment of small
cell base stations (SCBSs). Small cells enhance the spectrum efficiency and
thus enlarge the capacity of mobile networks. Although SCBSs consume much less
power than macro BSs (MBSs) do, the overall power consumption of a large number
of SCBSs is phenomenal. As the energy harvesting technology advances, base
stations (BSs) can be powered by green energy to alleviate the on-grid power
consumption. For mobile networks with high BS density, traffic load balancing
is critical in order to exploit the capacity of SCBSs. To fully utilize
harvested energy, it is desirable to incorporate the green energy utilization
as a performance metric in traffic load balancing strategies. In this paper, we
have proposed a traffic load balancing framework that strives a balance between
network utilities, e.g., the average traffic delivery latency, and the green
energy utilization. Various properties of the proposed framework have been
derived. Leveraging the software-defined radio access network architecture, the
proposed scheme is implemented as a virtually distributed algorithm, which
significantly reduces the communication overheads between users and BSs. The
simulation results show that the proposed traffic load balancing framework
enables an adjustable trade-off between the on-grid power consumption and the
average traffic delivery latency, and saves a considerable amount of on-grid
power, e.g., 30%, at a cost of only a small increase, e.g., 8%, of the average
traffic delivery latency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7786</identifier>
 <datestamp>2015-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7786</id><created>2014-07-29</created><updated>2015-08-28</updated><authors><author><keyname>Pearson</keyname><forenames>John W.</forenames></author><author><keyname>Olver</keyname><forenames>Sheehan</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author></authors><title>Numerical Methods for the Computation of the Confluent and Gauss
  Hypergeometric Functions</title><categories>math.NA cs.MS math-ph math.MP physics.comp-ph</categories><comments>42 pages</comments><msc-class>Primary: 33C05, 33C15, Secondary: 41A58, 41A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two most commonly used hypergeometric functions are the confluent
hypergeometric function and the Gauss hypergeometric function. We review the
available techniques for accurate, fast, and reliable computation of these two
hypergeometric functions in different parameter and variable regimes. The
methods that we investigate include Taylor and asymptotic series computations,
Gauss-Jacobi quadrature, numerical solution of differential equations,
recurrence relations, and others. We discuss the results of numerical
experiments used to determine the best methods, in practice, for each parameter
and variable regime considered. We provide 'roadmaps' with our recommendation
for which methods should be used in each situation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7790</identifier>
 <datestamp>2015-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7790</id><created>2014-07-29</created><authors><author><keyname>Cheung</keyname><forenames>Kent Tsz Kan</forenames></author><author><keyname>Yang</keyname><forenames>Shaoshi</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Spectral and Energy Spectral Efficiency Optimization of Joint Transmit
  and Receive Beamforming Based Multi-Relay MIMO-OFDMA Cellular Networks</title><categories>cs.IT math.IT</categories><comments>17 pages, 10 figures, 1 table, 3 algorithms, to appear in IEEE
  Transactions on Wireless Communications</comments><journal-ref>IEEE Transactions on Wireless Communications, Vol. 13, No. 11, pp.
  6147 - 6165, Nov. 2014</journal-ref><doi>10.1109/TWC.2014.2348996</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We first conceive a novel transmission protocol for a multi-relay
multiple-input--multiple-output orthogonal frequency-division multiple-access
(MIMO-OFDMA) cellular network based on joint transmit and receive beamforming.
We then address the associated network-wide spectral efficiency (SE) and energy
spectral efficiency (ESE) optimization problems. More specifically, the
network's MIMO channels are mathematically decomposed into several effective
multiple-input--single-output (MISO) channels, which are essentially spatially
multiplexed for transmission. Hence, these effective MISO channels are referred
to as spatial multiplexing components (SMCs). For the sake of improving the
SE/ESE performance attained, the SMCs are grouped using a pair of proposed
grouping algorithms. The first is optimal in the sense that it exhaustively
evaluates all the possible combinations of SMCs satisfying both the
semi-orthogonality criterion and other relevant system constraints, whereas the
second is a lower-complexity alternative. Corresponding to each of the two
grouping algorithms, the pair of SE and ESE maximization problems are
formulated, thus the optimal SMC groups and optimal power control variables can
be obtained for each subcarrier block. These optimization problems are proven
to be concave, and the dual decomposition approach is employed for obtaining
their solutions. Relying on these optimization solutions, the impact of various
system parameters on both the attainable SE and ESE is characterized. In
particular, we demonstrate that under certain conditions the lower-complexity
SMC grouping algorithm achieves 90% of the SE/ESE attained by the
exhaustive-search based optimal grouping algorithm, while imposing as little as
3.5% of the latter scheme's computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7799</identifier>
 <datestamp>2015-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7799</id><created>2014-07-29</created><updated>2015-04-17</updated><authors><author><keyname>Dyer</keyname><forenames>Martin</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author><author><keyname>Richerby</keyname><forenames>David</forenames></author></authors><title>Counting $4\times 4$ Matrix Partitions of Graphs</title><categories>cs.CC</categories><comments>Revised and clarified. Download the paper source to obtain the
  program we used to check all the cases and its output (see the program source
  code for an explanation of the output format)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a symmetric matrix $M\in \{0,1,*\}^{D\times D}$, an $M$-partition of a
graph $G$ is a function from $V(G)$ to $D$ such that no edge of $G$ is mapped
to a $0$ of $M$ and no non-edge to a $1$. We give a computer-assisted proof
that, when $|D|=4$, the problem of counting the $M$-partitions of an input
graph is either in FP or is #P-complete. Tractability is proved by reduction to
the related problem of counting list $M$-partitions; intractability is shown
using a gadget construction and interpolation. We use a computer program to
determine which of the two cases holds for all but a small number of matrices,
which we resolve manually to establish the dichotomy. We conjecture that the
dichotomy also holds for $|D|&gt;4$. More specifically, we conjecture that, for
any symmetric matrix $M\in\{0,1,*\}^{D\times D}$, the complexity of counting
$M$-partitions is the same as the related problem of counting list
$M$-partitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7803</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7803</id><created>2014-07-25</created><updated>2014-08-03</updated><authors><author><keyname>Reid</keyname><forenames>Samuel</forenames></author></authors><title>A Sequent Calculus for Dynamic Topological Logic</title><categories>math.LO cs.LO</categories><comments>12 pages. Due to a lack of explanation in the soundness proofs and an
  error in cut-elimination this paper has been withdrawn for further research
  and editing</comments><msc-class>03F03</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a sequent calculus for the temporal-over-topological fragment
$\textbf{DTL}_{0}^{\circ * \slash \Box}$ of dynamic topological logic
$\textbf{DTL}$, prove soundness semantically, and prove completeness
syntactically using the axiomatization of $\textbf{DTL}_{0}^{\circ * \slash
\Box}$ given in \cite{paper3}. A cut-free sequent calculus for
$\textbf{DTL}_{0}^{\circ * \slash \Box}$ is obtained as the union of the
propositional fragment of Gentzen's classical sequent calculus, two $\Box$
structural rules for the modal extension, and nine $\circ$ (next) and $*$
(henceforth) structural rules for the temporal extension. Future research will
focus on the construction of a hypersequent calculus for dynamic topological
$\textbf{S5}$ logic in order to prove Kremer's Next Removal Conjecture for the
logic of homeomorphisms on almost discrete spaces $\textbf{S5H}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7810</identifier>
 <datestamp>2015-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7810</id><created>2014-07-26</created><updated>2015-01-08</updated><authors><author><keyname>Rouchon</keyname><forenames>Pierre</forenames></author></authors><title>Models and Feedback Stabilization of Open Quantum Systems</title><categories>math.OC cs.SY quant-ph</categories><comments>Extended version of the paper attached to an invited conference for
  the International Congress of Mathematicians in Seoul, August 13 - 21, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At the quantum level, feedback-loops have to take into account measurement
back-action. We present here the structure of the Markovian models including
such back-action and sketch two stabilization methods: measurement-based
feedback where an open quantum system is stabilized by a classical controller;
coherent or autonomous feedback where a quantum system is stabilized by a
quantum controller with decoherence (reservoir engineering). We begin to
explain these models and methods for the photon box experiments realized in the
group of Serge Haroche (Nobel Prize 2012). We present then these models and
methods for general open quantum systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7819</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7819</id><created>2014-07-29</created><authors><author><keyname>Luo</keyname><forenames>Shikai</forenames></author><author><keyname>Song</keyname><forenames>Rui</forenames></author><author><keyname>Witten</keyname><forenames>Daniela</forenames></author></authors><title>Sure Screening for Gaussian Graphical Models</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose {graphical sure screening}, or GRASS, a very simple and
computationally-efficient screening procedure for recovering the structure of a
Gaussian graphical model in the high-dimensional setting. The GRASS estimate of
the conditional dependence graph is obtained by thresholding the elements of
the sample covariance matrix. The proposed approach possesses the sure
screening property: with very high probability, the GRASS estimated edge set
contains the true edge set. Furthermore, with high probability, the size of the
estimated edge set is controlled. We provide a choice of threshold for GRASS
that can control the expected false positive rate. We illustrate the
performance of GRASS in a simulation study and on a gene expression data set,
and show that in practice it performs quite competitively with more complex and
computationally-demanding techniques for graph estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7823</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7823</id><created>2014-07-26</created><authors><author><keyname>Kachhvah</keyname><forenames>Ajay Deep</forenames></author><author><keyname>Sen</keyname><forenames>Abhijit</forenames></author></authors><title>Time delay enhanced synchronization in a star network of second order
  Kuramoto oscillators</title><categories>nlin.AO cs.SI cs.SY nlin.CD</categories><comments>11 Pages, 5 Figures. Submitted to Phys. Rev. E</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the onset of synchronization transition in a star network of
Kuramoto phase oscillators in the presence of inertia and a time delay in the
coupling. A direct correlation between the natural frequencies of the
oscillators and their degrees is assumed. The presence of time delay is seen to
enhance the onset of first order synchronization. The star network also
exhibits different synchronization transitions depending on the value of time
delay. An analytical prediction to observe the effect of the time delay is
provided and further supported by simulation results. Our findings may help
provide valuable insights into the understanding of mechanisms that lead to
synchronization on complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7841</identifier>
 <datestamp>2014-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7841</id><created>2014-07-29</created><updated>2014-11-26</updated><authors><author><keyname>Crampton</keyname><forenames>Jason</forenames></author><author><keyname>Sellwood</keyname><forenames>James</forenames></author></authors><title>Caching and Auditing in the RPPM Model</title><categories>cs.CR</categories><comments>Accepted for publication at STM 2014 (without proofs, which are
  included in this longer version)</comments><acm-class>D.4.6; H.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crampton and Sellwood recently introduced a variant of relationship-based
access control based on the concepts of relationships, paths and principal
matching, to which we will refer as the RPPM model. In this paper, we show that
the RPPM model can be extended to provide support for caching of authorization
decisions and enforcement of separation of duty policies. We show that these
extensions are natural and powerful. Indeed, caching provides far greater
advantages in RPPM than it does in most other access control models and we are
able to support a wide range of separation of duty policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7844</identifier>
 <datestamp>2014-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7844</id><created>2014-07-29</created><authors><author><keyname>Conti</keyname><forenames>Mauro</forenames></author><author><keyname>Mancini</keyname><forenames>Luigi V.</forenames></author><author><keyname>Spolaor</keyname><forenames>Riccardo</forenames></author><author><keyname>Verde</keyname><forenames>Nino V.</forenames></author></authors><title>Can't you hear me knocking: Identification of user actions on Android
  apps via traffic analysis</title><categories>cs.CR</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While smartphone usage become more and more pervasive, people start also
asking to which extent such devices can be maliciously exploited as &quot;tracking
devices&quot;. The concern is not only related to an adversary taking physical or
remote control of the device (e.g., via a malicious app), but also to what a
passive adversary (without the above capabilities) can observe from the device
communications. Work in this latter direction aimed, for example, at inferring
the apps a user has installed on his device, or identifying the presence of a
specific user within a network.
  In this paper, we move a step forward: we investigate to which extent it is
feasible to identify the specific actions that a user is doing on his mobile
device, by simply eavesdropping the device's network traffic. In particular, we
aim at identifying actions like browsing someone's profile on a social network,
posting a message on a friend's wall, or sending an email. We design a system
that achieves this goal starting from encrypted TCP/IP packets: it works
through identification of network flows and application of machine learning
techniques. We did a complete implementation of this system and run a thorough
set of experiments, which show that it can achieve accuracy and precision
higher than 95%, for most of the considered actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7849</identifier>
 <datestamp>2014-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7849</id><created>2014-07-29</created><updated>2014-08-22</updated><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author></authors><title>The Operationalization of &quot;Fields&quot; as WoS Subject Categories (WCs) in
  Evaluative Bibliometrics: The cases of &quot;Library and Information Science&quot; and
  &quot;Science &amp; Technology Studies&quot;</title><categories>cs.DL cs.CY</categories><comments>accepted for publication in the Journal of the Association for
  Information Science and Technology (JASIST); 22 August 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normalization of citation scores using reference sets based on Web-of-Science
Subject Categories (WCs) has become an established (&quot;best&quot;) practice in
evaluative bibliometrics. For example, the Times Higher Education World
University Rankings are, among other things, based on this operationalization.
However, WCs were developed decades ago for the purpose of information
retrieval and evolved incrementally with the database; the classification is
machine-based and partially manually corrected. Using the WC &quot;information
science &amp; library science&quot; and the WCs attributed to journals in the field of
&quot;science and technology studies,&quot; we show that WCs do not provide sufficient
analytical clarity to carry bibliometric normalization in evaluation practices
because of &quot;indexer effects.&quot; Can the compliance with &quot;best practices&quot; be
replaced with an ambition to develop &quot;best possible practices&quot;? New research
questions can then be envisaged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7882</identifier>
 <datestamp>2014-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7882</id><created>2014-07-29</created><updated>2014-11-11</updated><authors><author><keyname>Even</keyname><forenames>Guy</forenames></author><author><keyname>Medina</keyname><forenames>Moti</forenames></author><author><keyname>Ron</keyname><forenames>Dana</forenames></author></authors><title>Distributed Maximum Matching in Bounded Degree Graphs</title><categories>cs.DC cs.DS</categories><comments>arXiv admin note: substantial text overlap with arXiv:1402.3796</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present deterministic distributed algorithms for computing approximate
maximum cardinality matchings and approximate maximum weight matchings. Our
algorithm for the unweighted case computes a matching whose size is at least
$(1-\eps)$ times the optimal in $\Delta^{O(1/\eps)} +
O\left(\frac{1}{\eps^2}\right) \cdot\log^*(n)$ rounds where $n$ is the number
of vertices in the graph and $\Delta$ is the maximum degree. Our algorithm for
the edge-weighted case computes a matching whose weight is at least $(1-\eps)$
times the optimal in
$\log(\min\{1/\wmin,n/\eps\})^{O(1/\eps)}\cdot(\Delta^{O(1/\eps)}+\log^*(n))$
rounds for edge-weights in $[\wmin,1]$.
  The best previous algorithms for both the unweighted case and the weighted
case are by Lotker, Patt-Shamir, and Pettie~(SPAA 2008). For the unweighted
case they give a randomized $(1-\eps)$-approximation algorithm that runs in
$O((\log(n)) /\eps^3)$ rounds. For the weighted case they give a randomized
$(1/2-\eps)$-approximation algorithm that runs in $O(\log(\eps^{-1}) \cdot
\log(n))$ rounds. Hence, our results improve on the previous ones when the
parameters $\Delta$, $\eps$ and $\wmin$ are constants (where we reduce the
number of runs from $O(\log(n))$ to $O(\log^*(n))$), and more generally when
$\Delta$, $1/\eps$ and $1/\wmin$ are sufficiently slowly increasing functions
of $n$. Moreover, our algorithms are deterministic rather than randomized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7887</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7887</id><created>2014-07-29</created><authors><author><keyname>Yaroslavtsev</keyname><forenames>Grigory</forenames></author></authors><title>Going for Speed: Sublinear Algorithms for Dense r-CSPs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give new sublinear and parallel algorithms for the extensively studied
problem of approximating n-variable r-CSPs (constraint satisfaction problems
with constraints of arity r up to an additive error. The running time of our
algorithms is O(n/\epsilon^2) + 2^O(1/\epsilon^2) for Boolean r-CSPs and O(k^4
n / \epsilon^2) + 2^O(log k / \epsilon^2) for r-CSPs with constraints on
variables over an alphabet of size k. For any constant k this gives optimal
dependence on n in the running time unconditionally, while the exponent in the
dependence on 1/\epsilon is polynomially close to the lower bound under the
exponential-time hypothesis, which is 2^\Omega(\epsilon^(-1/2)).
  For Max-Cut this gives an exponential improvement in dependence on 1/\epsilon
compared to the sublinear algorithms of Goldreich, Goldwasser and Ron (JACM'98)
and a linear speedup in n compared to the algorithms of Mathieu and Schudy
(SODA'08). For the maximization version of k-Correlation Clustering problem our
running time is O(k^4 n / \epsilon^2) + k^O(1/\epsilon^2), improving the
previously best n k^{O(1/\epsilon^3 log k/\epsilon) by Guruswami and Giotis
(SODA'06).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7889</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7889</id><created>2014-07-29</created><authors><author><keyname>Lakshminarayana</keyname><forenames>Subhash</forenames></author><author><keyname>Quek</keyname><forenames>Tony Q. S.</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Cooperation and Storage Tradeoffs in Power-Grids with Renewable Energy
  Resources</title><categories>cs.IT cs.SY math.IT</categories><journal-ref>IEEE Journal on Selected Areas in Communication (JSAC) on &quot;Smart
  Grid Communication Series&quot;, July 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most important challenges in smart grid systems is the integration
of renewable energy resources into its design. In this work, two different
techniques to mitigate the time varying and intermittent nature of renewable
energy generation are considered. The first one is the use of storage, which
smooths out the fluctuations in the renewable energy generation across time.
The second technique is the concept of distributed generation combined with
cooperation by exchanging energy among the distributed sources. This technique
averages out the variation in energy production across space. This paper
analyzes the trade-off between these two techniques. The problem is formulated
as a stochastic optimization problem with the objective of minimizing the time
average cost of energy exchange within the grid. First, an analytical model of
the optimal cost is provided by investigating the steady state of the system
for some specific scenarios. Then, an algorithm to solve the cost minimization
problem using the technique of Lyapunov optimization is developed and results
for the performance of the algorithm are provided. These results show that in
the presence of limited storage devices, the grid can benefit greatly from
cooperation, whereas in the presence of large storage capacity, cooperation
does not yield much benefit. Further, it is observed that most of the gains
from cooperation can be obtained by exchanging energy only among a few energy
harvesting sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7890</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7890</id><created>2014-07-29</created><authors><author><keyname>Cabral</keyname><forenames>Raquel</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro</forenames></author><author><keyname>Ram&#xed;rez</keyname><forenames>Jaime</forenames></author></authors><title>Variability Analysis of Complex Networks Measures based on Stochastic
  Distances</title><categories>physics.soc-ph cs.SI physics.data-an</categories><doi>10.1016/j.physa.2014.07.079</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks can model the structure and dynamics of different types of
systems. It has been shown that they are characterized by a set of measures. In
this work, we evaluate the variability of complex networks measures face to
perturbations and, for this purpose, we impose controlled perturbations and
quantify their effect. We analyze theoretical models (random, small-world and
scale-free) and real networks (a collaboration network and a metabolic
networks) along with the shortest path length, vertex degree, local cluster
coefficient and betweenness centrality measures. In such analysis, we propose
the use of three stochastic quantifiers: the Kullback-Leibler divergence and
the Jensen-Shannon and Hellinger distances. The sensitivity of these measures
was analyzed with respect to the following perturbations: edge addition, edge
removal, edge rewiring and node removal, all of them applied at different
intensities. The results reveal that the evaluated measures are influenced by
these perturbations. Additionally, hypotheses tests were performed to verify
the behavior of the degree distribution to identify the intensity of the
perturbations that leads to break this property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7900</identifier>
 <datestamp>2015-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7900</id><created>2014-07-29</created><updated>2015-05-24</updated><authors><author><keyname>Chalk</keyname><forenames>Cameron T.</forenames></author><author><keyname>Fernandez</keyname><forenames>Dominic A.</forenames></author><author><keyname>Huerta</keyname><forenames>Alejandro</forenames></author><author><keyname>Maldonado</keyname><forenames>Mario A.</forenames></author><author><keyname>Schweller</keyname><forenames>Robert T.</forenames></author><author><keyname>Sweet</keyname><forenames>Leslie</forenames></author></authors><title>Strict Self-Assembly of Fractals using Multiple Hands</title><categories>cs.CG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of the strict self-assembly of infinite
fractals within tile self-assembly. In particular, we provide tile assembly
algorithms for the assembly of the discrete Sierpinski triangle and the
discrete Sierpinski carpet within a class of models we term the
\emph{$h$-handed assembly model} ($h$-HAM), which generalizes the 2-HAM to
allow up to $h$ assemblies to combine in a single assembly step. Despite
substantial consideration, no purely growth self-assembly model has yet been
shown to strictly assemble an infinite fractal without significant modification
to the fractal shape. In this paper we not only achieve this, but in the case
of the Sierpinski carpet are able to achieve it within the 2-HAM, one of the
most well studied tile assembly models in the literature. Our specific results
are as follows. We provide a $6$-HAM construction for the Sierpinski triangle
that works at scale factor 1, 30 tile types, and assembles the fractal in a
\emph{near perfect} way in which all intermediate assemblies are finite-sized
iterations of the recursive fractal. We further assemble the Sierpinski
triangle within the $3$-HAM at scale factor 3 and 990 tile types. For the
Sierpinski carpet, we present a $2$-HAM result that works at scale factor 3 and
uses 1,216 tile types. We further include analysis showing that the aTAM is
incapable of strictly assembling the non-tree Sierpinski triangle considered in
this paper, and that multiple hands are needed for the near-perfect assembly of
the Sierpinski triangle and the Sierpinski carpet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7906</identifier>
 <datestamp>2014-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7906</id><created>2014-07-29</created><updated>2014-09-18</updated><authors><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>How Auto-Encoders Could Provide Credit Assignment in Deep Networks via
  Target Propagation</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose to exploit {\em reconstruction} as a layer-local training signal
for deep learning. Reconstructions can be propagated in a form of target
propagation playing a role similar to back-propagation but helping to reduce
the reliance on derivatives in order to perform credit assignment across many
levels of possibly strong non-linearities (which is difficult for
back-propagation). A regularized auto-encoder tends produce a reconstruction
that is a more likely version of its input, i.e., a small move in the direction
of higher likelihood. By generalizing gradients, target propagation may also
allow to train deep networks with discrete hidden units. If the auto-encoder
takes both a representation of input and target (or of any side information) in
input, then its reconstruction of input representation provides a target
towards a representation that is more likely, conditioned on all the side
information. A deep auto-encoder decoding path generalizes gradient propagation
in a learned way that can could thus handle not just infinitesimal changes but
larger, discrete changes, hopefully allowing credit assignment through a long
chain of non-linear operations. In addition to each layer being a good
auto-encoder, the encoder also learns to please the upper layers by
transforming the data into a space where it is easier to model by them,
flattening manifolds and disentangling factors. The motivations and theoretical
justifications for this approach are laid down in this paper, along with
conjectures that will have to be verified either mathematically or
experimentally, including a hypothesis stating that such auto-encoder mediated
target propagation could play in brains the role of credit assignment through
many non-linear, noisy and discrete transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7908</identifier>
 <datestamp>2015-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7908</id><created>2014-07-29</created><updated>2015-02-11</updated><authors><author><keyname>Smaldino</keyname><forenames>Paul E.</forenames></author><author><keyname>Epstein</keyname><forenames>Joshua M.</forenames></author></authors><title>Social Conformity Despite Individual Preferences for Distinctiveness</title><categories>physics.soc-ph cs.SI</categories><comments>11 pages, 6 figures, appendix</comments><acm-class>J.4</acm-class><journal-ref>Smaldino PE, Epstein JM (2015) Social conformity despite
  individual preferences for distinctiveness. Royal Society Open Science 2:
  140437</journal-ref><doi>10.1098/rsos.140437</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that individual behaviors directed at the attainment of
distinctiveness can in fact produce complete social conformity. We thus offer
an unexpected generative mechanism for this central social phenomenon.
Specifically, we establish that agents who have fixed needs to be distinct and
adapt their positions to achieve distinctiveness goals, can nevertheless
self-organize to a limiting state of absolute conformity. This seemingly
paradoxical result is deduced formally from a small number of natural
assumptions, and is then explored at length computationally. Interesting
departures from this conformity equilibrium are also possible, including
divergence in positions. The effect of extremist minorities on these dynamics
is discussed. A simple extension is then introduced, which allows the model to
generate and maintain social diversity, including multimodal distinctiveness
distributions. The paper contributes formal definitions, analytical deductions,
and counterintuitive findings to the literature on individual distinctiveness
and social conformity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7909</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7909</id><created>2014-07-29</created><authors><author><keyname>Fujiwara</keyname><forenames>Yuichiro</forenames></author></authors><title>Using arbitrary parity-check matrices for quantum error correction
  assisted by less noisy qubits</title><categories>quant-ph cs.IT math.IT</categories><comments>8 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently a framework for assisted quantum error correction was proposed in
which a specific type of error is allowed to occur on auxiliary qubits, which
is in contrast to standard entanglement assistance that requires noiseless
auxiliary qubits. However, while the framework maintains the ability to import
any binary or quaternary linear code without sacrificing active error
correction power, it requires the code designer to turn a parity-check matrix
of the underlying classical code into an equivalent one in standard form. This
means that classical coding theoretic techniques that require parity-check
matrices to be in specific form may not fully be exploitable. Another issue of
the recently proposed scheme is that the error correction capabilities for bit
errors and phase errors are generally equal, which is not ideal for asymmetric
error models. This paper addresses these two problems. We generalize the
framework in such a way that any parity-check matrix of any binary or
quaternary linear code can be exploited. Our generalization also allows for
importing a pair of distinct linear codes so that error correction capabilities
become suitably asymmetric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7917</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7917</id><created>2014-07-29</created><authors><author><keyname>Barba</keyname><forenames>Luis</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>Top-Down Skiplists</title><categories>cs.DS</categories><comments>18 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe todolists (top-down skiplists), a variant of skiplists (Pugh
1990) that can execute searches using at most $\log_{2-\varepsilon} n + O(1)$
binary comparisons per search and that have amortized update time
$O(\varepsilon^{-1}\log n)$. A variant of todolists, called working-todolists,
can execute a search for any element $x$ using $\log_{2-\varepsilon} w(x) +
o(\log w(x))$ binary comparisons and have amortized search time
$O(\varepsilon^{-1}\log w(w))$. Here, $w(x)$ is the &quot;working-set number&quot; of
$x$. No previous data structure is known to achieve a bound better than
$4\log_2 w(x)$ comparisons. We show through experiments that, if implemented
carefully, todolists are comparable to other common dictionary implementations
in terms of insertion times and outperform them in terms of search times.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7923</identifier>
 <datestamp>2015-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7923</id><created>2014-07-29</created><updated>2015-03-17</updated><authors><author><keyname>Katz</keyname><forenames>Daniel J.</forenames></author></authors><title>Divisibility of Weil Sums of Binomials</title><categories>math.NT cs.IT math.CO math.IT</categories><comments>11 pages</comments><msc-class>11T23, 11L05, 11L07, 11T71</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the Weil sum $W_{F,d}(u)=\sum_{x \in F} \psi(x^d+u x)$, where $F$ is
a finite field of characteristic $p$, $\psi$ is the canonical additive
character of $F$, $d$ is coprime to $|F^*|$, and $u \in F^*$. We say that
$W_{F,d}(u)$ is three-valued when it assumes precisely three distinct values as
$u$ runs through $F^*$: this is the minimum number of distinct values in the
nondegenerate case, and three-valued $W_{F,d}$ are rare and desirable. When
$W_{F,d}$ is three-valued, we give a lower bound on the $p$-adic valuation of
the values. This enables us to prove the characteristic $3$ case of a 1976
conjecture of Helleseth: when $p=3$ and $[F:{\mathbb F}_3]$ is a power of $2$,
we show that $W_{F,d}$ cannot be three-valued.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7924</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7924</id><created>2014-07-29</created><authors><author><keyname>Deza</keyname><forenames>Antoine</forenames></author><author><keyname>Huang</keyname><forenames>Kai</forenames></author><author><keyname>Metel</keyname><forenames>Michael R.</forenames></author></authors><title>Chance Constrained Optimization for Targeted Internet Advertising</title><categories>cs.CE math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a chance constrained optimization model for the fulfillment of
guaranteed display Internet advertising campaigns. The proposed formulation for
the allocation of display inventory takes into account the uncertainty of the
supply of Internet viewers. We discuss and present theoretical and
computational features of the model via Monte Carlo sampling and convex
approximations. Theoretical upper and lower bounds are presented along with a
numerical substantiation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7928</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7928</id><created>2014-07-29</created><authors><author><keyname>Kant</keyname><forenames>Gijs</forenames></author><author><keyname>van de Pol</keyname><forenames>Jaco</forenames></author></authors><title>Generating and Solving Symbolic Parity Games</title><categories>cs.LO cs.GT</categories><comments>In Proceedings GRAPHITE 2014, arXiv:1407.7671</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 159, 2014, pp. 2-14</journal-ref><doi>10.4204/EPTCS.159.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new tool for verification of modal mu-calculus formulae for
process specifications, based on symbolic parity games. It enhances an existing
method, that first encodes the problem to a Parameterised Boolean Equation
System (PBES) and then instantiates the PBES to a parity game. We improved the
translation from specification to PBES to preserve the structure of the
specification in the PBES, we extended LTSmin to instantiate PBESs to symbolic
parity games, and implemented the recursive parity game solving algorithm by
Zielonka for symbolic parity games. We use Multi-valued Decision Diagrams
(MDDs) to represent sets and relations, thus enabling the tools to deal with
very large systems. The transition relation is partitioned based on the
structure of the specification, which allows for efficient manipulation of the
MDDs. We performed two case studies on modular specifications, that demonstrate
that the new method has better time and memory performance than existing PBES
based tools and can be faster (but slightly less memory efficient) than the
symbolic model checker NuSMV.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7929</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7929</id><created>2014-07-29</created><authors><author><keyname>Fern&#xe1;ndez</keyname><forenames>Maribel</forenames><affiliation>King's College London, Department of Informatics, Strand, London WC2R 2LS, UK</affiliation></author><author><keyname>Kirchner</keyname><forenames>H&#xe9;l&#xe8;ne</forenames><affiliation>Inria, Domaine de Voluceau, Rocquencourt BP 105, 78153 Le Chesnay Cedex, France</affiliation></author><author><keyname>Pinaud</keyname><forenames>Bruno</forenames><affiliation>Bordeaux University, LaBRI CNRS UMR5800, 33405 Talence Cedex, France</affiliation></author></authors><title>Strategic Port Graph Rewriting: An Interactive Modelling and Analysis
  Framework</title><categories>cs.LO cs.SE</categories><comments>In Proceedings GRAPHITE 2014, arXiv:1407.7671</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 159, 2014, pp. 15-29</journal-ref><doi>10.4204/EPTCS.159.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present strategic portgraph rewriting as a basis for the implementation of
visual modelling and analysis tools. The goal is to facilitate the
specification, analysis and simulation of complex systems, using port graphs. A
system is represented by an initial graph and a collection of graph rewriting
rules, together with a user-defined strategy to control the application of
rules. The strategy language includes constructs to deal with graph traversal
and management of rewriting positions in the graph. We give a small-step
operational semantics for the language, and describe its implementation in the
graph transformation and visualisation tool PORGY.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7930</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7930</id><created>2014-07-29</created><authors><author><keyname>Blanco</keyname><forenames>Roi</forenames><affiliation>Yahoo! Research Barcelona, Spain</affiliation></author><author><keyname>Boldi</keyname><forenames>Paolo</forenames><affiliation>Dipartimento di informatica, Universit&#xe0; degli Studi di Milano</affiliation></author><author><keyname>Marino</keyname><forenames>Andrea</forenames><affiliation>Dipartimento di informatica, Universit&#xe0; degli Studi di Milano</affiliation></author></authors><title>Entity-Linking via Graph-Distance Minimization</title><categories>cs.DS cs.IR</categories><comments>In Proceedings GRAPHITE 2014, arXiv:1407.7671. The second and third
  authors were supported by the EU-FET grant NADINE (GA 288956)</comments><proxy>EPTCS</proxy><acm-class>G.2.2; G.2.3; F.2.m</acm-class><journal-ref>EPTCS 159, 2014, pp. 30-43</journal-ref><doi>10.4204/EPTCS.159.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entity-linking is a natural-language-processing task that consists in
identifying the entities mentioned in a piece of text, linking each to an
appropriate item in some knowledge base; when the knowledge base is Wikipedia,
the problem comes to be known as wikification (in this case, items are
wikipedia articles). One instance of entity-linking can be formalized as an
optimization problem on the underlying concept graph, where the quantity to be
optimized is the average distance between chosen items. Inspired by this
application, we define a new graph problem which is a natural variant of the
Maximum Capacity Representative Set. We prove that our problem is NP-hard for
general graphs; nonetheless, under some restrictive assumptions, it turns out
to be solvable in linear time. For the general case, we propose two heuristics:
one tries to enforce the above assumptions and another one is based on the
notion of hitting distance; we show experimentally how these approaches perform
with respect to some baselines on a real-world dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7931</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7931</id><created>2014-07-29</created><authors><author><keyname>Delzanno</keyname><forenames>Giorgio</forenames><affiliation>University of Genoa</affiliation></author><author><keyname>Rensink</keyname><forenames>Arend</forenames><affiliation>University of Twente</affiliation></author><author><keyname>Traverso</keyname><forenames>Riccardo</forenames><affiliation>University of Genoa / FBK-irst</affiliation></author></authors><title>Graph- versus Vector-Based Analysis of a Consensus Protocol</title><categories>cs.LO cs.DC</categories><comments>In Proceedings GRAPHITE 2014, arXiv:1407.7671</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 159, 2014, pp. 44-57</journal-ref><doi>10.4204/EPTCS.159.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Paxos distributed consensus algorithm is a challenging case-study for
standard, vector-based model checking techniques. Due to asynchronous
communication, exhaustive analysis may generate very large state spaces already
for small model instances. In this paper, we show the advantages of graph
transformation as an alternative modelling technique. We model Paxos in a rich
declarative transformation language, featuring (among other things) nested
quantifiers, and we validate our model using the GROOVE model checker, a
graph-based tool that exploits isomorphism as a natural way to prune the state
space via symmetry reductions. We compare the results with those obtained by
the standard model checker Spin on the basis of a vector-based encoding of the
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7932</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7932</id><created>2014-07-29</created><authors><author><keyname>Mansky</keyname><forenames>William</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Griffith</keyname><forenames>Dennis</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Gunter</keyname><forenames>Elsa L.</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author></authors><title>Specifying and Executing Optimizations for Parallel Programs</title><categories>cs.PL cs.LO</categories><comments>In Proceedings GRAPHITE 2014, arXiv:1407.7671</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 159, 2014, pp. 58-70</journal-ref><doi>10.4204/EPTCS.159.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compiler optimizations, usually expressed as rewrites on program graphs, are
a core part of all modern compilers. However, even production compilers have
bugs, and these bugs are difficult to detect and resolve. The problem only
becomes more complex when compiling parallel programs; from the choice of graph
representation to the possibility of race conditions, optimization designers
have a range of factors to consider that do not appear when dealing with
single-threaded programs. In this paper we present PTRANS, a domain-specific
language for formal specification of compiler transformations, and describe its
executable semantics. The fundamental approach of PTRANS is to describe program
transformations as rewrites on control flow graphs with temporal logic side
conditions. The syntax of PTRANS allows cleaner, more comprehensible
specification of program optimizations; its executable semantics allows these
specifications to act as prototypes for the optimizations themselves, so that
candidate optimizations can be tested and refined before going on to include
them in a compiler. We demonstrate the use of PTRANS to state, test, and refine
the specification of a redundant store elimination optimization on parallel
programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7933</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7933</id><created>2014-07-29</created><authors><author><keyname>Ziegert</keyname><forenames>Steffen</forenames><affiliation>University of Paderborn</affiliation></author></authors><title>Graph Transformation Planning via Abstraction</title><categories>cs.AI</categories><comments>In Proceedings GRAPHITE 2014, arXiv:1407.7671</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 159, 2014, pp. 71-83</journal-ref><doi>10.4204/EPTCS.159.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern software systems increasingly incorporate self-* behavior to adapt to
changes in the environment at runtime. Such adaptations often involve
reconfiguring the software architecture of the system. Many systems also need
to manage their architecture themselves, i.e., they need a planning component
to autonomously decide which reconfigurations to execute to reach a desired
target configuration. For the specification of reconfigurations, we employ
graph transformations systems (GTS) due to the close relation of graphs and UML
object diagrams. We solve the resulting planning problems with a planning
system that works directly on a GTS. It features a domain-independent heuristic
that uses the solution length of an abstraction of the original problem as an
estimate. Finally, we provide experimental results on two different domains,
which confirm that our heuristic performs better than another
domain-independent heuristic which resembles heuristics employed in related
work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7934</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7934</id><created>2014-07-29</created><authors><author><keyname>Senni</keyname><forenames>Valerio</forenames><affiliation>IMT Institute for Advanced Studies</affiliation></author><author><keyname>Stawowy</keyname><forenames>Michele</forenames><affiliation>IMT Institute for Advanced Studies</affiliation></author></authors><title>Backwards State-space Reduction for Planning in Dynamic Knowledge Bases</title><categories>cs.AI</categories><comments>In Proceedings GRAPHITE 2014, arXiv:1407.7671</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 159, 2014, pp. 84-99</journal-ref><doi>10.4204/EPTCS.159.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address the problem of planning in rich domains, where
knowledge representation is a key aspect for managing the complexity and size
of the planning domain. We follow the approach of Description Logic (DL) based
Dynamic Knowledge Bases, where a state of the world is represented concisely by
a (possibly changing) ABox and a (fixed) TBox containing the axioms, and
actions that allow to change the content of the ABox. The plan goal is given in
terms of satisfaction of a DL query. In this paper we start from a traditional
forward planning algorithm and we propose a much more efficient variant by
combining backward and forward search. In particular, we propose a Backward
State-space Reduction technique that consists in two phases: first, an Abstract
Planning Graph P is created by using the Abstract Backward Planning Algorithm
(ABP), then the abstract planning graph P is instantiated into a corresponding
planning graph P by using the Forward Plan Instantiation Algorithm (FPI). The
advantage is that in the preliminary ABP phase we produce a symbolic plan that
is a pattern to direct the search of the concrete plan. This can be seen as a
kind of informed search where the preliminary backward phase is useful to
discover properties of the state-space that can be used to direct the
subsequent forward phase. We evaluate the effectiveness of our ABP+FPI
algorithm in the reduction of the explored planning domain by comparing it to a
standard forward planning algorithm and applying both of them to a concrete
business case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7937</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7937</id><created>2014-07-30</created><authors><author><keyname>Balcan</keyname><forenames>Maria-Florina</forenames></author><author><keyname>Daniely</keyname><forenames>Amit</forenames></author><author><keyname>Mehta</keyname><forenames>Ruta</forenames></author><author><keyname>Urner</keyname><forenames>Ruth</forenames></author><author><keyname>Vazirani</keyname><forenames>Vijay V.</forenames></author></authors><title>Learning Economic Parameters from Revealed Preferences</title><categories>cs.GT cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent line of work, starting with Beigman and Vohra (2006) and
Zadimoghaddam and Roth (2012), has addressed the problem of {\em learning} a
utility function from revealed preference data. The goal here is to make use of
past data describing the purchases of a utility maximizing agent when faced
with certain prices and budget constraints in order to produce a hypothesis
function that can accurately forecast the {\em future} behavior of the agent.
  In this work we advance this line of work by providing sample complexity
guarantees and efficient algorithms for a number of important classes. By
drawing a connection to recent advances in multi-class learning, we provide a
computationally efficient algorithm with tight sample complexity guarantees
($\Theta(d/\epsilon)$ for the case of $d$ goods) for learning linear utility
functions under a linear price model. This solves an open question in
Zadimoghaddam and Roth (2012). Our technique yields numerous generalizations
including the ability to learn other well-studied classes of utility functions,
to deal with a misspecified model, and with non-linear prices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7964</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7964</id><created>2014-07-30</created><authors><author><keyname>Kafri</keyname><forenames>Oded</forenames></author></authors><title>Information Theoretic Approach to Social Networks</title><categories>cs.IT cs.SI math.IT physics.soc-ph</categories><comments>10 pages</comments><msc-class>82B30</msc-class><acm-class>C.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an information theoretic model for sociological networks. The
model is a microcanonical ensemble of states and particles. The states are the
possible pairs of nodes (i.e. people, sites and alike) which exchange
information. The particles are the energetic information bits. With analogy to
bosons gas, we define for these networks model: entropy, volume, pressure and
temperature. We show that these definitions are consistent with Carnot
efficiency (the second law) and ideal gas law. Therefore, if we have two large
networks: hot and cold having temperatures TH and TC and we remove Q energetic
bits from the hot network to the cold network we can save W profit bits. The
profit will be calculated from W equal or smaller than Q (1-TH/TC), namely,
Carnot formula. In addition it is shown that when two of these networks are
merged the entropy increases. This explains the tendency of economic and social
networks to merge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7989</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7989</id><created>2014-07-30</created><updated>2014-07-31</updated><authors><author><keyname>Alami</keyname><forenames>Yasser El Madani El</forenames></author><author><keyname>Nfaoui</keyname><forenames>El Habib</forenames></author><author><keyname>Beqqali</keyname><forenames>Omar El</forenames></author></authors><title>Multi-agents Architecture for Semantic Retrieving Video in Distributed
  Environment</title><categories>cs.IR</categories><comments>11 pages, 11 figures, The Proceeding of International Conference on
  Soft Computing and Software Engineering 2013</comments><journal-ref>International Journal of Soft Computing and Software Engineering
  [JSCSE], Vol. 3, No. 3, pp.430-440, 2013</journal-ref><doi>10.7321/jscse.v3.n3.65</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an integrated multi-agents architecture for indexing and
retrieving video information.The focus of our work is to elaborate an
extensible approach that gathers a priori almost of the mandatory tools which
palliate to the major intertwining problems raised in the whole process of the
video lifecycle (classification, indexing and retrieval). In fact, effective
and optimal retrieval video information needs a collaborative approach based on
multimodal aspects. Clearly, it must to take into account the distributed
aspect of the data sources, the adaptation of the contents, semantic
annotation, personalized request and active feedback which constitute the
backbone of a vigorous system which improve its performances in a smart way
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.7998</identifier>
 <datestamp>2015-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.7998</id><created>2014-07-30</created><updated>2015-12-08</updated><authors><author><keyname>Chen</keyname><forenames>Lin</forenames></author><author><keyname>Megow</keyname><forenames>Nicole</forenames></author><author><keyname>Schewior</keyname><forenames>Kevin</forenames></author></authors><title>New Results on Online Resource Minimization</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the online resource minimization problem in which jobs with hard
deadlines arrive online over time at their release dates. The task is to
determine a feasible schedule on a minimum number of machines. We rigorously
study this problem and derive various algorithms with small constant
competitive ratios for interesting restricted problem variants. As the most
important special case, we consider scheduling jobs with agreeable deadlines.
We provide the first constant ratio competitive algorithm for the
non-preemptive setting, which is of particular interest with regard to the
known strong lower bound of n for the general problem. For the preemptive
setting, we show that the natural algorithm LLF achieves a constant ratio for
agreeable jobs, while for general jobs it has a lower bound of Omega(n^(1/3)).
We also give an O(log n)-competitive algorithm for the general preemptive
problem, which improves upon the known O(p_max/p_min)-competitive algorithm.
Our algorithm maintains a dynamic partition of the job set into loose and tight
jobs and schedules each (temporal) subset individually on separate sets of
machines. The key is a characterization of how the decrease in the relative
laxity of jobs influences the optimum number of machines. To achieve this we
derive a compact expression of the optimum value, which might be of independent
interest. We complement the general algorithmic result by showing lower bounds
that rule out that other known algorithms may yield a similar performance
guarantee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8004</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8004</id><created>2014-07-30</created><updated>2014-08-09</updated><authors><author><keyname>McBryan</keyname><forenames>Tony</forenames></author><author><keyname>Renaud</keyname><forenames>Karen</forenames></author><author><keyname>Siebert</keyname><forenames>J. Paul</forenames></author></authors><title>An Investigation into the use of Images as Password Cues</title><categories>cs.HC cs.CY</categories><acm-class>H.1.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Computer users are generally authenticated by means of a password.
Unfortunately passwords are often forgotten and replacement is expensive and
inconvenient. Some people write their passwords down but these records can
easily be lost or stolen. The option we explore is to find a way to cue
passwords securely. The specific cueing technique we report on in this paper
employs images as cues. The idea is to elicit textual descriptions of the
images, which can then be used as passwords. We have defined a set of metrics
for the kind of image that could function effectively as a password cue. We
identified five candidate image types and ran an experiment to identify the
image class with the best performance in terms of the defined metrics.
  The first experiment identified inkblot-type images as being superior. We
tested this image, called a cueblot, in a real-life environment. We allowed
users to tailor their cueblot until they felt they could describe it, and they
then entered a description of the cueblot as their password. The cueblot was
displayed at each subsequent authentication attempt to cue the password.
Unfortunately, we found that users did not exploit the cueing potential of the
cueblot, and while there were a few differences between textual descriptions of
cueblots and non-cued passwords, they were not compelling. Hence our attempts
to alleviate the difficulties people experience with passwords, by giving them
access to a tailored cue, did not have the desired effect. We have to conclude
that the password mechanism might well be unable to benefit from bolstering
activities such as this one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8007</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8007</id><created>2014-07-30</created><authors><author><keyname>Renaud</keyname><forenames>Karen</forenames></author><author><keyname>Ramsay</keyname><forenames>Judith</forenames></author></authors><title>How Helpful is Colour-Cueing of PIN Entry?</title><categories>cs.HC cs.CY</categories><acm-class>H.1.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  21st Century citizens are faced with the need to remember numbers of PINs
(Personal Identification Numbers) in order to do their daily business, and they
often have difficulties due to human memory limitations. One way of helping
them could be by providing cues during the PIN entry process. The provision of
cues that would only be helpful to the PIN owner is challenging because the cue
should only make sense to the legitimate user, and not to a random observer. In
this paper we report on an empirical study where we added colour to the PINpad
to provide an implicit memory cue to PINpad users. We compared the impact of
colour PINpads as opposed to grey ones. As expected, the ability to recall a
PIN deteriorated significantly over time irrespective of the type of PINpad
used. However, there was ultimately no improvement in the ability to recall
PINs when using colour PINpads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8010</identifier>
 <datestamp>2015-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8010</id><created>2014-07-30</created><updated>2015-03-05</updated><authors><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author></authors><title>Alternative metrics in scientometrics: A meta-analysis of research into
  three altmetrics</title><categories>cs.DL physics.soc-ph</categories><comments>Accepted for publication in Scientometrics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Alternative metrics are currently one of the most popular research topics in
scientometric research. This paper provides an overview of research into three
of the most important altmetrics: microblogging (Twitter), online reference
managers (Mendeley and CiteULike) and blogging. The literature is discussed in
relation to the possible use of altmetrics in research evaluation. Since the
research was particularly interested in the correlation between altmetrics
counts and citation counts, this overview focuses particularly on this
correlation. For each altmetric, a meta-analysis is calculated for its
correlation with traditional citation counts. As the results of the
meta-analyses show, the correlation with traditional citations for
micro-blogging counts is negligible (pooled r=0.003), for blog counts it is
small (pooled r=0.12) and for bookmark counts from online reference managers,
medium to large (CiteULike pooled r=0.23; Mendeley pooled r=0.51).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8022</identifier>
 <datestamp>2014-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8022</id><created>2014-07-30</created><updated>2014-12-15</updated><authors><author><keyname>Ben-Yishai</keyname><forenames>Assaf</forenames></author><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author></authors><title>The Gaussian Channel with Noisy Feedback: Near-Capacity Performance via
  Simple Interaction</title><categories>cs.IT math.IT</categories><comments>Allerton Conference on Communication, Control, and Computing, October
  2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a pair of terminals connected by two independent additive white
Gaussian noise channels, and limited by individual power constraints. The first
terminal would like to reliably send information to the second terminal, within
a given error probability. We construct an explicit interactive scheme
consisting of only (non-linear) scalar operations, by endowing the
Schalkwijk-Kailath noiseless feedback scheme with modulo arithmetic. Our scheme
achieves a communication rate close to the Shannon limit, in a small number of
rounds. For example, for an error probability of $10^{-6}$, if the Signal to
Noise Ratio ($\mathrm{SNR}$) of the feedback channel exceeds the $\mathrm{SNR}$
of the forward channel by $20\mathrm{dB}$, our scheme operates $0.8\mathrm{dB}$
from the Shannon limit with only $19$ rounds of interaction. In comparison,
attaining the same performance using state of the art Forward Error Correction
(FEC) codes requires two orders of magnitude increase in delay and complexity.
On the other extreme, a minimal delay uncoded system with the same error
probability is bounded away by $9\mathrm{dB}$ from the Shannon limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8031</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8031</id><created>2014-07-30</created><authors><author><keyname>Gross</keyname><forenames>Jonathan L.</forenames></author><author><keyname>Kotrb&#x10d;&#xed;k</keyname><forenames>Michal</forenames></author><author><keyname>Sun</keyname><forenames>Timothy</forenames></author></authors><title>Genus Distributions of cubic series-parallel graphs</title><categories>cs.DM math.CO</categories><comments>21 pages</comments><msc-class>05C10, 05C30, 05C85, 68R10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a quadratic-time algorithm for the genus distribution of any
3-regular, biconnected series-parallel graph, which we extend to any
biconnected series-parallel graph of maximum degree at most 3. Since the
biconnected components of every graph of treewidth 2 are series-parallel
graphs, this yields, by use of bar-amalgamation, a quadratic-time algorithm for
every graph of treewidth at most 2 and maximum degree at most 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8032</identifier>
 <datestamp>2015-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8032</id><created>2014-07-30</created><updated>2015-07-03</updated><authors><author><keyname>Miller</keyname><forenames>Steve</forenames></author><author><keyname>Knowles</keyname><forenames>Joshua</forenames></author></authors><title>Population Fluctuation Promotes Cooperation in Networks</title><categories>cs.GT cs.NE physics.soc-ph</categories><comments>14 pages including references, 9 figures, 1 table, 3 equations</comments><journal-ref>Miller, S. &amp; Knowles, J. Population Fluctuation Promotes
  Cooperation in Networks. Sci. Rep. 5, 11054 (2015)</journal-ref><doi>10.1038/srep11054</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of explaining the emergence and evolution of
cooperation in dynamic network-structured populations. Building on seminal work
by Poncela et al, which shows how cooperation (in one-shot prisoner's dilemma)
is supported in growing populations by an evolutionary preferential attachment
(EPA) model, we investigate the effect of fluctuations in the population size.
We find that the fluctuating model is more robust than Poncela et al's in that
cooperation flourishes for a wide variety of initial conditions. In terms of
both the temptation to defect, and the types of strategies present in the
founder network, the fluctuating population is found to lead more securely to
cooperation. Further, we find that this model will also support the emergence
of cooperation from pre-existing non-cooperative random networks. This model,
like Poncela et al's, does not require agents to have memory, recognition of
other agents, or other cognitive abilities, and so may suggest a more general
explanation of the emergence of cooperation in early evolutionary transitions,
than mechanisms such as kin selection, direct and indirect reciprocity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8033</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8033</id><created>2014-07-30</created><updated>2015-09-23</updated><authors><author><keyname>Livi</keyname><forenames>Lorenzo</forenames></author><author><keyname>Giuliani</keyname><forenames>Alessandro</forenames></author><author><keyname>Sadeghian</keyname><forenames>Alireza</forenames></author></authors><title>Characterization of graphs for protein structure modeling and
  recognition of solubility</title><categories>physics.data-an cs.AI q-bio.BM q-bio.MN</categories><comments>To appear in Current Bioinformatics, Bentham Science</comments><doi>10.2174/1574893611666151109175216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the relations among structural, topological, and
chemical properties of the E.Coli proteome from the vantage point of the
solubility/aggregation propensity of proteins. Each E.Coli protein is initially
represented according to its known folded 3D shape. This step consists in
representing the available E.Coli proteins in terms of graphs. We first analyze
those graphs by considering pure topological characterizations, i.e., by
analyzing the mass fractal dimension and the distribution underlying both
shortest paths and vertex degrees. Results confirm the general architectural
principles of proteins. Successively, we focus on the statistical properties of
a representation of such graphs in terms of vectors composed of several
numerical features, which we extracted from their structural representation. We
found that protein size is the main discriminator for the solubility, while
however there are other factors that help explaining the solubility degree. We
finally analyze such data through a novel one-class classifier, with the aim of
discriminating among very and poorly soluble proteins. Results are encouraging
and consolidate the potential of pattern recognition techniques when employed
to describe complex biological systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8034</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8034</id><created>2014-07-30</created><authors><author><keyname>M&#xfc;elich</keyname><forenames>Sven</forenames></author><author><keyname>Puchinger</keyname><forenames>Sven</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author><author><keyname>Hiller</keyname><forenames>Matthias</forenames></author><author><keyname>Sigl</keyname><forenames>Georg</forenames></author></authors><title>Error Correction for Physical Unclonable Functions Using Generalized
  Concatenated Codes</title><categories>cs.IT math.IT</categories><comments>Accepted for: Fourteenth International Workshop on Algebraic and
  Combinatorial Coding Theory ACCT2014, Svetlogorsk (Kaliningrad region),
  Russia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physical Unclonable Functions can be used for secure key generation in
cryptographic applications. It is explained how methods from coding theory must
be applied in order to ensure reliable key regeneration. Based on previous
work, we show ways how to obtain better results with respect to error
probability and codeword length. Also, an example based on Generalized
Concatenated codes is given, which improves upon used coding schemes for PUFs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8039</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8039</id><created>2014-07-30</created><updated>2014-07-31</updated><authors><author><keyname>Conrad</keyname><forenames>Natasa Djurdjevac</forenames></author><author><keyname>Banisch</keyname><forenames>Ralf</forenames></author><author><keyname>Sch&#xfc;tte</keyname><forenames>Christof</forenames></author></authors><title>Modularity of Directed Networks: Cycle Decomposition Approach</title><categories>math-ph cs.SI math.MP math.PR physics.soc-ph</categories><msc-class>60J20 (Primary), 05C81, 94C15 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of decomposing networks into modules (or clusters) has gained
much attention in recent years, as it can account for a coarse-grained
description of complex systems, often revealing functional subunits of these
systems. A variety of module detection algorithms have been proposed, mostly
oriented towards finding hard partitionings of undirected networks. Despite the
increasing number of fuzzy clustering methods for directed networks, many of
these approaches tend to neglect important directional information. In this
paper, we present a novel random walk based approach for finding fuzzy
partitions of directed, weighted networks, where edge directions play a crucial
role in defining how well nodes in a module are interconnected. We will show
that cycle decomposition of a random walk process connects the notion of
network modules and information transport in a network, leading to a new,
symmetric measure of node communication. walk process, for which we will prove
that although being time-reversible it inherits all necessary information about
directions and modular structure of the original network. Finally, we will use
this measure to introduce a communication graph, for which we will show that
although being undirected it inherits all necessary information about modular
structures from the original network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8041</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8041</id><created>2014-07-30</created><authors><author><keyname>Karimi</keyname><forenames>Fariba</forenames></author><author><keyname>Ramenzoni</keyname><forenames>Ver&#xf3;nica C.</forenames></author><author><keyname>Holme</keyname><forenames>Petter</forenames></author></authors><title>Structural differences between open and direct communication in an
  online community</title><categories>cs.SI physics.soc-ph</categories><journal-ref>Physica A 414, 263-273 (2014)</journal-ref><doi>10.1016/j.physa.2014.07.037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most research of online communication focuses on modes of communication that
are either open (like forums, bulletin boards, Twitter, etc.) or direct (like
e-mails). In this work, we study a dataset that has both types of communication
channels. We relate our findings to theories of social organization and human
dynamics. The data comprises 36,492 users of a movie discussion community. Our
results show that there are differences in the way users communicate in the two
channels that are reflected in the shape of degree- and interevent time
distributions. The open communication that is designed to facilitate
conversations with any member, shows a broader degree distribution and more of
the triangles in the network are primarily formed in this mode of
communication. The direct channel is presumably preferred by closer
communication and the response time in dialogues is shorter. On a more
coarse-grained level, there are common patterns in the two networks. The
differences and overlaps between communication networks, thus, provide a unique
window into how social and structural aspects of communication establish and
evolve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8042</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8042</id><created>2014-07-30</created><authors><author><keyname>Evans</keyname><forenames>Lewis P. G.</forenames></author><author><keyname>Adams</keyname><forenames>Niall M.</forenames></author><author><keyname>Anagnostopoulos</keyname><forenames>Christoforos</forenames></author></authors><title>Targeting Optimal Active Learning via Example Quality</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many classification problems unlabelled data is abundant and a subset can
be chosen for labelling. This defines the context of active learning (AL),
where methods systematically select that subset, to improve a classifier by
retraining. Given a classification problem, and a classifier trained on a small
number of labelled examples, consider the selection of a single further
example. This example will be labelled by the oracle and then used to retrain
the classifier. This example selection raises a central question: given a fully
specified stochastic description of the classification problem, which example
is the optimal selection? If optimality is defined in terms of loss, this
definition directly produces expected loss reduction (ELR), a central quantity
whose maximum yields the optimal example selection. This work presents a new
theoretical approach to AL, example quality, which defines optimal AL behaviour
in terms of ELR. Once optimal AL behaviour is defined mathematically, reasoning
about this abstraction provides insights into AL. In a theoretical context the
optimal selection is compared to existing AL methods, showing that heuristics
can make sub-optimal selections. Algorithms are constructed to estimate example
quality directly. A large-scale experimental study shows these algorithms to be
competitive with standard AL methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8056</identifier>
 <datestamp>2015-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8056</id><created>2014-07-30</created><updated>2015-07-14</updated><authors><author><keyname>Facchi</keyname><forenames>Nicolo'</forenames></author><author><keyname>Gringoli</keyname><forenames>Francesco</forenames></author><author><keyname>Ricciato</keyname><forenames>Fabio</forenames></author><author><keyname>Toma</keyname><forenames>Andrea</forenames></author></authors><title>Emitter Localisation from Reception Timestamps in Asynchronous Networks</title><categories>cs.NI</categories><comments>To appear in Computer Networks</comments><doi>10.1016/j.comnet.2015.06.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of localising a mobile terminal (&quot;blind&quot; node) in
unknown position from a set of &quot;anchor&quot; nodes in known positions. The proposed
method does not require any form of node synchronisation nor measurement (or
control) of the transmission times, which is difficult or anyway costly to
achieve in practice. It relies exclusively on reception timestamps collected by
the anchor nodes, according to their local clocks, that overhear packets
transmitted by the blind node and by (at least one) other transmitting node(s)
in known position, e.g., other anchors. The clock differences between the nodes
are not eliminated ex ante through clock synchronisation, as in traditional ToA
and TDoA methods. Instead, they are counteracted ex post, during the data
processing stage, leveraging the data redundancy that is intrinsic to the
multiple reception of the same packet by different (anchor) nodes. We validate
the proposed method in different experimental settings, indoor and outdoor,
using exclusively low-cost Commercial-Off-The-Shelf WiFi devices, achieving
sub-meter accuracy in full Line-of-Sight conditions and meter-level accuracy in
mild Non-line-of-sight environment. The proposed method does not require that
the blind node participate actively to the localisation procedure and can use
&quot;opportunistically&quot; any legacy signal or packet available over-the-air for
communication purposes. Considering the very minimal requirement on the system
- basically, only that anchors in known positions are able to collect and share
reception timestamps - the proposed approach can enable practical adoption of
opportunistic and/or cooperative localisation on top of existing radio
communication systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8067</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8067</id><created>2014-07-30</created><authors><author><keyname>Yu</keyname><forenames>Fei</forenames></author><author><keyname>Rybar</keyname><forenames>Michal</forenames></author><author><keyname>Uhler</keyname><forenames>Caroline</forenames></author><author><keyname>Fienberg</keyname><forenames>Stephen E.</forenames></author></authors><title>Differentially-Private Logistic Regression for Detecting Multiple-SNP
  Association in GWAS Databases</title><categories>stat.ML cs.LG stat.AP</categories><comments>To appear in Proceedings of the 2014 International Conference on
  Privacy in Statistical Databases</comments><msc-class>62P10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following the publication of an attack on genome-wide association studies
(GWAS) data proposed by Homer et al., considerable attention has been given to
developing methods for releasing GWAS data in a privacy-preserving way. Here,
we develop an end-to-end differentially private method for solving regression
problems with convex penalty functions and selecting the penalty parameters by
cross-validation. In particular, we focus on penalized logistic regression with
elastic-net regularization, a method widely used to in GWAS analyses to
identify disease-causing genes. We show how a differentially private procedure
for penalized logistic regression with elastic-net regularization can be
applied to the analysis of GWAS data and evaluate our method's performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8069</identifier>
 <datestamp>2015-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8069</id><created>2014-07-30</created><updated>2015-01-25</updated><authors><author><keyname>Zhu</keyname><forenames>Yuan</forenames></author><author><keyname>Tang</keyname><forenames>Siyun</forenames></author></authors><title>New Algebraic Soft Decision Decoding Algorithm for Reed-Solomon Code</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new algebraic soft-decision decoding algorithm for
Reed-Solomon code is presented. It is based on rational interpolation and the
interpolation points are constructed by Berlekamp-Messay algorithm. Unlike the
traditional K{\&quot;o}tter-Vardy algorithm, new algorithm needs interpolation for
two smaller multiplicity matrixes, due to the corresponding factorization
algorithm for re-constructing codewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8078</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8078</id><created>2014-07-30</created><authors><author><keyname>Guettel</keyname><forenames>Stefan</forenames></author><author><keyname>Polizzi</keyname><forenames>Eric</forenames></author><author><keyname>Tang</keyname><forenames>Ping Tak Peter</forenames></author><author><keyname>Viaud</keyname><forenames>Gautier</forenames></author></authors><title>Zolotarev Quadrature Rules and Load Balancing for the FEAST Eigensolver</title><categories>math.NA cs.MS cs.NA</categories><comments>22 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The FEAST method for solving large sparse eigenproblems is equivalent to
subspace iteration with an approximate spectral projector and implicit
orthogonalization. This relation allows to characterize the convergence of this
method in terms of the error of a certain rational approximant to an indicator
function. We propose improved rational approximants leading to FEAST variants
with faster convergence, in particular, when using rational approximants based
on the work of Zolotarev. Numerical experiments demonstrate the possible
computational savings especially for pencils whose eigenvalues are not well
separated and when the dimension of the search space is only slightly larger
than the number of wanted eigenvalues. The new approach improves both
convergence robustness and load balancing when FEAST runs on multiple search
intervals in parallel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8088</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8088</id><created>2014-07-30</created><authors><author><keyname>Edera</keyname><forenames>Alejandro</forenames></author><author><keyname>Strappa</keyname><forenames>Yanela</forenames></author><author><keyname>Bromberg</keyname><forenames>Facundo</forenames></author></authors><title>The Grow-Shrink strategy for learning Markov network structures
  constrained by context-specific independences</title><categories>cs.LG cs.DS</categories><comments>12 pages, and 8 figures. This works was presented in IBERAMIA 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov networks are models for compactly representing complex probability
distributions. They are composed by a structure and a set of numerical weights.
The structure qualitatively describes independences in the distribution, which
can be exploited to factorize the distribution into a set of compact functions.
A key application for learning structures from data is to automatically
discover knowledge. In practice, structure learning algorithms focused on
&quot;knowledge discovery&quot; present a limitation: they use a coarse-grained
representation of the structure. As a result, this representation cannot
describe context-specific independences. Very recently, an algorithm called
CSPC was designed to overcome this limitation, but it has a high computational
complexity. This work tries to mitigate this downside presenting CSGS, an
algorithm that uses the Grow-Shrink strategy for reducing unnecessary
computations. On an empirical evaluation, the structures learned by CSGS
achieve competitive accuracies and lower computational complexity with respect
to those obtained by CSPC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8093</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8093</id><created>2014-07-30</created><authors><author><keyname>Jakeman</keyname><forenames>John D.</forenames></author><author><keyname>Eldred</keyname><forenames>Michael S.</forenames></author><author><keyname>Sargsyan</keyname><forenames>Khachik</forenames></author></authors><title>Enhancing $\ell_1$-minimization estimates of polynomial chaos expansions
  using basis selection</title><categories>cs.NA math.NA</categories><doi>10.1016/j.jcp.2015.02.025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a basis selection method that can be used with
$\ell_1$-minimization to adaptively determine the large coefficients of
polynomial chaos expansions (PCE). The adaptive construction produces
anisotropic basis sets that have more terms in important dimensions and limits
the number of unimportant terms that increase mutual coherence and thus degrade
the performance of $\ell_1$-minimization. The important features and the
accuracy of basis selection are demonstrated with a number of numerical
examples. Specifically, we show that for a given computational budget, basis
selection produces a more accurate PCE than would be obtained if the basis is
fixed a priori. We also demonstrate that basis selection can be applied with
non-uniform random variables and can leverage gradient information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8116</identifier>
 <datestamp>2015-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8116</id><created>2014-07-30</created><updated>2015-10-20</updated><authors><author><keyname>Price</keyname><forenames>D. C.</forenames></author><author><keyname>Clark</keyname><forenames>M. A.</forenames></author><author><keyname>Barsdell</keyname><forenames>B. R.</forenames></author><author><keyname>Babich</keyname><forenames>R.</forenames></author><author><keyname>Greenhill</keyname><forenames>L. J.</forenames></author></authors><title>Optimizing performance per watt on GPUs in High Performance Computing:
  temperature, frequency and voltage effects</title><categories>astro-ph.IM cs.DC</categories><comments>In Computer Science - Research and Development special issue on
  Energy-Aware High-Performance Computing. The final publication is available
  at Springer via http://dx.doi.org/10.1007/s00450-015-0300-5</comments><doi>10.1007/s00450-015-0300-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The magnitude of the real-time digital signal processing challenge attached
to large radio astronomical antenna arrays motivates use of high performance
computing (HPC) systems. The need for high power efficiency (performance per
watt) at remote observatory sites parallels that in HPC broadly, where
efficiency is an emerging critical metric. We investigate how the performance
per watt of graphics processing units (GPUs) is affected by temperature, core
clock frequency and voltage. Our results highlight how the underlying physical
processes that govern transistor operation affect power efficiency. In
particular, we show experimentally that GPU power consumption grows
non-linearly with both temperature and supply voltage, as predicted by physical
transistor models. We show lowering GPU supply voltage and increasing clock
frequency while maintaining a low die temperature increases the power
efficiency of an NVIDIA K20 GPU by up to 37-48% over default settings when
running xGPU, a compute-bound code used in radio astronomy. We discuss how
temperature-aware power models could be used to reduce power consumption for
future HPC installations. Automatic temperature-aware and application-dependent
voltage and frequency scaling (T-DVFS and A-DVFS) may provide a mechanism to
achieve better power efficiency for a wider range of codes running on GPUs
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8121</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8121</id><created>2014-07-30</created><authors><author><keyname>Bora</keyname><forenames>Dibya Jyoti</forenames></author><author><keyname>Gupta</keyname><forenames>Anil Kumar</forenames></author></authors><title>Clustering Approach Towards Image Segmentation: An Analytical Study</title><categories>cs.CV</categories><comments>10 pages, 3 figures</comments><journal-ref>International Journal of Research in Computer Applications and
  Robotics, ISSN 2320-7345, Vol.2, Issue.7, Pg.: 115-124 July 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image processing is an important research area in computer vision. Image
segmentation plays the vital rule in image processing research. There exist so
many methods for image segmentation. Clustering is an unsupervised study.
Clustering can also be used for image segmentation. In this paper, an in-depth
study is done on different clustering techniques that can be used for image
segmentation with their pros and cons. An experiment for color image
segmentation based on clustering with K-Means algorithm is performed to observe
the accuracy of clustering technique for the segmentation purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8123</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8123</id><created>2014-07-30</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Sharma</keyname><forenames>Richa</forenames></author></authors><title>Merging and Shifting of Images with Prominence Coefficient for
  Predictive Analysis using Combined Image</title><categories>cs.CV</categories><comments>7 pages,4 figures,Emerging Research in Computing, Information,
  Communication and Application (ERCICA13), International Conference on, NMIT,
  Bangalore, India, pp. 205,211, 2-3 Aug.2013 ISBN: 9789351071020</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shifting of objects in an image and merging many images after appropriate
shifting is being used in several engineering and scientific applications which
require complex perception development. A method has been presented here which
could be used in precision engineering and biological applications where more
precise prediction is required of a combined phenomenon with varying prominence
of each phenomenon. Accurate merging of intended pixels can be achieved in high
quality using frequency domain techniques even though initial properties of the
original pixels are lost in this process. This paper introduces a technique to
shift and merge various images with varying prominence of each image. A
coefficient named prominence coefficient has been introduced which is capable
of making some of the images transparent and highlighting the rest as per
requirement of merging process which can be used as a simple but effective
technique for overlapped view of a set of images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8132</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8132</id><created>2014-07-30</created><updated>2014-08-11</updated><authors><author><keyname>Barman</keyname><forenames>Sambhu Charan</forenames></author><author><keyname>Mondal</keyname><forenames>Sukumar</forenames></author><author><keyname>Pal</keyname><forenames>Madhumangal</forenames></author></authors><title>Computation of a Tree 3-Spanner on Trapezoid Graphs</title><categories>cs.DM</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a graph, a spanning tree is said to be a tree t-spanner of the graph if
the distance between any two vertices in is at most times their distance in .
The tree t-spanner has many applications in networks and distributed
environments. In this paper, an algorithm is presented to find a tree -spanner
on trapezoid graphs in time, where is the number of vertices of the graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8134</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8134</id><created>2014-07-30</created><authors><author><keyname>Aiello</keyname><forenames>Luca Maria</forenames></author><author><keyname>Deplano</keyname><forenames>Martina</forenames></author><author><keyname>Schifanella</keyname><forenames>Rossano</forenames></author><author><keyname>Ruffo</keyname><forenames>Giancarlo</forenames></author></authors><title>People are Strange when you're a Stranger: Impact and Influence of Bots
  on Social Networks</title><categories>cs.SI cs.AI cs.CY physics.soc-ph</categories><comments>10 pages, 9 figures, Proceedings of the 6th International AAAI
  Conference on Weblogs and Social Media, Dublin, IR, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bots are, for many Web and social media users, the source of many dangerous
attacks or the carrier of unwanted messages, such as spam. Nevertheless,
crawlers and software agents are a precious tool for analysts, and they are
continuously executed to collect data or to test distributed applications.
However, no one knows which is the real potential of a bot whose purpose is to
control a community, to manipulate consensus, or to influence user behavior. It
is commonly believed that the better an agent simulates human behavior in a
social network, the more it can succeed to generate an impact in that
community. We contribute to shed light on this issue through an online social
experiment aimed to study to what extent a bot with no trust, no profile, and
no aims to reproduce human behavior, can become popular and influential in a
social media. Results show that a basic social probing activity can be used to
acquire social relevance on the network and that the so-acquired popularity can
be effectively leveraged to drive users in their social connectivity choices.
We also register that our bot activity unveiled hidden social polarization
patterns in the community and triggered an emotional response of individuals
that brings to light subtle privacy hazards perceived by the user base.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8142</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8142</id><created>2014-07-30</created><updated>2015-04-01</updated><authors><author><keyname>Shun</keyname><forenames>Julian</forenames></author></authors><title>Parallel Wavelet Tree Construction</title><categories>cs.DS cs.DC</categories><comments>This is a longer version of the paper that appears in the Proceedings
  of the IEEE Data Compression Conference, 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present parallel algorithms for wavelet tree construction with
polylogarithmic depth, improving upon the linear depth of the recent parallel
algorithms by Fuentes-Sepulveda et al. We experimentally show on a 40-core
machine with two-way hyper-threading that we outperform the existing parallel
algorithms by 1.3--5.6x and achieve up to 27x speedup over the sequential
algorithm on a variety of real-world and artificial inputs. Our algorithms show
good scalability with increasing thread count, input size and alphabet size. We
also discuss extensions to variants of the standard wavelet tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8146</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8146</id><created>2014-07-30</created><authors><author><keyname>Rodrigues</keyname><forenames>J.</forenames></author><author><keyname>Mateus</keyname><forenames>P.</forenames></author><author><keyname>Paunkovi&#x107;</keyname><forenames>N.</forenames></author><author><keyname>Souto</keyname><forenames>A.</forenames></author></authors><title>Oblivious transfer based on single-qubit rotations</title><categories>quant-ph cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a bit-string quantum oblivious transfer protocol based on
single-qubit rotations. The proposed protocol does not violate the Lo's no-go
theorem that prevents the unconditional security of $1$-out-of-$2$ oblivious
transfer. Our protocol is based on a previously proposed quantum public key
protocol and its security relies on the laws of Quantum Mechanics. We also
present a single-bit oblivious transfer based on the proposed bit-string
protocol. The protocol can be implemented with current technology based on
optics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8147</identifier>
 <datestamp>2014-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8147</id><created>2014-07-30</created><updated>2014-12-09</updated><authors><author><keyname>Lin</keyname><forenames>Binbin</forenames></author><author><keyname>Li</keyname><forenames>Qingyang</forenames></author><author><keyname>Sun</keyname><forenames>Qian</forenames></author><author><keyname>Lai</keyname><forenames>Ming-Jun</forenames></author><author><keyname>Davidson</keyname><forenames>Ian</forenames></author><author><keyname>Fan</keyname><forenames>Wei</forenames></author><author><keyname>Ye</keyname><forenames>Jieping</forenames></author></authors><title>Stochastic Coordinate Coding and Its Application for Drosophila Gene
  Expression Pattern Annotation</title><categories>cs.LG cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  \textit{Drosophila melanogaster} has been established as a model organism for
investigating the fundamental principles of developmental gene interactions.
The gene expression patterns of \textit{Drosophila melanogaster} can be
documented as digital images, which are annotated with anatomical ontology
terms to facilitate pattern discovery and comparison. The automated annotation
of gene expression pattern images has received increasing attention due to the
recent expansion of the image database. The effectiveness of gene expression
pattern annotation relies on the quality of feature representation. Previous
studies have demonstrated that sparse coding is effective for extracting
features from gene expression images. However, solving sparse coding remains a
computationally challenging problem, especially when dealing with large-scale
data sets and learning large size dictionaries. In this paper, we propose a
novel algorithm to solve the sparse coding problem, called Stochastic
Coordinate Coding (SCC). The proposed algorithm alternatively updates the
sparse codes via just a few steps of coordinate descent and updates the
dictionary via second order stochastic gradient descent. The computational cost
is further reduced by focusing on the non-zero components of the sparse codes
and the corresponding columns of the dictionary only in the updating procedure.
Thus, the proposed algorithm significantly improves the efficiency and the
scalability, making sparse coding applicable for large-scale data sets and
large dictionary sizes. Our experiments on Drosophila gene expression data sets
demonstrate the efficiency and the effectiveness of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8151</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8151</id><created>2014-07-30</created><authors><author><keyname>Cuzzolin</keyname><forenames>Fabio</forenames></author></authors><title>Consistent transformations of belief functions</title><categories>cs.AI stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consistent belief functions represent collections of coherent or
non-contradictory pieces of evidence, but most of all they are the counterparts
of consistent knowledge bases in belief calculus. The use of consistent
transformations cs[.] in a reasoning process to guarantee coherence can
therefore be desirable, and generalizes similar techniques in classical logic.
Transformations can be obtained by minimizing an appropriate distance measure
between the original belief function and the collection of consistent ones. We
focus here on the case in which distances are measured using classical Lp
norms, in both the &quot;mass space&quot; and the &quot;belief space&quot; representation of belief
functions. While mass consistent approximations reassign the mass not focussed
on a chosen element of the frame either to the whole frame or to all supersets
of the element on an equal basis, approximations in the belief space do
distinguish these focal elements according to the &quot;focussed consistent
transformation&quot; principle. The different approximations are interpreted and
compared, with the help of examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8154</identifier>
 <datestamp>2015-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8154</id><created>2014-07-30</created><updated>2015-05-28</updated><authors><author><keyname>Einkemmer</keyname><forenames>Lukas</forenames></author><author><keyname>Ostermann</keyname><forenames>Alexander</forenames></author></authors><title>A splitting approach for the Kadomtsev--Petviashvili equation</title><categories>physics.comp-ph cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a splitting approach for the Kadomtsev--Petviashvili equation
with periodic boundary conditions and show that the necessary interpolation
procedure can be efficiently implemented. The error made by this numerical
scheme is compared to exponential integrators which have been shown in Klein
and Roidot (SIAM J. Sci. Comput., 2011) to perform best for stiff solutions of
the Kadomtsev--Petviashvili equation. Since many classic high order splitting
methods do not perform well, we propose a stable extrapolation method in order
to construct an efficient numerical scheme of order four. In addition, the
conservation properties and the possibility of order reduction for certain
initial values for the numerical schemes under consideration is investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8160</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8160</id><created>2014-07-30</created><updated>2014-08-21</updated><authors><author><keyname>Karumanchi</keyname><forenames>Siddharth</forenames></author><author><keyname>Mancini</keyname><forenames>Stefano</forenames></author><author><keyname>Winter</keyname><forenames>Andreas</forenames></author><author><keyname>Yang</keyname><forenames>Dong</forenames></author></authors><title>Quantum Channel Capacities with Passive Environment Assistance</title><categories>quant-ph cs.IT math.IT</categories><comments>14 pages, 13 figures, IEEE format, Theorem 9 (statement and proof)
  changed, updated References and Example 11 added. Comments are welcome!</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of passive environment-assisted communication via a
quantum channel, modeled as a unitary interaction between the information
carrying system and an environment. In this model, the environment is
controlled by a benevolent helper who can set its initial state such as to
assist sender and receiver of the communication link. (The case of a malicious
environment, also known as jammer, or arbitrarily varying channel, is
essentially well-understood and comprehensively reviewed.) Here, after setting
out precise definitions, focussing on the problem of quantum communication, we
show that entanglement plays a crucial role in this problem: indeed, the
assisted capacity where the helper is restricted to product states between
channel uses is different from the one with unrestricted helper. Furthermore,
prior shared entanglement between the helper and the receiver makes a
difference, too.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8161</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8161</id><created>2014-07-30</created><authors><author><keyname>Dud&#xed;k</keyname><forenames>Miroslav</forenames></author><author><keyname>Frongillo</keyname><forenames>Rafael</forenames></author><author><keyname>Vaughan</keyname><forenames>Jennifer Wortman</forenames></author></authors><title>Market Making with Decreasing Utility for Information</title><categories>cs.GT cs.AI</categories><journal-ref>M. Dudik, R. Frongillo, and J. Wortman Vaughan. Market Making with
  Decreasing Utility for Information. In Proceedings of the 30th Conference on
  Uncertainty in Artificial Intelligence, pages 152-161, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study information elicitation in cost-function-based combinatorial
prediction markets when the market maker's utility for information decreases
over time. In the sudden revelation setting, it is known that some piece of
information will be revealed to traders, and the market maker wishes to prevent
guaranteed profits for trading on the sure information. In the gradual decrease
setting, the market maker's utility for (partial) information decreases
continuously over time. We design adaptive cost functions for both settings
which: (1) preserve the information previously gathered in the market; (2)
eliminate (or diminish) rewards to traders for the publicly revealed
information; (3) leave the reward structure unaffected for other information;
and (4) maintain the market maker's worst-case loss. Our constructions utilize
mixed Bregman divergence, which matches our notion of utility for information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8168</identifier>
 <datestamp>2014-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8168</id><created>2014-07-30</created><authors><author><keyname>Kimball</keyname><forenames>Daniel</forenames></author><author><keyname>Michel</keyname><forenames>Elizabeth</forenames></author><author><keyname>Keltcher</keyname><forenames>Paul</forenames></author><author><keyname>Wolf</keyname><forenames>Michael M.</forenames></author></authors><title>Quantifying the Effect of Matrix Structure on Multithreaded Performance
  of the SpMV Kernel</title><categories>cs.DC cs.NA cs.PF</categories><comments>6 pages, 7 figures. IEEE HPEC 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse matrix-vector multiplication (SpMV) is the core operation in many
common network and graph analytics, but poor performance of the SpMV kernel
handicaps these applications. This work quantifies the effect of matrix
structure on SpMV performance, using Intel's VTune tool for the Sandy Bridge
architecture. Two types of sparse matrices are considered: finite difference
(FD) matrices, which are structured, and R-MAT matrices, which are
unstructured. Analysis of cache behavior and prefetcher activity reveals that
the SpMV kernel performs far worse with R-MAT matrices than with FD matrices,
due to the difference in matrix structure. To address the problems caused by
unstructured matrices, novel architecture improvements are proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8170</identifier>
 <datestamp>2015-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8170</id><created>2014-07-30</created><updated>2015-04-08</updated><authors><author><keyname>Abed</keyname><forenames>Fidaa</forenames></author><author><keyname>Caragiannis</keyname><forenames>Ioannis</forenames></author><author><keyname>Voudouris</keyname><forenames>Alexandros A.</forenames></author></authors><title>Near-optimal asymmetric binary matrix partitions</title><categories>cs.GT cs.CC</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the asymmetric binary matrix partition problem that was recently
introduced by Alon et al. (WINE 2013) to model the impact of asymmetric
information on the revenue of the seller in take-it-or-leave-it sales.
Instances of the problem consist of an $n \times m$ binary matrix $A$ and a
probability distribution over its columns. A partition scheme $B=(B_1,...,B_n)$
consists of a partition $B_i$ for each row $i$ of $A$. The partition $B_i$ acts
as a smoothing operator on row $i$ that distributes the expected value of each
partition subset proportionally to all its entries. Given a scheme $B$ that
induces a smooth matrix $A^B$, the partition value is the expected maximum
column entry of $A^B$. The objective is to find a partition scheme such that
the resulting partition value is maximized. We present a $9/10$-approximation
algorithm for the case where the probability distribution is uniform and a
$(1-1/e)$-approximation algorithm for non-uniform distributions, significantly
improving results of Alon et al. Although our first algorithm is combinatorial
(and very simple), the analysis is based on linear programming and duality
arguments. In our second result we exploit a nice relation of the problem to
submodular welfare maximization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8176</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8176</id><created>2014-07-30</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Sharma</keyname><forenames>Richa</forenames></author></authors><title>Accurate merging of images for predictive analysis using combined image</title><categories>cs.CV</categories><comments>5 pages, 4 figures,Signal Processing Image Processing &amp; Pattern
  Recognition (ICSIPR), 2013 International Conference on, Karunya University,
  Coimbatore, India, pp.169,173, 7-8 Feb. 2013. arXiv admin note: substantial
  text overlap with arXiv:1407.8123</comments><doi>10.1109/ICSIPR.2013.6497980</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several Scientific and engineering applications require merging of sampled
images for complex perception development. In most cases, for such
requirements, images are merged at intensity level. Even though it gives fairly
good perception of combined scenario of objects and scenes, it is found that
they are not sufficient enough to analyze certain engineering cases. The main
problem is incoherent modulation of intensity arising out of phase properties
being lost. In order to compensate these losses, combined phase and amplitude
merge is demanded. We present here a method which could be used in precision
engineering and biological applications where more precise prediction is
required of a combined phenomenon. When pixels are added, its original property
is lost but accurate merging of intended pixels can be achieved in high quality
using frequency domain properties of an image. This paper introduces a
technique to merge various images which can be used as a simple but effective
technique for overlapped view of a set of images and producing reduced dataset
for review purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8186</identifier>
 <datestamp>2015-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8186</id><created>2014-07-30</created><updated>2015-02-08</updated><authors><author><keyname>Zhao</keyname><forenames>Xiaoting</forenames></author><author><keyname>Frazier</keyname><forenames>Peter I.</forenames></author></authors><title>Exploration vs. Exploitation in the Information Filtering Problem</title><categories>math.OC cs.IR</categories><comments>36 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider information filtering, in which we face a stream of items too
voluminous to process by hand (e.g., scientific articles, blog posts, emails),
and must rely on a computer system to automatically filter out irrelevant
items. Such systems face the exploration vs. exploitation tradeoff, in which it
may be beneficial to present an item despite a low probability of relevance,
just to learn about future items with similar content. We present a Bayesian
sequential decision-making model of this problem, show how it may be solved to
optimality using a decomposition to a collection of two-armed bandit problems,
and show structural results for the optimal policy. We show that the resulting
method is especially useful when facing the cold start problem, i.e., when
filtering items for new users without a long history of past interactions. We
then present an application of this information filtering method to a
historical dataset from the arXiv.org repository of scientific articles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8187</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8187</id><created>2014-07-30</created><authors><author><keyname>Fisher</keyname><forenames>Charles K.</forenames></author><author><keyname>Mehta</keyname><forenames>Pankaj</forenames></author></authors><title>Fast Bayesian Feature Selection for High Dimensional Linear Regression
  in Genomics via the Ising Approximation</title><categories>q-bio.QM cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection, identifying a subset of variables that are relevant for
predicting a response, is an important and challenging component of many
methods in statistics and machine learning. Feature selection is especially
difficult and computationally intensive when the number of variables approaches
or exceeds the number of samples, as is often the case for many genomic
datasets. Here, we introduce a new approach -- the Bayesian Ising Approximation
(BIA) -- to rapidly calculate posterior probabilities for feature relevance in
L2 penalized linear regression. In the regime where the regression problem is
strongly regularized by the prior, we show that computing the marginal
posterior probabilities for features is equivalent to computing the
magnetizations of an Ising model. Using a mean field approximation, we show it
is possible to rapidly compute the feature selection path described by the
posterior probabilities as a function of the L2 penalty. We present simulations
and analytical results illustrating the accuracy of the BIA on some simple
regression problems. Finally, we demonstrate the applicability of the BIA to
high dimensional regression by analyzing a gene expression dataset with nearly
30,000 features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8194</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8194</id><created>2014-07-30</created><authors><author><keyname>Kawamura</keyname><forenames>Akitoshi</forenames></author><author><keyname>Kobayashi</keyname><forenames>Yusuke</forenames></author></authors><title>Fence patrolling by mobile agents with distinct speeds</title><categories>cs.CG cs.MA cs.RO</categories><comments>12 pages, 8 figures; preliminary version presented at ISAAC 2012</comments><doi>10.1007/s00446-014-0226-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Suppose we want to patrol a fence (line segment) using k mobile agents with
given speeds v_1, ..., v_k so that every point on the fence is visited by an
agent at least once in every unit time period. Czyzowicz et al. conjectured
that the maximum length of the fence that can be patrolled is (v_1 + ... +
v_k)/2, which is achieved by the simple strategy where each agent i moves back
and forth in a segment of length v_i/2. We disprove this conjecture by a
counterexample involving k = 6 agents. We also show that the conjecture is true
for k = 2, 3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8202</identifier>
 <datestamp>2016-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8202</id><created>2014-07-30</created><authors><author><keyname>Sutter</keyname><forenames>David</forenames></author><author><keyname>Sutter</keyname><forenames>Tobias</forenames></author><author><keyname>Esfahani</keyname><forenames>Peyman Mohajerin</forenames></author><author><keyname>Renner</keyname><forenames>Renato</forenames></author></authors><title>Efficient Approximation of Quantum Channel Capacities</title><categories>quant-ph cs.IT math.IT</categories><comments>36 pages, 1 figure</comments><journal-ref>IEEE Transactions on Information Theory vol. 62, no 1, pages
  578-598, 2016</journal-ref><doi>10.1109/TIT.2015.2503755</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an iterative method for approximating the capacity of
classical-quantum channels with a discrete input alphabet and a finite
dimensional output, possibly under additional constraints on the input
distribution. Based on duality of convex programming, we derive explicit upper
and lower bounds for the capacity. To provide an $\varepsilon$-close estimate
to the capacity, the presented algorithm requires $O(\tfrac{(N \vee M) M^3
\log(N)^{1/2}}{\varepsilon})$, where $N$ denotes the input alphabet size and
$M$ the output dimension. We then generalize the method for the task of
approximating the capacity of classical-quantum channels with a bounded
continuous input alphabet and a finite dimensional output. For channels with a
finite dimensional quantum mechanical input and output, the idea of a universal
encoder allows us to approximate the Holevo capacity using the same method. In
particular, we show that the problem of approximating the Holevo capacity can
be reduced to a multidimensional integration problem. For families of quantum
channels fulfilling a certain assumption we show that the complexity to derive
an $\varepsilon$-close solution to the Holevo capacity is subexponential or
even polynomial in the problem size. We provide several examples to illustrate
the performance of the approximation scheme in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8215</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8215</id><created>2014-07-30</created><authors><author><keyname>Feng</keyname><forenames>Vanessa Wei</forenames></author><author><keyname>Hirst</keyname><forenames>Graeme</forenames></author></authors><title>Two-pass Discourse Segmentation with Pairing and Global Features</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous attempts at RST-style discourse segmentation typically adopt
features centered on a single token to predict whether to insert a boundary
before that token. In contrast, we develop a discourse segmenter utilizing a
set of pairing features, which are centered on a pair of adjacent tokens in the
sentence, by equally taking into account the information from both tokens.
Moreover, we propose a novel set of global features, which encode
characteristics of the segmentation as a whole, once we have an initial
segmentation. We show that both the pairing and global features are useful on
their own, and their combination achieved an $F_1$ of 92.6% of identifying
in-sentence discourse boundaries, which is a 17.8% error-rate reduction over
the state-of-the-art performance, approaching 95% of human performance. In
addition, similar improvement is observed across different classification
frameworks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8242</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8242</id><created>2014-07-30</created><authors><author><keyname>Misra</keyname><forenames>Rakesh</forenames></author><author><keyname>Katti</keyname><forenames>Sachin</forenames></author></authors><title>A low-latency control plane for dense cellular networks</title><categories>cs.NI</categories><comments>14 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to keep up with the increasing demands for capacity, cellular
networks are becoming increasingly dense and heterogeneous. Dense deployments
are expected to provide a linear capacity scaling with the number of small
cells deployed due to spatial reuse gains. However in practice network capacity
is severely limited in dense networks due to interference. The primary reason
is that the current LTE control plane deployment model has very high latency
and is unable to cope with the demand of implementing interference management
techniques that require coordination on a millisecond timeframe.
  This paper presents SwiftC, a novel low-latency control plane design for LTE
networks. SwiftC's novel contribution is a design for efficiently sending and
receiving control plane messages over the LTE spectrum itself, thus creating a
direct and low-latency coordination signaling link between small cells and the
macrocell. SwiftC builds on recent work in full duplex radios and shows via
prototype implementations that a low latency control plane can be built over
the existing LTE network without wasting licensed spectrum. We also show the
benefits of SwiftC in implementing complex interference management techniques,
and show that with SwiftC small cell deployments can achieve almost a linear
capacity scaling with every small cell deployed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8244</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8244</id><created>2014-07-30</created><authors><author><keyname>Jia</keyname><forenames>Yuhan</forenames></author><author><keyname>Wu</keyname><forenames>Jianping</forenames></author><author><keyname>Du</keyname><forenames>Yiman</forenames></author><author><keyname>Qi</keyname><forenames>Geqi</forenames></author></authors><title>Study on FLOWSIM and its Application for Isolated Signal-ized
  Intersection Assessment</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently the traffic related problems have become strategically important,
due to the continuously increasing vehicle number. As a result, microscopic
simulation software has become an efficient method in traffic engineering for
its cost-effectiveness and safety characteristics. In this paper, a new fuzzy
logic based simulation software (FLOWSIM) is introduced, which can reflect the
mixed traffic flow phenomenon in China better. The fuzzy logic based
car-following model and lane-changing model are explained in detail.
Furthermore, its applications for mixed traffic flow management in mid-size
cities and for signalized intersection management assessment in large cities
are illustrated by examples in China. Finally, further study objectives are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8246</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8246</id><created>2014-07-30</created><authors><author><keyname>Baraniuk</keyname><forenames>Richard</forenames></author><author><keyname>Foucart</keyname><forenames>Simon</forenames></author><author><keyname>Needell</keyname><forenames>Deanna</forenames></author><author><keyname>Plan</keyname><forenames>Yaniv</forenames></author><author><keyname>Wootters</keyname><forenames>Mary</forenames></author></authors><title>Exponential decay of reconstruction error from binary measurements of
  sparse signals</title><categories>cs.IT math.IT math.ST stat.TH</categories><msc-class>94A12, 60D05, 90C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Binary measurements arise naturally in a variety of statistical and
engineering applications. They may be inherent to the problem---e.g., in
determining the relationship between genetics and the presence or absence of a
disease---or they may be a result of extreme quantization. In one-bit
compressed sensing it has recently been shown that the number of one-bit
measurements required for signal estimation mirrors that of unquantized
compressed sensing. Indeed, $s$-sparse signals in $\mathbb{R}^n$ can be
estimated (up to normalization) from $\Omega(s \log (n/s))$ one-bit
measurements. Nevertheless, controlling the precise accuracy of the error
estimate remains an open challenge. In this paper, we focus on optimizing the
decay of the error as a function of the oversampling factor $\lambda := m/(s
\log(n/s))$, where $m$ is the number of measurements. It is known that the
error in reconstructing sparse signals from standard one-bit measurements is
bounded below by $\Omega(\lambda^{-1})$. Without adjusting the measurement
procedure, reducing this polynomial error decay rate is impossible. However, we
show that an adaptive choice of the thresholds used for quantization may lower
the error rate to $e^{-\Omega(\lambda)}$. This improves upon guarantees for
other methods of adaptive thresholding as proposed in Sigma-Delta quantization.
We develop a general recursive strategy to achieve this exponential decay and
two specific polynomial-time algorithms which fall into this framework, one
based on convex programming and one on hard thresholding. This work is inspired
by the one-bit compressed sensing model, in which the engineer controls the
measurement procedure. Nevertheless, the principle is extendable to signal
reconstruction problems in a variety of binary statistical models as well as
statistical estimation problems like logistic regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8249</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8249</id><created>2014-07-30</created><authors><author><keyname>Xie</keyname><forenames>Yixuan</forenames><affiliation>Tyler</affiliation></author><author><keyname>Yuan</keyname><forenames>Jinhong</forenames><affiliation>Tyler</affiliation></author><author><keyname>Qifu</keyname><affiliation>Tyler</affiliation></author><author><keyname>Sun</keyname></author></authors><title>Design of Quantum Stabilizer Codes From Quadratic Residues Sets</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose two types, namely Type-I and Type-II, quantum stabilizer codes
using quadratic residue sets of prime modulus given by the form $p=4n\pm1$. The
proposed Type-I stabilizer codes are of cyclic structure and code length $N=p$.
They are constructed based on multi-weight circulant matrix generated from
idempotent polynomial, which is obtained from a quadratic residue set. The
proposed Type-II stabilizer codes are of quasi-cyclic (QC) structure and code
length $N=pk$, where $k$ is the size of a quadratic residue set. They are
constructed based on structured sparse-graphs codes derived from proto-matrix
and circulant permutation matrix. With the proposed methods, we design rich
classes of cyclic and quasi-cyclic quantum stabilizer codes with variable code
length. We show how the commutative constraint (also referred to as the
Symplectic Inner Product constraint) for quantum codes can be satisfied for
each proposed construction method. We also analyze both the dimension and
distance for Type-I stabilizer codes and the dimension of Type-II stabilizer
codes. For the cyclic quantum stabilizer codes, we show that they meet the
existing distance bounds in literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8251</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8251</id><created>2014-07-30</created><authors><author><keyname>Abdeen</keyname><forenames>Hani</forenames></author><author><keyname>Shata</keyname><forenames>Osama</forenames></author></authors><title>Type Variability and Completeness of Interfaces in Java Applications</title><categories>cs.SE</categories><journal-ref>International Journal of Software Engineering &amp; Applications
  (IJSEA), Vol.5, No.3, May 2014</journal-ref><doi>10.5121/ijsea.2014.5301</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Interfaces are widely used as central design elements of Java applications.
Although interfaces are abstract types similar to abstract classes, the usage
of interfaces in Java applications may considerably differ from the usage of
abstract classes. Unlike abstract classes, interfaces are meant to enable
multiple inheritance in Java programs. Hence, interfaces are meant to encode
shared similarities between classes belonging to different class-type
hierarchies. Therefore, it is frequent to use interfaces as partial types,
where an interface specifies one specific aspect or usage of its implementing
classes. In this paper, we investigate interfaces' usage in Java applications
from two perspectives. First, we investigate the usage of interfaces as types
of classes belonging to different class-type hierarchies (i.e., interface's
type variability). Second, we investigate the usage of interfaces as partial
types of implementing classes (i.e., interface's type completeness).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8258</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8258</id><created>2014-07-30</created><authors><author><keyname>Slay</keyname><forenames>Jill</forenames></author><author><keyname>Schulz</keyname><forenames>Fiona</forenames></author></authors><title>Development of an Ontology Based Forensic Search Mechanism: Proof of
  Concept</title><categories>cs.CR cs.IR</categories><proxy>Ibrahim Baggili</proxy><journal-ref>Journal of Digital Forensics, Security and Law, 1(1), 25-44</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the problems faced by Law Enforcement in searching large
quantities of electronic evidence. It examines the use of ontologies as the
basis for new forensic software filters and provides a proof of concept tool
based on an ontological design. It demonstrates that efficient searching is
produced through the use of such a design and points to further work that might
be carried out to extend this concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8269</identifier>
 <datestamp>2014-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8269</id><created>2014-07-30</created><updated>2014-09-24</updated><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Brill</keyname><forenames>Markus</forenames></author><author><keyname>Conitzer</keyname><forenames>Vincent</forenames></author><author><keyname>Elkind</keyname><forenames>Edith</forenames></author><author><keyname>Freeman</keyname><forenames>Rupert</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Justified Representation in Approval-Based Committee Voting</title><categories>cs.MA cs.GT</categories><comments>Preliminary version presented at MPREF 2014 which is subsumed by this
  version which has new coauthors</comments><msc-class>91A12, 68Q15</msc-class><acm-class>J.4; I.2.11; F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider approval-based committee voting, i.e., the setting where each
voter approves a subset of candidates, and these votes are then used to select
a fixed-size set of winners (committee). We propose a natural axiom for this
setting, which we call justified representation (JR). This axiom requires that
if a large enough group of voters exhibits agreement by supporting the same
candidate, then at least one voter in this group has an approved candidate in
the winning committee. We show that for every list of ballots it is possible to
select a committee that provides JR. We then check if this axiom is fulfilled
by well-known approval-based voting rules. We show that the answer is negative
for most of these rules, with a notable exception of PAV (Proportional Approval
Voting), an extreme version of RAV (Reweighted Approval Voting), and, for a
restricted preference domain, MAV (Minimax Approval Voting). We then introduce
a stronger version of the JR axiom, which we call Extended Justified
Representation (EJR), and show that PAV satisfies EJR, while other rules do
not. We also consider several other questions related to JR and EJR, including
the relationship between JR/EJR and unanimity, and the complexity of the
associated algorithmic problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8289</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8289</id><created>2014-07-31</created><updated>2014-08-05</updated><authors><author><keyname>He</keyname><forenames>Lifang</forenames></author><author><keyname>Kong</keyname><forenames>Xiangnan</forenames></author><author><keyname>Yu</keyname><forenames>Philip S.</forenames></author><author><keyname>Ragin</keyname><forenames>Ann B.</forenames></author><author><keyname>Hao</keyname><forenames>Zhifeng</forenames></author><author><keyname>Yang</keyname><forenames>Xiaowei</forenames></author></authors><title>DuSK: A Dual Structure-preserving Kernel for Supervised Tensor Learning
  with Applications to Neuroimages</title><categories>cs.LG</categories><comments>9 pages, 6 figures, conference,Proceedings of the 14th SIAM
  International Conference on Data Mining (SDM14), Philadelphia, USA, 2014</comments><acm-class>H.2.8; I.1.1; I.2.10; I.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With advances in data collection technologies, tensor data is assuming
increasing prominence in many applications and the problem of supervised tensor
learning has emerged as a topic of critical significance in the data mining and
machine learning community. Conventional methods for supervised tensor learning
mainly focus on learning kernels by flattening the tensor into vectors or
matrices, however structural information within the tensors will be lost. In
this paper, we introduce a new scheme to design structure-preserving kernels
for supervised tensor learning. Specifically, we demonstrate how to leverage
the naturally available structure within the tensorial representation to encode
prior knowledge in the kernel. We proposed a tensor kernel that can preserve
tensor structures based upon dual-tensorial mapping. The dual-tensorial mapping
function can map each tensor instance in the input space to another tensor in
the feature space while preserving the tensorial structure. Theoretically, our
approach is an extension of the conventional kernels in the vector space to
tensor space. We applied our novel kernel in conjunction with SVM to real-world
tensor classification problems including brain fMRI classification for three
different diseases (i.e., Alzheimer's disease, ADHD and brain damage by HIV).
Extensive empirical studies demonstrate that our proposed approach can
effectively boost tensor classification performances, particularly with small
sample sizes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8295</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8295</id><created>2014-07-31</created><authors><author><keyname>Kobitzsch</keyname><forenames>Moritz</forenames></author><author><keyname>Samaranayake</keyname><forenames>Samitha</forenames></author><author><keyname>Schieferdecker</keyname><forenames>Dennis</forenames></author></authors><title>Pruning Techniques for the Stochastic on-time Arrival
  Problem\texorpdfstring -- An Experimental Study</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing shortest paths is one of the most researched topics in algorithm
engineering. Currently available algorithms compute shortest paths in mere
fractions of a second on continental sized road networks. In the presence of
unreliability, however, current algorithms fail to achieve results as
impressive as for the static setting. In contrast to speed-up techniques for
static route planning, current implementations for the stochastic on-time
arrival problem require the computationally expensive step of solving
convolution products. Running times can reach hours when considering large
scale networks. We present a novel approach to reduce this immense
computational effort of stochastic routing based on existing techniques for
alternative routes. In an extensive experimental study, we show that the
process of stochastic route planning can be speed-up immensely, without
sacrificing much in terms of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8309</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8309</id><created>2014-07-31</created><updated>2016-02-02</updated><authors><author><keyname>Feng</keyname><forenames>Chen</forenames></author><author><keyname>Xu</keyname><forenames>Hong</forenames></author><author><keyname>Li</keyname><forenames>Baochun</forenames></author></authors><title>An Alternating Direction Method Approach to Cloud Traffic Management</title><categories>cs.NI cs.PF</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a unified framework for studying various cloud
traffic management problems, ranging from geographical load balancing to
backbone traffic engineering. We first abstract these real-world problems as a
multi-facility resource allocation problem, and then present two distributed
optimization algorithms by exploiting the special structure of the problem. Our
algorithms are inspired by Alternating Direction Method of Multipliers (ADMM),
enjoying a number of unique features. Compared to dual decomposition, they
converge with non-strictly convex objective functions; compared to other
ADMM-type algorithms, they not only achieve faster convergence under weaker
assumptions, but also have lower computational complexity and lower
message-passing overhead. The simulation results not only confirm these
desirable features of our algorithms, but also highlight several additional
advantages, such as scalability and fault-tolerance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8315</identifier>
 <datestamp>2015-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8315</id><created>2014-07-31</created><updated>2015-05-22</updated><authors><author><keyname>Hsieh</keyname><forenames>Sung-Hsien</forenames></author><author><keyname>Lu</keyname><forenames>Chun-Shien</forenames></author><author><keyname>Pei</keyname><forenames>Soo-Chang</forenames></author></authors><title>Sparse Fast Fourier Transform for Exactly and Generally K-Sparse Signals
  by Downsampling and Sparse Recovery</title><categories>cs.DS</categories><comments>31 pages, 6 figures, the preliminary version was published in ICASSP
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast Fourier Transform (FFT) is one of the most important tools in digital
signal processing. FFT costs O(N \log N) for transforming a signal of length N.
Recently, Sparse Fourier Transform (SFT) has emerged as a critical issue
addressing how to compute a compressed Fourier transform of a signal with
complexity being related to the sparsity of its spectrum. In this paper, a new
SFT algorithm is proposed for both exactly K-sparse signals (with K non-zero
frequencies) and generally K-sparse signals (with K significant frequencies),
with the assumption that the distribution of the non-zero frequencies is
uniform. The nuclear idea is to downsample the input signal at the beginning;
then, subsequent processing operates under downsampled signals, where signal
lengths are proportional to O(K). Downsampling, however, possibly leads to
&quot;aliasing.&quot; By the shift property of DFT, we recast the aliasing problem as
complex Bose-Chaudhuri-Hocquenghem (BCH) codes solved by syndrome decoding. The
proposed SFT algorithm for exactly K-sparse signals recovers 1-\tau frequencies
with computational complexity O(K \log K) and probability at least
1-O(\frac{c}{\tau})^{\tau K} under K=O(N), where c is a user-controlled
parameter.
  For generally K-sparse signals, due to the fact that BCH codes are sensitive
to noise, we combine a part of syndrome decoding with a compressive
sensing-based solver for obtaining $K$ significant frequencies. The
computational complexity of our algorithm is \max \left( O(K \log K), O(N)
\right), where the Big-O constant of O(N) is very small and only a simple
operation involves O(N). Our simulations reveal that O(N) does not dominate the
computational cost of sFFT-DT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8320</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8320</id><created>2014-07-31</created><authors><author><keyname>Chandio</keyname><forenames>Aftab Ahmed</forenames></author><author><keyname>Zhu</keyname><forenames>Dingju</forenames></author><author><keyname>Sodhro</keyname><forenames>Ali Hassan</forenames></author><author><keyname>Syed</keyname><forenames>Muhammad Umer</forenames></author></authors><title>An Implementation of Web Services for Inter-Connectivity of Information
  Systems</title><categories>cs.SE</categories><comments>7 pages, 5 figures, (Accepted for the Int. J. Com. Dig. Sys. Vol. 3,
  No. 3, ISSN. 2210-142X)</comments><journal-ref>International Journal of Computing and Digital Systems (IJCDS),
  Vol. 3, No. 3, pp. (2014)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As educational institutions and their departments rapidly increase, a
communication between their end-users becomes more and more difficult in
traditional online management systems (OMS). However, the end-users, i.e.,
employees, teaching staff, and students are associated to different sub-domains
and using different subsystems that are executed on different platforms
following different administrative policies. Because of their
intercommunication is not automated integrated, consequently, the overall
efficiency of the system is degraded and the communication time is increased.
Therefore, a technique for better interoperability and automated integration of
departments is an urgent needed. Many of existing systems does not have a set
of connections yet, such as the system of the University of Sindh (UoS). In
this paper, we propose a system for the UoS, named integration of
inter-connectivity of information system (i3) based on service oriented
architecture (SOA) with web services. The system i3 monitors and exchanges the
students information in support of verification along heterogeneous and
decentralized nature. Moreover, the proposed system provides capability of
interoperability between their subsystems that are deployed in different
departments of UoS and using different programming languages and database
management systems (DBMS)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8322</identifier>
 <datestamp>2015-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8322</id><created>2014-07-31</created><updated>2015-07-13</updated><authors><author><keyname>Corral</keyname><forenames>Alvaro</forenames></author><author><keyname>Boleda</keyname><forenames>Gemma</forenames></author><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames></author></authors><title>Zipf's law for word frequencies: word forms versus lemmas in long texts</title><categories>physics.soc-ph cs.CL physics.data-an</categories><journal-ref>PLoS ONE 10 (7), e0129031</journal-ref><doi>10.1371/journal.pone.0129031</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zipf's law is a fundamental paradigm in the statistics of written and spoken
natural language as well as in other communication systems. We raise the
question of the elementary units for which Zipf's law should hold in the most
natural way, studying its validity for plain word forms and for the
corresponding lemma forms. In order to have as homogeneous sources as possible,
we analyze some of the longest literary texts ever written, comprising four
different languages, with different levels of morphological complexity. In all
cases Zipf's law is fulfilled, in the sense that a power-law distribution of
word or lemma frequencies is valid for several orders of magnitude. We
investigate the extent to which the word-lemma transformation preserves two
parameters of Zipf's law: the exponent and the low-frequency cut-off. We are
not able to demonstrate a strict invariance of the tail, as for a few texts
both exponents deviate significantly, but we conclude that the exponents are
very similar, despite the remarkable transformation that going from words to
lemmas represents, considerably affecting all ranges of frequencies. In
contrast, the low-frequency cut-offs are less stable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8325</identifier>
 <datestamp>2015-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8325</id><created>2014-07-31</created><updated>2015-02-12</updated><authors><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author><author><keyname>Xiao</keyname><forenames>Tao</forenames></author></authors><title>Improved Efficiency Guarantees in Auctions with Budgets</title><categories>cs.GT</categories><comments>Strengthened results in private budget setting, in which our auction
  can work on any valuation function and guarantees a constant approximation
  ratio</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the efficiency guarantees in the simple auction environment where
the auctioneer has one unit of divisible good to be distributed among a number
of budget constrained agents. With budget constraints, the social welfare
cannot be approximated by a better factor than the number of agents by any
truthful mechanism. Thus, we follow a recent work by Dobzinski and Leme (ICALP
2014) to approximate the liquid welfare, which is the welfare of the agents
each capped by her/his own budget. We design a new truthful auction with an
approximation ratio of $\frac{\sqrt{5}+1}{2} \approx 1.618$, improving the best
previous ratio of $2$ when the budgets for agents are public knowledge and
their valuation is linear (additive). In private budget setting, we propose the
first constant approximation auction with approximation ratio of $34$.
Moreover, this auction works for any valuation function. Previously, only
$O(\log n)$ approximation was known for linear and decreasing marginal
(concave) valuations, and $O(\log^2 n)$ approximation was known for
sub-additive valuations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8337</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8337</id><created>2014-07-31</created><authors><author><keyname>Murthy</keyname><forenames>G. Vishnu</forenames></author><author><keyname>C.</keyname><forenames>Pavan Kumar</forenames></author><author><keyname>Kumar</keyname><forenames>Vakulabharanam Vijaya</forenames></author></authors><title>A New Model of Array Grammar for generating Connected Patterns on an
  Image Neighborhood</title><categories>cs.FL cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Study of patterns on images is recognized as an important step in
characterization and classification of image. The ability to efficiently
analyze and describe image patterns is thus of fundamental importance. The
study of syntactic methods of describing pictures has been of interest for
researchers. Array Grammars can be used to represent and recognize connected
patterns. In any image the patterns are recognized using connected patterns. It
is very difficult to represent all connected patterns (CP) even on a small 3 x
3 neighborhood in a pictorial way. The present paper proposes the model of
array grammar capable of generating any kind of simple or complex pattern and
derivation of connected pattern in an image neighborhood using the proposed
grammar is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8339</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8339</id><created>2014-07-31</created><updated>2015-11-15</updated><authors><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Yajun</forenames></author><author><keyname>Yuan</keyname><forenames>Yang</forenames></author></authors><title>Combinatorial Multi-Armed Bandit and Its Extension to Probabilistically
  Triggered Arms</title><categories>cs.LG</categories><comments>A preliminary version of the paper is published in ICML'2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a general framework for a large class of combinatorial multi-armed
bandit (CMAB) problems, where subsets of base arms with unknown distributions
form super arms. In each round, a super arm is played and the base arms
contained in the super arm are played and their outcomes are observed. We
further consider the extension in which more based arms could be
probabilistically triggered based on the outcomes of already triggered arms.
The reward of the super arm depends on the outcomes of all played arms, and it
only needs to satisfy two mild assumptions, which allow a large class of
nonlinear reward instances. We assume the availability of an offline
(\alpha,\beta)-approximation oracle that takes the means of the outcome
distributions of arms and outputs a super arm that with probability {\beta}
generates an {\alpha} fraction of the optimal expected reward. The objective of
an online learning algorithm for CMAB is to minimize
(\alpha,\beta)-approximation regret, which is the difference between the
\alpha{\beta} fraction of the expected reward when always playing the optimal
super arm, and the expected reward of playing super arms according to the
algorithm. We provide CUCB algorithm that achieves O(log n)
distribution-dependent regret, where n is the number of rounds played, and we
further provide distribution-independent bounds for a large class of reward
functions. Our regret analysis is tight in that it matches the bound of UCB1
algorithm (up to a constant factor) for the classical MAB problem, and it
significantly improves the regret bound in a earlier paper on combinatorial
bandits with linear rewards. We apply our CMAB framework to two new
applications, probabilistic maximum coverage and social influence maximization,
both having nonlinear reward structures. In particular, application to social
influence maximization requires our extension on probabilistically triggered
arms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8342</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8342</id><created>2014-07-31</created><authors><author><keyname>Moreira</keyname><forenames>Waldir</forenames></author><author><keyname>Mendes</keyname><forenames>Paulo</forenames></author></authors><title>Social-aware Forwarding in Opportunistic Wireless Networks: Content
  Awareness or Obliviousness?</title><categories>cs.NI</categories><comments>7 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the current host-based Internet architecture, networking faces
limitations in dynamic scenarios, due mostly to host mobility. The ICN paradigm
mitigates such problems by releasing the need to have an end-to-end transport
session established during the life time of the data transfer. Moreover, the
ICN concept solves the mismatch between the Internet architecture and the way
users would like to use it: currently a user needs to know the topological
location of the hosts involved in the communication when he/she just wants to
get the data, independently of its location. Most of the research efforts aim
to come up with a stable ICN architecture in fixed networks, with few examples
in ad-hoc and vehicular networks. However, the Internet is becoming more
pervasive with powerful personal mobile devices that allow users to form
dynamic networks in which content may be exchanged at all times and with low
cost. Such pervasive wireless networks suffer with different levels of
disruption given user mobility, physical obstacles, lack of cooperation,
intermittent connectivity, among others. This paper discusses the combination
of content knowledge (e.g., type and interested parties) and social awareness
within opportunistic networking as to drive the deployment of ICN solutions in
disruptive networking scenarios. With this goal in mind, we go over few
examples of social-aware content-based opportunistic networking proposals that
consider social awareness to allow content dissemination independently of the
level of network disruption. To show how much content knowledge can improve
social-based solutions, we illustrate by means of simulation some
content-oblivious/oriented proposals in scenarios based on synthetic mobility
patterns and real human traces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8348</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8348</id><created>2014-07-31</created><authors><author><keyname>Wagdy</keyname><forenames>Ahmed</forenames></author><author><keyname>El-Keyi</keyname><forenames>Amr</forenames></author><author><keyname>Khattab</keyname><forenames>Tamer</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author></authors><title>On the Degrees of Freedom of SISO X-Channel with Alternating CSIT</title><categories>cs.IT math.IT</categories><comments>It is only a draft insha'Allah. arXiv admin note: substantial text
  overlap with arXiv:1404.6348</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we establish the degrees of freedom (DoF) of the two-user
single input single output (SISO) X-channel with alternating channel state
information at the transmitters (CSIT). Three cases are considered for the
availability of CSIT; perfect, delayed and no-CSIT. Each state is associated
with a fraction of time denoted by $\lambda_P, \lambda_D$ and $\lambda_N $,
respectively. We provide new results for DoF of the two-user SISO X-channel
when the available CSIT alternates between these three cases under a certain
distribution $\Lambda(\lambda_P, \lambda_D, \lambda_N )$. Specifically, we show
that the X-channel with alternating CSIT for $\Lambda(1/8, 3/8, 1/2)$ can
achieve $5/4$ DoF. The interesting thing about $5/4$ is that it represents a
position of compromise or a middle ground between the channel knowledge that
transmitters need to steer interference and the degrees of freedom that the
network can achieve. Moreover, $5/4$ is strictly greater than $6/5$ which is
the upper bound for the X-channel with \textit{fixed} delayed CSIT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8355</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8355</id><created>2014-07-31</created><authors><author><keyname>Moreira</keyname><forenames>Waldir</forenames></author><author><keyname>Ferreira</keyname><forenames>Ronedo</forenames></author><author><keyname>Cirqueira</keyname><forenames>Douglas</forenames></author><author><keyname>Mendes</keyname><forenames>Paulo</forenames></author><author><keyname>Cerqueira</keyname><forenames>Eduardo</forenames></author></authors><title>SocialDTN: A DTN implementation for Digital and Social Inclusion</title><categories>cs.NI cs.CY</categories><comments>3 pages, 4 figures</comments><doi>10.1145/2502880.2502892</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite of the importance of access to computers and to the Internet for the
development of people and their inclusion in society, there are people that
still suffer with digital divide and social exclusion.
Delay/Disruption-Tolerant Networking (DTN) can help the digital/social
inclusion of these people as it allows opportunistic and asynchronous
communication, which does not depend upon networking infrastructure. We
introduce SocialDTN, an implementation of the DTN architecture for Android
devices that operates over Bluetooth, taking advantages of the social daily
routines of users. As we want to exploit the social proximity and interactions
existing among users, SocialDTN includes a social-aware opportunistic routing
proposal, dLife, instead of the well-known (but social-oblivious) PROPHET.
Simulations show the potential of dLife for our needs. Additionally, some
preliminary results from field experimentations are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8359</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8359</id><created>2014-07-31</created><authors><author><keyname>Torrellas</keyname><forenames>Marc</forenames></author><author><keyname>Agustin</keyname><forenames>Adrian</forenames></author><author><keyname>Vidal</keyname><forenames>Josep</forenames></author><author><keyname>Mu&#xf1;oz</keyname><forenames>Olga</forenames></author></authors><title>The DoF of the 3-user ($p,p+1$) MIMO Interference Channel</title><categories>cs.IT math.IT</categories><comments>31 pages, 3 figures, submitted to the IEEE Transactions on
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The \emph{degrees of freedom} (DoF) of the 3-user multiple-input
multiple-output (MIMO) interference channel (IC) with full channel state
information (CSI) and constant channel coefficients are characterized when
linear filters are employed and $(p,p+1)$ antennas are deployed at the
transmitters and receivers, respectively. The point of departure of this paper
is the work of Wang et al, which conjectured but not proved the DoF for the
configuration tackled in this work. In this work we prove the optimal DoF by
means of a transmission scheme based on asymmetric complex signaling (ACS)
together with symbol extensions in time and interference alignment (IA)
concepts. The paper deals with the $p=2,3$ cases, providing the transmit and
receive filters and the tools needed for proving the achievability of the DoF
for other values of $p$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8363</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8363</id><created>2014-07-31</created><authors><author><keyname>Moreira</keyname><forenames>Waldir</forenames></author><author><keyname>Mendes</keyname><forenames>Paulo</forenames></author><author><keyname>Sargento</keyname><forenames>Susana</forenames></author></authors><title>Social-aware Opportunistic Routing Protocol based on User's Interactions
  and Interests</title><categories>cs.NI</categories><doi>10.1007/978-3-319-04105-6_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, routing proposals must deal with a panoply of heterogeneous
devices, intermittent connectivity, and the users' constant need for
communication, even in rather challenging networking scenarios. Thus, we
propose a Social-aware Content-based Opportunistic Routing Protocol, SCORP,
that considers the users' social interaction and their interests to improve
data delivery in urban, dense scenarios. Through simulations, using synthetic
mobility and human traces scenarios, we compare the performance of our solution
against other two social-aware solutions, dLife and Bubble Rap, and the
social-oblivious Spray and Wait, in order to show that the combination of
social awareness and content knowledge can be beneficial when disseminating
data in challenging networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8365</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8365</id><created>2014-07-31</created><authors><author><keyname>Bahabadi</keyname><forenames>Mohammad Dehghan</forenames></author><author><keyname>Golpayegani</keyname><forenames>Alireza Hashemi</forenames></author><author><keyname>Esmaeili</keyname><forenames>Leila</forenames></author></authors><title>A Novel C2C E-Commerce Recommender System Based on Link Prediction:
  Applying Social Network Analysis</title><categories>cs.SI cs.IR</categories><comments>7 pages, 5 figures</comments><journal-ref>International Journal of Advanced Studies in Computer Science &amp;
  Engineering (ijascse), Vol 3, Issue 7, July 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social network analysis emerged as an important research topic in sociology
decades ago, and it has also attracted scientists from various fields of study
like psychology, anthropology, geography and economics. In recent years, a
significant number of researches has been conducted on using social network
analysis to design e-commerce recommender systems. Most of the current
recommender systems are designed for B2C e-commerce websites. This paper
focuses on building a recommendation algorithm for C2C e-commerce business
model by considering special features of C2C e-commerce websites. In this
paper, we consider users and their transactions as a network; by this mapping,
link prediction technique which is an important task in social network analysis
could be used to build the recommender system. The proposed tow-level
recommendation algorithm, rather than topology of the network, uses nodes
features like: category of items, ratings of users, and reputation of sellers.
The results show that the proposed model can be used to predict a portion of
future trades between users in a C2C commercial network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8368</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8368</id><created>2014-07-31</created><authors><author><keyname>Moreira</keyname><forenames>Waldir</forenames></author><author><keyname>Mendes</keyname><forenames>Paulo</forenames></author><author><keyname>Sargento</keyname><forenames>Susana</forenames></author></authors><title>Opportunistic Routing Based on Daily Routines</title><categories>cs.NI</categories><comments>6 pages, 7 figures</comments><doi>10.1109/WoWMoM.2012.6263749</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opportunistic routing is being investigated to enable the proliferation of
low-cost wireless applications. A recent trend is looking at social structures,
inferred from the social nature of human mobility, to bring messages close to a
destination. To have a better picture of social structures, social-based
opportunistic routing solutions should consider the dynamism of users' behavior
resulting from their daily routines. We address this challenge by presenting
dLife, a routing algorithm able to capture the dynamics of the network
represented by time-evolving social ties between pair of nodes. Experimental
results based on synthetic mobility models and real human traces show that
dLife has better delivery probability, latency, and cost than proposals based
on social structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8372</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8372</id><created>2014-07-31</created><authors><author><keyname>Moreira</keyname><forenames>Waldir</forenames></author><author><keyname>Mendes</keyname><forenames>Paulo</forenames></author><author><keyname>Sargento</keyname><forenames>Susana</forenames></author></authors><title>Assessment Model for Opportunistic Routing (LatinCom)</title><categories>cs.NI</categories><comments>6 pages, 2 figures, 2 tables</comments><doi>10.1109/LatinCOM.2011.6107393</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the increased capabilities of mobile devices and through wireless
opportunistic contacts, users can experience new ways to share and retrieve
content anywhere and anytime, even in the presence of link intermittency. Due
to the significant number of available routing solutions, it is difficult to
understand which one has the best performance, since all of them follow a
different evaluation method. This paper proposes an assessment model, based on
a new taxonomy, which comprises an evaluation guideline with performance
metrics and experimental setup to aid designers in evaluating solutions through
fair comparisons. Simulation results based on the proposed model revisit the
performance results published by Epidemic, PROPHET, and Bubble Rap, showing how
they perform under the same set of metrics and scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8373</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8373</id><created>2014-07-31</created><authors><author><keyname>Weller</keyname><forenames>Mathias</forenames></author></authors><title>Optimal Hub Labeling is NP-complete</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distance labeling is a preprocessing technique introduced by Peleg [Journal
of Graph Theory, 33(3)] to speed up distance queries in large networks. Herein,
each vertex receives a (short) label and, the distance between two vertices can
be inferred from their two labels. One such preprocessing problem occurs in the
hub labeling algorithm [Abraham et al., SODA'10]: the label of a vertex v is a
set of vertices x (the &quot;hubs&quot;) with their distance d(x,v) to v and the distance
between any two vertices u and v is the sum of their distances to a common hub.
The problem of assigning as few such hubs as possible was conjectured to be
NP-hard, but no proof was known to date. We give a reduction from the
well-known Vertex Cover problem on graphs to prove that finding an optimal hub
labeling is indeed NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8377</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8377</id><created>2014-07-31</created><authors><author><keyname>R.</keyname><forenames>Shashi Kumar N.</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>V</keyname><forenames>Suma</forenames></author></authors><title>SLI, a New Metric to determine Success of a Software Project</title><categories>cs.SE</categories><comments>5 pages, 4 tables, IEEE International Conference on Electronics and
  Communication Systems (ICECS)2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Project Management process plays a critical role in managing factors such as
cost, time, technology and personnel towards achieving the success of a project
and henceforth the sustainability of the company in the industrial market. This
paper emphasizes empirical study of several projects developed over a period of
time in a product and service based CMMI Level 5 Software Company. The
investigation shows impact analysis of resources such as cost, time, and number
of developers towards the successful completion of the project as allocated by
the project manager during the developmental process. The analysis has further
led to the introduction of a new qualitative metric, Success Level Index Metric
(SLI) whose index value varies from 0 to 1. SLI acts as a maturity indicator
that indicates the degree of maturity of the company in terms of success of
their projects based on which the company can choose their desired level of
success for their projects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8383</identifier>
 <datestamp>2015-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8383</id><created>2014-07-31</created><updated>2015-01-03</updated><authors><author><keyname>Briat</keyname><forenames>Corentin</forenames></author><author><keyname>Seuret</keyname><forenames>Alexandre</forenames></author></authors><title>On the necessity of looped-functionals arising in the analysis of
  pseudo-periodic, sampled-data and hybrid systems</title><categories>cs.SY math.CA math.DS math.OC</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Looped-functionals have been shown to be relevant for the analysis of a wide
variety of systems. However, the conditions obtained in previous works on the
analysis of sampled-data, impulsive and switched systems have only been shown
to be sufficient for the characterization of their associated discrete-time
stability conditions. We prove here that these conditions are also \necessary.
This result is derived for a wider class of linear systems, referred to as
impulsive pseudo-periodic systems, that encompass periodic, impulsive,
sampled-data and switched systems as special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8392</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8392</id><created>2014-07-31</created><authors><author><keyname>Sidhu</keyname><forenames>Gagan</forenames></author><author><keyname>Caffo</keyname><forenames>Brian</forenames></author></authors><title>MONEYBaRL: Exploiting pitcher decision-making using Reinforcement
  Learning</title><categories>cs.AI stat.AP</categories><comments>Published in at http://dx.doi.org/10.1214/13-AOAS712 the Annals of
  Applied Statistics (http://www.imstat.org/aoas/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOAS-AOAS712</report-no><journal-ref>Annals of Applied Statistics 2014, Vol. 8, No. 2, 926-955</journal-ref><doi>10.1214/13-AOAS712</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript uses machine learning techniques to exploit baseball
pitchers' decision making, so-called &quot;Baseball IQ,&quot; by modeling the at-bat
information, pitch selection and counts, as a Markov Decision Process (MDP).
Each state of the MDP models the pitcher's current pitch selection in a
Markovian fashion, conditional on the information immediately prior to making
the current pitch. This includes the count prior to the previous pitch, his
ensuing pitch selection, the batter's ensuing action and the result of the
pitch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8394</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8394</id><created>2014-07-31</created><authors><author><keyname>Pedroso</keyname><forenames>Jo&#xe3;o Pedro</forenames></author><author><keyname>Smeers</keyname><forenames>Yves</forenames></author></authors><title>Equilibria on a Game with Discrete Variables</title><categories>cs.GT</categories><comments>10 pages, Computability in Europe 2010</comments><msc-class>91-08</msc-class><acm-class>G.1.6; I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Equilibrium in Economics has been seldom addressed in a situation where some
variables are discrete. This work introduces a problem related to lot-sizing
with several players, and analyses some strategies which are likely to be found
in real world games. An illustration with a simple example is presented, with
concerns about the difficulty of the problem and computation possibilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8409</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8409</id><created>2014-07-31</created><updated>2014-08-19</updated><authors><author><keyname>Sima</keyname><forenames>Jin</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author></authors><title>Joint Network and Gelfand-Pinsker Coding for 3-Receiver Gaussian
  Broadcast Channels with Receiver Message Side Information</title><categories>cs.IT math.IT</categories><comments>Author's final version (presented at the 2014 IEEE International
  Symposium on Information Theory [ISIT 2014])</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of characterizing the capacity region for Gaussian broadcast
channels with receiver message side information appears difficult and remains
open for N &gt;= 3 receivers. This paper proposes a joint network and
Gelfand-Pinsker coding method for 3-receiver cases. Using the method, we
establish a unified inner bound on the capacity region of 3-receiver Gaussian
broadcast channels under general message side information configuration. The
achievability proof of the inner bound uses an idea of joint interference
cancelation, where interference is canceled by using both dirty-paper coding at
the encoder and successive decoding at some of the decoders. We show that the
inner bound is larger than that achieved by state of the art coding schemes. An
outer bound is also established and shown to be tight in 46 out of all 64
possible cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8411</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8411</id><created>2014-07-31</created><authors><author><keyname>Moreira</keyname><forenames>Waldir</forenames></author><author><keyname>Mendes</keyname><forenames>Paulo</forenames></author></authors><title>Social-aware Opportunistic Routing: The New Trend</title><categories>cs.NI</categories><comments>42 pages, 10 figures, 1 table</comments><doi>10.1007/978-1-4614-3514-3_2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since users move around based on social relationships and interests, the
resulting movement patterns can represent how nodes are socially connected
(i.e., nodes with strong social ties, nodes that meet occasionally by sharing
the same working environment). This means that social interactions reflect
personal relationships (e.g., family, friends, co-workers, passers-by) that may
be translated into statistical contact opportunities within and between social
groups over time. Such contact opportunities may be exploited to ensure good
data dissemination and retrieval, even in the presence of intermittent
connectivity. Thus, in the last years, a new trend based on social similarity
emerged where social relationships, interests, popularity and among others, are
used to improve opportunistic routing. In this chapter, the reader will learn
about the different approaches related to opportunistic routing focusing on the
social-aware approaches and how such approaches make use of social information
derived from opportunistic contacts to improve data forwarding. Additionally, a
brief overview on the existing taxonomies for opportunistic routing as well as
an updated one are provided along with a set of experiments in scenarios based
on synthetic mobility models and human traces in order to show the potential of
social-aware solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8422</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8422</id><created>2014-07-31</created><authors><author><keyname>Joseph</keyname><forenames>Jan Moritz</forenames></author><author><keyname>Claussen</keyname><forenames>Jens Christian</forenames></author></authors><title>A model for dynamical evolution of science in space</title><categories>physics.soc-ph cs.DL cs.SI nlin.AO</categories><comments>6 pages, 7 figures, comments and suggestions are welcome</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How does the topological space of science emerge? Inspired by the concept of
maps of science, i.e. mapping scientific topics to a scientific space, we ask
which topological structure a dynamical process of authors collaborating and
publishing papers can generate. We propose a dynamical process where papers as
well as new groups receive topical positions embedded in a two-dimensional
euclidean space. The precise position of new papers depends on previous topics
of the respective authors and is chosen randomly in a surrounding neighborhood
including novelty and interdisciplinarity. Depending on parameters, the spatial
structure resembles a simple Gaussian distribution, or spatial clusters of
side-topics are observed. We quantify the time-evolution of the spatial
structure and discuss the influence of inhomogenities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8427</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8427</id><created>2014-07-28</created><authors><author><keyname>Duncan</keyname><forenames>Ross</forenames><affiliation>University of Strathclyde, Glasgow, United Kingdom</affiliation></author><author><keyname>Panangaden</keyname><forenames>Prakash</forenames><affiliation>McGill University, Montreal, Canada</affiliation></author></authors><title>Proceedings 9th Workshop on Quantum Physics and Logic</title><categories>quant-ph cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 158, 2014</journal-ref><doi>10.4204/EPTCS.158</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the ninth workshop on Quantum Physics
and Logic (QPL2012) which took place in Brussels from the 10th to the 12th of
October 2012.
  QPL2012 brought together researchers working on mathematical foundations of
quantum physics, quantum computing, and spatio-temporal causal structures. The
particular focus was on the use of logical tools, ordered algebraic and
category-theoretic structures, formal languages, semantical techniques, and
other computer science methods for the study of physical behaviour in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8433</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8433</id><created>2014-07-31</created><authors><author><keyname>Bertrand</keyname><forenames>Pierre</forenames></author><author><keyname>Lenzen</keyname><forenames>Christoph</forenames></author></authors><title>The 1-2-3-Toolkit for Building Your Own Balls-into-Bins Algorithm</title><categories>cs.DC</categories><comments>brief announcement appears at DISC 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we examine a generic class of simple distributed
balls-into-bins algorithms. Exploiting the strong concentration bounds that
apply to balls-into-bins games, we provide an iterative method to compute
accurate estimates of the remaining balls and the load distribution after each
round. Each algorithm is classified by (i) the load that bins accept in a given
round, (ii) the number of messages each ball sends in a given round, and (iii)
whether each such message is given a rank expressing the sender's inclination
to commit to the receiving bin (if feasible). This novel ranking mechanism
results in notable improvements, in particular in the number of balls that may
commit to a bin in the first round of the algorithm. Simulations independently
verify the correctness of the results and confirm that our approximation is
highly accurate even for a moderate number of $10^6$ balls and bins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8463</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8463</id><created>2014-07-31</created><authors><author><keyname>Zhu</keyname><forenames>Jingge</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>Multiple Access via Compute-and-Forward</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lattice codes used under the Compute-and-Forward paradigm suggest an
alternative strategy for the standard Gaussian multiple-access channel (MAC):
The receiver successively decodes integer linear combinations of the messages
until it can invert and recover all messages. In this paper, this strategy is
developed and analyzed. For the two-user MAC, it is shown that without
time-sharing, the entire capacity region can be attained with a single-user
decoder as soon as the signal-to-noise ratios are above $1+\sqrt{2}$. A partial
analysis is given for more than two users. Lastly the strategy is extended to
the so-called dirty MAC where two interfering signals are known non-causally to
the two transmitters in a distributed fashion. Our scheme extends the
previously known results and gives new achievable rate regions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8469</identifier>
 <datestamp>2015-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8469</id><created>2014-07-31</created><updated>2015-02-25</updated><authors><author><keyname>Gomez</keyname><forenames>Gerardo</forenames></author><author><keyname>Lopez-Martinez</keyname><forenames>F. Javier</forenames></author><author><keyname>Morales-Jimenez</keyname><forenames>David</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author></authors><title>On the Equivalence between Interference and Eavesdropping in Wireless
  Communications</title><categories>cs.IT math.IT</categories><comments>This work has been accepted for publication at IEEE Transactions on
  Vehicular Technology. Copyright (c) 2014 IEEE. Personal use of this material
  is permitted. However, permission to use this material for any other purposes
  must be obtained from the IEEE by sending a request to
  pubs-permissions@ieee.org</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the problem of analyzing the outage probability in cellular
systems affected by co-channel interference and background noise is
mathematically equivalent to the problem of analyzing the wireless
information-theoretic security in terms of the maximum secrecy rate in fading
channels. Hence, these both apparently unrelated problems can be addressed by
using a common approach. We illustrate the applicability of the connection
unveiled herein to provide new results for the secrecy outage probability in
different scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8474</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8474</id><created>2014-07-31</created><authors><author><keyname>Bandyapadhyay</keyname><forenames>Sayan</forenames></author><author><keyname>Banik</keyname><forenames>Aritra</forenames></author><author><keyname>Das</keyname><forenames>Sandip</forenames></author><author><keyname>Sarkar</keyname><forenames>Hirak</forenames></author></authors><title>Voronoi Game on Graphs</title><categories>cs.DS cs.DM cs.GT</categories><comments>Journal preprint version, 18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  \textit{Voronoi game} is a geometric model of competitive facility location
problem played between two players. Users are generally modeled as points
uniformly distributed on a given underlying space. Each player chooses a set of
points in the underlying space to place their facilities. Each user avails
service from its nearest facility. Service zone of a facility consists of the
set of users which are closer to it than any other facility. Payoff of each
player is defined by the quantity of users served by all of its facilities. The
objective of each player is to maximize their respective payoff. In this paper
we consider the two players {\it Voronoi game} where the underlying space is a
road network modeled by a graph. In this framework we consider the problem of
finding $k$ optimal facility locations of Player 2 given any placement of $m$
facilities by Player 1. Our main result is a dynamic programming based
polynomial time algorithm for this problem on tree network. On the other hand,
we show that the problem is strongly $\mathcal{NP}$-complete for graphs. This
proves that finding a winning strategy of P2 is $\mathcal{NP}$-complete.
Consequently, we design an $1-\frac{1}{e}$ factor approximation algorithm,
where $e \approx 2.718$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8476</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8476</id><created>2014-07-31</created><updated>2014-08-06</updated><authors><author><keyname>Mukhopadhyay</keyname><forenames>Sabyasachi</forenames></author><author><keyname>Dash</keyname><forenames>Debadatta</forenames></author><author><keyname>Mitra</keyname><forenames>Asish</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Paritosh</forenames></author></authors><title>A comparative study between seasonal wind speed by Fourier and Wavelet
  analysis</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wind Energy is a useful resource for Renewable energy purpose. Wind speed
plays a vital role for wind energy calculation of certain location. So, it is
very much necessary to know the wind speed data characteristics. In this paper
fourier and wavelet transform are applied to study the wind speed data. We have
compared wind speed of winter with summer by taking their speed into account
using various discrete wavelets namely Haar and Daubechies-4 (Db-4). Also the
periodicity of wind speed is checked using Continuous Wavelet Transform (MCWT)
like Morlet. Thereafter a comparative study is done for detecting the
periodicity of both summer and winter. Then wavelet coherence is checked
between these two data for extracting the phase coherency information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8494</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8494</id><created>2014-07-31</created><authors><author><keyname>Yang</keyname><forenames>Jun</forenames></author><author><keyname>Kim</keyname><forenames>Il-Min</forenames></author><author><keyname>Kim</keyname><forenames>Dong In</forenames></author></authors><title>Joint Design of Optimal Cooperative Jamming and Power Allocation for
  Linear Precoding</title><categories>cs.IT math.IT</categories><comments>accepted by IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear precoding and cooperative jamming for multiuser broadcast channel is
studied to enhance the physical layer security. We consider the system where
multiple independent data streams are transmitted from the base station to
multiple legitimate users with the help of a friendly jammer. It is assumed
that a normalized linear precoding matrix is given at the base station, whereas
the power allocated to each user is to be determined. The problem is to jointly
design the power allocation across different users for linear precoding and the
cooperative jamming at the friendly jammer. The goal is to maximize a lower
bound of the secrecy rate, provided that a minimum communication rate to the
users is guaranteed. The optimal solution is obtained when the number of
antennas at the friendly jammer is no less than the total number of antennas at
the users and eavesdropper. Moreover, a suboptimal algorithm is proposed, which
can be applied for all the scenarios. Numerical results demonstrate that the
proposed schemes are effective for secure communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8497</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8497</id><created>2014-07-31</created><authors><author><keyname>Farag</keyname><forenames>Amal</forenames></author><author><keyname>Lu</keyname><forenames>Le</forenames></author><author><keyname>Turkbey</keyname><forenames>Evrim</forenames></author><author><keyname>Liu</keyname><forenames>Jiamin</forenames></author><author><keyname>Summers</keyname><forenames>Ronald M.</forenames></author></authors><title>A Bottom-Up Approach for Automatic Pancreas Segmentation in Abdominal CT
  Scans</title><categories>cs.CV</categories><comments>Abdominal Workshop in Conjunction with MICCAI 2014</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Organ segmentation is a prerequisite for a computer-aided diagnosis (CAD)
system to detect pathologies and perform quantitative analysis. For
anatomically high-variability abdominal organs such as the pancreas, previous
segmentation works report low accuracies when comparing to organs like the
heart or liver. In this paper, a fully-automated bottom-up method is presented
for pancreas segmentation, using abdominal computed tomography (CT) scans. The
method is based on a hierarchical two-tiered information propagation by
classifying image patches. It labels superpixels as pancreas or not via pooling
patch-level confidences on 2D CT slices over-segmented by the Simple Linear
Iterative Clustering approach. A supervised random forest (RF) classifier is
trained on the patch level and a two-level cascade of RFs is applied at the
superpixel level, coupled with multi-channel feature extraction, respectively.
On six-fold cross-validation using 80 patient CT volumes, we achieved 68.8%
Dice coefficient and 57.2% Jaccard Index, comparable to or slightly better than
published state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8498</identifier>
 <datestamp>2014-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8498</id><created>2014-07-31</created><updated>2014-11-06</updated><authors><author><keyname>Aguglia</keyname><forenames>Angela</forenames></author><author><keyname>Giuzzi</keyname><forenames>Luca</forenames></author></authors><title>Intersections of the Hermitian Surface with irreducible Quadrics in even
  Characteristic</title><categories>math.CO cs.DM math.AG</categories><comments>15 pages; revised version. This paper extends the results of
  arXiv:1307.8386 to the case q even</comments><msc-class>05B25, 51D20, 51E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We determine the possible intersection sizes of a Hermitian surface $\mathcal
H$ with an irreducible quadric of ${\mathrm PG}(3,q^2)$ sharing at least a
tangent plane at a common non-singular point when $q$ is even.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8499</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8499</id><created>2014-07-31</created><authors><author><keyname>Nagpal</keyname><forenames>Chirag</forenames></author><author><keyname>Singhal</keyname><forenames>Khushboo</forenames></author></authors><title>Twitter User Classification using Ambient Metadata</title><categories>cs.SI cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Microblogging websites, especially Twitter have become an important means of
communication, in today's time. Often these services have been found to be
faster than conventional news services. With millions of users, a need was felt
to classify users based on ambient metadata associated with their user
accounts. We particularly look at the effectiveness of the profile description
field in order to carry out the task of user classification. Our results show
that such metadata can be an effective feature for any classification task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8508</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8508</id><created>2014-07-30</created><authors><author><keyname>Serra</keyname><forenames>Roberto</forenames></author><author><keyname>Filisetti</keyname><forenames>Alessandro</forenames></author><author><keyname>Villani</keyname><forenames>Marco</forenames></author><author><keyname>Graudenzi</keyname><forenames>Alex</forenames></author><author><keyname>Damiani</keyname><forenames>Chiara</forenames></author><author><keyname>Panini</keyname><forenames>Tommaso</forenames></author></authors><title>A stochastic model of catalytic reaction networks in protocells</title><categories>q-bio.MN cs.CE math.DS nlin.AO</categories><comments>20 pages, 5 figures</comments><doi>10.1007/s11047-014-9445-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protocells are supposed to have played a key role in the self-organizing
processes leading to the emergence of life. Existing models either (i) describe
protocell architecture and dynamics, given the existence of sets of
collectively self-replicating molecules for granted, or (ii) describe the
emergence of the aforementioned sets from an ensemble of random molecules in a
simple experimental setting (e.g. a closed system or a steady-state flow
reactor) that does not properly describe a protocell. In this paper we present
a model that goes beyond these limitations by describing the dynamics of sets
of replicating molecules within a lipid vesicle. We adopt the simplest possible
protocell architecture, by considering a semi-permeable membrane that selects
the molecular types that are allowed to enter or exit the protocell and by
assuming that the reactions take place in the aqueous phase in the internal
compartment. As a first approximation, we ignore the protocell growth and
division dynamics. The behavior of catalytic reaction networks is then
simulated by means of a stochastic model that accounts for the creation and the
extinction of species and reactions. While this is not yet an exhaustive
protocell model, it already provides clues regarding some processes that are
relevant for understanding the conditions that can enable a population of
protocells to undergo evolution and selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8509</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8509</id><created>2014-07-30</created><authors><author><keyname>Alippi</keyname><forenames>Cesare</forenames></author><author><keyname>Bocca</keyname><forenames>Maurizio</forenames></author><author><keyname>Boracchi</keyname><forenames>Giacomo</forenames></author><author><keyname>Patwari</keyname><forenames>Neal</forenames></author><author><keyname>Roveri</keyname><forenames>Manuel</forenames></author></authors><title>RTI Goes Wild: Radio Tomographic Imaging for Outdoor People Detection
  and Localization</title><categories>cs.NI cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RF sensor networks are used to localize people indoor without requiring them
to wear invasive electronic devices. These wireless mesh networks, formed by
low-power radio transceivers, continuously measure the received signal strength
(RSS) of the links. Radio Tomographic Imaging (RTI) is a technique that
generates 2D images of the change in the electromagnetic field inside the area
covered by the radio transceivers to spot the presence and movements of
animates (e.g., people, large animals) or large metallic objects (e.g., cars).
Here, we present a RTI system for localizing and tracking people outdoors.
Differently than in indoor environments where the RSS does not change
significantly with time unless people are found in the monitored area, the
outdoor RSS signal is time-variant, e.g., due to rainfalls or wind-driven
foliage. We present a novel outdoor RTI method that, despite the nonstationary
noise introduced in the RSS data by the environment, achieves high localization
accuracy and dramatically reduces the energy consumption of the sensing units.
Experimental results demonstrate that the system accurately detects and tracks
a person in real-time in a large forested area under varying environmental
conditions, significantly reducing false positives, localization error and
energy consumption compared to state-of-the-art RTI methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8510</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8510</id><created>2014-07-30</created><updated>2014-08-14</updated><authors><author><keyname>Khawar</keyname><forenames>Awais</forenames></author><author><keyname>Abdelhadi</keyname><forenames>Ahmed</forenames></author><author><keyname>Clancy</keyname><forenames>T. Charles</forenames></author></authors><title>QPSK Waveform for MIMO Radar with Spectrum Sharing Constraints</title><categories>cs.NI cs.IT math.IT</categories><comments>submitted to IEEE Transactions. Distribution Statement A: Approved
  for public release; distribution is unlimited</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple-input multiple-output (MIMO) radar is a relatively new concept in
the field of radar signal processing. Many novel MIMO radar waveforms have been
developed by considering various performance metrics and constraints. In this
paper, we show that finite alphabet constant-envelope (FACE) quadrature-pulse
shift keying (QPSK) waveforms can be designed to realize a given covariance
matrix by transforming a constrained nonlinear optimization problem into an
unconstrained nonlinear optimization problem. In addition, we design QPSK
waveforms in a way that they don't cause interference to a cellular system, by
steering nulls towards a selected base station (BS). The BS is selected
according to our algorithm which guarantees minimum degradation in radar
performance due to null space projection (NSP) of radar waveforms. We design
QPSK waveforms with spectrum sharing constraints for a stationary and moving
radar platform. We show that the waveform designed for stationary MIMO radar
matches the desired beampattern closely, when the number of BS antennas
$N^{\text{BS}}$ is considerably less than the number of radar antennas $M$, due
to quasi-static interference channel. However, for moving radar the difference
between designed and desired waveforms is larger than stationary radar, due to
rapidly changing channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8513</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8513</id><created>2014-07-31</created><authors><author><keyname>Min</keyname><forenames>Byungjoon</forenames></author><author><keyname>Lee</keyname><forenames>Sangchul</forenames></author><author><keyname>Lee</keyname><forenames>Kyu-Min</forenames></author><author><keyname>Goh</keyname><forenames>K. -I.</forenames></author></authors><title>Link overlap, viability, and mutual percolation in multiplex networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>10 pages, 9 figures</comments><doi>10.1016/j.chaos.2014.12.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world complex systems are best modeled by multiplex networks. The
multiplexity has proved to have broad impact on the system's structure and
function. Most theoretical studies on multiplex networks to date, however, have
largely ignored the effect of link overlap across layers despite strong
empirical evidences for its significance. In this article, we investigate the
effect of link overlap in the viability of multiplex networks, both
analytically and numerically. Distinctive role of overlapping links in
viability and mutual connectivity is emphasized and exploited for setting up
proper analytic framework. A rich phase diagram for viability is obtained and
greatly diversified patterns of hysteretic behavior in viability are observed
in the presence of link overlap. Mutual percolation with link overlap is
revisited as a limit of multiplex viability problem, and controversy between
existing results is clarified. The distinctive role of overlapping links is
further demonstrated by the different responses of networks under random
removals of overlapping and non-overlapping links, respectively, as well as
under several removal strategies. Our results show that the link overlap
strongly facilitates viability and mutual percolation; at the same time, the
presence of link overlap poses challenge in analytical approach to the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8515</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8515</id><created>2014-07-29</created><authors><author><keyname>Patil</keyname><forenames>Suryakant B.</forenames></author><author><keyname>Suryawanshi</keyname><forenames>Vijay S.</forenames></author><author><keyname>Suryawanshi</keyname><forenames>Dipali V.</forenames></author><author><keyname>Patil</keyname><forenames>Preeti</forenames></author></authors><title>Integrated ERP System for Improving the Functional efficiency of the
  organization by Customized Architecture</title><categories>cs.DB</categories><comments>9 Pages; IJCEA 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An ERP is a kind of package which consist front end and backend as DBMS like
a collection of DBMSs. You can create DBMS to manage one aspect of your
business. For example, a publishing house has a database of books that keeps
information about books such as Author Name, Title, Translator Name, etc. But
this database app only helps enter books data and search them. It doesn't help
them, for example, sell books. They get or develop another DBMS database that
has all the Books data plus prices, discount formulas, names of common clients,
etc. Now they connect the Books database to Sales database and maybe also the
inventory database. Now its DBMS slowly turning into an ERP. They may add
payroll database and connect it to this ERP. They may develop sales staff and
commissions database and connect it to this ERP and so on. In the traditional
Database management system the different databases are used for the various
Campuses of the JSPM Group of Education like Wagholi Campus, Tathwade Campus,
Narhe Campus, Hadpsar Campuses, Bhavdhan Campus as well as Corporate office at
Katraj of same organization so it is not possible to keep different databases
for the same so in this paper proposed the use of Integrated Database for the
Entire organization using ERP system. The Proposed ERP system applied on the
existing Architecture of the JSPM Group; the marginal difference observed in
the Databases need to be accessed to generate the same number of Reports when
use the Traditional DBMS which end up with improvement in the Functional
efficiency of Organizational Architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8518</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8518</id><created>2014-07-28</created><authors><author><keyname>Rigamonti</keyname><forenames>Roberto</forenames></author><author><keyname>Lepetit</keyname><forenames>Vincent</forenames></author><author><keyname>Fua</keyname><forenames>Pascal</forenames></author></authors><title>Beyond KernelBoost</title><categories>cs.CV cs.LG</categories><report-no>EPFL-REPORT-200378</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this Technical Report we propose a set of improvements with respect to the
KernelBoost classifier presented in [Becker et al., MICCAI 2013]. We start with
a scheme inspired by Auto-Context, but that is suitable in situations where the
lack of large training sets poses a potential problem of overfitting. The aim
is to capture the interactions between neighboring image pixels to better
regularize the boundaries of segmented regions. As in Auto-Context [Tu et al.,
PAMI 2009] the segmentation process is iterative and, at each iteration, the
segmentation results for the previous iterations are taken into account in
conjunction with the image itself. However, unlike in [Tu et al., PAMI 2009],
we organize our recursion so that the classifiers can progressively focus on
difficult-to-classify locations. This lets us exploit the power of the
decision-tree paradigm while avoiding over-fitting. In the context of this
architecture, KernelBoost represents a powerful building block due to its
ability to learn on the score maps coming from previous iterations. We first
introduce two important mechanisms to empower the KernelBoost classifier,
namely pooling and the clustering of positive samples based on the appearance
of the corresponding ground-truth. These operations significantly contribute to
increase the effectiveness of the system on biomedical images, where texture
plays a major role in the recognition of the different image components. We
then present some other techniques that can be easily integrated in the
KernelBoost framework to further improve the accuracy of the final
segmentation. We show extensive results on different medical image datasets,
including some multi-label tasks, on which our method is shown to outperform
state-of-the-art approaches. The resulting segmentations display high accuracy,
neat contours, and reduced noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8535</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8535</id><created>2014-07-31</created><authors><author><keyname>Bousquet</keyname><forenames>Nicolas</forenames></author><author><keyname>Norin</keyname><forenames>Sergey</forenames></author><author><keyname>Vetta</keyname><forenames>Adrian</forenames></author></authors><title>A Near-Optimal Mechanism for Impartial Selection</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine strategy-proof elections to select a winner amongst a set of
agents, each of whom cares only about winning. This impartial selection problem
was introduced independently by Holzman and Moulin and Alon et al. Fisher and
Klimm showed that the permutation mechanism is impartial and $1/2$-optimal,
that is, it selects an agent who gains, in expectation, at least half the
number of votes of most popular agent. Furthermore, they showed the mechanism
is $7/12$-optimal if agents cannot abstain in the election. We show that a
better guarantee is possible, provided the most popular agent receives at least
a large enough, but constant, number of votes. Specifically, we prove that, for
any $\epsilon&gt;0$, there is a constant $N_{\epsilon}$ (independent of the number
$n$ of voters) such that, if the maximum number of votes of the most popular
agent is at least $N_{\epsilon}$ then the permutation mechanism is
$(\frac{3}{4}-\epsilon)$-optimal. This result is tight.
  Furthermore, in our main result, we prove that near-optimal impartial
mechanisms exist. In particular, there is an impartial mechanism that is
$(1-\epsilon)$-optimal, for any $\epsilon&gt;0$, provided that the maximum number
of votes of the most popular agent is at least a constant $M_{\epsilon}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8540</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8540</id><created>2014-07-31</created><authors><author><keyname>Winterrose</keyname><forenames>M. L.</forenames></author><author><keyname>Carter</keyname><forenames>K. M.</forenames></author><author><keyname>Wagner</keyname><forenames>N.</forenames></author><author><keyname>Streilein</keyname><forenames>W. W.</forenames></author></authors><title>Adaptive Attacker Strategy Development Against Moving Target Cyber
  Defenses</title><categories>cs.CR cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model of strategy formulation is used to study how an adaptive attacker
learns to overcome a moving target cyber defense. The attacker-defender
interaction is modeled as a game in which a defender deploys a temporal
platform migration defense. Against this defense, a population of attackers
develop strategies specifying the temporal ordering of resource investments
that bring targeted zero-day exploits into existence. Attacker response to two
defender temporal platform migration scheduling policies are examined. In the
first defender scheduling policy, the defender selects the active platform in
each match uniformly at random from a pool of available platforms. In the
second policy the defender schedules each successive platform to maximize the
diversity of the source code presented to the attacker. Adaptive attacker
response strategies are modeled by finite state machine (FSM) constructs that
evolve during simulated play against defender strategies via an evolutionary
algorithm. It is demonstrated that the attacker learns to invest heavily in
exploit creation for the platform with the least similarity to other platforms
when faced with a diversity defense, while avoiding investment in exploits for
this least similar platform when facing a randomization defense. Additionally,
it is demonstrated that the diversity-maximizing defense is superior for
shorter duration attacker-defender engagements, but performs sub-optimally in
extended attacker-defender interactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1407.8546</identifier>
 <datestamp>2014-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1407.8546</id><created>2014-07-31</created><authors><author><keyname>Campos</keyname><forenames>Filipe</forenames></author><author><keyname>Pereira</keyname><forenames>Jos&#xe9;</forenames></author></authors><title>Improving the Scalability of DPWS-Based Networked Infrastructures</title><categories>cs.DC cs.NI</categories><comments>28 pages, Technical Report</comments><acm-class>C.2.4; D.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Devices Profile for Web Services (DPWS) specification enables seamless
discovery, configuration, and interoperability of networked devices in various
settings, ranging from home automation and multimedia to manufacturing
equipment and data centers. Unfortunately, the sheer simplicity of event
notification mechanisms that makes it fit for resource-constrained devices,
makes it hard to scale to large infrastructures with more stringent
dependability requirements, ironically, where self-configuration would be most
useful. In this report, we address this challenge with a proposal to integrate
gossip-based dissemination in DPWS, thus maintaining compatibility with
original assumptions of the specification, and avoiding a centralized
configuration server or custom black-box middleware components. In detail, we
show how our approach provides an evolutionary and non-intrusive solution to
the scalability limitations of DPWS and experimentally evaluate it with an
implementation based on the the Web Services for Devices (WS4D) Java Multi
Edition DPWS Stack (JMEDS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0016</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0016</id><created>2014-06-26</created><authors><author><keyname>Guy</keyname><forenames>Stephen</forenames></author><author><keyname>Schwitter</keyname><forenames>Rolf</forenames></author></authors><title>Architecture of a Web-based Predictive Editor for Controlled Natural
  Language Processing</title><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe the architecture of a web-based predictive text
editor being developed for the controlled natural language PENG$^{ASP)$. This
controlled language can be used to write non-monotonic specifications that have
the same expressive power as Answer Set Programs. In order to support the
writing process of these specifications, the predictive text editor
communicates asynchronously with the controlled natural language processor that
generates lookahead categories and additional auxiliary information for the
author of a specification text. The text editor can display multiple sets of
lookahead categories simultaneously for different possible sentence
completions, anaphoric expressions, and supports the addition of new content
words to the lexicon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0017</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0017</id><created>2014-07-31</created><authors><author><keyname>Krichene</keyname><forenames>Walid</forenames></author><author><keyname>Drigh&#xe8;s</keyname><forenames>Benjamin</forenames></author><author><keyname>Bayen</keyname><forenames>Alexandre M.</forenames></author></authors><title>Learning Nash Equilibria in Congestion Games</title><categories>cs.LG cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the repeated congestion game, in which multiple populations of
players share resources, and make, at each iteration, a decentralized decision
on which resources to utilize. We investigate the following question: given a
model of how individual players update their strategies, does the resulting
dynamics of strategy profiles converge to the set of Nash equilibria of the
one-shot game? We consider in particular a model in which players update their
strategies using algorithms with sublinear discounted regret. We show that the
resulting sequence of strategy profiles converges to the set of Nash equilibria
in the sense of Ces\`aro means. However, strong convergence is not guaranteed
in general. We show that strong convergence can be guaranteed for a class of
algorithms with a vanishing upper bound on discounted regret, and which satisfy
an additional condition. We call such algorithms AREP algorithms, for
Approximate REPlicator, as they can be interpreted as a discrete-time
approximation of the replicator equation, which models the continuous-time
evolution of population strategies, and which is known to converge for the
class of congestion games. In particular, we show that the discounted Hedge
algorithm belongs to the AREP class, which guarantees its strong convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0023</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0023</id><created>2014-07-31</created><authors><author><keyname>Winterrose</keyname><forenames>Michael L.</forenames></author><author><keyname>Carter</keyname><forenames>Kevin M.</forenames></author></authors><title>Strategic Evolution of Adversaries Against Temporal Platform Diversity
  Active Cyber Defenses</title><categories>cs.CR cs.GT</categories><journal-ref>Proceedings of the Agent-Directed Simulation Symposium at the
  Spring Simulation Multiconference (2014): 68-76</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial dynamics are a critical facet within the cyber security domain,
in which there exists a co-evolution between attackers and defenders in any
given threat scenario. While defenders leverage capabilities to minimize the
potential impact of an attack, the adversary is simultaneously developing
countermeasures to the observed defenses. In this study, we develop a set of
tools to model the adaptive strategy formulation of an intelligent actor
against an active cyber defensive system. We encode strategies as binary
chromosomes representing finite state machines that evolve according to
Holland's genetic algorithm. We study the strategic considerations including
overall actor reward balanced against the complexity of the determined
strategies. We present a series of simulation results demonstrating the ability
to automatically search a large strategy space for optimal resultant fitness
against a variety of counter-strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0032</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0032</id><created>2014-07-31</created><updated>2015-03-14</updated><authors><author><keyname>G&#xe9;vay</keyname><forenames>G&#xe1;bor E.</forenames></author><author><keyname>Danner</keyname><forenames>G&#xe1;bor</forenames></author></authors><title>Calculating Ultra-Strong and Extended Solutions for Nine Men's Morris,
  Morabaraba, and Lasker</title><categories>cs.AI</categories><comments>(c) 2015 IEEE. Personal use of this material is permitted. Permission
  from IEEE must be obtained for all other users, including
  reprinting/republishing this material for advertising or promotional
  purposes, creating new collective works for resale or redistribution to
  servers or lists, or reuse of any copyrighted components of this work in
  other works</comments><acm-class>I.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The strong solutions of Nine Men's Morris and its variant, Lasker Morris are
well-known results (the starting positions are draws). We re-examined both of
these games, and calculated extended strong solutions for them. By this we mean
the game-theoretic values of all possible game states that could be reached
from certain starting positions where the number of stones to be placed by the
players is different from the standard rules. These were also calculated for a
previously unsolved third variant, Morabaraba, with interesting results: most
of the starting positions where the players can place an equal number of stones
(including the standard starting position) are wins for the first player (as
opposed to the above games, where these are usually draws).
  We also developed a multi-valued retrograde analysis, and used it as a basis
for an algorithm for solving these games ultra-strongly. This means that when
our program is playing against a fallible opponent, it has a greater chance of
achieving a better result than the game-theoretic value, compared to randomly
selecting between &quot;just strongly&quot; optimal moves. Previous attempts on
ultra-strong solutions used local heuristics or learning during games, but we
incorporated our algorithm into the retrograde analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0034</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0034</id><created>2014-07-31</created><authors><author><keyname>Pedarsani</keyname><forenames>Ramtin</forenames></author><author><keyname>Lee</keyname><forenames>Kangwook</forenames></author><author><keyname>Ramchandran</keyname><forenames>Kannan</forenames></author></authors><title>PhaseCode: Fast and Efficient Compressive Phase Retrieval based on
  Sparse-Graph-Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recovering a complex signal $x$ from $m$ intensity
measurements. We address multiple settings corresponding to whether the
measurement vectors are unconstrained choices or not, and to whether the signal
to be recovered is sparse or not. However, our main focus is on the case where
the measurement vectors are unconstrained, and where $x$ is exactly $K$-sparse,
or the so-called general compressive phase-retrieval problem. We introduce
PhaseCode, a novel family of fast and efficient merge-and-color algorithms that
are based on a sparse-graph-codes framework. As one instance, our PhaseCode
algorithm can provably recover, with high probability, all but a tiny $10^{-7}$
fraction of the significant signal components, using at most $m=14K$
measurements, which is a small constant factor from the fundamental limit, with
an optimal $O(K)$ decoding time and an optimal $O(K)$ memory complexity. Next,
motivated by some important practical classes of optical systems, we consider a
Fourier-friendly constrained measurement setting, and show that its performance
matches that of the unconstrained setting. In the Fourier-friendly setting that
we consider, the measurement matrix is constrained to be a cascade of Fourier
matrices and diagonal matrices. We also study the general non-sparse signal
case, for which we propose a simple deterministic set of $3n-2$ measurements
that can recover the n-length signal under some mild assumptions. Throughout,
we provide extensive simulation results that validate the practical power of
our proposed algorithms for the sparse unconstrained and Fourier-friendly
measurement settings, for noiseless and noisy scenarios. A key contribution of
our work is the novel use of coding-theoretic tools like density evolution
methods for the design and analysis of fast and efficient algorithms for
compressive phase-retrieval problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0043</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0043</id><created>2014-07-31</created><authors><author><keyname>Tran</keyname><forenames>Truyen</forenames></author><author><keyname>Phung</keyname><forenames>Dinh</forenames></author><author><keyname>Venkatesh</keyname><forenames>Svetha</forenames></author></authors><title>Learning From Ordered Sets and Applications in Collaborative Ranking</title><categories>cs.LG cs.IR stat.ML</categories><comments>JMLR: Workshop and Conference Proceedings 25:1-16, 2012, Asian
  Conference on Machine Learning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ranking over sets arise when users choose between groups of items. For
example, a group may be of those movies deemed $5$ stars to them, or a
customized tour package. It turns out, to model this data type properly, we
need to investigate the general combinatorics problem of partitioning a set and
ordering the subsets. Here we construct a probabilistic log-linear model over a
set of ordered subsets. Inference in this combinatorial space is highly
challenging: The space size approaches $(N!/2)6.93145^{N+1}$ as $N$ approaches
infinity. We propose a \texttt{split-and-merge} Metropolis-Hastings procedure
that can explore the state-space efficiently. For discovering hidden aspects in
the data, we enrich the model with latent binary variables so that the
posteriors can be efficiently evaluated. Finally, we evaluate the proposed
model on large-scale collaborative filtering tasks and demonstrate that it is
competitive against state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0045</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0045</id><created>2014-07-31</created><authors><author><keyname>Dokhanchi</keyname><forenames>Adel</forenames></author><author><keyname>Hoxha</keyname><forenames>Bardh</forenames></author><author><keyname>Fainekos</keyname><forenames>Georgios</forenames></author></authors><title>On-Line Monitoring for Temporal Logic Robustness</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide a Dynamic Programming algorithm for on-line
monitoring of the state robustness of Metric Temporal Logic specifications with
past time operators. We compute the robustness of MTL with unbounded past and
bounded future temporal operators MTL over sampled traces of Cyber-Physical
Systems. We implemented our tool in Matlab as a Simulink block that can be used
in any Simulink model. We experimentally demonstrate that the overhead of the
MTL robustness monitoring is acceptable for certain classes of practical
specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0047</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0047</id><created>2014-07-31</created><authors><author><keyname>Tran</keyname><forenames>Truyen</forenames></author><author><keyname>Phung</keyname><forenames>Dinh</forenames></author><author><keyname>Venkatesh</keyname><forenames>Svetha</forenames></author></authors><title>Cumulative Restricted Boltzmann Machines for Ordinal Matrix Data
  Analysis</title><categories>stat.ML cs.IR cs.LG stat.AP stat.ME</categories><comments>JMLR: Workshop and Conference Proceedings 25:1-16, 2012; Asian
  Conference on Machine Learning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ordinal data is omnipresent in almost all multiuser-generated feedback -
questionnaires, preferences etc. This paper investigates modelling of ordinal
data with Gaussian restricted Boltzmann machines (RBMs). In particular, we
present the model architecture, learning and inference procedures for both
vector-variate and matrix-variate ordinal data. We show that our model is able
to capture latent opinion profile of citizens around the world, and is
competitive against state-of-art collaborative filtering techniques on
large-scale public datasets. The model thus has the potential to extend
application of RBMs to diverse domains such as recommendation systems, product
reviews and expert assessments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0049</identifier>
 <datestamp>2014-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0049</id><created>2014-07-31</created><authors><author><keyname>Coecke</keyname><forenames>Bob</forenames><affiliation>University of Oxford, Department of Computer Science</affiliation></author><author><keyname>Heunen</keyname><forenames>Chris</forenames><affiliation>University of Oxford, Department of Computer Science</affiliation></author><author><keyname>Kissinger</keyname><forenames>Aleks</forenames><affiliation>University of Oxford, Department of Computer Science</affiliation></author></authors><title>Categories of Quantum and Classical Channels (extended abstract)</title><categories>cs.LO math.CT</categories><comments>In Proceedings QPL 2012, arXiv:1407.8427</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 158, 2014, pp. 1-14</journal-ref><doi>10.4204/EPTCS.158.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the CP*-construction on a dagger compact closed category as a
generalisation of Selinger's CPM-construction. While the latter takes a dagger
compact closed category and forms its category of &quot;abstract matrix algebras&quot;
and completely positive maps, the CP*-construction forms its category of
&quot;abstract C*-algebras&quot; and completely positive maps. This analogy is justified
by the case of finite-dimensional Hilbert spaces, where the CP*-construction
yields the category of finite-dimensional C*-algebras and completely positive
maps.
  The CP*-construction fully embeds Selinger's CPM-construction in such a way
that the objects in the image of the embedding can be thought of as &quot;purely
quantum&quot; state spaces. It also embeds the category of classical stochastic
maps, whose image consists of &quot;purely classical&quot; state spaces. By allowing
classical and quantum data to coexist, this provides elegant abstract notions
of preparation, measurement, and more general quantum channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0050</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0050</id><created>2014-07-31</created><authors><author><keyname>Roumen</keyname><forenames>Frank</forenames><affiliation>Radboud University Nijmegen</affiliation></author></authors><title>Coalgebraic Quantum Computation</title><categories>cs.LO math.CT</categories><comments>In Proceedings QPL 2012, arXiv:1407.8427</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 158, 2014, pp. 29-38</journal-ref><doi>10.4204/EPTCS.158.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coalgebras generalize various kinds of dynamical systems occuring in
mathematics and computer science. Examples of systems that can be modeled as
coalgebras include automata and Markov chains. We will present a coalgebraic
representation of systems occuring in the field of quantum computation, using
convex sets of density matrices as state spaces. This will allow us to derive a
method to convert quantum mechanical systems into simpler probabilistic systems
with the same probabilistic behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0051</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0051</id><created>2014-07-31</created><authors><author><keyname>Barr</keyname><forenames>Katie</forenames><affiliation>University of Leeds</affiliation></author><author><keyname>Kendon</keyname><forenames>Viv</forenames><affiliation>University of Leeds</affiliation></author></authors><title>The expressive power of quantum walks in terms of language acceptance</title><categories>cs.FL cs.ET quant-ph</categories><comments>In Proceedings QPL 2012, arXiv:1407.8427</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 158, 2014, pp. 39-51</journal-ref><doi>10.4204/EPTCS.158.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete time quantum walks are known to be universal for quantum
computation. This has been proven by showing that they can simulate a universal
quantum gate set. In this paper, we examine computation by quantum walks in
terms of language acceptance, and present two ways in which discrete time
quantum walks can accept some languages with certainty. These walks can take
quantum as well as classical inputs, and we show that when the input is
quantum, the walks can also be interpreted as performing the task of quantum
state discrimination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0052</identifier>
 <datestamp>2014-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0052</id><created>2014-07-31</created><authors><author><keyname>Hermens</keyname><forenames>Ronnie</forenames><affiliation>University of Groningen</affiliation></author></authors><title>Speakable in quantum mechanics: babbling on</title><categories>cs.LO quant-ph</categories><comments>In Proceedings QPL 2012, arXiv:1407.8427</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 158, 2014, pp. 53-64</journal-ref><doi>10.4204/EPTCS.158.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper consists of a short version of the derivation of the
intuitionistic quantum logic L_QM (which was originally introduced by Caspers,
Heunen, Landsman and Spitters). The elaboration consists of extending this
logic to a classical logic CL_QM. Some first steps are then taken towards
setting up a probabilistic framework based on CL_QM in terms of R\'enyi's
conditional probability spaces. Comparisons are then made with the traditional
framework for quantum probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0053</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0053</id><created>2014-07-31</created><authors><author><keyname>Bernardinello</keyname><forenames>Luca</forenames><affiliation>Universit&#xe0; degli studi di Milano-Bicocca</affiliation></author><author><keyname>Ferigato</keyname><forenames>Carlo</forenames><affiliation>Joint Research Centre of the European Commission</affiliation></author><author><keyname>Pomello</keyname><forenames>Lucia</forenames><affiliation>Universit&#xe0; degli studi di Milano-Bicocca</affiliation></author></authors><title>Between quantum logic and concurrency</title><categories>cs.LO cs.DM</categories><comments>In Proceedings QPL 2012, arXiv:1407.8427</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 158, 2014, pp. 65-75</journal-ref><doi>10.4204/EPTCS.158.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We start from two closure operators defined on the elements of a special kind
of partially ordered sets, called causal nets. Causal nets are used to model
histories of concurrent processes, recording occurrences of local states and of
events. If every maximal chain (line) of such a partially ordered set meets
every maximal antichain (cut), then the two closure operators coincide, and
generate a complete orthomodular lattice. In this paper we recall that, for any
closed set in this lattice, every line meets either it or its orthocomplement
in the lattice, and show that to any line, a two-valued state on the lattice
can be associated. Starting from this result, we delineate a logical language
whose formulas are interpreted over closed sets of a causal net, where every
line induces an assignment of truth values to formulas. The resulting logic is
non-classical; we show that maximal antichains in a causal net are associated
to Boolean (hence &quot;classical&quot;) substructures of the overall quantum logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0054</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0054</id><created>2014-07-31</created><authors><author><keyname>Schreiber</keyname><forenames>Urs</forenames><affiliation>Radboud University Nijmegen</affiliation></author><author><keyname>Shulman</keyname><forenames>Michael</forenames><affiliation>University of San Diego</affiliation></author></authors><title>Quantum Gauge Field Theory in Cohesive Homotopy Type Theory</title><categories>math-ph cs.LO math.CT math.MP</categories><comments>In Proceedings QPL 2012, arXiv:1407.8427</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 158, 2014, pp. 109-126</journal-ref><doi>10.4204/EPTCS.158.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We implement in the formal language of homotopy type theory a new set of
axioms called cohesion. Then we indicate how the resulting cohesive homotopy
type theory naturally serves as a formal foundation for central concepts in
quantum gauge field theory. This is a brief survey of work by the authors
developed in detail elsewhere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0055</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0055</id><created>2014-07-31</created><authors><author><keyname>Tran</keyname><forenames>Truyen</forenames></author><author><keyname>Phung</keyname><forenames>Dinh</forenames></author><author><keyname>Venkatesh</keyname><forenames>Svetha</forenames></author></authors><title>Thurstonian Boltzmann Machines: Learning from Multiple Inequalities</title><categories>stat.ML cs.LG stat.ME</categories><comments>Proceedings of the 30 th International Conference on Machine
  Learning, Atlanta, Georgia, USA, 2013. JMLR: W&amp;CP volume 28</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Thurstonian Boltzmann Machines (TBM), a unified architecture
that can naturally incorporate a wide range of data inputs at the same time.
Our motivation rests in the Thurstonian view that many discrete data types can
be considered as being generated from a subset of underlying latent continuous
variables, and in the observation that each realisation of a discrete type
imposes certain inequalities on those variables. Thus learning and inference in
TBM reduce to making sense of a set of inequalities. Our proposed TBM naturally
supports the following types: Gaussian, intervals, censored, binary,
categorical, muticategorical, ordinal, (in)-complete rank with and without
ties. We demonstrate the versatility and capacity of the proposed model on
three applications of very different natures; namely handwritten digit
recognition, collaborative filtering and complex social survey analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0058</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0058</id><created>2014-07-31</created><authors><author><keyname>Norouzitallab</keyname><forenames>Mehrab</forenames></author><author><keyname>Monajjemi</keyname><forenames>Valiallah</forenames></author><author><keyname>Ghidary</keyname><forenames>Saeed Shiry</forenames></author><author><keyname>Menhaj</keyname><forenames>Mohammad Bagher</forenames></author></authors><title>A Framework for learning multi-agent dynamic formation strategy in
  real-time applications</title><categories>cs.RO cs.LG cs.MA</categories><comments>27 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formation strategy is one of the most important parts of many multi-agent
systems with many applications in real world problems. In this paper, a
framework for learning this task in a limited domain (restricted environment)
is proposed. In this framework, agents learn either directly by observing an
expert behavior or indirectly by observing other agents or objects behavior.
First, a group of algorithms for learning formation strategy based on limited
features will be presented. Due to distributed and complex nature of many
multi-agent systems, it is impossible to include all features directly in the
learning process; thus, a modular scheme is proposed in order to reduce the
number of features. In this method, some important features have indirect
influence in learning instead of directly involving them as input features.
This framework has the ability to dynamically assign a group of positions to a
group of agents to improve system performance. In addition, it can change the
formation strategy when the context changes. Finally, this framework is able to
automatically produce many complex and flexible formation strategy algorithms
without directly involving an expert to present and implement such complex
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0062</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0062</id><created>2014-07-31</created><authors><author><keyname>Zhang</keyname><forenames>Di</forenames></author><author><keyname>Zhou</keyname><forenames>Zhenyu</forenames></author><author><keyname>Yu</keyname><forenames>Keping</forenames></author><author><keyname>Sato</keyname><forenames>Takuro</forenames></author></authors><title>Energy Efficiency Scheme with Cellular Partition Zooming for Massive
  MIMO Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiple-input multiple-output (Massive MIMO) has been realized as a
promising technology for next generation wireless mobile communications, in
which Spectral efficiency (SE) and energy efficiency (EE) are two critical
issues. Prior estimates have indicated that 57% energy of the cellular system
need to be supplied by the operator, especially to feed the base station (BS).
While varies scheduling studies concerned on the user equipment (UE) to reduce
the total energy consumption instead of BS. Fewer literatures address EE issues
from a BS perspective. In this paper, an EE scheme is proposed by reducing the
energy consumption of BS. The transmission model and parameters related to EE
is formulated first. Afterwards, an cellular partition zooming (CPZ) scheme is
proposed where the BS can zoom in to maintain the coverage area. Specifically,
if no user exists in the rare area of the coverage, BS will zoom out to sleep
mode to save energy. Comprehensive simulation results demonstrate that CPZ has
better EE performance with negligible impact on transmission rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0063</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0063</id><created>2014-07-31</created><authors><author><keyname>Pu</keyname><forenames>Cunlai</forenames></author><author><keyname>Li</keyname><forenames>Siyuan</forenames></author><author><keyname>Yang</keyname><forenames>Jian</forenames></author></authors><title>Epidemic spreading driven by biased random walks</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>9 figures</comments><doi>10.1016/j.physa.2015.03.035</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random walk is one of the basic mechanisms found in many network
applications. We study the epidemic spreading dynamics driven by biased random
walks on complex networks. In our epidemic model, each time infected nodes
constantly spread some infected packets by biased random walks to their
neighbor nodes causing the infection of the susceptible nodes that receive the
packets. An infected node get recovered from infection with a fixed
probability. Simulation and analytical results on model and real-world networks
show that the epidemic spreading becomes intense and wide with the increase of
delivery capacity of infected nodes, average node degree, homogeneity of node
degree distribution. Furthermore, there are corresponding optimal parameters
such that the infected nodes have instantaneously the largest population, and
the epidemic spreading process covers the largest part of a network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0074</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0074</id><created>2014-08-01</created><authors><author><keyname>Adelman</keyname><forenames>Ross</forenames></author><author><keyname>Gumerov</keyname><forenames>Nail A.</forenames></author><author><keyname>Duraiswami</keyname><forenames>Ramani</forenames></author></authors><title>Software for Computing the Spheroidal Wave Functions Using Arbitrary
  Precision Arithmetic</title><categories>cs.MS cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spheroidal wave functions, which are the solutions to the Helmholtz
equation in spheroidal coordinates, are notoriously difficult to compute.
Because of this, practically no programming language comes equipped with the
means to compute them. This makes problems that require their use hard to
tackle. We have developed computational software for calculating these special
functions. Our software is called spheroidal and includes several novel
features, such as: using arbitrary precision arithmetic; adaptively choosing
the number of expansion coefficients to compute and use; and using the
Wronskian to choose from several different methods for computing the spheroidal
radial functions to improve their accuracy. There are two types of spheroidal
wave functions: the prolate kind when prolate spheroidal coordinates are used;
and the oblate kind when oblate spheroidal coordinate are used. In this paper,
we describe both, methods for computing them, and our software. We have made
our software freely available on our webpage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0090</identifier>
 <datestamp>2014-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0090</id><created>2014-08-01</created><updated>2014-12-10</updated><authors><author><keyname>Das</keyname><forenames>Anup Kumar</forenames></author><author><keyname>Mishra</keyname><forenames>Sanjaya</forenames></author></authors><title>Genesis of Altmetrics or Article-level Metrics for Measuring Efficacy of
  Scholarly Communications: Current Perspectives</title><categories>cs.DL cs.IR</categories><journal-ref>Journal of Scientometric Research, 2014, 3(2), 82-92</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The article-level metrics (ALMs) or altmetrics becomes a new trendsetter in
recent times for measuring the impact of scientific publications and their
social outreach to intended audiences. The popular social networks such as
Facebook, Twitter, and Linkedin and social bookmarks such as Mendeley and
CiteULike are nowadays widely used for communicating research to larger
transnational audiences. In 2012, the San Francisco Declaration on Research
Assessment got signed by the scientific and researchers communities across the
world. This declaration has given preference to the ALM or altmetrics over
traditional but faulty journal impact factor (JIF)-based assessment of career
scientists. JIF does not consider impact or influence beyond citations count as
this count reflected only through Thomson Reuters' Web of Science database.
Furthermore, JIF provides indicator related to the journal, but not related to
a published paper. Thus, altmetrics now becomes an alternative metrics for
performance assessment of individual scientists and their contributed scholarly
publications. This paper provides a glimpse of genesis of altmetrics in
measuring efficacy of scholarly communications and highlights available
altmetric tools and social platforms linking altmetric tools, which are widely
used in deriving altmetric scores of scholarly publications. The paper thus
argues for institutions and policy makers to pay more attention to altmetrics
based indicators for evaluation purpose but cautions that proper safeguards and
validations are needed before their adoption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0096</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0096</id><created>2014-08-01</created><authors><author><keyname>Li</keyname><forenames>Jiankou</forenames></author><author><keyname>Zhang</keyname><forenames>Wei</forenames></author></authors><title>Conditional Restricted Boltzmann Machines for Cold Start Recommendations</title><categories>cs.IR cs.LG stat.ML</categories><comments>12 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Restricted Boltzman Machines (RBMs) have been successfully used in
recommender systems. However, as with most of other collaborative filtering
techniques, it cannot solve cold start problems for there is no rating for a
new item. In this paper, we first apply conditional RBM (CRBM) which could take
extra information into account and show that CRBM could solve cold start
problem very well, especially for rating prediction task. CRBM naturally
combine the content and collaborative data under a single framework which could
be fitted effectively. Experiments show that CRBM can be compared favourably
with matrix factorization models, while hidden features learned from the former
models are more easy to be interpreted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0101</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0101</id><created>2014-08-01</created><authors><author><keyname>Kumar</keyname><forenames>Sandeep</forenames></author><author><keyname>Sharma</keyname><forenames>Vivek Kumar</forenames></author><author><keyname>Kumari</keyname><forenames>Rajani</forenames></author></authors><title>Memetic Search in Differential Evolution Algorithm</title><categories>cs.NE</categories><doi>10.5120/15582-4406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential Evolution (DE) is a renowned optimization stratagem that can
easily solve nonlinear and comprehensive problems. DE is a well known and
uncomplicated population based probabilistic approach for comprehensive
optimization. It has apparently outperformed a number of Evolutionary
Algorithms and further search heuristics in the vein of Particle Swarm
Optimization at what time of testing over both yardstick and actual world
problems. Nevertheless, DE, like other probabilistic optimization algorithms,
from time to time exhibits precipitate convergence and stagnates at suboptimal
position. In order to stay away from stagnation behavior while maintaining an
excellent convergence speed, an innovative search strategy is introduced, named
memetic search in DE. In the planned strategy, positions update equation
customized as per a memetic search stratagem. In this strategy a better
solution participates more times in the position modernize procedure. The
position update equation is inspired from the memetic search in artificial bee
colony algorithm. The proposed strategy is named as Memetic Search in
Differential Evolution (MSDE). To prove efficiency and efficacy of MSDE, it is
tested over 8 benchmark optimization problems and three real world optimization
problems. A comparative analysis has also been carried out among proposed MSDE
and original DE. Results show that the anticipated algorithm go one better than
the basic DE and its recent deviations in a good number of the experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0102</identifier>
 <datestamp>2014-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0102</id><created>2014-08-01</created><authors><author><keyname>Kumar</keyname><forenames>Sandeep</forenames></author><author><keyname>Sharma</keyname><forenames>Vivek Kumar</forenames></author><author><keyname>Kumari</keyname><forenames>Rajani</forenames></author></authors><title>Randomized Memetic Artificial Bee Colony Algorithm</title><categories>cs.NE</categories><comments>arXiv admin note: text overlap with arXiv:1407.5574</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial Bee Colony (ABC) optimization algorithm is one of the recent
population based probabilistic approach developed for global optimization. ABC
is simple and has been showed significant improvement over other Nature
Inspired Algorithms (NIAs) when tested over some standard benchmark functions
and for some complex real world optimization problems. Memetic Algorithms also
become one of the key methodologies to solve the very large and complex
real-world optimization problems. The solution search equation of Memetic ABC
is based on Golden Section Search and an arbitrary value which tries to balance
exploration and exploitation of search space. But still there are some chances
to skip the exact solution due to its step size. In order to balance between
diversification and intensification capability of the Memetic ABC, it is
randomized the step size in Memetic ABC. The proposed algorithm is named as
Randomized Memetic ABC (RMABC). In RMABC, new solutions are generated nearby
the best so far solution and it helps to increase the exploitation capability
of Memetic ABC. The experiments on some test problems of different complexities
and one well known engineering optimization application show that the proposed
algorithm outperforms over Memetic ABC (MeABC) and some other variant of ABC
algorithm(like Gbest guided ABC (GABC),Hooke Jeeves ABC (HJABC), Best-So-Far
ABC (BSFABC) and Modified ABC (MABC) in case of almost all the problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0104</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0104</id><created>2014-08-01</created><authors><author><keyname>Moreira</keyname><forenames>Waldir</forenames></author><author><keyname>Mendes</keyname><forenames>Paulo</forenames></author></authors><title>Impact of Human Behavior on Social Opportunistic Forwarding</title><categories>cs.NI</categories><comments>26 pages, 9 figures, 2 tables. arXiv admin note: substantial text
  overlap with arXiv:1407.8342</comments><doi>10.1016/j.adhoc.2014.07.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current Internet design is not capable to support communications in
environments characterized by very long delays and frequent network partitions.
To allow devices to communicate in such environments, delay-tolerant networking
solutions have been proposed by exploiting opportunistic message forwarding,
with limited expectations of end-to-end connectivity and node resources. Such
solutions envision non-traditional communication scenarios, such as disaster
areas and development regions. Several forwarding algorithms have been
investigated, aiming to offer the best trade-off between cost (number of
message replicas) and rate of successful message delivery. Among such
proposals, there has been an effort to employ social similarity inferred from
user mobility patterns in opportunistic routing solutions to improve
forwarding. However, these research effort presents two major limitations:
first, it is focused on distribution of the intercontact time over the complete
network structure, ignoring the impact that human behavior has on the dynamics
of the network; and second, most of the proposed solutions look at challenging
networking environments where networks have low density, ignoring the potential
use of delay-tolerant networking to support low cost communications in networks
with higher density, such as urban scenarios. This paper presents a study of
the impact that human behavior has on opportunistic forwarding. Our goal is
twofold: i) to show that performance in low and high density networks can be
improved by taking the dynamics of the network into account; and ii) to show
that the delay-tolerant networking can be used to reduce communication costs in
networks with higher density by taking the behavior of the user into account.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0110</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0110</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author><author><keyname>Adan</keyname><forenames>Ivo</forenames></author><author><keyname>Boxma</keyname><forenames>Onno</forenames></author></authors><title>A Two-Queue Polling Model with Two Priority Levels in the First Queue</title><categories>math.PR cs.PF</categories><comments>A shorter version of this paper appeared in the proceedings of
  ValueTools 2008. The present paper is an extended version, selected for
  publication in JDEDS</comments><journal-ref>Discrete Event Dynamic Systems 20(4), pp. 511--536, 2010</journal-ref><doi>10.1007/s10626-009-0072-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a single-server cyclic polling system consisting of
two queues. Between visits to successive queues, the server is delayed by a
random switch-over time. Two types of customers arrive at the first queue: high
and low priority customers. For this situation the following service
disciplines are considered: gated, globally gated, and exhaustive. We study the
cycle time distribution, the waiting times for each customer type, the joint
queue length distribution at polling epochs, and the steady-state marginal
queue length distributions for each customer type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0114</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0114</id><created>2014-08-01</created><authors><author><keyname>Hetland</keyname><forenames>Magnus Lie</forenames></author><author><keyname>Lykkja</keyname><forenames>Ola Martin</forenames></author></authors><title>A Real-Time Spatial Index for In-Vehicle Units</title><categories>cs.DS</categories><comments>In Proc. of the 26th Norwegian Informatics Conference, NIK, 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a spatial indexing solution for the highly constrained
environment of an in-vehicle unit in a distributed vehicle tolling scheme based
on satellite navigation (GNSS). We show that an immutable, purely functional
implementation of a high-fanout quadtree is a simple, practical solution that
satisfies all the requirements of such a system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0119</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0119</id><created>2014-08-01</created><authors><author><keyname>Kunegis</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author></authors><title>Action at a Distance in Networks</title><categories>cs.SI</categories><comments>3 pages, no figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this short paper, we characterise the notion of preferential attachment in
networks as action at a distance, and argue that it can only be an emergent
phenomenon -- the actual mechanism by which networks grow always being the
closing of triangles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0124</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0124</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author><author><keyname>Adan</keyname><forenames>Ivo</forenames></author></authors><title>Mixed Gated/Exhaustive Service in a Polling Model with Priorities</title><categories>math.PR cs.PF</categories><journal-ref>Queueing Systems 63(1-4), pp. 383-399, 2009. Special issue for the
  Erlang Centennial</journal-ref><doi>10.1007/s11134-009-9115-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a single-server polling system with switch-over
times. We introduce a new service discipline, mixed gated/exhaustive service,
that can be used for queues with two types of customers: high and low priority
customers. At the beginning of a visit of the server to such a queue, a gate is
set behind all customers. High priority customers receive priority in the sense
that they are always served before any low priority customers. But high
priority customers have a second advantage over low priority customers. Low
priority customers are served according to the gated service discipline, i.e.
only customers standing in front of the gate are served during this visit. In
contrast, high priority customers arriving during the visit period of the queue
are allowed to pass the gate and all low priority customers before the gate.
  We study the cycle time distribution, the waiting time distributions for each
customer type, the joint queue length distribution of all priority classes at
all queues at polling epochs, and the steady-state marginal queue length
distributions for each customer type. Through numerical examples we illustrate
that the mixed gated/exhaustive service discipline can significantly decrease
waiting times of high priority jobs. In many cases there is a minimal negative
impact on the waiting times of low priority customers but, remarkably, it turns
out that in polling systems with larger switch-over times there can be even a
positive impact on the waiting times of low priority customers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0131</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0131</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author></authors><title>A Polling Model with Reneging at Polling Instants</title><categories>math.PR cs.PF</categories><journal-ref>Annals of Operations Research 198, pp. 5-23, 2012</journal-ref><doi>10.1007/s10479-010-0758-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a single-server, cyclic polling system with
switch-over times and Poisson arrivals. The service disciplines that are
discussed, are exhaustive and gated service. The novel contribution of the
present paper is that we consider the reneging of customers at polling
instants. In more detail, whenever the server starts or ends a visit to a
queue, some of the customers waiting in each queue leave the system before
having received service. The probability that a certain customer leaves the
queue, depends on the queue in which the customer is waiting, and on the
location of the server. We show that this system can be analysed by introducing
customer subtypes, depending on their arrival periods, and keeping track of the
moment when they abandon the system. In order to determine waiting time
distributions, we regard the system as a polling model with varying arrival
rates, and apply a generalised version of the distributional form of Little's
law. The marginal queue length distribution can be found by conditioning on the
state of the system (position of the server, and whether it is serving or
switching).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0134</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0134</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author><author><keyname>Winands</keyname><forenames>Erik</forenames></author><author><keyname>Adan</keyname><forenames>Ivo</forenames></author><author><keyname>van Wijk</keyname><forenames>Sandra</forenames></author></authors><title>Closed-Form Waiting Time Approximations for Polling Systems</title><categories>math.PR cs.PF</categories><journal-ref>Performance Evaluation 68, pp. 290-306, 2011</journal-ref><doi>10.1016/j.peva.2010.12.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A typical polling system consists of a number of queues, attended by a single
server in a fixed order. The vast majority of papers on polling systems
focusses on Poisson arrivals, whereas very few results are available for
general arrivals. The current study is the first one presenting simple
closed-form approximations for the mean waiting times in polling systems with
renewal arrival processes, performing well for ALL workloads. The
approximations are constructed using heavy traffic limits and newly developed
light traffic limits. The closed-form approximations may prove to be extremely
useful for system design and optimisation in application areas as diverse as
telecommunication, maintenance, manufacturing and transportation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0135</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0135</id><created>2014-08-01</created><authors><author><keyname>Robinson-Garc&#xed;a</keyname><forenames>Nicol&#xe1;s</forenames></author><author><keyname>Torres-Salinas</keyname><forenames>Daniel</forenames></author><author><keyname>Zahedi</keyname><forenames>Zohreh</forenames></author><author><keyname>Costas</keyname><forenames>Rodrigo</forenames></author></authors><title>New data, new possibilities: Exploring the insides of Altmetric.com</title><categories>cs.DL</categories><journal-ref>Robinson-Garcia, N.; Torres-Salinas, D.; Zahedi, Z.; Costas, R.
  (2014) New data, new possibilities: Exploring the insides of Altmetric.com.
  El profesional de la informaci\'on, 23(4), 359-366</journal-ref><doi>10.3145/epi.2014.jul.03</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes Altmetric.com, one of the most important altmetric data
providers currently used. We have analyzed a set of publications with DOI
number indexed in the Web of Science during the period 2011-2013 and collected
their data with the Altmetric API. 19% of the original set of papers was
retrieved from Altmetric.com including some altmetric data. We identified 16
different social media sources from which Altmetric.com retrieves data. However
five of them cover 95.5% of the total set. Twitter (87.1%) and Mendeley (64.8%)
have the highest coverage. We conclude that Altmetric.com is a transparent,
rich and accurate tool for altmetric data. Nevertheless, there are still
potential limitations on its exhaustiveness as well as on the selection of
social media sources that need further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0136</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0136</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author><author><keyname>van der Mei</keyname><forenames>Rob</forenames></author><author><keyname>Winands</keyname><forenames>Erik</forenames></author></authors><title>Applications of polling systems</title><categories>math.PR cs.PF</categories><journal-ref>Surveys in Operations Research and Management Science 16, pp.
  67-82, 2011</journal-ref><doi>10.1016/j.sorms.2011.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the first paper on polling systems, written by Mack in 1957, a huge
number of papers on this topic has been written. A typical polling system
consists of a number of queues, attended by a single server. In several
surveys, the most notable ones written by Takagi, detailed and comprehensive
descriptions of the mathematical analysis of polling systems are provided. The
goal of the present survey paper is to complement these papers by putting the
emphasis on \emph{applications} of polling models. We discuss not only the
capabilities, but also the limitations of polling models in representing
various applications. The present survey is directed at both academicians and
practitioners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0137</identifier>
 <datestamp>2014-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0137</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author><author><keyname>Adan</keyname><forenames>Ivo</forenames></author><author><keyname>Winands</keyname><forenames>Erik</forenames></author><author><keyname>Down</keyname><forenames>Doug</forenames></author></authors><title>Delays at signalised intersections with exhaustive traffic control</title><categories>math.PR cs.PF</categories><journal-ref>Probability in the Engineering and Informational Sciences 26(3),
  pp. 337-373, 2012</journal-ref><doi>10.1017/S0269964812000058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study a traffic intersection with vehicle-actuated traffic
signal control. Traffic lights stay green until all lanes within a group are
emptied. Assuming general renewal arrival processes, we derive exact limiting
distributions of the delays under Heavy Traffic (HT) conditions. Furthermore,
we derive the Light Traffic (LT) limit of the mean delays for intersections
with Poisson arrivals, and develop a heuristic adaptation of this limit to
capture the LT behaviour for other interarrival-time distributions. We combine
the LT and HT results to develop closed-form approximations for the mean delays
of vehicles in each lane. These closed-form approximations are quite accurate,
very insightful and simple to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0142</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0142</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author><author><keyname>Boxma</keyname><forenames>Onno</forenames></author><author><keyname>Winands</keyname><forenames>Erik</forenames></author></authors><title>On open problems in polling systems</title><categories>math.PR cs.PF</categories><journal-ref>Queueing Systems 68, pp. 365-374, 2011</journal-ref><doi>10.1007/s11134-011-9247-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper we address two open problems concerning polling systems,
viz., queueing systems consisting of multiple queues attended by a single
server that visits the queues one at a time. The first open problem deals with
a system consisting of two queues, one of which has gated service, while the
other receives 1-limited service. The second open problem concerns polling
systems with general (renewal) arrivals and deterministic switch-over times
that become infinitely large. We discuss related, known results for both
problems, and the difficulties encountered when trying to solve them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0144</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0144</id><created>2014-08-01</created><updated>2014-08-16</updated><authors><author><keyname>Broutin</keyname><forenames>Nicolas</forenames></author><author><keyname>Wang</keyname><forenames>Minmin</forenames></author></authors><title>Cutting down $\mathbf p$-trees and inhomogeneous continuum random trees</title><categories>math.PR cs.DM math.CO</categories><comments>44 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a fragmentation of the $\mathbf p$-trees of Camarri and Pitman
[Elect. J. Probab., vol. 5, pp. 1--18, 2000]. We give exact correspondences
between the $\mathbf p$-trees and trees which encode the fragmentation. We then
use these results to study the fragmentation of the ICRTs (scaling limits of
$\mathbf p$-trees) and give distributional correspondences between the ICRT and
the tree encoding the fragmentation. The theorems for the ICRT extend the ones
by Bertoin and Miermont [Ann. Appl. Probab., vol. 23(4), pp. 1469--1493, 2013]
about the cut tree of the Brownian continuum random tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0146</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0146</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author><author><keyname>van der Mei</keyname><forenames>Rob</forenames></author><author><keyname>Winands</keyname><forenames>Erik</forenames></author></authors><title>Waiting times in queueing networks with a single shared server</title><categories>math.PR cs.PF</categories><journal-ref>Queueing Systems 74(4), pp. 403-429, 2013</journal-ref><doi>10.1007/s11134-012-9334-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a queueing network with a single shared server that serves the
queues in a cyclic order. External customers arrive at the queues according to
independent Poisson processes. After completing service, a customer either
leaves the system or is routed to another queue. This model is very generic and
finds many applications in computer systems, communication networks,
manufacturing systems, and robotics. Special cases of the introduced network
include well-known polling models, tandem queues, systems with a waiting room,
multi-stage models with parallel queues, and many others. A complicating factor
of this model is that the internally rerouted customers do not arrive at the
various queues according to a Poisson process, causing standard techniques to
find waiting-time distributions to fail. In this paper we develop a new method
to obtain exact expressions for the Laplace-Stieltjes transforms of the
steady-state waiting-time distributions. This method can be applied to a wide
variety of models which lacked an analysis of the waiting-time distribution
until now.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0147</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0147</id><created>2014-08-01</created><authors><author><keyname>Liu</keyname><forenames>Kun</forenames></author><author><keyname>Fridman</keyname><forenames>Emilia</forenames></author><author><keyname>Hetel</keyname><forenames>Laurentiu</forenames></author></authors><title>Networked control systems in the presence of scheduling protocols and
  communication delays</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops the time-delay approach to Networked Control Systems
(NCSs) in the presence of variable transmission delays, sampling intervals and
communication constraints. The system sensor nodes are supposed to be
distributed over a network. Due to communication constraints only one node
output is transmitted through the communication channel at once. The scheduling
of sensor information towards the controller is ruled by a weighted
Try-Once-Discard (TOD) or by Round-Robin (RR) protocols. Differently from the
existing results on NCSs in the presence of scheduling protocols (in the
frameworks of hybrid and discrete-time systems), we allow the communication
delays to be greater than the sampling intervals. A novel hybrid system model
for the closed-loop system is presented that contains {\it time-varying delays
in the continuous dynamics and in the reset conditions}. A new
Lyapunov-Krasovskii method, which is based on discontinuous in time Lyapunov
functionals is introduced for the stability analysis of the delayed hybrid
systems. Polytopic type uncertainties in the system model can be easily
included in the analysis. The efficiency of the time-delay approach is
illustrated on the examples of uncertain cart-pendulum and of batch reactor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0151</identifier>
 <datestamp>2014-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0151</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author><author><keyname>van der Mei</keyname><forenames>Rob</forenames></author><author><keyname>Winands</keyname><forenames>Erik</forenames></author></authors><title>Queueing networks with a single shared server: light and heavy traffic</title><categories>math.PR cs.PF</categories><comments>The short paper was published in the proceedings of Performance 2011,
  Amsterdam</comments><journal-ref>SIGMETRICS Performance Evaluation Review 39(2), pp. 44-46, 2011</journal-ref><doi>10.1145/2034832.2034843</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a queueing network with a single shared server, that serves the
queues in a cyclic order according to the gated service discipline. External
customers arrive at the queues according to independent Poisson processes.
After completing service, a customer either leaves the system or is routed to
another queue. This model is very generic and finds many applications in
computer systems, communication networks, manufacturing systems and robotics.
Special cases of the introduced network include well-known polling models and
tandem queues. We derive exact limits of the mean delays under both
heavy-traffic and light-traffic conditions. By interpolating between these
asymptotic regimes, we develop simple closed-form approximations for the mean
delays for arbitrary loads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0173</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0173</id><created>2014-08-01</created><updated>2014-11-05</updated><authors><author><keyname>Moeller</keyname><forenames>Michael</forenames></author><author><keyname>Benning</keyname><forenames>Martin</forenames></author><author><keyname>Sch&#xf6;nlieb</keyname><forenames>Carola</forenames></author><author><keyname>Cremers</keyname><forenames>Daniel</forenames></author></authors><title>Variational Depth from Focus Reconstruction</title><categories>cs.CV math.OC</categories><doi>10.1109/TIP.2015.2479469</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of reconstructing a depth map from a
sequence of differently focused images, also known as depth from focus or shape
from focus. We propose to state the depth from focus problem as a variational
problem including a smooth but nonconvex data fidelity term, and a convex
nonsmooth regularization, which makes the method robust to noise and leads to
more realistic depth maps. Additionally, we propose to solve the nonconvex
minimization problem with a linearized alternating directions method of
multipliers (ADMM), allowing to minimize the energy very efficiently. A
numerical comparison to classical methods on simulated as well as on real data
is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0177</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0177</id><created>2014-08-01</created><updated>2014-08-04</updated><authors><author><keyname>Gambini</keyname><forenames>Juliana</forenames></author><author><keyname>Cassetti</keyname><forenames>Julia</forenames></author><author><keyname>Lucini</keyname><forenames>Mar&#xed;a Magdalena</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author></authors><title>Parameter Estimation in SAR Imagery using Stochastic Distances and
  Asymmetric Kernels</title><categories>cs.IT math.IT stat.AP</categories><comments>Accepted for publication in the IEEE Journal of Selected Topics in
  Applied Earth Observations and Remote Sensing (IEEE J-STARS), July 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyze several strategies for the estimation of the
roughness parameter of the $\mathcal G_I^0$ distribution. It has been shown
that this distribution is able to characterize a large number of targets in
monopolarized SAR imagery, deserving the denomination of &quot;Universal Model&quot; It
is indexed by three parameters: the number of looks (which can be estimated in
the whole image), a scale parameter, and the roughness or texture parameter.
The latter is closely related to the number of elementary backscatters in each
pixel, one of the reasons for receiving attention in the literature. Although
there are efforts in providing improved and robust estimates for such quantity,
its dependable estimation still poses numerical problems in practice. We
discuss estimators based on the minimization of stochastic distances between
empirical and theoretical densities, and argue in favor of using an estimator
based on the Triangular distance and asymmetric kernels built with Inverse
Gaussian densities. We also provide new results regarding the heavytailedness
of this distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0180</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0180</id><created>2014-08-01</created><authors><author><keyname>Ernvall</keyname><forenames>Toni</forenames></author><author><keyname>Westerb&#xe4;ck</keyname><forenames>Thomas</forenames></author><author><keyname>Hollanti</keyname><forenames>Camilla</forenames></author></authors><title>Linear Locally Repairable Codes with Random Matrices</title><categories>cs.IT math.IT</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, locally repairable codes with all-symbol locality are studied.
Methods to modify already existing codes are presented. Also, it is shown that
with high probability, a random matrix with a few extra columns guaranteeing
the locality property, is a generator matrix for a locally repairable code with
a good minimum distance. The proof of this gives also a constructive method to
find locally repairable codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0192</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0192</id><created>2014-08-01</created><authors><author><keyname>Albataineh</keyname><forenames>Zaid</forenames></author><author><keyname>Salem</keyname><forenames>Fathi M.</forenames></author></authors><title>Convex Cauchy Schwarz Independent Component Analysis for Blind Source
  Separation</title><categories>cs.IT math.IT</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new high performance Convex Cauchy Schwarz Divergence (CCS DIV)
measure for Independent Component Analysis (ICA) and Blind Source Separation
(BSS). The CCS DIV measure is developed by integrating convex functions into
the Cauchy Schwarz inequality. By including a convexity quality parameter, the
measure has a broad control range of its convexity curvature. With this
measure, a new CCS ICA algorithm is structured and a non parametric form is
developed incorporating the Parzen window based distribution. Furthermore,
pairwise iterative schemes are employed to tackle the high dimensional problem
in BSS. We present two schemes of pairwise non parametric ICA algorithms, one
is based on gradient decent and the second on the Jacobi Iterative method.
Several case study scenarios are carried out on noise free and noisy mixtures
of speech and music signals. Finally, the superiority of the proposed CCS ICA
algorithm is demonstrated in metric comparison performance with FastICA,
RobustICA, convex ICA (C ICA), and other leading existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0193</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0193</id><created>2014-08-01</created><authors><author><keyname>Albataineh</keyname><forenames>Zaid</forenames></author><author><keyname>Salem</keyname><forenames>Fathi M.</forenames></author></authors><title>A RobustICA Based Algorithm for Blind Separation of Convolutive Mixtures</title><categories>cs.LG cs.SD</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a frequency domain method based on robust independent component
analysis (RICA) to address the multichannel Blind Source Separation (BSS)
problem of convolutive speech mixtures in highly reverberant environments. We
impose regularization processes to tackle the ill-conditioning problem of the
covariance matrix and to mitigate the performance degradation in the frequency
domain. We apply an algorithm to separate the source signals in adverse
conditions, i.e. high reverberation conditions when short observation signals
are available. Furthermore, we study the impact of several parameters on the
performance of separation, e.g. overlapping ratio and window type of the
frequency domain method. We also compare different techniques to solve the
frequency-domain permutation ambiguity. Through simulations and real world
experiments, we verify the superiority of the presented convolutive algorithm
among other BSS algorithms, including recursive regularized ICA (RR ICA),
independent vector analysis (IVA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0196</identifier>
 <datestamp>2016-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0196</id><created>2014-08-01</created><updated>2016-01-14</updated><authors><author><keyname>Albataineh</keyname><forenames>Zaid</forenames></author><author><keyname>Salem</keyname><forenames>Fathi M.</forenames></author></authors><title>A Blind Adaptive CDMA Receiver Based on State Space Structures</title><categories>cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code Division Multiple Access (CDMA) is a channel access method, based on
spread-spectrum technology, used by various radio technologies world-wide. In
general, CDMA is used as an access method in many mobile standards such as
CDMA2000 and WCDMA. We address the problem of blind multiuser equalization in
the wideband CDMA system, in the noisy multipath propagation environment.
Herein, we propose three new blind receiver schemes, which are based on state
space structures and Independent Component Analysis (ICA). These blind
state-space receivers (BSSR) do not require knowledge of the propagation
parameters or spreading code sequences of the users they primarily exploit the
natural assumption of statistical independence among the source signals. We
also develop three semi blind adaptive detectors by incorporating the new
adaptive methods into the standard RAKE receiver structure. Extensive
comparative case study, based on Bit error rate (BER) performance of these
methods, is carried out for different number of users, symbols per user, and
signal to noise ratio (SNR) in comparison with conventional detectors,
including the Blind Multiuser Detectors (BMUD) and Linear Minimum mean squared
error (LMMSE). The results show that the proposed methods outperform the other
detectors in estimating the symbol signals from the received mixed CDMA
signals. Moreover, the new blind detectors mitigate the multi access
interference (MAI) in CDMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0200</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0200</id><created>2014-08-01</created><authors><author><keyname>Blumenthal</keyname><forenames>Sebastian</forenames></author><author><keyname>Bruyninckx</keyname><forenames>Herman</forenames></author></authors><title>Towards a Domain Specific Language for a Scene Graph based Robotic World
  Model</title><categories>cs.RO</categories><comments>Presented at DSLRob 2013 (arXiv:cs/1312.5952)</comments><report-no>DSLRob/2013/07</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robot world model representations are a vital part of robotic applications.
However, there is no support for such representations in model-driven
engineering tool chains. This work proposes a novel Domain Specific Language
(DSL) for robotic world models that are based on the Robot Scene Graph (RSG)
approach. The RSG-DSL can express (a) application specific scene
configurations, (b) semantic scene structures and (c) inputs and outputs for
the computational entities that are loaded into an instance of a world model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0204</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0204</id><created>2014-08-01</created><authors><author><keyname>Lin</keyname><forenames>Nan</forenames></author><author><keyname>Jiang</keyname><forenames>Junhai</forenames></author><author><keyname>Guo</keyname><forenames>Shicheng</forenames></author><author><keyname>Xiong</keyname><forenames>Momiao</forenames></author></authors><title>Functional Principal Component Analysis and Randomized Sparse Clustering
  Algorithm for Medical Image Analysis</title><categories>stat.ML cs.AI cs.CV cs.LG</categories><comments>35 pages, 2 figures, 6 tables</comments><doi>10.1371/journal.pone.0132945</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to advances in sensors, growing large and complex medical image data have
the ability to visualize the pathological change in the cellular or even the
molecular level or anatomical changes in tissues and organs. As a consequence,
the medical images have the potential to enhance diagnosis of disease,
prediction of clinical outcomes, characterization of disease progression,
management of health care and development of treatments, but also pose great
methodological and computational challenges for representation and selection of
features in image cluster analysis. To address these challenges, we first
extend one dimensional functional principal component analysis to the two
dimensional functional principle component analyses (2DFPCA) to fully capture
space variation of image signals. Image signals contain a large number of
redundant and irrelevant features which provide no additional or no useful
information for cluster analysis. Widely used methods for removing redundant
and irrelevant features are sparse clustering algorithms using a lasso-type
penalty to select the features. However, the accuracy of clustering using a
lasso-type penalty depends on how to select penalty parameters and a threshold
for selecting features. In practice, they are difficult to determine. Recently,
randomized algorithms have received a great deal of attention in big data
analysis. This paper presents a randomized algorithm for accurate feature
selection in image cluster analysis. The proposed method is applied to ovarian
and kidney cancer histology image data from the TCGA database. The results
demonstrate that the randomized feature selection method coupled with
functional principal component analysis substantially outperforms the current
sparse clustering algorithms in image cluster analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0210</identifier>
 <datestamp>2015-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0210</id><created>2014-08-01</created><updated>2015-08-22</updated><authors><author><keyname>Casenave</keyname><forenames>Fabien</forenames></author></authors><title>A Fast Summation Method for translation invariant kernels</title><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a Fast Multipole Method (FMM) where a low-rank approximation of the
kernel is obtained using the Empirical Interpolation Method (EIM). Contrary to
classical interpolation-based FMM, where the interpolation points and basis are
fixed beforehand, the EIM is a nonlinear approximation method which constructs
interpolation points and basis which are adapted to the kernel under
consideration. The basis functions are obtained using evaluations of the kernel
itself. We restrict ourselves to translation-invariant kernels, for which a
modified version of the EIM approximation can be used in a multilevel FMM
context; we call the obtained algorithm Empirical Interpolation Fast Multipole
Method (EIFMM). An important feature of the EIFMM is a built-in error
estimation of the interpolation error made by the low-rank approximation of the
far-field behavior of the kernel: the algorithm selects the optimal number of
interpolation points required to ensure a given accuracy for the result,
leading to important gains for inhomogeneous kernels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0213</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0213</id><created>2014-08-01</created><authors><author><keyname>Gomez-Vilardebo</keyname><forenames>Jesus</forenames></author><author><keyname>G&#xfc;nd&#xfc;z</keyname><forenames>Deniz</forenames></author></authors><title>Smart Meter Privacy for Multiple Users in the Presence of an Alternative
  Energy Source</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart meters (SMs) measure and report users' energy consumption to the
utility provider (UP) in almost real-time, providing a much more detailed
depiction of the consumer's energy consumption compared to their analog
counterparts. This increased rate of information flow to the UP, together with
its many potential benefits, raise important concerns regarding user privacy.
This work investigates, from an information theoretic perspective, the privacy
that can be achieved in a multi-user SM system in the presence of an
alternative energy source (AES). To measure privacy, we use the mutual
information rate between the users' real energy consumption profile and the SM
readings that are available to the UP. The objective is to characterize the
\textit{privacy-power function}, defined as the minimal information leakage
rate that can be obtained with an average power limited AES. We characterize
the privacy-power function in a single-letter form when the users' energy
demands are assumed to be independent and identically distributed over time.
Moreover, for binary and exponentially distributed energy demands, we provide
an explicit characterization of the privacy-power function. For any discrete
energy demands, we demonstrate that the privacy-power function can always be
efficiently evaluated numerically. Finally, for continuous energy demands, we
derive an explicit lower-bound on the privacy-power function, which is tight
for exponentially distributed loads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0258</identifier>
 <datestamp>2014-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0258</id><created>2014-08-01</created><authors><author><keyname>Lev</keyname><forenames>Omer</forenames></author><author><keyname>Oren</keyname><forenames>Joel</forenames></author><author><keyname>Boutilier</keyname><forenames>Craig</forenames></author><author><keyname>Rosenschein</keyname><forenames>Jeffery S.</forenames></author></authors><title>The Pricing War Continues: On Competitive Multi-Item Pricing</title><categories>cs.GT cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a game with \emph{strategic} vendors who own multiple items and a
single buyer with a submodular valuation function. The goal of the vendors is
to maximize their revenue via pricing of the items, given that the buyer will
buy the set of items that maximizes his net payoff.
  We show this game may not always have a pure Nash equilibrium, in contrast to
previous results for the special case where each vendor owns a single item. We
do so by relating our game to an intermediate, discrete game in which the
vendors only choose the available items, and their prices are set exogenously
afterwards.
  We further make use of the intermediate game to provide tight bounds on the
price of anarchy for the subset games that have pure Nash equilibria; we find
that the optimal PoA reached in the previous special cases does not hold, but
only a logarithmic one.
  Finally, we show that for a special case of submodular functions, efficient
pure Nash equilibria always exist.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0259</identifier>
 <datestamp>2014-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0259</id><created>2014-07-11</created><updated>2014-12-12</updated><authors><author><keyname>El-Bardan</keyname><forenames>Raghed</forenames></author><author><keyname>Masazade</keyname><forenames>Engin</forenames></author><author><keyname>Ozdemir</keyname><forenames>Onur</forenames></author><author><keyname>Han</keyname><forenames>Yunghsiang S.</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Permutation Trellis Coded Multi-level FSK Signaling to Mitigate Primary
  User Interference in Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>30 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We employ Permutation Trellis Code (PTC) based multi-level Frequency Shift
Keying signaling to mitigate the impact of Primary Users (PUs) on the
performance of Secondary Users (SUs) in Cognitive Radio Networks (CRNs). The
PUs are assumed to be dynamic in that they appear intermittently and stay
active for an unknown duration. Our approach is based on the use of PTC
combined with multi-level FSK modulation so that an SU can improve its data
rate by increasing its transmission bandwidth while operating at low power and
not creating destructive interference for PUs. We evaluate system performance
by obtaining an approximation for the actual Bit Error Rate (BER) using
properties of the Viterbi decoder and carry out a thorough performance analysis
in terms of BER and throughput. The results show that the proposed coded system
achieves i) robustness by ensuring that SUs have stable throughput in the
presence of heavy PU interference and ii) improved resiliency of SU links to
interference in the presence of multiple dynamic PUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0262</identifier>
 <datestamp>2014-12-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0262</id><created>2014-08-01</created><updated>2014-12-11</updated><authors><author><keyname>Varma</keyname><forenames>Girish</forenames></author></authors><title>Reducing uniformity in Khot-Saket hypergraph coloring hardness
  reductions</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent result, Khot and Saket [FOCS 2014] proved the quasi-NP-hardness
of coloring a 2-colorable 12-uniform hypergraph with $2^{(\log n)^{\Omega(1)}}$
colors. This result was proved using a novel outer PCP verifier which had a
strong soundness guarantee. In this note, we show that we can reduce the arity
of their result by modifying their 12-query inner verifier to an 8-query inner
verifier based on the hypergraph coloring hardness reductions of Guruswami et.
al. [STOC 2014]. More precisely, we prove quasi-NP-hardness of the following
problems on n-vertex hypergraphs.
  - Coloring a 2-colorable 8-uniform hypergraph with $2^{(\log n)^{\Omega(1)}}$
colors.
  - Coloring a 4-colorable 4-uniform hypergraph with $2^{(\log n)^{\Omega(1)}}$
colors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0272</identifier>
 <datestamp>2014-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0272</id><created>2014-08-01</created><updated>2014-09-26</updated><authors><author><keyname>Parmentier</keyname><forenames>Axel</forenames></author><author><keyname>Meunier</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author></authors><title>Stochastic Shortest Paths and Risk Measures</title><categories>cs.DS</categories><msc-class>90B99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider three shortest path problems in directed graphs with random arc
lengths. For the first and the second problems, a risk measure is involved.
While the first problem consists in finding a path minimizing this risk
measure, the second one consists in finding a path minimizing a deterministic
cost, while satisfying a constraint on the risk measure. We propose algorithms
solving these problems for a wide range of risk measures, which includes among
several others the $CVaR$ and the probability of being late. Their performances
are evaluated through experiments. One of the key elements in these algorithms
is the use of stochastic lower bounds that allow to discard partial solutions.
Good stochastic lower bounds are provided by the so-called Stochastic Ontime
Arrival Problem. This latter problem is the third one studied in this paper and
we propose a new and very efficient algorithm solving it. Complementary
discussions on the complexity of the problems are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0282</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0282</id><created>2014-08-01</created><authors><author><keyname>Boon</keyname><forenames>Marko</forenames></author><author><keyname>Adan</keyname><forenames>Ivo</forenames></author><author><keyname>Boxma</keyname><forenames>Onno</forenames></author></authors><title>A Polling Model with Multiple Priority Levels</title><categories>math.PR cs.PF</categories><comments>arXiv admin note: substantial text overlap with arXiv:1408.0110</comments><journal-ref>Performance Evaluation 67, pp. 468-484, 2010</journal-ref><doi>10.1016/j.peva.2010.01.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a single-server cyclic polling system. Between
visits to successive queues, the server is delayed by a random switch-over
time. The order in which customers are served in each queue is determined by a
priority level that is assigned to each customer at his arrival. For this
situation the following service disciplines are considered: gated, exhaustive,
and globally gated. We study the cycle time distribution, the waiting times for
each customer type, the joint queue length distribution of all priority classes
at all queues at polling epochs, and the steady-state marginal queue length
distributions for each customer type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0313</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0313</id><created>2014-08-01</created><authors><author><keyname>Krivulin</keyname><forenames>Nikolai</forenames></author></authors><title>Tropical optimization problems</title><categories>math.OC cs.SY</categories><comments>23 Pages. arXiv admin note: text overlap with arXiv:1406.1777</comments><msc-class>65K10 (Primary), 15A80, 65K05, 90C48, 41A50 (Secondary)</msc-class><journal-ref>Advances in Economics and Optimization: Collected Scientific
  Studies Dedicated to the Memory of L. V. Kantorovich, pp. 195-214, Nova
  Science Publishers, New York, 2014. ISBN 978-1-63117-073-7</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider optimization problems that are formulated and solved in the
framework of tropical mathematics. The problems consist in minimizing or
maximizing functionals defined on vectors of finite-dimensional semimodules
over idempotent semifields, and may involve constraints in the form of linear
equations and inequalities. The objective function can be either a linear
function or nonlinear function calculated by means of multiplicative conjugate
transposition of vectors. We start with an overview of known tropical
optimization problems and solution methods. Then, we formulate certain new
problems and present direct solutions to the problems in a closed compact
vector form suitable for further analysis and applications. For many problems,
the results obtained are complete solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0314</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0314</id><created>2014-08-01</created><authors><author><keyname>Amenta</keyname><forenames>Nina</forenames></author><author><keyname>Dey</keyname><forenames>Tamal K.</forenames></author></authors><title>Normal variation for adaptive feature size</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The change in the normal between any two nearby points on a closed, smooth
surface is bounded with respect to the local feature size (distance to the
medial axis). An incorrect proof of this lemma appeared as part of the analysis
of the &quot;crust&quot; algorithm of Amenta and Bern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0325</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0325</id><created>2014-08-01</created><authors><author><keyname>Forsati</keyname><forenames>Rana</forenames></author><author><keyname>Mahdavi</keyname><forenames>Mehrdad</forenames></author><author><keyname>Shamsfard</keyname><forenames>Mehrnoush</forenames></author><author><keyname>Sarwat</keyname><forenames>Mohamed</forenames></author></authors><title>Matrix Factorization with Explicit Trust and Distrust Relationships</title><categories>cs.SI cs.IR cs.LG</categories><comments>ACM Transactions on Information Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advent of online social networks, recommender systems have became
crucial for the success of many online applications/services due to their
significance role in tailoring these applications to user-specific needs or
preferences. Despite their increasing popularity, in general recommender
systems suffer from the data sparsity and the cold-start problems. To alleviate
these issues, in recent years there has been an upsurge of interest in
exploiting social information such as trust relations among users along with
the rating data to improve the performance of recommender systems. The main
motivation for exploiting trust information in recommendation process stems
from the observation that the ideas we are exposed to and the choices we make
are significantly influenced by our social context. However, in large user
communities, in addition to trust relations, the distrust relations also exist
between users. For instance, in Epinions the concepts of personal &quot;web of
trust&quot; and personal &quot;block list&quot; allow users to categorize their friends based
on the quality of reviews into trusted and distrusted friends, respectively. In
this paper, we propose a matrix factorization based model for recommendation in
social rating networks that properly incorporates both trust and distrust
relationships aiming to improve the quality of recommendations and mitigate the
data sparsity and the cold-start users issues. Through experiments on the
Epinions data set, we show that our new algorithm outperforms its standard
trust-enhanced or distrust-enhanced counterparts with respect to accuracy,
thereby demonstrating the positive effect that incorporation of explicit
distrust information can have on recommender systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0328</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0328</id><created>2014-08-01</created><authors><author><keyname>Wilkin</keyname><forenames>Tim</forenames></author><author><keyname>Beliakov</keyname><forenames>Gleb</forenames></author></authors><title>Weakly monotone averaging functions</title><categories>cs.AI math.CA</categories><msc-class>03E72, 03B52, 94D05, 26E60</msc-class><acm-class>I.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monotonicity with respect to all arguments is fundamental to the definition
of aggregation functions. It is also a limiting property that results in many
important non-monotonic averaging functions being excluded from the theoretical
framework. This work proposes a definition for weakly monotonic averaging
functions, studies some properties of this class of functions and proves that
several families of important non-monotonic means are actually weakly monotonic
averaging functions. Specifically we provide sufficient conditions for weak
monotonicity of the Lehmer mean and generalised mixture operators. We establish
weak monotonicity of several robust estimators of location and conditions for
weak monotonicity of a large class of penalty-based aggregation functions.
These results permit a proof of the weak monotonicity of the class of
spatial-tonal filters that include important members such as the bilateral
filter and anisotropic diffusion. Our concept of weak monotonicity provides a
sound theoretical and practical basis by which (monotone) aggregation functions
and non-monotone averaging functions can be related within the same framework,
allowing us to bridge the gap between these previously disparate areas of
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0332</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0332</id><created>2014-08-01</created><authors><author><keyname>Vaghela</keyname><forenames>Dushyant</forenames></author></authors><title>Social Media Impact on Website Ranking</title><categories>cs.SI</categories><comments>I Have Applied My SEO Research Work on http://explorequotes.com/ and
  Found Very Good Results in Web Ranking</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Internet is fast becoming critically important to commerce, industry and
individuals. Search Engine (SE) is the most vital component for communication
network and also used for discover information for users or people. Search
engine optimization (SEO) is the process that is mostly used to increasing
traffic from free, organic or natural listings on search engines and also helps
to increase website ranking. It includes techniques like link building,
directory submission, classified submission etc. but SMO, on the other hand, is
the process of promoting your website on social media platforms. It includes
techniques like RSS feeds, social news and bookmarking sites, video and
blogging sites, as well as social networking sites, such as Facebook, Twitter,
Google+, Tumblr, Pinterest, Instagram etc.Social media optimization is becoming
increasingly important for search engine optimization, as search engines are
increasingly utilizing the recommendations of users of social networks to rank
pages in the search engine result pages. Since it is more difficult to tip the
influence the search engines in this way. Social Media Optimization (SMO) may
also use to generate traffic on a website, promote your business at the center
of social marketing place and increase ranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0339</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0339</id><created>2014-08-02</created><authors><author><keyname>Sarma</keyname><forenames>Siddhartha</forenames></author></authors><title>Beamforming for Secure Communication via Untrusted Relay Nodes Using
  Artificial Noise</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-phase beamforming solution for secure communication using untrusted
relay nodes is presented. To thwart eavesdropping attempts of relay nodes, we
deliberately introduce artificial noise in the source message. After pointing
out the incongruity in evaluating secrecy rate in our model for certain
scenarios, we provide an SNR based frame work for secure communication. We
intend to bring down the SNR at each of the untrusted relay nodes below a
certain predefined threshold, whereas, using beamforming we want to boost the
SNR at the destination. With this motive optimal scaling vector is evaluated
for beamforming phase which not only nullifies the artificial noise transmitted
initially, but also maximizes the SNR at the destination. We discuss both the
total and individual power constraint scenarios and provide analytical solution
for both of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0355</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0355</id><created>2014-08-02</created><authors><author><keyname>Cai</keyname><forenames>Ning</forenames></author><author><keyname>Khan</keyname><forenames>M. Junaid</forenames></author></authors><title>Almost Decouplability of any Directed Weighted Network Topology</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a conception that any weighted directed network
topology is almost decouplable, which can help to transform the topology into a
similar form being composed of uncoupled vertices, and thus reduce the
complexity of analysis for networked dynamical systems. As an example of its
application, the consensus problem of linear multi-agent systems with
time-varying network topologies is addressed. As a result, a necessary and
sufficient condition for uniform consensus is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0366</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0366</id><created>2014-08-02</created><authors><author><keyname>Terasawa</keyname><forenames>Yoshihiro</forenames></author></authors><title>Publickey encryption by ordering</title><categories>cs.CR</categories><comments>in japanese</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1999, public key cryptography using the matrix was devised by a hish
school student of 16 yesrs old girl Sarah Flannery. This cryptosystem seemed
faster than RSA, and it's having the strength to surpass even the encryption to
RSA. However, this encryption scheme was broken bfore har papers were
published. In this paper, We try to construct publickey encryption scheme from
permutation group that is equivalent to matrix as noncommutative group. And we
explore the potential of this cryptsystem through implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0377</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0377</id><created>2014-08-02</created><authors><author><keyname>Tian</keyname><forenames>Chao</forenames></author><author><keyname>Sasidharan</keyname><forenames>Birenjith</forenames></author><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Vaishampayan</keyname><forenames>Vinay A.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Layered, Exact-Repair Regenerating Codes Via Embedded Error Correction
  and Block Designs</title><categories>cs.IT math.IT</categories><comments>This is a combination of the following two papers with additional
  results (new asymptotic analysis, a better alphabet size bound and smaller
  repetition factors): arXiv:1302.4670 &quot;Exact-Repair Regenerating Codes Via
  Layered Erasure Correction and Block Designs&quot; by Tian, Aggarwal, and
  Vaishampayan, and arXiv:1301.6157 &quot;High-Rate Regenerating Codes Through
  Layering&quot; by Sasidharan and Kumar</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new class of exact-repair regenerating codes is constructed by stitching
together shorter erasure correction codes, where the stitching pattern can be
viewed as block designs. The proposed codes have the &quot;help-by-transfer&quot;
property where the helper nodes simply transfer part of the stored data
directly, without performing any computation. This embedded error correction
structure makes the decoding process straightforward, and in some cases the
complexity is very low. We show that this construction is able to achieve
performance better than space-sharing between the minimum storage regenerating
codes and the minimum repair-bandwidth regenerating codes, and it is the first
class of codes to achieve this performance. In fact, it is shown that the
proposed construction can achieve a non-trivial point on the optimal
functional-repair tradeoff, and it is asymptotically optimal at high rate,
i.e., it asymptotically approaches the minimum storage and the minimum
repair-bandwidth simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0384</identifier>
 <datestamp>2014-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0384</id><created>2014-08-02</created><updated>2014-12-17</updated><authors><author><keyname>Kutten</keyname><forenames>Shay</forenames></author><author><keyname>Trehan</keyname><forenames>Chhaya</forenames></author></authors><title>Fast and Compact Distributed Verification and Self-Stabilization of a
  DFS Tree</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms for distributed verification and silent-stabilization
of a DFS(Depth First Search) spanning tree of a connected network. Computing
and maintaining such a DFS tree is an important task, e.g., for constructing
efficient routing schemes. Our algorithm improves upon previous work in various
ways. Comparable previous work has space and time complexities of $O(n\log
\Delta)$ bits per node and $O(nD)$ respectively, where $\Delta$ is the highest
degree of a node, $n$ is the number of nodes and $D$ is the diameter of the
network. In contrast, our algorithm has a space complexity of $O(\log n)$ bits
per node, which is optimal for silent-stabilizing spanning trees and runs in
$O(n)$ time. In addition, our solution is modular since it utilizes the
distributed verification algorithm as an independent subtask of the overall
solution. It is possible to use the verification algorithm as a stand alone
task or as a subtask in another algorithm. To demonstrate the simplicity of
constructing efficient DFS algorithms using the modular approach, We also
present a (non-sielnt) self-stabilizing DFS token circulation algorithm for
general networks based on our silent-stabilizing DFS tree. The complexities of
this token circulation algorithm are comparable to the known ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0391</identifier>
 <datestamp>2015-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0391</id><created>2014-08-02</created><updated>2015-11-02</updated><authors><author><keyname>W&#xe4;hlisch</keyname><forenames>Matthias</forenames></author><author><keyname>Schmidt</keyname><forenames>Robert</forenames></author><author><keyname>Schmidt</keyname><forenames>Thomas C.</forenames></author><author><keyname>Maennel</keyname><forenames>Olaf</forenames></author><author><keyname>Uhlig</keyname><forenames>Steve</forenames></author><author><keyname>Tyson</keyname><forenames>Gareth</forenames></author></authors><title>RiPKI: The Tragic Story of RPKI Deployment in the Web Ecosystem</title><categories>cs.NI cs.CR</categories><comments>Previous arXiv version of this paper has been published under the
  title &quot;When BGP Security Meets Content Deployment: Measuring and Analysing
  RPKI-Protection of Websites&quot;, Proc. of Fourteenth ACM Workshop on Hot Topics
  in Networks (HotNets), New York:ACM, 2015</comments><proxy>Matthias W\&quot;ahlisch</proxy><acm-class>C.2.2, C.2.5</acm-class><doi>10.1145/2834050.2834102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web content delivery is one of the most important services on the Internet.
Access to websites is typically secured via TLS. However, this security model
does not account for prefix hijacking on the network layer, which may lead to
traffic blackholing or transparent interception. Thus, to achieve comprehensive
security and service availability, additional protective mechanisms are
necessary such as the RPKI, a recently deployed Resource Public Key
Infrastructure to prevent hijacking of traffic by networks. This paper argues
two positions. First, that modern web hosting practices make route protection
challenging due to the propensity to spread servers across many different
networks, often with unpredictable client redirection strategies, and, second,
that we need a better understanding why protection mechanisms are not deployed.
To initiate this, we empirically explore the relationship between web hosting
infrastructure and RPKI deployment. Perversely, we find that less popular
websites are more likely to be secured than the prominent sites. Worryingly, we
find many large-scale CDNs do not support RPKI, thus making their customers
vulnerable. This leads us to explore business reasons why operators are
hesitant to deploy RPKI, which may help to guide future research on improving
Internet security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0393</identifier>
 <datestamp>2015-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0393</id><created>2014-08-02</created><authors><author><keyname>Mattson</keyname><forenames>Tim</forenames><affiliation>Intel Corporation</affiliation></author><author><keyname>Bader</keyname><forenames>David</forenames><affiliation>Georgia Institute of Technology</affiliation></author><author><keyname>Berry</keyname><forenames>Jon</forenames><affiliation>Sandia National Laboratory</affiliation></author><author><keyname>Buluc</keyname><forenames>Aydin</forenames><affiliation>Lawrence Berkeley National Laboratory</affiliation></author><author><keyname>Dongarra</keyname><forenames>Jack</forenames><affiliation>University of Tennessee</affiliation></author><author><keyname>Faloutsos</keyname><forenames>Christos</forenames><affiliation>Carnegie Melon University</affiliation></author><author><keyname>Feo</keyname><forenames>John</forenames><affiliation>Pacific Northwest National Laboratory</affiliation></author><author><keyname>Gilbert</keyname><forenames>John</forenames><affiliation>University of California at Santa Barbara</affiliation></author><author><keyname>Gonzalez</keyname><forenames>Joseph</forenames><affiliation>University of California at Berkeley</affiliation></author><author><keyname>Hendrickson</keyname><forenames>Bruce</forenames><affiliation>Sandia National Laboratory</affiliation></author><author><keyname>Kepner</keyname><forenames>Jeremy</forenames><affiliation>Massachusetts Institute of Technology</affiliation></author><author><keyname>Leiserson</keyname><forenames>Charles</forenames><affiliation>Massachusetts Institute of Technology</affiliation></author><author><keyname>Lumsdaine</keyname><forenames>Andrew</forenames><affiliation>Indiana University</affiliation></author><author><keyname>Padua</keyname><forenames>David</forenames><affiliation>University of Illinois at Urbana-Champaign</affiliation></author><author><keyname>Poole</keyname><forenames>Stephen</forenames><affiliation>Oak Ridge National Laboratory</affiliation></author><author><keyname>Reinhardt</keyname><forenames>Steve</forenames><affiliation>Cray Corporation</affiliation></author><author><keyname>Stonebraker</keyname><forenames>Mike</forenames><affiliation>Massachusetts Institute of Technology</affiliation></author><author><keyname>Wallach</keyname><forenames>Steve</forenames><affiliation>Convey Corporation</affiliation></author><author><keyname>Yoo</keyname><forenames>Andrew</forenames><affiliation>Lawrence Livermore National Laboratory</affiliation></author></authors><title>Standards for Graph Algorithm Primitives</title><categories>cs.MS cs.DM cs.DS</categories><comments>2 pages, IEEE HPEC 2013</comments><doi>10.1109/HPEC.2013.6670338</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is our view that the state of the art in constructing a large collection
of graph algorithms in terms of linear algebraic operations is mature enough to
support the emergence of a standard set of primitive building blocks. This
paper is a position paper defining the problem and announcing our intention to
launch an open effort to define this standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0395</identifier>
 <datestamp>2014-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0395</id><created>2014-08-02</created><updated>2014-11-27</updated><authors><author><keyname>Feldotto</keyname><forenames>Matthias</forenames></author><author><keyname>Scheideler</keyname><forenames>Christian</forenames></author><author><keyname>Graffi</keyname><forenames>Kalman</forenames></author></authors><title>HSkip+: A Self-Stabilizing Overlay Network for Nodes with Heterogeneous
  Bandwidths</title><categories>cs.DC cs.DS cs.NI</categories><comments>This is a long version of a paper published by IEEE in the
  Proceedings of the 14-th IEEE International Conference on Peer-to-Peer
  Computing</comments><doi>10.1109/P2P.2014.6934300</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present and analyze HSkip+, a self-stabilizing overlay
network for nodes with arbitrary heterogeneous bandwidths. HSkip+ has the same
topology as the Skip+ graph proposed by Jacob et al. [PODC 2009] but its
self-stabilization mechanism significantly outperforms the self-stabilization
mechanism proposed for Skip+. Also, the nodes are now ordered according to
their bandwidths and not according to their identifiers. Various other
solutions have already been proposed for overlay networks with heterogeneous
bandwidths, but they are not self-stabilizing. In addition to HSkip+ being
self-stabilizing, its performance is on par with the best previous bounds on
the time and work for joining or leaving a network of peers of logarithmic
diameter and degree and arbitrary bandwidths. Also, the dilation and congestion
for routing messages is on par with the best previous bounds for such networks,
so that HSkip+ combines the advantages of both worlds. Our theoretical
investigations are backed by simulations demonstrating that HSkip+ is indeed
performing much better than Skip+ and working correctly under high churn rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0399</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0399</id><created>2014-08-02</created><updated>2014-08-08</updated><authors><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>A Direct Coupling Coherent Quantum Observer</title><categories>quant-ph cs.SY math.OC</categories><comments>A version of this paper will appear in the Proceedings of the 2014
  IEEE Multi-conference on Systems and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of constructing a direct coupling quantum
observer for a closed linear quantum system. The proposed observer is shown to
be able to estimate some but not all of the plant variables in a time averaged
sense. A simple example and simulations are included to illustrate the
properties of the observer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0406</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0406</id><created>2014-08-02</created><updated>2014-08-19</updated><authors><author><keyname>Farajtabar</keyname><forenames>Mehrdad</forenames></author><author><keyname>Du</keyname><forenames>Nan</forenames></author><author><keyname>Rodriguez</keyname><forenames>Manuel Gomez</forenames></author><author><keyname>Valera</keyname><forenames>Isabel</forenames></author><author><keyname>Zha</keyname><forenames>Hongyuan</forenames></author><author><keyname>Song</keyname><forenames>Le</forenames></author></authors><title>Shaping Social Activity by Incentivizing Users</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Events in an online social network can be categorized roughly into endogenous
events, where users just respond to the actions of their neighbors within the
network, or exogenous events, where users take actions due to drives external
to the network. How much external drive should be provided to each user, such
that the network activity can be steered towards a target state? In this paper,
we model social events using multivariate Hawkes processes, which can capture
both endogenous and exogenous event intensities, and derive a time dependent
linear relation between the intensity of exogenous events and the overall
network activity. Exploiting this connection, we develop a convex optimization
framework for determining the required level of external drive in order for the
network to reach a desired activity level. We experimented with event data
gathered from Twitter, and show that our method can steer the activity of the
network more accurately than alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0407</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0407</id><created>2014-08-02</created><authors><author><keyname>Yu</keyname><forenames>Bei</forenames></author><author><keyname>Roy</keyname><forenames>Subhendu</forenames></author><author><keyname>Gao</keyname><forenames>Jhih-Rong</forenames></author><author><keyname>Pan</keyname><forenames>David Z.</forenames></author></authors><title>Triple Patterning Lithography (TPL) Layout Decomposition using
  End-Cutting (JM3 Special Session)</title><categories>cs.OH</categories><comments>J. Micro/Nanolith. MEMS MOEMS 14(1) XXXXXX (Jan-Mar 2015). arXiv
  admin note: text overlap with arXiv:1402.2425</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Triple patterning lithography (TPL) is one of the most promising techniques
in the 14nm logic node and beyond. Conventional LELELE type TPL technology
suffers from native conflict and overlapping problems. Recently, as an
alternative process, triple patterning lithography with end cutting (LELE-EC)
was proposed to overcome the limitations of LELELE manufacturing. In LELE-EC
process the first two masks are LELE type double patterning, while the third
mask is used to generate the end-cuts. Although the layout decomposition
problem for LELELE has been well-studied in the literature, only few attempts
have been made to address the LELE-EC layout decomposition problem. In this
paper we propose the comprehensive study for LELE-EC layout decomposition.
Conflict graph and end-cut graph are constructed to extract all the geometrical
relationships of both input layout and end-cut candidates. Based on these
graphs, integer linear programming (ILP) is formulated to minimize the conflict
number and the stitch number. The experimental results demonstrate the
effectiveness of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0409</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0409</id><created>2014-08-02</created><authors><author><keyname>Parter</keyname><forenames>Merav</forenames></author></authors><title>Vertex Fault Tolerant Additive Spanners</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A {\em fault-tolerant} structure for a network is required to continue
functioning following the failure of some of the network's edges or vertices.
In this paper, we address the problem of designing a {\em fault-tolerant}
additive spanner, namely, a subgraph $H$ of the network $G$ such that
subsequent to the failure of a single vertex, the surviving part of $H$ still
contains an \emph{additive} spanner for (the surviving part of) $G$, satisfying
$dist(s,t,H\setminus \{v\}) \leq dist(s,t,G\setminus \{v\})+\beta$ for every
$s,t,v \in V$. Recently, the problem of constructing fault-tolerant additive
spanners resilient to the failure of up to $f$ \emph{edges} has been considered
by Braunschvig et. al. The problem of handling \emph{vertex} failures was left
open therein. In this paper we develop new techniques for constructing additive
FT-spanners overcoming the failure of a single vertex in the graph. Our first
result is an FT-spanner with additive stretch $2$ and $\widetilde{O}(n^{5/3})$
edges. Our second result is an FT-spanner with additive stretch $6$ and
$\widetilde{O}(n^{3/2})$ edges. The construction algorithm consists of two main
components: (a) constructing an FT-clustering graph and (b) applying a modified
path-buying procedure suitably adopted to failure prone settings. Finally, we
also describe two constructions for {\em fault-tolerant multi-source additive
spanners}, aiming to guarantee a bounded additive stretch following a vertex
failure, for every pair of vertices in $S \times V$ for a given subset of
sources $S\subseteq V$. The additive stretch bounds of our constructions are 4
and 8 (using a different number of edges).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0427</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0427</id><created>2014-08-02</created><authors><author><keyname>Fujihara</keyname><forenames>Akihiro</forenames></author><author><keyname>Miwa</keyname><forenames>Hiroyoshi</forenames></author></authors><title>Homesick L\'evy walk: A mobility model having Ichi-go Ichi-e and
  scale-free properties of human encounters</title><categories>physics.soc-ph cs.SI</categories><comments>8 pages, 10 figures</comments><doi>10.1109/COMPSAC.2014.81</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, mobility models have been reconsidered based on findings by
analyzing some big datasets collected by GPS sensors, cellphone call records,
and Geotagging. To understand the fundamental statistical properties of the
frequency of serendipitous human encounters, we conducted experiments to
collect long-term data on human contact using short-range wireless
communication devices which many people frequently carry in daily life. By
analyzing the data we showed that the majority of human encounters occur
once-in-an-experimental-period: they are Ichi-go Ichi-e. We also found that the
remaining more frequent encounters obey a power-law distribution: they are
scale-free. To theoretically find the origin of these properties, we introduced
as a minimal human mobility model, Homesick L\'evy walk, where the walker
stochastically selects moving long distances as well as L\'evy walk or
returning back home. Using numerical simulations and a simple mean-field
theory, we offer a theoretical explanation for the properties to validate the
mobility model. The proposed model is helpful for evaluating long-term
performance of routing protocols in delay tolerant networks and mobile
opportunistic networks better since some utility-based protocols select nodes
with frequent encounters for message transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0442</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0442</id><created>2014-08-02</created><authors><author><keyname>Oren</keyname><forenames>Joel</forenames></author><author><keyname>Filmus</keyname><forenames>Yuval</forenames></author><author><keyname>Zick</keyname><forenames>Yair</forenames></author><author><keyname>Bachrach</keyname><forenames>Yoram</forenames></author></authors><title>Power Distribution in Randomized Weighted Voting: the Effects of the
  Quota</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Shapley value in weighted voting games. The Shapley value has
been used as an index for measuring the power of individual agents in
decision-making bodies and political organizations, where decisions are made by
a majority vote process. We characterize the impact of changing the quota
(i.e., the minimum number of seats in the parliament that are required to form
a coalition) on the Shapley values of the agents. Contrary to previous studies,
which assumed that the agent weights (corresponding to the size of a caucus or
a political party) are fixed, we analyze new domains in which the weights are
stochastically generated, modelling, for example, elections processes.
  We examine a natural weight generation process: the Balls and Bins model,
with uniform as well as exponentially decaying probabilities. We also analyze
weights that admit a super-increasing sequence, answering several open
questions pertaining to the Shapley values in such games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0445</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0445</id><created>2014-08-02</created><authors><author><keyname>Pan</keyname><forenames>Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Heng-Liang</forenames></author><author><keyname>Qi</keyname><forenames>Jie</forenames></author></authors><title>The physical limit of logical compare operation</title><categories>physics.data-an cond-mat.stat-mech cs.CC</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper two connected Szilard single molecule engines (with different
temperature) model of Maxwell's demon are used to demonstrate and analysis the
logical compare operation. The logical and physical complexity of compare
operations are both showed to be kTln2. Then this limit was used to prove the
time complexity lower bound of sorting problem. It confirmed the proposed way
to measure the complexity of a problem, provided another evidence of the
equivalence between information theoretical and thermodynamic entropies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0451</identifier>
 <datestamp>2015-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0451</id><created>2014-08-02</created><updated>2015-02-24</updated><authors><author><keyname>Glen</keyname><forenames>Amy</forenames></author><author><keyname>Lev&#xe9;</keyname><forenames>Florence</forenames></author></authors><title>Generalized trapezoidal words</title><categories>math.CO cs.DM</categories><comments>Major revision</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The factor complexity function $C_w(n)$ of a finite or infinite word $w$
counts the number of distinct factors of $w$ of length $n$ for each $n \ge 0$.
A finite word $w$ of length $|w|$ is said to be trapezoidal if the graph of its
factor complexity $C_w(n)$ as a function of $n$ (for $0 \leq n \leq |w|$) is
that of a regular trapezoid (or possibly an isosceles triangle); that is,
$C_w(n)$ increases by 1 with each $n$ on some interval of length $r$, then
$C_w(n)$ is constant on some interval of length $s$, and finally $C_w(n)$
decreases by 1 with each $n$ on an interval of the same length $r$. Necessarily
$C_w(1)=2$ (since there is one factor of length $0$, namely the empty word), so
any trapezoidal word is on a binary alphabet. Trapezoidal words were first
introduced by de Luca (1999) when studying the behaviour of the factor
complexity of finite Sturmian words, i.e., factors of infinite &quot;cutting
sequences&quot;, obtained by coding the sequence of cuts in an integer lattice over
the positive quadrant of $\mathbb{R}^2$ made by a line of irrational slope.
Every finite Sturmian word is trapezoidal, but not conversely. However, both
families of words (trapezoidal and Sturmian) are special classes of so-called
&quot;rich words&quot; (also known as &quot;full words&quot;) - a wider family of finite and
infinite words characterized by containing the maximal number of palindromes -
studied in depth by the first author and others in 2009.
  In this paper, we introduce a natural generalization of trapezoidal words
over an arbitrary finite alphabet $\mathcal{A}$, called generalized trapezoidal
words (or GT-words for short). In particular, we study combinatorial and
structural properties of this new class of words, and we show that, unlike the
binary case, not all GT-words are rich in palindromes when $|\mathcal{A}| \geq
3$, but we can describe all those that are rich.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0452</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0452</id><created>2014-08-02</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Geetha</keyname><forenames>A. P.</forenames></author><author><keyname>Asharani</keyname></author></authors><title>Methodology For Detection of QRS Pattern Using Secondary Wavelets</title><categories>cs.CV</categories><comments>3 pages, 8 figures,Systemics, Cybernetics and Informatics
  (ICSCI)2012, International Conference on pp.327,330, Dr.MCR HRD Institute,
  Hyderabad, India, 15-18Feb 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applications of wavelet transform to the field of health care signals have
paved the way for implementing revolutionary approaches in detecting the
presence of certain abnormalities in human health patterns. There were
extensive studies carried out using primary wavelets in various signals like
Electrocardiogram (ECG), sonogram etc. with a certain amount of success. On the
other hand analysis using secondary wavelets which inherits the characteristics
of a set of variations available in signals like ECG can be a promise to detect
diseases with ease. Here a method to create a generalized adapted wavelet is
presented which contains the information of QRS pattern collected from an
anomaly sample space. The method has been tested and found to be successful in
locating the position of R peak in noise embedded ECG signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0453</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0453</id><created>2014-08-02</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Geetha</keyname><forenames>A. P.</forenames></author><author><keyname>Asharani</keyname><forenames>M.</forenames></author></authors><title>Adaptive Wavelet Based Identification and Extraction of PQRST
  Combination in Randomly Stretching ECG Sequence</title><categories>cs.CV</categories><comments>Signal and Information Processing (SIP), 2013 IEEE China Summit &amp;
  International Conference on, pp.278,282,Beijing, China, 6-10 July. 2013</comments><doi>10.1109/ChinaSIP.2013.6625344</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cardiovascular system study using ECG signals have evolved tremendously in
the domain of electronics and signal processing. However, there are certain
floating challenges unresolved in the analysis and detection of abnormal
performances of cardiovascular system. As the medical field is moving towards
more automated and intelligent systems, wrong detection or wrong
interpretations of ECG waveform of abnormal conditions can be quite fatal.
Since the PQRST signals vary their positions randomly, the process of locating,
identifying and classifying each feature can be cumbersome and it is prone to
errors. Here we present an automated scheme using adaptive wavelet to detect
prominent R-peak with extreme accuracy and algorithmically tag and mark the
coexisting peaks P, Q, S, and T with almost same accuracy. The adaptive wavelet
approach used in this scheme is capable of detecting R-peak in ECG with 99.99%
accuracy along with the rest of the waveforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0455</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0455</id><created>2014-08-03</created><authors><author><keyname>Sun</keyname><forenames>Liang</forenames></author><author><keyname>Lei</keyname><forenames>Ming</forenames></author></authors><title>Quantized CSI-Based Tomlinson-Harashima Precoding in Multiuser MIMO
  Systems</title><categories>cs.IT math.IT</categories><comments>22 pages, 4 figures, IEEE Transactions on Wireless Communications,
  Vol. 12, No. 3, March 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the implementation of Tomlinson-Harashima (TH) precoding
for multiuser MIMO systems based on quantized channel state information (CSI)
at the transmitter side. Compared with the results in [1], our scheme applies
to more general system setting where the number of users in the system can be
less than or equal to the number of transmit antennas. We also study the
achievable average sum rate of the proposed quantized CSI-based TH precoding
scheme. The expressions of the upper bounds on both the average sum rate of the
systems with quantized CSI and the mean loss in average sum rate due to CSI
quantization are derived. We also present some numerical results. The results
show that the nonlinear TH precoding can achieve much better performance than
that of linear zero-forcing precoding for both perfect CSI and quantized CSI
cases. In addition, our derived upper bound on the mean rate loss for TH
precoding converges to the true rate loss faster than that of zeroforcing
precoding obtained in [2] as the number of feedback bits becomes large. Both
the analytical and numerical results show that nonlinear precoding suffers from
imperfect CSI more than linear precoding does.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0467</identifier>
 <datestamp>2014-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0467</id><created>2014-08-03</created><updated>2014-08-26</updated><authors><author><keyname>Takabatake</keyname><forenames>Yoshimasa</forenames></author><author><keyname>Tabei</keyname><forenames>Yasuo</forenames></author><author><keyname>Sakamoto</keyname><forenames>Hiroshi</forenames></author></authors><title>Online Pattern Matching for String Edit Distance with Moves</title><categories>cs.DS</categories><comments>This paper has been accepted to the 21st edition of the International
  Symposium on String Processing and Information Retrieval (SPIRE2014)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Edit distance with moves (EDM) is a string-to-string distance measure that
includes substring moves in addition to ordinal editing operations to turn one
string to the other. Although optimizing EDM is intractable, it has many
applications especially in error detections. Edit sensitive parsing (ESP) is an
efficient parsing algorithm that guarantees an upper bound of parsing
discrepancies between different appearances of the same substrings in a string.
ESP can be used for computing an approximate EDM as the L1 distance between
characteristic vectors built by node labels in parsing trees. However, ESP is
not applicable to a streaming text data where a whole text is unknown in
advance. We present an online ESP (OESP) that enables an online pattern
matching for EDM. OESP builds a parse tree for a streaming text and computes
the L1 distance between characteristic vectors in an online manner. For the
space-efficient computation of EDM, OESP directly encodes the parse tree into a
succinct representation by leveraging the idea behind recent results of a
dynamic succinct tree. We experimentally test OESP on the ability to compute
EDM in an online manner on benchmark datasets, and we show OESP's efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0469</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0469</id><created>2014-08-03</created><authors><author><keyname>Sun</keyname><forenames>Liang</forenames></author><author><keyname>McKay</keyname><forenames>Matthew R.</forenames></author></authors><title>Tomlinson-Harashima Precoding for Multiuser MIMO Systems with Quantized
  CSI Feedback and User Scheduling</title><categories>cs.IT math.IT</categories><comments>13 pages, 4 figures, IEEE Trans. Signal Process., Aug. 2014</comments><doi>10.1109/TSP.2014.2336633</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the sum rate performance of a low complexity quantized
CSI-based Tomlinson-Harashima (TH) precoding scheme for downlink multiuser MIMO
tansmission, employing greedy user selection. The asymptotic distribution of
the output signal to interference plus noise ratio of each selected user and
the asymptotic sum rate as the number of users K grows large are derived by
using extreme value theory. For fixed finite signal to noise ratios and a
finite number of transmit antennas $n_T$, we prove that as K grows large, the
proposed approach can achieve the optimal sum rate scaling of the MIMO
broadcast channel. We also prove that, if we ignore the precoding loss, the
average sum rate of this approach converges to the average sum capacity of the
MIMO broadcast channel. Our results provide insights into the effect of
multiuser interference caused by quantized CSI on the multiuser diversity gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0474</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0474</id><created>2014-08-03</created><authors><author><keyname>Ricciato</keyname><forenames>Fabio</forenames></author></authors><title>Time to timestamp: opportunistic cooperative localization from reception
  time measurements</title><categories>cs.NI</categories><comments>This work is currently under review for a IEEE magazine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general framework for improving and extending GNSS-based
positioning by leveraging opportunistic measurements from legacy terrestrial
radio signals. The proposed approach requires only that participating nodes
collect and share reception timestamps of incoming packets and/or other
reference signals transmitted by other fixed or mobile nodes, with no need of
inter-node synchronization. The envisioned scheme couples the idea of
cooperative GNSS augmentation with recent pioneering work in the field of
time-based localization in asynchronous networks. In this contribution we
present the fundamental principles of the proposed approach and discuss the
system-level aspects that make it particularly appealing and timely for
Cooperative ITS applications, with the goal of motivating further research and
experimentation in this direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0482</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0482</id><created>2014-08-03</created><authors><author><keyname>Hasan</keyname><forenames>Cengis</forenames></author><author><keyname>Gorce</keyname><forenames>Jean-Marie</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author></authors><title>Green Broadcast Transmission in Cellular Networks: A Game Theoretic
  Approach</title><categories>cs.NI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the mobile assignment problem in a multi-cell broadcast
transmission seeking minimal total power consumption by considering both
transmission and operational powers. While the large scale nature of the
problem entails to find distributed solutions, game theory appears to be a
natural tool. We propose a novel distributed algorithm based on group formation
games, called \textit{the hedonic decision algorithm}. This formalism is
constructive: a new class of group formation games is introduced where the
utility of players within a group is separable and symmetric being a
generalized version of parity-affiliation games. The proposed hedonic decision
algorithm is also suitable for any set-covering problem. To evaluate the
performance of our algorithm, we propose other approaches to which our
algorithm is compared. We first develop a centralized recursive algorithm
called \textit{the hold minimum} being able to find the optimal assignments.
However, because of the NP-hard complexity of the mobile assignment problem, we
propose a centralized polynomial-time heuristic algorithm called \textit{the
column control} producing near-optimal solutions when the operational power
costs of base stations are taken into account. Starting from this efficient
centralized approach, a \textit{distributed column control algorithm} is also
proposed and compared to \textit{the hedonic decision algorithm}. We also
implement the nearest base station algorithm which is very simple and intuitive
and efficiently manage fast-moving users served by macro BSs. Extensive
simulation results are provided and highlight the relative performance of these
algorithms. The simulated scenarios are done according to Poisson point
processes for both mobiles and base stations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0488</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0488</id><created>2014-08-03</created><updated>2014-08-09</updated><authors><author><keyname>Sen</keyname><forenames>Sandeep</forenames></author></authors><title>Improved Randomized Rounding using Random Walks</title><categories>cs.DS</categories><comments>The primary result claimed in this submission doesn't hold for random
  0-1 matrices of size $n^2 \times n$ which can be proved by a probabilistic
  method. For such matrices, the RT bound is tight</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a novel algorithm for rounding packing integer programs based on
multidimensional Brownian motion in $\mathbb{R}^n$. Starting from an optimal
fractional feasible solution $\bar{x}$, the procedure converges in polynomial
time to a distribution over (possibly infeasible) point set $P \subset {\{0,1
\}}^n$ such that the expected value of any linear objective function over $P$
equals the value at $\bar{x}$. This is an alternate approach to the classical
randomized rounding method of Raghavan and Thompson \cite{RT:87}.
  Our procedure is very general and in conjunction with discrepancy based
arguments, yield efficient alternate methods for rounding other optimization
problems that can be expressed as packing ILPs including disjoint path problems
and MISR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0490</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0490</id><created>2014-08-03</created><authors><author><keyname>Davis</keyname><forenames>Joshua</forenames></author></authors><title>Some Basic Radio System OPSEC Considerations</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is an unscientific introduction to basic radio frequency system OPSEC
aspects that I have found to be overlooked and lacking in high security system
deployments that may have benefited from them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0499</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0499</id><created>2014-08-03</created><authors><author><keyname>Beigi</keyname><forenames>Salman</forenames></author><author><keyname>Etesami</keyname><forenames>Omid</forenames></author><author><keyname>Gohari</keyname><forenames>Amin</forenames></author></authors><title>The Value of Help Bits in Randomized and Average-Case Complexity</title><categories>cs.CC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  &quot;Help bits&quot; are some limited trusted information about an instance or
instances of a computational problem that may reduce the computational
complexity of solving that instance or instances. In this paper, we study the
value of help bits in the settings of randomized and average-case complexity.
  Amir, Beigel, and Gasarch (1990) show that for constant $k$, if $k$ instances
of a decision problem can be efficiently solved using less than $k$ bits of
help, then the problem is in P/poly. We extend this result to the setting of
randomized computation: We show that the decision problem is in P/poly if using
$\ell$ help bits, $k$ instances of the problem can be efficiently solved with
probability greater than $2^{\ell-k}$. The same result holds if using less than
$k(1 - h(\alpha))$ help bits (where $h(\cdot)$ is the binary entropy function),
we can efficiently solve $(1-\alpha)$ fraction of the instances correctly with
non-vanishing probability. We also extend these two results to non-constant but
logarithmic $k$. In this case however, instead of showing that the problem is
in P/poly we show that it satisfies &quot;$k$-membership comparability,&quot; a notion
known to be related to solving $k$ instances using less than $k$ bits of help.
  Next we consider the setting of average-case complexity: Assume that we can
solve $k$ instances of a decision problem using some help bits whose entropy is
less than $k$ when the $k$ instances are drawn independently from a particular
distribution. Then we can efficiently solve an instance drawn from that
distribution with probability better than $1/2$.
  Finally, we show that in the case where $k$ is super-logarithmic, assuming
$k$-membership comparability of a decision problem, one cannot prove that the
problem is in P/poly by a &quot;black-box proof.&quot;
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0500</identifier>
 <datestamp>2015-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0500</id><created>2014-08-03</created><updated>2015-01-25</updated><authors><author><keyname>Zheng</keyname><forenames>Da</forenames></author><author><keyname>Mhembere</keyname><forenames>Disa</forenames></author><author><keyname>Burns</keyname><forenames>Randal</forenames></author><author><keyname>Vogelstein</keyname><forenames>Joshua</forenames></author><author><keyname>Priebe</keyname><forenames>Carey E.</forenames></author><author><keyname>Szalay</keyname><forenames>Alexander S.</forenames></author></authors><title>FlashGraph: Processing Billion-Node Graphs on an Array of Commodity SSDs</title><categories>cs.DC</categories><comments>published in FAST'15</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph analysis performs many random reads and writes, thus, these workloads
are typically performed in memory. Traditionally, analyzing large graphs
requires a cluster of machines so the aggregate memory exceeds the graph size.
We demonstrate that a multicore server can process graphs with billions of
vertices and hundreds of billions of edges, utilizing commodity SSDs with
minimal performance loss. We do so by implementing a graph-processing engine on
top of a user-space SSD file system designed for high IOPS and extreme
parallelism. Our semi-external memory graph engine called FlashGraph stores
vertex state in memory and edge lists on SSDs. It hides latency by overlapping
computation with I/O. To save I/O bandwidth, FlashGraph only accesses edge
lists requested by applications from SSDs; to increase I/O throughput and
reduce CPU overhead for I/O, it conservatively merges I/O requests. These
designs maximize performance for applications with different I/O
characteristics. FlashGraph exposes a general and flexible vertex-centric
programming interface that can express a wide variety of graph algorithms and
their optimizations. We demonstrate that FlashGraph in semi-external memory
performs many algorithms with performance up to 80% of its in-memory
implementation and significantly outperforms PowerGraph, a popular distributed
in-memory graph engine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0501</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0501</id><created>2014-08-03</created><authors><author><keyname>Aquino</keyname><forenames>Andr&#xe9; L. L.</forenames></author><author><keyname>Junior</keyname><forenames>Orlando S.</forenames></author><author><keyname>Frery</keyname><forenames>Alejandro C.</forenames></author><author><keyname>de Albuquerque</keyname><forenames>&#xc9;dler Lins</forenames></author><author><keyname>Mini</keyname><forenames>Raquel A. F.</forenames></author></authors><title>MuSA: Multivariate Sampling Algorithm for Wireless Sensor Networks</title><categories>cs.DC cs.NI</categories><journal-ref>IEEE Transactions on Computers, pages 968--978, volume 53, number
  4, April 2014</journal-ref><doi>10.1109/TC.2012.229</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wireless sensor network can be used to collect and process environmental
data, which is often of multivariate nature. This work proposes a multivariate
sampling algorithm based on component analysis techniques in wireless sensor
networks. To improve the sampling, the algorithm uses component analysis
techniques to rank the data. Once ranked, the most representative data is
retained. Simulation results show that our technique reduces the data keeping
its representativeness. In addition, the energy consumption and delay to
deliver the data on the network are reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0510</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0510</id><created>2014-08-03</created><authors><author><keyname>Naldi</keyname><forenames>Maurizio</forenames></author></authors><title>A note on &quot;The Need for End-to-End Evaluation of Cloud Availability&quot;</title><categories>cs.DC</categories><comments>8 pages, 1 figure</comments><acm-class>C.4; H.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud availability is a major performance parameter for cloud platforms, but
there are very few measurements on commercial platforms, and most of them rely
on outage reports as appeared on specialized sites, providers' dashboards, or
the general press. A paper recently presented at the PAM 2014 conference by Hu
et alii reports the results of a measurement campaign. In this note, the
results of that paper are summarized, highlighting sources of inaccuracy and
some possible improvements. In particular, the use of a low probing frequency
could lead to non detection of short outages, as well as to an inaccurate
estimation of the outage duration statistics. Overcoming this lack of accuracy
is relevant to properly assess SLA violations and establish the basis for
insurance claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0517</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0517</id><created>2014-08-03</created><authors><author><keyname>Gadepally</keyname><forenames>Vijay</forenames></author><author><keyname>Kepner</keyname><forenames>Jeremy</forenames></author></authors><title>Big Data Dimensional Analysis</title><categories>cs.DB cs.DC</categories><comments>From IEEE HPEC 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to collect and analyze large amounts of data is a growing problem
within the scientific community. The growing gap between data and users calls
for innovative tools that address the challenges faced by big data volume,
velocity and variety. One of the main challenges associated with big data
variety is automatically understanding the underlying structures and patterns
of the data. Such an understanding is required as a pre-requisite to the
application of advanced analytics to the data. Further, big data sets often
contain anomalies and errors that are difficult to know a priori. Current
approaches to understanding data structure are drawn from the traditional
database ontology design. These approaches are effective, but often require too
much human involvement to be effective for the volume, velocity and variety of
data encountered by big data systems. Dimensional Data Analysis (DDA) is a
proposed technique that allows big data analysts to quickly understand the
overall structure of a big dataset, determine anomalies. DDA exploits
structures that exist in a wide class of data to quickly determine the nature
of the data and its statical anomalies. DDA leverages existing schemas that are
employed in big data databases today. This paper presents DDA, applies it to a
number of data sets, and measures its performance. The overhead of DDA is low
and can be applied to existing big data systems without greatly impacting their
computing requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0521</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0521</id><created>2014-08-03</created><authors><author><keyname>Gadepally</keyname><forenames>Vijay</forenames></author><author><keyname>Krishnamurthy</keyname><forenames>Ashok</forenames></author><author><keyname>Ozguner</keyname><forenames>Umit</forenames></author></authors><title>A Hands-on Education Program on Cyber Physical Systems for High School
  Students</title><categories>cs.CY cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyber Physical Systems (CPS) are the conjoining of an entities' physical and
computational elements. The development of a typical CPS system follows a
sequence from conceptual modeling, testing in simulated (virtual) worlds,
testing in controlled (possibly laboratory) environments and finally
deployment. Throughout each (repeatable) stage, the behavior of the physical
entities, the sensing and situation assessment, and the computation and control
options have to be understood and carefully represented through abstraction.
  The CPS Group at the Ohio State University, as part of an NSF funded CPS
project on &quot;Autonomous Driving in Mixed Environments&quot;, has been developing CPS
related educational activities at the K-12, undergraduate and graduate levels.
The aim of these educational activities is to train students in the principles
and design issues in CPS and to broaden the participation in science and
engineering. The project team has a strong commitment to impact STEM education
across the entire K-20 community.
  In this paper, we focus on the K-12 community and present a two-week Summer
Program for high school juniors and seniors that introduces them to the
principles of CPS design and walks them through several of the design steps. We
also provide an online repository that aids CPS researchers in providing a
similar educational experience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0528</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0528</id><created>2014-08-03</created><updated>2014-08-04</updated><authors><author><keyname>Huang</keyname><forenames>Xiaocheng</forenames></author><author><keyname>Bao</keyname><forenames>Zhuowei</forenames></author><author><keyname>Davidson</keyname><forenames>Susan B.</forenames></author><author><keyname>Milo</keyname><forenames>Tova</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojie</forenames></author></authors><title>Answering Regular Path Queries on Workflow Provenance</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a novel approach for efficiently evaluating regular path
queries over provenance graphs of workflows that may include recursion. The
approach assumes that an execution g of a workflow G is labeled with
query-agnostic reachability labels using an existing technique. At query time,
given g, G and a regular path query R, the approach decomposes R into a set of
subqueries R1, ..., Rk that are safe for G. For each safe subquery Ri, G is
rewritten so that, using the reachability labels of nodes in g, whether or not
there is a path which matches Ri between two nodes can be decided in constant
time. The results of each safe subquery are then composed, possibly with some
small unsafe remainder, to produce an answer to R. The approach results in an
algorithm that significantly reduces the number of subqueries k over existing
techniques by increasing their size and complexity, and that evaluates each
subquery in time bounded by its input and output size. Experimental results
demonstrate the benefit of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0531</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0531</id><created>2014-08-03</created><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Patel</keyname><forenames>Viresh</forenames></author></authors><title>Parameterized TSP: Beating the Average</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Travelling Salesman Problem (TSP), we are given a complete graph $K_n$
together with an integer weighting $w$ on the edges of $K_n$, and we are asked
to find a Hamilton cycle of $K_n$ of minimum weight. Let $h(w)$ denote the
average weight of a Hamilton cycle of $K_n$ for the weighting $w$. Vizing
(1973) asked whether there is a polynomial-time algorithm which always finds a
Hamilton cycle of weight at most $h(w)$. He answered this question in the
affirmative and subsequently Rublineckii (1973) and others described several
other TSP heuristics satisfying this property. In this paper, we prove a
considerable generalisation of Vizing's result: for each fixed $k$, we give an
algorithm that decides whether, for any input edge weighting $w$ of $K_n$,
there is a Hamilton cycle of $K_n$ of weight at most $h(w)-k$ (and constructs
such a cycle if it exists). For $k$ fixed, the running time of the algorithm is
polynomial in $n$, where the degree of the polynomial does not depend on $k$
(i.e., the generalised Vizing problem is fixed-parameter tractable with respect
to the parameter $k$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0532</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0532</id><created>2014-08-03</created><authors><author><keyname>Cerone</keyname><forenames>Vito</forenames></author><author><keyname>Lasserre</keyname><forenames>Jean-Bernard</forenames></author><author><keyname>Piga</keyname><forenames>Dario</forenames></author><author><keyname>Regruto</keyname><forenames>Diego</forenames></author></authors><title>A unified framework for solving a general class of conditional and
  robust set-membership estimation problems</title><categories>cs.SY math.OC</categories><comments>Accpeted for publication in the IEEE Transactions on Automatic
  Control (2014)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a unified framework for solving a general class of
problems arising in the context of set-membership estimation/identification
theory. More precisely, the paper aims at providing an original approach for
the computation of optimal conditional and robust projection estimates in a
nonlinear estimation setting where the operator relating the data and the
parameter to be estimated is assumed to be a generic multivariate polynomial
function and the uncertainties affecting the data are assumed to belong to
semialgebraic sets. By noticing that the computation of both the conditional
and the robust projection optimal estimators requires the solution to min-max
optimization problems that share the same structure, we propose a unified
two-stage approach based on semidefinite-relaxation techniques for solving such
estimation problems. The key idea of the proposed procedure is to recognize
that the optimal functional of the inner optimization problems can be
approximated to any desired precision by a multivariate polynomial function by
suitably exploiting recently proposed results in the field of parametric
optimization. Two simulation examples are reported to show the effectiveness of
the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0540</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0540</id><created>2014-08-03</created><updated>2014-08-14</updated><authors><author><keyname>Khawar</keyname><forenames>Awais</forenames></author><author><keyname>Abdelhadi</keyname><forenames>Ahmed</forenames></author><author><keyname>Clancy</keyname><forenames>T. Charles</forenames></author></authors><title>Target Detection Performance of Spectrum Sharing MIMO Radars</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE transactions. Distribution Statement A: Approved
  for public release; distribution is unlimited</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future wireless communication systems are envisioned to share radio frequency
(RF) spectrum, with other services such as radars, in order to meet the growing
spectrum demands. In this paper, we consider co-channel spectrum sharing
between cellular systems and radars. We address the problem of target detection
by radars that are subject to shape its waveform in a way that it does not
cause interference to cellular systems. We consider a multiple-input
multiple-output (MIMO) radar and a MIMO cellular communication system with $\mc
K$ base stations (BS). We propose a spectrum sharing algorithm which steers
radar nulls, by projecting radar waveform onto the null space of interference
channel, towards a `selected' BS, thus, protecting it from radar interference.
This BS is selected, among $\mc K$ BSs, on the basis of guaranteeing minimum
waveform degradation. We study target detection capabilities of this null-space
projected (NSP) waveform and compare it with the orthogonal waveform. We derive
the generalized likelihood ratio test (GLRT) for target detection and derive
detector statistic for NSP and orthogonal waveform. The target detection
performance for NSP and orthogonal waveform is studied theoretically and via
Monte Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0549</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0549</id><created>2014-08-03</created><updated>2015-03-15</updated><authors><author><keyname>Zhang</keyname><forenames>Xinchen</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Downlink Cellular Network Analysis with Multi-slope Path Loss Models</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing cellular network analyses, and even simulations, typically use the
standard path loss model where received power decays like $\|x\|^{-\alpha}$
over a distance $\|x\|$. This standard path loss model is quite idealized, and
in most scenarios the path loss exponent $\alpha$ is itself a function of
$\|x\|$, typically an increasing one. Enforcing a single path loss exponent can
lead to orders of magnitude differences in average received and interference
powers versus the true values. In this paper we study \emph{multi-slope} path
loss models, where different distance ranges are subject to different path loss
exponents. We focus on the dual-slope path loss function, which is a piece-wise
power law and continuous and accurately approximates many practical scenarios.
We derive the distributions of SIR, SNR, and finally SINR before finding the
potential throughput scaling, which provides insight on the observed
cell-splitting rate gain. The exact mathematical results show that the SIR
monotonically decreases with network density, while the converse is true for
SNR, and thus the network coverage probability in terms of SINR is maximized at
some finite density. With ultra-densification (network density goes to
infinity), there exists a \emph{phase transition} in the near-field path loss
exponent $\alpha_0$: if $\alpha_0 &gt;1$ unbounded potential throughput can be
achieved asymptotically; if $\alpha_0 &lt;1$, ultra-densification leads in the
extreme case to zero throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0553</identifier>
 <datestamp>2014-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0553</id><created>2014-08-03</created><updated>2014-12-16</updated><authors><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Ge</keyname><forenames>Rong</forenames></author><author><keyname>Janzamin</keyname><forenames>Majid</forenames></author></authors><title>Sample Complexity Analysis for Learning Overcomplete Latent Variable
  Models through Tensor Methods</title><categories>cs.LG math.PR stat.ML</categories><comments>Title changed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide guarantees for learning latent variable models emphasizing on the
overcomplete regime, where the dimensionality of the latent space can exceed
the observed dimensionality. In particular, we consider multiview mixtures,
spherical Gaussian mixtures, ICA, and sparse coding models. We provide tight
concentration bounds for empirical moments through novel covering arguments. We
analyze parameter recovery through a simple tensor power update algorithm. In
the semi-supervised setting, we exploit the label or prior information to get a
rough estimate of the model parameters, and then refine it using the tensor
method on unlabeled samples. We establish that learning is possible when the
number of components scales as $k=o(d^{p/2})$, where $d$ is the observed
dimension, and $p$ is the order of the observed moment employed in the tensor
method. Our concentration bound analysis also leads to minimax sample
complexity for semi-supervised learning of spherical Gaussian mixtures. In the
unsupervised setting, we use a simple initialization algorithm based on SVD of
the tensor slices, and provide guarantees under the stricter condition that
$k\le \beta d$ (where constant $\beta$ can be larger than $1$), where the
tensor method recovers the components under a polynomial running time (and
exponential in $\beta$). Our analysis establishes that a wide range of
overcomplete latent variable models can be learned efficiently with low
computational and sample complexity through tensor decomposition methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0557</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0557</id><created>2014-08-03</created><authors><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author><author><keyname>Su</keyname><forenames>Hsin-Hao</forenames></author></authors><title>Almost-Tight Distributed Minimum Cut Algorithms</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of computing the minimum cut in a weighted distributed
message-passing networks (the CONGEST model). Let $\lambda$ be the minimum cut,
$n$ be the number of nodes in the network, and $D$ be the network diameter. Our
algorithm can compute $\lambda$ exactly in $O((\sqrt{n} \log^{*} n+D)\lambda^4
\log^2 n)$ time. To the best of our knowledge, this is the first paper that
explicitly studies computing the exact minimum cut in the distributed setting.
Previously, non-trivial sublinear time algorithms for this problem are known
only for unweighted graphs when $\lambda\leq 3$ due to Pritchard and
Thurimella's $O(D)$-time and $O(D+n^{1/2}\log^* n)$-time algorithms for
computing $2$-edge-connected and $3$-edge-connected components.
  By using the edge sampling technique of Karger's, we can convert this
algorithm into a $(1+\epsilon)$-approximation $O((\sqrt{n}\log^{*}
n+D)\epsilon^{-5}\log^3 n)$-time algorithm for any $\epsilon&gt;0$. This improves
over the previous $(2+\epsilon)$-approximation $O((\sqrt{n}\log^{*}
n+D)\epsilon^{-5}\log^2 n\log\log n)$-time algorithm and
$O(\epsilon^{-1})$-approximation $O(D+n^{\frac{1}{2}+\epsilon}
\mathrm{poly}\log n)$-time algorithm of Ghaffari and Kuhn. Due to the lower
bound of $\Omega(D+n^{1/2}/\log n)$ by Das Sarma et al. which holds for any
approximation algorithm, this running time is tight up to a $ \mathrm{poly}\log
n$ factor.
  To get the stated running time, we developed an approximation algorithm which
combines the ideas of Thorup's algorithm and Matula's contraction algorithm. It
saves an $\epsilon^{-9}\log^{7} n$ factor as compared to applying Thorup's tree
packing theorem directly. Then, we combine Kutten and Peleg's tree partitioning
algorithm and Karger's dynamic programming to achieve an efficient distributed
algorithm that finds the minimum cut when we are given a spanning tree that
crosses the minimum cut exactly once.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0562</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0562</id><created>2014-08-03</created><authors><author><keyname>Shibata</keyname><forenames>Hiroyuki</forenames></author><author><keyname>Honjo</keyname><forenames>Toshimori</forenames></author><author><keyname>Shimizu</keyname><forenames>Kaoru</forenames></author></authors><title>Quantum key distribution over a 72 dB channel loss using ultralow dark
  count superconducting single-photon detectors</title><categories>quant-ph cond-mat.supr-con cs.CR physics.optics</categories><comments>6 pages, 3 figures, accepted for publication in Opt. Lett</comments><journal-ref>Optics Letters, Vol. 39, Issue 17, pp. 5078-5081 (2014)</journal-ref><doi>10.1364/OL.39.005078</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report the first Quantum key distribution (QKD) experiment over a 72 dB
channel loss using superconducting nanowire single-photon detectors (SSPD,
SNSPD) with the dark count rate (DCR) of 0.01 cps. The DCR of the SSPD, which
is dominated by the blackbody radiation at room temperature, is blocked by
introducing cold optical bandpass filter. We employ the differential phase
shift QKD (DPS-QKD) scheme with a 1 GHz system clock rate. The quantum bit
error rate (QBER) below 3 % is achieved when the length of the dispersion
shifted fiber (DSF) is 336 km (72 dB loss), which is low enough to generate
secure keys.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0570</identifier>
 <datestamp>2014-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0570</id><created>2014-08-03</created><updated>2014-12-22</updated><authors><author><keyname>Dong</keyname><forenames>Jie</forenames></author><author><keyname>Smith</keyname><forenames>David B.</forenames></author><author><keyname>Hanlen</keyname><forenames>Leif W.</forenames></author></authors><title>Co-channel Interference Mitigation for Wireless Body Area Networks
  Coexistence Using a Non-Cooperative Game</title><categories>cs.NI</categories><comments>This paper has been withdrawn due to significant revision requied</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we enable the coexistence of multiple wireless body area
networks (BANs) using a finite repeated non-cooperative game, in which BANs are
rational players but act selfishly. A game-theoretic based transmit power
control scheme employing a novel utility function is proposed to maximize each
network's packet delivery ratio (PDR) at low transmit power. The proposed
utility function penalizes players with high transmission power, which reduces
the interference caused to other coexisting BANs. Considering the purpose of
inter-BAN interference mitigation, PDR is expressed as a compressed exponential
function of inverse signal-to-interference-and-noise ratio (SINR), so it is
essentially a function of transmit powers of all coexisting BANs. It is proven
that a unique Nash Equilibrium (NE) exists and hence there is a subgame-perfect
equilibrium, considering best-response at each stage independent of history.
Realistic and extensive on- and inter-body channel models are employed. Results
confirm that the effectiveness of the proposed scheme in better interference
management, greater reliability and reduced transmit power, comparing with
other schemes commonly applied in BAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0573</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0573</id><created>2014-08-03</created><updated>2015-03-23</updated><authors><author><keyname>Vempaty</keyname><forenames>Aditya</forenames></author><author><keyname>Varshney</keyname><forenames>Lav R.</forenames></author></authors><title>The Non-Regular CEO Problem</title><categories>cs.IT math.IT</categories><comments>18 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the CEO problem for non-regular source distributions (such as
uniform or truncated Gaussian). A group of agents observe independently
corrupted versions of data and transmit coded versions over rate-limited links
to a CEO. The CEO then estimates the underlying data based on the received
coded observations. Agents are not allowed to convene before transmitting their
observations. This formulation is motivated by the practical problem of a
firm's CEO estimating (non-regular) beliefs about a sequence of events, before
acting on them. Agents' observations are modeled as jointly distributed with
the underlying data through a given conditional probability density function.
We study the asymptotic behavior of the minimum achievable mean squared error
distortion at the CEO in the limit when the number of agents $L$ and the sum
rate $R$ tend to infinity. We establish a $1/R^2$ convergence of the
distortion, an intermediate regime of performance between the exponential
behavior in discrete CEO problems [Berger, Zhang, and Viswanathan (1996)], and
the $1/R$ behavior in Gaussian CEO problems [Viswanathan and Berger (1997)].
Achievability is proved by a layered architecture with scalar quantization,
distributed entropy coding, and midrange estimation. The converse is proved
using the Bayesian Chazan-Zakai-Ziv bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0574</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0574</id><created>2014-08-03</created><authors><author><keyname>Sealfon</keyname><forenames>Adam</forenames></author><author><keyname>Sotiraki</keyname><forenames>Aikaterini</forenames></author></authors><title>Agreement in Partitioned Dynamic Networks</title><categories>cs.DC</categories><comments>A summary of these results will appear as a brief announcement in
  DISC 2014</comments><msc-class>68W15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the dynamic network model, the communication graph is assumed to be
connected in every round but is otherwise arbitrary. We consider the related
setting of $p$-partitioned dynamic networks, in which the communication graph
in each round consists of at most $p$ connected components. We explore the
problem of $k$-agreement in this model for $k\geq p$. We show that if the
number of processes is unknown then it is impossible to achieve $k$-agreement
for any $k$ and any $p\geq 2$. Given an upper bound $n$ on the number of
processes, we provide algorithms achieving $k$-agreement in $p(n-p)$ rounds for
$k=p$ and in $O(n/\epsilon)$ rounds for $k=\lceil (1+\epsilon)p \rceil$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0581</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0581</id><created>2014-08-04</created><authors><author><keyname>Adeogun</keyname><forenames>Ramoni</forenames></author><author><keyname>Teal</keyname><forenames>Paul</forenames></author><author><keyname>Dmochowski</keyname><forenames>Pawel</forenames></author></authors><title>Parametric Schemes for Prediction of Wideband MIMO Wireless Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information on the future state of time varying frequency selective channels
can significantly enhance the effectiveness of feedback in adaptive and limited
feedback MIMO-OFDM systems. This paper investigates the parametric
extrapolation of wideband MIMO channels using variations of the double
directional MIMO model. We propose three predictors which estimate parameters
of the channel using 4D, 3D and 2D extensions of the ESPRIT algorithm and
predict future states of the channel using the models. Furthermore, using the
vector formulation of the Cramer Rao lower bound for functions of parameters,
we derive a bound on the prediction error in wideband MIMO channels. Numerical
simulations are used to evaluate the performance of the proposed algorithms
under different channel and transmission conditions, and a comparison is made
with the derived error bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0586</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0586</id><created>2014-08-04</created><authors><author><keyname>Ishwar</keyname><forenames>Prakash</forenames></author></authors><title>A note on the sum-rate-distortion function of some lossy source coding
  problems involving infinite-valued distortion functions</title><categories>cs.IT math.IT</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a number of lossy source coding problems it is shown that even if the
usual single-letter sum-rate-distortion expressions may become invalid for
non-infinite distortion functions, they can be approached, to any desired
accuracy, via the usual valid expressions for appropriately truncated finite
versions of the distortion functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0592</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0592</id><created>2014-08-04</created><updated>2014-09-17</updated><authors><author><keyname>Zhang</keyname><forenames>Chun-Mei</forenames></author><author><keyname>Li</keyname><forenames>Mo</forenames></author><author><keyname>Li</keyname><forenames>Hong-Wei</forenames></author><author><keyname>Yin</keyname><forenames>Zhen-Qiang</forenames></author><author><keyname>Wang</keyname><forenames>Dong</forenames></author><author><keyname>Huang</keyname><forenames>Jing-Zheng</forenames></author><author><keyname>Han</keyname><forenames>Yun-Guang</forenames></author><author><keyname>Xu</keyname><forenames>Man-Li</forenames></author><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Shuang</forenames></author><author><keyname>Treeviriyanupab</keyname><forenames>Patcharapong</forenames></author><author><keyname>Guo</keyname><forenames>Guang-Can</forenames></author><author><keyname>Han</keyname><forenames>Zheng-Fu</forenames></author></authors><title>Decoy state measurement-device-independent quantum key distribution
  based on the Clauser-Horne-Shimony-Holt inequality</title><categories>quant-ph cs.IT math.IT</categories><comments>4 pages, 2 figures</comments><journal-ref>Phys. Rev. A 90, 034302 (2014)</journal-ref><doi>10.1103/PhysRevA.90.034302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The measurement-device-independent quantum key distribution (MDI-QKD)
protocol is proposed to remove the detector side channel attacks, while its
security relies on the assumption that the encoding systems are perfectly
characterized. In contrast, the MDI-QKD protocol based on the
Clauser-Horne-Shimony-Holt inequality (CHSH-MDI-QKD) weakens this assumption,
which only requires the quantum state to be prepared in the two-dimensional
Hilbert space and the devices are independent. In experimental realizations,
the weak coherent state, which is always used in QKD systems due to the lack of
an ideal single photon source, may be prepared in the high-dimensional space.
In this paper, we investigate the decoy-state CHSH-MDI-QKD protocol with $s(3
\le s \le 5)$ intensities, including one signal state and $s-1$ decoy states,
and we also consider the finite-size effect on the decoy-state CHSH-MDI-QKD
protocol with five intensities. Simulation results show that this scheme is
very practical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0595</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0595</id><created>2014-08-04</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Malhotra</keyname><forenames>Meenakshi</forenames></author></authors><title>Correlating and Cross-linking Knowledge Threads in Informledge System
  for Creating New Knowledge</title><categories>cs.AI</categories><comments>6 pages, 6 figures, 3 tables, International Conference on Knowledge
  Engineering and Ontology Development, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been a considerable advance in computing, to mimic the way in which
the brain tries to comprehend and structure the information to retrieve
meaningful knowledge. It is identified that neuronal entities hold whole of the
knowledge that the species makes use of. We intended to develop a modified
knowledge based system, termed as Informledge System (ILS) with autonomous
nodes and intelligent links that integrate and structure the pieces of
knowledge. We conceive that every piece of knowledge is a cluster of
cross-linked and correlated structure. In this paper, we put forward the theory
of the nodes depicting concepts, referred as Entity Concept State which in turn
is dealt with Concept State Diagrams (CSD). This theory is based on an abstract
framework provided by the concepts. The framework represents the ILS as the
weighted graph where the weights attached with the linked nodes help in
knowledge retrieval by providing the direction of connectivity of autonomous
nodes present in knowledge thread traversal. Here for the first time in the
process of developing Informledge, we apply tenor computation for creating
intelligent combinatorial knowledge with cross mutation to create fresh
knowledge which looks to be the fundamentals of a typical thought process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0596</identifier>
 <datestamp>2015-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0596</id><created>2014-08-04</created><updated>2015-10-31</updated><authors><author><keyname>Besser</keyname><forenames>Bert</forenames></author></authors><title>Approximation Bounds For Minimum Degree Matching</title><categories>cs.DS</categories><comments>% CHANGELOG % rev 1 2014-12-02 % - Show that the class APV contains
  many prominent greedy matching algorithms. % - Adapt inapproximability bound
  for APV-algorithms to a priori knowledge on |V|. % rev 2 2015-10-31 % -
  improve performance guarantee of MINGREEDY to be tight</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the MINGREEDY strategy for Maximum Cardinality Matching.
MINGREEDY repeatedly selects an edge incident with a node of minimum degree.
For graphs of degree at most $\Delta$ we show that MINGREEDY achieves
approximation ratio at least $ \frac{\Delta-1}{2\Delta-3} $ in the worst case
and that this performance is optimal among adaptive priority algorithms in the
vertex model, which include many prominent greedy matching heuristics. Even
when considering expected approximation ratios of randomized greedy strategies,
no better worst case bounds are known for graphs of small degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0605</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0605</id><created>2014-08-04</created><authors><author><keyname>Nguyen</keyname><forenames>Viet-Anh</forenames></author><author><keyname>Lu</keyname><forenames>Jiangbo</forenames></author><author><keyname>Zhao</keyname><forenames>Shengkui</forenames></author><author><keyname>Vu</keyname><forenames>Tien Dung</forenames></author><author><keyname>Yang</keyname><forenames>Hongsheng</forenames></author><author><keyname>Douglas</keyname><forenames>Jones L.</forenames></author><author><keyname>Do</keyname><forenames>Minh N.</forenames></author></authors><title>ITEM: Immersive Telepresence for Entertainment and Meetings - A
  Practical Approach</title><categories>cs.MM</categories><acm-class>H.5.1; I.4.9</acm-class><doi>10.1109/JSTSP.2014.2375819</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an Immersive Telepresence system for Entertainment and
Meetings (ITEM). The system aims to provide a radically new video communication
experience by seamlessly merging participants into the same virtual space to
allow a natural interaction among them and shared collaborative contents. With
the goal to make a scalable, flexible system for various business solutions as
well as easily accessible by massive consumers, we address the challenges in
the whole pipeline of media processing, communication, and displaying in our
design and realization of such a system. Particularly, in this paper we focus
on the system aspects that maximize the end-user experience, optimize the
system and network resources, and enable various teleimmersive application
scenarios. In addition, we also present a few key technologies, i.e. fast
object-based video coding for real world data and spatialized audio capture and
3D sound localization for group teleconferencing. Our effort is to investigate
and optimize the key system components and provide an efficient end-to-end
optimization and integration by considering user needs and preferences.
Extensive experiments show the developed system runs reliably and comfortably
in real time with a minimal setup requirement (e.g. a webcam and/or a depth
camera, an optional microphone array, a laptop/desktop connected to the public
Internet) for teleimmersive communication. With such a really minimal
deployment requirement, we present a variety of interesting applications and
user experiences created by ITEM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0614</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0614</id><created>2014-08-04</created><authors><author><keyname>Dzupire</keyname><forenames>Nelson Christopher</forenames></author><author><keyname>Nkansah-Gyekye</keyname><forenames>Yaw</forenames></author></authors><title>A Multi-Stage Supply Chain Network Optimization Using Genetic Algorithms</title><categories>math.OC cs.NE</categories><comments>12 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In today's global business market place, individual firms no longer compete
as independent entities with unique brand names but as integral part of supply
chain links. Key to success of any business is satisfying customer's demands on
time which may result in cost reductions and increase in service level. In
supply chain networks decisions are made with uncertainty about product's
demands, costs, prices, lead times, quality in a competitive and collaborative
environment. If poor decisions are made, they may lead to excess inventories
that are costly or to insufficient inventory that cannot meet customer's
demands. In this work we developed a bi-objective model that minimizes system
wide costs of the supply chain and delays on delivery of products to
distribution centers for a three echelon supply chain. Picking a set of Pareto
front for multi-objective optimization problems require robust and efficient
methods that can search an entire space. We used evolutionary algorithms to
find the set of Pareto fronts which have proved to be effective in finding the
entire set of Pareto fronts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0620</identifier>
 <datestamp>2014-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0620</id><created>2014-08-04</created><updated>2014-11-12</updated><authors><author><keyname>Charron-Bost</keyname><forenames>Bernadette</forenames></author><author><keyname>F&#xfc;gger</keyname><forenames>Matthias</forenames></author><author><keyname>Nowak</keyname><forenames>Thomas</forenames></author></authors><title>Approximate Consensus in Highly Dynamic Networks: The Role of Averaging
  Algorithms</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the approximate consensus problem in highly
dynamic networks in which topology may change continually and unpredictably. We
prove that in both synchronous and partially synchronous systems, approximate
consensus is solvable if and only if the communication graph in each round has
a rooted spanning tree, i.e., there is a coordinator at each time. The striking
point in this result is that the coordinator is not required to be unique and
can change arbitrarily from round to round. Interestingly, the class of
averaging algorithms, which are memoryless and require no process identifiers,
entirely captures the solvability issue of approximate consensus in that the
problem is solvable if and only if it can be solved using any averaging
algorithm. Concerning the time complexity of averaging algorithms, we show that
approximate consensus can be achieved with precision of $\varepsilon$ in a
coordinated network model in $O(n^{n+1} \log\frac{1}{\varepsilon})$ synchronous
rounds, and in $O(\Delta n^{n\Delta+1} \log\frac{1}{\varepsilon})$ rounds when
the maximum round delay for a message to be delivered is $\Delta$. While in
general, an upper bound on the time complexity of averaging algorithms has to
be exponential, we investigate various network models in which this exponential
bound in the number of nodes reduces to a polynomial bound. We apply our
results to networked systems with a fixed topology and classical benign fault
models, and deduce both known and new results for approximate consensus in
these systems. In particular, we show that for solving approximate consensus, a
complete network can tolerate up to 2n-3 arbitrarily located link faults at
every round, in contrast with the impossibility result established by Santoro
and Widmayer (STACS '89) showing that exact consensus is not solvable with n-1
link faults per round originating from the same node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0629</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0629</id><created>2014-08-04</created><updated>2014-11-16</updated><authors><author><keyname>Kullmann</keyname><forenames>Oliver</forenames></author><author><keyname>Zhao</keyname><forenames>Xishun</forenames></author></authors><title>Bounds for variables with few occurrences in conjunctive normal forms</title><categories>math.CO cs.DM cs.LO</categories><comments>90 pages; second version has changed style, various small errors and
  typos corrected, and improved presentation of results, third version with
  various editorial improvements; continues arXiv:1010.5756</comments><msc-class>68R99 (Primary) 03B05, 05D99 (Secondary)</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate connections between SAT (the propositional satisfiability
problem) and combinatorics, around the minimum degree (number of occurrences)
of variables in various forms of redundancy-free boolean conjunctive normal
forms (clause-sets).
  Lean clause-sets do not have non-trivial autarkies, that is, it is not
possible to satisfy some clauses and leave the other clauses untouched. The
deficiency of a clause-set is the difference of the number of clauses and the
number of variables. We prove a precise upper bound on the minimum variable
degree of lean clause-sets in dependency on the deficiency. If a clause-set
does not fulfil this upper bound, then it must have a non-trivial autarky; we
show that the autarky-reduction (elimination of affected clauses) can be done
in polynomial time, while it is open to find the autarky itself in polynomial
time.
  Then we investigate this upper bound for the special case of minimally
unsatisfiable clause-sets. We show that the bound can be improved here,
introducing a general method to improve the underlying recurrence.
  We consider precise relations, and thus the investigations have a
number-theoretical flavour. We try to build a bridge from logic to
combinatorics (especially to hypergraph colouring), and we discuss thoroughly
the background and open problems, and provide many examples and explanations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0651</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0651</id><created>2014-08-04</created><authors><author><keyname>Brunelli</keyname><forenames>Matteo</forenames></author><author><keyname>Fedrizzi</keyname><forenames>Michele</forenames></author></authors><title>Boundary properties of the inconsistency of pairwise comparisons in
  group decisions</title><categories>cs.AI</categories><comments>21 pages, 6 figures</comments><doi>10.1016/j.ejor.2014.07.045</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes an analysis of the effects of consensus and preference
aggregation on the consistency of pairwise comparisons. We define some boundary
properties for the inconsistency of group preferences and investigate their
relation with different inconsistency indices. Some results are presented on
more general dependencies between properties of inconsistency indices and the
satisfaction of boundary properties. In the end, given three boundary
properties and nine indices among the most relevant ones, we will be able to
present a complete analysis of what indices satisfy what properties and offer a
reflection on the interpretation of the inconsistency of group preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0652</identifier>
 <datestamp>2014-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0652</id><created>2014-08-04</created><updated>2014-12-16</updated><authors><author><keyname>Brandner</keyname><forenames>G&#xfc;nther</forenames></author><author><keyname>Klinglmayr</keyname><forenames>Johannes</forenames></author><author><keyname>Schilcher</keyname><forenames>Udo</forenames></author><author><keyname>Egarter</keyname><forenames>Dominik</forenames></author><author><keyname>Bettstetter</keyname><forenames>Christian</forenames></author></authors><title>Precision of Pulse-Coupled Oscillator Synchronization on FPGA-Based
  Radios</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The precision of synchronization algorithms based on the theory of
pulse-coupled oscillators is evaluated on FPGA-based radios for the first time.
Measurements show that such algorithms can reach precision in the low
microsecond range when being implemented in the physical layer. Furthermore, we
propose an algorithm extension accounting for phase rate deviations of the
hardware and show that an improved precision below one microsecond is possible
with this extension in the given setup. The resulting algorithm can thus be
applied in ad hoc wireless systems for fully distributed synchronization of
transmission slots or sleep cycles, in particular, if centralized
synchronization is impossible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0677</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0677</id><created>2014-08-04</created><authors><author><keyname>Muelder</keyname><forenames>Chris W.</forenames></author><author><keyname>Leaf</keyname><forenames>Nick</forenames></author><author><keyname>Sigovan</keyname><forenames>Carmen</forenames></author><author><keyname>Ma</keyname><forenames>Kwan-Liu</forenames></author></authors><title>A Moving Least Squares Based Approach for Contour Visualization of
  Multi-Dimensional Data</title><categories>cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of high dimensional data is a common task. Often, small multiples
are used to visualize 1 or 2 dimensions at a time, such as in a scatterplot
matrix. Associating data points between different views can be difficult
though, as the points are not fixed. Other times, dimensional reduction
techniques are employed to summarize the whole dataset in one image, but
individual dimensions are lost in this view. In this paper, we present a means
of augmenting a dimensional reduction plot with isocontours to reintroduce the
original dimensions. By applying this to each dimension in the original data,
we create multiple views where the points are consistent, which facilitates
their comparison. Our approach employs a combination of a novel, graph-based
projection technique with a GPU accelerated implementation of moving least
squares to interpolate space between the points. We also present evaluations of
this approach both with a case study and with a user study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0680</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0680</id><created>2014-08-04</created><authors><author><keyname>Berri</keyname><forenames>Rafael A.</forenames></author><author><keyname>Silva</keyname><forenames>Alexandre G.</forenames></author><author><keyname>Parpinelli</keyname><forenames>Rafael S.</forenames></author><author><keyname>Girardi</keyname><forenames>Elaine</forenames></author><author><keyname>Arthur</keyname><forenames>Rangel</forenames></author></authors><title>A Pattern Recognition System for Detecting Use of Mobile Phones While
  Driving</title><categories>cs.CV</categories><comments>8 pages, 9th International Conference on Computer Vision Theory and
  Applications</comments><doi>10.5220/0004684504110418</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is estimated that 80% of crashes and 65% of near collisions involved
drivers inattentive to traffic for three seconds before the event. This paper
develops an algorithm for extracting characteristics allowing the cell phones
identification used during driving a vehicle. Experiments were performed on
sets of images with 100 positive images (with phone) and the other 100 negative
images (no phone), containing frontal images of the driver. Support Vector
Machine (SVM) with Polynomial kernel is the most advantageous classification
system to the features provided by the algorithm, obtaining a success rate of
91.57% for the vision system. Tests done on videos show that it is possible to
use the image datasets for training classifiers in real situations. Periods of
3 seconds were correctly classified at 87.43% of cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0683</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0683</id><created>2014-08-04</created><authors><author><keyname>Engelfriet</keyname><forenames>Joost</forenames></author></authors><title>Context-Free Grammars with Storage</title><categories>cs.FL</categories><comments>58 pages, 8 figures, slightly revised version of a report from 1986</comments><report-no>86-11</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context-free S grammars are introduced, for arbitrary (storage) type S, as a
uniform framework for recursion-based grammars, automata, and transducers,
viewed as programs. To each occurrence of a nonterminal of a context-free S
grammar an object of type S is associated, that can be acted upon by tests and
operations, as indicated in the rules of the grammar. Taking particular storage
types gives particular formalisms, such as indexed grammars, top-down tree
transducers, attribute grammars, etc. Context-free S grammars are equivalent to
pushdown S automata. The context-free S languages can be obtained from the
deterministic one-way S automaton languages by way of the delta operations on
languages, introduced in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0689</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0689</id><created>2014-08-04</created><updated>2014-08-05</updated><authors><author><keyname>Gong</keyname><forenames>Yue-Jiao</forenames></author><author><keyname>Zhang</keyname><forenames>Jun</forenames></author></authors><title>Real-Time Traffic Signal Control for Modern Roundabouts by Using
  Particle Swarm Optimization-Based Fuzzy Controller</title><categories>cs.NE</categories><report-no>SYSU -- 201103</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Due to that the existing traffic facilities can hardly be extended,
developing traffic signal control methods is the most important way to improve
the traffic efficiency of modern roundabouts. This paper proposes a novel
traffic signal controller with two fuzzy layers for signalizing the roundabout.
The outer layer of the controller computes urgency degrees of all the phase
subsets and then activates the most urgent subset. This mechanism helps to
instantly respond to the current traffic condition of the roundabout so as to
improve real-timeness. The inner layer of the controller computes extension
time of the current phase. If the extension value is larger than a threshold
value, the current phase is maintained; otherwise the next phase in the running
phase subset (selected by the outer layer) is activated. The inner layer adopts
well-designed phase sequences, which helps to smooth the traffic flows and to
avoid traffic jam. In general, the proposed traffic signal controller is
capable of improving real-timeness as well as reducing traffic congestion.
Moreover, an offline particle swarm optimization (PSO) algorithm is developed
to optimize the membership functions adopted in the proposed controller. By
using optimal membership functions, the performance of the controller can be
further improved. Simulation results demonstrate that the proposed controller
outperforms previous traffic signal controllers in terms of improving the
traffic efficiency of modern roundabouts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0694</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0694</id><created>2014-07-31</created><authors><author><keyname>Blanco</keyname><forenames>Krystal</forenames></author><author><keyname>Briceno</keyname><forenames>Aida</forenames></author><author><keyname>Steele</keyname><forenames>Andrea</forenames></author><author><keyname>Tapia</keyname><forenames>Javier</forenames></author><author><keyname>McKay</keyname><forenames>John</forenames></author><author><keyname>Towers</keyname><forenames>Sherry</forenames></author><author><keyname>Yong</keyname><forenames>Kamuela E.</forenames></author></authors><title>The Dynamics of Offensive Messages in the World of Social Media: the
  Control of Cyberbullying on Twitter</title><categories>cs.SI cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 21st century has redefined the way we communicate, our concept of
individual and group privacy, and the dynamics of acceptable behavioral norms.
The messaging dynamics on Twitter, an internet social network, has opened new
ways/modes of spreading information. As a result cyberbullying or in general,
the spread of offensive messages, is a prevalent problem. The aim of this
report is to identify and evaluate conditions that would dampen the role of
cyberbullying dynamics on Twitter. We present a discrete-time non-linear
compartmental model to explore how the introduction of a Quarantine class may
help to hinder the spread of offensive messages. We based the parameters of
this model on recent Twitter data related to a topic that communities would
deem most offensive, and found that for Twitter a level of quarantine can
always be achieved that will immediately suppress the spread of offensive
messages, and that this level of quarantine is independent of the number of
offenders spreading the message. We hope that the analysis of this dynamic
model will shed some insights into the viability of new models of methods for
reducing cyberbullying in public social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0699</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0699</id><created>2014-08-01</created><authors><author><keyname>Ormerod</keyname><forenames>Paul</forenames></author><author><keyname>Nyman</keyname><forenames>Rickard</forenames></author><author><keyname>Bentley</keyname><forenames>R Alexander</forenames></author></authors><title>Nowcasting economic and social data: when and why search engine data
  fails, an illustration using Google Flu Trends</title><categories>physics.soc-ph cs.CY cs.SI</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Obtaining an accurate picture of the current state of the economy is
particularly important to central banks and finance ministries, and of
epidemics to health ministries. There is increasing interest in the use of
search engine data to provide such 'nowcasts' of social and economic
indicators. However, people may search for a phrase because they independently
want the information, or they may search simply because many others are
searching for it. We consider the effect of the motivation for searching on the
accuracy of forecasts made using search engine data of contemporaneous social
and economic indicators. We illustrate the implications for forecasting
accuracy using four episodes in which Google Flu Trends data gave accurate
predictions of actual flu cases, and four in which the search data
over-predicted considerably. Using a standard statistical methodology, the Bass
diffusion model, we show that the independent search for information motive was
much stronger in the cases of accurate prediction than in the inaccurate ones.
Social influence, the fact that people may search for a phrase simply because
many others are, was much stronger in the inaccurate compared to the accurate
cases. Search engine data may therefore be an unreliable predictor of
contemporaneous indicators when social influence on the decision to search is
strong.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0700</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0700</id><created>2014-08-04</created><authors><author><keyname>Ghazi</keyname><forenames>Aboubakr Achraf El</forenames></author><author><keyname>Ulbrich</keyname><forenames>Mattias</forenames></author><author><keyname>Taghdiri</keyname><forenames>Mana</forenames></author><author><keyname>Herda</keyname><forenames>Mihai</forenames></author></authors><title>Reducing the Complexity of Quantified Formulas via Variable Elimination</title><categories>cs.LO</categories><journal-ref>11th International Workshop on Satisfiability Modulo Theories
  (SMT), pages 87-99, July 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general simplification of quantified SMT formulas using variable
elimination. The simplification is based on an analysis of the ground terms
occurring as arguments in function applications. We use this information to
generate a system of set constraints, which is then solved to compute a set of
sufficient ground terms for each variable. Universally quantified variables
with a finite set of sufficient ground terms can be eliminated by instantiating
them with the computed ground terms. The resulting SMT formula contains
potentially fewer quantifiers and thus is potentially easier to solve. We
describe how a satisfying model of the resulting formula can be modified to
satisfy the original formula. Our experiments show that in many cases, this
simplification considerably improves the solving time, and our evaluations
using Z3 and CVC4 indicate that the idea is not specific to a particular
solver, but can be applied in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0701</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0701</id><created>2014-07-31</created><authors><author><keyname>Gonz&#xe1;lez-Valiente</keyname><forenames>C. L.</forenames></author></authors><title>Apuntes relevantes sobre la evaluaci\'on en la alfabetizaci\'on
  informacional</title><categories>cs.CY</categories><comments>Libr\'insula: La Isla de los Libros; 2014, 331</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The purpose of this study is to reflect on some questions concerning the
evaluation in information literacy. It is discussed some elements such as
scenarios, objects and methods in the evaluation of information literacy
programs. It is highlighted the need to influence in the context of such
programs as the result of student learning. Some notions emerged from the
educational field are taken into account to solidify the ideas presented here.
It is argued the implications of this type of assessment practices for
information professionals, who serve as trainers of information skills.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0703</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0703</id><created>2014-08-04</created><authors><author><keyname>Thompson</keyname><forenames>David R. M</forenames></author><author><keyname>Leyton-Brown</keyname><forenames>Kevin</forenames></author></authors><title>Computational Analysis of Perfect-Information Position Auctions</title><categories>cs.GT cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  After experimentation with other designs, the major search engines converged
on the weighted, generalized second-price auction (wGSP) for selling keyword
advertisements. Notably, this convergence occurred before position auctions
were well understood (or, indeed, widely studied) theoretically. While much
progress has been made since, theoretical analysis is still not able to settle
the question of why search engines found wGSP preferable to other position
auctions. We approach this question in a new way, adopting a new analytical
paradigm we dub &quot;computational mechanism analysis.&quot; By sampling position
auction games from a given distribution, encoding them in a computationally
efficient representation language, computing their Nash equilibria, and then
calculating economic quantities of interest, we can quantitatively answer
questions that theoretical methods have not. We considered seven widely studied
valuation models from the literature and three position auction variants
(generalized first price, unweighted generalized second price, and wGSP). We
found that wGSP consistently showed the best ads of any position auction,
measured both by social welfare and by relevance (expected number of clicks).
Even in models where wGSP was already known to have bad worse-case efficiency,
we found that it almost always performed well on average. In contrast, we found
that revenue was extremely variable across auction mechanisms, and was highly
sensitive to equilibrium selection, the preference model, and the valuation
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0707</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0707</id><created>2014-08-04</created><authors><author><keyname>Ghazi</keyname><forenames>Aboubakr Achraf El</forenames></author><author><keyname>Geilmann</keyname><forenames>Ulrich</forenames></author><author><keyname>Ulbrich</keyname><forenames>Mattias</forenames></author><author><keyname>Taghdiri</keyname><forenames>Mana</forenames></author></authors><title>A Dual-Engine for Early Analysis of Critical Systems</title><categories>cs.LO</categories><comments>Workshop on Dependable Software for Critical Infrastructures (DSCI),
  Berlin 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a framework for modeling, simulating, and checking
properties of critical systems based on the Alloy language -- a declarative,
first-order, relational logic with a built-in transitive closure operator. The
paper introduces a new dual-analysis engine that is capable of providing both
counterexamples and proofs. Counterexamples are found fully automatically using
an SMT solver, which provides a better support for numerical expressions than
the existing Alloy Analyzer. Proofs, however, cannot always be found
automatically since the Alloy language is undecidable. Our engine offers an
economical approach by first trying to prove properties using a
fully-automatic, SMT-based analysis, and switches to an interactive theorem
prover only if the first attempt fails. This paper also reports on applying our
framework to Microsoft's COM standard and the mark-and-sweep garbage collection
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0719</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0719</id><created>2014-08-04</created><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Van Der Hofstad</keyname><forenames>Remco W.</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Sokol</keyname><forenames>Marina</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Personalized PageRank with Node-dependent Restart</title><categories>cs.IR</categories><proxy>ccsd</proxy><report-no>RR-8570</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Personalized PageRank is an algorithm to classify the improtance of web pages
on a user-dependent basis. We introduce two generalizations of Personalized
PageRank with node-dependent restart. The first generalization is based on the
proportion of visits to nodes before the restart, whereas the second
generalization is based on the probability of visited node just before the
restart. In the original case of constant restart probability, the two measures
coincide. We discuss interesting particular cases of restart probabilities and
restart distributions. We show that the both generalizations of Personalized
PageRank have an elegant expression connecting the so-called direct and reverse
Personalized PageRanks that yield a symmetry property of these Personalized
PageRanks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0725</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0725</id><created>2014-08-04</created><authors><author><keyname>Wetzels</keyname><forenames>Jos</forenames></author></authors><title>Hidden in snow, revealed in thaw: Cold boot attacks revisited</title><categories>cs.CR</categories><comments>26 pages</comments><acm-class>K.6.5</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we will provide an overview of the current state-of-the-art
with regards to so-called cold boot attacks, their practical applicability and
feasibility, potential counter-measures and their effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0726</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0726</id><created>2014-07-24</created><authors><author><keyname>Kang</keyname><forenames>Xin</forenames></author><author><keyname>Wu</keyname><forenames>Yongdong</forenames></author></authors><title>A Trust-based Pollution Attack Prevention Scheme in Peer-to-Peer
  Streaming Networks</title><categories>cs.NI cs.GT</categories><comments>to appear in Computer Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, peer-to-peer (P2P) streaming systems have become a popular way to
deliver multimedia content over the internet due to their low bandwidth
requirement, high video streaming quality, and flexibility. However, P2P
streaming systems are vulnerable to various attacks, especially pollution
attacks, due to their distributed and dynamically changing infrastructure. In
this paper, by exploring the features of various pollution attacks, we propose
a trust management system tailored for P2P streaming systems. Both direct trust
and indirect trust are taken into consideration when designing the trust
management system. A new direct trust model is proposed. A dynamic confidence
factor that can dynamically adjust the weight of direct and indirect trust in
computing the trust is also proposed and studied. A novel double-threshold
trust utilization scheme is given. It is shown that the proposed trust
management system is effective in identifying polluters and preventing them
from further sharing of polluted data chunks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0727</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0727</id><created>2014-07-24</created><authors><author><keyname>Kang</keyname><forenames>Xin</forenames></author><author><keyname>Wu</keyname><forenames>Yongdong</forenames></author></authors><title>Incentive Mechanism Design for Heterogeneous Peer-to-Peer Networks: A
  Stackelberg Game Approach</title><categories>cs.NI cs.GT</categories><comments>to appear in IEEE Transactions on Mobile Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With high scalability, high video streaming quality, and low bandwidth
requirement, peer-to-peer (P2P) systems have become a popular way to exchange
files and deliver multimedia content over the internet. However, current P2P
systems are suffering from &quot;free-riding&quot; due to the peers' selfish nature. In
this paper, we propose a credit-based incentive mechanism to encourage peers to
cooperate with each other in a heterogeneous network consisting of wired and
wireless peers. The proposed mechanism can provide differentiated service to
peers with different credits through biased resource allocation. A Stackelberg
game is formulated to obtain the optimal pricing and purchasing strategies,
which can jointly maximize the revenue of the uploader and the utilities of the
downloaders. In particular, peers' heterogeneity and selfish nature are taken
into consideration when designing the utility functions for the Stackelberg
game. It is shown that the proposed resource allocation scheme is effective in
providing service differentiation for peers and stimulating them to make
contribution to the P2P streaming system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0733</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0733</id><created>2014-08-04</created><authors><author><keyname>Sreekumar</keyname><forenames>Shilpa</forenames></author><author><keyname>Salam</keyname><forenames>Vincy</forenames></author></authors><title>Advanced reversible Data Hiding With Encrypted Data</title><categories>cs.CR</categories><comments>4 pages, 10 figures, Published with International Journal of
  Engineering Trends and Technology (IJETT)</comments><journal-ref>IJETT, V13(7),310-313 July 2014. ISSN:2231-5381</journal-ref><doi>10.14445/22315381/IJETT-V13P262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advanced RDH work focuses on both data encryption and image encryption
which makes it more secure and free of errors. All previous methods embed data
without encrypting the data which may subject to errors on the data extraction
or image recovery. The proposed work provides a novel RDH scheme in which both
data and image can be encrypted and extracted reversibly without any errors. In
the proposed work, data extraction and image recovery are free of any errors.
The PSNR is significantly improved in the proposed work. This advanced work
also performs data hiding in videos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0751</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0751</id><created>2014-08-04</created><authors><author><keyname>Abdullah</keyname><forenames>Amirali</forenames></author><author><keyname>Andoni</keyname><forenames>Alexandr</forenames></author><author><keyname>Kannan</keyname><forenames>Ravindran</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author></authors><title>Spectral Approaches to Nearest Neighbor Search</title><categories>cs.DS</categories><comments>Accepted in the proceedings of FOCS 2014. 30 pages and 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study spectral algorithms for the high-dimensional Nearest Neighbor Search
problem (NNS). In particular, we consider a semi-random setting where a dataset
$P$ in $\mathbb{R}^d$ is chosen arbitrarily from an unknown subspace of low
dimension $k\ll d$, and then perturbed by fully $d$-dimensional Gaussian noise.
We design spectral NNS algorithms whose query time depends polynomially on $d$
and $\log n$ (where $n=|P|$) for large ranges of $k$, $d$ and $n$. Our
algorithms use a repeated computation of the top PCA vector/subspace, and are
effective even when the random-noise magnitude is {\em much larger} than the
interpoint distances in $P$. Our motivation is that in practice, a number of
spectral NNS algorithms outperform the random-projection methods that seem
otherwise theoretically optimal on worst case datasets. In this paper we aim to
provide theoretical justification for this disparity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0765</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0765</id><created>2014-08-04</created><updated>2014-08-19</updated><authors><author><keyname>Liu</keyname><forenames>Yu</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Haimovich</keyname><forenames>Alexander M.</forenames></author><author><keyname>Su</keyname><forenames>Wei</forenames></author></authors><title>Modulation Classification via Gibbs Sampling Based on a Latent Dirichlet
  Bayesian Network</title><categories>cs.IT cs.CV math.IT</categories><comments>Contains corrections with respect to the version to appear on IEEE
  Signal Processing Letters (see Fig. 2)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel Bayesian modulation classification scheme is proposed for a
single-antenna system over frequency-selective fading channels. The method is
based on Gibbs sampling as applied to a latent Dirichlet Bayesian network (BN).
The use of the proposed latent Dirichlet BN provides a systematic solution to
the convergence problem encountered by the conventional Gibbs sampling approach
for modulation classification. The method generalizes, and is shown to improve
upon, the state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0782</identifier>
 <datestamp>2014-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0782</id><created>2014-08-04</created><authors><author><keyname>Ashwini</keyname><forenames>Sandeep</forenames></author><author><keyname>Choi</keyname><forenames>Jinho D.</forenames></author></authors><title>Targetable Named Entity Recognition in Social Media</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach for recognizing what we call targetable named
entities; that is, named entities in a targeted set (e.g, movies, books, TV
shows). Unlike many other NER systems that need to retrain their statistical
models as new entities arrive, our approach does not require such retraining,
which makes it more adaptable for types of entities that are frequently
updated. For this preliminary study, we focus on one entity type, movie title,
using data collected from Twitter. Our system is tested on two evaluation sets,
one including only entities corresponding to movies in our training set, and
the other excluding any of those entities. Our final model shows F1-scores of
76.19% and 78.70% on these evaluation sets, which gives strong evidence that
our approach is completely unbiased to any par- ticular set of entities found
during training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0784</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0784</id><created>2014-08-04</created><updated>2014-08-05</updated><authors><author><keyname>Gardiner</keyname><forenames>Joseph</forenames></author><author><keyname>Nagaraja</keyname><forenames>Shishir</forenames></author></authors><title>Blindspot: Indistinguishable Anonymous Communications</title><categories>cs.CR</categories><comments>13 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication anonymity is a key requirement for individuals under targeted
surveillance. Practical anonymous communications also require
indistinguishability - an adversary should be unable to distinguish between
anonymised and non-anonymised traffic for a given user. We propose Blindspot, a
design for high-latency anonymous communications that offers
indistinguishability and unobservability under a (qualified) global active
adversary. Blindspot creates anonymous routes between sender-receiver pairs by
subliminally encoding messages within the pre-existing communication behaviour
of users within a social network. Specifically, the organic image sharing
behaviour of users. Thus channel bandwidth depends on the intensity of image
sharing behaviour of users along a route. A major challenge we successfully
overcome is that routing must be accomplished in the face of significant
restrictions - channel bandwidth is stochastic. We show that conventional
social network routing strategies do not work. To solve this problem, we
propose a novel routing algorithm. We evaluate Blindspot using a real-world
dataset. We find that it delivers reasonable results for applications requiring
low-volume unobservable communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0807</identifier>
 <datestamp>2015-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0807</id><created>2014-08-04</created><updated>2015-04-01</updated><authors><author><keyname>Avis</keyname><forenames>David</forenames></author><author><keyname>Bremner</keyname><forenames>David</forenames></author><author><keyname>Tiwary</keyname><forenames>Hans Raj</forenames></author><author><keyname>Watanabe</keyname><forenames>Osamu</forenames></author></authors><title>Polynomial size linear programs for problems in P</title><categories>cs.DM</categories><comments>17 pages, 1 figure; This version comprises of a major revision of the
  earlier version, with several errors corrected and parts rewritten. This
  version has been submitted for peer review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A perfect matching in an undirected graph $G=(V,E)$ is a set of vertex
disjoint edges from $E$ that include all vertices in $V$. The perfect matching
problem is to decide if $G$ has such a matching. Recently Rothvo{\ss} proved
the striking result that the Edmonds' matching polytope has exponential
extension complexity. Here for each $n=|V|$ we describe a perfect matching
polytope that is different from Edmonds' polytope and define a weaker notion of
extended formulation. We show that the new polytope has a weak extended
formulation (WEF) $Q$ of polynomial size. For each graph $G$ with $n$ vertices
we can readily construct an objective function so that solving the resulting
linear program over $Q$ decides whether or not $G$ has a perfect matching. The
construction is uniform in the sense that, for each $n$, a single polytope is
defined for the class of all graphs with $n$ nodes. The method extends to solve
poly time optimization problems, such as the weighted matching problem. In this
case a logarithmic (in the weight of the optimum solution) number of
optimizations are made over the constructed WEF.
  The method described in the paper involves construction of a compiler that
converts an algorithm given in a prescribed pseudocode into a polytope. It can
therefore be used to construct a polytope for any decision problem in {\bf P}
which can be solved by a given algorithm. Compared with earlier results of
Dobkin-Lipton-Reiss and Valiant our method allows the construction of explicit
linear programs directly from algorithms written for a standard register model,
without intermediate transformations. We apply our results to obtain polynomial
upper bounds on the non-negative rank of certain slack matrices related to
membership testing of languages in {\bf P/Poly}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0809</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0809</id><created>2014-08-04</created><authors><author><keyname>Krebs</keyname><forenames>Andreas</forenames></author><author><keyname>Straubing</keyname><forenames>Howard</forenames></author></authors><title>EF+EX Forest Algebras</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine languages of unranked forests definable using the temporal
operators EF and EX. We characterize the languages definable in this logic, and
various fragments thereof, using the syntactic forest algebras introduced by
Bojanczyk and Walukiewicz. Our algebraic characterizations yield efficient
algorithms for deciding when a given language of forests is definable in this
logic. The proofs are based on understanding the wreath product closures of a
few small algebras, for which we introduce a general ideal theory for forest
algebras. This combines ideas from the work of Bojanczyk and Walukiewicz for
the analogous logics on binary trees and from early work of Stiffler on wreath
product of finite semigroups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0812</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0812</id><created>2014-08-04</created><authors><author><keyname>Newport</keyname><forenames>Calvin</forenames></author></authors><title>Lower Bounds for Structuring Unreliable Radio Networks</title><categories>cs.DC</categories><comments>An extended abstract of this work appears in the 2014 proceedings of
  the International Symposium on Distributed Computing (DISC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study lower bounds for randomized solutions to the maximal
independent set (MIS) and connected dominating set (CDS) problems in the dual
graph model of radio networks---a generalization of the standard graph-based
model that now includes unreliable links controlled by an adversary. We begin
by proving that a natural geographic constraint on the network topology is
required to solve these problems efficiently (i.e., in time polylogarthmic in
the network size). We then prove the importance of the assumption that nodes
are provided advance knowledge of their reliable neighbors (i.e, neighbors
connected by reliable links). Combined, these results answer an open question
by proving that the efficient MIS and CDS algorithms from [Censor-Hillel, PODC
2011] are optimal with respect to their dual graph model assumptions. They also
provide insight into what properties of an unreliable network enable efficient
local computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0814</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0814</id><created>2014-08-04</created><authors><author><keyname>Akbas</keyname><forenames>Emre</forenames></author><author><keyname>Eckstein</keyname><forenames>Miguel P.</forenames></author></authors><title>Object Detection Through Exploration With A Foveated Visual Field</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a foveated object detector (FOD) as a biologically-inspired
alternative to the sliding window (SW) approach which is the dominant method of
search in computer vision object detection. Similar to the human visual system,
the FOD has higher resolution at the fovea and lower resolution at the visual
periphery. Consequently, more computational resources are allocated at the
fovea and relatively fewer at the periphery. The FOD processes the entire
scene, uses retino-specific object detection classifiers to guide eye
movements, aligns its fovea with regions of interest in the input image and
integrates observations across multiple fixations. Our approach combines modern
object detectors from computer vision with a recent model of peripheral pooling
regions found at the V1 layer of the human visual system. We assessed various
eye movement strategies on the PASCAL VOC 2007 dataset and show that the FOD
performs on par with the SW detector while bringing significant computational
cost savings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0818</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0818</id><created>2014-08-04</created><authors><author><keyname>Hung</keyname><forenames>Weil-Lun</forenames></author><author><keyname>Chauhan</keyname><forenames>Himanshu</forenames></author><author><keyname>Garg</keyname><forenames>Vijay K.</forenames></author></authors><title>ActiveMonitor: Non-blocking Monitor Executions for Increased Parallelism</title><categories>cs.DC cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a set of novel ideas on design and implementation of monitor
objects for multi-threaded programs. Our approach has two main goals: (a)
increase parallelism in monitor objects and thus provide performance gains
(shorter runtimes) for multi-threaded programs, and (b) introduce constructs
that allow programmers to easily write monitor-based multi-threaded programs
that can achieve these performance gains. We describe the concepts of our
framework, called ActiveMonitor, and its prototype implementation using
futures. We evaluate its performance in terms of runtimes of multi-threaded
programs on linked-list, bounded-buffer, and other fundamental problems
implemented in Java. We compare the runtimes of our implementation against
implementations using Java's reentrant locks, recently proposed automatic
signaling framework AutoSynch, and some other techniques from the literature.
The results of of the evaluation indicate that monitors based on our framework
provide significant gains in runtime performance in comparison to traditional
monitors implemented using Java's reentrant locks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0826</identifier>
 <datestamp>2014-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0826</id><created>2014-08-04</created><authors><author><keyname>Ying</keyname><forenames>Kai</forenames></author><author><keyname>Yu</keyname><forenames>Zhenhua</forenames></author><author><keyname>Baxley</keyname><forenames>Robert J.</forenames></author><author><keyname>Zhou</keyname><forenames>G. Tong</forenames></author></authors><title>Optimization of Signal-to-Noise-and-Distortion Ratio for Dynamic Range
  Limited Nonlinearities</title><categories>cs.IT math.IT</categories><doi>10.1016/j.dsp.2014.10.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many components used in signal processing and communication applications,
such as power amplifiers and analog-to-digital converters, are nonlinear and
have a finite dynamic range. The nonlinearity associated with these devices
distorts the input, which can degrade the overall system performance.
Signal-to-noise-and-distortion ratio (SNDR) is a common metric to quantify the
performance degradation. One way to mitigate nonlinear distortions is by
maximizing the SNDR. In this paper, we analyze how to maximize the SNDR of the
nonlinearities in optical wireless communication (OWC) systems. Specifically,
we answer the question of how to optimally predistort a double-sided
memory-less nonlinearity that has both a &quot;turn-on&quot; value and a maximum
&quot;saturation&quot; value. We show that the SNDR-maximizing response given the
constraints is a double-sided limiter with a certain linear gain and a certain
bias value. Both the gain and the bias are functions of the probability density
function (PDF) of the input signal and the noise power. We also find a lower
bound of the nonlinear system capacity, which is given by the SDNR and an upper
bound determined by dynamic signal-to-noise ratio (DSNR). An application of the
results herein is to design predistortion linearization of nonlinear devices
like light emitting diodes (LEDs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0828</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0828</id><created>2014-08-04</created><authors><author><keyname>Chalermsook</keyname><forenames>Parinya</forenames></author><author><keyname>Laekhanukit</keyname><forenames>Bundit</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author></authors><title>Pre-Reduction Graph Products: Hardnesses of Properly Learning DFAs and
  Approximating EDP on DAGs</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of graph products is a major research topic and typically concerns
the term $f(G*H)$, e.g., to show that $f(G*H)=f(G)f(H)$. In this paper, we
study graph products in a non-standard form $f(R[G*H]$ where $R$ is a
&quot;reduction&quot;, a transformation of any graph into an instance of an intended
optimization problem. We resolve some open problems as applications.
  (1) A tight $n^{1-\epsilon}$-approximation hardness for the minimum
consistent deterministic finite automaton (DFA) problem, where $n$ is the
sample size. Due to Board and Pitt [Theoretical Computer Science 1992], this
implies the hardness of properly learning DFAs assuming $NP\neq RP$ (the
weakest possible assumption).
  (2) A tight $n^{1/2-\epsilon}$ hardness for the edge-disjoint paths (EDP)
problem on directed acyclic graphs (DAGs), where $n$ denotes the number of
vertices.
  (3) A tight hardness of packing vertex-disjoint $k$-cycles for large $k$.
  (4) An alternative (and perhaps simpler) proof for the hardness of properly
learning DNF, CNF and intersection of halfspaces [Alekhnovich et al., FOCS 2004
and J. Comput.Syst.Sci. 2008].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0838</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0838</id><created>2014-08-04</created><authors><author><keyname>Qu</keyname><forenames>Lizhen</forenames></author><author><keyname>Andres</keyname><forenames>Bjoern</forenames></author></authors><title>Estimating Maximally Probable Constrained Relations by Mathematical
  Programming</title><categories>cs.LG cs.NA math.OC stat.ML</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimating a constrained relation is a fundamental problem in machine
learning. Special cases are classification (the problem of estimating a map
from a set of to-be-classified elements to a set of labels), clustering (the
problem of estimating an equivalence relation on a set) and ranking (the
problem of estimating a linear order on a set). We contribute a family of
probability measures on the set of all relations between two finite, non-empty
sets, which offers a joint abstraction of multi-label classification,
correlation clustering and ranking by linear ordering. Estimating (learning) a
maximally probable measure, given (a training set of) related and unrelated
pairs, is a convex optimization problem. Estimating (inferring) a maximally
probable relation, given a measure, is a 01-linear program. It is solved in
linear time for maps. It is NP-hard for equivalence relations and linear
orders. Practical solutions for all three cases are shown in experiments with
real data. Finally, estimating a maximally probable measure and relation
jointly is posed as a mixed-integer nonlinear program. This formulation
suggests a mathematical programming approach to semi-supervised learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0845</identifier>
 <datestamp>2015-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0845</id><created>2014-08-04</created><authors><author><keyname>Zhao</keyname><forenames>Jing</forenames></author><author><keyname>Miao</keyname><forenames>Lili</forenames></author><author><keyname>Fang</keyname><forenames>Haiyang</forenames></author><author><keyname>Zhang</keyname><forenames>Qian-Ming</forenames></author><author><keyname>Nie</keyname><forenames>Min</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Predicting missing links and their weights via reliable-route-based
  method</title><categories>cs.SI cs.IR physics.soc-ph</categories><comments>5 pages, 4 tables</comments><journal-ref>Scientific Reports 5 (2015) 12261</journal-ref><doi>10.1038/srep12261</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link prediction aims to uncover missing links or predict the emergence of
future relationships according to the current networks structure. Plenty of
algorithms have been developed for link prediction in unweighted networks, with
only a very few of them having been extended to weighted networks. Thus far,
how to predict weights of links is important but rarely studied. In this
Letter, we present a reliable-route-based method to extend unweighted local
similarity indices to weighted indices and propose a method to predict both the
link existence and link weights accordingly. Experiments on different real
networks suggest that the weighted resource allocation index has the best
performance to predict the existence of links, while the reliable-route-based
weighted resource allocation index performs noticeably better on weight
prediction. Further analysis shows a strong correlation for both link
prediction and weight prediction: the larger the clustering coefficient, the
higher the prediction accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0848</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0848</id><created>2014-08-04</created><updated>2016-01-07</updated><authors><author><keyname>Zhang</keyname><forenames>Xiao-Lei</forenames></author></authors><title>Multilayer bootstrap networks</title><categories>cs.LG cs.NE stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a simple multilayer bootstrap network for unsupervised
dimensionality reduction that each layer of the network is a group of mutually
independent k-centers clusterings, and the centers of a clustering are randomly
sampled data points. We further compress the network size of multilayer
bootstrap network by a neural network in a pseudo supervised way for
prediction. We report comparison results in data visualization, clustering, and
document retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0853</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0853</id><created>2014-08-04</created><updated>2014-11-04</updated><authors><author><keyname>Yukawa</keyname><forenames>Masahiro</forenames></author></authors><title>Adaptive Learning in Cartesian Product of Reproducing Kernel Hilbert
  Spaces</title><categories>cs.LG stat.ML</categories><doi>10.1109/TSP.2015.2463261</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel adaptive learning algorithm based on iterative orthogonal
projections in the Cartesian product of multiple reproducing kernel Hilbert
spaces (RKHSs). The task is estimating/tracking nonlinear functions which are
supposed to contain multiple components such as (i) linear and nonlinear
components, (ii) high- and low- frequency components etc. In this case, the use
of multiple RKHSs permits a compact representation of multicomponent functions.
The proposed algorithm is where two different methods of the author meet:
multikernel adaptive filtering and the algorithm of hyperplane projection along
affine subspace (HYPASS). In a certain particular case, the sum space of the
RKHSs is isomorphic to the product space and hence the proposed algorithm can
also be regarded as an iterative projection method in the sum space. The
efficacy of the proposed algorithm is shown by numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0854</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0854</id><created>2014-08-04</created><authors><author><keyname>Adelman</keyname><forenames>Ross</forenames></author><author><keyname>Gumerov</keyname><forenames>Nail A.</forenames></author><author><keyname>Duraiswami</keyname><forenames>Ramani</forenames></author></authors><title>Semi-Analytical Computation of Acoustic Scattering by Spheroids and
  Disks</title><categories>cs.MS cs.SD physics.comp-ph</categories><doi>10.1121/1.4901318</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analytical solutions to acoustic scattering problems involving nonspherical
shapes, such as spheroids and disks, have long been known and have many
applications. However, these solutions require special functions that are not
easily computable. For this reason, their asymptotic forms are typically used
since they are more readily available. We explore these solutions and provide
computational software for calculating their nonasymptotic forms, which are
accurate over a wide range of frequencies and distances. This software, which
runs in MATLAB, computes the solutions to acoustic scattering problems
involving spheroids and disks by semi-analytical means, and is freely available
from our webpage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0868</identifier>
 <datestamp>2015-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0868</id><created>2014-08-05</created><authors><author><keyname>Hossain</keyname><forenames>Arafat</forenames></author><author><keyname>Canning</keyname><forenames>John</forenames></author><author><keyname>Ast</keyname><forenames>Sandra</forenames></author><author><keyname>Rutledge</keyname><forenames>Peter J.</forenames></author><author><keyname>Jamalipour</keyname><forenames>Abbas</forenames></author></authors><title>Intelligent smartphone-based portable network diagnostics for water
  security Case Study realtime pH mapping of tap water</title><categories>physics.ins-det cs.CY</categories><comments>Submitted for publication, April 2014</comments><journal-ref>Photonic Sensors December 2015, Volume 5, Issue 4, pp 289-297</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a field-portable, smartphone fluorometer to assess water quality based
on the pH response of a designer probe, a map of pH of public tap water sites
has been obtained. A custom designed Android application digitally processed
and mapped the results utilizing the GPS service of the smartphone. The map
generated indicates no disruption in pH for all sites measured. All the data
are assessed to fall inside the upper limit of local government regulations and
are consistent with authority reported measurements. The work demonstrates a
new security concept: environmental forensics utilizing the advantage of
real-time analysis for the detection of potential water quality disruption at
any point in the city. The concept can be extended on national and global
scales to a wide variety of analytes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0872</identifier>
 <datestamp>2014-10-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0872</id><created>2014-08-05</created><updated>2014-10-15</updated><authors><author><keyname>Liao</keyname><forenames>Shengcai</forenames></author><author><keyname>Mo</keyname><forenames>Zhipeng</forenames></author><author><keyname>Zhu</keyname><forenames>Jianqing</forenames></author><author><keyname>Hu</keyname><forenames>Yang</forenames></author><author><keyname>Li</keyname><forenames>Stan Z.</forenames></author></authors><title>Open-set Person Re-identification</title><categories>cs.CV</categories><comments>The OPeRID v1.0 dataset and evaluation toolkit is now available to
  download at http://www.cbsr.ia.ac.cn/users/scliao/projects/operidv1/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Person re-identification is becoming a hot research for developing both
machine learning algorithms and video surveillance applications. The task of
person re-identification is to determine which person in a gallery has the same
identity to a probe image. This task basically assumes that the subject of the
probe image belongs to the gallery, that is, the gallery contains this person.
However, in practical applications such as searching a suspect in a video, this
assumption is usually not true. In this paper, we consider the open-set person
re-identification problem, which includes two sub-tasks, detection and
identification. The detection sub-task is to determine the presence of the
probe subject in the gallery, and the identification sub-task is to determine
which person in the gallery has the same identity as the accepted probe. We
present a database collected from a video surveillance setting of 6 cameras,
with 200 persons and 7,413 images segmented. Based on this database, we develop
a benchmark protocol for evaluating the performance under the open-set person
re-identification scenario. Several popular metric learning algorithms for
person re-identification have been evaluated as baselines. From the baseline
performance, we observe that the open-set person re-identification problem is
still largely unresolved, thus further attention and effort is needed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0876</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0876</id><created>2014-08-05</created><updated>2014-12-27</updated><authors><author><keyname>Fan</keyname><forenames>Congmin</forenames></author><author><keyname>Zhang</keyname><forenames>Ying Jun</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojun</forenames></author></authors><title>Dynamic Nested Clustering for Parallel PHY-Layer Processing in
  Cloud-RANs</title><categories>cs.IT cs.DC math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Featured by centralized processing and cloud based infrastructure, Cloud
Radio Access Network (C-RAN) is a promising solution to achieve an
unprecedented system capacity in future wireless cellular networks. The huge
capacity gain mainly comes from the centralized and coordinated signal
processing at the cloud server. However, full-scale coordination in a
large-scale C-RAN requires the processing of very large channel matrices,
leading to high computational complexity and channel estimation overhead. To
resolve this challenge, we exploit the near-sparsity of large C-RAN channel
matrices, and derive a unified theoretical framework for clustering and
parallel processing. Based on the framework, we propose a dynamic nested
clustering (DNC) algorithm that not only greatly improves the system
scalability in terms of baseband-processing and channel-estimation complexity,
but also is amenable to various parallel processing strategies for different
data center architectures. With the proposed algorithm, we show that the
computation time for the optimal linear detector is greatly reduced from
$O(N^3)$ to no higher than $O(N^{\frac{42}{23}})$, where $N$ is the number of
RRHs in C-RAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0881</identifier>
 <datestamp>2014-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0881</id><created>2014-08-05</created><updated>2014-10-16</updated><authors><author><keyname>Dowty</keyname><forenames>James G.</forenames></author></authors><title>Volumes of logistic regression models with applications to model
  selection</title><categories>math.ST cs.IT math.IT stat.ME stat.ML stat.TH</categories><comments>Improved the section on volume jumps and added a new volume bound
  (Theorem 13) for models with generic design matrices</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logistic regression models with $n$ observations and $q$ linearly-independent
covariates are shown to have Fisher information volumes which are bounded below
by $\pi^q$ and above by ${n \choose q} \pi^q$. This is proved with a novel
generalization of the classical theorems of Pythagoras and de Gua, which is of
independent interest. The finding that the volume is always finite is new, and
it implies that the volume can be directly interpreted as a measure of model
complexity. The volume is shown to be a continuous function of the design
matrix $X$ at generic $X$, but to be discontinuous in general. This means that
models with sparse design matrices can be significantly less complex than
nearby models, so the resulting model-selection criterion prefers sparse
models. This is analogous to the way that $\ell^1$-regularisation tends to
prefer sparse model fits, though in our case this behaviour arises
spontaneously from general principles. Lastly, an unusual topological duality
is shown to exist between the ideal boundaries of the natural and expectation
parameter spaces of logistic regression models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0889</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0889</id><created>2014-08-05</created><updated>2014-08-06</updated><authors><author><keyname>Moosavi</keyname><forenames>Vahid</forenames></author></authors><title>Computing With Contextual Numbers</title><categories>cs.CE cs.CV cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self Organizing Map (SOM) has been applied into several classical modeling
tasks including clustering, classification, function approximation and
visualization of high dimensional spaces. The final products of a trained SOM
are a set of ordered (low dimensional) indices and their associated high
dimensional weight vectors. While in the above-mentioned applications, the
final high dimensional weight vectors play the primary role in the
computational steps, from a certain perspective, one can interpret SOM as a
nonparametric encoder, in which the final low dimensional indices of the
trained SOM are pointer to the high dimensional space. We showed how using a
one-dimensional SOM, which is not common in usual applications of SOM, one can
develop a nonparametric mapping from a high dimensional space to a continuous
one-dimensional numerical field. These numerical values, called contextual
numbers, are ordered in a way that in a given context, similar numbers refer to
similar high dimensional states. Further, as these numbers can be treated
similarly to usual continuous numbers, they can be replaced with their
corresponding high dimensional states within any data driven modeling problem.
As a potential application, we showed how using contextual numbers could be
used for the problem of high dimensional spatiotemporal dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0890</identifier>
 <datestamp>2015-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0890</id><created>2014-08-05</created><updated>2015-01-21</updated><authors><author><keyname>Chen</keyname><forenames>Hubie</forenames></author><author><keyname>Mengel</keyname><forenames>Stefan</forenames></author></authors><title>A Trichotomy in the Complexity of Counting Answers to Conjunctive
  Queries</title><categories>cs.CC cs.DB cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conjunctive queries are basic and heavily studied database queries; in
relational algebra, they are the select-project-join queries. In this article,
we study the fundamental problem of counting, given a conjunctive query and a
relational database, the number of answers to the query on the database. In
particular, we study the complexity of this problem relative to sets of
conjunctive queries. We present a trichotomy theorem, which shows essentially
that this problem on a set of conjunctive queries is either tractable,
equivalent to the parameterized CLIQUE problem, or as hard as the parameterized
counting CLIQUE problem; the criteria describing which of these situations
occurs is simply stated, in terms of graph-theoretic conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0926</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0926</id><created>2014-08-05</created><authors><author><keyname>Halpin</keyname><forenames>Harry</forenames></author><author><keyname>Cheney</keyname><forenames>James</forenames></author></authors><title>Dynamic Provenance for SPARQL Update</title><categories>cs.DB</categories><comments>Pre-publication version of ISWC 2014 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the Semantic Web currently can exhibit provenance information by using
the W3C PROV standards, there is a &quot;missing link&quot; in connecting PROV to storing
and querying for dynamic changes to RDF graphs using SPARQL. Solving this
problem would be required for such clear use-cases as the creation of version
control systems for RDF. While some provenance models and annotation techniques
for storing and querying provenance data originally developed with databases or
workflows in mind transfer readily to RDF and SPARQL, these techniques do not
readily adapt to describing changes in dynamic RDF datasets over time. In this
paper we explore how to adapt the dynamic copy-paste provenance model of
Buneman et al. [2] to RDF datasets that change over time in response to SPARQL
updates, how to represent the resulting provenance records themselves as RDF in
a manner compatible with W3C PROV, and how the provenance information can be
defined by reinterpreting SPARQL updates. The primary contribution of this
paper is a semantic framework that enables the semantics of SPARQL Update to be
used as the basis for a 'cut-and-paste' provenance model in a principled
manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0943</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0943</id><created>2014-08-05</created><updated>2014-08-25</updated><authors><author><keyname>Wehmuth</keyname><forenames>Klaus</forenames><affiliation>National Laboratory for Scientific Computing</affiliation></author><author><keyname>Fleury</keyname><forenames>&#xc9;ric</forenames><affiliation>LIP - Ecole Normale Sup&#xe9;rieure de Lyon</affiliation></author><author><keyname>Ziviani</keyname><forenames>Artur</forenames><affiliation>National Laboratory for Scientific Computing</affiliation></author></authors><title>On MultiAspect Graphs</title><categories>cs.DM</categories><comments>30pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different graph generalizations have been recently used in an ad-hoc manner
to represent multilayer networks, i.e. systems formed by distinct layers where
each layer can be seen as a network. Similar constructions have also been used
to represent time-varying networks. We introduce the concept of MultiAspect
Graph (MAG) as a graph generalization that we prove to be isomorphic to a
directed graph, and also capable of representing all these previous
generalizations. In our proposal, the set of vertices, layers, time instants,
or any other independent feature is considered as an aspect of the MAG. For
instance, a MAG is able to represent multilayer or time-varying networks, while
both concepts can also be combined to represent a multilayer time-varying
network. Since the MAG structure admits an arbitrary (finite) number of
aspects, it hence introduces a powerful modelling abstraction for networked
complex systems. This paper formalizes the concept of MAG and then derives
theoretical results that can be useful in the analysis of complex networked
systems modelled using the proposed MAG abstraction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0948</identifier>
 <datestamp>2015-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0948</id><created>2014-08-05</created><updated>2015-03-05</updated><authors><author><keyname>Maksimenko</keyname><forenames>Aleksandr</forenames></author></authors><title>A special role of Boolean quadratic polytopes among other combinatorial
  polytopes</title><categories>cs.CC math.CO</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider several families of combinatorial polytopes associated with the
following NP-complete problems: maximum cut, Boolean quadratic programming,
quadratic linear ordering, quadratic assignment, set partition, set packing,
stable set, 3-assignment. For comparing two families of polytopes we use the
following method. We say that a family $P$ is affinely reduced to a family $Q$
if for every polytope $p\in P$ there exists $q\in Q$ such that $p$ is affinely
equivalent to $q$ or to a face of $q$, where $\dim q = O((\dim p)^k)$ for some
constant $k$. Under this comparison the above-mentioned families are splitted
into two equivalence classes. We show also that these two classes are simpler
(in the above sence) than the families of poytopes of the following problems:
set covering, traveling salesman, 0-1 knapsack problem, 3-satisfiability, cubic
subgraph, partial ordering. In particular, Boolean quadratic polytopes appear
as faces of polytopes in every of the mentioned families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0957</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0957</id><created>2014-08-05</created><authors><author><keyname>Chu</keyname><forenames>Duc-Hiep</forenames></author><author><keyname>Jaffar</keyname><forenames>Joxan</forenames></author></authors><title>A Framework to Synergize Partial Order Reduction with State
  Interpolation</title><categories>cs.LO cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of reasoning about interleavings in safety
verification of concurrent programs. In the literature, there are two prominent
techniques for pruning the search space. First, there are well-investigated
trace-based methods, collectively known as &quot;Partial Order Reduction (POR)&quot;,
which operate by weakening the concept of a trace by abstracting the total
order of its transitions into a partial order. Second, there is state-based
interpolation where a collection of formulas can be generalized by taking into
account the property to be verified. Our main contribution is a framework that
synergistically combines POR with state interpolation so that the sum is more
than its parts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0965</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0965</id><created>2014-08-05</created><authors><author><keyname>Thang</keyname><forenames>Nguyen Kim</forenames></author></authors><title>Lagrangian Duality based Algorithms in Online Scheduling</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Lagrangian duality based approaches to design and analyze
algorithms for online energy-efficient scheduling. First, we present a
primal-dual framework. Our approach makes use of the Lagrangian weak duality
and convexity to derive dual programs for problems which could be formulated as
convex assignment problems. The duals have intuitive structures as the ones in
linear programming. The constraints of the duals explicitly indicate the online
decisions and naturally lead to competitive algorithms. Second, we use a
dual-fitting approach, which also based on the weak duality, to study problems
which are unlikely to admit convex relaxations. Through the analysis, we show
an interesting feature in which primal-dual gives idea for designing algorithms
while the analysis is done by dual-fitting.
  We illustrate the advantages and the flexibility of the approaches through
problems in different setting: from single machine to unrelated machine
environments, from typical competitive analysis to the one with resource
augmentation, from convex relaxations to non-convex relaxations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0967</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0967</id><created>2014-08-05</created><authors><author><keyname>Race</keyname><forenames>Shaina</forenames></author><author><keyname>Meyer</keyname><forenames>Carl</forenames></author><author><keyname>Valakuzhy</keyname><forenames>Kevin</forenames></author></authors><title>Determining the Number of Clusters via Iterative Consensus Clustering</title><categories>stat.ML cs.CV cs.LG</categories><comments>Proceedings of the 2013 SIAM International Conference on Data Mining</comments><doi>10.1137/1.9781611972832.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use a cluster ensemble to determine the number of clusters, k, in a group
of data. A consensus similarity matrix is formed from the ensemble using
multiple algorithms and several values for k. A random walk is induced on the
graph defined by the consensus matrix and the eigenvalues of the associated
transition probability matrix are used to determine the number of clusters. For
noisy or high-dimensional data, an iterative technique is presented to refine
this consensus matrix in way that encourages a block-diagonal form. It is shown
that the resulting consensus matrix is generally superior to existing
similarity matrices for this type of spectral analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0972</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0972</id><created>2014-08-05</created><authors><author><keyname>Race</keyname><forenames>Shaina</forenames></author><author><keyname>Meyer</keyname><forenames>Carl</forenames></author></authors><title>A Flexible Iterative Framework for Consensus Clustering</title><categories>stat.ML cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel framework for consensus clustering is presented which has the ability
to determine both the number of clusters and a final solution using multiple
algorithms. A consensus similarity matrix is formed from an ensemble using
multiple algorithms and several values for k. A variety of dimension reduction
techniques and clustering algorithms are considered for analysis. For noisy or
high-dimensional data, an iterative technique is presented to refine this
consensus matrix in way that encourages algorithms to agree upon a common
solution. We utilize the theory of nearly uncoupled Markov chains to determine
the number, k , of clusters in a dataset by considering a random walk on the
graph defined by the consensus matrix. The eigenvalues of the associated
transition probability matrix are used to determine the number of clusters.
This method succeeds at determining the number of clusters in many datasets
where previous methods fail. On every considered dataset, our consensus method
provides a final result with accuracy well above the average of the individual
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0979</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0979</id><created>2014-08-05</created><authors><author><keyname>Jha</keyname><forenames>Sumit Kumar</forenames></author><author><keyname>Mukund</keyname><forenames>Madhavan</forenames></author><author><keyname>Saha</keyname><forenames>Ratul</forenames></author><author><keyname>Thiagarajan</keyname><forenames>P S</forenames></author></authors><title>Distributed Markov Chains</title><categories>cs.DC cs.LO</categories><acm-class>D.2.4; F.1.2; F.3.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The formal verification of large probabilistic models is important and
challenging. Exploiting the concurrency that is often present is one way to
address this problem. Here we study a restricted class of asynchronous
distributed probabilistic systems in which the synchronizations determine the
probability distribution for the next moves of the participating agents. The
key restriction we impose is that the synchronizations are deterministic, in
the sense that any two simultaneously enabled synchronizations must involve
disjoint sets of agents. As a result, this network of agents can be viewed as a
succinct and distributed presentation of a large global Markov chain. A rich
class of Markov chains can be represented this way.
  We define an interleaved semantics for our model in terms of the local
synchronization actions. The network structure induces an independence relation
on these actions, which, in turn, induces an equivalence relation over the
interleaved runs in the usual way. We construct a natural probability measure
over these equivalence classes of runs by exploiting Mazurkiewicz trace theory
and the probability measure space of the associated global Markov chain.
  It turns out that verification of our model, called DMCs (distributed Markov
chains), can often be efficiently carried out by exploiting the partial order
nature of the interleaved semantics. To demonstrate this, we develop a
statistical model checking (SMC) procedure and use it to verify two large
distributed probabilistic networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0982</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0982</id><created>2014-08-05</created><authors><author><keyname>Alali</keyname><forenames>Abdelhakim</forenames></author><author><keyname>Assayad</keyname><forenames>Ismail</forenames></author><author><keyname>Sadik</keyname><forenames>Mohamed</forenames></author></authors><title>Modeling and simulation of multiprocessor systems MPSoC by SystemC/TLM2</title><categories>cs.AR</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 11,
  Issue 3, No 2, May 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current manufacturing technology allows the integration of a complex
multiprocessor system on one piece of silicon (MPSoC for Multiprocessor
System-on- Chip). One way to manage the growing complexity of these systems is
to increase the level of abstraction and to address the system-level design. In
this paper, we focus on the implementation in SystemC language with TLM
(Transaction Level Model) to model an MPSOC platform. Our main contribution is
to define a comprehensive, fast and accurate method for designing and
evaluating performance for MPSoC systems. The studied MPSoC is composed of
MicroBlaze microprocessors, memory, a timer, a VGA and an interrupt handler
with two examples of software. This paper has two novel contributions: the
first is to develop this MPSOC at CABA and TLM for ISS (Instruction Set
Simulator), Native simulations and timed Programmer s View (PV+T); the second
is to show that with PV+T simulations we can achieve timing fidelity with
higher speeds than CABA simulations and have almost the same precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0985</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0985</id><created>2014-08-05</created><authors><author><keyname>Luque</keyname><forenames>Jordi</forenames></author><author><keyname>Luque</keyname><forenames>Bartolo</forenames></author><author><keyname>Lacasa</keyname><forenames>Lucas</forenames></author></authors><title>Speech earthquakes: scaling and universality in human voice</title><categories>physics.soc-ph cs.CL q-bio.NC</categories><comments>Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Speech is a distinctive complex feature of human capabilities. In order to
understand the physics underlying speech production, in this work we
empirically analyse the statistics of large human speech datasets ranging
several languages. We first show that during speech the energy is unevenly
released and power-law distributed, reporting a universal robust
Gutenberg-Richter-like law in speech. We further show that such earthquakes in
speech show temporal correlations, as the interevent statistics are again
power-law distributed. Since this feature takes place in the intra-phoneme
range, we conjecture that the responsible for this complex phenomenon is not
cognitive, but it resides on the physiological speech production mechanism.
Moreover, we show that these waiting time distributions are scale invariant
under a renormalisation group transformation, suggesting that the process of
speech generation is indeed operating close to a critical point. These results
are put in contrast with current paradigms in speech processing, which point
towards low dimensional deterministic chaos as the origin of nonlinear traits
in speech fluctuations. As these latter fluctuations are indeed the aspects
that humanize synthetic speech, these findings may have an impact in future
speech synthesis technologies. Results are robust and independent of the
communication language or the number of speakers, pointing towards an universal
pattern and yet another hint of complexity in human speech.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0990</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0990</id><created>2014-08-02</created><authors><author><keyname>Rao</keyname><forenames>M. V. Panduranga</forenames></author><author><keyname>Shet</keyname><forenames>K. C.</forenames></author></authors><title>Assessment of Response Time for New Multi Level Feedback Queue Scheduler</title><categories>cs.OS</categories><comments>7 pages, 5 figures</comments><msc-class>68U20</msc-class><acm-class>D.3.2</acm-class><journal-ref>International Journal of Computer Trends and Technology (IJCTT),
  Volume 13, Number 3, Pages: 113-119, July 2014. ISSN:2231-2803</journal-ref><doi>10.14445/22312803/IJCTT-V13P124</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Response time is one of the characteristics of scheduler, happens to be a
prominent attribute of any CPU scheduling algorithm. The proposed New Multi
Level Feedback Queue [NMLFQ] Scheduler is compared with dynamic, real time,
Dependent Activity Scheduling Algorithm (DASA) and Lockes Best Effort
Scheduling Algorithm (LBESA). We abbreviated beneficial result of NMLFQ
scheduler in comparison with dynamic best effort schedulers with respect to
response time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.0998</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.0998</id><created>2014-08-05</created><authors><author><keyname>Risi</keyname><forenames>Sebastian</forenames></author><author><keyname>Zhang</keyname><forenames>Jinhong</forenames></author><author><keyname>Taarnby</keyname><forenames>Rasmus</forenames></author><author><keyname>Greve</keyname><forenames>Peter</forenames></author><author><keyname>Piskur</keyname><forenames>Jan</forenames></author><author><keyname>Liapis</keyname><forenames>Antonios</forenames></author><author><keyname>Togelius</keyname><forenames>Julian</forenames></author></authors><title>The Case for a Mixed-Initiative Collaborative Neuroevolution Approach</title><categories>cs.NE</categories><comments>Presented at WebAL-1: Workshop on Artificial Life and the Web 2014
  (arXiv:1406.2507)</comments><report-no>WebAL1/2014/06</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is clear that the current attempts at using algorithms to create
artificial neural networks have had mixed success at best when it comes to
creating large networks and/or complex behavior. This should not be unexpected,
as creating an artificial brain is essentially a design problem. Human design
ingenuity still surpasses computational design for most tasks in most domains,
including architecture, game design, and authoring literary fiction. This leads
us to ask which the best way is to combine human and machine design capacities
when it comes to designing artificial brains. Both of them have their strengths
and weaknesses; for example, humans are much too slow to manually specify
thousands of neurons, let alone the billions of neurons that go into a human
brain, but on the other hand they can rely on a vast repository of common-sense
understanding and design heuristics that can help them perform a much better
guided search in design space than an algorithm. Therefore, in this paper we
argue for a mixed-initiative approach for collaborative online brain building
and present first results towards this goal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1000</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1000</id><created>2014-08-02</created><updated>2015-04-14</updated><authors><author><keyname>Acharya</keyname><forenames>Jayadev</forenames></author><author><keyname>Orlitsky</keyname><forenames>Alon</forenames></author><author><keyname>Suresh</keyname><forenames>Ananda Theertha</forenames></author><author><keyname>Tyagi</keyname><forenames>Himanshu</forenames></author></authors><title>Estimating Renyi Entropy of Discrete Distributions</title><categories>cs.IT cs.DS cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was recently shown that estimating the Shannon entropy $H(p)$ of a
discrete $k$-symbol distribution $p$ requires $\Theta(k/\log k)$ samples, a
number that grows near-linearly in the support size. In many applications
$H(p)$ can be replaced by the more general Renyi entropy of order $\alpha$,
$H_\alpha(p)$. We determine the number of samples needed to estimate
$H_\alpha(p)$ for all $\alpha$, showing that $\alpha &lt; 1$ requires a
super-linear, roughly $k^{1/\alpha}$ samples, noninteger $\alpha&gt;1$ requires a
near-linear $k$ samples, but, perhaps surprisingly, integer $\alpha&gt;1$ requires
only $\Theta(k^{1-1/\alpha})$ samples. Furthermore, developing on a recently
established connection between polynomial approximation and estimation of
additive functions of the form $\sum_x f (p_x)$, we reduce the sample
complexity for noninteger values of $\alpha$ by a factor of $\log k$ compared
to the empirical estimator. The estimators achieving these bounds are simple
and run in time linear in the number of samples. Our lower bound provides an
explicit construction of distributions with different Renyi entropies that are
hard to distinguish.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1011</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1011</id><created>2014-08-05</created><updated>2014-08-06</updated><authors><author><keyname>Hasibi</keyname><forenames>Faegheh</forenames></author><author><keyname>Bratsberg</keyname><forenames>Svein Erik</forenames></author></authors><title>Non-hierarchical Structures: How to Model and Index Overlaps?</title><categories>cs.DB cs.DS cs.IR</categories><comments>The paper has been accepted at the Balisage 2014 conference</comments><acm-class>H.3.1; H.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Overlap is a common phenomenon seen when structural components of a digital
object are neither disjoint nor nested inside each other. Overlapping
components resist reduction to a structural hierarchy, and tree-based indexing
and query processing techniques cannot be used for them. Our solution to this
data modeling problem is TGSA (Tree-like Graph for Structural Annotations), a
novel extension of the XML data model for non-hierarchical structures. We
introduce an algorithm for constructing TGSA from annotated documents; the
algorithm can efficiently process non-hierarchical structures and is associated
with formal proofs, ensuring that transformation of the document to the data
model is valid. To enable high performance query analysis in large data
repositories, we further introduce an extension of XML pre-post indexing for
non-hierarchical structures, which can process both reachability and
overlapping relationships.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1017</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1017</id><created>2014-08-05</created><authors><author><keyname>Etessami</keyname><forenames>Kousha</forenames></author><author><keyname>Hansen</keyname><forenames>Kristoffer Arnsfelt</forenames></author><author><keyname>Miltersen</keyname><forenames>Peter Bro</forenames></author><author><keyname>Sorensen</keyname><forenames>Troels Bjerre</forenames></author></authors><title>The complexity of approximating a trembling hand perfect equilibrium of
  a multi-player game in strategic form</title><categories>cs.GT cs.CC</categories><comments>conference version to appear at SAGT'14</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the task of computing an approximation of a trembling hand
perfect equilibrium for an n-player game in strategic form, n &gt;= 3. We show
that this task is complete for the complexity class FIXP_a. In particular, the
task is polynomial time equivalent to the task of computing an approximation of
a Nash equilibrium in strategic form games with three (or more) players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1021</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1021</id><created>2014-08-05</created><authors><author><keyname>Calciu</keyname><forenames>Irina</forenames></author><author><keyname>Mendes</keyname><forenames>Hammurabi</forenames></author><author><keyname>Herlihy</keyname><forenames>Maurice</forenames></author></authors><title>The Adaptive Priority Queue with Elimination and Combining</title><categories>cs.DC</categories><comments>Accepted at DISC'14 - this is the full version with appendices,
  including more algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Priority queues are fundamental abstract data structures, often used to
manage limited resources in parallel programming. Several proposed parallel
priority queue implementations are based on skiplists, harnessing the potential
for parallelism of the add() operations. In addition, methods such as Flat
Combining have been proposed to reduce contention by batching together multiple
operations to be executed by a single thread. While this technique can decrease
lock-switching overhead and the number of pointer changes required by the
removeMin() operations in the priority queue, it can also create a sequential
bottleneck and limit parallelism, especially for non-conflicting add()
operations.
  In this paper, we describe a novel priority queue design, harnessing the
scalability of parallel insertions in conjunction with the efficiency of
batched removals. Moreover, we present a new elimination algorithm suitable for
a priority queue, which further increases concurrency on balanced workloads
with similar numbers of add() and removeMin() operations. We implement and
evaluate our design using a variety of techniques including locking, atomic
operations, hardware transactional memory, as well as employing adaptive
heuristics given the workload.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1022</identifier>
 <datestamp>2014-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1022</id><created>2014-08-05</created><updated>2014-08-05</updated><authors><author><keyname>Aryal</keyname><forenames>Gaurab</forenames></author><author><keyname>Stauber</keyname><forenames>Ronald</forenames></author></authors><title>A Note on Kuhn's Theorem with Ambiguity Averse Players</title><categories>q-fin.EC cs.GT</categories><comments>7 figures</comments><doi>10.1016/j.econlet.2014.08.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kuhn's Theorem shows that extensive games with perfect recall can
equivalently be analyzed using mixed or behavioral strategies, as long as
players are expected utility maximizers. This note constructs an example that
illustrate the limits of Kuhn's Theorem in an environment with ambiguity averse
players who use maxmin decision rule and full Bayesian updating.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1023</identifier>
 <datestamp>2015-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1023</id><created>2014-08-05</created><updated>2015-07-02</updated><authors><author><keyname>Yu</keyname><forenames>Jiangshan</forenames></author><author><keyname>Cheval</keyname><forenames>Vincent</forenames></author><author><keyname>Ryan</keyname><forenames>Mark</forenames></author></authors><title>DTKI: a new formalized PKI with no trusted parties</title><categories>cs.CR</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The security of public key validation protocols for web-based applications
has recently attracted attention because of weaknesses in the certificate
authority model, and consequent attacks.
  Recent proposals using public logs have succeeded in making certificate
management more transparent and verifiable. How- ever, those proposals involve
a fixed set of authorities which create a monopoly, and they have heavy
reliance on trusted parties that monitor the logs.
  We propose a distributed transparent key infrastructure (DTKI), which greatly
reduces the monopoly of service providers and removes the reliance on trusted
parties. In addition, this paper formalises the public log data structure and
provides a formal analysis of the security that DTKI guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1025</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1025</id><created>2014-08-05</created><authors><author><keyname>Alaa</keyname><forenames>Ahmed M.</forenames></author></authors><title>Stable Throughput Region of Cognitive-Relay Networks with Imperfect
  Sensing and Finite Relaying Buffer</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we obtain the stable throughput region for a cognitive
relaying scheme with a finite relaying buffer and imperfect sensing. The
analysis investigates the effect of the secondary user's finite relaying
capabilities under different scenarios of primary, secondary and relaying links
outages. Furthermore, we demonstrate the effect of miss detection and false
alarm probabilities on the achievable throughput for the primary and secondary
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1031</identifier>
 <datestamp>2014-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1031</id><created>2014-07-31</created><updated>2014-12-23</updated><authors><author><keyname>Elhoseiny</keyname><forenames>Mohamed</forenames></author><author><keyname>Elgammal</keyname><forenames>Ahmed</forenames></author></authors><title>Text to Multi-level MindMaps: A Novel Method for Hierarchical Visual
  Abstraction of Natural Language Text</title><categories>cs.CL cs.HC</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MindMapping is a well-known technique used in note taking, which encourages
learning and studying. MindMapping has been manually adopted to help present
knowledge and concepts in a visual form. Unfortunately, there is no reliable
automated approach to generate MindMaps from Natural Language text. This work
firstly introduces MindMap Multilevel Visualization concept which is to jointly
visualize and summarize textual information. The visualization is achieved
pictorially across multiple levels using semantic information (i.e. ontology),
while the summarization is achieved by the information in the highest levels as
they represent abstract information in the text. This work also presents the
first automated approach that takes a text input and generates a MindMap
visualization out of it. The approach could visualize text documents in
multilevel MindMaps, in which a high-level MindMap node could be expanded into
child MindMaps. \ignore{ As far as we know, this is the first work that view
MindMapping as a new approach to jointly summarize and visualize textual
information.} The proposed method involves understanding of the input text and
converting it into intermediate Detailed Meaning Representation (DMR). The DMR
is then visualized with two modes; Single level or Multiple levels, which is
convenient for larger text. The generated MindMaps from both approaches were
evaluated based on Human Subject experiments performed on Amazon Mechanical
Turk with various parameter settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1032</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1032</id><created>2014-08-04</created><authors><author><keyname>Iyer</keyname><forenames>K. Viswanathan</forenames></author></authors><title>A case for Intranet-based 0nline portal for undergraduate Computer
  Science education</title><categories>cs.CY</categories><comments>V Annual International Conference on Computer Science Education:
  Innovation and Technology, 22-23 Sept. 2014, Singapore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our proposal for selective subjects especially those involving intensive
problem-solving assignments and/or tutorials, such as Introduction to
Algorithms and Data structures, Discrete Mathematics, Coding Theory, Number
theory, Combinatorics and Graph Theory (CGT), Automata theory, is to supplement
lectures with a moderated online forum against an intranet portal. By way of
illustration we take the example of a restricted view of OEIS
(http://oeis.org). The restriction can be w.r.t. sequences in OEIS that are
directly relevant to say CGT. N.J.A.Sloane's OEIS is a collection of over
2,39,147 integer sequences and their properties. In particular OEIS contains
definitions of many combinatorial structures, dense range of interpretations,
generating functions and conjectured ones, cross references within OEIS and to
outside resources, references to texts and technical articles, codes in Maple,
Mathematica etc. For organizing courses such as the above mentioned, a first
task is to partially create an OEIS-like instructor-moderated portal in a
university intranet. During the course of lectures and tutorials students are
invited to contribute to the portal and these may be augmented/approved by
instructors suitably, to find a place in the portal. By this many concepts can
be conveyed to the students in an interesting way with the desired results. In
the arguments presented, examples related to CGT are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1044</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1044</id><created>2014-08-05</created><updated>2014-11-01</updated><authors><author><keyname>Perea-Vega</keyname><forenames>Diego</forenames></author><author><keyname>Girard</keyname><forenames>Andre</forenames></author><author><keyname>Frigon</keyname><forenames>Jean-Francois</forenames></author></authors><title>Fast Heuristics for Power Allocation in Zero-Forcing OFDMA-SDMA Systems
  with Minimum Rate Constraints</title><categories>cs.IT cs.NI math.IT</categories><comments>17 text pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate in this paper the optimal power allocation in an OFDM-SDMA
system when some users have minimum downlink transmission rate requirements. We
first solve the unconstrained power allocation problem for which we propose a
fast zero-finding technique that is guaranteed to find an optimal solution, and
an approximate solution that has lower complexity but is not guaranteed to
converge. For the more complex minimum rate constrained problem, we propose two
approximate algorithms. One is an iterative technique that finds an optimal
solution on the rate boundaries so that the solution is feasible, but not
necessarily optimal. The other is not iterative but cannot guarantee a feasible
solution. We present numerical results showing that the computation time for
the iterative heuristic is one order of magnitude faster than finding the exact
solution with a numerical solver, and the non-iterative technique is an
additional order of magnitude faster than the iterative heuristic. We also show
that in most cases, the amount of infeasibility with the non-iterative
technique is small enough that it could probably be used in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1052</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1052</id><created>2014-08-05</created><authors><author><keyname>Sooda</keyname><forenames>Kavitha</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Optimal path selection in Graded network using Artificial Bee Colony
  algorithm with Agent enabled Information</title><categories>cs.NI</categories><comments>6 pages, 4 figures, 2 tables, Hybrid Intelligent Systems (HIS), 2012
  12th International Conference on</comments><doi>10.1109/HIS.2012.6421356</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a network aware approach for routing in graded
network using Artificial Bee Colony (ABC) algorithm. ABC has been used as a
good search process for optimality exploitation and exploration. The paper
shows how ABC approach has been utilized for determining the optimal path based
on bandwidth availability of the link and how it outperformed non graded
network while deriving the optimal path. The selection of the nodes is based on
the direction of the destination node also. This would help in narrowing down
the number of nodes participating in routing. Here an agent system governs the
collection of QoS parameters of the nodes. Also a quadrant is synthesized with
centre as the source node. Based on the information of which quadrant the
destination belongs, a search is performed. Among the many searches observed by
the onlooker bees the best path is selected based on which onlooker bee comes
back to source with information of the optimal path. The simulation result
shows that the path convergence in graded network with ABC was 30% faster than
non-graded ABC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1054</identifier>
 <datestamp>2015-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1054</id><created>2014-08-04</created><authors><author><keyname>Czarnecki</keyname><forenames>Wojciech Marian</forenames></author><author><keyname>Tabor</keyname><forenames>Jacek</forenames></author></authors><title>Multithreshold Entropy Linear Classifier</title><categories>cs.LG stat.ML</categories><doi>10.1016/j.eswa.2015.03.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear classifiers separate the data with a hyperplane. In this paper we
focus on the novel method of construction of multithreshold linear classifier,
which separates the data with multiple parallel hyperplanes. Proposed model is
based on the information theory concepts -- namely Renyi's quadratic entropy
and Cauchy-Schwarz divergence.
  We begin with some general properties, including data scale invariance. Then
we prove that our method is a multithreshold large margin classifier, which
shows the analogy to the SVM, while in the same time works with much broader
class of hypotheses. What is also interesting, proposed method is aimed at the
maximization of the balanced quality measure (such as Matthew's Correlation
Coefficient) as opposed to very common maximization of the accuracy. This
feature comes directly from the optimization problem statement and is further
confirmed by the experiments on the UCI datasets.
  It appears, that our Multithreshold Entropy Linear Classifier (MELC) obtaines
similar or higher scores than the ones given by SVM on both synthetic and real
data. We show how proposed approach can be benefitial for the cheminformatics
in the task of ligands activity prediction, where despite better classification
results, MELC gives some additional insight into the data structure (classes of
underrepresented chemical compunds).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1068</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1068</id><created>2014-08-05</created><authors><author><keyname>Aguilar</keyname><forenames>Jorge</forenames></author><author><keyname>Sanchez</keyname><forenames>Moises</forenames></author><author><keyname>Fernandez-y-Fernandez</keyname><forenames>Carlos</forenames></author><author><keyname>Rocha</keyname><forenames>Everth</forenames></author><author><keyname>Martinez</keyname><forenames>David</forenames></author><author><keyname>Figueroa</keyname><forenames>Jose</forenames></author></authors><title>The Size of Software Projects Developed by Mexican Companies</title><categories>cs.SE</categories><comments>5 pages, The 2014 International Conference on Software Engineering
  Research and Practice (SERP'14)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, most software projects around the world are small rather than
large. Despite this, there are more methodologies, tools, frameworks,
processes, and so on, for developing and managing large software projects than
for small ones. Small software projects are important because they generate
considerable resources. For example: apps (small mobile applications) generate
around $25 billion dollars of revenue. This paper shows our findings regarding
the size of the projects built by Mexican software development companies. We
surveyed 107 Mexican companies and found that 92% of their developed projects
are micro and small, and 8% are medium or large. In addition, according to our
research, 84.1% of companies in Mexico are micro or small businesses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1076</identifier>
 <datestamp>2014-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1076</id><created>2014-08-05</created><authors><author><keyname>Backes</keyname><forenames>Michael</forenames></author><author><keyname>Grimm</keyname><forenames>Niklas</forenames></author><author><keyname>Kate</keyname><forenames>Aniket</forenames></author></authors><title>Lime: Data Lineage in the Malicious Environment</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intentional or unintentional leakage of confidential data is undoubtedly one
of the most severe security threats that organizations face in the digital era.
The threat now extends to our personal lives: a plethora of personal
information is available to social networks and smartphone providers and is
indirectly transferred to untrustworthy third party and fourth party
applications.
  In this work, we present a generic data lineage framework LIME for data flow
across multiple entities that take two characteristic, principal roles (i.e.,
owner and consumer). We define the exact security guarantees required by such a
data lineage mechanism toward identification of a guilty entity, and identify
the simplifying non repudiation and honesty assumptions. We then develop and
analyze a novel accountable data transfer protocol between two entities within
a malicious environment by building upon oblivious transfer, robust
watermarking, and signature primitives. Finally, we perform an experimental
evaluation to demonstrate the practicality of our protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1087</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1087</id><created>2014-08-05</created><authors><author><keyname>Sooda</keyname><forenames>Kavitha</forenames></author><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author></authors><title>Competitive performance analysis of two evolutionary algorithms for
  routing optimization in graded network</title><categories>cs.NI</categories><comments>6 pages, 7 figures, 2 tables, 3rd IEEE International Advanced
  Computing Conference (IACC), 2013. arXiv admin note: text overlap with
  arXiv:1408.1052</comments><doi>10.1109/IAdCC.2013.651430</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we compare the two intelligent route generation system and its
performance capability in graded networks using Artificial Bee Colony (ABC)
algorithm and Genetic Algorithm (GA). Both ABC and GA have found its importance
in optimization technique for determining optimal path while routing operations
in the network. The paper shows how ABC approach has been utilized for
determining the optimal path based on bandwidth availability of the links and
determines better quality paths over GA. Here the nodes participating in the
routing are evaluated for their QoS metric. The nodes which satisfy the minimum
threshold value of the metric are chosen and enabled to participate in routing.
A quadrant is synthesized on the source as the centre and depending on which
quadrant the destination node belongs to, a search for optimal path is
performed. The simulation results show that ABC speeds up local minimum search
convergence by around 60% as compared to GA with respect to traffic intensity,
and opens the possibility for cognitive routing in future intelligent networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1110</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1110</id><created>2014-08-05</created><authors><author><keyname>Zeng</keyname><forenames>Yingfu</forenames></author><author><keyname>Rose</keyname><forenames>Chad</forenames></author><author><keyname>Brauner</keyname><forenames>Paul</forenames></author><author><keyname>Taha</keyname><forenames>Walid</forenames></author><author><keyname>Masood</keyname><forenames>Jawad</forenames></author><author><keyname>Philippsen</keyname><forenames>Roland</forenames></author><author><keyname>Malley</keyname><forenames>Marcia O.</forenames></author><author><keyname>Cartwright</keyname><forenames>Robert</forenames></author></authors><title>Modeling Basic Aspects of Cyber-Physical Systems, Part II</title><categories>cs.RO</categories><comments>Presented at DSLRob 2013 (arXiv:cs/1312.5952)</comments><report-no>DSLRob/2013/03</report-no><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We continue to consider the question of what language features are needed to
effectively model cyber-physical systems (CPS). In previous work, we proposed
using a core language as a way to study this question, and showed how several
basic aspects of CPS can be modeled clearly in a language with a small set of
constructs. This paper reports on the result of our analysis of two, more
complex, case studies from the domain of rigid body dynamics. The first one, a
quadcopter, illustrates that previously proposed core language can support
larger, more interesting systems than previously shown. The second one, a
serial robot, provides a concrete example of why we should add language support
for static partial derivatives, namely that it would significantly improve the
way models of rigid body dynamics can be expressed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1118</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1118</id><created>2014-08-05</created><authors><author><keyname>Ebeida</keyname><forenames>Mohamed S.</forenames></author><author><keyname>Mitchell</keyname><forenames>Scott A.</forenames></author><author><keyname>Awad</keyname><forenames>Muhammad A.</forenames></author><author><keyname>Park</keyname><forenames>Chonhyon</forenames></author><author><keyname>Swiler</keyname><forenames>Laura P.</forenames></author><author><keyname>Manocha</keyname><forenames>Dinesh</forenames></author><author><keyname>Wei</keyname><forenames>Li-Yi</forenames></author></authors><title>Spoke Darts for Efficient High Dimensional Blue Noise Sampling</title><categories>cs.GR</categories><comments>12 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blue noise refers to sample distributions that are random and well-spaced,
with a variety of applications in graphics, geometry, and optimization.
However, prior blue noise sampling algorithms typically suffer from the
curse-of-dimensionality, especially when striving to cover a domain maximally.
This hampers their applicability for high dimensional domains.
  We present a blue noise sampling method that can achieve high quality and
performance across different dimensions. Our key idea is spoke-dart sampling,
sampling locally from hyper-annuli centered at prior point samples, using
lines, planes, or, more generally, hyperplanes. Spoke-dart sampling is more
efficient at high dimensions than the state-of-the-art alternatives: global
sampling and advancing front point sampling. Spoke-dart sampling achieves good
quality as measured by differential domain spectrum and spatial coverage. In
particular, it probabilistically guarantees that each coverage gap is small,
whereas global sampling can only guarantee that the sum of gaps is not large.
We demonstrate advantages of our method through empirical analysis and
applications across dimensions 8 to 23 in Delaunay graphs, global optimization,
and motion planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1119</identifier>
 <datestamp>2015-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1119</id><created>2014-08-05</created><updated>2015-04-13</updated><authors><author><keyname>Scarlett</keyname><forenames>Jonathan</forenames></author><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author></authors><title>Second-Order Asymptotics for the Discrete Memoryless MAC with Degraded
  Message Sets</title><categories>cs.IT math.IT</categories><comments>5 Pages, 1 Figure. Follow-up paper of http://arxiv.org/abs/1310.1197.
  Accepted to ISIT 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the second-order asymptotics of the discrete memoryless
multiple-access channel with degraded message sets. For a fixed average error
probability $\epsilon\in(0,1)$ and an arbitrary point on the boundary of the
capacity region, we characterize the speed of convergence of rate pairs that
converge to that point for codes that have asymptotic error probability no
larger than $\epsilon$, thus complementing an analogous result given previously
for the Gaussian setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1127</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1127</id><created>2014-08-05</created><authors><author><keyname>Solnushkin</keyname><forenames>Konstantin S.</forenames></author></authors><title>SADDLE: A Modular Design Automation Framework for Cluster Supercomputers
  and Data Centres</title><categories>cs.DC</categories><comments>13 pages, 2 figures, 1 table. The work was presented at the
  International Supercomputing Conference (ISC'14) in Leipzig, Germany</comments><acm-class>C.1.4; C.5.1; J.6; K.6.2</acm-class><journal-ref>Springer, Lecture Notes in Computer Science (LNCS), Volume 8488,
  2014, pp 232-244</journal-ref><doi>10.1007/978-3-319-07518-1_15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present SADDLE, a modular framework for automated design of
cluster supercomputers and data centres. In contrast with commonly used
approaches that operate on logic gate level (Verilog, VHDL) or board level
(such as EDA tools), SADDLE works at a much higher level of abstraction: its
building blocks are ready-made servers, network switches, power supply systems
and so on. Modular approach provides the potential to include low-level tools
as elements of SADDLE's design workflow, moving towards the goal of electronic
system level (ESL) design automation. Designs produced by SADDLE include
project documentation items such as bills of materials and wiring diagrams,
providing a formal specification of a computer system and streamlining assembly
operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1135</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1135</id><created>2014-08-05</created><authors><author><keyname>Avanaki</keyname><forenames>Ali R. N.</forenames></author><author><keyname>Espig</keyname><forenames>Kathryn S.</forenames></author><author><keyname>Xthona</keyname><forenames>Albert</forenames></author><author><keyname>Kimpe</keyname><forenames>Tom R. L.</forenames></author><author><keyname>Bakic</keyname><forenames>Predrag R.</forenames></author><author><keyname>Maidment</keyname><forenames>Andrew D. A.</forenames></author></authors><title>It is hard to see a needle in a haystack: Modeling contrast masking
  effect in a numerical observer</title><categories>cs.CV</categories><doi>10.1007/978-3-319-07887-8_100</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the framework of a virtual clinical trial for breast imaging, we aim
to develop numerical observers that follow the same detection performance
trends as those of a typical human observer. In our prior work, we showed that
by including spatiotemporal contrast sensitivity function (stCSF) of human
visual system (HVS) in a multi-slice channelized Hotelling observer (msCHO), we
can correctly predict trends of a typical human observer performance with the
viewing parameters of browsing speed, viewing distance and contrast. In this
work we further improve our numerical observer by modeling contrast masking.
After stCSF, contrast masking is the second most prominent property of HVS and
it refers to the fact that the presence of one signal affects the visibility
threshold for another signal. Our results indicate that the improved numerical
observer better predicts changes in detection performance with background
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1136</identifier>
 <datestamp>2015-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1136</id><created>2014-08-05</created><updated>2015-06-22</updated><authors><author><keyname>Gardiner</keyname><forenames>Joseph</forenames></author><author><keyname>Cova</keyname><forenames>Marco</forenames></author><author><keyname>Nagaraja</keyname><forenames>Shishir</forenames></author></authors><title>Command &amp; Control: Understanding, Denying and Detecting - A review of
  malware C2 techniques, detection and defences</title><categories>cs.CR</categories><comments>Work commissioned by CPNI, available at c2report.org. 38 pages.
  Listing abstract compressed from version appearing in report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this survey, we first briefly review the current state of cyber attacks,
highlighting significant recent changes in how and why such attacks are
performed. We then investigate the mechanics of malware command and control
(C2) establishment: we provide a comprehensive review of the techniques used by
attackers to set up such a channel and to hide its presence from the attacked
parties and the security tools they use. We then switch to the defensive side
of the problem, and review approaches that have been proposed for the detection
and disruption of C2 channels. We also map such techniques to widely-adopted
security controls, emphasizing gaps or limitations (and success stories) in
current best practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1147</identifier>
 <datestamp>2015-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1147</id><created>2014-08-05</created><authors><author><keyname>Krotov</keyname><forenames>Denis</forenames></author><author><keyname>Villanueva</keyname><forenames>Merc&#xe8;</forenames></author></authors><title>Classification of the Z2Z4-Linear Hadamard Codes and Their Automorphism
  Groups</title><categories>cs.IT math.CO math.IT</categories><comments>19 pages</comments><msc-class>94B05, 94B25</msc-class><journal-ref>IEEE Trans. Inf. Theory 61(2) 2015, 887-894</journal-ref><doi>10.1109/TIT.2014.2379644</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $Z_2Z_4$-linear Hadamard code of length $\alpha+2\beta=2^t$ is a binary
Hadamard code which is the Gray map image of a $Z_2Z_4$-additive code with
$\alpha$ binary coordinates and $\beta$ quaternary coordinates. It is known
that there are exactly $\lfloor (t-1)/2 \rfloor$ and $\lfloor t/2 \rfloor$
nonequivalent $Z_2Z_4$-linear Hadamard codes of length $2^t$, with $\alpha=0$
and $\alpha \not= 0$, respectively, for all $t\geq 3$. In this paper, it is
shown that each $Z_2Z_4$-linear Hadamard code with $\alpha=0$ is equivalent to
a $Z_2Z_4$-linear Hadamard code with $\alpha \not= 0$; so there are only
$\lfloor t/2 \rfloor$ nonequivalent $Z_2Z_4$-linear Hadamard codes of length
$2^t$. Moreover, the order of the monomial automorphism group for the
$Z_2Z_4$-additive Hadamard codes and the permutation automorphism group of the
corresponding $Z_2Z_4$-linear Hadamard codes are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1150</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1150</id><created>2014-08-05</created><authors><author><keyname>Jain</keyname><forenames>Abhishek</forenames></author><author><keyname>Gupta</keyname><forenames>Dr. Hima</forenames></author><author><keyname>Jana</keyname><forenames>Sandeep</forenames></author><author><keyname>Kumar</keyname><forenames>Krishna</forenames></author></authors><title>Early Development of UVM based Verification Environment of Image Signal
  Processing Designs using TLM Reference Model of RTL</title><categories>cs.SE</categories><comments>International Journal of Advanced Computer Science and Applications,
  Vol. 5, No. 2, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With semiconductor industry trend of smaller the better, from an idea to a
final product, more innovation on product portfolio and yet remaining
competitive and profitable are few criteria which are culminating into pressure
and need for more and more innovation for CAD flow, process management and
project execution cycle. Project schedules are very tight and to achieve first
silicon success is key for projects. This necessitates quicker verification
with better coverage matrix. Quicker Verification requires early development of
the verification environment with wider test vectors without waiting for RTL to
be available.
  In this paper, we are presenting a novel approach of early development of
reusable multi-language verification flow, by addressing four major activities
of verification like Early creation of Executable Specification, Early creation
of Verification Environment, Early development of test vectors and Better and
increased Re-use of blocks.
  Although this paper focuses on early development of UVM based Verification
Environment of Image Signal Processing designs using TLM Reference Model of
RTL, same concept can be extended for non-image signal processing designs.
  Main Keywords are SystemVerilog, SystemC, Transaction Level Modeling,
Universal Verification Methodology (UVM), Processor model, Universal
Verification Component (UVC), Reference Model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1155</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1155</id><created>2014-08-05</created><authors><author><keyname>Mohar</keyname><forenames>Bojan</forenames></author><author><keyname>Rafiey</keyname><forenames>Arash</forenames></author><author><keyname>Tayfeh-Rezaie</keyname><forenames>Behruz</forenames></author><author><keyname>Wu</keyname><forenames>Hehui</forenames></author></authors><title>Interval minors of complete bipartite graphs</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interval minors of bipartite graphs were recently introduced by Jacob Fox in
the study of Stanley-Wilf limits. We investigate the maximum number of edges in
$K_{r,s}$-interval minor free bipartite graphs. We determine exact values when
$r=2$ and describe the extremal graphs. For $r=3$, lower and upper bounds are
given and the structure of $K_{3,s}$-interval minor free graphs is studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1160</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1160</id><created>2014-08-05</created><authors><author><keyname>Tran</keyname><forenames>Truyen</forenames></author><author><keyname>Phung</keyname><forenames>Dinh</forenames></author><author><keyname>Venkatesh</keyname><forenames>Svetha</forenames></author></authors><title>Mixed-Variate Restricted Boltzmann Machines</title><categories>stat.ML cs.LG stat.ME</categories><comments>Originally published in Proceedings of ACML'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern datasets are becoming heterogeneous. To this end, we present in this
paper Mixed-Variate Restricted Boltzmann Machines for simultaneously modelling
variables of multiple types and modalities, including binary and continuous
responses, categorical options, multicategorical choices, ordinal assessment
and category-ranked preferences. Dependency among variables is modeled using
latent binary variables, each of which can be interpreted as a particular
hidden aspect of the data. The proposed model, similar to the standard RBMs,
allows fast evaluation of the posterior for the latent variables. Hence, it is
naturally suitable for many common tasks including, but not limited to, (a) as
a pre-processing step to convert complex input data into a more convenient
vectorial representation through the latent posteriors, thereby offering a
dimensionality reduction capacity, (b) as a classifier supporting binary,
multiclass, multilabel, and label-ranking outputs, or a regression tool for
continuous outputs and (c) as a data completion tool for multimodal and
heterogeneous data. We evaluate the proposed model on a large-scale dataset
using the world opinion survey results on three tasks: feature extraction and
visualization, data completion and prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1162</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1162</id><created>2014-08-05</created><authors><author><keyname>Tran</keyname><forenames>Truyen</forenames></author><author><keyname>Phung</keyname><forenames>Dinh</forenames></author><author><keyname>Venkatesh</keyname><forenames>Svetha</forenames></author><author><keyname>Bui</keyname><forenames>Hung H.</forenames></author></authors><title>MCMC for Hierarchical Semi-Markov Conditional Random Fields</title><categories>stat.ML cs.LG stat.ME</categories><comments>NIPS'09 Workshop on Deep Learning for Speech Recognition and Related
  Applications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep architecture such as hierarchical semi-Markov models is an important
class of models for nested sequential data. Current exact inference schemes
either cost cubic time in sequence length, or exponential time in model depth.
These costs are prohibitive for large-scale problems with arbitrary length and
depth. In this contribution, we propose a new approximation technique that may
have the potential to achieve sub-cubic time complexity in length and linear
time depth, at the cost of some loss of quality. The idea is based on two
well-known methods: Gibbs sampling and Rao-Blackwellisation. We provide some
simulation-based evaluation of the quality of the RGBS with respect to run time
and sequence length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1165</identifier>
 <datestamp>2015-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1165</id><created>2014-08-05</created><authors><author><keyname>Jiang</keyname><forenames>Chunlan</forenames></author><author><keyname>Liu</keyname><forenames>Zhengwei</forenames></author><author><keyname>Wu</keyname><forenames>Jinsong</forenames></author></authors><title>Noncommutative Uncertainty Principles</title><categories>math.OA cs.IT math.IT math.QA</categories><comments>41 pages, 71 figures</comments><msc-class>46L37, 43A30, 94A15</msc-class><journal-ref>Journal of Functional Analysis 270 (2016), pp. 264-311</journal-ref><doi>10.1016/j.jfa.2015.08.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical uncertainty principles deal with functions on abelian groups.
In this paper, we discuss the uncertainty principles for finite index
subfactors which include the cases for finite groups and finite dimensional Kac
algebras. We prove the Hausdorff-Young inequality, Young's inequality, the
Hirschman-Beckner uncertainty principle, the Donoho-Stark uncertainty
principle. We characterize the minimizers of the uncertainty principles. We
also prove that the minimizer is uniquely determined by the supports of itself
and its Fourier transform. The proofs take the advantage of the analytic and
the categorial perspectives of subfactor planar algebras. Our method to prove
the uncertainty principles also works for more general cases, such as Popa's
$\lambda$-lattices, modular tensor categories etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1167</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1167</id><created>2014-08-05</created><authors><author><keyname>Tran</keyname><forenames>Truyen</forenames></author><author><keyname>Bui</keyname><forenames>Hung</forenames></author><author><keyname>Venkatesh</keyname><forenames>Svetha</forenames></author></authors><title>Boosted Markov Networks for Activity Recognition</title><categories>cs.LG cs.CV stat.ML</categories><comments>International Conference on Intelligent Sensors, Sensor Networks and
  Information Processing (ISSNIP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore a framework called boosted Markov networks to combine the learning
capacity of boosting and the rich modeling semantics of Markov networks and
applying the framework for video-based activity recognition. Importantly, we
extend the framework to incorporate hidden variables. We show how the framework
can be applied for both model learning and feature selection. We demonstrate
that boosted Markov networks with hidden variables perform comparably with the
standard maximum likelihood estimation. However, our framework is able to learn
sparse models, and therefore can provide computational savings when the learned
models are used for classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1168</identifier>
 <datestamp>2015-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1168</id><created>2014-08-05</created><updated>2015-07-29</updated><authors><author><keyname>Taylor</keyname><forenames>Dane</forenames></author><author><keyname>Klimm</keyname><forenames>Florian</forenames></author><author><keyname>Harrington</keyname><forenames>Heather A.</forenames></author><author><keyname>Kramar</keyname><forenames>Miroslav</forenames></author><author><keyname>Mischaikow</keyname><forenames>Konstantin</forenames></author><author><keyname>Porter</keyname><forenames>Mason A.</forenames></author><author><keyname>Mucha</keyname><forenames>Peter J.</forenames></author></authors><title>Topological data analysis of contagion maps for examining spreading
  processes on networks</title><categories>nlin.AO cs.SI math.DS physics.soc-ph</categories><comments>Main Text and Supplementary Information</comments><journal-ref>Nature Communications 6, 7723 (2015)</journal-ref><doi>10.1038/ncomms8723</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social and biological contagions are influenced by the spatial embeddedness
of networks. Historically, many epidemics spread as a wave across part of the
Earth's surface; however, in modern contagions long-range edges -- for example,
due to airline transportation or communication media -- allow clusters of a
contagion to appear in distant locations. Here we study the spread of
contagions on networks through a methodology grounded in topological data
analysis and nonlinear dimension reduction. We construct &quot;contagion maps&quot; that
use multiple contagions on a network to map the nodes as a point cloud. By
analyzing the topology, geometry, and dimensionality of manifold structure in
such point clouds, we reveal insights to aid in the modeling, forecast, and
control of spreading processes. Our approach highlights contagion maps also as
a viable tool for inferring low-dimensional structure in networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1173</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1173</id><created>2014-08-05</created><authors><author><keyname>Desai</keyname><forenames>Parth Rajesh</forenames></author><author><keyname>Desai</keyname><forenames>Pooja Nikhil</forenames></author><author><keyname>Ajmera</keyname><forenames>Komal Deepak</forenames></author><author><keyname>Mehta</keyname><forenames>Khushbu</forenames></author></authors><title>A Review Paper on Oculus Rift-A Virtual Reality Headset</title><categories>cs.HC</categories><comments>5 pages,7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Oculus rift: Virtual reality (VR) is a burgeoning field that has the inherent
potential of manipulating peoples mind with a superlative 3D experience. Oculus
rift is one such application that assists in achieving the same. With the
fleeting enhancements in VR it now seems very feasible to provide the user with
experiences that were earlier thought to be merely a dream or a nightmare.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1179</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1179</id><created>2014-08-06</created><authors><author><keyname>Zhang</keyname><forenames>Qizhi</forenames></author><author><keyname>Yang</keyname><forenames>Changqing</forenames></author></authors><title>On the hopping pattern design for D2D discovery with invariant</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on the hopping pattern design for device-to-device
(D2D) discovery. The requirements of hopping pattern is discussed, where the
impact of specific system constraints, e.g., frequency hopping, is also taken
into consideration. Specifically speaking, we discover and utilize the novel
feature of resource hopping, i.e., &quot;hopping invariant&quot; to design four new
hopping patterns and analyze their performance. The hopping invariant can be
used to deliver information for specific users without extra radio resources,
and due to the connection between hopping invariant and resource location,
receiver complexity can be significantly reduced. Furthermore, our schemes are
designed to be independent of discovery frame number, which makes them more
suitable to be implemented in practical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1180</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1180</id><created>2014-08-06</created><authors><author><keyname>Zhang</keyname><forenames>Qizhi</forenames></author></authors><title>A class of hopping patterns with minimal collisions</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In \cite{VTC} three metrics for hopping pattern performance evaluation is
proposed: column period, maximal collision ratio, maximal continual collision
number, a lower bound of maximal continual collision number is given also. In
this paper we give a lower bound of maximal collision ratio, a class of hopping
pattern whose both maximal collision ratio and maximal continual collision
number fit the lower bounds is constructed also.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1182</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1182</id><created>2014-08-06</created><updated>2014-11-16</updated><authors><author><keyname>Berisha</keyname><forenames>Visar</forenames></author><author><keyname>Hero</keyname><forenames>Alfred O.</forenames></author></authors><title>Empirical non-parametric estimation of the Fisher Information</title><categories>stat.CO cs.IT math.IT stat.ML</categories><comments>12 pages</comments><doi>10.1109/LSP.2014.2378514</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fisher information matrix (FIM) is a foundational concept in statistical
signal processing. The FIM depends on the probability distribution, assumed to
belong to a smooth parametric family. Traditional approaches to estimating the
FIM require estimating the probability distribution function (PDF), or its
parameters, along with its gradient or Hessian. However, in many practical
situations the PDF of the data is not known but the statistician has access to
an observation sample for any parameter value. Here we propose a method of
estimating the FIM directly from sampled data that does not require knowledge
of the underlying PDF. The method is based on non-parametric estimation of an
$f$-divergence over a local neighborhood of the parameter space and a relation
between curvature of the $f$-divergence and the FIM. Thus we obtain an
empirical estimator of the FIM that does not require density estimation and is
asymptotically consistent. We empirically evaluate the validity of our approach
using two experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1190</identifier>
 <datestamp>2014-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1190</id><created>2014-08-06</created><updated>2014-11-10</updated><authors><author><keyname>Murase</keyname><forenames>Yohsuke</forenames></author><author><keyname>T&#xf6;r&#xf6;k</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Jo</keyname><forenames>Hang-Hyun</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author></authors><title>Multilayer weighted social network model</title><categories>physics.soc-ph cs.SI</categories><comments>9 pages, 9 figures</comments><journal-ref>Phys. Rev. E 90, 052810 (2014)</journal-ref><doi>10.1103/PhysRevE.90.052810</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent empirical studies using large-scale data sets have validated the
Granovetter hypothesis on the structure of the society in that there are
strongly wired communities connected by weak ties. However, as interaction
between individuals takes place in diverse contexts, these communities turn out
to be overlapping. This implies that the society has a multilayered structure,
where the layers represent the different contexts. To model this structure we
begin with a single-layer weighted social network (WSN) model showing the
Granovetterian structure. We find that when merging such WSN models, a
sufficient amount of interlayer correlation is needed to maintain the
relationship between topology and link weights, while these correlations
destroy the enhancement in the community overlap due to multiple layers. To
resolve this, we devise a geographic multilayer WSN model, where the indirect
interlayer correlations due to the geographic constraints of individuals
enhance the overlaps between the communities and, at the same time, the
Granovetterian structure is preserved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1201</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1201</id><created>2014-08-06</created><authors><author><keyname>Wikedzi</keyname><forenames>Timothy Y.</forenames></author><author><keyname>Sinde</keyname><forenames>Ramadhani S.</forenames></author><author><keyname>McIntyre</keyname><forenames>Dan K.</forenames></author></authors><title>System Analysis and Design for integrated sponsored SMS/USSD Based
  M-Services (A case study of Maternal Health M-Service in Tanzania)</title><categories>cs.CY cs.SE</categories><comments>11 pages,10 figures</comments><journal-ref>Wikedzi, T. Y., Sinde, R. S., &amp; McIntyre, D. K. (2014). System
  Analysis and Design for integrated sponsored SMS/USSD Based M-Services.
  IJCSIS, 12(7), 11</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Mobile phones have proven to be the best way of providing reliable access to
information to people in low and mid income countries where other forms of
communication perform poorly. As a result of the wide spread of mobile phones,
there has been an increase in number of Mobile Application (M-Services) which
are being used as a tool for disseminating different type information to
people. M-Services of this nature are established to address informational
challenges that are faced by people especially low income people. Because of
this then, these projects must be sustained so that people can enjoy the
benefits of it. Contrary to this, reports show that most of these M-Services
are facing the challenge of cost of operating them, which in a direct way
affects the sustainability of these services. In this paper therefore we
present an analysis and later design of a noncommercial M-Service, which
integrates advertising functionality as a tool for subsidizing the cost of
operating M-Services. To achieve this we have employed some concepts of
Information System Analysis and Design (ISAD) as the guiding principle towards
achieving our design. A prototype of M-Health is used for the study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1209</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1209</id><created>2014-08-06</created><authors><author><keyname>Nguyen</keyname><forenames>Hiep H.</forenames></author><author><keyname>Imine</keyname><forenames>Abdessamad</forenames></author><author><keyname>Rusinowitch</keyname><forenames>Micha&#xeb;l</forenames></author></authors><title>Anonymizing Social Graphs via Uncertainty Semantics</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rather than anonymizing social graphs by generalizing them to super
nodes/edges or adding/removing nodes and edges to satisfy given privacy
parameters, recent methods exploit the semantics of uncertain graphs to achieve
privacy protection of participating entities and their relationship. These
techniques anonymize a deterministic graph by converting it into an uncertain
form. In this paper, we propose a generalized obfuscation model based on
uncertain adjacency matrices that keep expected node degrees equal to those in
the unanonymized graph. We analyze two recently proposed schemes and show their
fitting into the model. We also point out disadvantages in each method and
present several elegant techniques to fill the gap between them. Finally, to
support fair comparisons, we develop a new tradeoff quantifying framework by
leveraging the concept of incorrectness in location privacy research.
Experiments on large social graphs demonstrate the effectiveness of our
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1211</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1211</id><created>2014-08-06</created><authors><author><keyname>Feige</keyname><forenames>Uriel</forenames></author><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Immorlica</keyname><forenames>Nicole</forenames></author><author><keyname>Izsak</keyname><forenames>Rani</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Syrgkanis</keyname><forenames>Vasilis</forenames></author></authors><title>A Unifying Hierarchy of Valuations with Complements and Substitutes</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new hierarchy over monotone set functions, that we refer to as
$\mathcal{MPH}$ (Maximum over Positive Hypergraphs). Levels of the hierarchy
correspond to the degree of complementarity in a given function. The highest
level of the hierarchy, $\mathcal{MPH}$-$m$ (where $m$ is the total number of
items) captures all monotone functions. The lowest level, $\mathcal{MPH}$-$1$,
captures all monotone submodular functions, and more generally, the class of
functions known as $\mathcal{XOS}$. Every monotone function that has a positive
hypergraph representation of rank $k$ (in the sense defined by Abraham,
Babaioff, Dughmi and Roughgarden [EC 2012]) is in $\mathcal{MPH}$-$k$. Every
monotone function that has supermodular degree $k$ (in the sense defined by
Feige and Izsak [ITCS 2013]) is in $\mathcal{MPH}$-$(k+1)$. In both cases, the
converse direction does not hold, even in an approximate sense. We present
additional results that demonstrate the expressiveness power of
$\mathcal{MPH}$-$k$.
  One can obtain good approximation ratios for some natural optimization
problems, provided that functions are required to lie in low levels of the
$\mathcal{MPH}$ hierarchy. We present two such applications. One shows that the
maximum welfare problem can be approximated within a ratio of $k+1$ if all
players hold valuation functions in $\mathcal{MPH}$-$k$. The other is an upper
bound of $2k$ on the price of anarchy of simultaneous first price auctions.
  Being in $\mathcal{MPH}$-$k$ can be shown to involve two requirements -- one
is monotonicity and the other is a certain requirement that we refer to as
$\mathcal{PLE}$ (Positive Lower Envelope). Removing the monotonicity
requirement, one obtains the $\mathcal{PLE}$ hierarchy over all non-negative
set functions (whether monotone or not), which can be fertile ground for
further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1222</identifier>
 <datestamp>2015-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1222</id><created>2014-08-06</created><updated>2015-03-01</updated><authors><author><keyname>Bhattacharya</keyname><forenames>Abhijit</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>An Approximate Inner Bound to the QoS Aware Throughput Region of a Tree
  Network under IEEE 802.15.4 CSMA/CA and Application to Wireless Sensor
  Network Design</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a tree network spanning a set of source nodes that generate
measurement packets, a set of additional relay nodes that only forward packets
from the sources, and a data sink. We assume that the paths from the sources to
the sink have bounded hop count. We assume that the nodes use the IEEE 802.15.4
CSMA/CA for medium access control, and that there are no hidden terminals. In
this setting, starting with a set of simple fixed point equations, we derive
sufficient conditions for the tree network to approximately satisfy certain
given QoS targets such as end-to-end delivery probability and delay under a
given rate of generation of measurement packets at the sources (arrival rates
vector). The structures of our sufficient conditions provide insight on the
dependence of the network performance on the arrival rate vector, and the
topological properties of the network. Furthermore, for the special case of
equal arrival rates, default backoff parameters, and for a range of values of
target QoS, we show that among all path-length-bounded trees (spanning a given
set of sources and BS) that meet the sufficient conditions, a shortest path
tree achieves the maximum throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1225</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1225</id><created>2014-08-06</created><updated>2014-08-18</updated><authors><author><keyname>Srivastava</keyname><forenames>Rachit</forenames></author><author><keyname>Ladwa</keyname><forenames>Sanjay Motilal</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Abhijit</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>A Fast and Accurate Performance Analysis of Beaconless IEEE 802.15.4
  Multi-Hop Networks</title><categories>cs.NI</categories><comments>arXiv admin note: text overlap with arXiv:1201.3001</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop an approximate analytical technique for evaluating the performance
of multi-hop networks based on beaconless IEEE 802.15.4, a popular standard for
wireless sensor networks. The network comprises sensor nodes, which generate
measurement packets, relay nodes which only forward packets, and a data sink
(base station). We consider a detailed stochastic process at each node, and
analyse this process taking into account the interaction with neighboring nodes
via certain time averaged unknown variables (e.g., channel sensing rates,
collision probabilities, etc.). By coupling the analyses at various nodes, we
obtain fixed point equations that can be solved numerically to obtain the
unknown variables, thereby yielding approximations of time average performance
measures, such as packet discard probabilities and average queueing delays. The
model incorporates packet generation at the sensor nodes and queues at the
sensor nodes and relay nodes. We demonstrate the accuracy of our model by an
extensive comparison with simulations. As an additional assessment of the
accuracy of the model, we utilize it in an algorithm for sensor network design
with quality-of-service (QoS) objectives, and show that designs obtained using
our model actually satisfy the QoS constraints (as validated by simulating the
networks), and the predictions are accurate to well within 10% as compared to
the simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1228</identifier>
 <datestamp>2015-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1228</id><created>2014-08-06</created><updated>2015-03-09</updated><authors><author><keyname>Pang</keyname><forenames>Jun</forenames></author><author><keyname>Zhang</keyname><forenames>Yang</forenames></author></authors><title>Location Prediction: Communities Speak Louder than Friends</title><categories>cs.SI physics.soc-ph</categories><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Humans are social animals and they interact with different communities of
friends to conduct different activities. The literature shows that human
mobility is constrained by their social relations as well as geographic
constraints. In this paper, we investigate the social impact of a person's
communities on his mobility, instead of all friends from his online social
networks. This study can be particularly useful, as certain social behaviors
are influenced by specific communities but not all friends. To achieve our
goal, we first develop a measure to characterize a person's social diversity,
which we term `community entropy'. Through analysis of a real-life dataset, we
demonstrate that a person's mobility is influenced only by a small fraction of
his communities and the influence depends on the social contexts of the
communities. We then exploit machine learning techniques to predict users'
future movement based on their communities' information. Experiments on a
location-based social network dataset demonstrate the prediction's
effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1233</identifier>
 <datestamp>2014-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1233</id><created>2014-08-06</created><updated>2014-12-03</updated><authors><author><keyname>Etessami</keyname><forenames>Kousha</forenames></author></authors><title>The complexity of computing a (quasi-)perfect equilibrium for an
  n-player extensive form game of perfect recall</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of computing or approximating refinements of Nash
equilibrium for a given finite n-player extensive form game of perfect recall
(EFGPR), where n &gt;= 3. Our results apply to a number of well-studied
refinements, including sequential (SE), extensive-form perfect (PE), and
quasi-perfect equilibrium (QPE). These refine Nash and subgame-perfect
equilibrium. Of these, the most refined notions are PE and QPE. By classic
results, all these equilibria exist in any EFGPR. We show that, for all these
notions of equilibrium, approximating an equilibrium for a given EFGPR, to
within a given desired precision, is FIXP_a-complete. We also consider the
complexity of corresponding &quot;almost&quot; equilibrium notions, and show that they
are PPAD-complete. In particular, we define &quot;delta-almost
epsilon-(quasi-)perfect&quot; equilibrium, and show computing one is PPAD-complete.
We show these notions refine &quot;delta-almost subgame-perfect equilibrium&quot; for
EFGPRs, which is PPAD-complete. Thus, approximating one such (delta-almost)
equilibrium for n-player EFGPRs, n &gt;= 3, is P-time equivalent to approximating
a (delta-almost) NE for a normal form game (NFG) with 3 or more players. NFGs
are trivially encodable as EFGPRs without blowup in size. Thus our results
extend the celebrated complexity results for NFGs to refinements of equilibrium
in the more general setting of EFGPRs. For 2-player EFGPRs, analogous
complexity results follow from the algorithms of Koller, Megiddo, and von
Stengel (1996), von Stengel, van den Elzen, and Talman (2002), and Miltersen
and Soerensen (2010). For n-player EFGPRs, an analogous result for Nash and
subgame-perfect equilibrium was given by Daskalakis, Fabrikant, and
Papadimitriou (2006). However, no analogous results were known for the more
refined notions of equilibrium for EFGPRs with 3 or more players.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1237</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1237</id><created>2014-08-06</created><authors><author><keyname>Srinivasan</keyname><forenames>Balaji Vasan</forenames></author><author><keyname>Hu</keyname><forenames>Qi</forenames></author><author><keyname>Gumerov</keyname><forenames>Nail A.</forenames></author><author><keyname>Murtugudde</keyname><forenames>Raghu</forenames></author><author><keyname>Duraiswami</keyname><forenames>Ramani</forenames></author></authors><title>Preconditioned Krylov solvers for kernel regression</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A primary computational problem in kernel regression is solution of a dense
linear system with the $N\times N$ kernel matrix. Because a direct solution has
an O($N^3$) cost, iterative Krylov methods are often used with fast
matrix-vector products. For poorly conditioned problems, convergence of the
iteration is slow and preconditioning becomes necessary. We investigate
preconditioning from the viewpoint of scalability and efficiency. The problems
that conventional preconditioners face when applied to kernel methods are
demonstrated. A \emph{novel flexible preconditioner }that not only improves
convergence but also allows utilization of fast kernel matrix-vector products
is introduced. The performance of this preconditioner is first illustrated on
synthetic data, and subsequently on a suite of test problems in kernel
regression and geostatistical kriging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1245</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1245</id><created>2014-08-06</created><updated>2014-11-15</updated><authors><author><keyname>Afshar</keyname><forenames>Saeed</forenames><affiliation>University of Western Sydney</affiliation></author><author><keyname>George</keyname><forenames>Libin</forenames><affiliation>University of Western Sydney</affiliation><affiliation>University of New South Wales</affiliation></author><author><keyname>Tapson</keyname><forenames>Jonathan</forenames><affiliation>University of Western Sydney</affiliation></author><author><keyname>van Schaik</keyname><forenames>Andre</forenames><affiliation>University of Western Sydney</affiliation></author><author><keyname>Hamilton</keyname><forenames>Tara Julia</forenames><affiliation>University of Western Sydney</affiliation><affiliation>University of New South Wales</affiliation></author></authors><title>Racing to Learn: Statistical Inference and Learning in a Single Spiking
  Neuron with Adaptive Kernels</title><categories>cs.NE q-bio.NC</categories><comments>In submission to Frontiers in Neuroscience</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper describes the Synapto-dendritic Kernel Adapting Neuron (SKAN), a
simple spiking neuron model that performs statistical inference and
unsupervised learning of spatiotemporal spike patterns. SKAN is the first
proposed neuron model to investigate the effects of dynamic synapto-dendritic
kernels and demonstrate their computational power even at the single neuron
scale. The rule-set defining the neuron is simple there are no complex
mathematical operations such as normalization, exponentiation or even
multiplication. The functionalities of SKAN emerge from the real-time
interaction of simple additive and binary processes. Like a biological neuron,
SKAN is robust to signal and parameter noise, and can utilize both in its
operations. At the network scale neurons are locked in a race with each other
with the fastest neuron to spike effectively hiding its learnt pattern from its
neighbors. The robustness to noise, high speed and simple building blocks not
only make SKAN an interesting neuron model in computational neuroscience, but
also make it ideal for implementation in digital and analog neuromorphic
systems which is demonstrated through an implementation in a Field Programmable
Gate Array (FPGA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1256</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1256</id><created>2014-08-06</created><authors><author><keyname>Fahrenberg</keyname><forenames>Uli</forenames></author><author><keyname>K&#x159;et&#xed;nsk&#xfd;</keyname><forenames>Jan</forenames></author><author><keyname>Legay</keyname><forenames>Axel</forenames></author><author><keyname>Traonouez</keyname><forenames>Louis-Marie</forenames></author></authors><title>Compositionality for Quantitative Specifications</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a framework for compositional and iterative design and
verification of systems with quantitative information, such as rewards, time or
energy. It is based on disjunctive modal transition systems where we allow
actions to bear various types of quantitative information. Throughout the
design process the actions can be further refined and the information made more
precise. We show how to compute the results of standard operations on the
systems, including the quotient (residual), which has not been previously
considered for quantitative non-deterministic systems. Our quantitative
framework has close connections to the modal nu-calculus and is compositional
with respect to general notions of distances between systems and the standard
operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1258</identifier>
 <datestamp>2015-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1258</id><created>2014-08-06</created><updated>2015-01-03</updated><authors><author><keyname>Petersen</keyname><forenames>Holger</forenames></author></authors><title>On Practical Regular Expressions</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report on simulation, hierarchy, and decidability results for Practical
Regular Expressions (PRE), which may include back references in addition to the
standard operations union, concatenation, and star.
  The following results are obtained:
  PRE can be simulated by the classical model of nondeterministic finite
automata with sensing one-way heads. The number of heads depends on the number
of different variables in the expressions.
  A space bound O(n log m) for matching a text of length m with a PRE with n
variables based on the previous simulation. This improves the bound O(nm) from
(C\^ampeanu and Santean 2009).
  PRE cannot be simulated by deterministic finite automata with at most three
sensing one-way heads or deterministic finite automata with any number of
non-sensing one-way heads.
  PRE with a bounded number of occurrences of variables in any match can be
simulated by nondeterministic finite automata with one-way heads.
  There is a tight hierarchy of PRE with a growing number of non-nested
variables over a fixed alphabet. A previously known hierarchy was based on
nested variables and growing alphabets (Larsen 1998).
  Matching of PRE without star over a single-letter alphabet is NP-complete.
This strengthens the corresponding result for expressions over larger alphabets
and with star (Aho 1990).
  Inequivalence of PRE without closure operators is Sigma^P_2-complete.
  The decidability of universality of PRE over a single letter alphabet is
linked to the existence of Fermat Primes.
  Greibach's Theorem applies to languages characterized by PRE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1260</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1260</id><created>2014-08-06</created><authors><author><keyname>Kolchin</keyname><forenames>Maxim</forenames></author><author><keyname>Kozlov</keyname><forenames>Fedor</forenames></author></authors><title>Unstable markup: A template-based information extraction from web sites
  with unstable markup</title><categories>cs.IR cs.DL</categories><comments>ESWC 2014 Semantic Publishing Challenge, Task 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents results of a work on crawling CEUR Workshop proceedings
web site to a Linked Open Data (LOD) dataset in the framework of ESWC 2014
Semantic Publishing Challenge 2014. Our approach is based on using an
extensible template-dependent crawler and DBpedia for linking extracted
entities, such as the names of universities and countries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1265</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1265</id><created>2014-08-06</created><authors><author><keyname>Ferreira</keyname><forenames>Rui</forenames></author><author><keyname>Grossi</keyname><forenames>Roberto</forenames></author><author><keyname>Rizzi</keyname><forenames>Romeo</forenames></author><author><keyname>Sacomoto</keyname><forenames>Gustavo</forenames></author><author><keyname>Sagot</keyname><forenames>Marie-France</forenames></author></authors><title>Amortized $\tilde{O}(|V|)$-Delay Algorithm for Listing Chordless Cycles
  in Undirected Graphs</title><categories>cs.DS</categories><comments>Accepted in ESA 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chordless cycles are very natural structures in undirected graphs, with an
important history and distinguished role in graph theory. Motivated also by
previous work on the classical problem of listing cycles, we study how to list
chordless cycles. The best known solution to list all the $C$ chordless cycles
contained in an undirected graph $G = (V,E)$ takes $O(|E|^2 +|E|\cdot C)$ time.
In this paper we provide an algorithm taking $\tilde{O}(|E| + |V |\cdot C)$
time. We also show how to obtain the same complexity for listing all the $P$
chordless $st$-paths in $G$ (where $C$ is replaced by $P$ ).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1268</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1268</id><created>2014-08-06</created><authors><author><keyname>Khalid</keyname><forenames>Yawar Ismail</forenames></author><author><keyname>Hassan</keyname><forenames>Naveed Ul</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Huang</keyname><forenames>Shisheng</forenames></author></authors><title>Demand Response Management For Power Throttling Air Conditioning Loads
  In Residential Smart Grids</title><categories>cs.SY</categories><comments>6 pages, 2 figures, 1 table, conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop an algorithm for peak load reduction to reduce the
impact of increased air conditioner usage in a residential smart grid
community. We develop Demand Response Management (DRM) plans that clearly spell
out the maximum duration as well as maximum severity of inconvenience. We model
the air conditioner as a power throttling device and for any given DRM plan we
study the impact of increasing the number of power states on the resulting peak
load reduction. Through simulations, we find out that adding just one
additional state to the basic ON/OFF model, which can throttle power to 50% of
the rated air conditioner power, can result in significant amount of peak
reduction. However, the peak load that can be reduced is diminishing with the
increase in number of states. Furthermore, we also observe the impact of
inconvenience duration and inconvenience severity in terms of peak load
reduction. These observations can serve as useful guidelines for developing
appropriate DRM plans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1271</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1271</id><created>2014-08-06</created><authors><author><keyname>Borgstr&#xf6;m</keyname><forenames>Johannes</forenames><affiliation>Uppsala University</affiliation></author><author><keyname>Crafa</keyname><forenames>Silvia</forenames><affiliation>University of Padova</affiliation></author></authors><title>Proceedings Combined 21st International Workshop on Expressiveness in
  Concurrency and 11th Workshop on Structural Operational Semantics</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><acm-class>F3.2</acm-class><journal-ref>EPTCS 160, 2014</journal-ref><doi>10.4204/EPTCS.160</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the Combined 21st International
Workshop on Expressiveness in Concurrency and the 11th Workshop on Structural
Operational Semantics (EXPRESS/SOS 2014) which was held on 1st September 2014
in Rome, Italy, as an affiliated workshop of CONCUR 2014, the 25th
International Conference on Concurrency Theory.
  The EXPRESS workshops aim at bringing together researchers interested in the
expressiveness of various formal systems and semantic notions, particularly in
the field of concurrency. Their focus has traditionally been on the comparison
between programming concepts (such as concurrent, functional, imperative, logic
and object-oriented programming) and between mathematical models of computation
(such as process algebras, Petri nets, event structures, modal logics, and
rewrite systems) on the basis of their relative expressive power. The EXPRESS
workshop series has run successfully since 1994 and over the years this focus
has become broadly construed.
  The SOS workshops aim at being a forum for researchers, students and
practitioners interested in new developments, and directions for future
investigation, in the field of structural operational semantics. One of the
specific goals of the SOS workshop series is to establish synergies between the
concurrency and programming language communities working on the theory and
practice of SOS. Reports on applications of SOS to other fields are also most
welcome, including: modelling and analysis of biological systems, security of
computer systems programming, modelling and analysis of embedded systems,
specification of middle-ware and coordination languages, programming language
semantics and implementation, static analysis software and hardware
verification, and semantics for domain-specific languages and model-based
engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1274</identifier>
 <datestamp>2015-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1274</id><created>2014-08-06</created><updated>2015-04-30</updated><authors><author><keyname>Clough</keyname><forenames>James R.</forenames></author><author><keyname>Evans</keyname><forenames>Tim S.</forenames></author></authors><title>What is the dimension of citation space?</title><categories>physics.soc-ph cs.DL cs.SI</categories><comments>20 pages, 11 figures + appendix, 3 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Citation networks represent the flow of information between agents. They are
constrained in time and so form directed acyclic graphs which have a causal
structure. Here we provide novel quantitative methods to characterise that
structure by adapting methods used in the causal set approach to quantum
gravity by considering the networks to be embedded in a Minkowski spacetime and
measuring its dimension using Myrheim-Meyer and Midpoint-scaling estimates. We
illustrate these methods on citation networks from the arXiv, supreme court
judgements from the USA, and patents and find that otherwise similar citation
networks have measurably different dimensions. We suggest that these
differences can be interpreted in terms of the level of diversity or narrowness
in citation behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1276</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1276</id><created>2014-08-06</created><updated>2014-08-07</updated><authors><author><keyname>Sharad</keyname><forenames>Kumar</forenames></author><author><keyname>Danezis</keyname><forenames>George</forenames></author></authors><title>An Automated Social Graph De-anonymization Technique</title><categories>cs.CR cs.SI</categories><comments>12 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present a generic and automated approach to re-identifying nodes in
anonymized social networks which enables novel anonymization techniques to be
quickly evaluated. It uses machine learning (decision forests) to matching
pairs of nodes in disparate anonymized sub-graphs. The technique uncovers
artefacts and invariants of any black-box anonymization scheme from a small set
of examples. Despite a high degree of automation, classification succeeds with
significant true positive rates even when small false positive rates are
sought. Our evaluation uses publicly available real world datasets to study the
performance of our approach against real-world anonymization strategies, namely
the schemes used to protect datasets of The Data for Development (D4D)
Challenge. We show that the technique is effective even when only small numbers
of samples are used for training. Further, since it detects weaknesses in the
black-box anonymization scheme it can re-identify nodes in one social network
when trained on another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1278</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1278</id><created>2014-08-06</created><authors><author><keyname>Kendrew</keyname><forenames>Sarah</forenames><affiliation>University of Oxford</affiliation></author><author><keyname>Deen</keyname><forenames>Casey</forenames><affiliation>MPIA Heidelberg</affiliation></author><author><keyname>Radziwill</keyname><forenames>Nicole</forenames><affiliation>James Madison University</affiliation></author><author><keyname>Crawford</keyname><forenames>Steve</forenames><affiliation>SAAO, Cape Town</affiliation></author><author><keyname>Gilbert</keyname><forenames>James</forenames><affiliation>University of Oxford</affiliation></author><author><keyname>Gully-Santiago</keyname><forenames>Michael</forenames><affiliation>University of Texas at Austin</affiliation></author><author><keyname>Kubanek</keyname><forenames>Petr</forenames><affiliation>Institute of Physics, Czech Republic</affiliation></author></authors><title>The first SPIE software Hack Day</title><categories>astro-ph.IM cs.CY physics.optics</categories><comments>To be published in Proc. SPIE volume 9152; paper will be available in
  the SPIE Digital Library via Open Access</comments><doi>10.1117/12.2075357</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report here on the software Hack Day organised at the 2014 SPIE conference
on Astronomical Telescopes and Instrumentation in Montreal. The first ever Hack
Day to take place at an SPIE event, the aim of the day was to bring together
developers to collaborate on innovative solutions to problems of their choice.
Such events have proliferated in the technology community, providing
opportunities to showcase, share and learn skills. In academic environments,
these events are often also instrumental in building community beyond the
limits of national borders, institutions and projects. We show examples of
projects the participants worked on, and provide some lessons learned for
future events.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1284</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1284</id><created>2014-08-06</created><authors><author><keyname>Bartz</keyname><forenames>Hannes</forenames></author><author><keyname>Wachter-Zeh</keyname><forenames>Antonia</forenames></author></authors><title>Efficient Interpolation-Based Decoding of Interleaved Subspace and
  Gabidulin Codes</title><categories>cs.IT math.IT</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An interpolation-based decoding scheme for interleaved subspace codes is
presented. The scheme can be used as a (not necessarily polynomial-time) list
decoder as well as a probabilistic unique decoder. Both interpretations allow
to decode interleaved subspace codes beyond half the minimum subspace distance.
Further, an efficient interpolation procedure for the required linearized
multivariate polynomials is presented and a computationally- and
memory-efficient root-finding algorithm for the probabilistic unique decoder is
proposed. These two efficient algorithms can also be applied for accelerating
the decoding of interleaved Gabidulin codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1292</identifier>
 <datestamp>2015-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1292</id><created>2014-08-06</created><updated>2015-10-08</updated><authors><author><keyname>Kuzborskij</keyname><forenames>Ilja</forenames></author><author><keyname>Orabona</keyname><forenames>Francesco</forenames></author><author><keyname>Caputo</keyname><forenames>Barbara</forenames></author></authors><title>Scalable Greedy Algorithms for Transfer Learning</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the binary transfer learning problem, focusing on
how to select and combine sources from a large pool to yield a good performance
on a target task. Constraining our scenario to real world, we do not assume the
direct access to the source data, but rather we employ the source hypotheses
trained from them. We propose an efficient algorithm that selects relevant
source hypotheses and feature dimensions simultaneously, building on the
literature on the best subset selection problem. Our algorithm achieves
state-of-the-art results on three computer vision datasets, substantially
outperforming both transfer learning and popular feature selection baselines in
a small-sample setting. We also present a randomized variant that achieves the
same results with a fraction of the computational cost. Also, we theoretically
prove that, under reasonable assumptions on the source hypotheses, our
algorithm can learn effectively from few examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1293</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1293</id><created>2014-08-06</created><updated>2014-08-07</updated><authors><author><keyname>Graziotin</keyname><forenames>Daniel</forenames></author><author><keyname>Wang</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Abrahamsson</keyname><forenames>Pekka</forenames></author></authors><title>Do feelings matter? On the correlation of affects and the self-assessed
  productivity in software engineering</title><categories>cs.SE</categories><comments>33 pages, 5 figures. Extension of arXiv:1306.1772 [cs.SE]. Published
  in Journal of Software: Evolution and Process (early view) at
  http://onlinelibrary.wiley.com/doi/10.1002/smr.1673/abstract</comments><doi>10.1002/smr.1673</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background: software engineering research (SE) lacks theory and methodologies
for addressing human aspects in software development. Development tasks are
undertaken through cognitive processing activities. Affects (emotions, moods,
feelings) have a linkage to cognitive processing activities and the
productivity of individuals. SE research needs to incorporate affect
measurements to valorize human factors and to enhance management styles.
  Objective: analyze the affects dimensions of valence, arousal, and dominance
of software developers and their real-time correlation with their self-assessed
productivity (sPR).
  Method: repeated measurements design with 8 participants (4 students, 4
professionals), conveniently sampled and studied individually over 90 minutes
of programming. The analysis was performed by fitting a linear mixed- effects
(LME) model.
  Results: valence and dominance are positively correlated with the sPR. The
model was able to express about 38% of deviance from the sPR. Many lessons were
learned when employing psychological measurements in SE and for fitting LME.
  Conclusion: this article demonstrates the value of applying psychological
tests in SE and echoes a call to valorize the human, individualized aspects of
software developers. It reports a body of knowledge about affects, their
classification, their measurement, and the best practices to perform
psychological measurements in SE with LME models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1294</identifier>
 <datestamp>2015-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1294</id><created>2014-08-06</created><updated>2015-05-15</updated><authors><author><keyname>Faqeeh</keyname><forenames>Ali</forenames></author><author><keyname>Melnik</keyname><forenames>Sergey</forenames></author><author><keyname>Gleeson</keyname><forenames>James P.</forenames></author></authors><title>Network cloning unfolds the effect of clustering on dynamical processes</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI</categories><comments>9 pages, 8 figures</comments><msc-class>05C82</msc-class><journal-ref>Phys. Rev. E 91, 052807 (2015)</journal-ref><doi>10.1103/PhysRevE.91.052807</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce network $L$-cloning, a technique for creating ensembles of
random networks from any given real-world or artificial network. Each member of
the ensemble is an $L$-cloned network constructed from $L$ copies of the
original network. The degree distribution of an $L$-cloned network and, more
importantly, the degree-degree correlation between and beyond nearest neighbors
are identical to those of the original network. The density of triangles in an
\LC network, and hence its clustering coefficient, is reduced by a factor of
$L$ compared to those of the original network. Furthermore, the density of
loops of any fixed length approaches zero for sufficiently large values of $L$.
Other variants of $L$-cloning allow us to keep intact the short loops of
certain lengths. As an application, we employ these network cloning methods to
investigate the effect of short loops on dynamical processes running on
networks and to inspect the accuracy of corresponding tree-based theories. We
demonstrate that dynamics on $L$-cloned networks (with sufficiently large $L$)
are accurately described by the so-called adjacency tree-based theories,
examples of which include the message passing technique, some pair
approximation methods, and the belief propagation algorithm used respectively
to study bond percolation, SI epidemics, and the Ising model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1295</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1295</id><created>2014-08-06</created><authors><author><keyname>Xu</keyname><forenames>Kui</forenames></author><author><keyname>Xu</keyname><forenames>Youyun</forenames></author><author><keyname>Zhang</keyname><forenames>Dongmei</forenames></author><author><keyname>Ma</keyname><forenames>Wenfeng</forenames></author></authors><title>Max-SINR Receiver for HMCT Systems over Non-Stationary Doubly Dispersive
  Channel</title><categories>cs.IT math.IT</categories><comments>This paper has been accepted by URSI GASS 2014 and will be presented
  in the proceeding of URSI GASS 2014</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, a maximizing Signal-to-Interference plus-Noise Ratio
(Max-SINR) receiver for Hexagonal Multicarrier Transmission (HMCT) system over
non-stationary doubly dispersive (NSDD) channel is proposed. The closed-form
timing offset expression of the prototype pulse for the proposed Max-SINR HMCT
receiver over NSDD channel is derived. Simulation results show that the
proposed Max-SINR receiver outperforms traditional projection scheme and
obtains an approximation to the theoretical upper bound SINR performance within
all the local stationarity regions (LSRs). Meanwhile, the SINR performance of
the proposed Max-SINR HMCT receiver is robust to the estimation error between
the estimated value and the real value of root mean square (RMS) delay spread.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1297</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1297</id><created>2014-08-06</created><authors><author><keyname>Roy</keyname><forenames>Arnab</forenames></author><author><keyname>Schaffer</keyname><forenames>J. David</forenames></author><author><keyname>Laramee</keyname><forenames>Craig B.</forenames></author></authors><title>New crossover operators for multiple subset selection tasks</title><categories>cs.NE</categories><comments>19 Pages, 8 Figures, 3 Tables. More information can be found in (A.
  Roy (2014). Evolving spike neural network based spatio-temporal pattern
  classifiers with an application to identifying the alcoholic brain. Ph.D.
  dissertation, Department of Bioengineering, Binghamton University,
  Binghamton, NY-13902, U.S.A.)</comments><msc-class>68</msc-class><acm-class>I.5.2, I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have introduced two crossover operators, MMX-BLXexploit and
MMX-BLXexplore, for simultaneously solving multiple feature/subset selection
problems where the features may have numeric attributes and the subset sizes
are not predefined. These operators differ on the level of exploration and
exploitation they perform; one is designed to produce convergence controlled
mutation and the other exhibits a quasi-constant mutation rate. We illustrate
the characteristic of these operators by evolving pattern detectors to
distinguish alcoholics from controls using their visually evoked response
potentials (VERPs). This task encapsulates two groups of subset selection
problems; choosing a subset of EEG leads along with the lead-weights (features
with attributes) and the other that defines the temporal pattern that
characterizes the alcoholic VERPs. We observed better generalization
performance from MMX-BLXexplore. Perhaps, MMX-BLXexploit was handicapped by not
having a restart mechanism. These operators are novel and appears to hold
promise for solving simultaneous feature selection problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1310</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1310</id><created>2014-08-06</created><authors><author><keyname>Han</keyname><forenames>Yunghsiang S.</forenames></author><author><keyname>Pai</keyname><forenames>Hung-Ta</forenames></author><author><keyname>Chen</keyname><forenames>Po-Ning</forenames></author><author><keyname>Wu</keyname><forenames>Ting-Yi</forenames></author></authors><title>Maximum-likelihood Soft-decision Decoding for Binary Linear Block Codes
  Based on Their Supercodes</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 table</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Based on the notion of supercodes, we propose a two-phase maximum-likelihood
soft-decision decoding (tpMLSD) algorithm for binary linear block codes in this
work. The first phase applies the Viterbi algorithm backwardly to a trellis
derived from the parity-check matrix of the supercode of the linear block code.
Using the information retained from the first phase, the second phase employs
the priority-first search algorithm to the trellis corresponding to the linear
block code itself, which guarantees finding the ML decision. Simulations on
Reed-Muller codes show that the proposed two-phase scheme is an order of
magnitude more efficient in average decoding complexity than the recursive
maximum-likelihood decoding (RMLD) [1] when the signal-to-noise ratio per
information bit is 4.5 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1312</identifier>
 <datestamp>2015-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1312</id><created>2014-08-06</created><updated>2015-08-19</updated><authors><author><keyname>Lam</keyname><forenames>Albert Y. S.</forenames></author><author><keyname>Leung</keyname><forenames>Ka-Cheong</forenames></author><author><keyname>Li</keyname><forenames>Victor O. K.</forenames></author></authors><title>Vehicular Energy Network</title><categories>cs.SY</categories><comments>9 pages, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The smart grid nurtures many innovative ideas and applications, and it
revolutionizes the power system. Unfortunately, many of these new ideas cannot
be easily integrated into the existing power system due to power reliability
and security reasons. We can build an energy transmission system upon the
traffic network and utilize electric vehicles (EVs) as energy carriers to
transport energy over a large geographical region. We construct a generalized
architecture called the vehicular energy network (VEN) and develop a
mathematically tractable framework for VEN. Dynamic wireless (dis)charging
allows electric energy, as an energy packet, to be added and subtracted from EV
batteries seamlessly. With proper routing, we can transport energy from the
sources to destinations through EVs along appropriate vehicular routes based on
the information via the vehicular ad-hoc network. This paper gives a thorough
preliminary study of VEN with characteristics listed and possible drawbacks
discussed. We illustrate its significance by setting up a VEN with real traffic
data in the United Kingdom. Our implementation shows that a substantial amount
of renewable energy can be transported from some remote wind farms to London
under some reasonable settings. VEN can complement the power network and
enhance the overall power transmission rate. With packet switching-like design,
many further developments can be built upon VEN by incorporating ideas and
results from the data networking domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1319</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1319</id><created>2014-08-06</created><authors><author><keyname>Evans</keyname><forenames>Lewis</forenames></author><author><keyname>Adams</keyname><forenames>Niall M.</forenames></author><author><keyname>Anagnostopoulos</keyname><forenames>Christoforos</forenames></author></authors><title>When does Active Learning Work?</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active Learning (AL) methods seek to improve classifier performance when
labels are expensive or scarce. We consider two central questions: Where does
AL work? How much does it help? To address these questions, a comprehensive
experimental simulation study of Active Learning is presented. We consider a
variety of tasks, classifiers and other AL factors, to present a broad
exploration of AL performance in various settings. A precise way to quantify
performance is needed in order to know when AL works. Thus we also present a
detailed methodology for tackling the complexities of assessing AL performance
in the context of this experimental study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1338</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1338</id><created>2014-08-06</created><authors><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author><author><keyname>Baccelli</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>The Boolean Model in the Shannon Regime: Three Thresholds and Related
  Asymptotics</title><categories>math.PR cond-mat.stat-mech cs.IT math.IT</categories><msc-class>60D05, 94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a family of Boolean models, indexed by integers $n \ge 1$, where the
$n$-th model features a Poisson point process in ${\mathbb{R}}^n$ of intensity
$e^{n \rho_n}$ with $\rho_n \to \rho$ as $n \to \infty$, and balls of
independent and identically distributed radii distributed like $\bar X_n
\sqrt{n}$, with $\bar X_n$ satisfying a large deviations principle. It is shown
that there exist three deterministic thresholds: $\tau_d$ the degree threshold;
$\tau_p$ the percolation threshold; and $\tau_v$ the volume fraction threshold;
such that asymptotically as $n$ tends to infinity, in a sense made precise in
the paper: (i) for $\rho &lt; \tau_d$, almost every point is isolated, namely its
ball intersects no other ball; (ii) for $\tau_d&lt; \rho&lt; \tau_p$, almost every
ball intersects an infinite number of balls and nevertheless there is no
percolation; (iii) for $\tau_p&lt; \rho&lt; \tau_v$, the volume fraction is 0 and
nevertheless percolation occurs; (iv) for $\tau_d&lt; \rho&lt; \tau_v$, almost every
ball intersects an infinite number of balls and nevertheless the volume
fraction is 0; (v) for $\rho &gt; \tau_v$, the whole space covered. The analysis
of this asymptotic regime is motivated by related problems in information
theory, and may be of interest in other applications of stochastic geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1340</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1340</id><created>2014-08-06</created><authors><author><keyname>Bringmann</keyname><forenames>Karl</forenames></author><author><keyname>K&#xfc;nnemann</keyname><forenames>Marvin</forenames></author></authors><title>Improved approximation for Fr\'echet distance on c-packed curves
  matching conditional lower bounds</title><categories>cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fr\'echet distance is a well-studied and very popular measure of
similarity of two curves. The best known algorithms have quadratic time
complexity, which has recently been shown to be optimal assuming the Strong
Exponential Time Hypothesis (SETH) [Bringmann FOCS'14].
  To overcome the worst-case quadratic time barrier, restricted classes of
curves have been studied that attempt to capture realistic input curves. The
most popular such class are c-packed curves, for which the Fr\'echet distance
has a $(1+\epsilon)$-approximation in time $\tilde{O}(c n /\epsilon)$ [Driemel
et al. DCG'12]. In dimension $d \ge 5$ this cannot be improved to
$O((cn/\sqrt{\epsilon})^{1-\delta})$ for any $\delta &gt; 0$ unless SETH fails
[Bringmann FOCS'14].
  In this paper, exploiting properties that prevent stronger lower bounds, we
present an improved algorithm with runtime $\tilde{O}(cn/\sqrt{\epsilon})$.
This is optimal in high dimensions apart from lower order factors unless SETH
fails. Our main new ingredients are as follows: For filling the classical
free-space diagram we project short subcurves onto a line, which yields
one-dimensional separated curves with roughly the same pairwise distances
between vertices. Then we tackle this special case in near-linear time by
carefully extending a greedy algorithm for the Fr\'echet distance of
one-dimensional separated curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1358</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1358</id><created>2014-08-06</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>Sooda</keyname><forenames>Kavitha</forenames></author></authors><title>An intelligent routing approach using genetic algorithms for quality
  graded network</title><categories>cs.NI</categories><comments>16 Pages, 7 figures, 3 tables. arXiv admin note: substantial text
  overlap with arXiv:1203.6713</comments><journal-ref>International Journal of Intelligent Systems Technologies And
  Applications, InderScience Enterprise Ltd, Volume 1, Issue 3/4, 2012</journal-ref><doi>10.1504/IJISTA.2012.052495</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intelligent routing in networks has opened up many challenges in modelling
and methods, over the past decade. Many techniques do exist for routing on such
an environment where path determination was carried out by advertisement,
position and near-optimum node selection schemes. In this paper, an efficient
routing scheme has been proposed using genetic algorithm for a grade-based
two-level node selection method. This method assumes that nodes have the
knowledge of its environment and is capable of taking decision for route
discovery. The data learnt from the topology which is under consideration for
routing, is saved in its local memory. In this two-level node selection scheme,
the route discovery operation takes place in multiple levels. At the first
level, the grade based selection is applied for considering the most optimal
nodes which would be fit for sending data. At the second level, the optimal
path is discovered using Genetic Algorithm. The simulation result shows that
faster convergence of path took place in the case of the proposed method with
good fitness value, as compared to non-graded network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1362</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1362</id><created>2014-08-06</created><authors><author><keyname>Morcillo</keyname><forenames>Jes&#xfa;s Mu&#xf1;oz</forenames></author><author><keyname>Faion</keyname><forenames>Florian</forenames></author><author><keyname>Zea</keyname><forenames>Antonio</forenames></author><author><keyname>Hanebeck</keyname><forenames>Uwe D.</forenames></author><author><keyname>Trotha</keyname><forenames>Caroline Y. Robertson-von</forenames></author></authors><title>e-Installation: Synesthetic Documentation of Media Art via Telepresence
  Technologies</title><categories>cs.OH</categories><comments>3 figures, 14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new synesthetic documentation method that contributes to
media art conservation is presented. This new method is called e-Installation
in analogy to the idea of the e-Book as the electronic version of a real book.
An e-Installation is a virtualized media artwork that reproduces all
synesthesia, interaction, and meaning levels of the artwork. Advanced 3D
modeling and telepresence technologies with a very high level of immersion
allow the virtual re-enactment of works of media art that are no longer
performable or rarely exhibited. The virtual re-enactment of a media artwork
can be designed with a scalable level of complexity depending on whether it
addresses professionals such as curators, art restorers, and art theorists or
the general public. An e-Installation is independent from the artwork's
physical location and can be accessed via head-mounted display or similar data
goggles, computer browser, or even mobile devices. In combination with
informational and preventive conservation measures, the e-Installation offers
an intermediate and long-term solution to archive, disseminate, and pass down
the milestones of media art history as a synesthetic documentation when the
original work can no longer be repaired or exhibited in its full function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1363</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1363</id><created>2014-08-06</created><authors><author><keyname>Norris</keyname><forenames>Boyana</forenames></author><author><keyname>Bernstein</keyname><forenames>Sa-Lin</forenames></author><author><keyname>Nair</keyname><forenames>Ramya</forenames></author><author><keyname>Jessup</keyname><forenames>Elizabeth</forenames></author></authors><title>Lighthouse: A User-Centered Web Service for Linear Algebra Software</title><categories>cs.MS</categories><comments>10 pages, 10 figures, 3 tables</comments><acm-class>G.4; H.4; D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various fields of science and engineering rely on linear algebra for large
scale data analysis, modeling and simulation, machine learning, and other
applied problems. Linear algebra computations often dominate the execution time
of such applications. Meanwhile, experts in these domains typically lack the
training or time required to develop efficient, high-performance
implementations of linear algebra algorithms. In the Lighthouse project, we
enable developers with varied backgrounds to readily discover and effectively
apply the best available numerical software for their problems. We have
developed a search-based expert system that combines expert knowledge, machine
learningbased classification of existing numerical software collections, and
automated code generation and optimization. Lighthouse provides a novel
software engineering environment aimed at maximizing both developer
productivity and application performance for dense and sparse linear algebra
computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1376</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1376</id><created>2014-08-06</created><updated>2015-04-08</updated><authors><author><keyname>Matousek</keyname><forenames>Jiri</forenames></author><author><keyname>Nikolov</keyname><forenames>Aleksandar</forenames></author><author><keyname>Talwar</keyname><forenames>Kunal</forenames></author></authors><title>Factorization Norms and Hereditary Discrepancy</title><categories>math.CO cs.CG cs.DS</categories><comments>This is an expanded and simplified version, which also mostly
  subsumes arXiv:1311.6204. The &quot;ellipsoid infinity norm&quot; terminology is
  replaced by the standard factorization norm terminology</comments><msc-class>05B20, 11K38, 05D05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $\gamma_2$ norm of a real $m\times n$ matrix $A$ is the minimum number
$t$ such that the column vectors of $A$ are contained in a $0$-centered
ellipsoid $E\subseteq\mathbb{R}^m$ which in turn is contained in the hypercube
$[-t, t]^m$. We prove that this classical quantity approximates the
\emph{hereditary discrepancy} $\mathrm{herdisc}\ A$ as follows: $\gamma_2(A) =
{O(\log m)}\cdot \mathrm{herdisc}\ A$ and $\mathrm{herdisc}\ A = O(\sqrt{\log
m}\,)\cdot\gamma_2(A) $. Since $\gamma_2$ is polynomial-time computable, this
gives a polynomial-time approximation algorithm for hereditary discrepancy.
Both inequalities are shown to be asymptotically tight.
  We then demonstrate on several examples the power of the $\gamma_2$ norm as a
tool for proving lower and upper bounds in discrepancy theory. Most notably, we
prove a new lower bound of $\Omega(\log^{d-1} n)$ for the \emph{$d$-dimensional
Tusn\'ady problem}, asking for the combinatorial discrepancy of an $n$-point
set in $\mathbb{R}^d$ with respect to axis-parallel boxes. For $d&gt;2$, this
improves the previous best lower bound, which was of order approximately
$\log^{(d-1)/2}n$, and it comes close to the best known upper bound of
$O(\log^{d+1/2}n)$, for which we also obtain a new, very simple proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1377</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1377</id><created>2014-08-06</created><authors><author><keyname>Tirri</keyname><forenames>Seppo Ilari</forenames></author></authors><title>The Mathematical Abstraction Theory, The Fundamentals for Knowledge
  Representation and Self-Evolving Autonomous Problem Solving Systems</title><categories>cs.LO cs.AI</categories><comments>This article is a part of my thesis giving the unity for both
  knowledge presentation and self-evolution in autonomous problem solving
  mathematical systems and for that reason draws heavily from my previous work
  arxiv:1305.5637</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intention of the present study is to establish the mathematical
fundamentals for automated problem solving essentially targeted for robotics by
approaching the task universal algebraically introducing knowledge as
realizations of generalized free algebra based nets, graphs with gluing forms
connecting in- and out-edges to nodes. Nets are caused to undergo
transformations in conceptual level by type wise differentiated intervening net
rewriting systems dispersing problems to abstract parts, matching being
determined by substitution relations. Achieved sets of conceptual nets
constitute congruent classes. New results are obtained within construction of
problem solving systems where solution algorithms are derived parallel with
other candidates applied to the same net classes. By applying parallel
transducer paths consisting of net rewriting systems to net classes congruent
quotient algebras are established and the manifested class rewriting comprises
all solution candidates whenever produced nets are in anticipated languages
liable to acceptance of net automata. Furthermore new solutions will be added
to the set of already known ones thus expanding the solving power in the
forthcoming. Moreover special attention is set on universal abstraction,
thereof generation by net block homomorphism, consequently multiple order
solving systems and the overall decidability of the set of the solutions. By
overlapping presentation of nets new abstraction relation among nets is
formulated alongside with consequent alphabetical net block renetting system
proportional to normal forms of renetting systems regarding the operational
power. A new structure in self-evolving problem solving is established via
saturation by groups of equivalence relations and iterative closures of
generated quotient transducer algebras over the whole evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1387</identifier>
 <datestamp>2015-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1387</id><created>2014-08-06</created><updated>2015-12-16</updated><authors><author><keyname>Shah</keyname><forenames>Nihar B.</forenames></author><author><keyname>Zhou</keyname><forenames>Dengyong</forenames></author></authors><title>Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing</title><categories>cs.GT cs.HC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowdsourcing has gained immense popularity in machine learning applications
for obtaining large amounts of labeled data. Crowdsourcing is cheap and fast,
but suffers from the problem of low-quality data. To address this fundamental
challenge in crowdsourcing, we propose a simple payment mechanism to
incentivize workers to answer only the questions that they are sure of and skip
the rest. We show that surprisingly, under a mild and natural &quot;no-free-lunch&quot;
requirement, this mechanism is the one and only incentive-compatible payment
mechanism possible. We also show that among all possible incentive-compatible
mechanisms (that may or may not satisfy no-free-lunch), our mechanism makes the
smallest possible payment to spammers. We further extend our results to a more
general setting in which workers are required to provide a quantized confidence
for each question. Interestingly, this unique mechanism takes a
&quot;multiplicative&quot; form. The simplicity of the mechanism is an added benefit. In
preliminary experiments involving over 900 worker-task pairs, we observe a
significant drop in the error rates under this unique mechanism for the same or
lower monetary expenditure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1390</identifier>
 <datestamp>2014-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1390</id><created>2014-08-06</created><authors><author><keyname>DasGupta</keyname><forenames>Bhaskar</forenames></author><author><keyname>Mobasheri</keyname><forenames>Nasim</forenames></author></authors><title>On optimal approximability results for computing the strong metric
  dimension</title><categories>cs.CC cs.DM</categories><comments>4 pages</comments><msc-class>68Q17, 68Q25, 68R10</msc-class><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short note, we observe that the problem of computing the strong
metric dimension of a graph can be reduced to the problem of computing a
minimum node cover of a transformed graph within an additive logarithmic
factor. This implies both a 2-approximation algorithm and a
(2-\epsilon)-inapproximability for the problem of computing the strong metric
dimension of a graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1391</identifier>
 <datestamp>2015-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1391</id><created>2014-08-07</created><authors><author><keyname>Li</keyname><forenames>Kezhi</forenames></author><author><keyname>Cong</keyname><forenames>Shuang</forenames></author></authors><title>State of the Art and Prospects of Structured Sensing Matrices in
  Compressed Sensing</title><categories>cs.IT math.IT</categories><journal-ref>Front. Comput. Sci. 2015 9(5): 665--677</journal-ref><doi>10.1007/s11704-015-3326-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing (CS) enables people to acquire the compressed measurements
directly and recover sparse or compressible signals faithfully even when the
sampling rate is much lower than the Nyquist rate. However, the pure random
sensing matrices usually require huge memory for storage and high computational
cost for signal reconstruction. Many structured sensing matrices have been
proposed recently to simplify the sensing scheme and the hardware
implementation in practice. Based on the restricted isometry property and
coherence, couples of existing structured sensing matrices are reviewed in this
paper, which have special structures, high recovery performance, and many
advantages such as the simple construction, fast calculation and easy hardware
implementation. The number of measurements and the universality of different
structure matrices are compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1416</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1416</id><created>2014-08-06</created><authors><author><keyname>Bojinov</keyname><forenames>Hristo</forenames></author><author><keyname>Michalevsky</keyname><forenames>Yan</forenames></author><author><keyname>Nakibly</keyname><forenames>Gabi</forenames></author><author><keyname>Boneh</keyname><forenames>Dan</forenames></author></authors><title>Mobile Device Identification via Sensor Fingerprinting</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate how the multitude of sensors on a smartphone can be used to
construct a reliable hardware fingerprint of the phone. Such a fingerprint can
be used to de-anonymize mobile devices as they connect to web sites, and as a
second factor in identifying legitimate users to a remote server. We present
two implementations: one based on analyzing the frequency response of the
speakerphone-microphone system, and another based on analyzing device-specific
accelerometer calibration errors. Our accelerometer-based fingerprint is
especially interesting because the accelerometer is accessible via JavaScript
running in a mobile web browser without requesting any permissions or notifying
the user. We present the results of the most extensive sensor fingerprinting
experiment done to date, which measured sensor properties from over 10,000
mobile devices. We show that the entropy from sensor fingerprinting is
sufficient to uniquely identify a device among thousands of devices, with low
probability of collision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1422</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1422</id><created>2014-08-06</created><authors><author><keyname>Bannister</keyname><forenames>Michael J.</forenames></author><author><keyname>Devanny</keyname><forenames>William E.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>The Galois Complexity of Graph Drawing: Why Numerical Solutions are
  Ubiquitous for Force-Directed, Spectral, and Circle Packing Drawings</title><categories>cs.CG</categories><comments>Graph Drawing 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many well-known graph drawing techniques, including force directed drawings,
spectral graph layouts, multidimensional scaling, and circle packings, have
algebraic formulations. However, practical methods for producing such drawings
ubiquitously use iterative numerical approximations rather than constructing
and then solving algebraic expressions representing their exact solutions. To
explain this phenomenon, we use Galois theory to show that many variants of
these problems have solutions that cannot be expressed by nested radicals or
nested roots of low-degree polynomials. Hence, such solutions cannot be
computed exactly even in extended computational models that include such
operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1429</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1429</id><created>2014-08-06</created><authors><author><keyname>Bhaskar</keyname><forenames>Umang</forenames></author><author><keyname>Ligett</keyname><forenames>Katrina</forenames></author><author><keyname>Schulman</keyname><forenames>Leonard J.</forenames></author><author><keyname>Swamy</keyname><forenames>Chaitanya</forenames></author></authors><title>Achieving Target Equilibria in Network Routing Games without Knowing the
  Latency Functions</title><categories>cs.GT cs.DS</categories><comments>36 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of network routing games typically assumes, right at the onset,
precise and detailed information about the latency functions. Such information
may, however, be unavailable or difficult to obtain. Moreover, one is often
primarily interested in enforcing a desired target flow as the equilibrium by
suitably influencing player behavior in the routing game. We ask whether one
can achieve target flows as equilibria without knowing the underlying latency
functions.
  Our main result gives a crisp positive answer to this question. We show that,
under fairly general settings, one can efficiently compute edge tolls that
induce a given target multicommodity flow in a nonatomic routing game using a
polynomial number of queries to an oracle that takes candidate tolls as input
and returns the resulting equilibrium flow. This result is obtained via a novel
application of the ellipsoid method. Our algorithm extends easily to many other
settings, such as (i) when certain edges cannot be tolled or there is an upper
bound on the total toll paid by a user, and (ii) general nonatomic congestion
games. We obtain tighter bounds on the query complexity for series-parallel
networks, and single-commodity routing games with linear latency functions, and
complement these with a query-complexity lower bound. We also obtain strong
positive results for Stackelberg routing to achieve target equilibria in
series-parallel graphs.
  Our results build upon various new techniques that we develop pertaining to
the computation of, and connections between, different notions of approximate
equilibrium; properties of multicommodity flows and tolls in series-parallel
graphs; and sensitivity of equilibrium flow with respect to tolls. Our results
demonstrate that one can indeed circumvent the potentially-onerous task of
modeling latency functions, and yet obtain meaningful results for the
underlying routing game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1431</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1431</id><created>2014-08-06</created><authors><author><keyname>Paluch</keyname><forenames>Katarzyna</forenames></author></authors><title>Maximum ATSP with Weights Zero and One via Half-Edges</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a fast combinatorial $3/4$-approximation algorithm for the maximum
asymmetric TSP with weights zero and one. The approximation factor of this
algorithm matches the currently best one given by Bl\&quot;aser in 2004 and based on
linear programming. Our algorithm first computes a maximum size matching and a
maximum weight cycle cover without certain cycles of length two but possibly
with {\em half-edges} - a half-edge of a given edge $e$ is informally speaking
a half of $e$ that contains one of the endpoints of $e$. Then from the computed
matching and cycle cover it extracts a set of paths, whose weight is large
enough to be able to construct a traveling salesman tour with the claimed
guarantee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1437</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1437</id><created>2014-08-06</created><authors><author><keyname>Coogan</keyname><forenames>Samuel</forenames></author><author><keyname>Gol</keyname><forenames>Ebru Aydin</forenames></author><author><keyname>Arcak</keyname><forenames>Murat</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author></authors><title>Traffic Network Control from Temporal Logic Specifications</title><categories>cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a framework for generating a signal control policy for a traffic
network of signalized intersections to accomplish control objectives
expressible using linear temporal logic. By applying techniques from model
checking and formal methods, we obtain a correct-by-construction controller
that is guaranteed to satisfy complex specifications. To apply these tools, we
identify and exploit structural properties particular to traffic networks that
allow for efficient computation of a finite state abstraction. In particular,
traffic networks exhibit a componentwise monotonicity property which allows
reach set computations that scale linearly with the dimension of the continuous
state space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1440</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1440</id><created>2014-08-06</created><authors><author><keyname>Cloud</keyname><forenames>Jason</forenames></author><author><keyname>Leith</keyname><forenames>Douglas</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>In-Order Delivery Delay of Transport Layer Coding</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large number of streaming applications use reliable transport protocols
such as TCP to deliver content over the Internet. However, head-of-line
blocking due to packet loss recovery can often result in unwanted behavior and
poor application layer performance. Transport layer coding can help mitigate
this issue by helping to recover from lost packets without waiting for
retransmissions. We consider the use of an on-line network code that inserts
coded packets at strategic locations within the underlying packet stream. If
retransmissions are necessary, additional coding packets are transmitted to
ensure the receiver's ability to decode. An analysis of this scheme is provided
that helps determine both the expected in-order packet delivery delay and its
variance. Numerical results are then used to determine when and how many coded
packets should be inserted into the packet stream, in addition to determining
the trade-offs between reducing the in-order delay and the achievable rate. The
analytical results are finally compared with experimental results to provide
insight into how to minimize the delay of existing transport layer protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1451</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1451</id><created>2014-08-06</created><authors><author><keyname>Mashtizadeh</keyname><forenames>Ali Jose</forenames></author><author><keyname>Bittau</keyname><forenames>Andrea</forenames></author><author><keyname>Mazieres</keyname><forenames>David</forenames></author><author><keyname>Boneh</keyname><forenames>Dan</forenames></author></authors><title>Cryptographically Enforced Control Flow Integrity</title><categories>cs.CR cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent Pwn2Own competitions have demonstrated the continued effectiveness of
control hijacking attacks despite deployed countermeasures including stack
canaries and ASLR. A powerful defense called Control flow Integrity (CFI)
offers a principled approach to preventing such attacks. However, prior CFI
implementations use static analysis and must limit protection to remain
practical. These limitations have enabled attacks against all known CFI
systems, as demonstrated in recent work.
  This paper presents a cryptographic approach to control flow integrity (CCFI)
that is both fine-grain and practical: using message authentication codes (MAC)
to protect control flow elements such as return addresses, function pointers,
and vtable pointers. MACs on these elements prevent even powerful attackers
with random read/write access to memory from tampering with program control
flow. We implemented CCFI in Clang/LLVM, taking advantage of recently available
cryptographic CPU instructions. We evaluate our system on several large
software packages (including nginx, Apache and memcache) as well as all their
dependencies. The cost of protection ranges from a 3-18% decrease in request
rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1453</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1453</id><created>2014-08-06</created><authors><author><keyname>Pohjola</keyname><forenames>Johannes &#xc5;man</forenames></author><author><keyname>Parrow</keyname><forenames>Joachim</forenames></author></authors><title>Priorities Without Priorities: Representing Preemption in Psi-Calculi</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS/SOS 2014, arXiv:1408.1271</comments><proxy>EPTCS</proxy><acm-class>F.1.2</acm-class><journal-ref>EPTCS 160, 2014, pp. 2-15</journal-ref><doi>10.4204/EPTCS.160.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Psi-calculi is a parametric framework for extensions of the pi-calculus with
data terms and arbitrary logics. In this framework there is no direct way to
represent action priorities, where an action can execute only if all other
enabled actions have lower priority. We here demonstrate that the psi-calculi
parameters can be chosen such that the effect of action priorities can be
encoded.
  To accomplish this we define an extension of psi-calculi with action
priorities, and show that for every calculus in the extended framework there is
a corresponding ordinary psi-calculus, without priorities, and a translation
between them that satisfies strong operational correspondence. This is a
significantly stronger result than for most encodings between process calculi
in the literature.
  We also formally prove in Nominal Isabelle that the standard congruence and
structural laws about strong bisimulation hold in psi-calculi extended with
priorities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1454</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1454</id><created>2014-08-06</created><authors><author><keyname>Peters</keyname><forenames>Kirstin</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Yonova-Karbe</keyname><forenames>Tsvetelina</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Nestmann</keyname><forenames>Uwe</forenames><affiliation>TU Berlin</affiliation></author></authors><title>Matching in the Pi-Calculus</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS/SOS 2014, arXiv:1408.1271</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 160, 2014, pp. 16-29</journal-ref><doi>10.4204/EPTCS.160.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study whether, in the pi-calculus, the match prefix-a conditional operator
testing two names for (syntactic) equality-is expressible via the other
operators. Previously, Carbone and Maffeis proved that matching is not
expressible this way under rather strong requirements (preservation and
reflection of observables). Later on, Gorla developed a by now widely-tested
set of criteria for encodings that allows much more freedom (e.g. instead of
direct translations of observables it allows comparison of calculi with respect
to reachability of successful states). In this paper, we offer a considerably
stronger separation result on the non-expressibility of matching using only
Gorla's relaxed requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1455</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1455</id><created>2014-08-06</created><authors><author><keyname>Given-Wilson</keyname><forenames>Thomas</forenames><affiliation>INRIA, Paris, France</affiliation></author></authors><title>On the Expressiveness of Intensional Communication</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS/SOS 2014, arXiv:1408.1271</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 160, 2014, pp. 30-46</journal-ref><doi>10.4204/EPTCS.160.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The expressiveness of communication primitives has been explored in a common
framework based on the pi-calculus by considering four features: synchronism
(asynchronous vs synchronous), arity (monadic vs polyadic data), communication
medium (shared dataspaces vs channel-based), and pattern-matching (binding to a
name vs testing name equality). Here pattern-matching is generalised to account
for terms with internal structure such as in recent calculi like Spi calculi,
Concurrent Pattern Calculus and Psi calculi. This paper explores intensionality
upon terms, in particular communication primitives that can match upon both
names and structures. By means of possibility/impossibility of encodings, this
paper shows that intensionality alone can encode synchronism, arity,
communication-medium, and pattern-matching, yet no combination of these without
intensionality can encode any intensional language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1456</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1456</id><created>2014-08-06</created><authors><author><keyname>Wagner</keyname><forenames>Christoph</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Nestmann</keyname><forenames>Uwe</forenames><affiliation>TU Berlin</affiliation></author></authors><title>States in Process Calculi</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS/SOS 2014, arXiv:1408.1271</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 160, 2014, pp. 48-62</journal-ref><doi>10.4204/EPTCS.160.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal reasoning about distributed algorithms (like Consensus) typically
requires to analyze global states in a traditional state-based style. This is
in contrast to the traditional action-based reasoning of process calculi.
Nevertheless, we use domain-specific variants of the latter, as they are
convenient modeling languages in which the local code of processes can be
programmed explicitly, with the local state information usually managed via
parameter lists of process constants. However, domain-specific process calculi
are often equipped with (unlabeled) reduction semantics, building upon a rich
and convenient notion of structural congruence. Unfortunately, the price for
this convenience is that the analysis is cumbersome: the set of reachable
states is modulo structural congruence, and the processes' state information is
very hard to identify. We extract from congruence classes of reachable states
individual state-informative representatives that we supply with a proper
formal semantics. As a result, we can now freely switch between the process
calculus terms and their representatives, and we can use the stateful
representatives to perform assertional reasoning on process calculus models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1457</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1457</id><created>2014-08-06</created><authors><author><keyname>Gebler</keyname><forenames>Daniel</forenames><affiliation>VU University Amsterdam</affiliation></author><author><keyname>Tini</keyname><forenames>Simone</forenames><affiliation>University of Insubria</affiliation></author></authors><title>Fixed-point Characterization of Compositionality Properties of
  Probabilistic Processes Combinators</title><categories>cs.PL cs.LO</categories><comments>In Proceedings EXPRESS/SOS 2014, arXiv:1408.1271</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 160, 2014, pp. 63-78</journal-ref><doi>10.4204/EPTCS.160.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bisimulation metric is a robust behavioural semantics for probabilistic
processes. Given any SOS specification of probabilistic processes, we provide a
method to compute for each operator of the language its respective metric
compositionality property. The compositionality property of an operator is
defined as its modulus of continuity which gives the relative increase of the
distance between processes when they are combined by that operator. The
compositionality property of an operator is computed by recursively counting
how many times the combined processes are copied along their evolution. The
compositionality properties allow to derive an upper bound on the distance
between processes by purely inspecting the operators used to specify those
processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1458</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1458</id><created>2014-08-06</created><authors><author><keyname>Klin</keyname><forenames>Bartek</forenames></author><author><keyname>Nachy&#x142;a</keyname><forenames>Beata</forenames></author></authors><title>Distributive Laws and Decidable Properties of SOS Specifications</title><categories>cs.PL</categories><comments>In Proceedings EXPRESS/SOS 2014, arXiv:1408.1271</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 160, 2014, pp. 79-93</journal-ref><doi>10.4204/EPTCS.160.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Some formats of well-behaved operational specifications, correspond to
natural transformations of certain types (for example, GSOS and coGSOS laws).
These transformations have a common generalization: distributive laws of monads
over comonads. We prove that this elegant theoretical generalization has
limited practical benefits: it does not translate to any concrete rule format
that would be complete for specifications that contain both GSOS and coGSOS
rules. This is shown for the case of labeled transition systems and
deterministic stream systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1459</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1459</id><created>2014-08-06</created><authors><author><keyname>Gay</keyname><forenames>Simon J.</forenames><affiliation>School of Computing Science, University of Glasgow</affiliation></author><author><keyname>Gesbert</keyname><forenames>Nils</forenames><affiliation>Grenoble INP - Ensimag</affiliation></author><author><keyname>Ravara</keyname><forenames>Ant&#xf3;nio</forenames><affiliation>CITI and Dep de Inform&#xe1;tica, FCT, Universidade Nova de Lisboa</affiliation></author></authors><title>Session Types as Generic Process Types</title><categories>cs.PL cs.LO</categories><comments>In Proceedings EXPRESS/SOS 2014, arXiv:1408.1271</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 160, 2014, pp. 94-110</journal-ref><doi>10.4204/EPTCS.160.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Behavioural type systems ensure more than the usual safety guarantees of
static analysis. They are based on the idea of &quot;types-as-processes&quot;, providing
dedicated type algebras for particular properties, ranging from protocol
compatibility to race-freedom, lock-freedom, or even responsiveness. Two
successful, although rather different, approaches, are session types and
process types. The former allows to specify and verify (distributed)
communication protocols using specific type (proof) systems; the latter allows
to infer from a system specification a process abstraction on which it is
simpler to verify properties, using a generic type (proof) system. What is the
relationship between these approaches? Can the generic one subsume the specific
one? At what price? And can the former be used as a compiler for the latter?
The work presented herein is a step towards answers to such questions.
Concretely, we define a stepwise encoding of a pi-calculus with sessions and
session types (the system of Gay and Hole) into a pi-calculus with process
types (the Generic Type System of Igarashi and Kobayashi). We encode session
type environments, polarities (which distinguish session channels end-points),
and labelled sums. We show forward and reverse operational correspondences for
the encodings, as well as typing correspondences. To faithfully encode session
subtyping in process types subtyping, one needs to add to the target language
record constructors and new subtyping rules. In conclusion, the programming
convenience of session types as protocol abstractions can be combined with the
simplicity and power of the pi-calculus, taking advantage in particular of the
framework provided by the Generic Type System.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1460</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1460</id><created>2014-08-06</created><authors><author><keyname>Franke-Arnold</keyname><forenames>Sonja</forenames><affiliation>University of Glasgow</affiliation></author><author><keyname>Gay</keyname><forenames>Simon J.</forenames><affiliation>University of Glasgow</affiliation></author><author><keyname>Puthoor</keyname><forenames>Ittoop Vergheese</forenames><affiliation>University of Glasgow</affiliation></author></authors><title>Verification of Linear Optical Quantum Computing using Quantum Process
  Calculus</title><categories>cs.LO cs.PL</categories><comments>In Proceedings EXPRESS/SOS 2014, arXiv:1408.1271</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 160, 2014, pp. 111-129</journal-ref><doi>10.4204/EPTCS.160.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explain the use of quantum process calculus to describe and analyse linear
optical quantum computing (LOQC). The main idea is to define two processes, one
modelling a linear optical system and the other expressing a specification, and
prove that they are behaviourally equivalent. We extend the theory of
behavioural equivalence in the process calculus Communicating Quantum Processes
(CQP) to include multiple particles (namely photons) as information carriers,
described by Fock states or number states. We summarise the theory in this
paper, including the crucial result that equivalence is a congruence, meaning
that it is preserved by embedding in any context. In previous work, we have
used quantum process calculus to model LOQC but without verifying models
against specifications. In this paper, for the first time, we are able to carry
out verification. We illustrate this approach by describing and verifying two
models of an LOQC CNOT gate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1461</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1461</id><created>2014-08-06</created><authors><author><keyname>Hell</keyname><forenames>Pavol</forenames></author><author><keyname>Mohar</keyname><forenames>Bojan</forenames></author><author><keyname>Rafiey</keyname><forenames>Arash</forenames></author></authors><title>Ordering without forbidden patterns</title><categories>cs.DM cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let F be a set of ordered patterns, i.e., graphs whose vertices are linearly
ordered. An F-free ordering of the vertices of a graph H is a linear ordering
of V(H) such that none of patterns in F occurs as an induced ordered subgraph.
We denote by ORD(F) the decision problem asking whether an input graph admits
an F-free ordering; we also use ORD(F) to denote the class of graphs that do
admit an F-free ordering. It was observed by Damaschke (and others) that many
natural graph classes can be described as ORD(F) for sets F of small patterns
(with three or four vertices). Damaschke also noted that for many sets F
consisting of patterns with three vertices, ORD(F) is polynomial-time solvable
by known algorithms or their simple modifications. We complete the picture by
proving that all these problems can be solved in polynomial time. In fact, we
provide a single master algorithm, i.e., we solve in polynomial time the
problem $ORD_3$ in which the input is a set F of patterns with at most three
vertices and a graph H, and the problem is to decide whether or not H admits an
F-free ordering of the vertices. Our algorithm certifies non-membership by a
forbidden substructure, and thus provides a single forbidden structure
characterization for all the graph classes described by some ORD(F) with F
consisting of patterns with at most three vertices. Many of the problems ORD(F)
with F consisting of larger patterns have been shown to be NP-complete by
Duffus, Ginn, and Rodl, and we add two simple examples.
  We also discuss a bipartite version of the problem, BORD(F), in which the
input is a bipartite graph H with a fixed bipartition of the vertices, and we
are given a set F of bipartite patterns. We also describe some examples of
digraph ordering problems and algorithms. We conjecture that for every set F of
forbidden patterns, ORD(F) is either polynomial or NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1467</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1467</id><created>2014-08-06</created><updated>2014-11-03</updated><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author></authors><title>Interactive Channel Capacity Revisited</title><categories>cs.DS cs.DC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide the first capacity approaching coding schemes that robustly
simulate any interactive protocol over an adversarial channel that corrupts any
$\epsilon$ fraction of the transmitted symbols. Our coding schemes achieve a
communication rate of $1 - O(\sqrt{\epsilon \log \log 1/\epsilon})$ over any
adversarial channel. This can be improved to $1 - O(\sqrt{\epsilon})$ for
random, oblivious, and computationally bounded channels, or if parties have
shared randomness unknown to the channel.
  Surprisingly, these rates exceed the $1 - \Omega(\sqrt{H(\epsilon)}) = 1 -
\Omega(\sqrt{\epsilon \log 1/\epsilon})$ interactive channel capacity bound
which [Kol and Raz; STOC'13] recently proved for random errors. We conjecture
$1 - \Theta(\sqrt{\epsilon \log \log 1/\epsilon})$ and $1 -
\Theta(\sqrt{\epsilon})$ to be the optimal rates for their respective settings
and therefore to capture the interactive channel capacity for random and
adversarial errors.
  In addition to being very communication efficient, our randomized coding
schemes have multiple other advantages. They are computationally efficient,
extremely natural, and significantly simpler than prior (non-capacity
approaching) schemes. In particular, our protocols do not employ any coding but
allow the original protocol to be performed as-is, interspersed only by short
exchanges of hash values. When hash values do not match, the parties backtrack.
Our approach is, as we feel, by far the simplest and most natural explanation
for why and how robust interactive communication in a noisy environment is
possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1468</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1468</id><created>2014-08-06</created><authors><author><keyname>Yang</keyname><forenames>Ang</forenames></author><author><keyname>Jing</keyname><forenames>Yindi</forenames></author><author><keyname>Xing</keyname><forenames>Chengwen</forenames></author><author><keyname>Fei</keyname><forenames>Zesong</forenames></author><author><keyname>Kuang</keyname><forenames>Jingming</forenames></author></authors><title>Performance Analysis and Location Optimization for Massive MIMO Systems
  with Circularly Distributed Antennas</title><categories>cs.IT math.IT</categories><comments>Single column, 30 pages, 8 figures. Submitted to IEEE Transactions on
  Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the achievable rate of the uplink of a single-cell
multi-user distributed massive multiple-input-multiple-output (MIMO) system.
The multiple users are equipped with single antenna and the base station (BS)
is equipped with a large number of distributed antennas. We derive an
analytical expression for the asymptotic ergodic achievable rate of the system
under zero-forcing (ZF) detector. In particular, we consider circular antenna
array, where the distributed BS antennas are located evenly on a circle, and
derive an analytical expression and closed-form tight bounds for the achievable
rate of an arbitrarily located user. Subsequently, closed-form bounds on the
average achievable rate per user are obtained under the assumption that the
users are uniformly located in the cell. Based on the bounds, we can understand
the behavior of the system rate with respect to different parameters and find
the optimal location of the circular BS antenna array that maximizes the
average rate. Numerical results are provided to assess our analytical results
and examine the impact of the number and the location of the BS antennas, the
transmit power, and the path-loss exponent on system performance. It is shown
that circularly distributed massive MIMO system largely outperforms centralized
massive MIMO system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1469</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1469</id><created>2014-08-06</created><authors><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author><author><keyname>Mixon</keyname><forenames>Dustin G.</forenames></author></authors><title>A Multiple Hypothesis Testing Approach to Low-Complexity Subspace
  Unmixing</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Submitted for journal publication; 27 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subspace-based signal processing has a rich history in the literature.
Traditional focus in this direction has been on problems involving a few
subspaces. But a number of problems in different application areas have emerged
in recent years that involve significantly larger number of subspaces relative
to the ambient dimension. It becomes imperative in such settings to first
identify a smaller set of active subspaces that contribute to the observations
before further information processing tasks can be carried out. We term this
problem of identification of a small set of active subspaces among a huge
collection of subspaces from a single (noisy) observation in the ambient space
as subspace unmixing. In this paper, we formally pose the subspace unmixing
problem, discuss its connections with problems in wireless communications,
hyperspectral imaging, high-dimensional statistics and compressed sensing, and
propose and analyze a low-complexity algorithm, termed marginal subspace
detection (MSD), for subspace unmixing. The MSD algorithm turns the subspace
unmixing problem into a multiple hypothesis testing (MHT) problem and our
analysis helps control the family-wise error rate of this MHT problem at any
level. Some other highlights of our analysis of the MSD algorithm include: (i)
it is applicable to an arbitrary collection of subspaces on the Grassmann
manifold; (ii) it relies on properties of the collection of subspaces that are
computable in polynomial time; and (iii) it allows for linear scaling of the
number of active subspaces as a function of the ambient dimension. Finally, we
also present numerical results in the paper to better understand the
performance of the MSD algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1479</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1479</id><created>2014-08-07</created><authors><author><keyname>Delcher</keyname><forenames>Arthur L.</forenames></author><author><keyname>Grove</keyname><forenames>Adam J.</forenames></author><author><keyname>Kasif</keyname><forenames>Simon</forenames></author><author><keyname>Pearl</keyname><forenames>Judea</forenames></author></authors><title>Logarithmic-Time Updates and Queries in Probabilistic Networks</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Eleventh Conference on Uncertainty in
  Artificial Intelligence (UAI1995)</comments><proxy>auai</proxy><report-no>UAI-P-1995-PG-116-124</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a dynamic data structure that supports efficient
algorithms for updating and querying singly connected Bayesian networks (causal
trees and polytrees). In the conventional algorithms, new evidence in absorbed
in time O(1) and queries are processed in time O(N), where N is the size of the
network. We propose a practical algorithm which, after a preprocessing phase,
allows us to answer queries in time O(log N) at the expense of O(logn N) time
per evidence absorption. The usefulness of sub-linear processing time manifests
itself in applications requiring (near) real-time response over large
probabilistic databases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1480</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1480</id><created>2014-08-07</created><authors><author><keyname>Darwiche</keyname><forenames>Adnan</forenames></author><author><keyname>Provan</keyname><forenames>Gregory M.</forenames></author></authors><title>Query DAGs: A Practical Paradigm for Implementing Belief Network
  Inference</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twelfth Conference on Uncertainty in
  Artificial Intelligence (UAI1996)</comments><proxy>auai</proxy><report-no>UAI-P-1996-PG-203-210</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new paradigm for implementing inference in belief networks,
which relies on compiling a belief network into an arithmetic expression called
a Query DAG (Q-DAG). Each non-leaf node of a Q-DAG represents a numeric
operation, a number, or a symbol for evidence. Each leaf node of a Q-DAG
represents the answer to a network query, that is, the probability of some
event of interest. It appears that Q-DAGs can be generated using any of the
algorithms for exact inference in belief networks --- we show how they can be
generated using clustering and conditioning algorithms. The time and space
complexity of a Q-DAG generation algorithm is no worse than the time complexity
of the inference algorithm on which it is based; that of a Q-DAG on-line
evaluation algorithm is linear in the size of the Q-DAG, and such inference
amounts to a standard evaluation of the arithmetic expression it represents.
The main value of Q-DAGs is in reducing the software and hardware resources
required to utilize belief networks in on-line, real-world applications. The
proposed framework also facilitates the development of on-line inference on
different software and hardware platforms, given the simplicity of the Q-DAG
evaluation algorithm. This paper describes this new paradigm for probabilistic
inference, explaining how it works, its uses, and outlines some of the research
directions that it leads to.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1481</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1481</id><created>2014-08-07</created><authors><author><keyname>Lehmann</keyname><forenames>Daniel</forenames></author></authors><title>Generalized Qualitative Probability: Savage Revisited</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twelfth Conference on Uncertainty in
  Artificial Intelligence (UAI1996)</comments><proxy>auai</proxy><report-no>UAI-P-1996-PG-381-388</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preferences among acts are analyzed in the style of L. Savage, but as
partially ordered. The rationality postulates considered are weaker than
Savage's on three counts. The Sure Thing Principle is derived in this setting.
The postulates are shown to lead to a characterization of generalized
qualitative probability that includes and blends both traditional qualitative
probability and the ranked structures used in logical approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1482</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1482</id><created>2014-08-07</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Axiomatizing Causal Reasoning</title><categories>cs.AI cs.LO</categories><comments>Appears in Proceedings of the Fourteenth Conference on Uncertainty in
  Artificial Intelligence (UAI1998)</comments><proxy>auai</proxy><report-no>UAI-P-1998-PG-202-210</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Causal models defined in terms of a collection of equations, as defined by
Pearl, are axiomatized here. Axiomatizations are provided for three
successively more general classes of causal models: (1) the class of recursive
theories (those without feedback), (2) the class of theories where the
solutions to the equations are unique, (3) arbitrary theories (where the
equations may not have solutions and, if they do, they are not necessarily
unique). It is shown that to reason about causality in the most general third
class, we must extend the language used by Galles and Pearl. In addition, the
complexity of the decision procedures is examined for all the languages and
classes of models considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1483</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1483</id><created>2014-08-07</created><authors><author><keyname>Becker</keyname><forenames>Ann</forenames></author><author><keyname>Bar-Yehuada</keyname><forenames>Reuven</forenames></author><author><keyname>Geiger</keyname><forenames>Dan</forenames></author></authors><title>Random Algorithms for the Loop Cutset Problem</title><categories>cs.AI cs.DS</categories><comments>Appears in Proceedings of the Fifteenth Conference on Uncertainty in
  Artificial Intelligence (UAI1999)</comments><proxy>auai</proxy><report-no>UAI-P-1999-PG-49-56</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to find a minimum loop cutset in a Bayesian network with high
probability. Finding such a loop cutset is the first step in Pearl's method of
conditioning for inference. Our random algorithm for finding a loop cutset,
called &quot;Repeated WGuessI&quot;, outputs a minimum loop cutset, after O(c 6^k k n)
steps, with probability at least 1-(1 over{6^k})^{c 6^k}), where c&gt;1 is a
constant specified by the user, k is the size of a minimum weight loop cutset,
and n is the number of vertices. We also show empirically that a variant of
this algorithm, called WRA, often finds a loop cutset that is closer to the
minimum loop cutset than the ones found by the best deterministic algorithms
known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1484</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1484</id><created>2014-08-07</created><authors><author><keyname>Peshkin</keyname><forenames>Leonid</forenames></author><author><keyname>Kim</keyname><forenames>Kee-Eung</forenames></author><author><keyname>Meuleau</keyname><forenames>Nicolas</forenames></author><author><keyname>Kaelbling</keyname><forenames>Leslie Pack</forenames></author></authors><title>Learning to Cooperate via Policy Search</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Sixteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2000)</comments><proxy>auai</proxy><report-no>UAI-P-2000-PG-489-496</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative games are those in which both agents share the same payoff
structure. Value-based reinforcement-learning algorithms, such as variants of
Q-learning, have been applied to learning cooperative games, but they only
apply when the game state is completely observable to both agents. Policy
search methods are a reasonable alternative to value-based methods for
partially observable environments. In this paper, we provide a gradient-based
distributed policy-search method for cooperative games and compare the notion
of local optimum to that of Nash equilibrium. We demonstrate the effectiveness
of this method experimentally in a small, partially observable simulated soccer
domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1485</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1485</id><created>2014-08-07</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Pucella</keyname><forenames>Riccardo</forenames></author></authors><title>A Logic for Reasoning about Upper Probabilities</title><categories>cs.AI cs.LO</categories><comments>Appears in Proceedings of the Seventeenth Conference on Uncertainty
  in Artificial Intelligence (UAI2001)</comments><proxy>auai</proxy><report-no>UAI-P-2001-PG-203-210</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a propositional logic to reason about the uncertainty of events,
where the uncertainty is modeled by a set of probability measures assigning an
interval of probability to each event. We give a sound and complete
axiomatization for the logic, and show that the satisfiability problem is
NP-complete, no harder than satisfiability for propositional logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1486</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1486</id><created>2014-08-07</created><authors><author><keyname>Conitzer</keyname><forenames>Vincent</forenames></author><author><keyname>Sandholm</keyname><forenames>Tuomas</forenames></author></authors><title>Complexity of Mechanism Design</title><categories>cs.GT</categories><comments>Appears in Proceedings of the Eighteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2002)</comments><proxy>auai</proxy><report-no>UAI-P-2002-PG-103-110</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aggregation of conflicting preferences is a central problem in multiagent
systems. The key difficulty is that the agents may report their preferences
insincerely. Mechanism design is the art of designing the rules of the game so
that the agents are motivated to report their preferences truthfully and a
(socially) desirable outcome is chosen. We propose an approach where a
mechanism is automatically created for the preference aggregation setting at
hand. This has several advantages, but the downside is that the mechanism
design optimization problem needs to be solved anew each time. Focusing on
settings where side payments are not possible, we show that the mechanism
design problem is NP-complete for deterministic mechanisms. This holds both for
dominant-strategy implementation and for Bayes-Nash implementation. We then
show that if we allow randomized mechanisms, the mechanism design problem
becomes tractable. In other words, the coordinator can tackle the computational
complexity introduced by its uncertainty about the agents preferences BY making
the agents face additional uncertainty.This comes at no loss, AND IN SOME cases
at a gain, IN the(social) objective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1487</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1487</id><created>2014-08-07</created><authors><author><keyname>Zaffalon</keyname><forenames>Marco</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Robust Feature Selection by Mutual Information Distributions</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Eighteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2002)</comments><proxy>auai</proxy><report-no>UAI-P-2002-PG-577-584</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mutual information is widely used in artificial intelligence, in a
descriptive way, to measure the stochastic dependence of discrete random
variables. In order to address questions such as the reliability of the
empirical value, one must consider sample-to-population inferential approaches.
This paper deals with the distribution of mutual information, as obtained in a
Bayesian framework by a second-order Dirichlet prior distribution. The exact
analytical expression for the mean and an analytical approximation of the
variance are reported. Asymptotic approximations of the distribution are
proposed. The results are applied to the problem of selecting features for
incremental learning and classification of the naive Bayes classifier. A fast,
newly defined method is shown to outperform the traditional approach based on
empirical mutual information on a number of real data sets. Finally, a
theoretical development is reported that allows one to efficiently extend the
above methods to incomplete samples in an easy and effective way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1488</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1488</id><created>2014-08-07</created><authors><author><keyname>de Cooman</keyname><forenames>Gert</forenames></author><author><keyname>Zaffalon</keyname><forenames>Marco</forenames></author></authors><title>Updating with incomplete observations</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Nineteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2003)</comments><proxy>auai</proxy><report-no>UAI-P-2003-PG-142-150</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, there is renewed interest in the problem, raised by Shafer in
1985, of updating probabilities when observations are incomplete (or
set-valued). This is a fundamental problem, and of particular interest for
Bayesian networks. Recently, Grunwald and Halpern have shown that commonly used
updating strategies fail here, except under very special assumptions. We
propose a new rule for updating probabilities with incomplete observations. Our
approach is deliberately conservative: we make no or weak assumptions about the
so-called incompleteness mechanism that produces incomplete observations. We
model our ignorance about this mechanism by a vacuous lower prevision, a tool
from the theory of imprecise probabilities, and we derive a new updating rule
using coherence arguments. In general, our rule produces lower posterior
probabilities, as well as partially determinate decisions. This is a logical
consequence of the ignorance about the incompleteness mechanism. We show how
the new rule can properly address the apparent paradox in the 'Monty Hall'
puzzle. In addition, we apply it to the classification of new evidence in
Bayesian networks constructed using expert knowledge. We provide an exact
algorithm for this task with linear-time complexity, also for multiply
connected nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1489</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1489</id><created>2014-08-07</created><authors><author><keyname>Storkey</keyname><forenames>Amos J.</forenames></author><author><keyname>Hambly</keyname><forenames>Nigel C.</forenames></author><author><keyname>Williams</keyname><forenames>Christopher K. I.</forenames></author><author><keyname>Mann</keyname><forenames>Robert G.</forenames></author></authors><title>Renewal Strings for Cleaning Astronomical Databases</title><categories>cs.AI astro-ph.IM</categories><comments>Appears in Proceedings of the Nineteenth Conference on Uncertainty in
  Artificial Intelligence (UAI2003)</comments><proxy>auai</proxy><report-no>UAI-P-2003-PG-559-566</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large astronomical databases obtained from sky surveys such as the
SuperCOSMOS Sky Surveys (SSS) invariably suffer from a small number of spurious
records coming from artefactual effects of the telescope, satellites and junk
objects in orbit around earth and physical defects on the photographic plate or
CCD. Though relatively small in number these spurious records present a
significant problem in many situations where they can become a large proportion
of the records potentially of interest to a given astronomer. In this paper we
focus on the four most common causes of unwanted records in the SSS: satellite
or aeroplane tracks, scratches fibres and other linear phenomena introduced to
the plate, circular halos around bright stars due to internal reflections
within the telescope and diffraction spikes near to bright stars. Accurate and
robust techniques are needed for locating and flagging such spurious objects.
We have developed renewal strings, a probabilistic technique combining the
Hough transform, renewal processes and hidden Markov models which have proven
highly effective in this context. The methods are applied to the SSS data to
develop a dataset of spurious object detections, along with confidence
measures, which can allow this unwanted data to be removed from consideration.
These methods are general and can be adapted to any future astronomical survey
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1490</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1490</id><created>2014-08-07</created><authors><author><keyname>Woo</keyname><forenames>Jun Young</forenames></author><author><keyname>Kim</keyname><forenames>Kee Hoon</forenames></author><author><keyname>No</keyname><forenames>Jong Seon</forenames></author><author><keyname>Shin</keyname><forenames>Dong Joon</forenames></author></authors><title>OS effect in SLM schemes with correlation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BER is analyzed SLM schemes with correlation metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1492</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1492</id><created>2014-08-07</created><authors><author><keyname>Shnayder</keyname><forenames>Victor</forenames></author><author><keyname>Parkes</keyname><forenames>David C.</forenames></author><author><keyname>Kawadia</keyname><forenames>Vikas</forenames></author><author><keyname>Hoon</keyname><forenames>Jeremy</forenames></author></authors><title>Truthful Prioritization Schemes for Spectrum Sharing</title><categories>cs.GT</categories><comments>This report is an extended version of our paper in ACM MOBIHOC 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a protocol for dynamic prioritization of data on shared routers
such as untethered 3G/4G devices. The mechanism prioritizes bandwidth in favor
of users with the highest value, and is incentive compatible, so that users can
simply report their true values for network access. A revenue pooling mechanism
also aligns incentives for sellers, so that they will choose to use
prioritization methods that retain the incentive properties on the buy-side. In
this way, the design allows for an open architecture. In addition to revenue
pooling, the technical contribution is to identify a class of stochastic demand
models and a prioritization scheme that provides allocation monotonicity.
Simulation results confirm efficiency gains from dynamic prioritization
relative to prior methods, as well as the effectiveness of revenue pooling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1494</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1494</id><created>2014-08-07</created><authors><author><keyname>Garcia</keyname><forenames>David</forenames></author><author><keyname>Tessone</keyname><forenames>Claudio Juan</forenames></author><author><keyname>Mavrodiev</keyname><forenames>Pavlin</forenames></author><author><keyname>Perony</keyname><forenames>Nicolas</forenames></author></authors><title>The digital traces of bubbles: feedback cycles between socio-economic
  signals in the Bitcoin economy</title><categories>physics.soc-ph cs.SI nlin.AO q-fin.ST</categories><comments>16 pages, 3 figures, supplementary material</comments><journal-ref>Journal of the Royal Society Interface, pp. 20140623, vol. 11
  (2014)</journal-ref><doi>10.1098/?rsif.2014.0623</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What is the role of social interactions in the creation of price bubbles?
Answering this question requires obtaining collective behavioural traces
generated by the activity of a large number of actors. Digital currencies offer
a unique possibility to measure socio-economic signals from such digital
traces. Here, we focus on Bitcoin, the most popular cryptocurrency. Bitcoin has
experienced periods of rapid increase in exchange rates (price) followed by
sharp decline; we hypothesise that these fluctuations are largely driven by the
interplay between different social phenomena. We thus quantify four
socio-economic signals about Bitcoin from large data sets: price on on-line
exchanges, volume of word-of-mouth communication in on-line social media,
volume of information search, and user base growth. By using vector
autoregression, we identify two positive feedback loops that lead to price
bubbles in the absence of exogenous stimuli: one driven by word of mouth, and
the other by new Bitcoin adopters. We also observe that spikes in information
search, presumably linked to external events, precede drastic price declines.
Understanding the interplay between the socio-economic signals we measured can
lead to applications beyond cryptocurrencies to other phenomena which leave
digital footprints, such as on-line social network usage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1506</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1506</id><created>2014-08-07</created><authors><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author><author><keyname>Luzzi</keyname><forenames>Laura</forenames></author><author><keyname>Belfiore</keyname><forenames>Jean-Claude</forenames></author></authors><title>Shifted inverse determinant sums and new bounds for the DMT of
  space-time lattice codes</title><categories>cs.IT math.IT</categories><comments>To appear in Proc. 2014 IEEE Int. Symp. Inform. Theory (ISIT),
  Hawaii, USA, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers shifted inverse determinant sums arising from the union
bound of the pairwise error probability for space-time codes in
multiple-antenna fading channels. Previous work by Vehkalahti et al. focused on
the approximation of these sums for low multiplexing gains, providing a
complete classification of the inverse determinant sums as a function of
constellation size for the most well-known algebraic space-time codes. This
work aims at building a general framework for the study of the shifted sums for
all multiplexing gains. New bounds obtained using dyadic summing techniques
suggest that the behavior of the shifted sums does characterize many properties
of a lattice code such as the diversity-multiplexing gain trade-off, both under
maximum-likelihood decoding and infinite lattice naive decoding. Moreover,
these bounds allow to characterize the signal-to-noise ratio thresholds
corresponding to different diversity gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1519</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1519</id><created>2014-08-07</created><updated>2014-08-08</updated><authors><author><keyname>Brown</keyname><forenames>Chlo&#xeb;</forenames></author><author><keyname>Lathia</keyname><forenames>Neal</forenames></author><author><keyname>Noulas</keyname><forenames>Anastasios</forenames></author><author><keyname>Mascolo</keyname><forenames>Cecilia</forenames></author><author><keyname>Blondel</keyname><forenames>Vincent</forenames></author></authors><title>Group colocation behavior in technological social networks</title><categories>cs.SI physics.soc-ph</categories><comments>7 pages, 8 figures. Accepted for publication in PLOS One</comments><doi>10.1371/journal.pone.0105816</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze two large datasets from technological networks with location and
social data: user location records from an online location-based social
networking service, and anonymized telecommunications data from a European
cellphone operator, in order to investigate the differences between individual
and group behavior with respect to physical location. We discover agreements
between the two datasets: firstly, that individuals are more likely to meet
with one friend at a place they have not visited before, but tend to meet at
familiar locations when with a larger group. We also find that groups of
individuals are more likely to meet at places that their other friends have
visited, and that the type of a place strongly affects the propensity for
groups to meet there. These differences between group and solo mobility has
potential technological applications, for example, in venue recommendation in
location-based social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1534</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1534</id><created>2014-08-07</created><authors><author><keyname>Aggarwal</keyname><forenames>Anupama</forenames></author><author><keyname>Kumaraguru</keyname><forenames>Ponnurangam</forenames></author></authors><title>Followers or Phantoms? An Anatomy of Purchased Twitter Followers</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online Social Media (OSM) is extensively used by contemporary Internet users
to communicate, socialize and disseminate information. This has led to the
creation of a distinct online social identity which in turn has created the
need of online social reputation management techniques. A significant
percentage of OSM users utilize various methods to drive and manage their
reputation on OSM. This has given rise to underground markets which buy/sell
fraudulent accounts, `likes', `comments' (Facebook, Instagram) and `followers'
(Twitter) to artificially boost their social reputation. In this study, we
present an anatomy of purchased followers on Twitter and their behaviour. We
illustrate in detail the profile characteristics, content sharing and
behavioural patterns of purchased follower accounts.
  Previous studies have analyzed the purchased follower markets and customers.
Ours is the first study which analyzes the anatomy of purchased followers
accounts. Some of the key insights of our study show that purchased followers
have a very high unfollow entropy rate and low social engagement with their
friends. In addition, we noticed that purchased follower accounts have
significant difference in their interaction and content sharing patterns in
comparison to random Twitter users. We also found that underground markets do
not follow their service policies and guarantees they provide to customer. Our
study highlights the key identifiers for suspicious follow behaviour. We then
built a supervised learning mechanism to predict suspicious follower behaviour
with 88.2% accuracy. We believe that understanding the anatomy and
characteristics of purchased followers can help detect suspicious follower
behaviour and fraudulent accounts to a larger extent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1540</identifier>
 <datestamp>2015-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1540</id><created>2014-08-07</created><authors><author><keyname>Rahaman</keyname><forenames>Ramij</forenames></author><author><keyname>Wie&#x15b;niak</keyname><forenames>Marcin</forenames></author><author><keyname>&#x17b;ukowski</keyname><forenames>Marek</forenames></author></authors><title>Quantum Byzantine Agreement via Hardy correlations and entanglement
  swapping</title><categories>quant-ph cs.CR cs.DC cs.IT math.IT</categories><comments>The protocol presented here is a solution of the original Byzantine
  agreement problem and not its sub-problem like detectable Byzantine
  agreement. Comments are welcome</comments><journal-ref>Phys. Rev. A 92, 042302 (2015)</journal-ref><doi>10.1103/PhysRevA.92.042302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a device-independent quantum scheme for the {\em Byzantine
Generals} problem. The protocol is for three parties. Party $C$ is to send two
identical one bit messages to parties $A$ and $B$. The receivers $A$ and $B$
may exchange two one bit messages informing the other party on the message
received from $C$. A bit flipping error in one of the transmissions, does not
allow the receiving parties to establish what was the message of $C$. Our
quantum scheme has the feature that if the messages of the Byzantine protocol
are readable (that is give an unambiguous bit value for any of the receivers),
then any error by $C$ (cheating by one of the commanding general) is
impossible. $A$ and $B$ do not have to exchange protocol messages to be sure of
this.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1542</identifier>
 <datestamp>2015-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1542</id><created>2014-08-07</created><updated>2015-05-24</updated><authors><author><keyname>Abeliuk</keyname><forenames>Andres</forenames></author><author><keyname>Berbeglia</keyname><forenames>Gerardo</forenames></author><author><keyname>Cebrian</keyname><forenames>Manuel</forenames></author><author><keyname>Van Hentenryck</keyname><forenames>Pascal</forenames></author></authors><title>Measuring and Optimizing Cultural Markets</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social influence has been shown to create significant unpredictability in
cultural markets, providing one potential explanation why experts routinely
fail at predicting commercial success of cultural products. To counteract the
difficulty of making accurate predictions, &quot;measure and react&quot; strategies have
been advocated but finding a concrete strategy that scales for very large
markets has remained elusive so far. Here we propose a &quot;measure and optimize&quot;
strategy based on an optimization policy that uses product quality, appeal, and
social influence to maximize expected profits in the market at each decision
point. Our computational experiments show that our policy leverages social
influence to produce significant performance benefits for the market, while our
theoretical analysis proves that our policy outperforms in expectation any
policy not displaying social information. Our results contrast with earlier
work which focused on showing the unpredictability and inequalities created by
social influence. Not only do we show for the first time that dynamically
showing consumers positive social information under our policy increases the
expected performance of the seller in cultural markets. We also show that, in
reasonable settings, our policy does not introduce significant unpredictability
and identifies &quot;blockbusters&quot;. Overall, these results shed new light on the
nature of social influence and how it can be leveraged for the benefits of the
market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1546</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1546</id><created>2014-08-07</created><authors><author><keyname>G&#xf3;mez-Torrecillas</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Lobillo</keyname><forenames>F. J.</forenames></author><author><keyname>Navarro</keyname><forenames>Gabriel</forenames></author></authors><title>Ideal codes over separable ring extensions</title><categories>cs.IT math.IT math.RA</categories><msc-class>68P30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the application of the theoretical algebraic notion
of a separable ring extension, in the realm of cyclic convolutional codes or,
more generally, ideal codes. We work under very mild conditions, that cover all
previously known as well as new non trivial examples. It is proved that ideal
codes are direct summands as left ideals of the underlying non-commutative
algebra, in analogy with cyclic block codes. This implies, in particular, that
they are generated by an idempotent element. Hence, by using a suitable
separability element, we design an efficient algorithm for computing one of
such idempotents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1549</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1549</id><created>2014-08-07</created><authors><author><keyname>Azad</keyname><forenames>Reza</forenames></author><author><keyname>Azad</keyname><forenames>Babak</forenames></author><author><keyname>Khalifa</keyname><forenames>Nabil Belhaj</forenames></author><author><keyname>Jamali</keyname><forenames>Shahram</forenames></author></authors><title>Real-Time Human-Computer Interaction Based on Face and Hand Gesture
  Recognition</title><categories>cs.CV</categories><journal-ref>International Journal in Foundations of Computer Science &amp;
  Technology 07/2014; 4(4):37-48</journal-ref><doi>10.5121/ijfcst.2014.4403</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At the present time, hand gestures recognition system could be used as a more
expected and useable approach for human computer interaction. Automatic hand
gesture recognition system provides us a new tactic for interactive with the
virtual environment. In this paper, a face and hand gesture recognition system
which is able to control computer media player is offered. Hand gesture and
human face are the key element to interact with the smart system. We used the
face recognition scheme for viewer verification and the hand gesture
recognition in mechanism of computer media player, for instance, volume
down/up, next music and etc. In the proposed technique, first, the hand gesture
and face location is extracted from the main image by combination of skin and
cascade detector and then is sent to recognition stage. In recognition stage,
first, the threshold condition is inspected then the extracted face and gesture
will be recognized. In the result stage, the proposed technique is applied on
the video dataset and the high precision ratio acquired. Additional the
recommended hand gesture recognition method is applied on static American Sign
Language (ASL) database and the correctness rate achieved nearby 99.40%. also
the planned method could be used in gesture based computer games and virtual
reality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1560</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1560</id><created>2014-08-07</created><authors><author><keyname>Seda</keyname><forenames>A.</forenames></author><author><keyname>Vedat</keyname><forenames>S.</forenames></author></authors><title>MacWilliams identities for poset level weight enumerators of linear
  codes</title><categories>cs.IT math.IT</categories><msc-class>94B05, 94B60, 94B99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Codes over various metrics such as Rosenbloom-Tsfasman (RT), Lee, etc. have
been considered. Recently, codes over poset metrics have been studied. Poset
metric is a great generalization of many metrics especially the well-known ones
such as the RT and the Hamming metrics. Poset metric can be realized on the
channels with localized error occurrences. It has been shown that MacWilliams
identities are not admissible for codes over poset metrics in general [Kim and
Oh, 2005]. Lately, to overcome this problem some further studies on MacWilliams
identities over poset metrics has been presented. In this paper, we introduce
new poset level weight enumerators of linear codes over Frobenius commutative
rings. We derive MacWilliams-type identities for each of the given enumerators
which generalize in great deal the previous results discussed in the
literature. Most of the weight enumerators in the literature such as Hamming,
Rosenbloom-Tsfasman and complete m-spotty weight enumerators follow as
corollaries to these identities especially.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1577</identifier>
 <datestamp>2015-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1577</id><created>2014-08-07</created><updated>2015-10-17</updated><authors><author><keyname>Elbassioni</keyname><forenames>Khaled</forenames></author><author><keyname>Mehlhorn</keyname><forenames>Kurt</forenames></author><author><keyname>Ramezani</keyname><forenames>Fahimeh</forenames></author></authors><title>Towards More Practical Linear Programming-based Techniques for
  Algorithmic Mechanism Design</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  R. Lavy and C. Swamy (FOCS 2005, J. ACM 2011) introduced a general method for
obtaining truthful-in-expectation mechanisms from linear programming based
approximation algorithms. Due to the use of the Ellipsoid method, a direct
implementation of the method is unlikely to be efficient in practice. We
propose to use the much simpler and usually faster multiplicative weights
update method instead. The simplification comes at the cost of slightly weaker
approximation and truthfulness guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1589</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1589</id><created>2014-08-07</created><authors><author><keyname>Karimaddini</keyname><forenames>Zahra</forenames></author><author><keyname>Unal</keyname><forenames>Erkan</forenames></author><author><keyname>Menshykau</keyname><forenames>Denis</forenames></author><author><keyname>Iber</keyname><forenames>Dagmar</forenames></author></authors><title>Simulating Organogenesis in COMSOL: Image-based Modeling</title><categories>cs.CE q-bio.TO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical Modelling has a long history in developmental biology. Advances
in experimental techniques and computational algorithms now permit the
development of increasingly more realistic models of organogenesis. In
particular, 3D geometries of developing organs have recently become available.
In this paper, we show how to use image-based data for simulations of
organogenesis in COMSOL Multiphysics. As an example, we use limb bud
development, a classical model system in mouse developmental biology. We
discuss how embryonic geometries with several subdomains can be read into
COMSOL using the Matlab LiveLink, and how these can be used to simulate models
on growing embryonic domains. The ALE method is used to solve signaling models
even on strongly deforming domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1592</identifier>
 <datestamp>2016-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1592</id><created>2014-08-07</created><authors><author><keyname>Slavkovik</keyname><forenames>Marija</forenames></author><author><keyname>Dennis</keyname><forenames>Louise A.</forenames></author><author><keyname>Fisher</keyname><forenames>Michael</forenames></author></authors><title>An Abstract Formal Basis for Digital Crowds</title><categories>cs.LO cs.MA</categories><comments>32 pages, 4 figures</comments><doi>10.1007/s10619-014-7161-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowdsourcing, together with its related approaches, has become very popular
in recent years. All crowdsourcing processes involve the participation of a
digital crowd, a large number of people that access a single Internet platform
or shared service. In this paper we explore the possibility of applying formal
methods, typically used for the verification of software and hardware systems,
in analysing the behaviour of a digital crowd. More precisely, we provide a
formal description language for specifying digital crowds. We represent digital
crowds in which the agents do not directly communicate with each other. We
further show how this specification can provide the basis for sophisticated
formal methods, in particular formal verification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1600</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1600</id><created>2014-08-07</created><authors><author><keyname>Chaturvedi</keyname><forenames>Animesh</forenames></author></authors><title>Change Impact Analysis Based Regression Testing of Web Services</title><categories>cs.SE cs.DC</categories><comments>Master of Technology Thesis, PDPM Indian Institute of Information
  Technology, Design and Manufacturing Jabalpur (2014)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reducing the effort required to make changes in web services is one of the
primary goals in web service projects maintenance and evolution. Normally,
functional and non-functional testing of a web service is performed by testing
the operations specified in its WSDL. The regression testing is performed by
identifying the changes made thereafter to the web service code and the WSDL.
In this thesis, we present a tool-supported approach to perform efficient
regression testing of web services. By representing a web service as a directed
graph of WSDL elements, we identify and gathers the changed portions of the
graph and use this information to reduce regression testing efforts.
Specifically, we identify, categorize, and capture the web service testing
needs in two different ways, namely, Operationalized Regression Testing of Web
Service (ORTWS) and Parameterized Regression Testing of Web Service (PRTWS).
Both of the approach can be combined to reduce the regression testing efforts
in the web service project. The proposed approach is prototyped as a tool,
named as Automatic Web Service Change Management (AWSCM), which helps in
selecting the relevant test cases to construct reduced test suite from the old
test suite. We present few case studies on different web service projects to
demonstrate the applicability of the proposed tool. The reduction in the effort
for regression testing of web service is also estimated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1602</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1602</id><created>2014-08-07</created><authors><author><keyname>Li</keyname><forenames>Xiangkun</forenames></author><author><keyname>Borsche</keyname><forenames>Theodor</forenames></author><author><keyname>Andersson</keyname><forenames>G&#xf6;ran</forenames></author></authors><title>PV Integration in Low-Voltage Feeders with Demand Response</title><categories>cs.SY</categories><comments>Working Paper, to be submitted at PowerTech 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increased distributed Photo-Voltaic (PV) generation leads to an increase in
voltages and unwarranted backflows into the grid. This paper investigates
Demand Response (DR) with Electric Water Heaters (EWHs) as a way to increase
the PV hosting capacity of a low-voltage feeder. A control strategy relying
only on power measurements at the transformer is proposed. Flexible loads are
optimally dispatched considering energy acquisition costs, a PV shedding
penalty, and power and energy constraints. Furthermore, grouping of loads and
PV plants is investigated, and switching penalties are used to reduce the
unnecessary switching of loads. It is shown that this strategy can
substantially increase the PV hosting capacity of a Low-Voltage (LV) feeder,
even when only basic controllability is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1603</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1603</id><created>2014-08-07</created><authors><author><keyname>Di Patti</keyname><forenames>Francesca</forenames></author><author><keyname>Fanelli</keyname><forenames>Duccio</forenames></author><author><keyname>Piazza</keyname><forenames>Francesco</forenames></author></authors><title>Optimal search strategies on complex networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>Supplementary material is available on request</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks are ubiquitous in nature and play a role of paramount
importance in many contexts. Internet and the cyberworld, which permeate our
everyday life, are self-organized hierarchical graphs. Urban traffic flows on
intricate road networks, which impact both transportation design and epidemic
control. In the brain, neurons are cabled through heterogeneous connections,
which support the propagation of electric signals. In all these cases, the true
challenge is to unveil the mechanisms through which specific dynamical features
are modulated by the underlying topology of the network. Here, we consider
agents randomly hopping along the links of a graph, with the additional
possibility of performing long-range hops to randomly chosen disconnected nodes
with a given probability. We show that an optimal combination of the two jump
rules exists that maximises the efficiency of target search, the optimum
reflecting the topology of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1605</identifier>
 <datestamp>2014-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1605</id><created>2014-08-07</created><updated>2014-12-23</updated><authors><author><keyname>Bisson</keyname><forenames>Mauro</forenames></author><author><keyname>Bernaschi</keyname><forenames>Massimo</forenames></author><author><keyname>Mastrostefano</keyname><forenames>Enrico</forenames></author></authors><title>Parallel Distributed Breadth First Search on the Kepler Architecture</title><categories>cs.DC</categories><comments>In this revision we adopt a technique to reduce the size of exchanged
  messages that relies on the use of a bitmap. This change halves, by itself,
  the total execution time. Now the code reaches 800 GTEPS on 4096 Kepler GPUs.
  We also made some modifications to the Introduction and to the performance
  section. Added new references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the results obtained by using an evolution of our CUDA-based
solution for the exploration, via a Breadth First Search, of large graphs. This
latest version exploits at its best the features of the Kepler architecture and
relies on a combination of techniques to reduce both the number of
communications among the GPUs and the amount of exchanged data. The final
result is a code that can visit more than 800 billion edges in a second by
using a cluster equipped with 4096 Tesla K20X GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1647</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1647</id><created>2014-08-07</created><authors><author><keyname>Pedersen</keyname><forenames>Truls</forenames></author><author><keyname>Dyrkolbotn</keyname><forenames>Sjur</forenames></author></authors><title>Computing consensus: A logic for reasoning about deliberative processes
  based on argumentation</title><categories>cs.LO</categories><comments>Presented at the 1st International Workshop on Argument for Agreement
  and Assurance (AAA 2013)</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider multi-agent argumentation, where each agent's view of the
arguments is encoded as an argumentation framework (AF). Then we study
deliberative processes than can occur on this basis. We think of a deliberative
process as taking the shape of a stepwise aggregation of a single joint AF, and
we are interested in reasoning about the space of possible outcomes. The only
restriction we place on deliberative processes is that they should satisfy
faithfulness, a postulate amounting to requiring that whenever deliberation
leads to a new relationship being introduced between two arguments, this
relationship is endorsed by at least one participating agent. We use modal
logic to reason about the resulting deliberative structures, and we provide
some technical results on model checking. We also give an example and suggest
some directions for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1655</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1655</id><created>2014-08-06</created><authors><author><keyname>Hardt</keyname><forenames>Moritz</forenames></author><author><keyname>Ullman</keyname><forenames>Jonathan</forenames></author></authors><title>Preventing False Discovery in Interactive Data Analysis is Hard</title><categories>cs.LG cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that, under a standard hardness assumption, there is no
computationally efficient algorithm that given $n$ samples from an unknown
distribution can give valid answers to $n^{3+o(1)}$ adaptively chosen
statistical queries. A statistical query asks for the expectation of a
predicate over the underlying distribution, and an answer to a statistical
query is valid if it is &quot;close&quot; to the correct expectation over the
distribution.
  Our result stands in stark contrast to the well known fact that exponentially
many statistical queries can be answered validly and efficiently if the queries
are chosen non-adaptively (no query may depend on the answers to previous
queries). Moreover, a recent work by Dwork et al. shows how to accurately
answer exponentially many adaptively chosen statistical queries via a
computationally inefficient algorithm; and how to answer a quadratic number of
adaptive queries via a computationally efficient algorithm. The latter result
implies that our result is tight up to a linear factor in $n.$
  Conceptually, our result demonstrates that achieving statistical validity
alone can be a source of computational intractability in adaptive settings. For
example, in the modern large collaborative research environment, data analysts
typically choose a particular approach based on previous findings. False
discovery occurs if a research finding is supported by the data but not by the
underlying distribution. While the study of preventing false discovery in
Statistics is decades old, to the best of our knowledge our result is the first
to demonstrate a computational barrier. In particular, our result suggests that
the perceived difficulty of preventing false discovery in today's collaborative
research environment may be inherent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1656</identifier>
 <datestamp>2015-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1656</id><created>2014-08-06</created><updated>2015-09-07</updated><authors><author><keyname>Liao</keyname><forenames>Shengcai</forenames></author><author><keyname>Jain</keyname><forenames>Anil K.</forenames></author><author><keyname>Li</keyname><forenames>Stan Z.</forenames></author></authors><title>A Fast and Accurate Unconstrained Face Detector</title><categories>cs.CV</categories><comments>This paper has been accepted by TPAMI. The source code is available
  on the project page
  http://www.cbsr.ia.ac.cn/users/scliao/projects/npdface/index.html</comments><doi>10.1109/TPAMI.2015.2448075</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method to address challenges in unconstrained face detection,
such as arbitrary pose variations and occlusions. First, a new image feature
called Normalized Pixel Difference (NPD) is proposed. NPD feature is computed
as the difference to sum ratio between two pixel values, inspired by the Weber
Fraction in experimental psychology. The new feature is scale invariant,
bounded, and is able to reconstruct the original image. Second, we propose a
deep quadratic tree to learn the optimal subset of NPD features and their
combinations, so that complex face manifolds can be partitioned by the learned
rules. This way, only a single soft-cascade classifier is needed to handle
unconstrained face detection. Furthermore, we show that the NPD features can be
efficiently obtained from a look up table, and the detection template can be
easily scaled, making the proposed face detector very fast. Experimental
results on three public face datasets (FDDB, GENKI, and CMU-MIT) show that the
proposed method achieves state-of-the-art performance in detecting
unconstrained faces with arbitrary pose variations and occlusions in cluttered
scenes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1664</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1664</id><created>2014-08-07</created><updated>2014-08-14</updated><authors><author><keyname>Chen</keyname><forenames>Yetian</forenames></author><author><keyname>Tian</keyname><forenames>Jin</forenames></author><author><keyname>Nikolova</keyname><forenames>Olga</forenames></author><author><keyname>Aluru</keyname><forenames>Srinivas</forenames></author></authors><title>A Parallel Algorithm for Exact Bayesian Structure Discovery in Bayesian
  Networks</title><categories>cs.AI cs.DC cs.LG</categories><comments>25 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Exact Bayesian structure discovery in Bayesian networks requires exponential
time and space. Using dynamic programming (DP), the fastest known serial
algorithm computes the exact posterior probabilities of structural features in
$O(n2^n)$ time and space, if the number of parents per node or indegree is
bounded by a constant $d$. Here we present a parallel algorithm capable of
computing the exact posterior probabilities for all $n(n-1)$ edges with optimal
parallel time and space efficiency. That is, if $p=2^k$ processors are used,
the run-time and space usage reduce to $O(n2^{n-k}+k(n-k)^d)$ and
$O(n2^{n-k})$, respectively. Our algorithm is based the observation that the
original DP steps constitute a $n$-$D$ hypercube. In our algorithm, we take a
delicate way to coordinate the computations of correlated DP procedures such
that large amount of data exchange is suppressed. Further, we develop parallel
techniques for two variants of the well-known zeta transform, which have
applications outside the context of Bayesian networks. We demonstrate the
capability of our algorithm on datasets with up to 33 variables and its
scalability on up to 2048 processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1667</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1667</id><created>2014-08-07</created><authors><author><keyname>Bessi</keyname><forenames>Alessandro</forenames></author><author><keyname>Coletto</keyname><forenames>Mauro</forenames></author><author><keyname>Davidescu</keyname><forenames>George Alexandru</forenames></author><author><keyname>Scala</keyname><forenames>Antonio</forenames></author><author><keyname>Caldarelli</keyname><forenames>Guido</forenames></author><author><keyname>Quattrociocchi</keyname><forenames>Walter</forenames></author></authors><title>Science vs Conspiracy: collective narratives in the age of
  (mis)information</title><categories>cs.SI cs.HC physics.soc-ph</categories><doi>10.1371/journal.pone.0118093</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The large availability of user provided contents on online social media
facilitates people aggregation around common interests, worldviews and
narratives. However, in spite of the enthusiastic rhetoric about the so called
{\em wisdom of crowds}, unsubstantiated rumors -- as alternative explanation to
main stream versions of complex phenomena -- find on the Web a natural medium
for their dissemination. In this work we study, on a sample of 1.2 million of
individuals, how information related to very distinct narratives -- i.e. main
stream scientific and alternative news -- are consumed on Facebook. Through a
thorough quantitative analysis, we show that distinct communities with similar
information consumption patterns emerge around distinctive narratives.
Moreover, consumers of alternative news (mainly conspiracy theories) result to
be more focused on their contents, while scientific news consumers are more
prone to comment on alternative news. We conclude our analysis testing the
response of this social system to 4709 troll information -- i.e. parodistic
imitation of alternative and conspiracy theories. We find that, despite the
false and satirical vein of news, usual consumers of conspiracy news are the
most prone to interact with them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1675</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1675</id><created>2014-08-07</created><updated>2014-08-12</updated><authors><author><keyname>Cheney</keyname><forenames>James</forenames></author><author><keyname>Ahmed</keyname><forenames>Amal</forenames></author><author><keyname>Acar</keyname><forenames>Umut A.</forenames></author></authors><title>Database Queries that Explain their Work</title><categories>cs.PL cs.DB</categories><comments>PPDP 2014</comments><acm-class>D.3.0; D.3.3</acm-class><doi>10.1145/2643135.2643143</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Provenance for database queries or scientific workflows is often motivated as
providing explanation, increasing understanding of the underlying data sources
and processes used to compute the query, and reproducibility, the capability to
recompute the results on different inputs, possibly specialized to a part of
the output. Many provenance systems claim to provide such capabilities;
however, most lack formal definitions or guarantees of these properties, while
others provide formal guarantees only for relatively limited classes of
changes. Building on recent work on provenance traces and slicing for
functional programming languages, we introduce a detailed tracing model of
provenance for multiset-valued Nested Relational Calculus, define trace slicing
algorithms that extract subtraces needed to explain or recompute specific parts
of the output, and define query slicing and differencing techniques that
support explanation. We state and prove correctness properties for these
techniques and present a proof-of-concept implementation in Haskell.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1681</identifier>
 <datestamp>2015-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1681</id><created>2014-08-07</created><updated>2015-04-28</updated><authors><author><keyname>Moitra</keyname><forenames>Ankur</forenames></author></authors><title>Super-resolution, Extremal Functions and the Condition Number of
  Vandermonde Matrices</title><categories>cs.IT cs.DS math.IT math.ST stat.TH</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Super-resolution is a fundamental task in imaging, where the goal is to
extract fine-grained structure from coarse-grained measurements. Here we are
interested in a popular mathematical abstraction of this problem that has been
widely studied in the statistics, signal processing and machine learning
communities. We exactly resolve the threshold at which noisy super-resolution
is possible. In particular, we establish a sharp phase transition for the
relationship between the cutoff frequency ($m$) and the separation ($\Delta$).
If $m &gt; 1/\Delta + 1$, our estimator converges to the true values at an inverse
polynomial rate in terms of the magnitude of the noise. And when $m &lt;
(1-\epsilon) /\Delta$ no estimator can distinguish between a particular pair of
$\Delta$-separated signals even if the magnitude of the noise is exponentially
small.
  Our results involve making novel connections between {\em extremal functions}
and the spectral properties of Vandermonde matrices. We establish a sharp phase
transition for their condition number which in turn allows us to give the first
noise tolerance bounds for the matrix pencil method. Moreover we show that our
methods can be interpreted as giving preconditioners for Vandermonde matrices,
and we use this observation to design faster algorithms for super-resolution.
We believe that these ideas may have other applications in designing faster
algorithms for other basic tasks in signal processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1688</identifier>
 <datestamp>2014-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1688</id><created>2014-08-07</created><authors><author><keyname>Yang</keyname><forenames>Chao</forenames></author><author><keyname>Caih</keyname><forenames>Shengnan</forenames></author><author><keyname>Wang</keyname><forenames>Jingdong</forenames></author><author><keyname>Quan</keyname><forenames>Long</forenames></author></authors><title>Low-rank SIFT: An Affine Invariant Feature for Place Recognition</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we present a novel affine-invariant feature based on SIFT,
leveraging the regular appearance of man-made objects. The feature achieves
full affine invariance without needing to simulate over affine parameter space.
Low-rank SIFT, as we name the feature, is based on our observation that local
tilt, which are caused by changes of camera axis orientation, could be
normalized by converting local patches to standard low-rank forms. Rotation,
translation and scaling invariance could be achieved in ways similar to SIFT.
As an extension of SIFT, our method seeks to add prior to solve the ill-posed
affine parameter estimation problem and normalizes them directly, and is
applicable to objects with regular structures. Furthermore, owing to recent
breakthrough in convex optimization, such parameter could be computed
efficiently. We will demonstrate its effectiveness in place recognition as our
major application. As extra contributions, we also describe our pipeline of
constructing geotagged building database from the ground up, as well as an
efficient scheme for automatic feature selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1692</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1692</id><created>2014-08-07</created><authors><author><keyname>Chan</keyname><forenames>Hei</forenames></author><author><keyname>Darwiche</keyname><forenames>Adnan</forenames></author></authors><title>When do Numbers Really Matter?</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Seventeenth Conference on Uncertainty
  in Artificial Intelligence (UAI2001)</comments><proxy>auai</proxy><report-no>UAI-P-2001-PG-65-74</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common wisdom has it that small distinctions in the probabilities quantifying
a Bayesian network do not matter much for the resultsof probabilistic queries.
However, one can easily develop realistic scenarios under which small
variations in network probabilities can lead to significant changes in computed
queries. A pending theoretical question is then to analytically characterize
parameter changes that do or do not matter. In this paper, we study the
sensitivity of probabilistic queries to changes in network parameters and prove
some tight bounds on the impact that such parameters can have on queries. Our
analytical results pinpoint some interesting situations under which parameter
changes do or do not matter. These results are important for knowledge
engineers as they help them identify influential network parameters. They are
also important for approximate inference algorithms that preprocessnetwork CPTs
to eliminate small distinctions in probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1693</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1693</id><created>2014-08-08</created><authors><author><keyname>Hunter</keyname><forenames>Timothy</forenames></author><author><keyname>Alaoui</keyname><forenames>Ahmed El</forenames></author><author><keyname>Bayen</keyname><forenames>Alexandre</forenames></author></authors><title>Computing the log-determinant of symmetric, diagonally dominant matrices
  in near-linear time</title><categories>cs.NA cs.DS</categories><comments>Submitted to the SIAM Journal on Computing (SICOMP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new algorithms for computing the log-determinant of symmetric,
diagonally dominant matrices. Existing algorithms run with cubic complexity
with respect to the size of the matrix in the worst case. Our algorithm
computes an approximation of the log-determinant in time near-linear with
respect to the number of non-zero entries and with high probability. This
algorithm builds upon the utra-sparsifiers introduced by Spielman and Teng for
Laplacian matrices and ultimately uses their refined versions introduced by
Koutis, Miller and Peng in the context of solving linear systems. We also
present simpler algorithms that compute upper and lower bounds and that may be
of more immediate practical interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1713</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1713</id><created>2014-08-07</created><authors><author><keyname>Matienzo</keyname><forenames>Mark A.</forenames><affiliation>Digital Public Library of America</affiliation></author><author><keyname>Rudersdorf</keyname><forenames>Amy</forenames><affiliation>Digital Public Library of America</affiliation></author></authors><title>The Digital Public Library of America Ingestion Ecosystem: Lessons
  Learned After One Year of Large-Scale Collaborative Metadata Aggregation</title><categories>cs.DL</categories><comments>11 pages, 3 figures; Int'l Conf. on Dublin Core and Metadata
  Applications 2014</comments><acm-class>H.3.7</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The Digital Public Library of America (DPLA) aggregates metadata for cultural
heritage materials from 20 direct partners, or Hubs, across the United States.
While the initial build-out of the DPLA's infrastructure used a lightweight
ingestion system that was ultimately pushed into production, a year's
experience has allowed DPLA and its partners to identify limitations to that
system, the quality and scalability of metadata remediation and enhancement
possible, and areas for collaboration and leadership across the partnership.
Although improved infrastructure is needed to support aggregation at this scale
and complexity, ultimately DPLA needs to balance responsibilities across the
partnership and establish a strong community that shares ownership of the
aggregation process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1717</identifier>
 <datestamp>2014-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1717</id><created>2014-08-07</created><updated>2014-11-27</updated><authors><author><keyname>Kalofolias</keyname><forenames>Vassilis</forenames></author><author><keyname>Bresson</keyname><forenames>Xavier</forenames></author><author><keyname>Bronstein</keyname><forenames>Michael</forenames></author><author><keyname>Vandergheynst</keyname><forenames>Pierre</forenames></author></authors><title>Matrix Completion on Graphs</title><categories>cs.LG stat.ML</categories><comments>Version of NIPS 2014 workshop &quot;Out of the Box: Robustness in High
  Dimension&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of finding the missing values of a matrix given a few of its
entries, called matrix completion, has gathered a lot of attention in the
recent years. Although the problem under the standard low rank assumption is
NP-hard, Cand\`es and Recht showed that it can be exactly relaxed if the number
of observed entries is sufficiently large. In this work, we introduce a novel
matrix completion model that makes use of proximity information about rows and
columns by assuming they form communities. This assumption makes sense in
several real-world problems like in recommender systems, where there are
communities of people sharing preferences, while products form clusters that
receive similar ratings. Our main goal is thus to find a low-rank solution that
is structured by the proximities of rows and columns encoded by graphs. We
borrow ideas from manifold learning to constrain our solution to be smooth on
these graphs, in order to implicitly force row and column proximities. Our
matrix recovery model is formulated as a convex non-smooth optimization
problem, for which a well-posed iterative scheme is provided. We study and
evaluate the proposed matrix completion on synthetic and real data, showing
that the proposed structured low-rank recovery model outperforms the standard
matrix completion model in many situations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1727</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1727</id><created>2014-08-07</created><authors><author><keyname>Vladimirov</keyname><forenames>Andrey</forenames></author><author><keyname>Addison</keyname><forenames>Cliff</forenames></author></authors><title>Cluster-level tuning of a shallow water equation solver on the Intel MIC
  architecture</title><categories>cs.MS cs.CE cs.DC physics.comp-ph physics.flu-dyn</categories><comments>Colfax Research publication. 11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper demonstrates the optimization of the execution environment of a
hybrid OpenMP+MPI computational fluid dynamics code (shallow water equation
solver) on a cluster enabled with Intel Xeon Phi coprocessors. The discussion
includes: (1) Controlling the number and affinity of OpenMP threads to optimize
access to memory bandwidth; (2) Tuning the inter-operation of OpenMP and MPI to
partition the problem for better data locality; (3) Ordering the MPI ranks in a
way that directs some of the traffic into faster communication channels; (4)
Using efficient peer-to-peer communication between Xeon Phi coprocessors based
on the InfiniBand fabric.
  With tuning, the application has 90% percent efficiency of parallel scaling
up to 8 Intel Xeon Phi coprocessors in 2 compute nodes. For larger problems,
scalability is even better, because of the greater computation to communication
ratio. However, problems of that size do not fit in the memory of one
coprocessor. The performance of the solver on one Intel Xeon Phi coprocessor
7120P exceeds the performance on a dual-socket Intel Xeon E5-2697 v2 CPU by a
factor of 1.6x. In a 2-node cluster with 4 coprocessors per compute node, the
MIC architecture yields 5.8x more performance than the CPUs. Only one line of
legacy Fortran code had to be changed in order to achieve the reported
performance on the MIC architecture (not counting changes to the command-line
interface). The methodology discussed in this paper is directly applicable to
other bandwidth-bound stencil algorithms utilizing a hybrid OpenMP+MPI
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1750</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1750</id><created>2014-08-07</created><authors><author><keyname>Saffar</keyname><forenames>Hamidreza Ebrahimzadeh</forenames></author><author><keyname>Khuzani</keyname><forenames>Masoud Badiei</forenames></author><author><keyname>Mitran</keyname><forenames>Patrick</forenames></author></authors><title>Time-Asynchronous Gaussian Multiple Access Relay Channel with Correlated
  Sources</title><categories>cs.IT math.IT</categories><comments>Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the transmission of a set of correlated sources $(U_1,\cdots,U_K)$
over a Gaussian multiple access relay channel with time asynchronism between
the encoders. We assume that the maximum possible offset
${\mathsf{d_{max}}}(n)$ between the transmitters grows without bound as the
block length $n \rightarrow \infty$ while the relative ratio
${{\mathsf{d_{max}}}(n) / n}$ of the maximum possible offset to the block
length asymptotically vanishes. For such a joint source-channel coding problem,
and under specific gain conditions, we derive necessary and sufficient
conditions for reliable communications and show that separate source and
channel coding achieves optimal performance. In particular, we first derive a
general outer bound on the source entropy content for all channel gains as our
main result. Then, using Slepian-Wolf source coding combined with the channel
coding scheme introduced in \cite{Cover_McEliece:81} on top of block Markov
coding, we show that the thus achieved inner bound matches the outer bound.
Consequently, as a corollary, we also address the problem of sending a pair of
correlated sources over a two user interference channel in the same context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1754</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1754</id><created>2014-08-07</created><authors><author><keyname>Gange</keyname><forenames>Graeme</forenames></author><author><keyname>Navas</keyname><forenames>Jorge A.</forenames></author><author><keyname>Schachte</keyname><forenames>Peter</forenames></author><author><keyname>Sondergaard</keyname><forenames>Harald</forenames></author><author><keyname>Stuckey</keyname><forenames>Peter J.</forenames></author></authors><title>A Partial-Order Approach to Array Content Analysis</title><categories>cs.PL</categories><acm-class>D.2.4; D.3.1; F.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a parametric abstract domain for array content analysis. The
method maintains invariants for contiguous regions of the array, similar to the
methods of Gopan, Reps and Sagiv, and of Halbwachs and Peron. However, it
introduces a novel concept of an array content graph, avoiding the need for an
up-front factorial partitioning step. The resulting analysis can be used with
arbitrary numeric relational abstract domains; we evaluate the domain on a
range of array manipulating program fragments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1759</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1759</id><created>2014-08-08</created><authors><author><keyname>Azad</keyname><forenames>Reza</forenames></author><author><keyname>Azad</keyname><forenames>Babak</forenames></author><author><keyname>Kazerooni</keyname><forenames>Iman Tavakoli</forenames></author></authors><title>Real-Time and Robust Method for Hand Gesture Recognition System Based on
  Cross-Correlation Coefficient</title><categories>cs.CV</categories><comments>arXiv admin note: substantial text overlap with
  http://dx.doi.org/10.1109/ICCCA.2012.6179213 by other author</comments><journal-ref>Advances in Computer Science: an International Journal, Vol. 2,
  Issue 5, No.6, pp. 121-125, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hand gesture recognition possesses extensive applications in virtual reality,
sign language recognition, and computer games. The direct interface of hand
gestures provides us a new way for communicating with the virtual environment.
In this paper a novel and real-time approach for hand gesture recognition
system is presented. In the suggested method, first, the hand gesture is
extracted from the main image by the image segmentation and morphological
operation and then is sent to feature extraction stage. In feature extraction
stage the Cross-correlation coefficient is applied on the gesture to recognize
it. In the result part, the proposed approach is applied on American Sign
Language (ASL) database and the accuracy rate obtained 98.34%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1764</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1764</id><created>2014-08-08</created><authors><author><keyname>Hanly</keyname><forenames>Stephen V.</forenames></author><author><keyname>Liu</keyname><forenames>Chunshan</forenames></author><author><keyname>Whiting</keyname><forenames>Phil</forenames></author></authors><title>Capacity and Stable Scheduling in Heterogeneous Wireless Networks</title><categories>cs.NI</categories><comments>30 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous wireless networks (HetNets) provide a means to increase network
capacity by introducing small cells and adopting a layered architecture.
HetNets allocate resources flexibly through time sharing and cell range
expansion/contraction allowing a wide range of possible schedulers. In this
paper we define the capacity of a HetNet down link in terms of the maximum
number of downloads per second which can be achieved for a given offered
traffic density. Given this definition we show that the capacity is determined
via the solution to a continuous linear program (LP). If the solution is
smaller than 1 then there is a scheduler such that the number of mobiles in the
network has ergodic properties with finite mean waiting time. If the solution
is greater than 1 then no such scheduler exists. The above results continue to
hold if a more general class of schedulers is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1767</identifier>
 <datestamp>2016-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1767</id><created>2014-08-08</created><updated>2016-01-21</updated><authors><author><keyname>Esfahani</keyname><forenames>Peyman Mohajerin</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>A Tractable Fault Detection and Isolation Approach for Nonlinear Systems
  with Probabilistic Performance</title><categories>math.OC cs.SY</categories><doi>10.1109/TAC.2015.2438415</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a novel perspective along with a scalable methodology
to design a fault detection and isolation (FDI) filter for high dimensional
nonlinear systems. Previous approaches on FDI problems are either confined to
linear systems or they are only applicable to low dimensional dynamics with
specific structures. In contrast, shifting attention from the system dynamics
to the disturbance inputs, we propose a relaxed design perspective to train a
linear residual generator given some statistical information about the
disturbance patterns. That is, we propose an optimization-based approach to
robustify the filter with respect to finitely many signatures of the
nonlinearity. We then invoke recent results in randomized optimization to
provide theoretical guarantees for the performance of the proposed filer.
Finally, motivated by a cyber-physical attack emanating from the
vulnerabilities introduced by the interaction between IT infrastructure and
power system, we deploy the developed theoretical results to detect such an
intrusion before the functionality of the power system is disrupted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1770</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1770</id><created>2014-08-08</created><authors><author><keyname>Nair</keyname><forenames>T R Gopalakrishnan</forenames></author><author><keyname>Sooda</keyname><forenames>Kavitha</forenames></author><author><keyname>Selvarani</keyname><forenames>R</forenames></author></authors><title>A QoS based Routing Approach using Genetic Algorithms for Bandwidth
  Maximization in Network</title><categories>cs.NI</categories><comments>13 pages, 3 figures, 5 tables,. arXiv admin note: substantial text
  overlap with arXiv:1001.3920, arXiv:1408.1358; also substantial text overlap
  with
  http://cs-wwwarchiv.cs.unibas.ch/personen/sifalakis_manos/research/ms_setn2004.pdf
  and other sources without attribution</comments><journal-ref>International Journal of Artificial Intelligence and Soft
  Computing (IJAISC), Volume 4, Issue 1,2014, Inderscience Enterprise Ltd, pp.
  80,94</journal-ref><doi>10.1504/IJAISC.2014.059289</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the path selection problem from a known source to the
destination in dense networks. The proposed solution for route discovery uses
the genetic algorithm approach for a QoS based network. The multi point
crossover and mutation helps in determining the optimal path and alternate path
when required. The input to the genetic algorithm is a learnt module which is a
part of the cognitive router that takes care of four QoS parameters. Here the
set of nodes selected for routing is determined by delay, jitter and loss. On
this graded surface of nodes selected, the bandwidth parameter is considered
for path selection. The aim of the approach is to occupy the maximized
bandwidth along the forward channels and minimize the route length. The
population size is considered as fixed nodes participating in the network
scenario, which will be limited to a known size of topology. The simulated
results show that by using genetic algorithm (GA) approach the probability of
convergence to shortest path is higher.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1774</identifier>
 <datestamp>2014-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1774</id><created>2014-08-08</created><authors><author><keyname>Ferrer-i-Cancho</keyname><forenames>Ramon</forenames></author></authors><title>Beyond description. Comment on &quot;Approaching human language with complex
  networks&quot; by Cong &amp; Liu</title><categories>cs.CL cs.SI physics.soc-ph</categories><doi>10.1016/j.plrev.2014.07.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comment on &quot;Approaching human language with complex networks&quot; by Cong &amp; Liu
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1776</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1776</id><created>2014-08-08</created><authors><author><keyname>Klimek</keyname><forenames>Radoslaw</forenames></author><author><keyname>Kotulski</keyname><forenames>Leszek</forenames></author></authors><title>Context-awareness of the IoT through the on-the-fly preference modeling</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The context-awareness of things that belong to IoT networks have to be
considered in a distributed computation paradigm. In the paper we suggest the
use of graph transformations and temporal logic as a formal framework for a
knowledge representation of user/inhabitant behaviors in multi-agent systems.
IoT networks are considered as graph structures. Dynamic preference models,
understood as a priority in the selecting, is also introduced. Preference
models as a result of observed behaviors base on formal logic, and they are
built on-the-fly by software agents. Software agents gather knowledge about
user preferences expressed in terms of logical specifications as well as
suggest on-the-fly future behavior basing on the logical inference process
using the semantic tableaux method. The predictive processes are result of some
new and important events in the context of IoT systems that should meet a
response. Due to the ubiquitous availability of cyber systems that interact
with physical environments, there is a great need to develop technologies that
target the whole IoT system as a context-awareness system. Formal approach
increases the trustworthy of a system. A simple yet illustrative example is
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1784</identifier>
 <datestamp>2014-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1784</id><created>2014-08-08</created><authors><author><keyname>Huang</keyname><forenames>Haiping</forenames></author><author><keyname>Kabashima</keyname><forenames>Yoshiyuki</forenames></author></authors><title>Origin of the computational hardness for learning with binary synapses</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.LG q-bio.NC</categories><comments>9 pages, 1 figure</comments><journal-ref>Phys. Rev. E 90, 052813 (2014)</journal-ref><doi>10.1103/PhysRevE.90.052813</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised learning in a binary perceptron is able to classify an extensive
number of random patterns by a proper assignment of binary synaptic weights.
However, to find such assignments in practice, is quite a nontrivial task. The
relation between the weight space structure and the algorithmic hardness has
not yet been fully understood. To this end, we analytically derive the
Franz-Parisi potential for the binary preceptron problem, by starting from an
equilibrium solution of weights and exploring the weight space structure around
it. Our result reveals the geometrical organization of the weight
space\textemdash the weight space is composed of isolated solutions, rather
than clusters of exponentially many close-by solutions. The point-like clusters
far apart from each other in the weight space explain the previously observed
glassy behavior of stochastic local search heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1788</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1788</id><created>2014-08-08</created><authors><author><keyname>Andreotti</keyname><forenames>Riccardo</forenames></author><author><keyname>Marchetti</keyname><forenames>Leonardo</forenames></author><author><keyname>Sanguinetti</keyname><forenames>Luca</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Distributed power control over interference channels using ACK/NACK
  feedback</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, IEEE Global Communications Conference (GLOBECOM),
  Austin, Texas, Dec. 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider a network composed of several single-antenna
transmitter-receiver pairs in which each pair aims at selfishly minimizing the
power required to achieve a given signal-to-interference-plus-noise ratio. This
is obtained modeling the transmitter-receiver pairs as rational agents that
engage in a non-cooperative game. Capitalizing on the well-known results on the
existence and structure of the generalized Nash equilibrium (GNE) point of the
underlying game, a low complexity, iterative and distributed algorithm is
derived to let each terminal reach the GNE using only a limited feedback in the
form of link-layer acknowledgement (ACK) or negative acknowledgement (NACK).
Numerical results are used to prove that the proposed solution is able to
achieve convergence in a scalable and adaptive manner under different operating
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1789</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1789</id><created>2014-08-08</created><updated>2015-12-06</updated><authors><author><keyname>Bartal</keyname><forenames>Yair</forenames></author><author><keyname>Gottlieb</keyname><forenames>Lee-Ad</forenames></author></authors><title>Dimension reduction techniques for $\ell_p$, $1 \le p \le 2$, with
  applications</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For Euclidean space ($\ell_2$), there exists the powerful dimension reduction
transform of Johnson and Lindenstrauss, with a host of known applications.
Here, we consider the problem of dimension reduction for all $\ell_p$ spaces $1
\le p \le 2$. Although strong lower bounds are known for dimension reduction in
$\ell_1$, Ostrovsky and Rabani successfully circumvented these by presenting an
$\ell_1$ embedding that maintains fidelity in only a bounded distance range,
with applications to clustering and nearest neighbor search. However, their
embedding techniques are specific to $\ell_1$ and do not naturally extend to
other norms.
  In this paper, we apply a range of advanced techniques and produce bounded
range dimension reduction embeddings for all of $1 \le p \le 2$, thereby
demonstrating that the approach initiated by Ostrovsky and Rabani for $\ell_1$
can be extended to a much more general framework. We also obtain improved
bounds in terms of the intrinsic dimensionality. As a result we achieve
improved bounds for proximity problems including snowflake embeddings and
clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1800</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1800</id><created>2014-08-08</created><authors><author><keyname>Czap</keyname><forenames>L&#xe1;szl&#xf3;</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>Secret Communication over Broadcast Erasure Channels with State-feedback</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a 1-to-$K$ communication scenario, where a source transmits
private messages to $K$ receivers through a broadcast erasure channel, and the
receivers feed back strictly causally and publicly their channel states after
each transmission. We explore the achievable rate region when we require that
the message to each receiver remains secret - in the information theoretical
sense - from all the other receivers. We characterize the capacity of secure
communication in all the cases where the capacity of the 1-to-$K$ communication
scenario without the requirement of security is known. As a special case, we
characterize the secret-message capacity of a single receiver point-to-point
erasure channel with public state-feedback in the presence of a passive
eavesdropper.
  We find that in all cases where we have an exact characterization, we can
achieve the capacity by using linear complexity two-phase schemes: in the first
phase we create appropriate secret keys, and in the second phase we use them to
encrypt each message. We find that the amount of key we need is smaller than
the size of the message, and equal to the amount of encrypted message the
potential eavesdroppers jointly collect. Moreover, we prove that a dishonest
receiver that provides deceptive feedback cannot diminish the rate experienced
by the honest receivers.
  We also develop a converse proof which reflects the two-phase structure of
our achievability scheme. As a side result, our technique leads to a new outer
bound proof for the non-secure communication problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1816</identifier>
 <datestamp>2015-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1816</id><created>2014-08-08</created><updated>2015-08-26</updated><authors><author><keyname>Montanaro</keyname><forenames>Ashley</forenames></author></authors><title>Quantum pattern matching fast on average</title><categories>quant-ph cs.DS</categories><comments>22 pages, 2 figures; v3: further minor changes, essentially published
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $d$-dimensional pattern matching problem is to find an occurrence of a
pattern of length $m \times \dots \times m$ within a text of length $n \times
\dots \times n$, with $n \ge m$. This task models various problems in text and
image processing, among other application areas. This work describes a quantum
algorithm which solves the pattern matching problem for random patterns and
texts in time $\widetilde{O}((n/m)^{d/2} 2^{O(d^{3/2}\sqrt{\log m})})$. For
large $m$ this is super-polynomially faster than the best possible classical
algorithm, which requires time $\widetilde{\Omega}( (n/m)^d + n^{d/2} )$. The
algorithm is based on the use of a quantum subroutine for finding hidden shifts
in $d$ dimensions, which is a variant of algorithms proposed by Kuperberg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1843</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1843</id><created>2014-08-08</created><authors><author><keyname>Frittella</keyname><forenames>Sabine</forenames></author><author><keyname>Palmigiano</keyname><forenames>Alessandra</forenames></author><author><keyname>Santocanale</keyname><forenames>Luigi</forenames></author></authors><title>Dual characterizations for finite lattices via correspondence theory for
  monotone modal logic</title><categories>math.LO cs.LO</categories><msc-class>03G10, 03B45, 03B70</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a formal connection between algorithmic correspondence theory
and certain dual characterization results for finite lattices, similar to
Nation's characterization of a hierarchy of pseudovarieties of finite lattices,
progressively generalizing finite distributive lattices. This formal connection
is mediated through monotone modal logic. Indeed, we adapt the correspondence
algorithm ALBA to the setting of monotone modal logic, and we use a certain
duality-induced encoding of finite lattices as monotone neighbourhood frames to
translate lattice terms into formulas in monotone modal logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1847</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1847</id><created>2014-08-08</created><authors><author><keyname>Heinrich</keyname><forenames>Marc</forenames></author><author><keyname>Munteanu</keyname><forenames>Alexander</forenames></author><author><keyname>Sohler</keyname><forenames>Christian</forenames></author></authors><title>Asymptotically exact streaming algorithms</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new computational model for data streams: asymptotically exact
streaming algorithms. These algorithms have an approximation ratio that tends
to one as the length of the stream goes to infinity while the memory used by
the algorithm is restricted to polylog(n) size. Thus, the output of the
algorithm is optimal in the limit. We show positive results in our model for a
series of important problems that have been discussed in the streaming
literature. These include computing the frequency moments, clustering problems
and least squares regression. Our results also include lower bounds for
problems, which have streaming algorithms in the ordinary setting but do not
allow for sublinear space algorithms in our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1851</identifier>
 <datestamp>2015-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1851</id><created>2014-08-08</created><updated>2015-01-23</updated><authors><author><keyname>Antonopoulos</keyname><forenames>Timos</forenames></author><author><keyname>Hunter</keyname><forenames>Paul</forenames></author><author><keyname>Raza</keyname><forenames>Shahab</forenames></author><author><keyname>Worrell</keyname><forenames>James</forenames></author></authors><title>Three Variables Suffice for Real-Time Specification</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural framework for real-time specification is monadic first-order logic
over the structure $(\mathbb{R},&lt;,+1)$---the ordered real line with unary $+1$
function. Our main result is that $(\mathbb{R},&lt;,+1)$ has the 3-variable
property: every monadic first-order formula with at most 3 free variables is
equivalent over this structure to one that uses 3 variables in total. As a
corollary we obtain also the 3-variable property for the structure
$(\mathbb{R},&lt;,f)$ for any fixed linear function
$f:\mathbb{R}\rightarrow\mathbb{R}$. On the other hand, we exhibit a countable
dense linear order $(E,&lt;)$ and a bijection $f:E\rightarrow E$ such that
$(E,&lt;,f)$ does not have the $k$-variable property for any $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1854</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1854</id><created>2014-08-08</created><authors><author><keyname>Antignac</keyname><forenames>Thibaud</forenames><affiliation>Inria Grenoble Rh&#xf4;ne-Alpes / CITI Insa de Lyon</affiliation></author><author><keyname>M&#xe9;tayer</keyname><forenames>Daniel Le</forenames><affiliation>Inria Grenoble Rh&#xf4;ne-Alpes / CITI Insa de Lyon</affiliation></author></authors><title>Privacy Architectures: Reasoning About Data Minimisation and Integrity</title><categories>cs.CR</categories><comments>appears in STM - 10th International Workshop on Security and Trust
  Management 8743 (2014)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy by design will become a legal obligation in the European Community if
the Data Protection Regulation eventually gets adopted. However, taking into
account privacy requirements in the design of a system is a challenging task.
We propose an approach based on the specification of privacy architectures and
focus on a key aspect of privacy, data minimisation, and its tension with
integrity requirements. We illustrate our formal framework through a smart
metering case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1855</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1855</id><created>2014-08-08</created><authors><author><keyname>Techakesari</keyname><forenames>Onvaree</forenames></author><author><keyname>Nurdin</keyname><forenames>Hendra I.</forenames></author></authors><title>On the Quasi-Balanceable Class of Linear Quantum Stochastic Systems</title><categories>quant-ph cs.SY</categories><comments>12 pages. Submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns the recently proposed quasi-balanced truncation model
reduction method for linear quantum stochastic systems. It has previously been
shown that the quasi-balanceable class of systems (i.e. systems that can be
truncated via the quasi-balanced method) includes the class of completely
passive systems. In this work, we refine the previously established
characterization of quasi-balanceable systems and show that the class of
quasi-balanceable systems is strictly larger than the class of completely
passive systems. In particular, we derive a novel characterization of
completely passive linear quantum stochastic systems solely in terms of the
controllability Gramian of such systems. Exploiting this result, we prove that
all linear quantum stochastic systems with a pure Gaussian steady-state (active
systems included) are all quasi-balanceable, and establish a new complete
parameterization for this important class of systems. Examples are provided to
illustrate our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1868</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1868</id><created>2014-08-08</created><authors><author><keyname>Krivine</keyname><forenames>Jean-Louis</forenames></author></authors><title>On the structure of classical realizability models of ZF</title><categories>cs.LO math.LO</categories><comments>17 pages</comments><msc-class>03E40</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The technique of &quot;classical realizability&quot; is an extension of the method of
&quot;forcing&quot;; it permits to extend the Curry-Howard correspondence between proofs
and programs, to Zermelo-Fraenkel set theory and to build new models of ZF,
called &quot;realizability models&quot;. The structure of these models is, in general,
much more complicated than that of the particular case of &quot;forcing models&quot;. We
show here that the class of constructible sets of any realizability model is an
elementary extension of the constructibles of the ground model (a trivial fact
in the case of forcing, since these classes are identical). It follows that
Shoenfield absoluteness theorem applies to realizability models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1873</identifier>
 <datestamp>2014-09-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1873</id><created>2014-08-06</created><authors><author><keyname>Rodr&#xed;guez</keyname><forenames>Juan Duque</forenames></author><author><keyname>G&#xf3;mez-Ullate</keyname><forenames>David</forenames></author><author><keyname>Mej&#xed;a-Monasterio</keyname><forenames>Carlos</forenames></author></authors><title>Limits on the performance of Infotaxis under inaccurate modelling of the
  environment</title><categories>cs.ET cond-mat.stat-mech</categories><comments>8 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance of infotaxis search strategy measured by the rate of
success and mean search time, under changes in the environment parameters such
as diffusivity, rate of emission or wind velocity. We also investigate the drop
of performance caused by an innacurate modelling of the environment. Our
findings show that infotaxis remains robust as long as the estimated parameters
fall within a certain range around their true values, but the success rate
quickly drops making infotaxis no longer feasible if the searcher agent
severely underestimates or overestimates the real environment parameters. This
study places some limits on the performance of infotaxis, and thus it has
practical consequences for the design of infotaxis based machines to track and
detect an emitting source of chemicals or volatile substances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1900</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1900</id><created>2014-08-07</created><authors><author><keyname>Yesil</keyname><forenames>Ayse Ferhan</forenames></author><author><keyname>Yalabik</keyname><forenames>M. Cemal</forenames></author></authors><title>A Report of a Significant Error On a Frequently Used Pseudo Random
  Number Generator</title><categories>cs.MS cond-mat.stat-mech cs.CE</categories><comments>9 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emergence of stochastic simulations as an extensively used computational tool
for scientific purposes intensified the need for more accurate ways of
generating sufficiently long sequences of uncorrelated random numbers. Even
though several different methods have been proposed for this end, deterministic
algorithms known as pseudo-random number generators (PRNGs) emerged to be the
most widely used tool as a replicable, portable and easy to use method to
generate such random number sequences. Here, we introduce a simple Poisson
process whose simulation gives systematic errors when the very commonly used
random number generator of the GNU C Library (Glibc) is utilised. The PRNG of
Glibc is an additive lagged Fibonacci generator, the family of such PRNGs are
accepted as relatively safe among other PRNGs. The systematic errors indicate
complex correlation relations among random numbers which requires a further
explanation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1906</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1906</id><created>2014-08-08</created><authors><author><keyname>Olson</keyname><forenames>Randal S.</forenames></author><author><keyname>Haley</keyname><forenames>Patrick B.</forenames></author><author><keyname>Dyer</keyname><forenames>Fred C.</forenames></author><author><keyname>Adami</keyname><forenames>Christoph</forenames></author></authors><title>Exploring the evolution of a trade-off between vigilance and foraging in
  group-living organisms</title><categories>q-bio.PE cs.GT cs.NE</categories><comments>26 pages (double-spaced, single column), 6 figures, 2 SI figures</comments><journal-ref>Royal Society open science 2 (2015) 150135</journal-ref><doi>10.1098/rsos.150135</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the fact that grouping behavior has been actively studied for over a
century, the relative importance of the numerous proposed fitness benefits of
grouping remain unclear. We use a digital model of evolving prey under
simulated predation to directly explore the evolution of gregarious foraging
behavior according to one such benefit, the &quot;many eyes&quot; hypothesis. According
to this hypothesis, collective vigilance allows prey in large groups to detect
predators more efficiently by making alarm signals or behavioral cues to each
other, thereby allowing individuals within the group to spend more time
foraging. Here, we find that collective vigilance is sufficient to select for
gregarious foraging behavior as long there is not a direct cost for grouping
(e.g., competition for limited food resources), even when controlling for
confounding factors such as the dilution effect. Further, we explore the role
of the genetic relatedness and reproductive strategy of the prey, and find that
highly related groups of prey with a semelparous reproductive strategy are the
most likely to evolve gregarious foraging behavior mediated by the benefit of
vigilance. These findings, combined with earlier studies with evolving digital
organisms, further sharpen our understanding of the factors favoring grouping
behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1913</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1913</id><created>2014-08-08</created><authors><author><keyname>Parker</keyname><forenames>Adam S. R.</forenames></author><author><keyname>Edwards</keyname><forenames>Ann L.</forenames></author><author><keyname>Pilarski</keyname><forenames>Patrick M.</forenames></author></authors><title>Using Learned Predictions as Feedback to Improve Control and
  Communication with an Artificial Limb: Preliminary Findings</title><categories>cs.AI cs.HC cs.LG cs.RO</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many people suffer from the loss of a limb. Learning to get by without an arm
or hand can be very challenging, and existing prostheses do not yet fulfil the
needs of individuals with amputations. One promising solution is to provide
greater communication between a prosthesis and its user. Towards this end, we
present a simple machine learning interface to supplement the control of a
robotic limb with feedback to the user about what the limb will be experiencing
in the near future. A real-time prediction learner was implemented to predict
impact-related electrical load experienced by a robot limb; the learning
system's predictions were then communicated to the device's user to aid in
their interactions with a workspace. We tested this system with five
able-bodied subjects. Each subject manipulated the robot arm while receiving
different forms of vibrotactile feedback regarding the arm's contact with its
workspace. Our trials showed that communicable predictions could be learned
quickly during human control of the robot arm. Using these predictions as a
basis for feedback led to a statistically significant improvement in task
performance when compared to purely reactive feedback from the device. Our
study therefore contributes initial evidence that prediction learning and
machine intelligence can benefit not just control, but also feedback from an
artificial limb. We expect that a greater level of acceptance and ownership can
be achieved if the prosthesis itself takes an active role in transmitting
learned knowledge about its state and its situation of use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1928</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1928</id><created>2014-08-08</created><authors><author><keyname>Good</keyname><forenames>Benjamin M</forenames></author><author><keyname>Nanis</keyname><forenames>Max</forenames></author><author><keyname>Su</keyname><forenames>Andrew I.</forenames></author></authors><title>Microtask crowdsourcing for disease mention annotation in PubMed
  abstracts</title><categories>cs.CL</categories><comments>Preprint of an article submitted for consideration in the Pacific
  Symposium on Biocomputing copyright 2015; World Scientific Publishing Co.,
  Singapore, 2015; http://psb.stanford.edu/. Data produced for this analysis
  are available at
  http://figshare.com/articles/Disease_Mention_Annotation_with_Mechanical_Turk/1126402</comments><msc-class>9208</msc-class><acm-class>H.5.3; I.2.7</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Identifying concepts and relationships in biomedical text enables knowledge
to be applied in computational analyses. Many biological natural language
process (BioNLP) projects attempt to address this challenge, but the state of
the art in BioNLP still leaves much room for improvement. Progress in BioNLP
research depends on large, annotated corpora for evaluating information
extraction systems and training machine learning models. Traditionally, such
corpora are created by small numbers of expert annotators often working over
extended periods of time. Recent studies have shown that workers on microtask
crowdsourcing platforms such as Amazon's Mechanical Turk (AMT) can, in
aggregate, generate high-quality annotations of biomedical text. Here, we
investigated the use of the AMT in capturing disease mentions in PubMed
abstracts. We used the NCBI Disease corpus as a gold standard for refining and
benchmarking our crowdsourcing protocol. After several iterations, we arrived
at a protocol that reproduced the annotations of the 593 documents in the
training set of this gold standard with an overall F measure of 0.872
(precision 0.862, recall 0.883). The output can also be tuned to optimize for
precision (max = 0.984 when recall = 0.269) or recall (max = 0.980 when
precision = 0.436). Each document was examined by 15 workers, and their
annotations were merged based on a simple voting method. In total 145 workers
combined to complete all 593 documents in the span of 1 week at a cost of $.06
per abstract per worker. The quality of the annotations, as judged with the F
measure, increases with the number of workers assigned to each task such that
the system can be tuned to balance cost against quality. These results
demonstrate that microtask crowdsourcing can be a valuable tool for generating
well-annotated corpora in BioNLP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1935</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1935</id><created>2014-08-08</created><authors><author><keyname>Shafiei</keyname><forenames>Niloufar</forenames></author></authors><title>Non-Blocking Doubly-Linked Lists with Good Amortized Complexity</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new non-blocking doubly-linked list implementation for an
asynchronous shared-memory system. It is the first such implementation for
which an upper bound on amortized time complexity has been proved. In our
implementation, operations access the list via cursors. Each cursor is
associated with an item in the list and is local to a process. The
implementation supports two update operations, insertBefore and delete, and two
move operations, moveRight and moveLeft. An insertBefore(c, x) operation
inserts an item x into the list immediately before the cursor c's location. A
delete(c) operation removes the item at the cursor c's location and sets the
cursor to the next item in the list. The move operations move the cursor one
position to the right or left. The update operations use single-word
Compare&amp;Swap instructions. The move operations only read shared memory and
never change the state of the data structure. If all update operations modify
different parts of the list, they run completely concurrently. Let cp(op) be
the maximum number of active cursors at any one time during the operation op.
The amortized complexity of each update operation op is O(cp(op)) and each move
operation is O(1). We have written a detailed correctness proof and amortized
analysis of our implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1938</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1938</id><created>2014-08-08</created><authors><author><keyname>Mayr</keyname><forenames>C.</forenames></author><author><keyname>Sch&#xfc;ffny</keyname><forenames>R.</forenames></author></authors><title>Applying Spiking Neural Nets to Noise Shaping</title><categories>cs.ET</categories><journal-ref>IEICE Transactions on Information and Systems, vol. E88-D, no. 8,
  pages 1885-1892, 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  -In recent years, there has been an increased focus on the mechanics of
information transmission in spiking neural networks. Especially the Noise
Shaping properties of these networks and their similarity to Delta-Sigma
Modulators has received a lot of attention. However, very little of the
research done in this area has focused on the effect the weights in these
networks have on the Noise Shaping properties and on post- processing of the
network output signal. This paper concerns itself with the various modes of
network operation and beneficial as well as detrimental effects which the
systematic generation of network weights can effect. Also, a method for
post-processing of the spiking output signal is introduced, bringing the output
signal more in line with conventional Delta-Sigma Modulators. Relevancy of this
research to industrial application of neural nets as building blocks of
oversampled A/D converters is shown. Also, further points of contention are
listed, which must be thoroughly researched to add to the above mentioned
applicability of spiking neural nets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1945</identifier>
 <datestamp>2014-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1945</id><created>2014-08-08</created><authors><author><keyname>Chen</keyname><forenames>Xiaojie</forenames></author><author><keyname>Szolnoki</keyname><forenames>Attila</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Probabilistic sharing solves the problem of costly punishment</title><categories>physics.soc-ph cs.GT q-bio.PE</categories><comments>15 pages, 5 figures; accepted for publication in New Journal of
  Physics</comments><journal-ref>New J. Phys. 16 (2014) 083016</journal-ref><doi>10.1088/1367-2630/16/8/083016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperators that refuse to participate in sanctioning defectors create the
second-order free-rider problem. Such cooperators will not be punished because
they contribute to the public good, but they also eschew the costs associated
with punishing defectors. Altruistic punishers - those that cooperate and
punish - are at a disadvantage, and it is puzzling how such behaviour has
evolved. We show that sharing the responsibility to sanction defectors rather
than relying on certain individuals to do so permanently can solve the problem
of costly punishment. Inspired by the fact that humans have strong but also
emotional tendencies for fair play, we consider probabilistic sanctioning as
the simplest way of distributing the duty. In well-mixed populations the public
goods game is transformed into a coordination game with full cooperation and
defection as the two stable equilibria, while in structured populations pattern
formation supports additional counterintuitive solutions that are reminiscent
of Parrondo's paradox.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1964</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1964</id><created>2014-08-08</created><authors><author><keyname>Bonamy</keyname><forenames>Marthe</forenames></author><author><keyname>Bousquet</keyname><forenames>Nicolas</forenames></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>The Erd\H{o}s-Hajnal Conjecture for Long Holes and Anti-holes</title><categories>cs.DM math.CO</categories><comments>6 pages, submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Erd\H{o}s and Hajnal conjectured that, for every graph $H$, there exists a
constant $c_H$ such that every graph $G$ on $n$ vertices which does not contain
any induced copy of $H$ has a clique or a stable set of size $n^{c_H}$. We
prove that for every $k$, there exists $c_k&gt;0$ such that every graph $G$ on $n$
vertices not inducing a cycle of length at least $k$ nor its complement
contains a clique or a stable set of size $n^{c_k}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1980</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1980</id><created>2014-08-08</created><updated>2015-07-24</updated><authors><author><keyname>Platzer</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Differential Game Logic</title><categories>cs.LO math.LO</categories><report-no>CMU-CS-13-100R</report-no><msc-class>03F03, 03B70, 34A38, 91A25</msc-class><acm-class>F.3.1, F.4.1</acm-class><journal-ref>ACM Transactions on Computational Logic 17(1), pages 1:1-1:52,
  2015</journal-ref><doi>10.1145/2817824</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential game logic (dGL) is a logic for specifying and verifying
properties of hybrid games, i.e. games that combine discrete, continuous, and
adversarial dynamics. Unlike hybrid systems, hybrid games allow choices in the
system dynamics to be resolved adversarially by different players with
different objectives. The logic dGL can be used to study the existence of
winning strategies for such hybrid games, i.e. ways of resolving the player's
choices in some way so that he wins by achieving his objective for all choices
of the opponent. Hybrid games are determined, i.e. from each state, one player
has a winning strategy, yet computing their winning regions may take
transfinitely many steps. The logic dGL, nevertheless, has a sound and complete
axiomatization relative to any expressive logic. Separating axioms are
identified that distinguish hybrid games from hybrid systems. Finally, dGL is
proved to be strictly more expressive than the corresponding logic of hybrid
systems by characterizing the expressiveness of both.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1984</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1984</id><created>2014-08-08</created><authors><author><keyname>Mayr</keyname><forenames>C.</forenames></author><author><keyname>Sch&#xfc;ffny</keyname><forenames>R.</forenames></author></authors><title>Neighborhood Rank Order Coding for Robust Texture Analysis and Feature
  Extraction</title><categories>cs.CV</categories><journal-ref>Proc. 7th International Conference on Hybrid Intelligent Systems
  HIS 07, pages 290-295, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research into the visual cortex and general neural information processing has
led to various attempts to integrate pulse computation schemes in image
analysis systems. Of interest is especially the robustness of representing an
analogue signal in the phase or duration of a pulsed, quasi-digital signal, as
well as the possibility of direct digital interaction, i.e. computation, among
these signals. Such a computation can also achieve information compaction for
subsequent processing stages. By using a pulse order encoding scheme motivated
by dendritic pulse interaction, we will show that a powerful low-level feature
and texture extraction operator, called Pulsed Local Orientation Coding (PLOC),
can be implemented. Feature extraction results are being presented, and a
possible VLSI implementation is detailed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1985</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1985</id><created>2014-08-08</created><authors><author><keyname>Pierrehumbert</keyname><forenames>Janet B.</forenames></author><author><keyname>Stonedahl</keyname><forenames>Forrest</forenames></author><author><keyname>Daland</keyname><forenames>Robert</forenames></author></authors><title>A model of grassroots changes in linguistic systems</title><categories>cs.CL nlin.AO physics.soc-ph</categories><comments>30 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linguistic norms emerge in human communities because people imitate each
other. A shared linguistic system provides people with the benefits of shared
knowledge and coordinated planning. Once norms are in place, why would they
ever change? This question, echoing broad questions in the theory of social
dynamics, has particular force in relation to language. By definition, an
innovator is in the minority when the innovation first occurs. In some areas of
social dynamics, important minorities can strongly influence the majority
through their power, fame, or use of broadcast media. But most linguistic
changes are grassroots developments that originate with ordinary people. Here,
we develop a novel model of communicative behavior in communities, and identify
a mechanism for arbitrary innovations by ordinary people to have a good chance
of being widely adopted.
  To imitate each other, people must form a mental representation of what other
people do. Each time they speak, they must also decide which form to produce
themselves. We introduce a new decision function that enables us to smoothly
explore the space between two types of behavior: probability matching (matching
the probabilities of incoming experience) and regularization (producing some
forms disproportionately often). Using Monte Carlo methods, we explore the
interactions amongst the degree of regularization, the distribution of biases
in a network, and the network position of the innovator. We identify two
regimes for the widespread adoption of arbritrary innovations, viewed as
informational cascades in the network. With moderate regularization of
experienced input, average people (not well-connected people) are the most
likely source of successful innovations. Our results shed light on a major
outstanding puzzle in the theory of language change. The framework also holds
promise for understanding the dynamics of other social norms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1986</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1986</id><created>2014-08-08</created><authors><author><keyname>Mayr</keyname><forenames>C.</forenames></author><author><keyname>Heittmann</keyname><forenames>A.</forenames></author><author><keyname>Sch&#xfc;ffny</keyname><forenames>R.</forenames></author></authors><title>Gabor-like Image Filtering using a Neural Microcircuit</title><categories>cs.CV cs.ET q-bio.NC</categories><journal-ref>IEEE Transactions on Neural Networks, vol. 18, pages 955-959, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we present an implementation of a neural microcircuit for
image processing employing Hebbian-adaptive learning. The neuronal circuit
utilizes only excitatory synapses to correlate action potentials, extracting
the uncorrelated ones, which contain significant image information. This
circuit is capable of approximating Gabor-like image filtering and other image
processing functions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1987</identifier>
 <datestamp>2015-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1987</id><created>2014-08-08</created><updated>2015-01-28</updated><authors><author><keyname>Xing</keyname><forenames>Hong</forenames></author><author><keyname>Liu</keyname><forenames>Liang</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Secrecy Wireless Information and Power Transfer in Fading Wiretap
  Channel</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Vehicular Technology</comments><doi>10.1109/TVT.2015.2395725</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simultaneous wireless information and power transfer (SWIPT) has recently
drawn significant interests for its dual use of radio signals to provide
wireless data and energy access at the same time. However, a challenging
secrecy communication issue arises as the messages sent to the information
receivers (IRs) may be eavesdropped by the energy receivers (ERs), which are
presumed to harvest energy only from the received signals. To tackle this
problem, we propose in this paper an artificial noise (AN) aided transmission
scheme to facilitate the secrecy information transmission to IRs and yet meet
the energy harvesting requirement for ERs, under the assumption that the AN can
be cancelled at IRs but not at ERs. Specifically, the proposed scheme splits
the transmit power into two parts, to send the confidential message to the IR
and an AN to interfere with the ER, respectively. Under a simplified three-node
wiretap channel setup, the transmit power allocations and power splitting
ratios over fading channels are jointly optimized to minimize the outage
probability for delay-limited secrecy information transmission, or to maximize
the average rate for no-delay-limited secrecy information transmission, subject
to a combination of average and peak power constraints at the transmitter as
well as an average energy harvesting constraint at the ER. Both the secrecy
outage probability minimization and average rate maximization problems are
shown to be non-convex, for each of which we propose the optimal solution based
on the dual decomposition as well as suboptimal solution based on the
alternating optimization. Furthermore, two benchmark schemes are introduced for
comparison. Finally, the performances of proposed schemes are evaluated by
simulations in terms of various trade-offs for wireless (secrecy) information
versus energy transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1993</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1993</id><created>2014-08-08</created><authors><author><keyname>Xu</keyname><forenames>Li</forenames></author><author><keyname>Zhan</keyname><forenames>Zhenxin</forenames></author><author><keyname>Xu</keyname><forenames>Shouhuai</forenames></author><author><keyname>Ye</keyname><forenames>Keyin</forenames></author></authors><title>An Evasion and Counter-Evasion Study in Malicious Websites Detection</title><categories>cs.CR cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Malicious websites are a major cyber attack vector, and effective detection
of them is an important cyber defense task. The main defense paradigm in this
regard is that the defender uses some kind of machine learning algorithms to
train a detection model, which is then used to classify websites in question.
Unlike other settings, the following issue is inherent to the problem of
malicious websites detection: the attacker essentially has access to the same
data that the defender uses to train its detection models. This 'symmetry' can
be exploited by the attacker, at least in principle, to evade the defender's
detection models. In this paper, we present a framework for characterizing the
evasion and counter-evasion interactions between the attacker and the defender,
where the attacker attempts to evade the defender's detection models by taking
advantage of this symmetry. Within this framework, we show that an adaptive
attacker can make malicious websites evade powerful detection models, but
proactive training can be an effective counter-evasion defense mechanism. The
framework is geared toward the popular detection model of decision tree, but
can be adapted to accommodate other classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.1995</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.1995</id><created>2014-08-08</created><authors><author><keyname>Volkovich</keyname><forenames>Ilya</forenames></author></authors><title>Characterizing Arithmetic Read-Once Formulae</title><categories>cs.DM</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An \emph{arithmetic read-once formula} (ROF for short) is a formula (i.e. a
tree of computation) in which the operations are $\{+,\times\}$ and such that
every input variable labels at most one leaf. We give a simple characterization
of such formulae. Other than being interesting in its own right, our
characterization gives rise to a property testing algorithm for functions
computable by such formulae. To the best of our knowledge, prior to our work no
characterization and/or property testing algorithm was known for this kind of
formulae.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2003</identifier>
 <datestamp>2014-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2003</id><created>2014-08-08</created><updated>2014-08-26</updated><authors><author><keyname>Han</keyname><forenames>Bo</forenames></author><author><keyname>He</keyname><forenames>Bo</forenames></author><author><keyname>Nian</keyname><forenames>Rui</forenames></author><author><keyname>Ma</keyname><forenames>Mengmeng</forenames></author><author><keyname>Zhang</keyname><forenames>Shujing</forenames></author><author><keyname>Li</keyname><forenames>Minghui</forenames></author><author><keyname>Lendasse</keyname><forenames>Amaury</forenames></author></authors><title>LARSEN-ELM: Selective Ensemble of Extreme Learning Machines using LARS
  for Blended Data</title><categories>cs.LG stat.ML</categories><comments>Accepted for publication in Neurocomputing, 01/19/2014</comments><journal-ref>Neurocomputing, 2014, Elsevier. Manuscript ID: NEUCOM-D-13-01029</journal-ref><doi>10.1016/j.neucom.2014.01.069</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extreme learning machine (ELM) as a neural network algorithm has shown its
good performance, such as fast speed, simple structure etc, but also, weak
robustness is an unavoidable defect in original ELM for blended data. We
present a new machine learning framework called LARSEN-ELM for overcoming this
problem. In our paper, we would like to show two key steps in LARSEN-ELM. In
the first step, preprocessing, we select the input variables highly related to
the output using least angle regression (LARS). In the second step, training,
we employ Genetic Algorithm (GA) based selective ensemble and original ELM. In
the experiments, we apply a sum of two sines and four datasets from UCI
repository to verify the robustness of our approach. The experimental results
show that compared with original ELM and other methods such as OP-ELM,
GASEN-ELM and LSBoost, LARSEN-ELM significantly improve robustness performance
while keeping a relatively high speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2004</identifier>
 <datestamp>2014-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2004</id><created>2014-08-08</created><updated>2014-09-23</updated><authors><author><keyname>Han</keyname><forenames>Bo</forenames></author><author><keyname>He</keyname><forenames>Bo</forenames></author><author><keyname>Ma</keyname><forenames>Mengmeng</forenames></author><author><keyname>Sun</keyname><forenames>Tingting</forenames></author><author><keyname>Yan</keyname><forenames>Tianhong</forenames></author><author><keyname>Lendasse</keyname><forenames>Amaury</forenames></author></authors><title>RMSE-ELM: Recursive Model based Selective Ensemble of Extreme Learning
  Machines for Robustness Improvement</title><categories>cs.LG cs.NE</categories><comments>Accepted for publication in Mathematical Problems in Engineering,
  09/22/2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Extreme learning machine (ELM) as an emerging branch of shallow networks has
shown its excellent generalization and fast learning speed. However, for
blended data, the robustness of ELM is weak because its weights and biases of
hidden nodes are set randomly. Moreover, the noisy data exert a negative
effect. To solve this problem, a new framework called RMSE-ELM is proposed in
this paper. It is a two-layer recursive model. In the first layer, the
framework trains lots of ELMs in different groups concurrently, then employs
selective ensemble to pick out an optimal set of ELMs in each group, which can
be merged into a large group of ELMs called candidate pool. In the second
layer, selective ensemble is recursively used on candidate pool to acquire the
final ensemble. In the experiments, we apply UCI blended datasets to confirm
the robustness of our new approach in two key aspects (mean square error and
standard deviation). The space complexity of our method is increased to some
degree, but the results have shown that RMSE-ELM significantly improves
robustness with slightly computational time compared with representative
methods (ELM, OP-ELM, GASEN-ELM, GASEN-BP and E-GASEN). It becomes a potential
framework to solve robustness issue of ELM for high-dimensional blended data in
the future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2005</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2005</id><created>2014-08-08</created><authors><author><keyname>Zhang</keyname><forenames>Yizhen</forenames></author><author><keyname>Tan</keyname><forenames>Zihan</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author></authors><title>On the Meeting Time for Two Random Walks on a Regular Graph</title><categories>math.PR cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an analysis of the expected meeting time of two independent random
walks on a regular graph. For 1-D circle and 2-D torus graphs, we show that the
expected meeting time can be expressed as the sum of the inverse of non-zero
eigenvalues of a suitably defined Laplacian matrix. We also conjecture based on
empirical evidence that this result holds more generally for simple random
walks on arbitrary regular graphs. Further, we show that the expected meeting
time for the 1-D circle of size $N$ is $\Theta(N^2)$, and for a 2-D $N \times
N$ torus it is $\Theta(N^2 log N)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2015</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2015</id><created>2014-08-08</created><authors><author><keyname>Elboushaki</keyname><forenames>Abdessamad</forenames></author><author><keyname>Hannane</keyname><forenames>Rachida</forenames></author><author><keyname>Nagabhushan</keyname><forenames>P.</forenames></author><author><keyname>Javed</keyname><forenames>Mohammed</forenames></author></authors><title>Automatic Removal of Marginal Annotations in Printed Text Document</title><categories>cs.CV</categories><comments>Original Article Published by Elsevier at ERCICA-2014, Pages 123-131,
  August 2014</comments><journal-ref>Proceedings of Second International Conference on Emerging
  Research in Computing, Information,Communication and Applications
  (ERCICA-14), pages 123-131, August 2014, Bangalore</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering the original printed texts from a document with added handwritten
annotations in the marginal area is one of the challenging problems, especially
when the original document is not available. Therefore, this paper aims at
salvaging automatically the original document from the annotated document by
detecting and removing any handwritten annotations that appear in the marginal
area of the document without any loss of information. Here a two stage
algorithm is proposed, where in the first stage due to approximate marginal
boundary detection with horizontal and vertical projection profiles, all of the
marginal annotations along with some part of the original printed text that may
appear very close to the marginal boundary are removed. Therefore as a second
stage, using the connected components, a strategy is applied to bring back the
printed text components cropped during the first stage. The proposed method is
validated using a dataset of 50 documents having complex handwritten
annotations, which gives an overall accuracy of 89.01% in removing the marginal
annotations and 97.74% in case of retrieving the original printed text
document.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2023</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2023</id><created>2014-08-09</created><authors><author><keyname>Adeogun</keyname><forenames>Ramoni</forenames></author></authors><title>Capacity and Error Rate Analysis of MIMO Satellite Communication Systems
  in Fading Scenarios</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigated the capacity and bit error rate (BER)
performance of Multiple Input Multiple Output (MIMO) satellite systems with
single and multiple dual polarized satellites in geostationary orbit and a
mobile ground receiving station with multiple antennas. We evaluated the
effects of both system parameters such as number of satellites, number of
receive antennas, and SNR and environmental factors including atmospheric
signal attenuations and signal phase disturbances on the overall system
performance using both analytical and spatial models for MIMO satellite
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2025</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2025</id><created>2014-08-09</created><authors><author><keyname>Shalizi</keyname><forenames>Cosma</forenames></author><author><keyname>Klinkner</keyname><forenames>Kristina Lisa</forenames></author></authors><title>Blind Construction of Optimal Nonlinear Recursive Predictors for
  Discrete Sequences</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-504-511</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new method for nonlinear prediction of discrete random sequences
under minimal structural assumptions. We give a mathematical construction for
optimal predictors of such processes, in the form of hidden Markov models. We
then describe an algorithm, CSSR (Causal-State Splitting Reconstruction), which
approximates the ideal predictor from data. We discuss the reliability of CSSR,
its data requirements, and its performance in simulations. Finally, we compare
our approach to existing methods using variablelength Markov models and
cross-validated hidden Markov models, and show theoretically and experimentally
that our method delivers results superior to the former and at least comparable
to the latter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2027</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2027</id><created>2014-08-09</created><authors><author><keyname>Karabaev</keyname><forenames>Eldar</forenames></author><author><keyname>Skvortsova</keyname><forenames>Olga</forenames></author></authors><title>A Heuristic Search Algorithm for Solving First-Order MDPs</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-First Conference on Uncertainty
  in Artificial Intelligence (UAI2005)</comments><proxy>auai</proxy><report-no>UAI-P-2005-PG-292-299</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a heuristic search algorithm for solving first-order MDPs
(FOMDPs). Our approach combines first-order state abstraction that avoids
evaluating states individually, and heuristic search that avoids evaluating all
states. Firstly, we apply state abstraction directly on the FOMDP avoiding
propositionalization. Such kind of abstraction is referred to as firstorder
state abstraction. Secondly, guided by an admissible heuristic, the search is
restricted only to those states that are reachable from the initial state. We
demonstrate the usefullness of the above techniques for solving FOMDPs on a
system, referred to as FCPlanner, that entered the probabilistic track of the
International Planning Competition (IPC'2004).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2028</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2028</id><created>2014-08-09</created><authors><author><keyname>Coquelin</keyname><forenames>Pierre-Arnuad</forenames></author><author><keyname>Munos</keyname><forenames>Remi</forenames></author></authors><title>Bandit Algorithms for Tree Search</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Third Conference on Uncertainty
  in Artificial Intelligence (UAI2007)</comments><proxy>auai</proxy><report-no>UAI-P-2007-PG-67-74</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bandit based methods for tree search have recently gained popularity when
applied to huge trees, e.g. in the game of go [6]. Their efficient exploration
of the tree enables to re- turn rapidly a good value, and improve preci- sion
if more time is provided. The UCT algo- rithm [8], a tree search method based
on Up- per Confidence Bounds (UCB) [2], is believed to adapt locally to the
effective smoothness of the tree. However, we show that UCT is
&quot;over-optimistic&quot; in some sense, leading to a worst-case regret that may be
very poor. We propose alternative bandit algorithms for tree search. First, a
modification of UCT us- ing a confidence sequence that scales expo- nentially
in the horizon depth is analyzed. We then consider Flat-UCB performed on the
leaves and provide a finite regret bound with high probability. Then, we
introduce and analyze a Bandit Algorithm for Smooth Trees (BAST) which takes
into account ac- tual smoothness of the rewards for perform- ing efficient
&quot;cuts&quot; of sub-optimal branches with high confidence. Finally, we present an
incremental tree expansion which applies when the full tree is too big
(possibly in- finite) to be entirely represented and show that with high
probability, only the optimal branches are indefinitely developed. We illus-
trate these methods on a global optimization problem of a continuous function,
given noisy values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2029</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2029</id><created>2014-08-09</created><authors><author><keyname>de Cooman</keyname><forenames>Gert</forenames></author><author><keyname>Hermans</keyname><forenames>Filip</forenames></author><author><keyname>Quaeghebeur</keyname><forenames>Erik</forenames></author></authors><title>Sensitivity analysis for finite Markov chains in discrete time</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence (UAI2008)</comments><proxy>auai</proxy><report-no>UAI-P-2008-PG-129-136</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When the initial and transition probabilities of a finite Markov chain in
discrete time are not well known, we should perform a sensitivity analysis.
This is done by considering as basic uncertainty models the so-called credal
sets that these probabilities are known or believed to belong to, and by
allowing the probabilities to vary over such sets. This leads to the definition
of an imprecise Markov chain. We show that the time evolution of such a system
can be studied very efficiently using so-called lower and upper expectations.
We also study how the inferred credal set about the state at time n evolves as
n-&gt;infinity: under quite unrestrictive conditions, it converges to a uniquely
invariant credal set, regardless of the credal set given for the initial state.
This leads to a non-trivial generalisation of the classical Perron-Frobenius
Theorem to imprecise Markov chains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2030</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2030</id><created>2014-08-09</created><authors><author><keyname>Niepert</keyname><forenames>Mathias</forenames></author><author><keyname>Van Gucht</keyname><forenames>Dirk</forenames></author><author><keyname>Gyssens</keyname><forenames>Marc</forenames></author></authors><title>On the Conditional Independence Implication Problem: A Lattice-Theoretic
  Approach</title><categories>cs.AI cs.LO</categories><comments>Appears in Proceedings of the Twenty-Fourth Conference on Uncertainty
  in Artificial Intelligence (UAI2008)</comments><proxy>auai</proxy><report-no>UAI-P-2008-PG-435-443</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lattice-theoretic framework is introduced that permits the study of the
conditional independence (CI) implication problem relative to the class of
discrete probability measures. Semi-lattices are associated with CI statements
and a finite, sound and complete inference system relative to semi-lattice
inclusions is presented. This system is shown to be (1) sound and complete for
saturated CI statements, (2) complete for general CI statements, and (3) sound
and complete for stable CI statements. These results yield a criterion that can
be used to falsify instances of the implication problem and several heuristics
are derived that approximate this &quot;lattice-exclusion&quot; criterion in polynomial
time. Finally, we provide experimental results that relate our work to results
obtained from other existing inference algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2031</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2031</id><created>2014-08-09</created><authors><author><keyname>Beygelzimer</keyname><forenames>Alina</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Lifshits</keyname><forenames>Yuri</forenames></author><author><keyname>Sorkin</keyname><forenames>Gregory</forenames></author><author><keyname>Strehl</keyname><forenames>Alexander L.</forenames></author></authors><title>Conditional Probability Tree Estimation Analysis and Algorithms</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</comments><proxy>auai</proxy><report-no>UAI-P-2009-PG-51-58</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of estimating the conditional probability of a label
in time O(log n), where n is the number of possible labels. We analyze a
natural reduction of this problem to a set of binary regression problems
organized in a tree structure, proving a regret bound that scales with the
depth of the tree. Motivated by this analysis, we propose the first online
algorithm which provably constructs a logarithmic depth tree on the set of
labels to solve this problem. We test the algorithm empirically, showing that
it works succesfully on a dataset with roughly 106 labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2032</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2032</id><created>2014-08-09</created><authors><author><keyname>Daume</keyname><forenames>Hal</forenames><suffix>III</suffix></author></authors><title>Bayesian Multitask Learning with Latent Hierarchies</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</comments><proxy>auai</proxy><report-no>UAI-P-2009-PG-135-142</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We learn multiple hypotheses for related tasks under a latent hierarchical
relationship between tasks. We exploit the intuition that for domain
adaptation, we wish to share classifier structure, but for multitask learning,
we wish to share covariance structure. Our hierarchical model is seen to
subsume several previously proposed multitask learning models and performs well
on three distinct real-world data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2033</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2033</id><created>2014-08-09</created><authors><author><keyname>Finegold</keyname><forenames>Michael A.</forenames></author><author><keyname>Drton</keyname><forenames>Mathias</forenames></author></authors><title>Robust Graphical Modeling with t-Distributions</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</comments><proxy>auai</proxy><report-no>UAI-P-2009-PG-169-176</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical Gaussian models have proven to be useful tools for exploring
network structures based on multivariate data. Applications to studies of gene
expression have generated substantial interest in these models, and resulting
recent progress includes the development of fitting methodology involving
penalization of the likelihood function. In this paper we advocate the use of
the multivariate t and related distributions for more robust inference of
graphs. In particular, we demonstrate that penalized likelihood inference
combined with an application of the EM algorithm provides a simple and
computationally efficient approach to model selection in the t-distribution
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2034</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2034</id><created>2014-08-09</created><authors><author><keyname>Gomez</keyname><forenames>Vicenc</forenames></author><author><keyname>Kappen</keyname><forenames>Hilbert</forenames></author><author><keyname>Chertkov</keyname><forenames>Michael</forenames></author></authors><title>Approximate inference on planar graphs using Loop Calculus and Belief
  Propagation</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</comments><proxy>auai</proxy><report-no>UAI-P-2009-PG-195-202</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce novel results for approximate inference on planar graphical
models using the loop calculus framework. The loop calculus (Chertkov and
Chernyak, 2006b) allows to express the exact partition function Z of a
graphical model as a finite sum of terms that can be evaluated once the belief
propagation (BP) solution is known. In general, full summation over all
correction terms is intractable. We develop an algorithm for the approach
presented in Chertkov et al. (2008) which represents an efficient truncation
scheme on planar graphs and a new representation of the series in terms of
Pfaffians of matrices. We analyze in detail both the loop series and the
Pfaffian series for models with binary variables and pairwise interactions, and
show that the first term of the Pfaffian series can provide very accurate
approximations. The algorithm outperforms previous truncation schemes of the
loop series and is competitive with other state-of-the-art methods for
approximate inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2035</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2035</id><created>2014-08-09</created><authors><author><keyname>Kurihara</keyname><forenames>Kenichi</forenames></author><author><keyname>Tanaka</keyname><forenames>Shu</forenames></author><author><keyname>Miyashita</keyname><forenames>Seiji</forenames></author></authors><title>Quantum Annealing for Clustering</title><categories>cs.AI cs.LG</categories><comments>Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</comments><proxy>auai</proxy><report-no>UAI-P-2009-PG-321-328</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies quantum annealing (QA) for clustering, which can be seen
as an extension of simulated annealing (SA). We derive a QA algorithm for
clustering and propose an annealing schedule, which is crucial in practice.
Experiments show the proposed QA algorithm finds better clustering assignments
than SA. Furthermore, QA is as easy as SA to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2036</identifier>
 <datestamp>2015-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2036</id><created>2014-08-09</created><updated>2015-10-16</updated><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames></author></authors><title>Characterizing predictable classes of processes</title><categories>cs.LG stat.ML</categories><comments>This is a duplicate submission of 0905.4341, made by UAI foundation
  who had the brilliant idea of flooding arxiv with UAI papers 5 years after
  the conference, without checking whether these papers were already submitted
  to arxiv or at least asking the authors. Great job, UAI! The journal
  (extended) version appears in JMLR, 11: 581-602, 2010; also as
  arXiv:0912.4883</comments><proxy>auai</proxy><report-no>UAI-P-2009-PG-471-478</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem is sequence prediction in the following setting. A sequence
x1,..., xn,... of discrete-valued observations is generated according to some
unknown probabilistic law (measure) mu. After observing each outcome, it is
required to give the conditional probabilities of the next observation. The
measure mu belongs to an arbitrary class C of stochastic processes. We are
interested in predictors ? whose conditional probabilities converge to the
'true' mu-conditional probabilities if any mu { C is chosen to generate the
data. We show that if such a predictor exists, then a predictor can also be
obtained as a convex combination of a countably many elements of C. In other
words, it can be obtained as a Bayesian predictor whose prior is concentrated
on a countable set. This result is established for two very different measures
of performance of prediction, one of which is very strong, namely, total
variation, and the other is very weak, namely, prediction in expected average
Kullback-Leibler divergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2037</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2037</id><created>2014-08-09</created><authors><author><keyname>Sato</keyname><forenames>Issei</forenames></author><author><keyname>Kurihara</keyname><forenames>Kenichi</forenames></author><author><keyname>Tanaka</keyname><forenames>Shu</forenames></author><author><keyname>Nakagawa</keyname><forenames>Hiroshi</forenames></author><author><keyname>Miyashita</keyname><forenames>Seiji</forenames></author></authors><title>Quantum Annealing for Variational Bayes Inference</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</comments><proxy>auai</proxy><report-no>UAI-P-2009-PG-479-486</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents studies on a deterministic annealing algorithm based on
quantum annealing for variational Bayes (QAVB) inference, which can be seen as
an extension of the simulated annealing for variational Bayes (SAVB) inference.
QAVB is as easy as SAVB to implement. Experiments revealed QAVB finds a better
local optimum than SAVB in terms of the variational free energy in latent
Dirichlet allocation (LDA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2038</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2038</id><created>2014-08-09</created><authors><author><keyname>Shimizu</keyname><forenames>Shohei</forenames></author><author><keyname>Hyvarinen</keyname><forenames>Aapo</forenames></author><author><keyname>Kawahara</keyname><forenames>Yoshinobu</forenames></author></authors><title>A direct method for estimating a causal ordering in a linear
  non-Gaussian acyclic model</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty
  in Artificial Intelligence (UAI2009)</comments><proxy>auai</proxy><report-no>UAI-P-2009-PG-506-513</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structural equation models and Bayesian networks have been widely used to
analyze causal relations between continuous variables. In such frameworks,
linear acyclic models are typically used to model the datagenerating process of
variables. Recently, it was shown that use of non-Gaussianity identifies a
causal ordering of variables in a linear acyclic model without using any prior
knowledge on the network structure, which is not the case with conventional
methods. However, existing estimation methods are based on iterative search
algorithms and may not converge to a correct solution in a finite number of
steps. In this paper, we propose a new direct method to estimate a causal
ordering based on non-Gaussianity. In contrast to the previous methods, our
algorithm requires no algorithmic parameters and is guaranteed to converge to
the right solution within a small fixed number of steps if the data strictly
follows the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2039</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2039</id><created>2014-08-09</created><authors><author><keyname>Adams</keyname><forenames>Ryan Prescott</forenames></author><author><keyname>Dahl</keyname><forenames>George E.</forenames></author><author><keyname>Murray</keyname><forenames>Iain</forenames></author></authors><title>Incorporating Side Information in Probabilistic Matrix Factorization
  with Gaussian Processes</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</comments><proxy>auai</proxy><report-no>UAI-P-2010-PG-1-9</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic matrix factorization (PMF) is a powerful method for modeling
data associ- ated with pairwise relationships, Finding use in collaborative
Filtering, computational bi- ology, and document analysis, among other areas.
In many domains, there are additional covariates that can assist in prediction.
For example, when modeling movie ratings, we might know when the rating
occurred, where the user lives, or what actors appear in the movie. It is
difficult, however, to incorporate this side information into the PMF model. We
propose a framework for incorporating side information by coupling together
multi- ple PMF problems via Gaussian process priors. We replace scalar latent
features with func- tions that vary over the covariate space. The GP priors on
these functions require them to vary smoothly and share information. We apply
this new method to predict the scores of professional basketball games, where
side information about the venue and date of the game are relevant for the
outcome.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2040</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2040</id><created>2014-08-09</created><authors><author><keyname>Chernov</keyname><forenames>Alexey</forenames></author><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author></authors><title>Prediction with Advice of Unknown Number of Experts</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</comments><proxy>auai</proxy><report-no>UAI-P-2010-PG-117-125</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the framework of prediction with expert advice, we consider a recently
introduced kind of regret bounds: the bounds that depend on the effective
instead of nominal number of experts. In contrast to the Normal- Hedge bound,
which mainly depends on the effective number of experts but also weakly depends
on the nominal one, we obtain a bound that does not contain the nominal number
of experts at all. We use the defensive forecasting method and introduce an
application of defensive forecasting to multivalued supermartingales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2041</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2041</id><created>2014-08-09</created><authors><author><keyname>Low</keyname><forenames>Yucheng</forenames></author><author><keyname>Gonzalez</keyname><forenames>Joseph E.</forenames></author><author><keyname>Kyrola</keyname><forenames>Aapo</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos E.</forenames></author><author><keyname>Hellerstein</keyname><forenames>Joseph</forenames></author></authors><title>GraphLab: A New Framework For Parallel Machine Learning</title><categories>cs.LG cs.DC</categories><comments>Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</comments><proxy>auai</proxy><report-no>UAI-P-2010-PG-340-349</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing and implementing efficient, provably correct parallel machine
learning (ML) algorithms is challenging. Existing high-level parallel
abstractions like MapReduce are insufficiently expressive while low-level tools
like MPI and Pthreads leave ML experts repeatedly solving the same design
challenges. By targeting common patterns in ML, we developed GraphLab, which
improves upon abstractions like MapReduce by compactly expressing asynchronous
iterative algorithms with sparse computational dependencies while ensuring data
consistency and achieving a high degree of parallel performance. We demonstrate
the expressiveness of the GraphLab framework by designing and implementing
parallel versions of belief propagation, Gibbs sampling, Co-EM, Lasso and
Compressed Sensing. We show that using GraphLab we can achieve excellent
parallel performance on large scale real-world problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2042</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2042</id><created>2014-08-09</created><authors><author><keyname>Silva</keyname><forenames>Ricardo</forenames></author><author><keyname>Gramacy</keyname><forenames>Robert B.</forenames></author></authors><title>Gaussian Process Structural Equation Models with Latent Variables</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</comments><proxy>auai</proxy><report-no>UAI-P-2010-PG-537-545</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a variety of disciplines such as social sciences, psychology, medicine and
economics, the recorded data are considered to be noisy measurements of latent
variables connected by some causal structure. This corresponds to a family of
graphical models known as the structural equation model with latent variables.
While linear non-Gaussian variants have been well-studied, inference in
nonparametric structural equation models is still underdeveloped. We introduce
a sparse Gaussian process parameterization that defines a non-linear structure
connecting latent variables, unlike common formulations of Gaussian process
latent variable models. The sparse parameterization is given a full Bayesian
treatment without compromising Markov chain Monte Carlo efficiency. We compare
the stability of the sampling procedure and the predictive ability of the model
against the current practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2044</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2044</id><created>2014-08-09</created><authors><author><keyname>Talwalkar</keyname><forenames>Ameet</forenames></author><author><keyname>Rostamizadeh</keyname><forenames>Afshin</forenames></author></authors><title>Matrix Coherence and the Nystrom Method</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</comments><proxy>auai</proxy><report-no>UAI-P-2010-PG-572-579</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Nystrom method is an efficient technique used to speed up large-scale
learning applications by generating low-rank approximations. Crucial to the
performance of this technique is the assumption that a matrix can be well
approximated by working exclusively with a subset of its columns. In this work
we relate this assumption to the concept of matrix coherence, connecting
coherence to the performance of the Nystrom method. Making use of related work
in the compressed sensing and the matrix completion literature, we derive novel
coherence-based bounds for the Nystrom method in the low-rank setting. We then
present empirical results that corroborate these theoretical bounds. Finally,
we present more general empirical results for the full-rank setting that
convincingly demonstrate the ability of matrix coherence to measure the degree
to which information can be extracted from a subset of columns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2045</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2045</id><created>2014-08-09</created><authors><author><keyname>Voevodski</keyname><forenames>Konstantin</forenames></author><author><keyname>Balcan</keyname><forenames>Maria-Florina</forenames></author><author><keyname>Roglin</keyname><forenames>Heiko</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author><author><keyname>Xia</keyname><forenames>Yu</forenames></author></authors><title>Efficient Clustering with Limited Distance Information</title><categories>cs.LG cs.AI</categories><comments>Appears in Proceedings of the Twenty-Sixth Conference on Uncertainty
  in Artificial Intelligence (UAI2010)</comments><proxy>auai</proxy><report-no>UAI-P-2010-PG-632-640</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a point set S and an unknown metric d on S, we study the problem of
efficiently partitioning S into k clusters while querying few distances between
the points. In our model we assume that we have access to one versus all
queries that given a point s 2 S return the distances between s and all other
points. We show that given a natural assumption about the structure of the
instance, we can efficiently find an accurate clustering using only O(k)
distance queries. We use our algorithm to cluster proteins by sequence
similarity. This setting nicely fits our model because we can use a fast
sequence database search program to query a sequence against an entire dataset.
We conduct an empirical study that shows that even though we query a small
fraction of the distances between the points, we produce clusterings that are
close to a desired clustering given by manual classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2046</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2046</id><created>2014-08-09</created><authors><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author><author><keyname>Tan</keyname><forenames>Colin Keng-Yan</forenames></author><author><keyname>Oran</keyname><forenames>Ali</forenames></author><author><keyname>Jaillet</keyname><forenames>Patrick</forenames></author><author><keyname>Dolan</keyname><forenames>John</forenames></author><author><keyname>Sukhatme</keyname><forenames>Gaurav</forenames></author></authors><title>Decentralized Data Fusion and Active Sensing with Mobile Sensors for
  Modeling and Predicting Spatiotemporal Traffic Phenomena</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><proxy>auai</proxy><report-no>UAI-P-2012-PG-163-173</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of modeling and predicting spatiotemporal traffic phenomena over
an urban road network is important to many traffic applications such as
detecting and forecasting congestion hotspots. This paper presents a
decentralized data fusion and active sensing (D2FAS) algorithm for mobile
sensors to actively explore the road network to gather and assimilate the most
informative data for predicting the traffic phenomenon. We analyze the time and
communication complexity of D2FAS and demonstrate that it can scale well with a
large number of observations and sensors. We provide a theoretical guarantee on
its predictive performance to be equivalent to that of a sophisticated
centralized sparse approximation for the Gaussian process (GP) model: The
computation of such a sparse approximate GP model can thus be parallelized and
distributed among the mobile sensors (in a Google-like MapReduce paradigm),
thereby achieving efficient and scalable prediction. We also theoretically
guarantee its active sensing performance that improves under various practical
environmental conditions. Empirical evaluation on real-world urban road network
data shows that our D2FAS algorithm is significantly more time-efficient and
scalable than state-oftheart centralized algorithms while achieving comparable
predictive performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2047</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2047</id><created>2014-08-09</created><authors><author><keyname>Chen</keyname><forenames>Yutian</forenames></author><author><keyname>Welling</keyname><forenames>Max</forenames></author></authors><title>Bayesian Structure Learning for Markov Random Fields with a Spike and
  Slab Prior</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><proxy>auai</proxy><report-no>UAI-P-2012-PG-174-184</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years a number of methods have been developed for automatically
learning the (sparse) connectivity structure of Markov Random Fields. These
methods are mostly based on L1-regularized optimization which has a number of
disadvantages such as the inability to assess model uncertainty and expensive
crossvalidation to find the optimal regularization parameter. Moreover, the
model's predictive performance may degrade dramatically with a suboptimal value
of the regularization parameter (which is sometimes desirable to induce
sparseness). We propose a fully Bayesian approach based on a &quot;spike and slab&quot;
prior (similar to L0 regularization) that does not suffer from these
shortcomings. We develop an approximate MCMC method combining Langevin dynamics
and reversible jump MCMC to conduct inference in this model. Experiments show
that the proposed model learns a good combination of the structure and
parameter values without the need for separate hyper-parameter tuning.
Moreover, the model's predictive performance is much more robust than L1-based
methods with hyper-parameter settings that induce highly sparse model
structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2048</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2048</id><created>2014-08-09</created><authors><author><keyname>Hay</keyname><forenames>Nicholas</forenames></author><author><keyname>Russell</keyname><forenames>Stuart</forenames></author><author><keyname>Tolpin</keyname><forenames>David</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author></authors><title>Selecting Computations: Theory and Applications</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><proxy>auai</proxy><report-no>UAI-P-2012-PG-346-355</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential decision problems are often approximately solvable by simulating
possible future action sequences. Metalevel decision procedures have been
developed for selecting which action sequences to simulate, based on estimating
the expected improvement in decision quality that would result from any
particular simulation; an example is the recent work on using bandit algorithms
to control Monte Carlo tree search in the game of Go. In this paper we develop
a theoretical basis for metalevel decisions in the statistical framework of
Bayesian selection problems, arguing (as others have done) that this is more
appropriate than the bandit framework. We derive a number of basic results
applicable to Monte Carlo selection problems, including the first finite
sampling bounds for optimal policies in certain cases; we also provide a simple
counterexample to the intuitive conjecture that an optimal policy will
necessarily reach a decision in all cases. We then derive heuristic
approximations in both Bayesian and distribution-free settings and demonstrate
their superiority to bandit-based heuristics in one-shot decision problems and
in Go.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2049</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2049</id><created>2014-08-09</created><authors><author><keyname>Huszar</keyname><forenames>Ferenc</forenames></author><author><keyname>Duvenaud</keyname><forenames>David</forenames></author></authors><title>Optimally-Weighted Herding is Bayesian Quadrature</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><proxy>auai</proxy><report-no>UAI-P-2012-PG-377-386</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Herding and kernel herding are deterministic methods of choosing samples
which summarise a probability distribution. A related task is choosing samples
for estimating integrals using Bayesian quadrature. We show that the criterion
minimised when selecting samples in kernel herding is equivalent to the
posterior variance in Bayesian quadrature. We then show that sequential
Bayesian quadrature can be viewed as a weighted version of kernel herding which
achieves performance superior to any other weighted herding method. We
demonstrate empirically a rate of convergence faster than O(1/N). Our results
also imply an upper bound on the empirical error of the Bayesian quadrature
estimate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2051</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2051</id><created>2014-08-09</created><authors><author><keyname>Iyer</keyname><forenames>Rishabh</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff A.</forenames></author></authors><title>Algorithms for Approximate Minimization of the Difference Between
  Submodular Functions, with Applications</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><proxy>auai</proxy><report-no>UAI-P-2012-PG-407-417</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the work of Narasimhan and Bilmes [30] for minimizing set functions
representable as a dierence between submodular functions. Similar to [30], our
new algorithms are guaranteed to monotonically reduce the objective function at
every step. We empirically and theoretically show that the per-iteration cost
of our algorithms is much less than [30], and our algorithms can be used to
efficiently minimize a dierence between submodular functions under various
combinatorial constraints, a problem not previously addressed. We provide
computational bounds and a hardness result on the multiplicative
inapproximability of minimizing the dierence between submodular functions. We
show, however, that it is possible to give worst-case additive bounds by
providing a polynomial time computable lower-bound on the minima. Finally we
show how a number of machine learning problems can be modeled as minimizing the
dierence between submodular functions. We experimentally show the validity of
our algorithms by testing them on the problem of feature selection with
submodular cost features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2052</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2052</id><created>2014-08-09</created><authors><author><keyname>Niepert</keyname><forenames>Mathias</forenames></author></authors><title>Markov Chains on Orbits of Permutation Groups</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><proxy>auai</proxy><report-no>UAI-P-2012-PG-624-633</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach to detecting and utilizing symmetries in
probabilistic graphical models with two main contributions. First, we present a
scalable approach to computing generating sets of permutation groups
representing the symmetries of graphical models. Second, we introduce orbital
Markov chains, a novel family of Markov chains leveraging model symmetries to
reduce mixing times. We establish an insightful connection between model
symmetries and rapid mixing of orbital Markov chains. Thus, we present the
first lifted MCMC algorithm for probabilistic graphical models. Both analytical
and empirical results demonstrate the effectiveness and efficiency of the
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2053</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2053</id><created>2014-08-09</created><authors><author><keyname>Schlicht</keyname><forenames>Erik J.</forenames></author><author><keyname>Lee</keyname><forenames>Ritchie</forenames></author><author><keyname>Wolpert</keyname><forenames>David H.</forenames></author><author><keyname>Kochenderfer</keyname><forenames>Mykel J.</forenames></author><author><keyname>Tracey</keyname><forenames>Brendan</forenames></author></authors><title>Predicting the behavior of interacting humans by fusing data from
  multiple sources</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><proxy>auai</proxy><report-no>UAI-P-2012-PG-756-765</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-fidelity methods combine inexpensive low-fidelity simulations with
costly but highfidelity simulations to produce an accurate model of a system of
interest at minimal cost. They have proven useful in modeling physical systems
and have been applied to engineering problems such as wing-design optimization.
During human-in-the-loop experimentation, it has become increasingly common to
use online platforms, like Mechanical Turk, to run low-fidelity experiments to
gather human performance data in an efficient manner. One concern with these
experiments is that the results obtained from the online environment generalize
poorly to the actual domain of interest. To address this limitation, we extend
traditional multi-fidelity approaches to allow us to combine fewer data points
from high-fidelity human-in-the-loop experiments with plentiful but less
accurate data from low-fidelity experiments to produce accurate models of how
humans interact. We present both model-based and model-free methods, and
summarize the predictive performance of each method under dierent conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2054</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2054</id><created>2014-08-09</created><authors><author><keyname>Wipf</keyname><forenames>David</forenames></author></authors><title>Non-Convex Rank Minimization via an Empirical Bayesian Approach</title><categories>cs.LG cs.NA stat.ML</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><proxy>auai</proxy><report-no>UAI-P-2012-PG-914-923</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications that require matrix solutions of minimal rank, the
underlying cost function is non-convex leading to an intractable, NP-hard
optimization problem. Consequently, the convex nuclear norm is frequently used
as a surrogate penalty term for matrix rank. The problem is that in many
practical scenarios there is no longer any guarantee that we can correctly
estimate generative low-rank matrices of interest, theoretical special cases
notwithstanding. Consequently, this paper proposes an alternative empirical
Bayesian procedure build upon a variational approximation that, unlike the
nuclear norm, retains the same globally minimizing point estimate as the rank
function under many useful constraints. However, locally minimizing solutions
are largely smoothed away via marginalization, allowing the algorithm to
succeed when standard convex relaxations completely fail. While the proposed
methodology is generally applicable to a wide range of low-rank applications,
we focus our attention on the robust principal component analysis problem
(RPCA), which involves estimating an unknown low-rank matrix with unknown
sparse corruptions. Theoretical and empirical evidence are presented to show
that our method is potentially superior to related MAP-based approaches, for
which the convex principle component pursuit (PCP) algorithm (Candes et al.,
2011) can be viewed as a special case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2055</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2055</id><created>2014-08-09</created><authors><author><keyname>Zhang</keyname><forenames>Amy</forenames></author><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>Ioannidis</keyname><forenames>Stratis</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Guess Who Rated This Movie: Identifying Users Through Subspace
  Clustering</title><categories>cs.LG cs.IR stat.ML</categories><comments>Appears in Proceedings of the Twenty-Eighth Conference on Uncertainty
  in Artificial Intelligence (UAI2012)</comments><proxy>auai</proxy><report-no>UAI-P-2012-PG-944-953</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is often the case that, within an online recommender system, multiple
users share a common account. Can such shared accounts be identified solely on
the basis of the userprovided ratings? Once a shared account is identified, can
the different users sharing it be identified as well? Whenever such user
identification is feasible, it opens the way to possible improvements in
personalized recommendations, but also raises privacy concerns. We develop a
model for composite accounts based on unions of linear subspaces, and use
subspace clustering for carrying out the identification task. We show that a
significant fraction of such accounts is identifiable in a reliable manner, and
illustrate potential uses for personalized recommendation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2056</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2056</id><created>2014-08-09</created><authors><author><keyname>Ahmad</keyname><forenames>Sheeraz</forenames></author><author><keyname>Yu</keyname><forenames>Angela</forenames></author></authors><title>Active Sensing as Bayes-Optimal Sequential Decision Making</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-12-21</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sensory inference under conditions of uncertainty is a major problem in both
machine learning and computational neuroscience. An important but poorly
understood aspect of sensory processing is the role of active sensing. Here, we
present a Bayes-optimal inference and control framework for active sensing,
C-DAC (Context-Dependent Active Controller). Unlike previously proposed
algorithms that optimize abstract statistical objectives such as information
maximization (Infomax) [Butko &amp; Movellan, 2010] or one-step look-ahead accuracy
[Najemnik &amp; Geisler, 2005], our active sensing model directly minimizes a
combination of behavioral costs, such as temporal delay, response error, and
effort. We simulate these algorithms on a simple visual search task to
illustrate scenarios in which context-sensitivity is particularly beneficial
and optimization with respect to generic statistical objectives particularly
inadequate. Motivated by the geometric properties of the C-DAC policy, we
present both parametric and non-parametric approximations, which retain
context-sensitivity while significantly reducing computational complexity.
These approximations enable us to investigate the more complex problem
involving peripheral vision, and we notice that the difference between C-DAC
and statistical policies becomes even more evident in this scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2057</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2057</id><created>2014-08-09</created><authors><author><keyname>Borboudakis</keyname><forenames>Giorgos</forenames></author><author><keyname>Tsamardinos</keyname><forenames>Ioannis</forenames></author></authors><title>Scoring and Searching over Bayesian Networks with Causal and Associative
  Priors</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-102-111</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A significant theoretical advantage of search-and-score methods for learning
Bayesian Networks is that they can accept informative prior beliefs for each
possible network, thus complementing the data. In this paper, a method is
presented for assigning priors based on beliefs on the presence or absence of
certain paths in the true network. Such beliefs correspond to knowledge about
the possible causal and associative relations between pairs of variables. This
type of knowledge naturally arises from prior experimental and observational
data, among others. In addition, a novel search-operator is proposed to take
advantage of such prior knowledge. Experiments show that, using path beliefs
improves the learning of the skeleton, as well as the edge directions in the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2058</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2058</id><created>2014-08-09</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Chmelik</keyname><forenames>Martin</forenames></author></authors><title>POMDPs under Probabilistic Semantics</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-142-151</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider partially observable Markov decision processes (POMDPs) with
limit-average payoff, where a reward value in the interval [0,1] is associated
to every transition, and the payoff of an infinite path is the long-run average
of the rewards. We consider two types of path constraints: (i) quantitative
constraint defines the set of paths where the payoff is at least a given
threshold lambda_1 in (0,1]; and (ii) qualitative constraint which is a special
case of quantitative constraint with lambda_1=1. We consider the computation of
the almost-sure winning set, where the controller needs to ensure that the path
constraint is satisfied with probability 1. Our main results for qualitative
path constraint are as follows: (i) the problem of deciding the existence of a
finite-memory controller is EXPTIME-complete; and (ii) the problem of deciding
the existence of an infinite-memory controller is undecidable. For quantitative
path constraint we show that the problem of deciding the existence of a
finite-memory controller is undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2060</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2060</id><created>2014-08-09</created><authors><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Cao</keyname><forenames>Nannan</forenames></author><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author><author><keyname>Ouyang</keyname><forenames>Ruofei</forenames></author><author><keyname>Tan</keyname><forenames>Colin Keng-Yan</forenames></author><author><keyname>Jaillet</keyname><forenames>Patrick</forenames></author></authors><title>Parallel Gaussian Process Regression with Low-Rank Covariance Matrix
  Approximations</title><categories>cs.LG cs.DC stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-152-161</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian processes (GP) are Bayesian non-parametric models that are widely
used for probabilistic regression. Unfortunately, it cannot scale well with
large data nor perform real-time predictions due to its cubic time cost in the
data size. This paper presents two parallel GP regression methods that exploit
low-rank covariance matrix approximations for distributing the computational
load among parallel machines to achieve time efficiency and scalability. We
theoretically guarantee the predictive performances of our proposed parallel
GPs to be equivalent to that of some centralized approximate GP regression
methods: The computation of their centralized counterparts can be distributed
among parallel machines, hence achieving greater time efficiency and
scalability. We analytically compare the properties of our parallel GPs such as
time, space, and communication complexity. Empirical evaluation on two
real-world datasets in a cluster of 20 computing nodes shows that our parallel
GPs are significantly more time-efficient and scalable than their centralized
counterparts and exact/full GP while achieving predictive performances
comparable to full GP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2061</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2061</id><created>2014-08-09</created><authors><author><keyname>Iwata</keyname><forenames>Tomoharu</forenames></author><author><keyname>Duvenaud</keyname><forenames>David</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Warped Mixtures for Nonparametric Cluster Shapes</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-311-320</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A mixture of Gaussians fit to a single curved or heavy-tailed cluster will
report that the data contains many clusters. To produce more appropriate
clusterings, we introduce a model which warps a latent mixture of Gaussians to
produce nonparametric cluster shapes. The possibly low-dimensional latent
mixture model allows us to summarize the properties of the high-dimensional
clusters (or density manifolds) describing the data. The number of manifolds,
as well as the shape and dimension of each manifold is automatically inferred.
We derive a simple inference scheme for this model which analytically
integrates out both the mixture parameters and the warping function. We show
that our model is effective for density estimation, performs better than
infinite Gaussian mixture models at recovering the true number of clusters, and
produces interpretable summaries of high-dimensional datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2062</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2062</id><created>2014-08-09</created><authors><author><keyname>Iyer</keyname><forenames>Rishabh</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff A.</forenames></author></authors><title>The Lovasz-Bregman Divergence and connections to rank aggregation,
  clustering, and web ranking</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-321-330</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the recently introduced theory of Lovasz-Bregman (LB) divergences
(Iyer &amp; Bilmes 2012) in several ways. We show that they represent a distortion
between a &quot;score&quot; and an &quot;ordering&quot;, thus providing a new view of rank
aggregation and order based clustering with interesting connections to web
ranking. We show how the LB divergences have a number of properties akin to
many permutation based metrics, and in fact have as special cases forms very
similar to the Kendall-tau metric. We also show how the LB divergences subsume
a number of commonly used ranking measures in information retrieval, like NDCG
and AUC. Unlike the traditional permutation based metrics, however, the LB
divergence naturally captures a notion of &quot;confidence&quot; in the orderings, thus
providing a new representation to applications involving aggregating scores as
opposed to just orderings. We show how a number of recently used web ranking
models are forms of Lovasz-Bregman rank aggregation and also observe that a
natural form of Mallow's model using the LB divergence has been used as
conditional ranking models for the &quot;Learning to Rank&quot; problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2063</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2063</id><created>2014-08-09</created><authors><author><keyname>Mooij</keyname><forenames>Joris</forenames></author><author><keyname>Janzing</keyname><forenames>Dominik</forenames></author><author><keyname>Schoelkopf</keyname><forenames>Bernhard</forenames></author></authors><title>From Ordinary Differential Equations to Structural Causal Models: the
  deterministic case</title><categories>cs.AI</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-440-448</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how, and under which conditions, the equilibrium states of a
first-order Ordinary Differential Equation (ODE) system can be described with a
deterministic Structural Causal Model (SCM). Our exposition sheds more light on
the concept of causality as expressed within the framework of Structural Causal
Models, especially for cyclic models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2064</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2064</id><created>2014-08-09</created><authors><author><keyname>Muandet</keyname><forenames>Krikamol</forenames></author><author><keyname>Schoelkopf</keyname><forenames>Bernhard</forenames></author></authors><title>One-Class Support Measure Machines for Group Anomaly Detection</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-449-458</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose one-class support measure machines (OCSMMs) for group anomaly
detection which aims at recognizing anomalous aggregate behaviors of data
points. The OCSMMs generalize well-known one-class support vector machines
(OCSVMs) to a space of probability measures. By formulating the problem as
quantile estimation on distributions, we can establish an interesting
connection to the OCSVMs and variable kernel density estimators (VKDEs) over
the input space on which the distributions are defined, bridging the gap
between large-margin methods and kernel density estimators. In particular, we
show that various types of VKDEs can be considered as solutions to a class of
regularization problems studied in this paper. Experiments on Sloan Digital Sky
Survey dataset and High Energy Particle Physics dataset demonstrate the
benefits of the proposed framework in real-world applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2065</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2065</id><created>2014-08-09</created><authors><author><keyname>Ross</keyname><forenames>Stephane</forenames></author><author><keyname>Mineiro</keyname><forenames>Paul</forenames></author><author><keyname>Langford</keyname><forenames>John</forenames></author></authors><title>Normalized Online Learning</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-537-545</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce online learning algorithms which are independent of feature
scales, proving regret bounds dependent on the ratio of scales existent in the
data rather than the absolute scale. This has several useful effects: there is
no need to pre-normalize data, the test-time and test-space complexity are
reduced, and the algorithms are more robust.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2066</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2066</id><created>2014-08-09</created><authors><author><keyname>Sindhwani</keyname><forenames>Vikas</forenames></author><author><keyname>Minh</keyname><forenames>Ha Quang</forenames></author><author><keyname>Lozano</keyname><forenames>Aurelie</forenames></author></authors><title>Scalable Matrix-valued Kernel Learning for High-dimensional Nonlinear
  Multivariate Regression and Granger Causality</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-586-595</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a general matrix-valued multiple kernel learning framework for
high-dimensional nonlinear multivariate regression problems. This framework
allows a broad class of mixed norm regularizers, including those that induce
sparsity, to be imposed on a dictionary of vector-valued Reproducing Kernel
Hilbert Spaces. We develop a highly scalable and eigendecomposition-free
algorithm that orchestrates two inexact solvers for simultaneously learning
both the input and output components of separable matrix-valued kernels. As a
key application enabled by our framework, we show how high-dimensional causal
inference tasks can be naturally cast as sparse function estimation problems,
leading to novel nonlinear extensions of a class of Graphical Granger Causality
techniques. Our algorithmic developments and extensive empirical studies are
complemented by theoretical analyses in terms of Rademacher generalization
bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2067</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2067</id><created>2014-08-09</created><authors><author><keyname>Tossou</keyname><forenames>Aristide</forenames></author><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author></authors><title>Probabilistic inverse reinforcement learning in unknown environments</title><categories>cs.LG stat.ML</categories><comments>Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty
  in Artificial Intelligence (UAI2013)</comments><proxy>auai</proxy><report-no>UAI-P-2013-PG-635-643</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning by demonstration from agents acting in
unknown stochastic Markov environments or games. Our aim is to estimate agent
preferences in order to construct improved policies for the same task that the
agents are trying to solve. To do so, we extend previous probabilistic
approaches for inverse reinforcement learning in known MDPs to the case of
unknown dynamics or opponents. We do this by deriving two simplified
probabilistic models of the demonstrator's policy and utility. For
tractability, we use maximum a posteriori estimation rather than full Bayesian
inference. Under a flat prior, this results in a convex optimisation problem.
We find that the resulting algorithms are highly competitive against a variety
of other methods for inverse reinforcement learning that do have knowledge of
the dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2071</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2071</id><created>2014-08-09</created><authors><author><keyname>Hegeman</keyname><forenames>James W.</forenames></author><author><keyname>Pemmaraju</keyname><forenames>Sriram V.</forenames></author><author><keyname>Sardeshmukh</keyname><forenames>Vivek B.</forenames></author></authors><title>Near-Constant-Time Distributed Algorithms on a Congested Clique</title><categories>cs.DC</categories><comments>Full version of DISC 2014 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents constant-time and near-constant-time distributed
algorithms for a variety of problems in the congested clique model. We show how
to compute a 3-ruling set in expected $O(\log \log \log n)$ rounds and using
this, we obtain a constant-approximation to metric facility location, also in
expected $O(\log \log \log n)$ rounds. In addition, assuming an input metric
space of constant doubling dimension, we obtain constant-round algorithms to
compute constant-factor approximations to the minimum spanning tree and the
metric facility location problems. These results significantly improve on the
running time of the fastest known algorithms for these problems in the
congested clique setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2072</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2072</id><created>2014-08-09</created><authors><author><keyname>Bhagat</keyname><forenames>S.</forenames></author><author><keyname>Chaudhuri</keyname><forenames>S. Gan</forenames></author><author><keyname>Mukhopadhyaya</keyname><forenames>K.</forenames></author></authors><title>Formation of General Position by Asynchronous Mobile Robots</title><categories>cs.DC cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The traditional distributed model of autonomous, homogeneous, mobile point
robots usually assumes that the robots do not create any visual obstruction for
the other robots, i.e., the robots are see through. In this paper, we consider
a slightly more realistic model, by incorporating the notion of obstructed
visibility (i.e., robots are not see through) for other robots. Under the new
model of visibility, a robot may not have the full view of its surroundings.
Many of the existing algorithms demand that each robot should have the complete
knowledge of the positions of other robots. Since, vision is the only mean of
their communication, it is required that the robots are in general position
(i.e., no three robots are collinear). We consider asynchronous robots. They
also do not have common chirality (or any agreement on a global coordinate
system). In this paper, we present a distributed algorithm for obtaining a
general position for the robots in finite time from any arbitrary
configuration. The algorithm also assures collision free motion for each robot.
This algorithm may also be used as a preprocessing module for many other
subsequent tasks performed by the robots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2078</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2078</id><created>2014-08-09</created><authors><author><keyname>Guirguis</keyname><forenames>Arsany</forenames></author><author><keyname>Guirguis</keyname><forenames>Raymond</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>Primary User-aware Network Coding for Multi-hop Cognitive Radio Networks</title><categories>cs.NI</categories><comments>Accepted for publication in the IEEE Globecom 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding has proved its efficiency in increasing the network
performance for traditional ad-hoc networks. In this paper, we investigate
using network coding for enhancing the throughput of multi-hop cognitive radio
networks. We formulate the network coding throughput maximization problem as a
graph theory problem, where different constraints and primary users'
characteristics are mapped to the graph structure. We then show that the
optimal solution to this problem in NP-hard and propose a heuristic algorithm
to efficiently solve it.
  Evaluation of the proposed algorithm through NS2 simulations shows that we
can increase the throughput of the constrained secondary users' network by
150\% to 200\% for a wide range of scenarios covering different primary users'
densities, traffic loads, and spectrum availability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2081</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2081</id><created>2014-08-09</created><authors><author><keyname>Gogacz</keyname><forenames>Tomasz</forenames></author><author><keyname>Marcinkowski</keyname><forenames>Jerzy</forenames></author></authors><title>On the BDD/FC Conjecture</title><categories>cs.DB</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Bounded Derivation Depth property (BDD) and Finite Controllability (FC) are
two properties of sets of datalog rules and tuple generating dependencies
(known as Datalog +/- programs), which recently attracted some attention. We
conjecture that the first of these properties implies the second, and support
this conjecture by some evidence proving, among other results, that it holds
true for all theories over binary signature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2095</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2095</id><created>2014-08-09</created><updated>2014-08-23</updated><authors><author><keyname>Gon&#xe7;alves</keyname><forenames>C&#xe9;cile</forenames><affiliation>INRIA Saclay - Ile de France, LIX</affiliation></author></authors><title>A Point Counting Algorithm for Cyclic Covers of the Projective Line</title><categories>cs.CG cs.CR math.NT</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Kedlaya-style point counting algorithm for cyclic covers $y^r =
f(x)$ over a finite field $\mathbb{F}_{p^n}$ with $p$ not dividing $r$, and $r$
and $\deg{f}$ not necessarily coprime. This algorithm generalizes the
Gaudry-G\&quot;urel algorithm for superelliptic curves to a more general class of
curves, and has essentially the same complexity. Our practical improvements
include a simplified algorithm exploiting the automorphism of $\mathcal{C}$,
refined bounds on the $p$-adic precision, and an alternative pseudo-basis for
the Monsky-Washnitzer cohomology which leads to an integral matrix when $p \geq
2r$. Each of these improvements can also be applied to the original
Gaudry-G\&quot;urel algorithm. We include some experimental results, applying our
algorithm to compute Weil polynomials of some large genus cyclic covers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2098</identifier>
 <datestamp>2015-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2098</id><created>2014-08-09</created><updated>2015-05-18</updated><authors><author><keyname>Song</keyname><forenames>Jiho</forenames></author><author><keyname>Choi</keyname><forenames>Junil</forenames></author><author><keyname>Larew</keyname><forenames>Stephen G.</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author><author><keyname>Thomas</keyname><forenames>Timothy A.</forenames></author><author><keyname>Ghosh</keyname><forenames>Amitava</forenames></author></authors><title>Adaptive Millimeter Wave Beam Alignment for Dual-Polarized MIMO Systems</title><categories>cs.IT math.IT</categories><comments>12 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fifth generation wireless systems are expected to employ multiple antenna
communication at millimeter wave (mmWave) frequencies using small cells within
heterogeneous cellular networks. The high path loss of mmWave as well as
physical obstructions make communication challenging. To compensate for the
severe path loss, mmWave systems may employ a beam alignment algorithm that
facilitates highly directional transmission by aligning the beam direction of
multiple antenna arrays. This paper discusses a mmWave system employing
dual-polarized antennas. First, we propose a practical soft-decision beam
alignment (soft-alignment) algorithm that exploits orthogonal polarizations. By
sounding the orthogonal polarizations in parallel, the equality criterion of
the Welch bound for training sequences is relaxed. Second, the analog
beamforming system is adapted to the directional characteristics of the mmWave
link assuming a high Ricean K-factor and poor scattering environment. The
soft-algorithm enables the mmWave system to align innumerable narrow beams to
channel subspace in an attempt to effectively scan the mmWave channel. Thirds,
we propose a method to efficiently adapt the number of channel sounding
observations to the specific channel environment based on an approximate
probability of beam misalignment. Simulation results show the proposed
soft-alignment algorithm with adaptive sounding time effectively scans the
channel subspace of a mobile user by exploiting polarization diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2103</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2103</id><created>2014-08-09</created><authors><author><keyname>Monperrus</keyname><forenames>Martin</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>A Critical Review of &quot;Automatic Patch Generation Learned from
  Human-Written Patches&quot;: Essay on the Problem Statement and the Evaluation of
  Automatic Software Repair</title><categories>cs.SE</categories><comments>ICSE 2014, India (2014)</comments><proxy>ccsd</proxy><doi>10.1145/2568225.2568324</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At ICSE'2013, there was the first session ever dedicated to automatic program
repair. In this session, Kim et al. presented PAR, a novel template-based
approach for fixing Java bugs. We strongly disagree with key points of this
paper. Our critical review has two goals. First, we aim at explaining why we
disagree with Kim and colleagues and why the reasons behind this disagreement
are important for research on automatic software repair in general. Second, we
aim at contributing to the field with a clarification of the essential ideas
behind automatic software repair. In particular we discuss the main evaluation
criteria of automatic software repair: understandability, correctness and
completeness. We show that depending on how one sets up the repair scenario,
the evaluation goals may be contradictory. Eventually, we discuss the nature of
fix acceptability and its relation to the notion of software correctness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2116</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2116</id><created>2014-08-09</created><authors><author><keyname>Delbot</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIP6</affiliation></author><author><keyname>Laforest</keyname><forenames>Christian</forenames><affiliation>LIMOS</affiliation></author><author><keyname>Rovedakis</keyname><forenames>Stephane</forenames><affiliation>CEDRIC</affiliation></author></authors><title>Self-stabilizing algorithms for Connected Vertex Cover and Clique
  decomposition problems</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many wireless networks, there is no fixed physical backbone nor
centralized network management. The nodes of such a network have to
self-organize in order to maintain a virtual backbone used to route messages.
Moreover, any node of the network can be a priori at the origin of a malicious
attack. Thus, in one hand the backbone must be fault-tolerant and in other hand
it can be useful to monitor all network communications to identify an attack as
soon as possible. We are interested in the minimum \emph{Connected Vertex
Cover} problem, a generalization of the classical minimum Vertex Cover problem,
which allows to obtain a connected backbone. Recently, Delbot et
al.~\cite{DelbotLP13} proposed a new centralized algorithm with a constant
approximation ratio of $2$ for this problem. In this paper, we propose a
distributed and self-stabilizing version of their algorithm with the same
approximation guarantee. To the best knowledge of the authors, it is the first
distributed and fault-tolerant algorithm for this problem. The approach
followed to solve the considered problem is based on the construction of a
connected minimal clique partition. Therefore, we also design the first
distributed self-stabilizing algorithm for this problem, which is of
independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2123</identifier>
 <datestamp>2014-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2123</id><created>2014-08-09</created><updated>2014-09-11</updated><authors><author><keyname>Arabas</keyname><forenames>Sylwester</forenames></author><author><keyname>Bareford</keyname><forenames>Michael R.</forenames></author><author><keyname>de Silva</keyname><forenames>Lakshitha R.</forenames></author><author><keyname>Gent</keyname><forenames>Ian P.</forenames></author><author><keyname>Gorman</keyname><forenames>Benjamin M.</forenames></author><author><keyname>Hajiarabderkani</keyname><forenames>Masih</forenames></author><author><keyname>Henderson</keyname><forenames>Tristan</forenames></author><author><keyname>Hutton</keyname><forenames>Luke</forenames></author><author><keyname>Konovalov</keyname><forenames>Alexander</forenames></author><author><keyname>Kotthoff</keyname><forenames>Lars</forenames></author><author><keyname>McCreesh</keyname><forenames>Ciaran</forenames></author><author><keyname>Nacenta</keyname><forenames>Miguel A.</forenames></author><author><keyname>Paul</keyname><forenames>Ruma R.</forenames></author><author><keyname>Petrie</keyname><forenames>Karen E. J.</forenames></author><author><keyname>Razaq</keyname><forenames>Abdul</forenames></author><author><keyname>Reijsbergen</keyname><forenames>Dani&#xeb;l</forenames></author><author><keyname>Takeda</keyname><forenames>Kenji</forenames></author></authors><title>Case Studies and Challenges in Reproducibility in the Computational
  Sciences</title><categories>cs.CE cs.DL</categories><comments>This paper was written at the First Summer School on Experimental
  Methodology in Computational Science Research, St Andrews, August 4-8, 2014,
  http://blogs.cs.st-andrews.ac.uk/emcsr2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the reproducibility of computational science research
and identifies key challenges facing the community today. It is the result of
the First Summer School on Experimental Methodology in Computational Science
Research (https://blogs.cs.st-andrews.ac.uk/emcsr2014/).
  First, we consider how to reproduce experiments that involve human subjects,
and in particular how to deal with different ethics requirements at different
institutions. Second, we look at whether parallel and distributed computational
experiments are more or less reproducible than serial ones. Third, we consider
reproducible computational experiments from fields outside computer science.
Our final case study looks at whether reproducibility for one researcher is the
same as for another, by having an author attempt to have others reproduce their
own, reproducible, paper.
  This paper is open, executable and reproducible: the whole process of writing
this paper is captured in the source control repository hosting both the source
of the paper, supplementary codes and data; we are providing setup for several
experiments on which we were working; finally, we try to describe what we have
achieved during the week of the school in a way that others may reproduce (and
hopefully improve) our experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2125</identifier>
 <datestamp>2015-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2125</id><created>2014-08-09</created><updated>2015-09-23</updated><authors><author><keyname>Seiller</keyname><forenames>Thomas</forenames></author></authors><title>A Correspondence between Maximal Abelian Sub-Algebras and Linear Logic
  Fragments</title><categories>math.LO cs.LO</categories><msc-class>03B70, 03F52, 03B47, 46L99, 47N99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a correspondence between a classification of maximal abelian
sub-algebras (MASAs) proposed by Jacques Dixmier and fragments of linear logic.
We expose for this purpose a modified construction of Girard's hyperfinite
geometry of interaction which interprets proofs as operators in a von Neumann
algebra. The expressivity of the logic soundly interpreted in this model is
dependent on properties of a MASA which is a parameter of the interpretation.
We also unveil the essential role played by MASAs in previous geometry of
interaction constructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2129</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2129</id><created>2014-08-09</created><authors><author><keyname>Glenszczyk</keyname><forenames>Anna</forenames></author></authors><title>Negational Fragment of Intuitionistic Control Logic</title><categories>math.LO cs.LO</categories><comments>Draft, 22 pages</comments><msc-class>03B60, 03B20, 03B70 (primary), 03B62 (secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate properties of monadic purely negational fragment of
Intuitionistic Control Logic (ICL). This logic arises from Intuitionistic
Propositional Logic (IPL) by extending language of IPL by additional new
constant for falsum. Having two different falsum constants enables to define
two forms of negation. We analyse implicational relations between negational
monadic formulae and present a poset of non equivalent formulae of this
fragment of ICL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2154</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2154</id><created>2014-08-09</created><updated>2015-03-21</updated><authors><author><keyname>Trujillo-Rasua</keyname><forenames>Rolando</forenames></author><author><keyname>Yero</keyname><forenames>Ismael G.</forenames></author></authors><title>k-Metric Antidimension: a Privacy Measure for Social Graphs</title><categories>math.CO cs.DB</categories><comments>24 pages</comments><msc-class>05C12, 91D30, 05C82, 05C85, 05C90</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G = (V, E)$ be a simple connected graph and $S = \{w_1, \cdots, w_t\}
\subseteq V$ an ordered subset of vertices. The metric representation of a
vertex $u\in V$ with respect to $S$ is the $t$-vector $r(u|S) = (d_G(u, w_1),
\cdots, d_G(u, w_t))$, where $d_G(u, v)$ represents the length of a shortest
$u-v$ path in $G$. The set $S$ is called a resolving set for $G$ if $r(u|S) =
r(v|S)$ implies $u = v$ for every $u, v \in V$. The smallest cardinality of a
resolving set is the metric dimension of $G$. In this article we propose, to
the best of our knowledge, a new problem in Graph Theory that resembles to the
aforementioned metric dimension problem. We call $S$ a $k$-antiresolving set if
$k$ is the largest positive integer such that for every vertex $v \in V-S$
there exist other $k-1$ different vertices $v_1, \cdots, v_{k-1} \in V-S$ with
$r(v|S) = r(v_1|S) = \cdots = r(v_{k-1}|S)$, \emph{i.e.}, $v$ and $v_1, \cdots,
v_{k-1}$ have the same metric representation with respect to $S$. The
$k$-metric antidimension of $G$ is the minimum cardinality among all the
$k$-antiresolving sets for $G$.
  In this article, we introduce a novel privacy measure, named $(k,
\ell)$-anonymity and based on the $k$-metric antidimension problem, aimed at
evaluating the resistance of social graphs to active attacks. We, therefore,
propose a true-biased algorithm for computing the $k$-metric antidimension of
random graphs. The success rate of our algorithm, according to empirical
results, is above $80 \%$ and $90 \%$ when looking for a $k$-antiresolving
basis and a $k$-antiresolving set respectively. We also investigate theoretical
properties of the $k$-antiresolving sets and the $k$-metric antidimension of
graphs. In particular, we focus on paths, cycles, complete bipartite graphs and
trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2156</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2156</id><created>2014-08-09</created><authors><author><keyname>Balakrishnan</keyname><forenames>Sivaraman</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Yu</keyname><forenames>Bin</forenames></author></authors><title>Statistical guarantees for the EM algorithm: From population to
  sample-based analysis</title><categories>math.ST cs.LG stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a general framework for proving rigorous guarantees on the
performance of the EM algorithm and a variant known as gradient EM. Our
analysis is divided into two parts: a treatment of these algorithms at the
population level (in the limit of infinite data), followed by results that
apply to updates based on a finite set of samples. First, we characterize the
domain of attraction of any global maximizer of the population likelihood. This
characterization is based on a novel view of the EM updates as a perturbed form
of likelihood ascent, or in parallel, of the gradient EM updates as a perturbed
form of standard gradient ascent. Leveraging this characterization, we then
provide non-asymptotic guarantees on the EM and gradient EM algorithms when
applied to a finite set of samples. We develop consequences of our general
theory for three canonical examples of incomplete-data problems: mixture of
Gaussians, mixture of regressions, and linear regression with covariates
missing completely at random. In each case, our theory guarantees that with a
suitable initialization, a relatively small number of EM (or gradient EM) steps
will yield (with high probability) an estimate that is within statistical error
of the MLE. We provide simulations to confirm this theoretically predicted
behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2157</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2157</id><created>2014-08-09</created><authors><author><keyname>Christiani</keyname><forenames>Tobias</forenames></author><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>Generating k-independent variables in constant time</title><categories>cs.DS</categories><comments>Accepted to The 55th Annual Symposium on Foundations of Computer
  Science (FOCS 2014). Copyright IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generation of pseudorandom elements over finite fields is fundamental to
the time, space and randomness complexity of randomized algorithms and data
structures. We consider the problem of generating $k$-independent random values
over a finite field $\mathbb{F}$ in a word RAM model equipped with constant
time addition and multiplication in $\mathbb{F}$, and present the first
nontrivial construction of a generator that outputs each value in constant
time, not dependent on $k$. Our generator has period length
$|\mathbb{F}|\,\mbox{poly} \log k$ and uses $k\,\mbox{poly}(\log k) \log
|\mathbb{F}|$ bits of space, which is optimal up to a $\mbox{poly} \log k$
factor. We are able to bypass Siegel's lower bound on the time-space tradeoff
for $k$-independent functions by a restriction to sequential evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2159</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2159</id><created>2014-08-09</created><authors><author><keyname>Ebrahimi</keyname><forenames>Roozbeh</forenames></author><author><keyname>Gao</keyname><forenames>Jie</forenames></author><author><keyname>Ghasemiesfeh</keyname><forenames>Golnaz</forenames></author><author><keyname>Schoenebeck</keyname><forenames>Grant</forenames></author></authors><title>Complex Contagions in Kleinberg's Small World Model</title><categories>cs.DS cs.SI</categories><comments>arXiv admin note: text overlap with arXiv:1404.2668</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex contagions describe diffusion of behaviors in a social network in
settings where spreading requires the influence by two or more neighbors. In a
$k$-complex contagion, a cluster of nodes are initially infected, and
additional nodes become infected in the next round if they have at least $k$
already infected neighbors. It has been argued that complex contagions better
model behavioral changes such as adoption of new beliefs, fashion trends or
expensive technology innovations. This has motivated rigorous understanding of
spreading of complex contagions in social networks. Despite simple contagions
($k=1$) that spread fast in all small world graphs, how complex contagions
spread is much less understood. Previous work~\cite{Ghasemiesfeh:2013:CCW}
analyzes complex contagions in Kleinberg's small world
model~\cite{kleinberg00small} where edges are randomly added according to a
spatial distribution (with exponent $\gamma$) on top of a two dimensional grid
structure. It has been shown in~\cite{Ghasemiesfeh:2013:CCW} that the speed of
complex contagions differs exponentially when $\gamma=0$ compared to when
$\gamma=2$.
  In this paper, we fully characterize the entire parameter space of $\gamma$
except at one point, and provide upper and lower bounds for the speed of
$k$-complex contagions. We study two subtly different variants of Kleinberg's
small world model and show that, with respect to complex contagions, they
behave differently. For each model and each $k \geq 2$, we show that there is
an intermediate range of values, such that when $\gamma$ takes any of these
values, a $k$-complex contagion spreads quickly on the corresponding graph, in
a polylogarithmic number of rounds. However, if $\gamma$ is outside this range,
then a $k$-complex contagion requires a polynomial number of rounds to spread
to the entire network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2172</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2172</id><created>2014-08-09</created><authors><author><keyname>Bonamy</keyname><forenames>Marthe</forenames></author><author><keyname>Charbit</keyname><forenames>Pierre</forenames></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>Graphs with large chromatic number induce $3k$-cycles</title><categories>cs.DM math.CO</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Answering a question of Kalai and Meshulam, we prove that graphs without
induced cycles of length $3k$ have bounded chromatic number. This implies the
very first case of a much broader question asserting that every graph with
large chromatic number induces a graph $H$ such that the sum of the Betti
numbers of the independence complex of $H$ is also large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2192</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2192</id><created>2014-08-10</created><updated>2015-03-22</updated><authors><author><keyname>Jiang</keyname><forenames>Feng</forenames></author><author><keyname>Chen</keyname><forenames>Jie</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author><author><keyname>Lopez-Salcedo</keyname><forenames>Jose A.</forenames></author></authors><title>Massive MIMO for Wireless Sensing with a Coherent Multiple Access
  Channel</title><categories>cs.IT math.IT</categories><comments>32 pages, 6 figures, accepted by IEEE Transactions on Signal
  Processing, Feb. 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the detection and estimation of a zero-mean Gaussian signal in a
wireless sensor network with a coherent multiple access channel, when the
fusion center (FC) is configured with a large number of antennas and the
wireless channels between the sensor nodes and FC experience Rayleigh fading.
For the detection problem, we study the Neyman-Pearson (NP) Detector and Energy
Detector (ED), and find optimal values for the sensor transmission gains. For
the NP detector which requires channel state information (CSI), we show that
detection performance remains asymptotically constant with the number of FC
antennas if the sensor transmit power decreases proportionally with the
increase in the number of antennas. Performance bounds show that the benefit of
multiple antennas at the FC disappears as the transmit power grows. The results
of the NP detector are also generalized to the linear minimum mean squared
error estimator. For the ED which does not require CSI, we derive optimal gains
that maximize the deflection coefficient of the detector, and we show that a
constant deflection can be asymptotically achieved if the sensor transmit power
scales as the inverse square root of the number of FC antennas. Unlike the NP
detector, for high sensor power the multi-antenna ED is observed to empirically
have significantly better performance than the single-antenna implementation. A
number of simulation results are included to validate the analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2195</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2195</id><created>2014-08-10</created><authors><author><keyname>Bouneffouf</keyname><forenames>Djallel</forenames></author></authors><title>R-UCB: a Contextual Bandit Algorithm for Risk-Aware Recommender Systems</title><categories>cs.IR cs.LG</categories><acm-class>I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Context-Aware Recommender Systems can be naturally modelled as an
exploration/exploitation trade-off (exr/exp) problem, where the system has to
choose between maximizing its expected rewards dealing with its current
knowledge (exploitation) and learning more about the unknown user's preferences
to improve its knowledge (exploration). This problem has been addressed by the
reinforcement learning community but they do not consider the risk level of the
current user's situation, where it may be dangerous to recommend items the user
may not desire in her current situation if the risk level is high. We introduce
in this paper an algorithm named R-UCB that considers the risk level of the
user's situation to adaptively balance between exr and exp. The detailed
analysis of the experimental results reveals several important discoveries in
the exr/exp behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2196</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2196</id><created>2014-08-10</created><authors><author><keyname>Bouneffouf</keyname><forenames>Djallel</forenames></author></authors><title>Exponentiated Gradient Exploration for Active Learning</title><categories>cs.LG cs.AI</categories><acm-class>I.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active learning strategies respond to the costly labelling task in a
supervised classification by selecting the most useful unlabelled examples in
training a predictive model. Many conventional active learning algorithms focus
on refining the decision boundary, rather than exploring new regions that can
be more informative. In this setting, we propose a sequential algorithm named
EG-Active that can improve any Active learning algorithm by an optimal random
exploration. Experimental results show a statistically significant and
appreciable improvement in the performance of our new approach over the
existing active feedback methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2207</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2207</id><created>2014-08-10</created><authors><author><keyname>Rad</keyname><forenames>J. A.</forenames></author><author><keyname>Kazem</keyname><forenames>S.</forenames></author><author><keyname>Shaban</keyname><forenames>M.</forenames></author><author><keyname>Parand</keyname><forenames>K.</forenames></author></authors><title>A new operational matrix based on Bernoulli polynomials</title><categories>cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research, the Bernoulli polynomials are introduced. The properties of
these polynomials are employed to construct the operational matrices of
integration together with the derivative and product. These properties are then
utilized to transform the differential equation to a matrix equation which
corresponds to a system of algebraic equations with unknown Bernoulli
coefficients. This method can be used for many problems such as differential
equations, integral equations and so on. Numerical examples show the method is
computationally simple and also illustrate the efficiency and accuracy of the
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2209</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2209</id><created>2014-08-10</created><authors><author><keyname>Rad</keyname><forenames>J. A.</forenames></author><author><keyname>Kazem</keyname><forenames>S.</forenames></author><author><keyname>Parand</keyname><forenames>K.</forenames></author></authors><title>The meshless method for solving radiative transfer problems in a slab
  medium based on radial basis functions</title><categories>cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a numerical meshless method for solving the radiative transfer
equations in a slab medium with an isotropic scattering is considered. The
method is based on radial basis functions to approximate the solution of an
integral-partial differential equation by using collocation method. For this
purpose different applications of RBFs are used. To this end the numerical
solutions are obtained without any mesh generation into the domain of the
problems. The results of numerical experiments are compared with the existing
results in illustrative examples to confirm the accuracy and efficiency of the
presented scheme. Also the norm of the residual functions are obtained to show
the convergence of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2214</identifier>
 <datestamp>2016-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2214</id><created>2014-08-10</created><updated>2016-01-21</updated><authors><author><keyname>Ivanov</keyname><forenames>Mikhail</forenames></author><author><keyname>H&#xe4;ger</keyname><forenames>Christian</forenames></author><author><keyname>Br&#xe4;nnstr&#xf6;m</keyname><forenames>Fredrik</forenames></author><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author><author><keyname>Alvarado</keyname><forenames>Alex</forenames></author><author><keyname>Agrell</keyname><forenames>Erik</forenames></author></authors><title>On the Information Loss of the Max-Log Approximation in BICM Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a comprehensive study of the information rate loss of the max-log
approximation for $M$-ary pulse-amplitude modulation (PAM) in a bit-interleaved
coded modulation (BICM) system. It is widely assumed that the calculation of
L-values using the max-log approximation leads to an information loss. We prove
that this assumption is correct for all $M$-PAM constellations and labelings
with the exception of a symmetric 4-PAM constellation labeled with a Gray code.
We also show that for max-log L-values, the BICM generalized mutual information
(GMI), which is an achievable rate for a standard BICM decoder, is too
pessimistic. In particular, it is proved that the so-called &quot;harmonized&quot; GMI,
which can be seen as the sum of bit-level GMIs, is achievable without any
modifications to the decoder. We then study how bit-level channel
symmetrization and mixing affect the mutual information (MI) and the GMI for
max-log L-values. Our results show that these operations, which are often used
when analyzing BICM systems, preserve the GMI. However, this is not necessarily
the case when the MI is considered. Necessary and sufficient conditions under
which these operations preserve the MI are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2222</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2222</id><created>2014-08-10</created><authors><author><keyname>Chen</keyname><forenames>Yongxin</forenames></author><author><keyname>Georgiou</keyname><forenames>Tryphon</forenames></author><author><keyname>Pavon</keyname><forenames>Michele</forenames></author></authors><title>Optimal steering of a linear stochastic system to a final probability
  distribution</title><categories>cs.SY math-ph math.MP</categories><comments>11 pages, 7 figures</comments><msc-class>93E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem to steer a linear dynamical system with full state
observation from an initial gaussian distribution in state-space to a final one
with minimum energy control. The system is stochastically driven through the
control channels; an example for such a system is that of an inertial particle
experiencing random &quot;white noise&quot; forcing. We show that a target probability
distribution can always be achieved in finite time. The optimal control is
given in state-feedback form and is computed explicitely by solving a pair of
differential Lyapunov equations that are coupled through their boundary values.
This result, given its attractive algorithmic nature, appears to have several
potential applications such as to active control of nanomechanical systems and
molecular cooling. The problem to steer a diffusion process between end-point
marginals has a long history (Schr\&quot;odinger bridges) and therefore, the present
case of steering a linear stochastic system constitutes a Schr\&quot;odinger bridge
for possibly degenerate diffusions. Our results, however, provide the first
implementable form of the optimal control for a general Gauss-Markov process.
Illustrative examples of the optimal evolution and control for inertial
particles and a stochastic oscillator are provided. A final result establishes
directly the property of Schr\&quot;{o}dinger bridges as the most likely random
evolution between given marginals to the present context of linear stochastic
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2232</identifier>
 <datestamp>2015-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2232</id><created>2014-08-10</created><updated>2015-04-10</updated><authors><author><keyname>M&#xfc;ller</keyname><forenames>Axel</forenames></author><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Wagner</keyname><forenames>Sebastian</forenames></author><author><keyname>Debbah</keyname><forenames>M&#xe9;rouane</forenames></author></authors><title>Interference-Aware RZF Precoding for Multi Cell Downlink Systems</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Signal Processing,
  2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a structure of an optimal linear precoder for multi cell downlink
systems has been described in [1, Eq (3.33)]. Other references (e.g., [2,3])
have used simplified versions of the precoder to obtain promising performance
gains. These gains have been hypothesized to stem from the additional degrees
of freedom that allow for interference mitigation through interference
relegation to orthogonal subspaces. However, no conclusive or rigorous
understanding has yet been developed. In this paper, we build on an intuitive
interference induction trade-off and the aforementioned precoding structure to
propose an interference aware RZF (iaRZF) precoding scheme for multi cell
downlink systems and we analyze its rate performance. Special emphasis is
placed on the induced interference mitigation mechanism of iaRZF. For example,
we will verify the intuitive expectation that the precoder structure can either
completely remove induced inter-cell or intra-cell interference. We state new
results from large-scale random matrix theory that make it possible to give
more intuitive and insightful explanations of the precoder behavior, also for
cases involving imperfect channel state information (CSI). We remark especially
that the interference-aware precoder makes use of all available information
about interfering channels to improve performance. Even very poor CSI allows
for significant sum-rate gains. Our obtained insights are then used to propose
heuristic precoder parameters for arbitrary systems, whose effectiveness are
shown in more involved system scenarios. Furthermore, calculation and
implementation of these parameters does not require explicit inter base station
cooperation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2237</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2237</id><created>2014-08-10</created><authors><author><keyname>Rudra</keyname><forenames>Atri</forenames></author><author><keyname>Wootters</keyname><forenames>Mary</forenames></author></authors><title>It'll probably work out: improved list-decoding through random
  operations</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we introduce a framework to study the effect of random
operations on the combinatorial list-decodability of a code. The operations we
consider correspond to row and column operations on the matrix obtained from
the code by stacking the codewords together as columns. This captures many
natural transformations on codes, such as puncturing, folding, and taking
subcodes; we show that many such operations can improve the list-decoding
properties of a code. There are two main points to this. First, our goal is to
advance our (combinatorial) understanding of list-decodability, by
understanding what structure (or lack thereof) is necessary to obtain it.
Second, we use our more general results to obtain a few interesting corollaries
for list decoding:
  (1) We show the existence of binary codes that are combinatorially
list-decodable from $1/2-\epsilon$ fraction of errors with optimal rate
$\Omega(\epsilon^2)$ that can be encoded in linear time.
  (2) We show that any code with $\Omega(1)$ relative distance, when randomly
folded, is combinatorially list-decodable $1-\epsilon$ fraction of errors with
high probability. This formalizes the intuition for why the folding operation
has been successful in obtaining codes with optimal list decoding parameters;
previously, all arguments used algebraic methods and worked only with specific
codes.
  (3) We show that any code which is list-decodable with suboptimal list sizes
has many subcodes which have near-optimal list sizes, while retaining the error
correcting capabilities of the original code. This generalizes recent results
where subspace evasive sets have been used to reduce list sizes of codes that
achieve list decoding capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2242</identifier>
 <datestamp>2015-07-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2242</id><created>2014-08-10</created><updated>2015-07-22</updated><authors><author><keyname>Li</keyname><forenames>Yuanxin</forenames></author><author><keyname>Chi</keyname><forenames>Yuejie</forenames></author></authors><title>Off-the-Grid Line Spectrum Denoising and Estimation with Multiple
  Measurement Vectors</title><categories>cs.IT math.IT math.NA</categories><comments>14 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed Sensing suggests that the required number of samples for
reconstructing a signal can be greatly reduced if it is sparse in a known
discrete basis, yet many real-world signals are sparse in a continuous
dictionary. One example is the spectrally-sparse signal, which is composed of a
small number of spectral atoms with arbitrary frequencies on the unit interval.
In this paper we study the problem of line spectrum denoising and estimation
with an ensemble of spectrally-sparse signals composed of the same set of
continuous-valued frequencies from their partial and noisy observations. Two
approaches are developed based on atomic norm minimization and structured
covariance estimation, both of which can be solved efficiently via semidefinite
programming. The first approach aims to estimate and denoise the set of signals
from their partial and noisy observations via atomic norm minimization, and
recover the frequencies via examining the dual polynomial of the convex
program. We characterize the optimality condition of the proposed algorithm and
derive the expected convergence rate for denoising, demonstrating the benefit
of including multiple measurement vectors. The second approach aims to recover
the population covariance matrix from the partially observed sample covariance
matrix by motivating its low-rank Toeplitz structure without recovering the
signal ensemble. Performance guarantee is derived with a finite number of
measurement vectors. The frequencies can be recovered via conventional spectrum
estimation methods such as MUSIC from the estimated covariance matrix. Finally,
numerical examples are provided to validate the favorable performance of the
proposed algorithms, with comparisons against several existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2260</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2260</id><created>2014-08-10</created><updated>2015-04-20</updated><authors><author><keyname>Solovey</keyname><forenames>Kiril</forenames></author><author><keyname>Halperin</keyname><forenames>Dan</forenames></author></authors><title>On the hardness of unlabeled multi-robot motion planning</title><categories>cs.RO cs.CC cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In unlabeled multi-robot motion planning several interchangeable robots
operate in a common workspace. The goal is to move the robots to a set of
target positions such that each position will be occupied by some robot. In
this paper, we study this problem for the specific case of unit-square robots
moving amidst polygonal obstacles and show that it is PSPACE-hard. We also
consider three additional variants of this problem and show that they are all
PSPACE-hard as well. To the best of our knowledge, this is the first hardness
proof for the unlabeled case. Furthermore, our proofs can be used to show that
the labeled variant (where each robot is assigned with a specific target
position), again, for unit-square robots, is PSPACE-hard as well, which sets
another precedence, as previous hardness results require the robots to be of
different shapes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2270</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2270</id><created>2014-08-10</created><authors><author><keyname>Frostig</keyname><forenames>Roy</forenames></author><author><keyname>Wang</keyname><forenames>Sida I.</forenames></author></authors><title>A sub-constant improvement in approximating the positive semidefinite
  Grothendieck problem</title><categories>cs.DS cs.CC math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semidefinite relaxations are a powerful tool for approximately solving
combinatorial optimization problems such as MAX-CUT and the Grothendieck
problem. By exploiting a bounded rank property of extreme points in the
semidefinite cone, we make a sub-constant improvement in the approximation
ratio of one such problem. Precisely, we describe a polynomial-time algorithm
for the positive semidefinite Grothendieck problem -- based on rounding from
the standard relaxation -- that achieves a ratio of $2/\pi + \Theta(1/{\sqrt
n})$, whereas the previous best is $2/\pi + \Theta(1/n)$. We further show a
corresponding integrality gap of $2/\pi+\tilde{O}(1/n^{1/3})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2277</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2277</id><created>2014-08-10</created><authors><author><keyname>Lafrance</keyname><forenames>Philip</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Yee</keyname><forenames>Randy</forenames></author></authors><title>Some properties of a Rudin-Shapiro-like sequence</title><categories>math.CO cs.FL math.NT</categories><comments>21 pages, 6 figures</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the sequence $(i_n)_{n \geq 0}$ defined by $i_n =
(-1)^{inv_2(n)}$, where $inv_2(n)$ denotes the number of inversions (i.e.,
occurrences of 10 as a scattered subsequence) in the binary representation of
n. We show that this sequence has many similarities to the classical
Rudin-Shapiro sequence. In particular, if S(N) denotes the N-th partial sum of
the sequence $(i_n)_{n \geq 0}$, we show that $S(N) = G(\log_4 N)\sqrt{N}$,
where G is a certain function that oscillates periodically between $\sqrt{3}/3$
and $\sqrt{2}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2279</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2279</id><created>2014-08-10</created><authors><author><keyname>Amir</keyname><forenames>Amihood</forenames></author><author><keyname>Kapah</keyname><forenames>Oren</forenames></author><author><keyname>Kopelowitz</keyname><forenames>Tsvi</forenames></author><author><keyname>Naor</keyname><forenames>Moni</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author></authors><title>The Family Holiday Gathering Problem or Fair and Periodic Scheduling of
  Independent Sets</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce and examine the {\em Holiday Gathering Problem} which models the
difficulty that couples have when trying to decide with which parents should
they spend the holiday. Our goal is to schedule the family gatherings so that
the parents that will be {\em happy}, i.e.\ all their children will be home
{\em simultaneously} for the holiday festivities, while minimizing the number
of consecutive holidays in which parents are not happy.
  The holiday gathering problem is closely related to several classical
problems in computer science, such as the {\em dining philosophers problem} on
a general graph and periodic scheduling,and has applications in scheduling of
transmissions made by cellular radios. We also show interesting connections
between periodic scheduling, coloring, and universal prefix free encodings.
  The combinatorial definition of the Holiday Gathering Problem is: given a
graph $G$, find an infinite sequence of independent-sets of $G$. The objective
function is to minimize, for every node $v$, the maximal gap between two
appearances of $v$. In good solutions this gap depends on local properties of
the node (i.e., its degree) and the the solution should be periodic, i.e.\ a
node appears every fixed number of periods. We show a coloring-based
construction where the period of each node colored with the $c$ is at most
$2^{1+\log^*c}\cdot\prod_{i=0}^{\log^*c} \log^{(i)}c$ (where $\log^{(i)}$ means
iterating the $\log$ function $i$ times). This is achieved via a connection
with {\it prefix-free encodings}. We prove that this is the best possible for
coloring-based solutions. We also show a construction with period at most $2d$
for a node of degree $d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2284</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2284</id><created>2014-08-10</created><authors><author><keyname>Zheng</keyname><forenames>Da</forenames></author><author><keyname>Szalay</keyname><forenames>Alexander</forenames></author><author><keyname>Terzis</keyname><forenames>Andreas</forenames></author></authors><title>Hadoop in Low-Power Processors</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In our previous work we introduced a so-called Amdahl blade microserver that
combines a low-power Atom processor, with a GPU and an SSD to provide a
balanced and energy-efficient system. Our preliminary results suggested that
the sequential I/O of Amdahl blades can be ten times higher than that a cluster
of conventional servers with comparable power consumption. In this paper we
investigate the performance and energy efficiency of Amdahl blades running
Hadoop. Our results show that Amdahl blades are 7.7 times and 3.4 times as
energy-efficient as the Open Cloud Consortium cluster for a data-intensive and
a compute-intensive application, respectively. The Hadoop Distributed
Filesystem has relatively poor performance on Amdahl blades because both disk
and network I/O are CPU-heavy operations on Atom processors. We demonstrate
three effective techniques to reduce CPU consumption and improve performance.
However, even with these improvements, the Atom processor is still the system's
bottleneck. We revisit Amdahl's law, and estimate that Amdahl blades need four
Atom cores to be well balanced for Hadoop tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2287</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2287</id><created>2014-08-10</created><authors><author><keyname>Hasse</keyname><forenames>Cael L.</forenames></author></authors><title>In principle determination of generic priors</title><categories>math.ST cs.AI stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probability theory as extended logic is completed such that essentially any
probability may be determined. This is done by considering propositional logic
(as opposed to predicate logic) as syntactically suffcient and imposing a
symmetry from propositional logic. It is shown how the notions of `possibility'
and `property' may be suffciently represented in propositional logic such that
1) the principle of indifference drops out and becomes essentially combinatoric
in nature and 2) one may appropriately represent assumptions where one assumes
there is a space of possibilities but does not assume the size of the space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2288</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2288</id><created>2014-08-10</created><authors><author><keyname>Valencia</keyname><forenames>Philip</forenames></author><author><keyname>Haak</keyname><forenames>Aiden</forenames></author><author><keyname>Cotillon</keyname><forenames>Alban</forenames></author><author><keyname>Jurdak</keyname><forenames>Raja</forenames></author></authors><title>Genetic Programming for Smart Phone Personalisation</title><categories>cs.NE cs.CY</categories><comments>43 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Personalisation in smart phones requires adaptability to dynamic context
based on user mobility, application usage and sensor inputs. Current
personalisation approaches, which rely on static logic that is developed a
priori, do not provide sufficient adaptability to dynamic and unexpected
context. This paper proposes genetic programming (GP), which can evolve program
logic in realtime, as an online learning method to deal with the highly dynamic
context in smart phone personalisation. We introduce the concept of
collaborative smart phone personalisation through the GP Island Model, in order
to exploit shared context among co-located phone users and reduce convergence
time. We implement these concepts on real smartphones to demonstrate the
capability of personalisation through GP and to explore the benefits of the
Island Model. Our empirical evaluations on two example applications confirm
that the Island Model can reduce convergence time by up to two-thirds over
standalone GP personalisation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2289</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2289</id><created>2014-08-10</created><authors><author><keyname>Li</keyname><forenames>Yi</forenames></author><author><keyname>Wei</keyname><forenames>Qi</forenames></author><author><keyname>Qiao</keyname><forenames>Fei</forenames></author><author><keyname>Yang</keyname><forenames>Huazhong</forenames></author></authors><title>Physical Computing With No Clock to Implement the Gaussian Pyramid of
  SIFT Algorithm</title><categories>cs.CV</categories><comments>6</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Physical computing is a technology utilizing the nature of electronic devices
and circuit topology to cope with computing tasks. In this paper, we propose an
active circuit network to implement multi-scale Gaussian filter, which is also
called Gaussian Pyramid in image preprocessing. Various kinds of methods have
been tried to accelerate the key stage in image feature extracting algorithm
these years. Compared with existing technologies, GPU parallel computing and
FPGA accelerating technology, physical computing has great advantage on
processing speed as well as power consumption. We have verified that processing
time to implement the Gaussian pyramid of the SIFT algorithm stands on
nanosecond level through the physical computing technology, while other
existing methods all need at least hundreds of millisecond. With an estimate on
the stray capacitance of the circuit, the power consumption is around 670pJ to
filter a 256x256 image. To the best of our knowledge, this is the most fast
processing technology to accelerate the SIFT algorithm, and it is also a rather
energy-efficient method, thanks to the proposed physical computing technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2290</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2290</id><created>2014-08-10</created><authors><author><keyname>Ma</keyname><forenames>Shan</forenames></author><author><keyname>Woolley</keyname><forenames>Matthew J.</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author><author><keyname>Yamamoto</keyname><forenames>Naoki</forenames></author></authors><title>Preparation of Pure Gaussian States via Cascaded Quantum Systems</title><categories>quant-ph cs.SY math.OC</categories><comments>A version of this paper will appear in the Proceedings of the 2014
  IEEE Multi-conference on Systems and Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides an alternative approach to the problem of preparing pure
Gaussian states in a linear quantum system. It is shown that any pure Gaussian
state can be generated by a cascade of one-dimensional open quantum harmonic
oscillators, without any direct interaction Hamiltonians between these
oscillators. This is physically advantageous from an experimental point of
view. An example on the preparation of two-mode squeezed states is given to
illustrate the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2292</identifier>
 <datestamp>2015-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2292</id><created>2014-08-10</created><updated>2015-01-11</updated><authors><author><keyname>Sun</keyname><forenames>Jingwei</forenames></author><author><keyname>Sun</keyname><forenames>Guangzhong</forenames></author></authors><title>SPLZ: An Efficient Algorithm for Single Source Shortest Path Problem
  Using Compression Method</title><categories>cs.DS</categories><comments>20 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient solution of the single source shortest path (SSSP) problem on road
networks is an important requirement for numerous real-world applications. This
paper introduces an algorithm for the SSSP problem using compression method.
Owning to precomputing and storing all-pairs shortest path (APSP), the process
of solving SSSP problem is a simple lookup of a little data from precomputed
APSP and decompression. APSP without compression needs at least 1TB memory for
a road network with one million vertices. Our algorithm can compress such an
APSP into several GB, and ensure a good performance of decompression. In our
experiment on a dataset about Northwest USA (with 1.2 millions vertices), our
method can achieve about three orders of magnitude faster than Dijkstra
algorithm based on binary heap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2293</identifier>
 <datestamp>2015-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2293</id><created>2014-08-10</created><updated>2015-07-17</updated><authors><author><keyname>Kennedy</keyname><forenames>Hugh L.</forenames></author></authors><title>Direct Digital Design of Loop-Shaping Filters for Sampled Control
  Systems</title><categories>cs.SY</categories><comments>In addition to the brief journal paper (see v3 comments), this paper
  was split into 2 conference papers: &quot;Numerical Derivation of Fading-Memory
  Polynomial and Sinusoidal Filters for Discrete-Time Control Systems&quot; and
  &quot;Application of Fading-Memory Polynomial Filters to the Control of an
  Electric Motor&quot;, to appear in Proc. 2015 IEEE Multi-Conference on Systems and
  Control</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A controller design technique for shaping the frequency response of a process
is described. A general linear model (GLM) is used to define the form of a lag
or lead compensator in discrete time using a prescribed set of basis functions.
The model is then transformed via the complex z-domain into a difference
equation for a recursive digital filter with an infinite impulse response
(IIR). A polynomial basis set is better for shaping the frequency response in
the near-zero region; whereas a sinusoidal basis set is better for defining the
response at arbitrary frequencies. The proposed compensator design method is
more flexible than existing low-order approaches and more suitable than other
general-purpose high-order methods. Performance of the resulting controller is
compared with digital proportional-integral-differential (PID) and
linear-state-space (LSS) algorithms in a real motor-control application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2294</identifier>
 <datestamp>2015-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2294</id><created>2014-08-10</created><updated>2015-08-25</updated><authors><author><keyname>Kennedy</keyname><forenames>Hugh L.</forenames></author></authors><title>Digital Filter Designs for Recursive Frequency Analysis</title><categories>cs.SY cs.SD</categories><comments>To appear in Journal of Circuits, Systems, and Computers (JCSC).
  Accepted draft version, Aug. 2015. Added summary tables. Expanded Conclusion
  and Summary Section. Fixed a few errors/typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital filters for recursively computing the discrete Fourier transform
(DFT) and estimating the frequency spectrum of sampled signals are examined,
with an emphasis on magnitude-response and numerical stability. In this
tutorial-style treatment, existing recursive techniques are reviewed, explained
and compared within a coherent framework; some fresh insights are provided and
new enhancements/modifications are proposed. It is shown that the replacement
of resonators by (non-recursive) modulators in sliding DFT (SDFT) analyzers
with either a finite impulse response (FIR), or an infinite impulse response
(IIR), does improve performance somewhat; however stability is not guaranteed,
as the cancellation of marginally stable poles by zeros is still involved. The
FIR deadbeat observer is shown to be more reliable than the SDFT methods, an
IIR variant is presented, and ways of fine-tuning its response are discussed. A
novel technique for stabilizing IIR SDFT analyzers with a fading memory, so
that all poles are inside the unit circle, is also derived. Slepian and
sum-of-cosine windows are adapted to improve the frequency responses for the
various FIR and IIR DFT methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2302</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2302</id><created>2014-08-11</created><authors><author><keyname>Orhan</keyname><forenames>Oner</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>Source-Channel Coding under Energy, Delay and Buffer Constraints</title><categories>cs.IT math.IT</categories><comments>30 pages, 15 figures. Submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Source-channel coding for an energy limited wireless sensor node is
investigated. The sensor node observes independent Gaussian source samples with
variances changing over time slots and transmits to a destination over a flat
fading channel. The fading is constant during each time slot. The compressed
samples are stored in a finite size data buffer and need to be delivered in at
most $d$ time slots. The objective is to design optimal transmission policies,
namely, optimal power and distortion allocation, over the time slots such that
the average distortion at destination is minimized. In particular, optimal
transmission policies with various energy constraints are studied. First, a
battery operated system in which sensor node has a finite amount of energy at
the beginning of transmission is investigated. Then, the impact of energy
harvesting, energy cost of processing and sampling are considered. For each
energy constraint, a convex optimization problem is formulated, and the
properties of optimal transmission policies are identified. For the strict
delay case, $d=1$, $2D$ waterfilling interpretation is provided. Numerical
results are presented to illustrate the structure of the optimal transmission
policy, to analyze the effect of delay constraints, data buffer size, energy
harvesting, processing and sampling costs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2303</identifier>
 <datestamp>2015-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2303</id><created>2014-08-11</created><updated>2015-09-01</updated><authors><author><keyname>Trautmann</keyname><forenames>Anna-Lena</forenames></author><author><keyname>Kuijper</keyname><forenames>Margreta</forenames></author></authors><title>Gabidulin Decoding via Minimal Bases of Linearized Polynomial Modules</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how Gabidulin codes can be decoded via parametrization by using
interpolation modules over the ring of linearized polynomials with composition.
Our decoding algorithm computes a list of message words that correspond to all
closest codewords to a given received word. This involves the computation of a
minimal basis for the interpolation module that corresponds to the received
word, followed by a search through the parametrization for valid message words.
Our module-theoretic approach strengthens the link between Gabidulin decoding
and Reed-Solomon decoding. Two subalgorithms are presented to compute the
minimal basis, one iterative, the other an extended Euclidean algorithm. Both
of these subalgorithms have polynomial time complexity. The complexity order of
the overall algorithm, using the parametrization, is then compared to
straightforward exhaustive search as well as to chase list decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2313</identifier>
 <datestamp>2016-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2313</id><created>2014-08-11</created><updated>2016-02-05</updated><authors><author><keyname>Shirazi</keyname><forenames>Sareh</forenames></author><author><keyname>Sanderson</keyname><forenames>Conrad</forenames></author><author><keyname>McCool</keyname><forenames>Chris</forenames></author><author><keyname>Harandi</keyname><forenames>Mehrtash T.</forenames></author></authors><title>Bags of Affine Subspaces for Robust Object Tracking</title><categories>cs.CV cs.MM cs.RO</categories><comments>in International Conference on Digital Image Computing: Techniques
  and Applications, 2015</comments><msc-class>14M15, 54B05</msc-class><acm-class>I.2.10; I.4.8; I.5.4</acm-class><doi>10.1109/DICTA.2015.7371239</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an adaptive tracking algorithm where the object is modelled as a
continuously updated bag of affine subspaces, with each subspace constructed
from the object's appearance over several consecutive frames. In contrast to
linear subspaces, affine subspaces explicitly model the origin of subspaces.
Furthermore, instead of using a brittle point-to-subspace distance during the
search for the object in a new frame, we propose to use a subspace-to-subspace
distance by representing candidate image areas also as affine subspaces.
Distances between subspaces are then obtained by exploiting the non-Euclidean
geometry of Grassmann manifolds. Experiments on challenging videos (containing
object occlusions, deformations, as well as variations in pose and
illumination) indicate that the proposed method achieves higher tracking
accuracy than several recent discriminative trackers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2317</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2317</id><created>2014-08-11</created><authors><author><keyname>Petrosyan</keyname><forenames>Petros A.</forenames></author><author><keyname>Khachatryan</keyname><forenames>Nerses A.</forenames></author></authors><title>Interval Total Colorings of Complete Multipartite Graphs and Hypercubes</title><categories>math.CO cs.DM</categories><comments>17 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A total coloring of a graph $G$ is a coloring of its vertices and edges such
that no adjacent vertices, edges, and no incident vertices and edges obtain the
same color. An interval total $t$-coloring of a graph $G$ is a total coloring
of $G$ with colors $1,\ldots,t$ such that all colors are used, and the edges
incident to each vertex $v$ together with $v$ are colored by $d_{G}(v)+1$
consecutive colors, where $d_{G}(v)$ is the degree of a vertex $v$ in $G$. In
this paper we prove that all complete multipartite graphs with the same number
of vertices in each part are interval total colorable. Moreover, we also give
some bounds for the minimum and the maximum span in interval total colorings of
these graphs. Next, we investigate interval total colorings of hypercubes
$Q_{n}$. In particular, we prove that $Q_{n}$ ($n\geq 3$) has an interval total
$t$-coloring if and only if $n+1\leq t\leq \frac{(n+1)(n+2)}{2}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2320</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2320</id><created>2014-08-11</created><authors><author><keyname>Rassaei</keyname><forenames>Farshad</forenames></author><author><keyname>Soh</keyname><forenames>Wee-Seng</forenames></author><author><keyname>Chua</keyname><forenames>Kee-Chaing</forenames></author></authors><title>A Statistical Modelling and Analysis of Residential Electric Vehicles'
  Charging Demand in Smart Grids</title><categories>cs.CE cs.SY</categories><comments>5 pages, 6 figures. arXiv admin note: substantial text overlap with
  arXiv:1407.1576</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Electric vehicles (EVs) add significant load on the power grid as they become
widespread. The characteristics of this extra load follow the patterns of
people's driving behaviours. In particular, random parameters such as arrival
time and charging time of the vehicles determine their expected charging demand
profile from the power grid. In this paper, we first present a model for
uncoordinated charging power demand of EVs based on a stochastic process and
accordingly we characterize an EV's expected daily power demand profile. Next,
we illustrate it for different charging time distributions through simulations.
This gives us useful insights into the long-term planning for upgrading power
systems' infrastructure to accommodate EVs. Then, we incorporate departure time
as another random variable into this modelling and introduce an autonomous
demand response (DR) technique to manage the EVs' charging demand. Our results
show that, it is possible to accommodate a large number of EVs and achieve the
same peak-to-average ratio (PAR) in daily aggregated power consumption of the
grid as when there is no EV in the system. This peak value can be decreased
further significantly when we add vehicle-to-grid (V2G) capability in the
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2327</identifier>
 <datestamp>2015-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2327</id><created>2014-08-11</created><updated>2015-10-02</updated><authors><author><keyname>Pedregosa</keyname><forenames>Fabian</forenames><affiliation>CEREMADE, PARIETAL</affiliation></author><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>SIERRA, LIENS</affiliation></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames><affiliation>TSI, LTCI</affiliation></author></authors><title>On the Consistency of Ordinal Regression Methods</title><categories>cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many of the ordinal regression models that have been proposed in the
literature can be seen as methods that minimize a convex surrogate of the
zero-one, absolute, or squared loss functions. A key property that allows to
study the statistical implications of such approximations is that of Fisher
consistency. In this paper we will characterize the Fisher consistency of a
rich family of surrogate loss functions used in the context of ordinal
regression, including support vector ordinal regression, ORBoosting and least
absolute deviation. We will see that, for a family of surrogate loss functions
that subsumes support vector ordinal regression and ORBoosting, consistency can
be fully characterized by the derivative of a real-valued function at zero, as
happens for convex margin-based surrogates in binary classification. We also
derive excess risk bounds for a surrogate of the absolute error that generalize
existing risk bounds for binary classification. Finally, our analysis suggests
a novel surrogate of the squared error loss. To prove the empirical performance
of such surrogate, we benchmarked it in terms of cross-validation error on 9
different datasets, where it outperforms competing approaches on 7 out of 9
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2333</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2333</id><created>2014-08-11</created><updated>2014-08-25</updated><authors><author><keyname>Bloem</keyname><forenames>Roderick</forenames></author><author><keyname>Egly</keyname><forenames>Uwe</forenames></author><author><keyname>Klampfl</keyname><forenames>Patrick</forenames></author><author><keyname>Koenighofer</keyname><forenames>Robert</forenames></author><author><keyname>Lonsing</keyname><forenames>Florian</forenames></author></authors><title>SAT-Based Methods for Circuit Synthesis</title><categories>cs.LO</categories><comments>Extended version of a paper at FMCAD'14</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reactive synthesis supports designers by automatically constructing correct
hardware from declarative specifications. Synthesis algorithms usually compute
a strategy, and then construct a circuit that implements it. In this work, we
study SAT- and QBF-based methods for the second step, i.e., computing circuits
from strategies. This includes methods based on QBF-certification,
interpolation, and computational learning. We present optimizations, efficient
implementations, and experimental results for synthesis from safety
specifications, where we outperform BDDs both regarding execution time and
circuit size. This is an extended version of [2], with an additional appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2335</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2335</id><created>2014-08-11</created><updated>2014-12-29</updated><authors><author><keyname>Bi</keyname><forenames>Suzhi</forenames></author><author><keyname>Ho</keyname><forenames>Chin Keong</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Wireless Powered Communication: Opportunities and Challenges</title><categories>cs.NI cs.IT math.IT</categories><comments>Accepted for publication by IEEE Communications Magazine</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The performance of wireless communication is fundamentally constrained by the
limited battery life of wireless devices, whose operations are frequently
disrupted due to the need of manual battery replacement/recharging. The recent
advance in radio frequency (RF) enabled wireless energy transfer (WET)
technology provides an attractive solution named wireless powered communication
(WPC), where the wireless devices are powered by dedicated wireless power
transmitters to provide continuous and stable microwave energy over the air. As
a key enabling technology for truly perpetual communications, WPC opens up the
potential to build a network with larger throughput, higher robustness, and
increased flexibility compared to its battery-powered counterpart. However, the
combination of wireless energy and information transmissions also raises many
new research problems and implementation issues to be addressed. In this
article, we provide an overview of state-of-the-art RF-enabled WET technologies
and their applications to wireless communications, with highlights on the key
design challenges, solutions, and opportunities ahead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2350</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2350</id><created>2014-08-11</created><authors><author><keyname>Amir</keyname><forenames>Amihood</forenames></author><author><keyname>Levy</keyname><forenames>Avivit</forenames></author><author><keyname>Porat</keyname><forenames>Ely</forenames></author><author><keyname>Shalom</keyname><forenames>B. Riva</forenames></author></authors><title>Dictionary Matching with One Gap</title><categories>cs.DS</categories><comments>A preliminary version was published at CPM 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dictionary matching with gaps problem is to preprocess a dictionary $D$
of $d$ gapped patterns $P_1,\ldots,P_d$ over alphabet $\Sigma$, where each
gapped pattern $P_i$ is a sequence of subpatterns separated by bounded
sequences of don't cares. Then, given a query text $T$ of length $n$ over
alphabet $\Sigma$, the goal is to output all locations in $T$ in which a
pattern $P_i\in D$, $1\leq i\leq d$, ends. There is a renewed current interest
in the gapped matching problem stemming from cyber security. In this paper we
solve the problem where all patterns in the dictionary have one gap with at
least $\alpha$ and at most $\beta$ don't cares, where $\alpha$ and $\beta$ are
given parameters. Specifically, we show that the dictionary matching with a
single gap problem can be solved in either $O(d\log d + |D|)$ time and
$O(d\log^{\varepsilon} d + |D|)$ space, and query time $O(n(\beta -\alpha
)\log\log d \log ^2 \min \{ d, \log |D| \} + occ)$, where $occ$ is the number
of patterns found, or preprocessing time and space: $O(d^2 + |D|)$, and query
time $O(n(\beta -\alpha ) + occ)$, where $occ$ is the number of patterns found.
As far as we know, this is the best solution for this setting of the problem,
where many overlaps may exist in the dictionary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2359</identifier>
 <datestamp>2014-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2359</id><created>2014-08-11</created><updated>2014-08-22</updated><authors><author><keyname>Rama</keyname><forenames>Taraka</forenames></author></authors><title>Gap-weighted subsequences for automatic cognate identification and
  phylogenetic inference</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we describe the problem of cognate identification and its
relation to phylogenetic inference. We introduce subsequence based features for
discriminating cognates from non-cognates. We show that subsequence based
features perform better than the state-of-the-art string similarity measures
for the purpose of cognate identification. We use the cognate judgments for the
purpose of phylogenetic inference and observe that these classifiers infer a
tree which is close to the gold standard tree. The contribution of this paper
is the use of subsequence features for cognate identification and to employ the
cognate judgments for phylogenetic inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2362</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2362</id><created>2014-08-11</created><updated>2014-11-16</updated><authors><author><keyname>Yakhontov</keyname><forenames>Sergey V.</forenames></author></authors><title>FP//LINSPACE computability of Riemann zeta function in Ko-Friedman model</title><categories>cs.CC</categories><comments>Sketch of evaluation of complex Riemann zeta function added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, we construct an algorithm for the evaluation of real
Riemann zeta function $\zeta(s)$ for all real $s$, $s&gt;1$, in polynomial time
and linear space on Turing machines in Ko-Friedman model. The algorithms is
based on a series expansion of real Riemann zeta function $\zeta(s)$ (the
series globally convergents) and uses algorithms for the evaluation of real
function $(1+x)^h$ and hypergeometric series in polynomial time and linear
space.
  The algorithm from the present paper modified in an obvious way to work with
the complex numbers can be used to evaluate complex Riemann zeta function
$\zeta(s)$ for $s=\sigma+\mathbf{i}t$, $\sigma\ne 1$ (so, also for the case of
$\sigma&lt;1$), in polynomial time and linear space in $n$ wherein $2^{-n}$ is a
precision of the computation; the modified algorithm will be also polynomial
time and linear space in $\lceil \log_2(t)\rceil$ and exponential time and
exponential space in $\lceil \log_2(\sigma)\rceil$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2364</identifier>
 <datestamp>2014-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2364</id><created>2014-08-11</created><updated>2014-11-17</updated><authors><author><keyname>Yakhontov</keyname><forenames>Sergey V.</forenames></author></authors><title>Notes on space complexity of integration of computable real functions in
  Ko-Friedman model</title><categories>cs.CC</categories><comments>Some additions</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper it is shown that real function $g(x)=\int_{0}^{x}f(t)dt$
is a linear-space computable real function on interval $[0,1]$ if $f$ is a
linear-space computable $C^2[0,1]$ real function on interval $[0,1]$, and this
result does not depend on any open question in the computational complexity
theory. The time complexity of computable real functions and integration of
computable real functions is considered in the context of Ko-Friedman model
which is based on the notion of Cauchy functions computable by Turing machines.
  In addition, a real computable function $f$ is given such that
$\int_{0}^{1}f\in FDSPACE(n^2)_{C[a,b]}$ but $\int_{0}^{1}f\notin FP_{C[a,b]}$
if $FP\ne#P$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2368</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2368</id><created>2014-08-11</created><authors><author><keyname>Shamir</keyname><forenames>Ohad</forenames></author></authors><title>On the Complexity of Bandit Linear Optimization</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the attainable regret for online linear optimization problems with
bandit feedback, where unlike the full-information setting, the player can only
observe its own loss rather than the full loss vector. We show that the price
of bandit information in this setting can be as large as $d$, disproving the
well-known conjecture that the regret for bandit linear optimization is at most
$\sqrt{d}$ times the full-information regret. Surprisingly, this is shown using
&quot;trivial&quot; modifications of standard domains, which have no effect in the
full-information setting. This and other results we present highlight some
interesting differences between full-information and bandit learning, which
were not considered in previous literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2380</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2380</id><created>2014-08-11</created><authors><author><keyname>Li</keyname><forenames>Xiaoyan</forenames></author><author><keyname>Tao</keyname><forenames>Dacheng</forenames></author></authors><title>Video Face Editing Using Temporal-Spatial-Smooth Warping</title><categories>cs.CV cs.AI cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Editing faces in videos is a popular yet challenging aspect of computer
vision and graphics, which encompasses several applications including facial
attractiveness enhancement, makeup transfer, face replacement, and expression
manipulation. Simply applying image-based warping algorithms to video-based
face editing produces temporal incoherence in the synthesized videos because it
is impossible to consistently localize facial features in two frames
representing two different faces in two different videos (or even two
consecutive frames representing the same face in one video). Therefore, high
performance face editing usually requires significant manual manipulation. In
this paper we propose a novel temporal-spatial-smooth warping (TSSW) algorithm
to effectively exploit the temporal information in two consecutive frames, as
well as the spatial smoothness within each frame. TSSW precisely estimates two
control lattices in the horizontal and vertical directions respectively from
the corresponding control lattices in the previous frame, by minimizing a novel
energy function that unifies a data-driven term, a smoothness term, and feature
point constraints. Corresponding warping surfaces then precisely map source
frames to the target frames. Experimental testing on facial attractiveness
enhancement, makeup transfer, face replacement, and expression manipulation
demonstrates that the proposed approaches can effectively preserve spatial
smoothness and temporal coherence in editing facial geometry, skin detail,
identity, and expression, which outperform the existing face editing methods.
In particular, TSSW is robust to subtly inaccurate localization of feature
points and is a vast improvement over image-based warping methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2385</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2385</id><created>2014-08-11</created><authors><author><keyname>Chen</keyname><forenames>Zhixiong</forenames></author><author><keyname>Du</keyname><forenames>Xiaoni</forenames></author><author><keyname>Marzouk</keyname><forenames>Radwa</forenames></author></authors><title>Trace representation of pseudorandom binary sequences derived from Euler
  quotients</title><categories>cs.CR</categories><comments>16 pages</comments><msc-class>94A55, 94A60, 65C10, 11B68</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the trace representation of a family of binary sequences derived from
Euler quotients by determining the corresponding defining polynomials. Trace
representation can help us producing the sequences efficiently and analyzing
their cryptographic properties, such as linear complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2401</identifier>
 <datestamp>2014-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2401</id><created>2014-08-11</created><updated>2014-10-30</updated><authors><author><keyname>Shi</keyname><forenames>Lei</forenames></author><author><keyname>Tong</keyname><forenames>Hanghang</forenames></author><author><keyname>Tang</keyname><forenames>Jie</forenames></author><author><keyname>Lin</keyname><forenames>Chuang</forenames></author></authors><title>Flow-based Influence Graph Visual Summarization</title><categories>cs.SI cs.HC</categories><comments>to appear in IEEE International Conference on Data Mining (ICDM),
  Shen Zhen, China, December 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visually mining a large influence graph is appealing yet challenging. People
are amazed by pictures of newscasting graph on Twitter, engaged by hidden
citation networks in academics, nevertheless often troubled by the unpleasant
readability of the underlying visualization. Existing summarization methods
enhance the graph visualization with blocked views, but have adverse effect on
the latent influence structure. How can we visually summarize a large graph to
maximize influence flows? In particular, how can we illustrate the impact of an
individual node through the summarization? Can we maintain the appealing graph
metaphor while preserving both the overall influence pattern and fine
readability?
  To answer these questions, we first formally define the influence graph
summarization problem. Second, we propose an end-to-end framework to solve the
new problem. Our method can not only highlight the flow-based influence
patterns in the visual summarization, but also inherently support rich graph
attributes. Last, we present a theoretic analysis and report our experiment
results. Both evidences demonstrate that our framework can effectively
approximate the proposed influence graph summarization objective while
outperforming previous methods in a typical scenario of visually mining
academic citation networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2425</identifier>
 <datestamp>2014-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2425</id><created>2014-08-11</created><updated>2014-10-30</updated><authors><author><keyname>Louis</keyname><forenames>Anand</forenames></author></authors><title>Hypergraph Markov Operators, Eigenvalues and Approximation Algorithms</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The celebrated Cheeger's Inequality \cite{am85,a86} establishes a bound on
the expansion of a graph via its spectrum. This inequality is central to a rich
spectral theory of graphs, based on studying the eigenvalues and eigenvectors
of the adjacency matrix (and other related matrices) of graphs. It has remained
open to define a suitable spectral model for hypergraphs whose spectra can be
used to estimate various combinatorial properties of the hypergraph.
  In this paper we introduce a new hypergraph Laplacian operator (generalizing
the Laplacian matrix of graphs)and study its spectra. We prove a Cheeger-type
inequality for hypergraphs, relating the second smallest eigenvalue of this
operator to the expansion of the hypergraph. We bound other hypergraph
expansion parameters via higher eigenvalues of this operator. We give bounds on
the diameter of the hypergraph as a function of the second smallest eigenvalue
of the Laplacian operator. The Markov process underlying the Laplacian operator
can be viewed as a dispersion process on the vertices of the hypergraph that
might be of independent interest. We bound the {\em Mixing-time} of this
process as a function of the second smallest eigenvalue of the Laplacian
operator. All these results are generalizations of the corresponding results
for graphs.
  We show that there can be no linear operator for hypergraphs whose spectra
captures hypergraph expansion in a Cheeger-like manner. For any $k$, we give a
polynomial time algorithm to compute an approximation to the $k^{th}$ smallest
eigenvalue of the operator. We show that this approximation factor is optimal
under the SSE hypothesis (introduced by \cite{rs10}) for constant values of
$k$.
  Finally, using the factor preserving reduction from vertex expansion in
graphs to hypergraph expansion, we show that all our results for hypergraphs
extend to vertex expansion in graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2430</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2430</id><created>2014-08-11</created><authors><author><keyname>Iolis</keyname><forenames>Boris</forenames></author><author><keyname>Bontempi</keyname><forenames>Gianluca</forenames></author></authors><title>Optimizing Component Combination in a Multi-Indexing Paragraph Retrieval
  System</title><categories>cs.IR cs.CL</categories><comments>5 pages, 1 figure, unpublished</comments><msc-class>68T50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate a method to optimize the combination of distinct components in
a paragraph retrieval system. Our system makes use of several indices, query
generators and filters, each of them potentially contributing to the quality of
the returned list of results. The components are combined with a weighed sum,
and we optimize the weights using a heuristic optimization algorithm. This
allows us to maximize the quality of our results, but also to determine which
components are most valuable in our system. We evaluate our approach on the
paragraph selection task of a Question Answering dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2431</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2431</id><created>2014-08-11</created><authors><author><keyname>Grispos</keyname><forenames>George</forenames></author><author><keyname>Glisson</keyname><forenames>William Bradley</forenames></author><author><keyname>Storer</keyname><forenames>Tim</forenames></author></authors><title>Rethinking Security Incident Response: The Integration of Agile
  Principles</title><categories>cs.CR cs.SE</categories><comments>Paper presented at the 20th Americas Conference on Information
  Systems (AMCIS 2014), Savannah, Georgia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In today's globally networked environment, information security incidents can
inflict staggering financial losses on organizations. Industry reports indicate
that fundamental problems exist with the application of current linear
plan-driven security incident response approaches being applied in many
organizations. Researchers argue that traditional approaches value containment
and eradication over incident learning. While previous security incident
response research focused on best practice development, linear plan-driven
approaches and the technical aspects of security incident response, very little
research investigates the integration of agile principles and practices into
the security incident response process. This paper proposes that the
integration of disciplined agile principles and practices into the security
incident response process is a practical solution to strengthening an
organization's security incident response posture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2436</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2436</id><created>2014-08-11</created><authors><author><keyname>Aloupis</keyname><forenames>Greg</forenames></author><author><keyname>Barba</keyname><forenames>Luis</forenames></author><author><keyname>Carmi</keyname><forenames>Paz</forenames></author><author><keyname>Dujmovi&#x107;</keyname><forenames>Vida</forenames></author><author><keyname>Frati</keyname><forenames>Fabrizio</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>Compatible Connectivity-Augmentation of Planar Disconnected Graphs</title><categories>cs.CG</categories><comments>23 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications to graph morphing, we consider the following
\emph{compatible connectivity-augmentation problem}: We are given a labelled
$n$-vertex planar graph, $\mathcal{G}$, that has $r\ge 2$ connected components,
and $k\ge 2$ isomorphic planar straight-line drawings, $G_1,\ldots,G_k$, of
$\mathcal{G}$. We wish to augment $\mathcal G$ by adding vertices and edges to
make it connected in such a way that these vertices and edges can be added to
$G_1,\ldots,G_k$ as points and straight-line segments, respectively, to obtain
$k$ planar straight-line drawings isomorphic to the augmentation of $\mathcal
G$. We show that adding $\Theta(nr^{1-1/k})$ edges and vertices to
$\mathcal{G}$ is always sufficient and sometimes necessary to achieve this
goal. The upper bound holds for all $r\in\{2,\ldots,n\}$ and $k\ge 2$ and is
achievable by an algorithm whose running time is $O(nr^{1-1/k})$ for $k=O(1)$
and whose running time is $O(kn^2)$ for general values of $k$. The lower bound
holds for all $r\in\{2,\ldots,n/4\}$ and $k\ge 2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2447</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2447</id><created>2014-08-08</created><updated>2015-03-23</updated><authors><author><keyname>Vychodil</keyname><forenames>Vilem</forenames></author></authors><title>Fuzzy inequational logic</title><categories>cs.LO cs.AI</categories><msc-class>03B52, 03C05, 03G10</msc-class><acm-class>F.4.1; I.2.3</acm-class><journal-ref>International Journal of Approximate Reasoning 60 (2015) 23-36</journal-ref><doi>10.1016/j.ijar.2015.03.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a logic for reasoning about graded inequalities which generalizes
the ordinary inequational logic used in universal algebra. The logic deals with
atomic predicate formulas of the form of inequalities between terms and
formalizes their semantic entailment and provability in graded setting which
allows to draw partially true conclusions from partially true assumptions. We
follow the Pavelka approach and define general degrees of semantic entailment
and provability using complete residuated lattices as structures of truth
degrees. We prove the logic is Pavelka-style complete. Furthermore, we present
a logic for reasoning about graded if-then rules which is obtained as
particular case of the general result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2466</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2466</id><created>2014-07-14</created><authors><author><keyname>Schwitter</keyname><forenames>Rolf</forenames></author></authors><title>Controlled Natural Language Processing as Answer Set Programming: an
  Experiment</title><categories>cs.CL cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most controlled natural languages (CNLs) are processed with the help of a
pipeline architecture that relies on different software components. We
investigate in this paper in an experimental way how well answer set
programming (ASP) is suited as a unifying framework for parsing a CNL, deriving
a formal representation for the resulting syntax trees, and for reasoning with
that representation. We start from a list of input tokens in ASP notation and
show how this input can be transformed into a syntax tree using an ASP grammar
and then into reified ASP rules in form of a set of facts. These facts are then
processed by an ASP meta-interpreter that allows us to infer new knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2467</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2467</id><created>2014-08-11</created><authors><author><keyname>Takac</keyname><forenames>Martin</forenames></author><author><keyname>Marecek</keyname><forenames>Jakub</forenames></author><author><keyname>Richtarik</keyname><forenames>Peter</forenames></author></authors><title>Inequality-Constrained Matrix Completion: Adding the Obvious Helps!</title><categories>math.OC cs.AI cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose imposing box constraints on the individual elements of the unknown
matrix in the matrix completion problem and present a number of natural
applications, ranging from collaborative filtering under interval uncertainty
to computer vision. Moreover, we design an alternating direction parallel
coordinate descent method (MACO) for a smooth unconstrained optimization
reformulation of the problem. In large scale numerical experiments in
collaborative filtering under uncertainty, our method obtains solution with
considerably smaller errors compared to classical matrix completion with
equalities. We show that, surprisingly, seemingly obvious and trivial
inequality constraints, when added to the formulation, can have a large impact.
This is demonstrated on a number of machine learning problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2468</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2468</id><created>2014-08-11</created><authors><author><keyname>Debattista</keyname><forenames>Jeremy</forenames></author><author><keyname>Lange</keyname><forenames>Christoph</forenames></author><author><keyname>Auer</keyname><forenames>S&#xf6;ren</forenames></author></authors><title>Representing Dataset Quality Metadata using Multi-Dimensional Views</title><categories>cs.DB cs.DL</categories><comments>Preprint of a paper submitted to the forthcoming SEMANTiCS 2014, 4-5
  September 2014, Leipzig, Germany</comments><acm-class>H.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data quality is commonly defined as fitness for use. The problem of
identifying quality of data is faced by many data consumers. Data publishers
often do not have the means to identify quality problems in their data. To make
the task for both stakeholders easier, we have developed the Dataset Quality
Ontology (daQ). daQ is a core vocabulary for representing the results of
quality benchmarking of a linked dataset. It represents quality metadata as
multi-dimensional and statistical observations using the Data Cube vocabulary.
Quality metadata are organised as a self-contained graph, which can, e.g., be
embedded into linked open datasets. We discuss the design considerations, give
examples for extending daQ by custom quality metrics, and present use cases
such as analysing data versions, browsing datasets by quality, and link
identification. We finally discuss how data cube visualisation tools enable
data publishers and consumers to analyse better the quality of their data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2473</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2473</id><created>2014-06-25</created><authors><author><keyname>Hou</keyname><forenames>Qing-Hu</forenames></author><author><keyname>Wang</keyname><forenames>Rong-Hua</forenames></author></authors><title>An Algorithm for Deciding the Summability of Bivariate Rational
  Functions</title><categories>cs.SC math.CA</categories><comments>18 pages</comments><msc-class>33F10, 39A04, 68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\Delta_x f(x,y)=f(x+1,y)-f(x,y)$ and $\Delta_y f(x,y)=f(x,y+1)-f(x,y)$
be the difference operators with respect to $x$ and $y$. A rational function
$f(x,y)$ is called summable if there exist rational functions $g(x,y)$ and
$h(x,y)$ such that $f(x,y)=\Delta_x g(x,y) + \Delta_y h(x,y)$. Recently, Chen
and Singer presented a method for deciding whether a rational function is
summable. To implement their method in the sense of algorithms, we need to
solve two problems. The first is to determine the shift equivalence of two
bivariate polynomials. We solve this problem by presenting an algorithm for
computing the dispersion sets of any two bivariate polynomials. The second is
to solve a univariate difference equation in an algebraically closed field. By
considering the irreducible factorization of the denominator of $f(x,y)$ in a
general field, we present a new criterion which requires only finding a
rational solution of a bivariate difference equation. This goal can be achieved
by deriving a universal denominator of the rational solutions and a degree
bound on the numerator. Combining these two algorithms, we can decide the
summability of a bivariate rational function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2476</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2476</id><created>2014-08-11</created><authors><author><keyname>Burrows</keyname><forenames>Alison</forenames></author><author><keyname>Gooberman-Hill</keyname><forenames>Rachel</forenames></author><author><keyname>Craddock</keyname><forenames>Ian</forenames></author><author><keyname>Coyle</keyname><forenames>David</forenames></author></authors><title>Sensors for healthcare: Would you want them in your home?</title><categories>cs.HC cs.CY</categories><comments>Positions paper presented at the ACM CHI 2014 workshop on Enabling
  Empathy in Health &amp; Care: Design Methods &amp; Challenges</comments><acm-class>H.5.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes some of the challenges set within SPHERE, a large-scale
Interdisciplinary Research Collaboration that aims to develop sensor systems to
monitor people's health and wellbeing in the home. In particular we discuss the
dual task facing the User- Centered Design research group, to ensure the
development of inclusive and desirable domestic healthcare technology. On the
one hand, we seek to gain a rich understanding of the many envisaged users of
the SPHERE system. On the other hand, for the user experience requirements to
be translated into tangible outputs, it is crucial that we effectively
communicate these findings to the broader team of SPHERE engineers and computer
scientists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2478</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2478</id><created>2014-08-11</created><authors><author><keyname>Gori</keyname><forenames>Marco</forenames></author><author><keyname>Lippi</keyname><forenames>Marco</forenames></author><author><keyname>Maggini</keyname><forenames>Marco</forenames></author><author><keyname>Melacci</keyname><forenames>Stefano</forenames></author></authors><title>Learning to see like children: proof of concept</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last few years we have seen a growing interest in machine learning
approaches to computer vision and, especially, to semantic labeling. Nowadays
state of the art systems use deep learning on millions of labeled images with
very successful results on benchmarks, though it is unlikely to expect similar
results in unrestricted visual environments. Most learning schemes essentially
ignore the inherent sequential structure of videos: this might be a critical
issue, since any visual recognition process is remarkably more complex when
shuffling video frames. Based on this remark, we propose a re-foundation of the
communication protocol between visual agents and the environment, which is
referred to as learning to see like children. Like for human interaction,
visual concepts are acquired by the agents solely by processing their own
visual stream along with human supervisions on selected pixels. We give a proof
of concept that remarkable semantic labeling can emerge within this protocol by
using only a few supervised examples. This is made possible by exploiting a
constraint of motion coherent labeling that virtually offers tons of
supervisions. Additional visual constraints, including those associated with
object supervisions, are used within the context of learning from constraints.
The framework is extended in the direction of lifelong learning, so as our
visual agents live in their own visual environment without distinguishing
learning and test set. Learning takes place in deep architectures under a
progressive developmental scheme. In order to evaluate our Developmental Visual
Agents (DVAs), in addition to classic benchmarks, we open the doors of our lab,
allowing people to evaluate DVAs by crowd-sourcing. Such assessment mechanism
might result in a paradigm shift in methodologies and algorithms for computer
vision, encouraging truly novel solutions within the proposed framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2504</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2504</id><created>2014-08-11</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author><author><keyname>Zhang</keyname><forenames>Cun-Hui</forenames></author></authors><title>Compressed Sensing with Very Sparse Gaussian Random Projections</title><categories>stat.ME cs.DS cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the use of very sparse random projections for compressed sensing
(sparse signal recovery) when the signal entries can be either positive or
negative. In our setting, the entries of a Gaussian design matrix are randomly
sparsified so that only a very small fraction of the entries are nonzero. Our
proposed decoding algorithm is simple and efficient in that the major cost is
one linear scan of the coordinates. We have developed two estimators: (i) the
{\em tie estimator}, and (ii) the {\em absolute minimum estimator}. Using only
the tie estimator, we are able to recover a $K$-sparse signal of length $N$
using $1.551 eK \log K/\delta$ measurements (where $\delta\leq 0.05$ is the
confidence). Using only the absolute minimum estimator, we can detect the
support of the signal using $eK\log N/\delta$ measurements. For a particular
coordinate, the absolute minimum estimator requires fewer measurements (i.e.,
with a constant $e$ instead of $1.551e$). Thus, the two estimators can be
combined to form an even more practical decoding framework.
  Prior studies have shown that existing one-scan (or roughly one-scan)
recovery algorithms using sparse matrices would require substantially more
(e.g., one order of magnitude) measurements than L1 decoding by linear
programming, when the nonzero entries of signals can be either negative or
positive. In this paper, following a known experimental setup, we show that, at
the same number of measurements, the recovery accuracies of our proposed method
are (at least) similar to the standard L1 decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2512</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2512</id><created>2014-08-11</created><authors><author><keyname>Gabora</keyname><forenames>Liane</forenames></author><author><keyname>Tseng</keyname><forenames>Simon</forenames></author></authors><title>Computational Evidence that Self-regulation of Creativity is Good for
  Society</title><categories>cs.CY q-bio.NC</categories><comments>6 pages. arXiv admin note: substantial text overlap with
  arXiv:1310.4753</comments><journal-ref>Proceedings of the 36th Annual Meeting of the Cognitive Science
  Society (pp. 2240-2245). Houston TX: Cognitive Science Society</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Excess individual creativity can be detrimental to society because creators
invest in unproven ideas at the expense of propagating proven ones. Moreover, a
proportion of individuals can benefit from creativity without being creative
themselves by copying creators. We hypothesized that (1) societies increase
their rate of cultural evolution by tempering the novelty-generating effects of
creativity with the novelty-preserving effects of imitation, and (2) this is
carried out by selectively rewarding and punishing creativity according to the
value of the individuals' creative outputs. We tested this using an agent-based
model of cultural evolution in which each agent self-regulated its
invention-to-imitation ratio as a function of the fitness of its cultural
outputs. In self-regulating societies, agents segregated into creators and
imitators. The mean fitness of cultural outputs was higher than in
non-self-regulating societies, and changes in diversity were rapider and more
pronounced. We discuss limitations and possible social implications of our
findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2529</identifier>
 <datestamp>2015-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2529</id><created>2014-08-11</created><updated>2015-02-24</updated><authors><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Markovich</keyname><forenames>Natalia M.</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Sreedharan</keyname><forenames>Jithin K.</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Distribution and Dependence of Extremes in Network Sampling Processes</title><categories>cs.SI cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore the dependence structure in the sampled sequence of large
networks. We consider randomized algorithms to sample the nodes and study
extremal properties in any associated stationary sequence of characteristics of
interest like node degrees, number of followers or income of the nodes in
Online Social Networks etc, which satisfy two mixing conditions. Several useful
extremes of the sampled sequence like $k$th largest value, clusters of
exceedances over a threshold, first hitting time of a large value etc are
investigated. We abstract the dependence and the statistics of extremes into a
single parameter that appears in Extreme Value Theory, called extremal index
(EI). In this work, we derive this parameter analytically and also estimate it
empirically. We propose the use of EI as a parameter to compare different
sampling procedures. As a specific example, degree correlations between
neighboring nodes are studied in detail with three prominent random walks as
sampling techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2539</identifier>
 <datestamp>2015-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2539</id><created>2014-08-11</created><updated>2015-04-24</updated><authors><author><keyname>Cai</keyname><forenames>Yang</forenames></author><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author><author><keyname>Papadimitriou</keyname><forenames>Christos H.</forenames></author></authors><title>Optimum Statistical Estimation with Strategic Data Sources</title><categories>stat.ML cs.GT cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an optimum mechanism for providing monetary incentives to the data
sources of a statistical estimator such as linear regression, so that high
quality data is provided at low cost, in the sense that the sum of payments and
estimation error is minimized. The mechanism applies to a broad range of
estimators, including linear and polynomial regression, kernel regression, and,
under some additional assumptions, ridge regression. It also generalizes to
several objectives, including minimizing estimation error subject to budget
constraints. Besides our concrete results for regression problems, we
contribute a mechanism design framework through which to design and analyze
statistical estimators whose examples are supplied by workers with cost for
labeling said examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2551</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2551</id><created>2014-08-11</created><authors><author><keyname>Nayyar</keyname><forenames>Ashutosh</forenames></author><author><keyname>Lessard</keyname><forenames>Laurent</forenames></author></authors><title>Optimal Control for LQG Systems on Graphs---Part I: Structural Results</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this two-part paper, we identify a broad class of decentralized
output-feedback LQG systems for which the optimal control strategies have a
simple intuitive estimation structure and can be computed efficiently. Roughly,
we consider the class of systems for which the coupling of dynamics among
subsystems and the inter-controller communication is characterized by the same
directed graph. Furthermore, this graph is assumed to be a multitree, that is,
its transitive reduction can have at most one directed path connecting each
pair of nodes. In this first part, we derive sufficient statistics that may be
used to aggregate each controller's growing available information. Each
controller must estimate the states of the subsystems that it affects (its
descendants) as well as the subsystems that it observes (its ancestors). The
optimal control action for a controller is a linear function of the estimate it
computes as well as the estimates computed by all of its ancestors. Moreover,
these state estimates may be updated recursively, much like a Kalman filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2552</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2552</id><created>2014-08-11</created><authors><author><keyname>Deshwar</keyname><forenames>Amit G.</forenames></author><author><keyname>Vembu</keyname><forenames>Shankar</forenames></author><author><keyname>Morris</keyname><forenames>Quaid</forenames></author></authors><title>Comparing Nonparametric Bayesian Tree Priors for Clonal Reconstruction
  of Tumors</title><categories>q-bio.PE cs.LG stat.ML</categories><comments>Preprint of an article submitted for consideration in the Pacific
  Symposium on Biocomputing \c{opyright} 2015; World Scientific Publishing Co.,
  Singapore, 2015; http://psb.stanford.edu/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical machine learning methods, especially nonparametric Bayesian
methods, have become increasingly popular to infer clonal population structure
of tumors. Here we describe the treeCRP, an extension of the Chinese restaurant
process (CRP), a popular construction used in nonparametric mixture models, to
infer the phylogeny and genotype of major subclonal lineages represented in the
population of cancer cells. We also propose new split-merge updates tailored to
the subclonal reconstruction problem that improve the mixing time of Markov
chains. In comparisons with the tree-structured stick breaking prior used in
PhyloSub, we demonstrate superior mixing and running time using the treeCRP
with our new split-merge procedures. We also show that given the same number of
samples, TSSB and treeCRP have similar ability to recover the subclonal
structure of a tumor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2564</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2564</id><created>2014-08-11</created><authors><author><keyname>Nyamawe</keyname><forenames>Ally S.</forenames></author></authors><title>A Proposed Framework for Development of a Visualizer Based on Memory
  Transfer Language (MTL)</title><categories>cs.PL</categories><comments>5 Pages, 15 Figures, Published with International Journal of Computer
  Trends and Technology (IJCTT)</comments><doi>10.14445/22312803/IJCTT-V13P136</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Computer programming is among the fundamental aspects of computer science
curriculum. Many students first introduced to introductory computer programming
courses experience difficulties in learning and comprehending. Vast amount of
researches have revealed that, generally programming courses are regarded as
difficult and challenging and thus often have the highest dropout rates.
Moreover, numerous researches have devoted in delivering new approaches and
tools in enhancing the process of teaching and learning computer programming to
novice programmers. One among the tools that have emerged to offer positive
results is Program Visualization tool (Visualizer). Visualizers have shown
remarkable contributions in facilitating novices to learn and comprehend
computer programming. In addition to that, an approach to visualize codes
execution, Memory Transfer Language (MTL), allows a novice to animate the code
through paper and pencil mechanism without actively involving the machine. MTL
depends on the concepts of RAM (Random Access Memory) to interpret the code
line by line. Programming requires effort and special approach in the way it is
learned and taught, thus this paper aimed at presenting a proposed framework
for developing a visualizer that employs the use of MTL to enhance teaching and
learning programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2572</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2572</id><created>2014-08-11</created><authors><author><keyname>Teng</keyname><forenames>Fei</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author><author><keyname>Honig</keyname><forenames>Michael L.</forenames></author></authors><title>Sharing of Unlicensed Spectrum by Strategic Operators</title><categories>cs.IT cs.GT math.IT</categories><comments>This paper was submitted to 2014 GlobalSIP Symposium on Game Theory
  for Signal Processing and Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Facing the challenge of providing sufficient network capacity for wireless
data, the industry is currently debating how to take advantage of hundreds of
megahertz of unlicensed spectrum. One specific proposal being considered by the
3GPP is to retool and deploy Long Term Evolution (LTE) technologies in
unlicensed bands. This paper studies the fundamental questions of whether and
how the unlicensed spectrum can be shared by intrinsically selfish operators.
Because the operators can be strategic, the questions is studied in a game
theoretic setting. A mechanism is proposed for operators to share the spectrum
in a given area and reach a subgame perfect Nash equilibrium, so that any
operator will only suffer loss by unilaterally deviating from the equilibrium.
It is shown that the number of strategic operators willing to invest is limited
due to entry barriers and externalities. These results suggest spectrum sharing
mechanisms for the deployment of LTE in unlicensed bands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2584</identifier>
 <datestamp>2015-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2584</id><created>2014-08-11</created><updated>2014-10-13</updated><authors><author><keyname>Haarmann</keyname><forenames>Jason</forenames></author><author><keyname>Murphy</keyname><forenames>Meg P.</forenames></author><author><keyname>Peters</keyname><forenames>Casey S.</forenames></author><author><keyname>Staecker</keyname><forenames>P. Christopher</forenames></author></authors><title>Homotopy equivalence of finite digital images</title><categories>math.GN cs.CG cs.CV</categories><comments>major fixes and removal of errors, terminology changes</comments><msc-class>55P10, 68R10</msc-class><acm-class>I.4.m</acm-class><journal-ref>Journal of Mathematical Imaging and Vision 53, Issue 3, p 288-302,
  2015</journal-ref><doi>10.1007/s10851-015-0578-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For digital images, there is an established homotopy equivalence relation
which parallels that of classical topology. Many classical homotopy equivalence
invariants, such as the Euler characteristic and the homology groups, do not
remain invariants in the digital setting. This paper develops a numerical
digital homotopy invariant and begins to catalog all possible connected digital
images on a small number of points, up to homotopy equivalence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2590</identifier>
 <datestamp>2015-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2590</id><created>2014-08-11</created><updated>2015-01-16</updated><authors><author><keyname>Kennedy</keyname><forenames>Hugh L.</forenames></author></authors><title>Multidimensional Digital Filters for Point-Target Detection in Cluttered
  Infrared Scenes</title><categories>cs.CV</categories><comments>Accepted version</comments><journal-ref>J. Electron. Imaging. 23 (6), 063019 (December 17, 2014)</journal-ref><doi>10.1117/1.JEI.23.6.063019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 3-D spatiotemporal prediction-error filter (PEF), is used to enhance
foreground/background contrast in (real and simulated) sensor image sequences.
Relative velocity is utilized to extract point-targets that would otherwise be
indistinguishable on spatial frequency alone. An optical-flow field is
generated using local estimates of the 3-D autocorrelation function via the
application of the fast Fourier transform (FFT) and inverse FFT. Velocity
estimates are then used to tune in a background-whitening PEF that is matched
to the motion and texture of the local background. Finite-impulse-response
(FIR) filters are designed and implemented in the frequency domain. An
analytical expression for the frequency response of velocity-tuned FIR filters,
of odd or even dimension, with an arbitrary delay in each dimension, is
derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2592</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2592</id><created>2014-08-11</created><authors><author><keyname>Dehkordi</keyname><forenames>Hooman Reisi</forenames></author><author><keyname>Frati</keyname><forenames>Fabrizio</forenames></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author></authors><title>Increasing-Chord Graphs On Point Sets</title><categories>cs.CG cs.DM</categories><comments>Accepted at GD '14</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the problem of constructing increasing-chord graphs spanning point
sets. We prove that, for every point set P with n points, there exists an
increasing-chord planar graph with O(n) Steiner points spanning P. Further, we
prove that, for every convex point set P with n points, there exists an
increasing-chord graph with O(n log n) edges (and with no Steiner points)
spanning P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2595</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2595</id><created>2014-08-11</created><authors><author><keyname>Chimani</keyname><forenames>Markus</forenames></author><author><keyname>Di Battista</keyname><forenames>Giuseppe</forenames></author><author><keyname>Frati</keyname><forenames>Fabrizio</forenames></author><author><keyname>Klein</keyname><forenames>Karsten</forenames></author></authors><title>Advances on Testing C-Planarity of Embedded Flat Clustered Graphs</title><categories>cs.DS cs.CG cs.DM</categories><comments>Accepted at GD '14</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show a polynomial-time algorithm for testing c-planarity of embedded flat
clustered graphs with at most two vertices per cluster on each face.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2597</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2597</id><created>2014-08-11</created><updated>2015-03-01</updated><authors><author><keyname>Xu</keyname><forenames>Yangyang</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author></authors><title>Block stochastic gradient iteration for convex and nonconvex
  optimization</title><categories>math.OC cs.LG cs.NA math.NA stat.ML</categories><msc-class>90C06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The stochastic gradient (SG) method can minimize an objective function
composed of a large number of differentiable functions, or solve a stochastic
optimization problem, to a moderate accuracy. The block coordinate
descent/update (BCD) method, on the other hand, handles problems with multiple
blocks of variables by updating them one at a time; when the blocks of
variables are easier to update individually than together, BCD has a lower
per-iteration cost. This paper introduces a method that combines the features
of SG and BCD for problems with many components in the objective and with
multiple (blocks of) variables.
  Specifically, a block stochastic gradient (BSG) method is proposed for
solving both convex and nonconvex programs. At each iteration, BSG approximates
the gradient of the differentiable part of the objective by randomly sampling a
small set of data or sampling a few functions from the sum term in the
objective, and then, using those samples, it updates all the blocks of
variables in either a deterministic or a randomly shuffled order. Its
convergence for both convex and nonconvex cases are established in different
senses. In the convex case, the proposed method has the same order of
convergence rate as the SG method. In the nonconvex case, its convergence is
established in terms of the expected violation of a first-order optimality
condition. The proposed method was numerically tested on problems including
stochastic least squares and logistic regression, which are convex, as well as
low-rank tensor recovery and bilinear logistic regression, which are nonconvex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2604</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2604</id><created>2014-08-11</created><authors><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author><author><keyname>Roytman</keyname><forenames>Alan</forenames></author></authors><title>Universal Streaming</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a stream of data, a typical approach in streaming algorithms is to
design a sophisticated algorithm with small memory that computes a specific
statistic over the streaming data. Usually, if one wants to compute a different
statistic after the stream is gone, it is impossible. But what if we want to
compute a different statistic after the fact? In this paper, we consider the
following fascinating possibility: can we collect some small amount of specific
data during the stream that is &quot;universal,&quot; i.e., where we do not know anything
about the statistics we will want to later compute, other than the guarantee
that had we known the statistic ahead of time, it would have been possible to
do so with small memory? In other words, is it possible to collect some data in
small space during the stream, such that any other statistic that can be
computed with comparable space can be computed after the fact? This is indeed
what we introduce (and show) in this paper with matching upper and lower
bounds: we show that it is possible to collect universal statistics of
polylogarithmic size, and prove that these universal statistics allow us after
the fact to compute all other statistics that are computable with similar
amounts of memory. We show that this is indeed possible, both for the standard
unbounded streaming model and the sliding window streaming model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2607</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2607</id><created>2014-08-11</created><authors><author><keyname>Dietrich</keyname><forenames>Jens</forenames></author><author><keyname>Jezek</keyname><forenames>Kamil</forenames></author><author><keyname>Brada</keyname><forenames>Premek</forenames></author></authors><title>What Java Developers Know About Compatibility, And Why This Matters</title><categories>cs.SE</categories><acm-class>D.2.2; D.2.4; D.2.7; D.2.9; D.2.13; D.3.3; D.4.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real-world programs are neither monolithic nor static -- they are constructed
using platform and third party libraries, and both programs and libraries
continuously evolve in response to change pressure. In case of the Java
language, rules defined in the Java Language and Java Virtual Machine
Specifications define when library evolution is safe. These rules distinguish
between three types of compatibility - binary, source and behavioural. We claim
that some of these rules are counter intuitive and not well-understood by many
developers. We present the results of a survey where we quizzed developers
about their understanding of the various types of compatibility. 414 developers
responded to our survey. We find that while most programmers are familiar with
the rules of source compatibility, they generally lack knowledge about the
rules of binary and behavioural compatibility. This can be problematic when
organisations switch from integration builds to technologies that require
dynamic linking, such as OSGi. We have assessed the gravity of the problem by
studying how often linkage-related problems are referenced in issue tracking
systems, and find that they are common.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2621</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2621</id><created>2014-08-12</created><authors><author><keyname>Huang</keyname><forenames>Kechao</forenames></author><author><keyname>Mitchell</keyname><forenames>David G. M.</forenames></author><author><keyname>Wei</keyname><forenames>Lai</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author><author><keyname>Costello</keyname><forenames>Daniel J.</forenames><suffix>Jr</suffix></author></authors><title>Performance Comparison of LDPC Block and Spatially Coupled Codes over
  GF(q)</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we compare the finite-length performance of protograph-based
spatially coupled low-density parity-check (SC-LDPC) codes and LDPC block codes
(LDPC-BCs) over GF(q). In order to reduce computational complexity and latency,
a sliding window decoder with a stopping rule based on a soft bit-error-rate
(BER) estimate is used for the q-ary SC-LDPC codes. Two regimes are considered:
one when the constraint length of q-ary SC-LDPC codes is equal to the block
length of q-ary LDPC-BCs and the other when the two decoding latencies are
equal. Simulation results confirm that, in both regimes, (3,6)-, (3,9)-, and
(3,12)-regular non-binary SC-LDPC codes can significantly outperform both
binary and non-binary LDPC-BCs and binary SC-LDPC codes. Finally, we present a
computational complexity comparison of q-ary SC-LDPC codes and q-ary LDPC-BCs
under equal decoding latency and equal decoding performance assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2626</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2626</id><created>2014-08-12</created><authors><author><keyname>Chi</keyname><forenames>Yang</forenames></author><author><keyname>Agrawal</keyname><forenames>Dharma P.</forenames></author></authors><title>TCP-Forward: Fast and Reliable TCP Variant for Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The congestion control algorithms in TCP may incur inferior performance in a
lossy network context like wireless networks. Previous works have shown that
random linear network coding can improve the throughput of TCP in such
networks, although it introduces extra decoding delay at the destination. In
this paper we try to alleviate the decoding delay by replacing random linear
network coding with LT Codes. Due to the inherent difference between linear
network coding and Fountain Codes, such replacement is not as simple as it
sounds. We conquer some practical problems and come up with TCP-Forward, a new
TCP variant which offers many properties that TCP as a streaming transport
protocol should offer. Our performance evaluation shows TCP-Forward provides
better performance than previous works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2632</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2632</id><created>2014-08-12</created><authors><author><keyname>Khan</keyname><forenames>Riaz A</forenames></author><author><keyname>Mir</keyname><forenames>Ajaz Hussain</forenames></author></authors><title>A Study of Network Based Mobility Management Schemes, 6LoWPAN Mobility,
  Open Issues and Proposed Solutions</title><categories>cs.NI</categories><comments>The document has single lined spaces with 45 pages, 10 figures and 2
  tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Nodes (SNs), the key elements for building Internet of Things
(IOT), have been deployed widely in order to get and transmit information over
the internet. With the introduction of IPv6 over Low Power Wireless Personal
Area Network (6LoWPAN), it is possible to connect these constrained devices to
IPv6 Networks and transmit IPv6 packets. The sensor nodes are being
deployed/installed on many objects and some of them are mobile (moving)
including mobile gadgets, physical objects (living or non-living) etc. These
mobile objects require sufficient Mobility Management Schemes to take care of
data transmission. Host based mobility protocols; MIPv6 and its extensions are
not suitable for these resource constrained devices. In this paper our focus is
to study PMIPv6 based mobility management and different Scenarios based on it
along with sensor devices. Existing research has made many improvements in
terms of HO latency but less attention has paid towards signaling cost and
packet loss particularly in time critical areas. The study provides the
complete survey of network based mobility management schemes, 6LoWPAN mobility,
challenges associated with them and solutions to meet these challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2639</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2639</id><created>2014-08-12</created><authors><author><keyname>Francis</keyname><forenames>Mathew</forenames></author><author><keyname>Hell</keyname><forenames>Pavol</forenames></author><author><keyname>Stacho</keyname><forenames>Juraj</forenames></author></authors><title>Forbidden structure characterization of circular-arc graphs and a
  certifying recognition algorithm</title><categories>cs.DM math.CO</categories><comments>26 pages, 3 figures</comments><msc-class>05C62, 05C85, 68R10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A circular-arc graph is the intersection graph of arcs of a circle. It is a
well-studied graph model with numerous natural applications. A certifying
algorithm is an algorithm that outputs a certificate, along with its answer (be
it positive or negative), where the certificate can be used to easily justify
the given answer. While the recognition of circular-arc graphs has been known
to be polynomial since the 1980s, no polynomial-time certifying recognition
algorithm is known to date, despite such algorithms being found for many
subclasses of circular-arc graphs. This is largely due to the fact that a
forbidden structure characterization of circular-arc graphs is not known, even
though the problem has been intensely studied since the seminal work of Klee in
the 1960s.
  In this contribution, we settle this problem. We present the first forbidden
structure characterization of circular-arc graphs. Our obstruction has the form
of mutually avoiding walks in the graph. It naturally extends a similar
obstruction that characterizes interval graphs. As a consequence, we give the
first polynomial-time certifying algorithm for the recognition of circular-arc
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2657</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2657</id><created>2014-08-12</created><authors><author><keyname>Fourestey</keyname><forenames>Gilles</forenames></author><author><keyname>Cumming</keyname><forenames>Ben</forenames></author><author><keyname>Gilly</keyname><forenames>Ladina</forenames></author><author><keyname>Schulthess</keyname><forenames>Thomas C.</forenames></author></authors><title>First Experiences With Validating and Using the Cray Power Management
  Database Tool</title><categories>cs.DC</categories><comments>This paper was presented at the 2014 Cray User Group (CUG) user
  meeting in Lugano, Switzerland,First Experiences With Validating and Using
  the Cray Power Management Database Tool, Gilles Fourestey and Ben Cumming and
  Ladina Gilly, Proceedings of the CUG meeting, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In October 2013 CSCS installed the first hybrid Cray XC-30 system, dubbed Piz
Daint. This system features the power management database (PMDB), that was
recently introduced by Cray to collect detailed power consumption information
in a non-intrusive manner. Power measurements are taken on each node, with
additional measurements for the Aries network and blowers, and recorded in a
database. This enables fine-grained reporting of power consumption that is not
possible with external power meters, and is useful to both application
developers and facility operators. This paper will show how benchmarks of
representative applications at CSCS were used to validate the PMDB on Piz
Daint. Furthermore we will elaborate, with the well-known HPL benchmark serving
as prototypical application, on how the PMDB streamlines the tuning for optimal
power efficiency in production, which lead to Piz Daint being recognised as the
most energy efficient petascale supercomputer presently in operation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2660</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2660</id><created>2014-08-12</created><authors><author><keyname>Blasco</keyname><forenames>Francisco L&#xe1;zaro</forenames></author><author><keyname>Liva</keyname><forenames>Gianluigi</forenames></author><author><keyname>Bauch</keyname><forenames>Gerhard</forenames></author></authors><title>LT Code Design for Inactivation Decoding</title><categories>cs.IT math.IT</categories><comments>6 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a simple model of inactivation decoding for LT codes which can be
used to estimate the decoding complexity as a function of the LT code degree
distribution. The model is shown to be accurate in variety of settings of
practical importance. The proposed method allows to perform a numerical
optimization on the degree distribution of a LT code aiming at minimizing the
number of inactivations required for decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2662</identifier>
 <datestamp>2015-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2662</id><created>2014-08-12</created><updated>2015-10-19</updated><authors><author><keyname>Talebanfard</keyname><forenames>Navid</forenames></author></authors><title>On the Structure and the Number of Prime Implicants of 2-CNFs</title><categories>cs.DM math.CO</categories><doi>10.1016/j.dam.2015.06.036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $m(n, k)$ be the maximum number of prime implicants that any $k$-CNF on n
variables can have. We show that $3^{n/3} \le m(n,2) \le (1+o(1))3^{n/3}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2674</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2674</id><created>2014-08-12</created><authors><author><keyname>Gheorghe</keyname><forenames>Marian</forenames></author><author><keyname>Stannett</keyname><forenames>Mike</forenames></author></authors><title>Integration Testing of Heterotic Systems</title><categories>cs.ET</categories><comments>13 pages, 1 figure. Keywords: Heterotic computing, P system, membrane
  system, unconventional computing, integration testing, system integration,
  hybrid computing, X-machine</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational theory and practice generally focus on single-paradigm systems,
but relatively little is known about how best to combine components based on
radically different approaches (e.g., silicon chips and wetware) into a single
coherent system. In particular, while testing strategies for single-technology
components are generally well developed, it is unclear at present how to
perform integration testing on heterotic systems: can we develop a test-set
generation strategy for checking whether specified behaviours emerge (and
unwanted behaviours do not) when components based on radically different
technologies are combined within a single system?
  In this paper, we describe an approach to modelling multi-technology
heterotic systems using a general-purpose formal specification strategy based
on Eilenberg's X-machine model of computation. We show how this approach can be
used to represent disparate technologies within a single framework, and propose
a strategy for using these formal models for automatic heterotic test-set
generation. We illustrate our approach by showing how to derive a test set for
a heterotic system combining an X-machine-based device with a cell-based P
system (membrane system).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2685</identifier>
 <datestamp>2015-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2685</id><created>2014-08-12</created><updated>2015-07-21</updated><authors><author><keyname>Carmi</keyname><forenames>Avishy Y.</forenames></author><author><keyname>Moskovich</keyname><forenames>Daniel</forenames></author></authors><title>Computing with Coloured Tangles</title><categories>cs.CC</categories><comments>36 pages,; Introduction entirely rewritten, Section 4.3 added</comments><msc-class>68Q15, 57M99</msc-class><acm-class>F.2.2</acm-class><journal-ref>Symmetry 2015, 7(3), 1289-1332</journal-ref><doi>10.3390/sym7031289</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We suggest a diagrammatic model of computation based on an axiom of
distributivity. A diagram of a decorated coloured tangle, similar to those that
appear in low dimensional topology, plays the role of a circuit diagram.
Equivalent diagrams represent bisimilar computations. We prove that our model
of computation is Turing complete, and that with bounded resources it can
moreover decide any language in complexity class IP, sometimes with better
performance parameters than corresponding classical protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2687</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2687</id><created>2014-08-12</created><authors><author><keyname>Rahman</keyname><forenames>Tamjid</forenames></author><author><keyname>Rokonuzzaman</keyname><forenames>M.</forenames></author></authors><title>A Noble Methodology for Users Work Process Driven Software Requirements
  for Smart Handheld Devices</title><categories>cs.SE</categories><comments>18 pages, 9 figures</comments><doi>10.5121/ijsea.2014.5402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Requirement engineering is a key ingredient for software development to be
effective. Apart from the traditional software requirement which is not much
appropriate for new emerging software such as smart handheld device based
software. In many perspectives of requirement engineering, traditional and new
emerging software are not similar. Whereas requirement engineering of
traditional software needs more research, it is obvious that new emerging
software needs methodically and in-depth research for improved productivity,
quality, risk management and validity. In particular, the result of this paper
shows that how effective requirement engineering can improve in project
negotiation, project planning, managing feature creep, testing, defect, rework
and product quality. This paper also shows a new methodology which is focused
on users work process applicable for eliciting the requirement of traditional
software and any new type software of smart handheld device such as iPad. As an
example, the paper shows how the methodology will be applied as a software
requirement of iPad-based software for play-group students.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2690</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2690</id><created>2014-08-12</created><authors><author><keyname>Kraft</keyname><forenames>Dennis</forenames></author><author><keyname>Fadaei</keyname><forenames>Salman</forenames></author><author><keyname>Bichler</keyname><forenames>Martin</forenames></author></authors><title>Fast Convex Decomposition for Truthful Social Welfare Approximation</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approximating the optimal social welfare while preserving truthfulness is a
well studied problem in algorithmic mechanism design. Assuming that the social
welfare of a given mechanism design problem can be optimized by an integer
program whose integrality gap is at most $\alpha$, Lavi and Swamy~\cite{Lavi11}
propose a general approach to designing a randomized $\alpha$-approximation
mechanism which is truthful in expectation. Their method is based on
decomposing an optimal solution for the relaxed linear program into a convex
combination of integer solutions. Unfortunately, Lavi and Swamy's decomposition
technique relies heavily on the ellipsoid method, which is notorious for its
poor practical performance. To overcome this problem, we present an alternative
decomposition technique which yields an $\alpha(1 + \epsilon)$ approximation
and only requires a quadratic number of calls to an integrality gap verifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2695</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2695</id><created>2014-08-12</created><authors><author><keyname>Lee</keyname><forenames>Y. -J.</forenames></author></authors><title>Web Object Size satisfying Mean Waiting Time In Multiple Access
  Environment</title><categories>cs.NI</categories><doi>10.5121/ijcnc.2014.6401</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper addresses web object size which is one of important performance
measures and affects to service time in multiple access environment. Since
packets arrive according to Poission distribution and web service time has
arbitrary distribution, M/G/1 model can be used to describe the behavior of the
web server system. In the time division multiplexing (TDM), we can use M/D/1
with vacations model, because service time is constant and server may have a
vacation. We derive the mean web object size satisfying the constraint such
that mean waiting time by round-robin scheduling in multiple access environment
is equal to the mean queueing delay of M/D/1 with vacations model in TDM and
M/H2/1 model, respectively. Performance evaluation shows that the mean web
object size increases as the link utilization increases at the given maximum
segment size (MSS), but converges on the lower bound when the number of
embedded objects included in a web page is beyond the threshold. Our results
can be applied to the economic design and maintenance of web service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2699</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2699</id><created>2014-08-12</created><authors><author><keyname>Cuskley</keyname><forenames>Christine F.</forenames></author><author><keyname>Pugliese</keyname><forenames>Martina</forenames></author><author><keyname>Castellano</keyname><forenames>Claudio</forenames></author><author><keyname>Colaiori</keyname><forenames>Francesca</forenames></author><author><keyname>Loreto</keyname><forenames>Vittorio</forenames></author><author><keyname>Tria</keyname><forenames>Francesca</forenames></author></authors><title>Internal and external dynamics in language: Evidence from verb
  regularity in a historical corpus of English</title><categories>physics.soc-ph cs.CL</categories><comments>12 page, 4 figures + Supporting Information (18 pages)</comments><journal-ref>PLoS ONE 9(8): e102882 (2014)</journal-ref><doi>10.1371/journal.pone.0102882</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human languages are rule governed, but almost invariably these rules have
exceptions in the form of irregularities. Since rules in language are efficient
and productive, the persistence of irregularity is an anomaly. How does
irregularity linger in the face of internal (endogenous) and external
(exogenous) pressures to conform to a rule? Here we address this problem by
taking a detailed look at simple past tense verbs in the Corpus of Historical
American English. The data show that the language is open, with many new verbs
entering. At the same time, existing verbs might tend to regularize or
irregularize as a consequence of internal dynamics, but overall, the amount of
irregularity sustained by the language stays roughly constant over time.
Despite continuous vocabulary growth, and presumably, an attendant increase in
expressive power, there is no corresponding growth in irregularity. We analyze
the set of irregulars, showing they may adhere to a set of minority rules,
allowing for increased stability of irregularity over time. These findings
contribute to the debate on how language systems become rule governed, and how
and why they sustain exceptions to rules, providing insight into the interplay
between the emergence and maintenance of rules and exceptions in language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2700</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2700</id><created>2014-08-12</created><updated>2015-03-27</updated><authors><author><keyname>Deleforge</keyname><forenames>Antoine</forenames></author><author><keyname>Horaud</keyname><forenames>Radu</forenames></author><author><keyname>Schechner</keyname><forenames>Yoav</forenames></author><author><keyname>Girin</keyname><forenames>Laurent</forenames></author></authors><title>Co-Localization of Audio Sources in Images Using Binaural Features and
  Locally-Linear Regression</title><categories>cs.SD cs.MM stat.AP stat.ML</categories><comments>15 pages, 8 figures</comments><journal-ref>IEEE Transactions on Audio, Speech, and Language Processing 23(4),
  718-731, April, 2015</journal-ref><doi>10.1109/TASLP.2015.2405475</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of localizing audio sources using binaural
measurements. We propose a supervised formulation that simultaneously localizes
multiple sources at different locations. The approach is intrinsically
efficient because, contrary to prior work, it relies neither on source
separation, nor on monaural segregation. The method starts with a training
stage that establishes a locally-linear Gaussian regression model between the
directional coordinates of all the sources and the auditory features extracted
from binaural measurements. While fixed-length wide-spectrum sounds (white
noise) are used for training to reliably estimate the model parameters, we show
that the testing (localization) can be extended to variable-length
sparse-spectrum sounds (such as speech), thus enabling a wide range of
realistic applications. Indeed, we demonstrate that the method can be used for
audio-visual fusion, namely to map speech signals onto images and hence to
spatially align the audio and visual modalities, thus enabling to discriminate
between speaking and non-speaking faces. We release a novel corpus of real-room
recordings that allow quantitative evaluation of the co-localization method in
the presence of one or two sound sources. Experiments demonstrate increased
accuracy and speed relative to several state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2701</identifier>
 <datestamp>2015-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2701</id><created>2014-08-12</created><updated>2015-09-18</updated><authors><author><keyname>Pastor-Satorras</keyname><forenames>Romualdo</forenames></author><author><keyname>Castellano</keyname><forenames>Claudio</forenames></author><author><keyname>Van Mieghem</keyname><forenames>Piet</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>Epidemic processes in complex networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><comments>62 pages, 15 figures, final version</comments><journal-ref>Rev. Mod. Phys. 87, 925 (2015)</journal-ref><doi>10.1103/RevModPhys.87.925</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years the research community has accumulated overwhelming evidence
for the emergence of complex and heterogeneous connectivity patterns in a wide
range of biological and sociotechnical systems. The complex properties of
real-world networks have a profound impact on the behavior of equilibrium and
nonequilibrium phenomena occurring in various systems, and the study of
epidemic spreading is central to our understanding of the unfolding of
dynamical processes in complex networks. The theoretical analysis of epidemic
spreading in heterogeneous networks requires the development of novel
analytical frameworks, and it has produced results of conceptual and practical
relevance. A coherent and comprehensive review of the vast research activity
concerning epidemic processes is presented, detailing the successful
theoretical approaches as well as making their limits and assumptions clear.
Physicists, mathematicians, epidemiologists, computer, and social scientists
share a common interest in studying epidemic spreading and rely on similar
models for the description of the diffusion of pathogens, knowledge, and
innovation. For this reason, while focusing on the main results and the
paradigmatic models in infectious disease modeling, the major results
concerning generalized social contagion processes are also presented. Finally,
the research activity at the forefront in the study of epidemic spreading in
coevolving, coupled, and time-varying networks is reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2721</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2721</id><created>2014-08-12</created><authors><author><keyname>Akoglu</keyname><forenames>Tulay Ayyildiz</forenames></author><author><keyname>Hauenstein</keyname><forenames>Jonathan D.</forenames></author><author><keyname>Szanto</keyname><forenames>Agnes</forenames></author></authors><title>Certifying solutions to overdetermined and singular polynomial systems
  over Q</title><categories>cs.SC math.AG math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with certifying that a given point is near an exact
root of an overdetermined or singular polynomial system with rational
coefficients. The difficulty lies in the fact that consistency of
overdetermined systems is not a continuous property. Our certification is based
on hybrid symbolic-numeric methods to compute the exact &quot;rational univariate
representation&quot; (RUR) of a component of the input system from approximate
roots. For overdetermined polynomial systems with simple roots, we compute an
initial RUR from approximate roots. The accuracy of the RUR is increased via
Newton iterations until the exact RUR is found, which we certify using exact
arithmetic. Since the RUR is well-constrained, we can use it to certify the
given approximate roots using alpha-theory. To certify isolated singular roots,
we use a determinantal form of the &quot;isosingular deflation&quot;, which adds new
polynomials to the original system without introducing new variables. The
resulting polynomial system is overdetermined, but the roots are now simple,
thereby reducing the problem to the overdetermined case. We prove that our
algorithms have complexity that are polynomial in the input plus the output
size upon successful convergence, and we use worst case upper bounds for
termination when our iteration does not converge to an exact RUR. Examples are
included to demonstrate the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2751</identifier>
 <datestamp>2015-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2751</id><created>2014-08-12</created><updated>2015-03-09</updated><authors><author><keyname>Lampesberger</keyname><forenames>Harald</forenames></author></authors><title>Technologies for Web and cloud service interaction: a survey</title><categories>cs.NI cs.DC</categories><comments>Accepted Version 2015-02-20, 41 pages, 19 figures, 3 tables, Service
  Oriented Computing and Applications (2015)</comments><acm-class>A.1; C.2.2; C.2.4; H.3.4; H.3.5</acm-class><doi>10.1007/s11761-015-0174-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolution of Web and service technologies has led to a wide landscape of
standards and protocols for interaction between loosely coupled software
components. Examples range from Web applications, mashups, apps, and mobile
devices to enterprise-grade services. Cloud computing is the industrialization
of service provision and delivery, where Web and enterprise services are
converging on a technological level. The article discusses this technological
landscape and, in particular, current trends with respect to cloud computing.
The survey focuses on the communication aspect of interaction by reviewing
languages, protocols, and architectures that drive today's standards and
software implementations applicable in clouds. Technological advances will
affect both client side and service side. There is a trend toward multiplexing,
multihoming, and encryption in upcoming transport mechanisms, especially for
architectures, where a client simultaneously sends a large number of requests
to some service. Furthermore, there are emerging client-to-client communication
capabilities in Web clients that could establish a foundation for upcoming
Web-based messaging architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2758</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2758</id><created>2014-08-12</created><authors><author><keyname>T&#xe4;nzer</keyname><forenames>Michael</forenames></author></authors><title>The Influence of Architectural Styles on Security, Using the Example of
  a Certification Authority</title><categories>cs.CR cs.SE</categories><comments>Study Thesis</comments><acm-class>D.2.11</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Often, security is considered in an advanced stage of the implementation of a
system, rather than integrating it into the system design. This leads to less
secure systems, as the security mechanisms are only applied as an afterthought
and therefore do not integrate well with the rest of the design. Also, several
statistics about discovered vulnerabilities in existing systems suggest, that
most of the vulnerabilities of a system are not caused by errors in the
cryptographic primitives, but in other parts of the implementation. So
integrating security concerns early in the design process seems a promising
approach for increasing the security of the resulting system.
  This work evaluates how the choice of the architectural style affects the
security of the resulting system. The evaluation is done on the example of an
existing certification authority (CA). The requirements for the system are
gathered and multiple designs according to different architectural styles are
drafted and evaluated using a risk evaluation method. Then the evaluated
designs are compared to find out whether there are significant differences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2764</identifier>
 <datestamp>2015-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2764</id><created>2014-08-12</created><updated>2015-08-23</updated><authors><author><keyname>Ramaswamy</keyname><forenames>Harish G.</forenames></author><author><keyname>Agarwal</keyname><forenames>Shivani</forenames></author></authors><title>Convex Calibration Dimension for Multiclass Loss Matrices</title><categories>cs.LG stat.ML</categories><comments>Accepted to JMLR, pending editing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study consistency properties of surrogate loss functions for general
multiclass learning problems, defined by a general multiclass loss matrix. We
extend the notion of classification calibration, which has been studied for
binary and multiclass 0-1 classification problems (and for certain other
specific learning problems), to the general multiclass setting, and derive
necessary and sufficient conditions for a surrogate loss to be calibrated with
respect to a loss matrix in this setting. We then introduce the notion of
convex calibration dimension of a multiclass loss matrix, which measures the
smallest `size' of a prediction space in which it is possible to design a
convex surrogate that is calibrated with respect to the loss matrix. We derive
both upper and lower bounds on this quantity, and use these results to analyze
various loss matrices. In particular, we apply our framework to study various
subset ranking losses, and use the convex calibration dimension as a tool to
show both the existence and non-existence of various types of convex calibrated
surrogates for these losses. Our results strengthen recent results of Duchi et
al. (2010) and Calauzenes et al. (2012) on the non-existence of certain types
of convex calibrated surrogates in subset ranking. We anticipate the convex
calibration dimension may prove to be a useful tool in the study and design of
surrogate losses for general multiclass learning problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2770</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2770</id><created>2014-08-12</created><updated>2014-08-16</updated><authors><author><keyname>Rajtmajer</keyname><forenames>Sarah</forenames></author><author><keyname>Griffin</keyname><forenames>Christopher</forenames></author><author><keyname>Mikesell</keyname><forenames>Derek</forenames></author><author><keyname>Squicciarini</keyname><forenames>Anna</forenames></author></authors><title>A cooperate-defect model for the spread of deviant behavior in social
  networks</title><categories>cs.GT cs.SI physics.soc-ph</categories><comments>9 pages, 6 figures, corrects an oversight in Version 1 in which
  equilibrium point analysis is insufficiently qualified</comments><msc-class>91A22, 91A43, 91A50</msc-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We present a game-theoretic model for the spread of deviant behavior in
online social networks. We utilize a two-strategy framework wherein each
player's behavior is classified as normal or deviant and evolves according to
the cooperate-defect payoff scheme of the classic prisoner's dilemma game. We
demonstrate convergence of individual behavior over time to a final strategy
vector and indicate counterexamples to this convergence outside the context of
prisoner's dilemma. Theoretical results are validated on a real-world dataset
collected from a popular online forum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2774</identifier>
 <datestamp>2015-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2774</id><created>2014-08-12</created><updated>2015-07-29</updated><authors><author><keyname>Fattahi</keyname><forenames>Jaouhar</forenames></author><author><keyname>Mejri</keyname><forenames>Mohamed</forenames></author><author><keyname>Houmani</keyname><forenames>Hanane</forenames></author></authors><title>A Semi-Decidable Procedure for Secrecy in Cryptographic Protocols</title><categories>cs.CR</categories><comments>Presentation enhanced</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a new semi-decidable procedure to analyze
cryptographic protocols for secrecy based on a new class of functions that we
call: the Witness-Functions. A Witness-Function is a reliable function that
guarantees the secrecy in any protocol proved increasing once analyzed by it.
Hence, the problem of correctness becomes a problem of protocol growth. A
Witness-Function operates on derivative messages in a role-based specification
and introduces new derivation techniques. We give here the technical aspects of
the Witness-Functions and we show how to use them in a semi-decidable
procedure. Then, we analyze a variation of the Needham-Schroeder protocol and
we show that a Witness-Function can also help to teach about flaws. Finally, we
analyze the NSL protocol and we prove that it is correct with respect to
secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2776</identifier>
 <datestamp>2015-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2776</id><created>2014-08-12</created><updated>2015-02-03</updated><authors><author><keyname>Schneider</keyname><forenames>Carsten</forenames></author></authors><title>A Difference Ring Theory for Symbolic Summation</title><categories>cs.SC</categories><comments>The environments are labelled differently, some parts are
  restructured, an index has been inserted, various typos are removed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A summation framework is developed that enhances Karr's difference field
approach. It covers not only indefinite nested sums and products in terms of
transcendental extensions, but it can treat, e.g., nested products defined over
roots of unity. The theory of the so-called $R\Pi\Sigma^*$-extensions is
supplemented by algorithms that support the construction of such difference
rings automatically and that assist in the task to tackle symbolic summation
problems. Algorithms are presented that solve parameterized telescoping
equations, and more generally parameterized first-order difference equations,
in the given difference ring. As a consequence, one obtains algorithms for the
summation paradigms of telescoping and Zeilberger's creative telescoping. With
this difference ring theory one obtains a rigorous summation machinery that has
been applied to numerous challenging problems coming, e.g., from combinatorics
and particle physics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2779</identifier>
 <datestamp>2014-10-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2779</id><created>2014-08-01</created><updated>2014-10-29</updated><authors><author><keyname>Ali</keyname><forenames>Ramy E.</forenames></author><author><keyname>Digham</keyname><forenames>Fadel F.</forenames></author><author><keyname>Seddik</keyname><forenames>Karim G.</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author><author><keyname>El-Keyi</keyname><forenames>Amr</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>A Probabilistic MAC for Cognitive Radio Systems with Energy Harvesting
  Nodes</title><categories>cs.NI cs.IT math.IT</categories><comments>5 pages, IEEE GlobalSIP 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a cognitive radio (CR) system where the secondary
user (SU) harvests energy from both the nature resources and the primary user
(PU) radio frequency(RF) signal. We propose an energy-based probabilistic
access scheme in which SU probabilistically accesses and senses the primary
channel. The decision is based on the available energy and the PU's activity.
We investigate the problem of maximizing the SU's success rate provided that
the PU average quality of service (QoS) constraint is satisfied. We also assume
multi-packet reception (MPR) capability and sensing errors under a Rayleigh
fading channel. Numerical results show the effectiveness of the proposed
probabilistic access scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2782</identifier>
 <datestamp>2015-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2782</id><created>2014-08-12</created><updated>2015-04-02</updated><authors><author><keyname>Ostrovsky</keyname><forenames>Rafail</forenames></author><author><keyname>Rosenbaum</keyname><forenames>Will</forenames></author></authors><title>Fast distributed almost stable marriages</title><categories>cs.GT cs.DC cs.DS</categories><comments>Various improvements in version 2: algorithms for general (not just
  &quot;almost regular&quot;) preferences; deterministic variant of the algorithm;
  streamlined proof of approximation guarantee</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In their seminal work on the Stable Marriage Problem, Gale and Shapley
describe an algorithm which finds a stable matching in $O(n^2)$ communication
rounds. Their algorithm has a natural interpretation as a distributed algorithm
where each player is represented by a single processor. In this distributed
model, Floreen, Kaski, Polishchuk, and Suomela recently showed that for bounded
preference lists, terminating the Gale-Shapley algorithm after a constant
number of rounds results in an almost stable matching. In this paper, we
describe a new deterministic distributed algorithm which finds an almost stable
matching in $O(\log^5 n)$ communication rounds for arbitrary preferences. We
also present a faster randomized variant which requires $O(\log^2 n)$ rounds.
This run-time can be improved to $O(1)$ rounds for &quot;almost regular&quot; (and in
particular complete) preferences. To our knowledge, these are the first
sub-polynomial round distributed algorithms for any variant of the stable
marriage problem with unbounded preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2790</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2790</id><created>2014-08-12</created><authors><author><keyname>Benmahammed</keyname><forenames>Khier</forenames></author><author><keyname>Badran</keyname><forenames>Saeed</forenames></author><author><keyname>Kourdi</keyname><forenames>Bassam</forenames></author></authors><title>Complex polynomials in engineering</title><categories>cs.SY</categories><comments>15 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Techniques for the evaluation of complex polynomials with one and two
variables are introduced. Polynomials arise in may areas such as control
systems, image and signal processing, coding theory, electrical networks, etc.,
and their evaluations are time consuming. This paper introduces new evaluation
algorithms that are straightforward with fewer arithmetic operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2800</identifier>
 <datestamp>2014-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2800</id><created>2014-08-12</created><updated>2014-08-27</updated><authors><author><keyname>Bikakis</keyname><forenames>Nikos</forenames></author><author><keyname>Tsinaraki</keyname><forenames>Chrisa</forenames></author><author><keyname>Stavrakantonakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Christodoulakis</keyname><forenames>Stavros</forenames></author></authors><title>Supporting SPARQL Update Queries in RDF-XML Integration</title><categories>cs.DB</categories><comments>13th International Semantic Web Conference (ISWC '14)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Web of Data encourages organizations and companies to publish their data
according to the Linked Data practices and offer SPARQL endpoints. On the other
hand, the dominant standard for information exchange is XML. The SPARQL2XQuery
Framework focuses on the automatic translation of SPARQL queries in XQuery
expressions in order to access XML data across the Web. In this paper, we
outline our ongoing work on supporting update queries in the RDF-XML
integration scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2803</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2803</id><created>2014-08-12</created><updated>2014-08-13</updated><authors><author><keyname>Jayadeva</keyname></author></authors><title>Learning a hyperplane classifier by minimizing an exact bound on the VC
  dimension</title><categories>cs.LG</categories><comments>Accepted Author Manuscript (Neurocomputing, Elsevier); 10 pages</comments><msc-class>68T05, 68T10, 68Q32,</msc-class><acm-class>I.5.1; I.5.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The VC dimension measures the capacity of a learning machine, and a low VC
dimension leads to good generalization. While SVMs produce state-of-the-art
learning performance, it is well known that the VC dimension of a SVM can be
unbounded; despite good results in practice, there is no guarantee of good
generalization. In this paper, we show how to learn a hyperplane classifier by
minimizing an exact, or \boldmath{$\Theta$} bound on its VC dimension. The
proposed approach, termed as the Minimal Complexity Machine (MCM), involves
solving a simple linear programming problem. Experimental results show, that on
a number of benchmark datasets, the proposed approach learns classifiers with
error rates much less than conventional SVMs, while often using fewer support
vectors. On many benchmark datasets, the number of support vectors is less than
one-tenth the number used by SVMs, indicating that the MCM does indeed learn
simpler representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2810</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2810</id><created>2014-08-12</created><authors><author><keyname>Rajabi</keyname><forenames>Roozbeh</forenames></author><author><keyname>Ghassemian</keyname><forenames>Hassan</forenames></author></authors><title>Spectral Unmixing of Hyperspectral Imagery using Multilayer NMF</title><categories>cs.CV</categories><comments>5 pages, Journal</comments><doi>10.1109/LGRS.2014.2325874</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperspectral images contain mixed pixels due to low spatial resolution of
hyperspectral sensors. Spectral unmixing problem refers to decomposing mixed
pixels into a set of endmembers and abundance fractions. Due to nonnegativity
constraint on abundance fractions, nonnegative matrix factorization (NMF)
methods have been widely used for solving spectral unmixing problem. In this
letter we proposed using multilayer NMF (MLNMF) for the purpose of
hyperspectral unmixing. In this approach, spectral signature matrix can be
modeled as a product of sparse matrices. In fact MLNMF decomposes the
observation matrix iteratively in a number of layers. In each layer, we applied
sparseness constraint on spectral signature matrix as well as on abundance
fractions matrix. In this way signatures matrix can be sparsely decomposed
despite the fact that it is not generally a sparse matrix. The proposed
algorithm is applied on synthetic and real datasets. Synthetic data is
generated based on endmembers from USGS spectral library. AVIRIS Cuprite
dataset has been used as a real dataset for evaluation of proposed method.
Results of experiments are quantified based on SAD and AAD measures. Results in
comparison with previously proposed methods show that the multilayer approach
can unmix data more effectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2812</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2812</id><created>2014-08-12</created><authors><author><keyname>Wrochna</keyname><forenames>Marcin</forenames></author></authors><title>Homomorphism reconfiguration via homotopy</title><categories>cs.CC math.CO</categories><comments>22 pages, 8 figures</comments><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider the following problem for a fixed graph H: given a graph G and
two H-colorings of G, i.e. homomorphisms from G to H, can one be transformed
(reconfigured) into the other by changing one color at a time, maintaining an
H-coloring throughout. This is the same as finding a path in the Hom(G,H)
complex. For H=K_k this is the problem of finding paths between k-colorings,
which was shown to be in P for k&lt;=3 and PSPACE-complete otherwise by Cereceda
et al. 2011. We generalize the positive side of this dichotomy by providing an
algorithm that solves the problem in polynomial time for any H with no C_4
subgraph. This gives a large class of constraints for which finding solutions
to the Constraint Satisfaction Problem is NP-complete, but finding paths in the
solution space is P.
  The algorithm uses a characterization of possible reconfiguration sequences
(paths in Hom(G,H)), whose main part is a purely topological condition
described in algebraic terms of the fundamental groupoid of H seen as a
topological space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2813</identifier>
 <datestamp>2014-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2813</id><created>2014-08-12</created><authors><author><keyname>Naghizadeh</keyname><forenames>Alireza</forenames></author><author><keyname>Yourdkhani</keyname><forenames>Tahereh</forenames></author><author><keyname>Razeghi</keyname><forenames>Behrooz</forenames></author><author><keyname>Meamari</keyname><forenames>Ehsan</forenames></author></authors><title>BSRone: Binary Search with Routing of O(1); A Scalable Circular Design
  for Distributed Networks</title><categories>cs.NI cs.IR</categories><comments>22 pages, 11 figures, This work has been submitted to the Springer
  journal for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-Peer (P2P) networks as distributed solutions are used in a variety of
applications. Based on the type of routing for queries among their nodes, they
are classified into three groups: structured, unstructured and small-world P2P
networks. Each of these categories has its own applications and benefits.
Structured networks by using Distributed Hash Tables (DHT) can forward request
search queries more efficiency. These networks usually organize a specific
topology and make a geometrical shape. A circular topology is a prevalent
design which was first introduced by Chord. In this paper, we propose BSROne, a
circular structured P2P design which attempts to consider several shortcomings
in the current networks. In our proposed method, we want to achieve O(1)
routing time without requiring all of the nodes to know about each other. By
removing the real connections between nodes and tying all of them with
super-nodes, we gave the network an ability to scale up by introducing one
layer above super-nodes. We achieved this by emulating the design of binary
search algorithm for supreme-nodes. In this paper, at first we introduce a
design where fixed super-nodes with unlimited resources are given to the
distributed network. In the next step, we explain how it can manage to work as
a P2P application. We finally discuss the possibility of removing the
scalability issue in a P2P environment for our design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2824</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2824</id><created>2014-08-11</created><authors><author><keyname>Apeltsin</keyname><forenames>Leonard</forenames></author></authors><title>A CryptoCubic Protocol for Hacker-Proof Off-Chain Bitcoin Transactions</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Off-Chain transactions allow for the immediate transfer of Cryptocurrency
between two parties, without delays or unavoidable transaction fees. Such
capabilities are critical for mainstream Cryptocurrency adaption. They allow
for the &quot;Coffee-Coin Criteria&quot;; under which a customer orders a coffee and pays
for that coffee in bitcoins. This is not possible with On-Chain transactions
today. Unfortunately, all existing Off-Chain transaction protocols are
notoriously unreliable The current generation of third-party facilitators are
vulnerable to hacker-based attacks. As Mt. Gox tragically demonstrated,
centralized-transaction institutions are easy targets for Cryptocurrency
thieves. The slightest security flaw in a third-party system will pounced on by
hackers, who will proceed to devour it like ants devouring a crab. Under such
circumstances, it no wonder that the Public treats most Cryptocurrency services
with a constant shadow of suspicion. For Bitcoin to flourish, its
anti-hierarchy principles must be applied to safe Off-Chain transactions. First
and foremost, we need a new hacker-proof protocol that can easily be executed
by any experienced developer. Preferably, the protocol will be open-sourced for
full reliability and transparency. This paper presents one such procedure,
which allows for he safe transmission of Bitcoin private key control by way of
Cryptocubic transactions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2842</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2842</id><created>2014-08-12</created><authors><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author></authors><title>Star-free languages and local divisors</title><categories>cs.FL</categories><comments>This is a prior version of an invited contribution at the 16th
  International Workshop on Descriptional Complexity of Formal Systems (DCFS
  2014) in Turku, Finland. The final publication is available at Springer via
  http://dx.doi.org/10.1007/978-3-319-09704-6_3</comments><msc-class>68Q45, 68Q70, 20M3</msc-class><acm-class>F.4.3</acm-class><journal-ref>In H. J\&quot;urgensen, J. Karhum\&quot;aki, and A. Okhotin, editors,
  Proceedings of DCFS 2014. LNCS vol. 8614, pp. 23-28, 2014</journal-ref><doi>10.1007/978-3-319-09704-6_3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A celebrated result of Sch\&quot;utzenberger says that a language is star-free if
and only if it is is recognized by a finite aperiodic monoid. We give a new
proof for this theorem using local divisors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2852</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2852</id><created>2014-08-12</created><authors><author><keyname>Al-Ameen</keyname><forenames>Mahdi Nasrullah</forenames><affiliation>The University of Texas at Arlington, Arlington, TX, USA</affiliation></author><author><keyname>Wright</keyname><forenames>Matthew</forenames><affiliation>The University of Texas at Arlington, Arlington, TX, USA</affiliation></author></authors><title>A Comprehensive Study of the GeoPass User Authentication Scheme</title><categories>cs.HC cs.CR</categories><comments>14 pages, 5 figures, 10 tables</comments><acm-class>K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Before deploying a new user authentication scheme, it is critical to subject
the scheme to comprehensive study. Few works, however, have undertaken such a
study. Recently, Thorpe et al. proposed GeoPass, the most promising of a class
of user authentication schemes based on geographic locations in online maps.
Their study showed very high memorability (97%) and satisfactory resilience
against online guessing, which means that GeoPass has compelling features for
real-world use. No comprehensive study, however, has been conducted for GeoPass
or any other location-based password scheme. In this paper, we present a
systematic approach for the detailed evaluation of a password system, which we
implement to study GeoPass. We conducted three separate studies to evaluate the
suitability of GeoPass for widespread use. First, we performed a field study
over two months, in which users in a real-world setting remembered their
location-passwords 96% of the time and showed improvement with more login
sessions. Second, we conducted a study to test how users would fare with
multiple location-passwords and found that users remembered their
location-passwords in less than 70% of login sessions, with 40% of login
failures due to interference effects. Third, we conducted a study to examine
the resilience of GeoPass against shoulder surfing. Our participants played the
role of attackers and had an overall success rate of 48%. Based on our results,
we suggest suitable applications of GeoPass in its current state and identify
aspects of GeoPass that must be improved before widespread deployment could be
considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2854</identifier>
 <datestamp>2015-04-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2854</id><created>2014-08-12</created><updated>2015-04-04</updated><authors><author><keyname>Azimi-Abarghouyi</keyname><forenames>Seyed Mohammad</forenames></author><author><keyname>Hejazi</keyname><forenames>Mohsen</forenames></author><author><keyname>Nasiri-Kenari</keyname><forenames>Masoumeh</forenames></author></authors><title>Distributed Compute-and-Forward Based Relaying Strategies in Multi-User
  Multi-Relay Networks</title><categories>cs.IT math.IT</categories><comments>29 pages, 9 figures, Submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose different practical distributed schemes to solve
the rank failure problem in the compute and forward (CMF)-based multi-user
multi-relay networks without central coordinator, in which the relays have no
prior information about each other. First, a new relaying strategy based on
CMF, named incremental compute-and-forward (ICMF), is proposed that performs
quite well in terms of the outage probability. We show that the distributed
ICMF scheme can even outperform the achievable rate of centralized optimal CMF
in strong enough inter relay links, with much less complexity. Then, as the
second scheme, amplify-forward and compute (AFC) is introduced in which the
equations are recovered in the destination rather than in the relays. Finally,
ICMF and AFC schemes are combined to present hybrid compute-amplify and forward
(HCAF) relaying scheme, which takes advantages of both ICMF, and AFC and
improves the performance of the ICMF considerably. We evaluate the performance
of the proposed strategies in terms of the outage probability and compare the
results with those of the conventional CMF strategy, the Decode and Forward
(DF) strategy, and also the centralized optimal CMF. The results indicate the
substantial superiority of the proposed schemes compared with the conventional
schemes, specially for high number of users and relays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2855</identifier>
 <datestamp>2014-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2855</id><created>2014-08-12</created><updated>2014-10-10</updated><authors><author><keyname>Azimi-Abarghouyi</keyname><forenames>Seyed Mohammad</forenames></author><author><keyname>Hejazi</keyname><forenames>Mohsen</forenames></author><author><keyname>Nasiri-Kenari</keyname><forenames>Masoumeh</forenames></author></authors><title>Compute-and-Forward Two-Way Relaying</title><categories>cs.IT math.IT</categories><comments>27 pages, 9 figures, Accepted for IET Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new two-way relaying scheme based on compute-and-forward
(CMF) framework and relay selection strategies is proposed, which provides a
higher throughput than the conventional two-way relaying schemes. Two cases of
relays with or without feedback transmission capability are considered. An
upper bound on the computation rate of each relay is derived, and based on
that, a lower bound on the outage probability of the system is presented
assuming block Rayleigh fading channels. Numerical results show that while the
average sum rate of the system without feedback, named as Max
Compute-and-Forward (M-CMF), reaches the derived upper bound only in low SNRs,
that of the system with feedback, named as Aligned Compute-and-Forward (A-CMF)
reaches the bound in all SNRs. However, both schemes approach the derived lower
bound on the outage probability in all SNRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2858</identifier>
 <datestamp>2015-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2858</id><created>2014-08-12</created><updated>2015-01-20</updated><authors><author><keyname>Ceccarello</keyname><forenames>Matteo</forenames></author><author><keyname>Silvestri</keyname><forenames>Francesco</forenames></author></authors><title>Experimental Evaluation of Multi-Round Matrix Multiplication on
  MapReduce</title><categories>cs.DC cs.DS cs.MS</categories><comments>Proc. of 17th Meeting on Algorithm Engineering and Experiments
  (ALENEX), 2015. The code is publicly available at http://www.dei.unipd.it/m3</comments><doi>10.1137/1.9781611973754.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common approach in the design of MapReduce algorithms is to minimize the
number of rounds. Indeed, there are many examples in the literature of
monolithic MapReduce algorithms, which are algorithms requiring just one or two
rounds. However, we claim that the design of monolithic algorithms may not be
the best approach in cloud systems. Indeed, multi-round algorithms may exploit
some features of cloud platforms by suitably setting the round number according
to the execution context. In this paper we carry out an experimental study of
multi-round MapReduce algorithms aiming at investigating the performance of the
multi-round approach. We use matrix multiplication as a case study. We first
propose a scalable Hadoop library, named M$_3$, for matrix multiplication in
the dense and sparse cases which allows to tradeoff round number with the
amount of data shuffled in each round and the amount of memory required by
reduce functions. Then, we present an extensive study of this library on an
in-house cluster and on Amazon Web Services aiming at showing its performance
and at comparing monolithic and multi-round approaches. The experiments show
that, even without a low level optimization, it is possible to design
multi-round algorithms with a small running time overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2869</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2869</id><created>2014-08-12</created><authors><author><keyname>Czarnecki</keyname><forenames>Wojciech Marian</forenames></author><author><keyname>Tabor</keyname><forenames>Jacek</forenames></author></authors><title>Cluster based RBF Kernel for Support Vector Machines</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the classical Gaussian SVM classification we use the feature space
projection transforming points to normal distributions with fixed covariance
matrices (identity in the standard RBF and the covariance of the whole dataset
in Mahalanobis RBF). In this paper we add additional information to Gaussian
SVM by considering local geometry-dependent feature space projection. We
emphasize that our approach is in fact an algorithm for a construction of the
new Gaussian-type kernel.
  We show that better (compared to standard RBF and Mahalanobis RBF)
classification results are obtained in the simple case when the space is
preliminary divided by k-means into two sets and points are represented as
normal distributions with a covariances calculated according to the dataset
partitioning.
  We call the constructed method C$_k$RBF, where $k$ stands for the amount of
clusters used in k-means. We show empirically on nine datasets from UCI
repository that C$_2$RBF increases the stability of the grid search (measured
as the probability of finding good parameters).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2871</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2871</id><created>2014-08-12</created><authors><author><keyname>Estrada</keyname><forenames>Matias</forenames></author><author><keyname>Mendoza</keyname><forenames>Marcelo</forenames></author></authors><title>Affinity Prediction in Online Social Networks</title><categories>cs.SI physics.soc-ph</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Link prediction is the problem of inferring whether potential edges between
pairs of vertices in a graph will be present or absent in the near future. To
perform this task it is usual to use information provided by a number of
available and observed vertices/edges. Then, a number of edge scoring methods
based on this information can be created. Usually, these methods assess local
structures of the observed graph, assuming that closer vertices in the original
period of observation will be more likely to form a link in the future. In this
paper we explore the combination of local and global features to conduct link
prediction in online social networks. The contributions of the paper are
twofold: a) We evaluate a number of strategies that combines global and local
features tackling the locality assumption of link prediction scoring methods,
and b) We only use network topology-based features, avoiding the inclusion of
informational or transactional based features that involve heavy computational
costs in the methods. We evaluate our proposal using real-world data provided
by Skout Inc., an affinity online social network with millions of users around
the world. Our results show that our proposal is feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2873</identifier>
 <datestamp>2014-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2873</id><created>2014-08-12</created><updated>2014-12-08</updated><authors><author><keyname>Hannun</keyname><forenames>Awni Y.</forenames></author><author><keyname>Maas</keyname><forenames>Andrew L.</forenames></author><author><keyname>Jurafsky</keyname><forenames>Daniel</forenames></author><author><keyname>Ng</keyname><forenames>Andrew Y.</forenames></author></authors><title>First-Pass Large Vocabulary Continuous Speech Recognition using
  Bi-Directional Recurrent DNNs</title><categories>cs.CL cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method to perform first-pass large vocabulary continuous speech
recognition using only a neural network and language model. Deep neural network
acoustic models are now commonplace in HMM-based speech recognition systems,
but building such systems is a complex, domain-specific task. Recent work
demonstrated the feasibility of discarding the HMM sequence modeling framework
by directly predicting transcript text from audio. This paper extends this
approach in two ways. First, we demonstrate that a straightforward recurrent
neural network architecture can achieve a high level of accuracy. Second, we
propose and evaluate a modified prefix-search decoding algorithm. This approach
to decoding enables first-pass speech recognition with a language model,
completely unaided by the cumbersome infrastructure of HMM-based systems.
Experiments on the Wall Street Journal corpus demonstrate fairly competitive
word error rates, and the importance of bi-directional network recurrence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2874</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2874</id><created>2014-08-12</created><updated>2015-10-26</updated><authors><author><keyname>D'Acci</keyname><forenames>Luca</forenames></author></authors><title>Urban DNA for cities evolutions. Cities as physical expression of
  dynamic equilibriums between competitive and cooperative forces</title><categories>cs.CY nlin.AO physics.soc-ph</categories><comments>http://www.urem.eu/isobenefit/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cities are physical manifestations of our competitive and cooperative
behaviours. The tension between these two forces generates dynamic equilibriums
whose material expressions are cities and their evolutions. In a Darwinian
cooperative view, as Darwinism does not involve only competition, the public
benefit obtained by cooperation, return in terms of private benefit too. An
urban genetic code is proposed, according to which cities emerge connecting
nature and urbanity, and as sum of multiuse, independent micro-areas, each one
with its centrality, job locations, parks and daily shops-services and
amenities. This mechanism, called Isobenefit Urbanism, is not static and
pre-designed, but allows infinitely dynamic changes and expansions. Rather than
describing The ideal city, which doesn't exist outside our own minds,
Isobenefit Urbanism describes what a city should avoid to be in order to not
become an unideal city. Its six principles are the urban DNA which does not
give predetermined forms but indications to follow according to contexts and
times. From an environmental angle, Isobenefit cities are resilient, low
carbon, adaptive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2887</identifier>
 <datestamp>2015-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2887</id><created>2014-08-12</created><updated>2015-12-13</updated><authors><author><keyname>Bihan</keyname><forenames>Nicolas Le</forenames></author><author><keyname>Chatelain</keyname><forenames>Florent</forenames></author><author><keyname>Manton</keyname><forenames>Jonathan H.</forenames></author></authors><title>Isotropic Multiple Scattering Processes on Hyperspheres</title><categories>cs.IT math.IT</categories><comments>16 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents several results about isotropic random walks and multiple
scattering processes on hyperspheres ${\mathbb S}^{p-1}$. It allows one to
derive the Fourier expansions on ${\mathbb S}^{p-1}$ of these processes. A
result of unimodality for the multiconvolution of symmetrical probability
density functions (pdf) on ${\mathbb S}^{p-1}$ is also introduced. Such
processes are then studied in the case where the scattering distribution is von
Mises Fisher (vMF). Asymptotic distributions for the multiconvolution of vMFs
on ${\mathbb S}^{p-1}$ are obtained. Both Fourier expansion and asymptotic
approximation allows us to compute estimation bounds for the parameters of
Compound Cox Processes (CCP) on ${\mathbb S}^{p-1}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2889</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2889</id><created>2014-08-12</created><authors><author><keyname>Ko</keyname><forenames>Albert H. R.</forenames></author><author><keyname>Sabourin</keyname><forenames>Robert</forenames></author><author><keyname>Britto</keyname><forenames>Alceu S.</forenames><suffix>Jr</suffix></author><author><keyname>Oliveira</keyname><forenames>Luiz E. S.</forenames></author></authors><title>A Classifier-free Ensemble Selection Method based on Data Diversity in
  Random Subspaces</title><categories>cs.LG cs.NE</categories><acm-class>I.5.2; I.5.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Ensemble of Classifiers (EoC) has been shown to be effective in improving
the performance of single classifiers by combining their outputs, and one of
the most important properties involved in the selection of the best EoC from a
pool of classifiers is considered to be classifier diversity. In general,
classifier diversity does not occur randomly, but is generated systematically
by various ensemble creation methods. By using diverse data subsets to train
classifiers, these methods can create diverse classifiers for the EoC. In this
work, we propose a scheme to measure data diversity directly from random
subspaces, and explore the possibility of using it to select the best data
subsets for the construction of the EoC. Our scheme is the first ensemble
selection method to be presented in the literature based on the concept of data
diversity. Its main advantage over the traditional framework (ensemble creation
then selection) is that it obviates the need for classifier training prior to
ensemble selection. A single Genetic Algorithm (GA) and a Multi-Objective
Genetic Algorithm (MOGA) were evaluated to search for the best solutions for
the classifier-free ensemble selection. In both cases, objective functions
based on different clustering diversity measures were implemented and tested.
All the results obtained with the proposed classifier-free ensemble selection
method were compared with the traditional classifier-based ensemble selection
using Mean Classifier Error (ME) and Majority Voting Error (MVE). The
applicability of the method is tested on UCI machine learning problems and NIST
SD19 handwritten numerals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2890</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2890</id><created>2014-08-12</created><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>He</keyname><forenames>Bo</forenames></author><author><keyname>Dong</keyname><forenames>Diya</forenames></author><author><keyname>Shen</keyname><forenames>Yue</forenames></author><author><keyname>Yan</keyname><forenames>Tianhong</forenames></author><author><keyname>Nian</keyname><forenames>Rui</forenames></author><author><keyname>Lendase</keyname><forenames>Amaury</forenames></author></authors><title>Robust OS-ELM with a novel selective ensemble based on particle swarm
  optimization</title><categories>cs.LG</categories><comments>Submitted to Mathematical Problems in Engineering</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a robust online sequential extreme learning machine (ROS-ELM)
is proposed. It is based on the original OS-ELM with an adaptive selective
ensemble framework. Two novel insights are proposed in this paper. First, a
novel selective ensemble algorithm referred to as particle swarm optimization
selective ensemble (PSOSEN) is proposed. Noting that PSOSEN is a general
selective ensemble method which is applicable to any learning algorithms,
including batch learning and online learning. Second, an adaptive selective
ensemble framework for online learning is designed to balance the robustness
and complexity of the algorithm. Experiments for both regression and
classification problems with UCI data sets are carried out. Comparisons between
OS-ELM, simple ensemble OS-ELM (EOS-ELM) and the proposed ROS-ELM empirically
show that ROS-ELM significantly improves the robustness and stability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2908</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2908</id><created>2014-08-12</created><updated>2014-08-14</updated><authors><author><keyname>Mathew</keyname><forenames>Priya</forenames></author><author><keyname>Augustine</keyname><forenames>Lismi</forenames></author><author><keyname>G.</keyname><forenames>Sabarinath</forenames></author><author><keyname>Devis</keyname><forenames>Tomson</forenames></author></authors><title>Hardware Implementation of (63,51) BCH Encoder and Decoder For WBAN
  Using LFSR and BMA</title><categories>cs.IT math.IT</categories><comments>11 Pages,8 Figures, 2 Tables</comments><journal-ref>International Journal on Information Theory (IJIT), Volume 3,
  No.3, July 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Error Correcting Codes are required to have a reliable communication through
a medium that has an unacceptable bit error rate and low signal to noise ratio.
In IEEE 802.15.6 2.4GHz Wireless Body Area Network (WBAN), data gets corrupted
during the transmission and reception due to noises and interferences. Ultra
low power operation is crucial to prolong the life of implantable devices.
Hence simple block codes like BCH (63, 51, 2) can be employed in the
transceiver design of 802.15.6 Narrowband PHY. In this paper, implementation of
BCH (63, 51, t = 2) Encoder and Decoder using VHDL is discussed. The incoming
51 bits are encoded into 63 bit code word using (63, 51) BCH encoder. It can
detect and correct up to 2 random errors. The design of an encoder is
implemented using Linear Feed Back Shift Register (LFSR) for polynomial
division and the decoder design is based on syndrome calculator, inversion-less
Berlekamp-Massey algorithm (BMA) and Chien search algorithm. Synthesis and
simulation were carried out using Xilinx ISE 14.2 and ModelSim 10.1c. The codes
are implemented over Virtex 4 FPGA device and tested on DN8000K10PCIE Logic
Emulation Board. To the best of our knowledge, it is the first time an
implementation of (63, 51) BCH encoder and decoder carried out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2910</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2910</id><created>2014-08-13</created><authors><author><keyname>Kumar</keyname><forenames>Surender</forenames></author><author><keyname>Kumar</keyname><forenames>Sumit</forenames></author><author><keyname>Bhushan</keyname><forenames>Bharat</forenames></author></authors><title>Energy Aware Clustering Protocol(EACP) For Heterogeneous WSNs</title><categories>cs.NI</categories><comments>15 Pages, 10 figures. in print at
  http://airccse.org/journal/ijc2014.html</comments><doi>10.5121/ijcnc.2014.6403</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Energy saving to prolong the network life is an important design issue while
developing a new routing protocol for wireless sensor network. Clustering is a
key technique for this and helps in maximizing the network lifetime and
scalability. Most of the routing and data dissemination protocols of WSN assume
a homogeneous network architecture, in which all sensors have the same
capabilities in terms of battery power, communication, sensing, storage, and
processing. Recently, there has been an interest in heterogeneous sensor
networks, especially for real deployments. This research paper has proposed a
new energy aware clustering protocol (EACP) for heterogeneous wireless sensor
networks. Heterogeneity is introduced in EACP by using two types of nodes:
normal and advanced. In EACP cluster heads for normal nodes are elected with
the help of a probability scheme based on residual and average energy of the
normal nodes. This will ensure that only the high residual normal nodes can
become the cluster head in a round. Advanced nodes use a separate probability
based scheme for cluster head election and they will further act as a gateway
for normal cluster heads and transmit their data load to base station when they
are not doing the duty of a cluster head. Finally a sleep state is suggested
for some sensor nodes during cluster formation phase to save network energy.
The performance of EACP is compared with SEP and simulation result shows the
better result for stability period, network life and energy saving than SEP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2914</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2914</id><created>2014-08-13</created><authors><author><keyname>Kumar</keyname><forenames>Surender</forenames></author><author><keyname>Prateek</keyname><forenames>Manish</forenames></author><author><keyname>Ahuja</keyname><forenames>N. J.</forenames></author><author><keyname>Bhushan</keyname><forenames>Bharat</forenames></author></authors><title>DE-LEACH: Distance and Energy Aware LEACH</title><categories>cs.NI</categories><comments>7 pages, 5 figures. available online at http://ijcaonline.org/2014</comments><doi>10.5120/15384-4072</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Wireless sensor network consists of large number of tiny sensor nodes which
are usually deployed in a harsh environment. Self configuration and
infrastructure less are the two fundamental properties of sensor networks.
Sensor nodes are highly energy constrained devices because they are battery
operated devices and due to harsh environment deployment it is impossible to
change or recharge their battery. Energy conservation and prolonging the
network life are two major challenges in a sensor network. Communication
consumes the large portion of WSN energy. Several protocols have been proposed
to realize power- efficient communication in a wireless sensor network. Cluster
based routing protocols are best known for increasing energy efficiency,
stability and network lifetime of WSNs. Low Energy Adaptive Clustering
Hierarchy (LEACH) is an important protocol in this class. One of the
disadvantages of LEACH is that it does not consider the nodes energy and
distance for the election of cluster head. This paper proposes a new energy
efficient clustering protocol DE-LEACH for homogeneous wireless sensor network
which is an extension of LEACH. DE-LEACH elects cluster head on the basis of
distance and residual energy of the nodes. Proposed protocol increases the
network life, stability and throughput of sensor network and simulations result
shows that DE-LEACH is better than LEACH.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2925</identifier>
 <datestamp>2015-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2925</id><created>2014-08-13</created><authors><author><keyname>De Domenico</keyname><forenames>Manlio</forenames></author><author><keyname>Lancichinetti</keyname><forenames>Andrea</forenames></author><author><keyname>Arenas</keyname><forenames>Alex</forenames></author><author><keyname>Rosvall</keyname><forenames>Martin</forenames></author></authors><title>Identifying modular flows on multilayer networks reveals highly
  overlapping organization in social systems</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Phys. Rev. X 5, 011027 (2015)</journal-ref><doi>10.1103/PhysRevX.5.011027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unveiling the community structure of networks is a powerful methodology to
comprehend interconnected systems across the social and natural sciences. To
identify different types of functional modules in interaction data aggregated
in a single network layer, researchers have developed many powerful methods.
For example, flow-based methods have proven useful for identifying modular
dynamics in weighted and directed networks that capture constraints on flow in
the systems they represent. However, many networked systems consist of agents
or components that exhibit multiple layers of interactions. Inevitably,
representing this intricate network of networks as a single aggregated network
leads to information loss and may obscure the actual organization. Here we
propose a method based on compression of network flows that can identify
modular flows in non-aggregated multilayer networks. Our numerical experiments
on synthetic networks show that the method can accurately identify modules that
cannot be identified in aggregated networks or by analyzing the layers
separately. We capitalize on our findings and reveal the community structure of
two multilayer collaboration networks: scientists affiliated to the Pierre
Auger Observatory and scientists publishing works on networks on the arXiv.
Compared to conventional aggregated methods, the multilayer method reveals
smaller modules with more overlap that better capture the actual organization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2927</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2927</id><created>2014-08-13</created><authors><author><keyname>Wang</keyname><forenames>Jingdong</forenames></author><author><keyname>Shen</keyname><forenames>Heng Tao</forenames></author><author><keyname>Song</keyname><forenames>Jingkuan</forenames></author><author><keyname>Ji</keyname><forenames>Jianqiu</forenames></author></authors><title>Hashing for Similarity Search: A Survey</title><categories>cs.DS cs.CV cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarity search (nearest neighbor search) is a problem of pursuing the data
items whose distances to a query item are the smallest from a large database.
Various methods have been developed to address this problem, and recently a lot
of efforts have been devoted to approximate search. In this paper, we present a
survey on one of the main solutions, hashing, which has been widely studied
since the pioneering work locality sensitive hashing. We divide the hashing
algorithms two main categories: locality sensitive hashing, which designs hash
functions without exploring the data distribution and learning to hash, which
learns hash functions according the data distribution, and review them from
various aspects, including hash function design and distance measure and search
scheme in the hash coding space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2930</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2930</id><created>2014-08-13</created><updated>2015-11-15</updated><authors><author><keyname>Ramezanian</keyname><forenames>Rasoul</forenames></author></authors><title>A Hypercomputation in Brouwer's Constructivism</title><categories>cs.LO cs.FL</categories><comments>This paper has been withdrawn by the author due to crucial errors in
  theorems 4.6 and 5.2 and definition 4.2</comments><msc-class>68Q10</msc-class><acm-class>F.1.1; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In contrast to other constructivist schools, for Brouwer, the notion of
&quot;constructive object&quot; is not restricted to be presented as `words' in some
finite alphabet of symbols, and choice sequences which are non-predetermined
and unfinished objects are legitimate constructive objects. In this way,
Brouwer's constructivism goes beyond Turing computability. Further, in 1999,
the term hypercomputation was introduced by J. Copeland. Hypercomputation
refers to models of computation which go beyond Church-Turing thesis. In this
paper, we propose a hypercomputation called persistently evolutionary Turing
machines based on Brouwer's notion of being constructive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2933</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2933</id><created>2014-08-13</created><authors><author><keyname>Hochgeschwender</keyname><forenames>Nico</forenames></author><author><keyname>Schneider</keyname><forenames>Sven</forenames></author><author><keyname>Voos</keyname><forenames>Holger</forenames></author><author><keyname>Kraetzschmar</keyname><forenames>Gerhard K.</forenames></author></authors><title>Towards a Robot Perception Specification Language</title><categories>cs.RO</categories><comments>Presented at DSLRob 2013 (arXiv:cs/1312.5952)</comments><report-no>DSLRob/2013/05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present our work in progress towards a domain-specific
language called Robot Perception Specification Language (RPSL). RSPL provide
means to specify the expected result (task knowledge) of a Robot Perception
Architecture in a declarative and framework-independent manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2938</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2938</id><created>2014-08-13</created><authors><author><keyname>Li</keyname><forenames>Wenbin</forenames></author><author><keyname>Fritz</keyname><forenames>Mario</forenames></author></authors><title>Learning Multi-Scale Representations for Material Classification</title><categories>cs.CV cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent progress in sparse coding and deep learning has made unsupervised
feature learning methods a strong competitor to hand-crafted descriptors. In
computer vision, success stories of learned features have been predominantly
reported for object recognition tasks. In this paper, we investigate if and how
feature learning can be used for material recognition. We propose two
strategies to incorporate scale information into the learning procedure
resulting in a novel multi-scale coding procedure. Our results show that our
learned features for material recognition outperform hand-crafted descriptors
on the FMD and the KTH-TIPS2 material classification benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2940</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2940</id><created>2014-08-13</created><authors><author><keyname>Lehrenfeld</keyname><forenames>Christoph</forenames></author><author><keyname>Reusken</keyname><forenames>Arnold</forenames></author></authors><title>Optimal preconditioners for Nitsche-XFEM discretizations of interface
  problems</title><categories>math.NA cs.NA</categories><comments>20 pages, 3 figures, 4 tables</comments><msc-class>65N12, 65N30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past decade, a combination of unfitted finite elements (or XFEM) with
the Nitsche method has become a popular discretization method for elliptic
interface problems. This development started with the introduction and analysis
of this Nitsche-XFEM technique in the paper [A. Hansbo, P. Hansbo, Comput.
Methods Appl. Mech. Engrg. 191 (2002)]. In general, the resulting linear
systems have very large condition numbers, which depend not only on the mesh
size $h$, but also on how the interface intersects the mesh. This paper is
concerned with the design and analysis of optimal preconditioners for such
linear systems. We propose an additive subspace preconditioner which is optimal
in the sense that the resulting condition number is independent of the mesh
size $h$ and the interface position. We further show that already the simple
diagonal scaling of the stifness matrix results in a condition number that is
bounded by $ch^{-2}$, with a constant $c$ that does not depend on the location
of the interface. Both results are proven for the two-dimensional case. Results
of numerical experiments in two and three dimensions are presented, which
illustrate the quality of the preconditioner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2941</identifier>
 <datestamp>2015-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2941</id><created>2014-08-13</created><authors><author><keyname>Lehrenfeld</keyname><forenames>Christoph</forenames></author></authors><title>The Nitsche XFEM-DG space-time method and its implementation in three
  space dimensions</title><categories>math.NA cs.CE</categories><comments>26 pages, 15 figures, 4 tables</comments><msc-class>65D30, 65M30</msc-class><journal-ref>SIAM J. Sci. Comput., 37 (1), 2015, A245--A270</journal-ref><doi>10.1137/130943534</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent paper [C. Lehrenfeld, A. Reusken, SIAM J. Num. Anal., 51
(2013)] a new finite element discretization method for a class of two-phase
mass transport problems is presented and analyzed. The transport problem
describes mass transport in a domain with an evolving interface. Across the
evolving interface a jump condition has to be satisfies. The discretization in
that paper is a space-time approach which combines a discontinuous Galerkin
(DG) technique (in time) with an extended finite element method (XFEM). Using
the Nitsche method the jump condition is enforced in a weak sense. While the
emphasis in that paper was on the analysis and one dimensional numerical
experiments the main contribution of this paper is the discussion of
implementation aspects for the spatially three dimensional case. As the
space-time interface is typically given only implicitly as the zero-level of a
level-set function, we construct a piecewise planar approximation of the
space-time interface. This discrete interface is used to divide the space-time
domain into its subdomains. An important component within this decomposition is
a new method for dividing four-dimensional prisms intersected by a piecewise
planar space-time interface into simplices. Such a subdivision algorithm is
necessary for numerical integration on the subdomains as well as on the
space-time interface. These numerical integrations are needed in the
implementation of the Nitsche XFEM-DG method in three space dimensions.
Corresponding numerical studies are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2943</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2943</id><created>2014-08-13</created><authors><author><keyname>Gambhir</keyname><forenames>Shweta</forenames></author><author><keyname>Tomar</keyname><forenames>Kuldeep</forenames></author></authors><title>Study of Computer Network Issues and Improvising Drop Rate of TCP Packet
  Using NS-2</title><categories>cs.NI</categories><comments>14 pages</comments><journal-ref>International Journal in Foundations of Computer Science &amp;
  Technology (IJFCST), Vol.4, No.4, July 2014 (Aircc Publication)
  ISSN:1839-7662, Editor-in-chief:Frantisek Darena, Mendel University in Brno,
  Czech Republic</journal-ref><doi>10.5121/ijfcst.2014.4407</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  As the enormous use of internet increases day by day so as security concern
is also raise day by day over the internet. In this paper we discuss the
network security and its related threats and also study the types of protocols
and few issues related to protocols in computer networks. We also simulate the
design of 5 node wired network scenario, its packet drop rate analysis through
TCP protocol using NS2 as a simulator. Analyzed the performance of 5-node
network when the packet is drop down by graphical method also called as Xgraph
when rate parameter is in mb and also analyzed the performance of same network
by changing the value of rate parameter at same time so no packets would drop
down at same time and also analyzed the performance by Xgraph method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2946</identifier>
 <datestamp>2014-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2946</id><created>2014-08-13</created><authors><author><keyname>Schreiber</keyname><forenames>Michael</forenames></author></authors><title>How to improve the outcome of performance evaluations in terms of
  percentiles for citation frequencies of my papers</title><categories>cs.DL physics.soc-ph</categories><comments>8 pages, 3 figures, 5 tables</comments><journal-ref>Journal of Informetrics 8, 873-879 (2014)</journal-ref><doi>10.1016/j.joi.2014.09.002</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Using empirical data I demonstrate that the result of performance evaluations
by percentiles can be drastically influenced by the proper choice of the
journal in which a manuscript is published.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2948</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2948</id><created>2014-08-13</created><authors><author><keyname>Alsheikh</keyname><forenames>Mohammad Abu</forenames></author><author><keyname>Poh</keyname><forenames>Puay Kai</forenames></author><author><keyname>Lin</keyname><forenames>Shaowei</forenames></author><author><keyname>Tan</keyname><forenames>Hwee-Pink</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author></authors><title>Efficient Data Compression with Error Bound Guarantee in Wireless Sensor
  Networks</title><categories>cs.NI</categories><comments>ACM MSWiM 2014</comments><acm-class>C.2.1; E.4</acm-class><doi>10.1145/2641798.2641799</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a data compression and dimensionality reduction scheme for data
fusion and aggregation applications to prevent data congestion and reduce
energy consumption at network connecting points such as cluster heads and
gateways. Our in-network approach can be easily tuned to analyze the data
temporal or spatial correlation using an unsupervised neural network scheme,
namely the autoencoders. In particular, our algorithm extracts intrinsic data
features from previously collected historical samples to transform the raw data
into a low dimensional representation. Moreover, the proposed framework
provides an error bound guarantee mechanism. We evaluate the proposed solution
using real-world data sets and compare it with traditional methods for temporal
and spatial data compression. The experimental validation reveals that our
approach outperforms several existing wireless sensor network's data
compression methods in terms of compression efficiency and signal
reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2955</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2955</id><created>2014-08-13</created><updated>2015-12-03</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>A Hoare-like logic of asserted single-pass instruction sequences</title><categories>cs.LO cs.PL</categories><comments>22 pages, the preliminaries have textual overlaps with the
  preliminaries in arXiv:1402.4950 [cs.LO] and earlier papers; introduction and
  conclusions rewritten, explanatory remarks added</comments><acm-class>D.2.4; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a formal system for proving the partial correctness of a
single-pass instruction sequence as considered in program algebra by
decomposition into proofs of the partial correctness of segments of the
single-pass instruction sequence concerned. The system is similar to Hoare
logics, but takes into account that, by the presence of jump instructions,
segments of single-pass instruction sequences may have multiple entry points
and multiple exit points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2962</identifier>
 <datestamp>2014-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2962</id><created>2014-08-13</created><updated>2014-08-26</updated><authors><author><keyname>Tanbourgi</keyname><forenames>Ralph</forenames></author><author><keyname>Jondral</keyname><forenames>Friedrich K.</forenames></author></authors><title>Analysis of Heterogeneous Cellular Networks under Frequency Diversity
  and Interference Correlation</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Wireless Communications Letters</comments><doi>10.1109/LWC.2014.2349008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analyzing heterogeneous cellular networks (HCNs) has become increasingly
complex, particularly due to irregular base station locations, massive
deployment of small cells, and flexible resource allocation. The latter is
usually not captured by existing stochastic models for analytical tractability.
In this work, we develop a more realistic stochastic model for a generic
$K$-tier HCN, where users are served in the downlink under frequency diversity.
We derive the rate coverage probability for this case, taking into account the
interference correlation across different parts of the allocated spectrum. Our
results indicate that ignoring this type of correlation may considerably
overestimate the offered date rate. Furthermore, the gain of spectrum
diversification is significant, particularly at low to moderate target data
rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2969</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2969</id><created>2014-08-13</created><authors><author><keyname>AlHakami</keyname><forenames>Hosam</forenames></author><author><keyname>Chen</keyname><forenames>Feng</forenames></author><author><keyname>Janicke</keyname><forenames>Helge</forenames></author></authors><title>An Extended Stable Marriage Problem Algorithm for Clone Detection</title><categories>cs.SE</categories><comments>20 pages, 10 figures, 6 tables</comments><journal-ref>Al Hakami,H, Chen, F &amp; Janicke, H (2014) An Extended Stable
  Marriage Problem Algorithm for Clone Detection, International Journal of
  Software Engineering &amp; Applications (IJSEA), Vol.5, No.4, pp 103-122</journal-ref><doi>10.5121/ijsea.2014.5407</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code cloning negatively affects industrial software and threatens
intellectual property. This paper presents a novel approach to detecting cloned
software by using a bijective matching technique. The proposed approach focuses
on increasing the range of similarity measures and thus enhancing the precision
of the detection. This is achieved by extending a well-known stable-marriage
problem (SMP) and demonstrating how matches between code fragments of different
files can be expressed. A prototype of the proposed approach is provided using
a proper scenario, which shows a noticeable improvement in several features of
clone detection such as scalability and accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2970</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2970</id><created>2014-08-13</created><authors><author><keyname>Goldberg</keyname><forenames>S. R.</forenames></author><author><keyname>Anthony</keyname><forenames>H.</forenames></author><author><keyname>Evans</keyname><forenames>T. S.</forenames></author></authors><title>Modelling Citation Networks</title><categories>physics.soc-ph cs.DL cs.SI</categories><comments>29 pages, 22 figures</comments><report-no>Imperial/TP/14/TSE/2</report-no><journal-ref>Scientometrics 105 (2015) 1577-1604</journal-ref><doi>10.1007/s11192-015-1737-9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The distribution of the number of academic publications as a function of
citation count for a given year is remarkably similar from year to year. We
measure this similarity as a width of the distribution and find it to be
approximately constant from year to year. We show that simple citation models
fail to capture this behaviour. We then provide a simple three parameter
citation network model using a mixture of local and global search processes
which can reproduce the correct distribution over time. We use the citation
network of papers from the hep-th section of arXiv to test our model. For this
data, around 20% of citations use global information to reference recently
published papers, while the remaining 80% are found using local searches. We
note that this is consistent with other studies though our motivation is very
different from previous work. Finally, we also find that the fluctuations in
the size of an academic publication's bibliography is important for the model.
This is not addressed in most models and needs further work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2981</identifier>
 <datestamp>2015-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2981</id><created>2014-08-13</created><updated>2015-02-10</updated><authors><author><keyname>Dedner</keyname><forenames>Andreas</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Eike Hermann</forenames></author><author><keyname>Scheichl</keyname><forenames>Robert</forenames></author></authors><title>Efficient Multigrid Preconditioners for Atmospheric Flow Simulations at
  High Aspect Ratio</title><categories>math.NA cs.DC cs.NA physics.ao-ph</categories><comments>22 pages, 6 Figures, 2 Tables</comments><msc-class>65N55, 65Y20, 65F08, 65Y05, 35J57, 86A10</msc-class><acm-class>G.1.8; J.2; G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many problems in fluid modelling require the efficient solution of highly
anisotropic elliptic partial differential equations (PDEs) in &quot;flat&quot; domains.
For example, in numerical weather- and climate-prediction an elliptic PDE for
the pressure correction has to be solved at every time step in a thin spherical
shell representing the global atmosphere. This elliptic solve can be one of the
computationally most demanding components in semi-implicit semi-Lagrangian time
stepping methods which are very popular as they allow for larger model time
steps and better overall performance. With increasing model resolution,
algorithmically efficient and scalable algorithms are essential to run the code
under tight operational time constraints. We discuss the theory and practical
application of bespoke geometric multigrid preconditioners for equations of
this type. The algorithms deal with the strong anisotropy in the vertical
direction by using the tensor-product approach originally analysed by B\&quot;{o}rm
and Hiptmair [Numer. Algorithms, 26/3 (2001), pp. 219-234]. We extend the
analysis to three dimensions under slightly weakened assumptions, and
numerically demonstrate its efficiency for the solution of the elliptic PDE for
the global pressure correction in atmospheric forecast models. For this we
compare the performance of different multigrid preconditioners on a
tensor-product grid with a semi-structured and quasi-uniform horizontal mesh
and a one dimensional vertical grid. The code is implemented in the Distributed
and Unified Numerics Environment (DUNE), which provides an easy-to-use and
scalable environment for algorithms operating on tensor-product grids. Parallel
scalability of our solvers on up to 20,480 cores is demonstrated on the HECToR
supercomputer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.2997</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.2997</id><created>2014-08-13</created><authors><author><keyname>Setty</keyname><forenames>Sreenivasa</forenames></author><author><keyname>Srinath</keyname><forenames>N. K</forenames></author><author><keyname>Hanumantharaju</keyname><forenames>M. C</forenames></author></authors><title>An Improved Approach for Contrast Enhancement of Spinal Cord Images
  based on Multiscale Retinex Algorithm</title><categories>cs.CV</categories><comments>13 pages, 6 figures, International Journal of Imaging and Robotics.
  arXiv admin note: text overlap with arXiv:1406.5710</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach for contrast enhancement of spinal cord
medical images based on multirate scheme incorporated into multiscale retinex
algorithm. The proposed work here uses HSV color space, since HSV color space
separates color details from intensity. The enhancement of medical image is
achieved by down sampling the original image into five versions, namely, tiny,
small, medium, fine, and normal scale. This is due to the fact that the each
versions of the image when independently enhanced and reconstructed results in
enormous improvement in the visual quality. Further, the contrast stretching
and MultiScale Retinex (MSR) techniques are exploited in order to enhance each
of the scaled version of the image. Finally, the enhanced image is obtained by
combining each of these scales in an efficient way to obtain the composite
enhanced image. The efficiency of the proposed algorithm is validated by using
a wavelet energy metric in the wavelet domain. Reconstructed image using
proposed method highlights the details (edges and tissues), reduces image noise
(Gaussian and Speckle) and improves the overall contrast. The proposed
algorithm also enhances sharp edges of the tissue surrounding the spinal cord
regions which is useful for diagnosis of spinal cord lesions. Elaborated
experiments are conducted on several medical images and results presented show
that the enhanced medical pictures are of good quality and is found to be
better compared with other researcher methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3002</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3002</id><created>2014-08-13</created><authors><author><keyname>Yun</keyname><forenames>Jooyeol</forenames></author><author><keyname>Seo</keyname><forenames>Jun won</forenames></author><author><keyname>Yoon</keyname><forenames>Taeseon</forenames></author></authors><title>The New Approach on Fuzzy Decision Trees</title><categories>cs.AI</categories><journal-ref>Jooyeol Yun, Jun won Seo, and Taeseon Yoon (2014) THE NEW APPROACH
  ON FUZZY DECISION TREES International Journal of Fuzzy Logic Systems (IJFLS)
  Vol.4, No.3, July 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decision trees have been widely used in machine learning. However, due to
some reasons, data collecting in real world contains a fuzzy and uncertain
form. The decision tree should be able to handle such fuzzy data. This paper
presents a method to construct fuzzy decision tree. It proposes a fuzzy
decision tree induction method in iris flower data set, obtaining the entropy
from the distance between an average value and a particular value. It also
presents an experiment result that shows the accuracy compared to former ID3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3025</identifier>
 <datestamp>2015-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3025</id><created>2014-08-13</created><updated>2015-05-29</updated><authors><author><keyname>Nagahara</keyname><forenames>M.</forenames></author><author><keyname>Quevedo</keyname><forenames>D. E.</forenames></author><author><keyname>Nesic</keyname><forenames>D.</forenames></author></authors><title>Maximum Hands-Off Control: A Paradigm of Control Effort Minimization</title><categories>cs.SY cs.IT math.IT math.OC</categories><comments>IEEE Transactions on Automatic Control, 2015 (to appear)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new paradigm of control, called a maximum
hands-off control. A hands-off control is defined as a control that has a short
support per unit time. The maximum hands-off control is the minimum support (or
sparsest) per unit time among all controls that achieve control objectives. For
finite horizon control, we show the equivalence between the maximum hands-off
control and L1-optimal control under a uniqueness assumption called normality.
This result rationalizes the use of L1 optimality in computing a maximum
hands-off control. We also propose an L1/L2-optimal control to obtain a smooth
hands-off control. Furthermore, we give a self-triggered feedback control
algorithm for linear time-invariant systems, which achieves a given sparsity
rate and practical stability in the case of plant disturbances. An example is
included to illustrate the effectiveness of the proposed control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3030</identifier>
 <datestamp>2014-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3030</id><created>2014-08-13</created><updated>2014-09-28</updated><authors><author><keyname>Reiter</keyname><forenames>Fabian</forenames></author></authors><title>Distributed Graph Automata and Verification of Distributed Algorithms</title><categories>cs.FL cs.DC cs.LO</categories><comments>26 pages, 6 figures, includes a condensed version of the author's
  Master's thesis arXiv:1404.6503. (This version of the article (v2) is
  identical to the previous one (v1), except for minor changes in phrasing.)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining ideas from distributed algorithms and alternating automata, we
introduce a new class of finite graph automata that recognize precisely the
languages of finite graphs definable in monadic second-order logic. By
restricting transitions to be nondeterministic or deterministic, we also obtain
two strictly weaker variants of our automata for which the emptiness problem is
decidable. As an application, we suggest how suitable graph automata might be
useful in formal verification of distributed algorithms, using Floyd-Hoare
logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3033</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3033</id><created>2014-08-13</created><authors><author><keyname>Mu&#xf1;oz</keyname><forenames>Cristina</forenames></author><author><keyname>Leone</keyname><forenames>Pierre</forenames></author></authors><title>A Network Architecture for Distributed Event Based Systems in an
  Ubiquitous Sensing Scenario</title><categories>cs.DC cs.NI</categories><comments>5 pages, 6 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Ubiquitous sensing devices frequently disseminate their data between them.
The use of a distributed event-based system that decouples publishers of
subscribers arises as an ideal candidate to implement the dissemination
process. In this paper, we present a network architecture which merges the
network and overlay layers of typical structured event-based systems.
Directional Random Walks (DRWs) are used for the construction of this merged
layer. Our first results show that DRWs are suitable to balance the load using
a few nodes in the network to construct the dissemination path. As future work,
we propose to study the properties of this new layer and to work on the design
of Bloom filters to manage broker nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3044</identifier>
 <datestamp>2015-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3044</id><created>2014-08-13</created><updated>2015-12-17</updated><authors><author><keyname>Albrecht</keyname><forenames>Benjamin</forenames></author></authors><title>Computing Hybridization Networks for Multiple Rooted Binary Phylogenetic
  Trees by Maximum Acyclic Agreement Forests</title><categories>q-bio.PE cs.DS</categories><comments>38 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a known fact that, given two rooted binary phylogenetic trees, the
concept of maximum acyclic agreement forests is sufficient to compute
hybridization networks with minimum hybridization number. In this work, we
demonstrate by first presenting an algorithm and then showing its correctness,
that this concept is also sufficient in the case of multiple input trees. More
precisely, we show that for computing minimum hybridization networks for
multiple rooted binary phylogenetic trees on the same set of taxa it suffices
to take only maximum acyclic agreement forests into account. Moreover, this
article contains a proof showing that the minimum hybridization number for a
set of rooted binary phylogenetic trees on the same set of taxa can be also
computed by solving subproblems referring to common clusters of the input
trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3045</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3045</id><created>2014-08-13</created><updated>2014-10-27</updated><authors><author><keyname>Patrascu</keyname><forenames>Mihai</forenames></author><author><keyname>Thorup</keyname><forenames>Mikkel</forenames></author></authors><title>Dynamic Integer Sets with Optimal Rank, Select, and Predecessor Search</title><categories>cs.DS</categories><comments>Presented with different formatting in Proceedings of the 55nd IEEE
  Symposium on Foundations of Computer Science (FOCS), 2014, pp. 166--175. The
  new version fixes a bug in one of the bounds stated for predecessor search,
  pointed out to me by Djamal Belazzougui</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a data structure representing a dynamic set S of w-bit integers on
a w-bit word RAM. With |S|=n and w &gt; log n and space O(n), we support the
following standard operations in O(log n / log w) time:
  - insert(x) sets S = S + {x}. - delete(x) sets S = S - {x}. - predecessor(x)
returns max{y in S | y&lt; x}. - successor(x) returns min{y in S | y &gt;= x}. -
rank(x) returns #{y in S | y&lt; x}. - select(i) returns y in S with rank(y)=i, if
any.
  Our O(log n/log w) bound is optimal for dynamic rank and select, matching a
lower bound of Fredman and Saks [STOC'89]. When the word length is large, our
time bound is also optimal for dynamic predecessor, matching a static lower
bound of Beame and Fich [STOC'99] whenever log n/log w=O(log w/loglog w).
  Technically, the most interesting aspect of our data structure is that it
supports all the above operations in constant time for sets of size n=w^{O(1)}.
This resolves a main open problem of Ajtai, Komlos, and Fredman [FOCS'83].
Ajtai et al. presented such a data structure in Yao's abstract cell-probe model
with w-bit cells/words, but pointed out that the functions used could not be
implemented. As a partial solution to the problem, Fredman and Willard
[STOC'90] introduced a fusion node that could handle queries in constant time,
but used polynomial time on the updates. We call our small set data structure a
dynamic fusion node as it does both queries and updates in constant time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3046</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3046</id><created>2014-08-11</created><authors><author><keyname>Esfahanizadeh</keyname><forenames>Homa</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>A Matrix Completion Approach to Linear Index Coding Problem</title><categories>cs.IT math.IT</categories><comments>5 pages, 7 figures, and 1 table submitted to ITW 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a general algorithm is proposed for rate analysis and code
design of linear index coding problems. Specifically a solution for minimum
rank matrix completion problem over finite fields representing the linear index
coding problem is devised in order to find the optimum transmission rate given
vector length and size of the field. The new approach can be applied to both
scalar and vector linear index coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3048</identifier>
 <datestamp>2014-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3048</id><created>2014-08-13</created><updated>2014-12-15</updated><authors><author><keyname>Szydlarski</keyname><forenames>Mikolaj</forenames></author><author><keyname>Grigori</keyname><forenames>Laura</forenames></author><author><keyname>Stompor</keyname><forenames>Radek</forenames></author></authors><title>Accelerating Cosmic Microwave Background map-making procedure through
  preconditioning</title><categories>astro-ph.CO cs.DC physics.comp-ph</categories><comments>19 pages // Final version submitted to A&amp;A</comments><acm-class>G.4; I.6; J.2</acm-class><journal-ref>A&amp;A 572, A39 (2014)</journal-ref><doi>10.1051/0004-6361/201323210</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimation of the sky signal from sequences of time ordered data is one of
the key steps in Cosmic Microwave Background (CMB) data analysis, commonly
referred to as the map-making problem. Some of the most popular and general
methods proposed for this problem involve solving generalised least squares
(GLS) equations with non-diagonal noise weights given by a block-diagonal
matrix with Toeplitz blocks. In this work we study new map-making solvers
potentially suitable for applications to the largest anticipated data sets.
They are based on iterative conjugate gradient (CG) approaches enhanced with
novel, parallel, two-level preconditioners. We apply the proposed solvers to
examples of simulated non-polarised and polarised CMB observations, and a set
of idealised scanning strategies with sky coverage ranging from nearly a full
sky down to small sky patches. We discuss in detail their implementation for
massively parallel computational platforms and their performance for a broad
range of parameters characterising the simulated data sets. We find that our
best new solver can outperform carefully-optimised standard solvers used today
by a factor of as much as 5 in terms of the convergence rate and a factor of up
to $4$ in terms of the time to solution, and to do so without significantly
increasing the memory consumption and the volume of inter-processor
communication. The performance of the new algorithms is also found to be more
stable and robust, and less dependent on specific characteristics of the
analysed data set. We therefore conclude that the proposed approaches are well
suited to address successfully challenges posed by new and forthcoming CMB data
sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3060</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3060</id><created>2014-08-13</created><authors><author><keyname>Le</keyname><forenames>Quoc Viet</forenames></author><author><keyname>Sarlos</keyname><forenames>Tamas</forenames></author><author><keyname>Smola</keyname><forenames>Alexander Johannes</forenames></author></authors><title>Fastfood: Approximate Kernel Expansions in Loglinear Time</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite their successes, what makes kernel methods difficult to use in many
large scale problems is the fact that storing and computing the decision
function is typically expensive, especially at prediction time. In this paper,
we overcome this difficulty by proposing Fastfood, an approximation that
accelerates such computation significantly. Key to Fastfood is the observation
that Hadamard matrices, when combined with diagonal Gaussian matrices, exhibit
properties similar to dense Gaussian random matrices. Yet unlike the latter,
Hadamard and diagonal matrices are inexpensive to multiply and store. These two
matrices can be used in lieu of Gaussian matrices in Random Kitchen Sinks
proposed by Rahimi and Recht (2009) and thereby speeding up the computation for
a large range of kernel functions. Specifically, Fastfood requires O(n log d)
time and O(n) storage to compute n non-linear basis functions in d dimensions,
a significant improvement from O(nd) computation and storage, without
sacrificing accuracy.
  Our method applies to any translation invariant and any dot-product kernel,
such as the popular RBF kernels and polynomial kernels. We prove that the
approximation is unbiased and has low variance. Experiments show that we
achieve similar accuracy to full kernel expansions and Random Kitchen Sinks
while being 100x faster and using 1000x less memory. These improvements,
especially in terms of memory usage, make kernel methods more practical for
applications that have large training sets and/or require real-time prediction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3079</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3079</id><created>2014-07-27</created><authors><author><keyname>Salah</keyname><forenames>Hani</forenames></author><author><keyname>Roos</keyname><forenames>Stefanie</forenames></author><author><keyname>Strufe</keyname><forenames>Thorsten</forenames></author></authors><title>A Lightweight Approach for Improving the Lookup Performance in
  Kademlia-type Systems</title><categories>cs.NI cs.DC</categories><comments>13 pages, 8 figures, conference version 'Diversity Entails
  Improvement: A new Neighbour Selection Scheme for Kademlia-type Systems' at
  IEEE P2P 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discovery of nodes and content in large-scale distributed systems is
generally based on Kademlia, today. Understanding Kademlia-type systems to
improve their performance is essential for maintaining a high service quality
for an increased number of participants, particularly when those systems are
adopted by latency-sensitive applications.
  This paper contributes to the understanding of Kademlia by studying the
impact of \emph{diversifying} neighbours' identifiers within each routing table
bucket on the lookup performance. We propose a new, yet backward-compatible,
neighbour selection scheme that attempts to maximize the aforementioned
diversity. The scheme does not cause additional overhead except negligible
computations for comparing the diversity of identifiers. We present a
theoretical model for the actual impact of the new scheme on the lookup's hop
count and validate it against simulations of three exemplary Kademlia-type
systems. We also measure the performance gain enabled by a partial deployment
for the scheme in the real KAD system. The results confirm the superiority of
the systems that incorporate our scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3081</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3081</id><created>2014-08-05</created><authors><author><keyname>Tran</keyname><forenames>Truyen</forenames></author><author><keyname>Bui</keyname><forenames>Hung</forenames></author><author><keyname>Venkatesh</keyname><forenames>Svetha</forenames></author></authors><title>Human Activity Learning and Segmentation using Partially Hidden
  Discriminative Models</title><categories>cs.LG cs.CV stat.ML</categories><comments>HAREM 2005: Proceedings of the International Workshop on Human
  Activity Recognition and Modelling</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning and understanding the typical patterns in the daily activities and
routines of people from low-level sensory data is an important problem in many
application domains such as building smart environments, or providing
intelligent assistance. Traditional approaches to this problem typically rely
on supervised learning and generative models such as the hidden Markov models
and its extensions. While activity data can be readily acquired from pervasive
sensors, e.g. in smart environments, providing manual labels to support
supervised training is often extremely expensive. In this paper, we propose a
new approach based on semi-supervised training of partially hidden
discriminative models such as the conditional random field (CRF) and the
maximum entropy Markov model (MEMM). We show that these models allow us to
incorporate both labeled and unlabeled data for learning, and at the same time,
provide us with the flexibility and accuracy of the discriminative framework.
Our experimental results in the video surveillance domain illustrate that these
models can perform better than their generative counterpart, the partially
hidden Markov model, even when a substantial amount of labels are unavailable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3082</identifier>
 <datestamp>2015-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3082</id><created>2014-08-13</created><updated>2015-04-24</updated><authors><author><keyname>Ong</keyname><forenames>Benjamin</forenames></author><author><keyname>Haynes</keyname><forenames>Ronald</forenames></author><author><keyname>Ladd</keyname><forenames>Kyle</forenames></author></authors><title>Algorithm xxx: RIDC Methods -- A Family of Parallel Time-Integrators</title><categories>cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Revisionist integral deferred correction (RIDC) methods are a family of
parallel--in--time methods to solve systems of initial values problems. The
approach is able to bootstrap lower order time integrators to provide high
order approximations in approximately the same wall clock time, hence providing
a multiplicative increase in the number of compute cores utilized. Here we
provide a C++ framework which automatically produces a parallel--in--time
solution of a system of initial value problems given user supplied code for the
right hand side of the system and a sequential code for a first-order time
step. The user supplied time step routine may be explicit or implicit and may
make use of any auxiliary libraries which take care of the solution of any
nonlinear algebraic systems which may arise or the numerical linear algebra
required. The code contains six examples of increasing complexity which also
serve as templates to solve user defined problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3083</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3083</id><created>2014-08-13</created><authors><author><keyname>Srivastava</keyname><forenames>Madhur</forenames></author></authors><title>Entropy Conserving Binarization Scheme for Video and Image Compression</title><categories>cs.IT cs.MM math.IT</categories><comments>12 pages, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a binarization scheme that converts non-binary data into a
set of binary strings. At present, there are many binarization algorithms, but
they are optimal for only specific probability distributions of the data
source. Overcoming the problem, it is shown in this paper that the presented
binarization scheme conserves the entropy of the original data having any
probability distribution of $m$-ary source. The major advantages of this scheme
are that it conserves entropy without the knowledge of the source and the
probability distribution of the source symbols. The scheme has linear
complexity in terms of the length of the input data. The binarization scheme
can be implemented in Context-based Adaptive Binary Arithmetic Coding (CABAC)
for video and image compression. It can also be utilized by various universal
data compression algorithms that have high complexity in compressing non-binary
data, and by binary data compression algorithms to optimally compress
non-binary data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3092</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3092</id><created>2014-08-13</created><authors><author><keyname>Suzuki</keyname><forenames>Taiji</forenames></author></authors><title>Convergence rate of Bayesian tensor estimator: Optimal rate without
  restricted strong convexity</title><categories>stat.ML cs.LG</categories><comments>27 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the statistical convergence rate of a Bayesian
low-rank tensor estimator. Our problem setting is the regression problem where
a tensor structure underlying the data is estimated. This problem setting
occurs in many practical applications, such as collaborative filtering,
multi-task learning, and spatio-temporal data analysis. The convergence rate is
analyzed in terms of both in-sample and out-of-sample predictive accuracies. It
is shown that a near optimal rate is achieved without any strong convexity of
the observation. Moreover, we show that the method has adaptivity to the
unknown rank of the true tensor, that is, the near optimal rate depending on
the true rank is achieved even if it is not known a priori.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3093</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3093</id><created>2014-08-13</created><updated>2014-08-14</updated><authors><author><keyname>Belazzougui</keyname><forenames>Djamal</forenames></author><author><keyname>Puglisi</keyname><forenames>Simon J.</forenames></author><author><keyname>Tabei</keyname><forenames>Yasuo</forenames></author></authors><title>Rank, select and access in grammar-compressed strings</title><categories>cs.DS</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a string $S$ of length $N$ on a fixed alphabet of $\sigma$ symbols, a
grammar compressor produces a context-free grammar $G$ of size $n$ that
generates $S$ and only $S$. In this paper we describe data structures to
support the following operations on a grammar-compressed string:
$\mbox{rank}_c(S,i)$ (return the number of occurrences of symbol $c$ before
position $i$ in $S$); $\mbox{select}_c(S,i)$ (return the position of the $i$th
occurrence of $c$ in $S$); and $\mbox{access}(S,i,j)$ (return substring
$S[i,j]$). For rank and select we describe data structures of size
$O(n\sigma\log N)$ bits that support the two operations in $O(\log N)$ time. We
propose another structure that uses $O(n\sigma\log (N/n)(\log N)^{1+\epsilon})$
bits and that supports the two queries in $O(\log N/\log\log N)$, where
$\epsilon&gt;0$ is an arbitrary constant. To our knowledge, we are the first to
study the asymptotic complexity of rank and select in the grammar-compressed
setting, and we provide a hardness result showing that significantly improving
the bounds we achieve would imply a major breakthrough on a hard
graph-theoretical problem. Our main result for access is a method that requires
$O(n\log N)$ bits of space and $O(\log N+m/\log_\sigma N)$ time to extract
$m=j-i+1$ consecutive symbols from $S$. Alternatively, we can achieve $O(\log
N/\log\log N+m/\log_\sigma N)$ query time using $O(n\log (N/n)(\log
N)^{1+\epsilon})$ bits of space. This matches a lower bound stated by Verbin
and Yu for strings where $N$ is polynomially related to $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3100</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3100</id><created>2014-08-09</created><authors><author><keyname>Warmuth</keyname><forenames>Manfred K.</forenames></author><author><keyname>Kuzmin</keyname><forenames>Dima</forenames></author></authors><title>A Bayesian Probability Calculus for Density Matrices</title><categories>quant-ph cs.AI math.ST stat.TH</categories><comments>Appears in Proceedings of the Twenty-Second Conference on Uncertainty
  in Artificial Intelligence (UAI2006)</comments><proxy>auai</proxy><report-no>UAI-P-2006-PG-503-511</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the main concepts in quantum physics is a density matrix, which is a
symmetric positive definite matrix of trace one. Finite probability
distributions are a special case where the density matrix is restricted to be
diagonal. Density matrices are mixtures of dyads, where a dyad has the form uu'
for any any unit column vector u. These unit vectors are the elementary events
of the generalized probability space. Perhaps the simplest case to see that
something unusual is going on is the case of uniform density matrix, i.e. 1/n
times identity. This matrix assigns probability 1/n to every unit vector, but
of course there are infinitely many of them. The new normalization rule thus
says that sum of probabilities over any orthonormal basis of directions is one.
We develop a probability calculus based on these more general distributions
that includes definitions of joints, conditionals and formulas that relate
these, i.e. analogs of the theorem of total probability, various Bayes rules
for the calculation of posterior density matrices, etc. The resulting calculus
parallels the familiar 'classical' probability calculus and always retains the
latter as a special case when all matrices are diagonal.
  Whereas the classical Bayesian methods maintain uncertainty about which model
is 'best', the generalization maintains uncertainty about which unit direction
has the largest variance. Surprisingly the bounds also generalize: as in the
classical setting we bound the negative log likelihood of the data by the
negative log likelihood of the MAP estimator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3110</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3110</id><created>2014-08-13</created><authors><author><keyname>Kumar</keyname><forenames>Surender</forenames></author><author><keyname>Prateek</keyname><forenames>Manish</forenames></author><author><keyname>Ahuja</keyname><forenames>N. J.</forenames></author><author><keyname>Bhushan</keyname><forenames>Bharat</forenames></author></authors><title>MEECDA: Multihop Energy Efficient Clustering and Data Aggregation
  Protocol for HWSN</title><categories>cs.NI</categories><comments>8 pages, 11 figures. available at http://ijcaonline.org/2014. arXiv
  admin note: substantial text overlap with arXiv:1408.2914</comments><doi>10.5120/15383-4047</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Wireless sensor network consists of large number of inexpensive tiny sensors
which are connected with low power wireless communications. Most of the routing
and data dissemination protocols of WSN assume a homogeneous network
architecture, in which all sensors have the same capabilities in terms of
battery power, communication, sensing, storage, and processing. However the
continued advances in miniaturization of processors and low-power
communications have enabled the development of a wide variety of nodes. When
more than one type of node is integrated into a WSN, it is called
heterogeneous. Multihop short distance communication is an important scheme to
reduce the energy consumption in a sensor network because nodes are densely
deployed in a WSN. In this paper M-EECDA (Multihop Energy Efficient Clustering
&amp; Data Aggregation Protocol for Heterogeneous WSN) is proposed and analyzed.
The protocol combines the idea of multihop communications and clustering for
achieving the best performance in terms of network life and energy consumption.
M-EECDA introduces a sleep state and three tier architecture for some cluster
heads to save energy of the network. M-EECDA consists of three types of sensor
nodes: normal, advance and super. To become cluster head in a round normal
nodes use residual energy based scheme. Advance and super nodes further act as
relay node to reduce the transmission load of a normal node cluster head when
they are not cluster heads in a round.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3115</identifier>
 <datestamp>2015-09-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3115</id><created>2014-08-13</created><updated>2015-09-25</updated><authors><author><keyname>Yang</keyname><forenames>Tianbao</forenames></author><author><keyname>Jin</keyname><forenames>Rong</forenames></author><author><keyname>Zhu</keyname><forenames>Shenghuo</forenames></author><author><keyname>Lin</keyname><forenames>Qihang</forenames></author></authors><title>On Data Preconditioning for Regularized Loss Minimization</title><categories>cs.NA cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study data preconditioning, a well-known and long-existing
technique, for boosting the convergence of first-order methods for regularized
loss minimization. It is well understood that the condition number of the
problem, i.e., the ratio of the Lipschitz constant to the strong convexity
modulus, has a harsh effect on the convergence of the first-order optimization
methods. Therefore, minimizing a small regularized loss for achieving good
generalization performance, yielding an ill conditioned problem, becomes the
bottleneck for big data problems. We provide a theory on data preconditioning
for regularized loss minimization. In particular, our analysis exhibits an
appropriate data preconditioner and characterizes the conditions on the loss
function and on the data under which data preconditioning can reduce the
condition number and therefore boost the convergence for minimizing the
regularized loss. To make the data preconditioning practically useful, we
endeavor to employ and analyze a random sampling approach to efficiently
compute the preconditioned data. The preliminary experiments validate our
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3139</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3139</id><created>2014-07-10</created><authors><author><keyname>Hosseini</keyname><forenames>Hossein</forenames></author><author><keyname>Hessar</keyname><forenames>Farzad</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Real-Time Impulse Noise Suppression from Images Using an Efficient
  Weighted-Average Filtering</title><categories>cs.CV</categories><doi>10.1109/LSP.2014.2381649</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a method for real-time high density impulse noise
suppression from images. In our method, we first apply an impulse detector to
identify the corrupted pixels and then employ an innovative weighted-average
filter to restore them. The filter takes the nearest neighboring interpolated
image as the initial image and computes the weights according to the relative
positions of the corrupted and uncorrupted pixels. Experimental results show
that the proposed method outperforms the best existing methods in both PSNR
measure and visual quality and is quite suitable for real-time applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3148</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3148</id><created>2014-08-13</created><authors><author><keyname>Bikakis</keyname><forenames>Nikos</forenames></author><author><keyname>Skourla</keyname><forenames>Melina</forenames></author><author><keyname>Papastefanatos</keyname><forenames>George</forenames></author></authors><title>rdf:SynopsViz - A Framework for Hierarchical Linked Data Visual
  Exploration and Analysis</title><categories>cs.DB</categories><comments>11th Extended Semantic Web Conference (ESWC '14)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of data visualization is to offer intuitive ways for information
perception and manipulation, especially for non-expert users. The Web of Data
has realized the availability of a huge amount of datasets. However, the volume
and heterogeneity of available information make it difficult for humans to
manually explore and analyse large datasets. In this paper, we present
rdf:SynopsViz, a tool for hierarchical charting and visual exploration of
Linked Open Data (LOD). Hierarchical LOD exploration is based on the creation
of multiple levels of hierarchically related groups of resources based on the
values of one or more properties. The adopted hierarchical model provides
effective information abstraction and summarization. Also, it allows efficient
-on the fly- statistic computations, using aggregations over the hierarchy
levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3153</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3153</id><created>2014-08-13</created><updated>2014-08-15</updated><authors><author><keyname>Wilcox-O'Hearn</keyname><forenames>L. Amber</forenames></author></authors><title>Detection is the central problem in real-word spelling correction</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Real-word spelling correction differs from non-word spelling correction in
its aims and its challenges. Here we show that the central problem in real-word
spelling correction is detection. Methods from non-word spelling correction,
which focus instead on selection among candidate corrections, do not address
detection adequately, because detection is either assumed in advance or heavily
constrained. As we demonstrate in this paper, merely discriminating between the
intended word and a random close variation of it within the context of a
sentence is a task that can be performed with high accuracy using
straightforward models. Trigram models are sufficient in almost all cases. The
difficulty comes when every word in the sentence is a potential error, with a
large set of possible candidate corrections. Despite their strengths, trigram
models cannot reliably find true errors without introducing many more, at least
not when used in the obvious sequential way without added structure. The
detection task exposes weakness not visible in the selection task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3154</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3154</id><created>2014-08-13</created><authors><author><keyname>Dabeeru</keyname><forenames>Vasavi Akhila</forenames></author></authors><title>User Profile Relationships using String Similarity Metrics in Social
  Networks</title><categories>cs.SI</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article reviews the problem of degree of closeness and interaction level
in a social network by ranking users based on similarity score. This similarity
is measured on the basis of social, geographic, educational, professional,
shared interests, pages liked, mutual interested groups or communities and
mutual friends. The technique addresses the problem of matching user profiles
in its globality by providing a suitable matching framework able to consider
all profiles' attributes and finding the similarity by new ways of string
metrics. It is able to discover the biggest possible number of profiles that
are similar to the target user profile, which the existing techniques are
unable to detect. Attributes were assigned weights manually; string and
semantic similarity metrics were used to compare attributes values thus
predicting the most similar profiles. Profile based similarity show the exact
relationship between users and this similarity between user profiles reflects
closeness and interaction between users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3164</identifier>
 <datestamp>2014-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3164</id><created>2014-08-13</created><updated>2014-11-06</updated><authors><author><keyname>Rahimian</keyname><forenames>Mohammad Amin</forenames></author><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author></authors><title>Detection and Isolation of Failures in Directed Networks of LTI Systems</title><categories>cs.SY cs.SI math.OC</categories><comments>arXiv admin note: substantial text overlap with arXiv:1309.5540.
  appears in IEEE Transactions on Control of Network Systems, 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a methodology to detect and isolate link failures in a weighted
and directed network of identical multi-input multi-output LTI systems when
only the output responses of a subset of nodes are available. Our method is
based on the observation of jump discontinuities in the output derivatives,
which can be explicitly related to the occurrence of link failures. The order
of the derivative at which the jump is observed is given by $r(d+1)$, where $r$
is the relative degree of each system's transfer matrix, and $d$ denotes the
distance from the location of the failure to the observation point. We then
propose detection and isolation strategies based on this relation. Furthermore,
we propose an efficient algorithm for sensor placement to detect and isolate
any possible link failure using a small number of sensors. Available results
from the theory of sub-modular set functions provide us with performance
guarantees that bound the size of the chosen sensor set within a logarithmic
factor of the smallest feasible set of sensors. These results are illustrated
through elaborative examples and supplemented by computer experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3169</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3169</id><created>2014-08-13</created><authors><author><keyname>Leike</keyname><forenames>Jan</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Indefinitely Oscillating Martingales</title><categories>cs.LG math.PR math.ST stat.TH</categories><comments>ALT 2014, extended technical report</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We construct a class of nonnegative martingale processes that oscillate
indefinitely with high probability. For these processes, we state a uniform
rate of the number of oscillations and show that this rate is asymptotically
close to the theoretical upper bound. These bounds on probability and
expectation of the number of upcrossings are compared to classical bounds from
the martingale literature. We discuss two applications. First, our results
imply that the limit of the minimum description length operator may not exist.
Second, we give bounds on how often one can change one's belief in a given
hypothesis when observing a stream of data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3170</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3170</id><created>2014-08-13</created><authors><author><keyname>Ch'ng</keyname><forenames>Eugene</forenames></author></authors><title>The Value of Using Big Data Technologies in Computational Social Science</title><categories>cs.SI physics.soc-ph</categories><comments>3rd ASE Big Data Science Conference, Tsinghua University Beijing, 3-7
  August 2014</comments><acm-class>J.4; H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discovery of phenomena in social networks has prompted renewed interests
in the field. Data in social networks however can be massive, requiring
scalable Big Data architecture. Conversely, research in Big Data needs the
volume and velocity of social media data for testing its scalability. Not only
so, appropriate data processing and mining of acquired datasets involve complex
issues in the variety, veracity, and variability of the data, after which
visualisation must occur before we can see fruition in our efforts. This
article presents topical, multimodal, and longitudinal social media datasets
from the integration of various scalable open source technologies. The article
details the process that led to the discovery of social information landscapes
within the Twitter social network, highlighting the experience of dealing with
social media datasets, using a funneling approach so that data becomes
manageable. The article demonstrated the feasibility and value of using
scalable open source technologies for acquiring massive, connected datasets for
research in the social sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3175</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3175</id><created>2014-08-13</created><authors><author><keyname>Reddy</keyname><forenames>V. Sidda</forenames></author><author><keyname>Rao</keyname><forenames>Dr. T. V.</forenames></author><author><keyname>Govardhan</keyname><forenames>Dr. A.</forenames></author></authors><title>Mining Frequent Itemsets (MFI) over Data Streams: Variable Window Size
  (VWS) by Context Variation Analysis (CVA) of the Streaming Transactions</title><categories>cs.DB</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The challenges with respect to mining frequent items over data streaming
engaging variable window size and low memory space are addressed in this
research paper. To check the varying point of context change in streaming
transaction we have developed a window structure which will be in two levels
and supports in fixing the window size instantly and controls the
heterogeneities and assures homogeneities among transactions added to the
window. To minimize the memory utilization, computational cost and improve the
process scalability, this design will allow fixing the coverage or support at
window level. Here in this document, an incremental mining of frequent
item-sets from the window and a context variation analysis approach are being
introduced. The complete technology that we are presenting in this document is
named as Mining Frequent Item-sets using Variable Window Size fixed by Context
Variation Analysis (MFI-VWS-CVA). There are clear boundaries among frequent and
infrequent item-sets in specific item-sets. In this design we have used window
size change to represent the conceptual drift in an information stream. As it
were, whenever there is a problem in setting window size effectively the
item-set will be infrequent. The experiments that we have executed and
documented proved that the algorithm that we have designed is much efficient
than that of existing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3181</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3181</id><created>2014-08-13</created><authors><author><keyname>Wang</keyname><forenames>Tianyu</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author></authors><title>Coalitional Graph Games for Popular Content Distribution in Cognitive
  Radio VANETs</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Popular content distribution is one of the key services provided by vehicular
ad hoc networks (VANETs), in which a popular file is broadcasted by roadside
units (RSUs) to the on-board units (OBUs) driving through a particular area.
Due to fast speed and deep fading, some file packets might be lost during the
vehicle-to-roadside broadcasting stage. In this paper, we propose a
peer-to-peer (P2P) approach to allow the OBUs to exchange data and complement
the missing packets. Specifically, we introduce a coalitional graph game to
model the cooperation among OBUs and propose a coalition formation algorithm to
implement the P2P approach. Moreover, cognitive radio is utilized for
vehicle-to-vehicle transmissions so that the P2P approach does not require
additional bandwidth. Simulation results show that the proposed approach
performs better in various conditions, relative to the non-cooperative
approach, in which the OBUs share no information and simply response to any
data request from other OBUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3182</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3182</id><created>2014-08-13</created><authors><author><keyname>Wang</keyname><forenames>Tianyu</forenames></author><author><keyname>Song</keyname><forenames>Lingyang</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author></authors><title>Distributed Cooperative Sensing in Cognitive Radio Networks: An
  Overlapping Coalition Formation Approach</title><categories>cs.NI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative spectrum sensing has been shown to yield a significant
performance improvement in cognitive radio networks. In this paper, we consider
distributed cooperative sensing (DCS) in which secondary users (SUs) exchange
data with one another instead of reporting to a common fusion center. In most
existing DCS algorithms, the SUs are grouped into disjoint cooperative groups
or coalitions, and within each coalition the local sensing data is exchanged.
However, these schemes do not account for the possibility that an SU can be
involved in multiple cooperative coalitions thus forming overlapping
coalitions. Here, we address this problem using novel techniques from a class
of cooperative games, known as overlapping coalition formation games, and based
on the game model, we propose a distributed DCS algorithm in which the SUs
self-organize into a desirable network structure with overlapping coalitions.
Simulation results show that the proposed overlapping algorithm yields
significant performance improvements, decreasing the total error probability up
to 25% in the Q_m+Q_f criterion, the missed detection probability up to 20% in
the Q_m/Q_f criterion, the overhead up to 80%, and the total report number up
to 10%, compared with the state-of-the-art non-overlapping algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3190</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3190</id><created>2014-08-14</created><authors><author><keyname>Bonamy</keyname><forenames>Marthe</forenames></author><author><keyname>Przyby&#x142;o</keyname><forenames>Jakub</forenames></author></authors><title>On the neighbour sum distinguishing index of planar graphs</title><categories>cs.DM math.CO</categories><comments>22 pages</comments><msc-class>05C78, 05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $c$ be a proper edge colouring of a graph $G=(V,E)$ with integers
$1,2,\ldots,k$. Then $k\geq \Delta(G)$, while by Vizing's theorem, no more than
$k=\Delta(G)+1$ is necessary for constructing such $c$. On the course of
investigating irregularities in graphs, it has been moreover conjectured that
only slightly larger $k$, i.e., $k=\Delta(G)+2$ enables enforcing additional
strong feature of $c$, namely that it attributes distinct sums of incident
colours to adjacent vertices in $G$ if only this graph has no isolated edges
and is not isomorphic to $C_5$. We prove the conjecture is valid for planar
graphs of sufficiently large maximum degree. In fact even stronger statement
holds, as the necessary number of colours stemming from the result of Vizing is
proved to be sufficient for this family of graphs. Specifically, our main
result states that every planar graph $G$ of maximum degree at least $28$ which
contains no isolated edges admits a proper edge colouring
$c:E\to\{1,2,\ldots,\Delta(G)+1\}$ such that $\sum_{e\ni u}c(e)\neq \sum_{e\ni
v}c(e)$ for every edge $uv$ of $G$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3193</identifier>
 <datestamp>2015-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3193</id><created>2014-08-14</created><updated>2015-04-10</updated><authors><author><keyname>Nayebi</keyname><forenames>Aran</forenames></author><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author><author><keyname>Belovs</keyname><forenames>Aleksandrs</forenames></author><author><keyname>Trevisan</keyname><forenames>Luca</forenames></author></authors><title>Quantum lower bound for inverting a permutation with advice</title><categories>quant-ph cs.CC cs.CR</categories><comments>To appear in Quantum Information &amp; Computation. Revised version based
  on referee comments</comments><journal-ref>Quantum Information &amp; Computation, 15(11 &amp; 12): 901-913, September
  2015</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a random permutation $f: [N] \to [N]$ as a black box and $y \in [N]$,
we want to output $x = f^{-1}(y)$. Supplementary to our input, we are given
classical advice in the form of a pre-computed data structure; this advice can
depend on the permutation but \emph{not} on the input $y$. Classically, there
is a data structure of size $\tilde{O}(S)$ and an algorithm that with the help
of the data structure, given $f(x)$, can invert $f$ in time $\tilde{O}(T)$, for
every choice of parameters $S$, $T$, such that $S\cdot T \ge N$. We prove a
quantum lower bound of $T^2\cdot S \ge \tilde{\Omega}(\epsilon N)$ for quantum
algorithms that invert a random permutation $f$ on an $\epsilon$ fraction of
inputs, where $T$ is the number of queries to $f$ and $S$ is the amount of
advice. This answers an open question of De et al.
  We also give a $\Omega(\sqrt{N/m})$ quantum lower bound for the simpler but
related Yao's box problem, which is the problem of recovering a bit $x_j$,
given the ability to query an $N$-bit string $x$ at any index except the
$j$-th, and also given $m$ bits of advice that depend on $x$ but not on $j$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3195</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3195</id><created>2014-08-14</created><authors><author><keyname>Xu</keyname><forenames>Wenjie</forenames></author><author><keyname>Quitin</keyname><forenames>Francois</forenames></author><author><keyname>Leng</keyname><forenames>Mei</forenames></author><author><keyname>Tay</keyname><forenames>Wee Peng</forenames></author><author><keyname>Razul</keyname><forenames>Sirajudeen G.</forenames></author></authors><title>Distributed localization of a RF target in NLOS environments</title><categories>cs.IT math.IT</categories><comments>30 pages, 11 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We propose a novel distributed expectation maximization (EM) method for
non-cooperative RF device localization using a wireless sensor network. We
consider the scenario where few or no sensors receive line-of-sight signals
from the target. In the case of non-line-of-sight signals, the signal path
consists of a single reflection between the transmitter and receiver. Each
sensor is able to measure the time difference of arrival of the target's signal
with respect to a reference sensor, as well as the angle of arrival of the
target's signal. We derive a distributed EM algorithm where each node makes use
of its local information to compute summary statistics, and then shares these
statistics with its neighbors to improve its estimate of the target
localization. Since all the measurements need not be centralized at a single
location, the spectrum usage can be significantly reduced. The distributed
algorithm also allows for increased robustness of the sensor network in the
case of node failures. We show that our distributed algorithm converges, and
simulation results suggest that our method achieves an accuracy close to the
centralized EM algorithm. We apply the distributed EM algorithm to a set of
experimental measurements with a network of four nodes, which confirm that the
algorithm is able to localize a RF target in a realistic non-line-of-sight
scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3198</identifier>
 <datestamp>2014-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3198</id><created>2014-08-14</created><updated>2014-11-26</updated><authors><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author></authors><title>Cutting Last Wires for Mobile Communications by Microwave Power Transfer</title><categories>cs.IT math.IT</categories><comments>11 pages, 5 figures. This paper will appear in the April special
  issue of IEEE Communications Magazine on Energy Harvesting Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advancements in microwave power transfer (MPT) over past decades have
enabled wireless power transfer over long distances. The latest breakthroughs
in wireless communication, namely massive MIMO, small cells and millimeter-wave
communication, make wireless networks suitable platforms for implementing MPT.
This can lead to the elimination of the &quot;last wires&quot; connecting mobile devices
to the grid for recharging, thereby tackling a long-standing ICT grand
challenge. Furthermore, the seamless integration between MPT and wireless
communication opens a new area called wirelessly powered communications (WPC)
where many new research directions arise e.g., simultaneous
information-and-power transfer, WPC network architectures, and techniques for
safe and efficient WPC. This article provides an introduction to WPC by
describing the key features of WPC, shedding light on a set of frequently asked
questions, and identifying the key design issues and discussing possible
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3202</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3202</id><created>2014-08-14</created><authors><author><keyname>Kumar</keyname><forenames>Surender</forenames></author><author><keyname>Prateek</keyname><forenames>Manish</forenames></author><author><keyname>Bhushan</keyname><forenames>Bharat</forenames></author></authors><title>Energy Efficient (EECP) Clustered Protocol for Heterogeneous Wireless
  Sensor Network</title><categories>cs.NI</categories><comments>6 pages, 6 figures, http://www.ijarcsse.com/7_July2013.php. arXiv
  admin note: text overlap with arXiv:1408.2914</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Energy Conservation and prolonging the life of Wireless Sensor Network is one
of the major issues in the wireless sensor network as sensor nodes are highly
energy constrained devices. Many routing protocols have been proposed for
sensor network, especially cluster based routing protocols. Cluster based
routing protocols are best known for its energy efficiency, network stability
and for increasing the life time of the sensor network. Low Energy Adaptive
Clustering Hierarchy (LEACH) is one of the fundamental protocols in this class.
In this research paper we propose a new energy efficient cluster based protocol
(EECP) for single hop heterogeneous wireless sensor network to increase the
life of a sensor network. Our sensor protocol use the distance of the sensor
from the sink as the major issue for the selection of a cluster in the sensor
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3206</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3206</id><created>2014-08-14</created><authors><author><keyname>Chen</keyname><forenames>He</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Jiang</keyname><forenames>Yunxiang</forenames></author><author><keyname>Ma</keyname><forenames>Yuanye</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Distributed Power Splitting for SWIPT in Relay Interference Channels
  using Game Theory</title><categories>cs.IT math.IT</categories><comments>Full version of a paper accepted by IEEE Trans. Wireless Commun., 14
  pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider simultaneous wireless information and power
transfer (SWIPT) in relay interference channels, where multiple
source-destination pairs communicate through their dedicated energy harvesting
relays. Each relay needs to split its received signal from sources into two
streams: one for information forwarding and the other for energy harvesting. We
develop a distributed power splitting framework using game theory to derive a
profile of power splitting ratios for all relays that can achieve a good
network-wide performance. Specifically, non-cooperative games are respectively
formulated for pure amplify-and-forward (AF) and decode-and-forward (DF)
networks, in which each link is modeled as a strategic player who aims to
maximize its own achievable rate. The existence and uniqueness for the Nash
equilibriums (NEs) of the formulated games are analyzed and a distributed
algorithm with provable convergence to achieve the NEs is also developed.
Subsequently, the developed framework is extended to the more general network
setting with mixed AF and DF relays. All the theoretical analyses are validated
by extensive numerical results. Simulation results show that the proposed
game-theoretical approach can achieve a near-optimal network-wide performance
on average, especially for the scenarios with relatively low and moderate
interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3215</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3215</id><created>2014-08-14</created><authors><author><keyname>Nugent</keyname><forenames>M. Alexander</forenames></author><author><keyname>Molter</keyname><forenames>Timothy W.</forenames></author></authors><title>Cortical Processing with Thermodynamic-RAM</title><categories>cs.NE cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  AHaH computing forms a theoretical framework from which a
biologically-inspired type of computing architecture can be built where, unlike
von Neumann systems, memory and processor are physically combined. In this
paper we report on an incremental step beyond the theoretical framework of AHaH
computing toward the development of a memristor-based physical neural
processing unit (NPU), which we call Thermodynamic-RAM (kT-RAM). While the
power consumption and speed dominance of such an NPU over von Neumann
architectures for machine learning applications is well appreciated,
Thermodynamic-RAM offers several advantages over other hardware approaches to
adaptation and learning. Benefits include general-purpose use, a simple yet
flexible instruction set and easy integration into existing digital platforms.
We present a high level design of kT-RAM and a formal definition of its
instruction set. We report the completion of a kT-RAM emulator and the
successful port of all previous machine learning benchmark applications
including unsupervised clustering, supervised and unsupervised classification,
complex signal prediction, unsupervised robotic actuation and combinatorial
optimization. Lastly, we extend a previous MNIST hand written digits benchmark
application, to show that an extra step of reading the synaptic states of AHaH
nodes during the train phase (healing) alone results in plasticity that
improves the classifier's performance, bumping our best F1 score up to 99.5%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3218</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3218</id><created>2014-08-14</created><authors><author><keyname>Saleh</keyname><forenames>Babak</forenames></author><author><keyname>Abe</keyname><forenames>Kanako</forenames></author><author><keyname>Arora</keyname><forenames>Ravneet Singh</forenames></author><author><keyname>Elgammal</keyname><forenames>Ahmed</forenames></author></authors><title>Toward Automated Discovery of Artistic Influence</title><categories>cs.CV cs.LG</categories><comments>29 pages, 14 figures and 12 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering the huge amount of art pieces that exist, there is valuable
information to be discovered. Examining a painting, an expert can determine its
style, genre, and the time period that the painting belongs. One important task
for art historians is to find influences and connections between artists. Is
influence a task that a computer can measure? The contribution of this paper is
in exploring the problem of computer-automated suggestion of influences between
artists, a problem that was not addressed before in a general setting. We first
present a comparative study of different classification methodologies for the
task of fine-art style classification. A two-level comparative study is
performed for this classification problem. The first level reviews the
performance of discriminative vs. generative models, while the second level
touches the features aspect of the paintings and compares semantic-level
features vs. low-level and intermediate-level features present in the painting.
Then, we investigate the question &quot;Who influenced this artist?&quot; by looking at
his masterpieces and comparing them to others. We pose this interesting
question as a knowledge discovery problem. For this purpose, we investigated
several painting-similarity and artist-similarity measures. As a result, we
provide a visualization of artists (Map of Artists) based on the similarity
between their works
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3223</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3223</id><created>2014-08-14</created><authors><author><keyname>Kuang</keyname><forenames>Quan</forenames></author></authors><title>Joint User Association and Reuse Pattern Selection in Heterogeneous
  Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>accepted in eleventh international Symposium on Wireless
  Communication Systems (ISWCS) 2014, Spain</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The successful deployment of LTE heterogeneous networks (HetNets) depends
crucially on the inter-cell interference (ICI) management. Among ICI
coordination schemes, fractional frequency reuse (FFR) is considered as an
efficient technique well-suited to OFDMA-based HetNets. Two coupled questions
in this context are: 1) how to associate users to appropriate base-stations
considering the long list of available candidate cells, and 2) how to allocate
frequency resources among multiple cells. In this paper, we treat the
multi-cell frequency allocation as frequency partitioning among multiple reuse
patterns, and develop a novel algorithm to solve these two coupled questions in
a joint manner. We also provide practical criterion to select the set of
essential candidate patterns from all possible patterns. Results show that the
proposed joint strategy improves both the cell-edge user and overall network
throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3229</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3229</id><created>2014-08-14</created><authors><author><keyname>Psillakis</keyname><forenames>Haris E.</forenames></author></authors><title>Robustness of the nonlinear PI control method to ignored actuator
  dynamics</title><categories>cs.SY math.OC</categories><comments>under review, 12 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note examines the robustness properties of the nonlinear PI control
method to ignored actuator dynamics. It is proven that global boundedness and
regulation can be achieved for sector bounded nonlinear systems with unknown
control directions if the actuator dynamics are sufficiently fast and the
nonlinear PI control gain is chosen from a subclass of the Nussbaum function
class. Simulation examples are also presented that demonstrate the validity of
our arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3231</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3231</id><created>2014-08-14</created><authors><author><keyname>Block</keyname><forenames>Delf</forenames></author><author><keyname>Heeren</keyname><forenames>S&#xf6;nke</forenames></author><author><keyname>K&#xfc;hnel</keyname><forenames>Stefan</forenames></author><author><keyname>Leschke</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Rumpe</keyname><forenames>Bernhard</forenames></author><author><keyname>Serebro</keyname><forenames>Vladislavs</forenames></author></authors><title>Simulations on Consumer Tests: A Perspective for Driver Assistance
  Systems</title><categories>cs.SE</categories><comments>6 pages, 5 figure, Proceedings of International Workshop on
  Engineering Simulations for Cyber-Physical Systems (ES4CPS '14)</comments><doi>10.1145/2559627.2559633</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article discusses new challenges for series development regarding the
vehicle safety that arise from the recently published AEB test protocol by the
consumer-test-organisation EuroNCAP for driver assistance systems [6]. The
tests from the test protocol are of great significance for an OEM that sells
millions of cars each year, due to the fact that a positive rating of the
vehicle-under-test (VUT) in safety relevant aspects is important for the
reputation of a car manufacturer. The further intensification and aggravation
of the test requirements for those systems is one of the challenges, that has
to be mastered in order to continuously make significant contributions to
safety for high-volume cars. Therefore, it is to be shown how a simulation
approach may support the development process, especially with tolerance
analysis. This article discusses the current stage of work, steps that are
planned for the future and results that can be expected at the end of such an
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3245</identifier>
 <datestamp>2014-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3245</id><created>2014-08-14</created><updated>2014-08-22</updated><authors><author><keyname>Abdelsatir</keyname><forenames>El-Tigani B.</forenames></author><author><keyname>Salahaldeen</keyname><forenames>Sahar</forenames></author><author><keyname>Omar</keyname><forenames>Hyam</forenames></author><author><keyname>Hashim</keyname><forenames>Afra</forenames></author></authors><title>A Novel (k,n) Secret Sharing Scheme from Quadratic Residues for
  Grayscale Images</title><categories>cs.CR</categories><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.6, No.4, July 2014</journal-ref><doi>10.5121/ijnsa.2014.6406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new grayscale image encryption algorithm based on $(k,n)$ threshold secret
sharing is proposed. The scheme allows a secret image to be transformed into
$n$ shares, where any $k \le n$ shares can be used to reconstruct the secret
image, while the knowledge of $k-1$ or fewer shares leaves no sufficient
information about the secret image and it becomes hard to decrypt the
transmitted image. In the proposed scheme, the pixels of the secret image are
first permuted and then encrypted by using quadratic residues. In the final
stage, the encrypted image is shared into n shadow images using polynomials of
Shamir scheme. The proposed scheme is provably secure and the experimental
results shows that the scheme performs well while maintaining high levels of
quality in the reconstructed image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3253</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3253</id><created>2014-08-14</created><updated>2014-08-17</updated><authors><author><keyname>Kelemen</keyname><forenames>Z&#xe1;dor D&#xe1;niel</forenames></author><author><keyname>B&#xe9;ny&#xe1;sz</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Badinka</keyname><forenames>Zolt&#xe1;n</forenames></author></authors><title>A measurement based software quality framework</title><categories>cs.SE</categories><comments>19 pages</comments><report-no>TKPH-QDTR-201401</report-no><doi>10.13140/2.1.3484.3528</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report we propose a solution to problem of the dependency on the
experience of the software project quality assurance personnel by providing a
transparent, objective and measurement based quality framework. The framework
helps the quality assurance experts making objective and comparable decisions
in software projects by defining and assessing measurable quality goals and
thresholds, directly relating these to an escalation mechanism. First results
of applying the proposed measurement based software quality framework in a real
life case study are also addressed in this report.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3264</identifier>
 <datestamp>2016-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3264</id><created>2014-08-14</created><updated>2016-01-06</updated><authors><author><keyname>Keyvanrad</keyname><forenames>Mohammad Ali</forenames></author><author><keyname>Homayounpour</keyname><forenames>Mohammad Mehdi</forenames></author></authors><title>A brief survey on deep belief networks and introducing a new object
  oriented toolbox (DeeBNet)</title><categories>cs.CV cs.LG cs.MS cs.NE</categories><comments>Technical Report 27 pages, Ver3.0</comments><msc-class>68T01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, this is very popular to use the deep architectures in machine
learning. Deep Belief Networks (DBNs) are deep architectures that use stack of
Restricted Boltzmann Machines (RBM) to create a powerful generative model using
training data. DBNs have many ability like feature extraction and
classification that are used in many applications like image processing, speech
processing and etc. This paper introduces a new object oriented MATLAB toolbox
with most of abilities needed for the implementation of DBNs. In the new
version, the toolbox can be used in Octave. According to the results of the
experiments conducted on MNIST (image), ISOLET (speech), and 20 Newsgroups
(text) datasets, it was shown that the toolbox can learn automatically a good
representation of the input from unlabeled data with better discrimination
between different classes. Also on all datasets, the obtained classification
errors are comparable to those of state of the art classifiers. In addition,
the toolbox supports different sampling methods (e.g. Gibbs, CD, PCD and our
new FEPCD method), different sparsity methods (quadratic, rate distortion and
our new normal method), different RBM types (generative and discriminative),
using GPU, etc. The toolbox is a user-friendly open source software and is
freely available on the website
http://ceit.aut.ac.ir/~keyvanrad/DeeBNet%20Toolbox.html .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3270</identifier>
 <datestamp>2014-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3270</id><created>2014-08-14</created><updated>2014-12-03</updated><authors><author><keyname>Lizier</keyname><forenames>Joseph T.</forenames></author></authors><title>JIDT: An information-theoretic toolkit for studying the dynamics of
  complex systems</title><categories>cs.IT cs.MS cs.SI math.IT nlin.AO physics.data-an</categories><comments>37 pages, 4 figures</comments><msc-class>94A15</msc-class><journal-ref>Frontiers in Robotics and AI, 1:11, 2014</journal-ref><doi>10.3389/frobt.2014.00011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex systems are increasingly being viewed as distributed information
processing systems, particularly in the domains of computational neuroscience,
bioinformatics and Artificial Life. This trend has resulted in a strong uptake
in the use of (Shannon) information-theoretic measures to analyse the dynamics
of complex systems in these fields. We introduce the Java Information Dynamics
Toolkit (JIDT): a Google code project which provides a standalone, (GNU GPL v3
licensed) open-source code implementation for empirical estimation of
information-theoretic measures from time-series data. While the toolkit
provides classic information-theoretic measures (e.g. entropy, mutual
information, conditional mutual information), it ultimately focusses on
implementing higher-level measures for information dynamics. That is, JIDT
focusses on quantifying information storage, transfer and modification, and the
dynamics of these operations in space and time. For this purpose, it includes
implementations of the transfer entropy and active information storage, their
multivariate extensions and local or pointwise variants. JIDT provides
implementations for both discrete and continuous-valued data for each measure,
including various types of estimator for continuous data (e.g. Gaussian,
box-kernel and Kraskov-Stoegbauer-Grassberger) which can be swapped at run-time
due to Java's object-oriented polymorphism. Furthermore, while written in Java,
the toolkit can be used directly in MATLAB, GNU Octave, Python and other
environments. We present the principles behind the code design, and provide
several examples to guide users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3286</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3286</id><created>2014-08-13</created><authors><author><keyname>Schuh</keyname><forenames>Bernd R.</forenames></author></authors><title>SAT for pedestrians</title><categories>cs.CC math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this short note is mainly pedagogical. It summarizes some
knowledge about Boolean satisfiability (SAT) and the P=NP? problem in an
elementary mathematical language. A convenient scheme to visualize and
manipulate CNF formulae is introduced. Also some results like the formulae for
the number of unsatisfied clauses and the number of solutions might be unknown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3297</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3297</id><created>2014-08-13</created><authors><author><keyname>Isenberg</keyname><forenames>Petra</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Isenberg</keyname><forenames>Tobias</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Sedlmair</keyname><forenames>Michael</forenames></author><author><keyname>Chen</keyname><forenames>Jian</forenames></author><author><keyname>M&#xf6;ller</keyname><forenames>Torsten</forenames></author></authors><title>Toward a deeper understanding of Visualization through keyword analysis</title><categories>cs.DL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the results of a comprehensive analysis of visualization paper
keywords supplied for 4366 papers submitted to five main visualization
conferences. We describe main keywords, topic areas, and 10-year historic
trends from two datasets: (1) the standardized PCS taxonomy keywords in use for
paper submissions for IEEE InfoVis, IEEE Vis-SciVis, IEEE VAST, EuroVis, and
IEEE PacificVis since 2009 and (2) the author-chosen keywords for papers
published in the IEEE Visualization conference series (now called IEEE VIS)
since 2004. Our analysis of research topics in visualization can serve as a
starting point to (a) help create a common vocabulary to improve communication
among different visualization sub-groups, (b) facilitate the process of
understanding differences and commonalities of the various research sub-fields
in visualization, (c) provide an understanding of emerging new research trends,
(d) facilitate the crucial step of finding the right reviewers for research
submissions, and (e) it can eventually lead to a comprehensive taxonomy of
visualization research. One additional tangible outcome of our work is an
application that allows visualization researchers to easily browse the 2600+
keywords used for IEEE VIS papers during the past 10 years, aiming at more
informed and, hence, more effective keyword selections for future visualization
publications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3300</identifier>
 <datestamp>2014-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3300</id><created>2014-08-13</created><updated>2014-09-03</updated><authors><author><keyname>Gong</keyname><forenames>Yuanhao</forenames></author><author><keyname>Sbalzarini</keyname><forenames>Ivo F.</forenames></author></authors><title>Gradient Distribution Priors for Biomedical Image Processing</title><categories>cs.CV</categories><comments>submitted to journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ill-posed inverse problems are commonplace in biomedical image processing.
Their solution typically requires imposing prior knowledge about the latent
ground truth. While this regularizes the problem to an extent where it can be
solved, it also biases the result toward the expected. With inappropriate
priors harming more than they use, it remains unclear what prior to use for a
given practical problem. Priors are hence mostly chosen in an {\em ad hoc} or
empirical fashion. We argue here that the gradient distribution of
natural-scene images may provide a versatile and well-founded prior for
biomedical images. We provide motivation for this choice from different points
of view, and we fully validate the resulting prior for use on biomedical images
by showing its stability and correlation with image quality. We then provide a
set of simple parametric models for the resulting prior, leading to
straightforward (quasi-)convex optimization problems for which we provide
efficient solver algorithms. We illustrate the use of the present models and
solvers in a variety of common image-processing tasks, including contrast
enhancement, noise level estimation, denoising, blind deconvolution,
zooming/up-sampling, and dehazing. In all cases we show that the present method
leads to results that are comparable to or better than the state of the art;
always using the same, simple prior. We conclude by discussing the limitations
and possible interpretations of the prior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3304</identifier>
 <datestamp>2015-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3304</id><created>2014-08-14</created><updated>2015-05-05</updated><authors><author><keyname>Chari</keyname><forenames>Visesh</forenames></author><author><keyname>Lacoste-Julien</keyname><forenames>Simon</forenames></author><author><keyname>Laptev</keyname><forenames>Ivan</forenames></author><author><keyname>Sivic</keyname><forenames>Josef</forenames></author></authors><title>On Pairwise Costs for Network Flow Multi-Object Tracking</title><categories>cs.CV math.OC</categories><journal-ref>The IEEE Conference on Computer Vision and Pattern Recognition
  (CVPR), 2015, pp. 5537-5545</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-object tracking has been recently approached with the min-cost network
flow optimization techniques. Such methods simultaneously resolve multiple
object tracks in a video and enable modeling of dependencies among tracks.
Min-cost network flow methods also fit well within the &quot;tracking-by-detection&quot;
paradigm where object trajectories are obtained by connecting per-frame outputs
of an object detector. Object detectors, however, often fail due to occlusions
and clutter in the video. To cope with such situations, we propose to add
pairwise costs to the min-cost network flow framework. While integer solutions
to such a problem become NP-hard, we design a convex relaxation solution with
an efficient rounding heuristic which empirically gives certificates of small
suboptimality. We evaluate two particular types of pairwise costs and
demonstrate improvements over recent tracking methods in real-world video
sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3309</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3309</id><created>2014-08-14</created><authors><author><keyname>Nam</keyname><forenames>Nguyen H.</forenames></author></authors><title>Utilizing the Active and Collaborative Learning Model in the
  Introductory Physics Course</title><categories>cs.CY</categories><journal-ref>Journal of Education &amp; Learning, Vol.3 No.3 September, 2014,
  pp.108-124</journal-ref><doi>10.5539/jel.v3n3p108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model of active and collaborative learning applied in training specific
subject makes clear advantage due to the goals of knowledge, skills that
students got to develop successful future job. The author exploits the learning
management system of Hanoi National University of Education to establish a
learning environment in the Introductory Physics course Part 2, which supports
to the blended learning, for the 1st year student. The method of pattern
languages is taken to redesign learning content in the framework of ACLM, which
focused on analysing real-life application and doing exercises, with the
support of information and communication technology. Both formative and
summative assessments were used to evaluate competency of students.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3310</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3310</id><created>2014-08-14</created><updated>2016-02-08</updated><authors><author><keyname>Paolini</keyname><forenames>Giovanni</forenames></author></authors><title>An algorithm for canonical forms of finite subsets of $\mathbb{Z}^d$ up
  to affinities</title><categories>cs.DS cs.DM math.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe an algorithm for the computation of canonical
forms of finite subsets of $\mathbb{Z}^d$, up to affinities over $\mathbb{Z}$.
For fixed dimension $d$, the worst-case asymptotic complexity of this algorithm
is $O(n \log^2 n \, s\,\mu(s))$, where $n$ is the number of points in the given
subset, $s$ is an upper bound to the size of the binary representation of any
of the $n$ points, and $\mu(s)$ is an upper bound to the number of operations
required to multiply two $s$-bit numbers. This problem arises e.g. in the
context of invariants computation of finitely presented groups with abelianized
group isomorphic to $\mathbb{Z}^d$. In that context one needs to decide whether
two Laurent polynomials in $d$ indeterminates, considered as elements of the
group ring over the abelianized group, are equivalent with respect to a change
of base.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3317</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3317</id><created>2014-08-14</created><authors><author><keyname>van Hulst</keyname><forenames>Allan</forenames></author><author><keyname>Reniers</keyname><forenames>Michel</forenames></author><author><keyname>Fokkink</keyname><forenames>Wan</forenames></author></authors><title>Maximally Permissive Controlled System Synthesis for Modal Logic</title><categories>cs.FL cs.LO cs.SY</categories><comments>SOFSEM 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method for controlled system synthesis on non-deterministic
automata, which includes the synthesis for deadlock-freeness, as well as
invariant and reachability expressions. Our technique restricts the behavior of
a Kripke-structure with labeled transitions, representing the uncontrolled
system, such that it adheres to a given requirement specification in an
expressive modal logic. while all non-invalidating behavior is retained. This
induces maximal permissiveness in the context of supervisory control. Research
presented in this paper allows a system model to be constrained according to a
broad set of liveness, safety and fairness specifications of desired behavior,
and embraces most concepts from Ramadge-Wonham supervisory control, including
controllability and marker-state reachability. Synthesis is defined in this
paper as a formal construction, which allowed a careful validation of its
correctness using the Coq proof assistant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3325</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3325</id><created>2014-08-14</created><authors><author><keyname>Bekos</keyname><forenames>Michael A.</forenames></author><author><keyname>van Dijk</keyname><forenames>Thomas C.</forenames></author><author><keyname>Kindermann</keyname><forenames>Philipp</forenames></author><author><keyname>Wolff</keyname><forenames>Alexander</forenames></author></authors><title>Simultaneous Drawing of Planar Graphs with Right-Angle Crossings and Few
  Bends</title><categories>cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two planar graphs that are defined on the same set of vertices, a RAC
simultaneous drawing is one in which each graph is drawn planar, there are no
edge overlaps and the crossings between the two graphs form right angles. The
geometric version restricts the problem to straight-line drawings. It is known,
however, that there exists a wheel and a matching which do not admit a
geometric RAC simultaneous drawing.
  In order to enlarge the class of graphs that admit RAC simultaneous drawings,
we allow bends in the resulting drawings. We prove that two planar graphs
always admit a RAC simultaneous drawing with six bends per edge each, in
quadratic area. For more restricted classes of planar graphs (i.e., matchings,
paths, cycles, outerplanar graphs and subhamiltonian graphs), we manage to
significantly reduce the required number of bends per edge, while keeping the
area quadratic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3326</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3326</id><created>2014-08-14</created><authors><author><keyname>Kozlov</keyname><forenames>Yeara</forenames></author><author><keyname>Esturo</keyname><forenames>Janick Martinez</forenames></author><author><keyname>Seidel</keyname><forenames>Hans-Peter</forenames></author><author><keyname>Weinkauf</keyname><forenames>Tino</forenames></author></authors><title>Regularized Harmonic Surface Deformation</title><categories>cs.GR</categories><comments>9 pages, 7 figures</comments><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Harmonic surface deformation is a well-known geometric modeling method that
creates plausible deformations in an interactive manner. However, this method
is susceptible to artifacts, in particular close to the deformation handles.
These artifacts often correlate with strong gradients of the deformation
energy.In this work, we propose a novel formulation of harmonic surface
deformation, which incorporates a regularization of the deformation energy. To
do so, we build on and extend a recently introduced generic linear
regularization approach. It can be expressed as a change of norm for the linear
optimization problem, i.e., the regularization is baked into the optimization.
This minimizes the implementation complexity and has only a small impact on
runtime. Our results show that a moderate use of regularization suppresses many
deformation artifacts common to the well-known harmonic surface deformation
method, without introducing new artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3332</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3332</id><created>2014-08-14</created><authors><author><keyname>Nedelko</keyname><forenames>Victor</forenames></author></authors><title>Exact and empirical estimation of misclassification probability</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the problem of risk estimation in the classification problem, with
specific focus on finding distributions that maximize the confidence intervals
of risk estimation. We derived simple analytic approximations for the maximum
bias of empirical risk for histogram classifier. We carry out a detailed study
on using these analytic estimates for empirical estimation of risk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3337</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3337</id><created>2014-08-14</created><authors><author><keyname>Seff</keyname><forenames>Ari</forenames></author><author><keyname>Lu</keyname><forenames>Le</forenames></author><author><keyname>Cherry</keyname><forenames>Kevin M.</forenames></author><author><keyname>Roth</keyname><forenames>Holger</forenames></author><author><keyname>Liu</keyname><forenames>Jiamin</forenames></author><author><keyname>Wang</keyname><forenames>Shijun</forenames></author><author><keyname>Hoffman</keyname><forenames>Joanne</forenames></author><author><keyname>Turkbey</keyname><forenames>Evrim B.</forenames></author><author><keyname>Summers</keyname><forenames>Ronald M.</forenames></author></authors><title>2D View Aggregation for Lymph Node Detection Using a Shallow Hierarchy
  of Linear Classifiers</title><categories>cs.CV cs.LG</categories><comments>This article will be presented at MICCAI (Medical Image Computing and
  Computer-Assisted Intervention) 2014</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Enlarged lymph nodes (LNs) can provide important information for cancer
diagnosis, staging, and measuring treatment reactions, making automated
detection a highly sought goal. In this paper, we propose a new algorithm
representation of decomposing the LN detection problem into a set of 2D object
detection subtasks on sampled CT slices, largely alleviating the curse of
dimensionality issue. Our 2D detection can be effectively formulated as linear
classification on a single image feature type of Histogram of Oriented
Gradients (HOG), covering a moderate field-of-view of 45 by 45 voxels. We
exploit both simple pooling and sparse linear fusion schemes to aggregate these
2D detection scores for the final 3D LN detection. In this manner, detection is
more tractable and does not need to perform perfectly at instance level (as
weak hypotheses) since our aggregation process will robustly harness collective
information for LN detection. Two datasets (90 patients with 389 mediastinal
LNs and 86 patients with 595 abdominal LNs) are used for validation.
Cross-validation demonstrates 78.0% sensitivity at 6 false positives/volume
(FP/vol.) (86.1% at 10 FP/vol.) and 73.1% sensitivity at 6 FP/vol. (87.2% at 10
FP/vol.), for the mediastinal and abdominal datasets respectively. Our results
compare favorably to previous state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3351</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3351</id><created>2014-08-14</created><updated>2014-08-18</updated><authors><author><keyname>Fekete</keyname><forenames>S&#xe1;ndor P.</forenames></author><author><keyname>Hendricks</keyname><forenames>Jacob</forenames></author><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Rogers</keyname><forenames>Trent A.</forenames></author><author><keyname>Schweller</keyname><forenames>Robert T.</forenames></author></authors><title>Universal Computation with Arbitrary Polyomino Tiles in Non-Cooperative
  Self-Assembly</title><categories>cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore the power of geometry to overcome the limitations of
non-cooperative self-assembly. We define a generalization of the abstract Tile
Assembly Model (aTAM), such that a tile system consists of a collection of
polyomino tiles, the Polyomino Tile Assembly Model (polyTAM), and investigate
the computational powers of polyTAM systems at temperature 1, where attachment
among tiles occurs without glue cooperation. Systems composed of the
unit-square tiles of the aTAM at temperature 1 are believed to be incapable of
Turing universal computation (while cooperative systems, with temperature &gt; 1,
are able). As our main result, we prove that for any polyomino $P$ of size 3 or
greater, there exists a temperature-1 polyTAM system containing only shape-$P$
tiles that is computationally universal. Our proof leverages the geometric
properties of these larger (relative to the aTAM) tiles and their abilities to
effectively utilize geometric blocking of particular growth paths of
assemblies, while allowing others to complete.
  To round out our main result, we provide strong evidence that size-1 (i.e.
aTAM tiles) and size-2 polyomino systems are unlikely to be computationally
universal by showing that such systems are incapable of geometric bit-reading,
which is a technique common to all currently known temperature-1
computationally universal systems. We further show that larger polyominoes with
a limited number of binding positions are unlikely to be computationally
universal, as they are only as powerful as temperature-1 aTAM systems. Finally,
we connect our work with other work on domino self-assembly to show that
temperature-1 assembly with at least 2 distinct shapes, regardless of the
shapes or their sizes, allows for universal computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3354</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3354</id><created>2014-08-07</created><authors><author><keyname>Plata-Chaves</keyname><forenames>Jorge</forenames></author><author><keyname>Bogdanovic</keyname><forenames>Nikola</forenames></author><author><keyname>Berberidis</keyname><forenames>Kostas</forenames></author></authors><title>Distributed Diffusion-Based LMS for Node-Specific Adaptive Parameter
  Estimation</title><categories>cs.CY cs.DC</categories><comments>13 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed adaptive algorithm is proposed to solve a node-specific
parameter estimation problem where nodes are interested in estimating
parameters of local interest, parameters of common interest to a subset of
nodes and parameters of global interest to the whole network. To address the
different node-specific parameter estimation problems, this novel algorithm
relies on a diffusion-based implementation of different Least Mean Squares
(LMS) algorithms, each associated with the estimation of a specific set of
local, common or global parameters. Coupled with the estimation of the
different sets of parameters, the implementation of each LMS algorithm is only
undertaken by the nodes of the network interested in a specific set of local,
common or global parameters. The study of convergence in the mean sense reveals
that the proposed algorithm is asymptotically unbiased. Moreover, a
spatial-temporal energy conservation relation is provided to evaluate the
steady-state performance at each node in the mean-square sense. Finally, the
theoretical results and the effectiveness of the proposed technique are
validated through computer simulations in the context of cooperative spectrum
sensing in Cognitive Radio networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3357</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3357</id><created>2014-08-14</created><authors><author><keyname>Xiong</keyname><forenames>Chenrong</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Improved Iterative Hard- and Soft-Reliability Based Majority-Logic
  Decoding Algorithms for Non-Binary Low-Density Parity-Check Codes</title><categories>cs.IT math.IT</categories><comments>12 pages, 11 figures</comments><doi>10.1109/TSP.2014.2349878</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-binary low-density parity-check (LDPC) codes have some advantages over
their binary counterparts, but unfortunately their decoding complexity is a
significant challenge. The iterative hard- and soft-reliability based
majority-logic decoding algorithms are attractive for non-binary LDPC codes,
since they involve only finite field additions and multiplications as well as
integer operations and hence have significantly lower complexity than other
algorithms. In this paper, we propose two improvements to the majority-logic
decoding algorithms. Instead of the accumulation of reliability information in
the existing majority-logic decoding algorithms, our first improvement is a new
reliability information update. The new update not only results in better error
performance and fewer iterations on average, but also further reduces
computational complexity. Since existing majority-logic decoding algorithms
tend to have a high error floor for codes whose parity check matrices have low
column weights, our second improvement is a re-selection scheme, which leads to
much lower error floors, at the expense of more finite field operations and
integer operations, by identifying periodic points, re-selecting intermediate
hard decisions, and changing reliability information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3359</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3359</id><created>2014-08-13</created><authors><author><keyname>Li</keyname><forenames>Bing</forenames></author><author><keyname>Zha</keyname><forenames>Hongyuan</forenames></author><author><keyname>Chiaromonte</keyname><forenames>Francesca</forenames></author></authors><title>Linear Contour Learning: A Method for Supervised Dimension Reduction</title><categories>cs.LG</categories><comments>Appears in Proceedings of the Twentieth Conference on Uncertainty in
  Artificial Intelligence (UAI2004)</comments><proxy>auai</proxy><report-no>UAI-P-2004-PG-349-356</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel approach to sufficient dimension reduction in regression,
based on estimating contour directions of negligible variation for the response
surface. These directions span the orthogonal complement of the minimal space
relevant for the regression, and can be extracted according to a measure of the
variation in the response, leading to General Contour Regression(GCR). In
comparison to exiisting sufficient dimension reduction techniques, this
sontour-based mothology guarantees exhaustive estimation of the central space
under ellipticity of the predictoor distribution and very mild additional
assumptions, while maintaining vn-consisytency and somputational ease.
Moreover, it proves to be robust to departures from ellipticity. We also
establish some useful population properties for GCR. Simulations to compare
performance with that of standard techniques such as ordinary least squares,
sliced inverse regression, principal hessian directions, and sliced average
variance estimation confirm the advntages anticipated by theoretical analyses.
We also demonstrate the use of contour-based methods on a data set concerning
grades of students from Massachusetts colleges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3373</identifier>
 <datestamp>2016-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3373</id><created>2014-08-14</created><updated>2016-02-26</updated><authors><author><keyname>Cooney</keyname><forenames>Tom</forenames></author><author><keyname>Mosonyi</keyname><forenames>Mil&#xe1;n</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Strong converse exponents for a quantum channel discrimination problem
  and quantum-feedback-assisted communication</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><comments>v3: 35 pages, 4 figures, accepted for publication in Communications
  in Mathematical Physics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the difficulty of discriminating between an arbitrary
quantum channel and a &quot;replacer&quot; channel that discards its input and replaces
it with a fixed state. We show that, in this particular setting, the most
general adaptive discrimination strategies provide no asymptotic advantage over
non-adaptive tensor-power strategies. This conclusion follows by proving a
quantum Stein's lemma for this channel discrimination setting, showing that a
constant bound on the Type I error leads to the Type II error decreasing to
zero exponentially quickly at a rate determined by the maximum relative entropy
registered between the channels. The strong converse part of the lemma states
that any attempt to make the Type II error decay to zero at a rate faster than
the channel relative entropy implies that the Type I error necessarily
converges to one. We then refine this latter result by identifying the optimal
strong converse exponent for this task. As a consequence of these results, we
can establish a strong converse theorem for the quantum-feedback-assisted
capacity of a channel, sharpening a result due to Bowen. Furthermore, our
channel discrimination result demonstrates the asymptotic optimality of a
non-adaptive tensor-power strategy in the setting of quantum illumination, as
was used in prior work on the topic. The sandwiched Renyi relative entropy is a
key tool in our analysis. Finally, by combining our results with recent results
of Hayashi and Tomamichel, we find a novel operational interpretation of the
mutual information of a quantum channel N as the optimal type II error exponent
when discriminating between a large number of independent instances of N and an
arbitrary &quot;worst-case&quot; replacer channel chosen from the set of all replacer
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3374</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3374</id><created>2014-08-14</created><updated>2016-02-22</updated><authors><author><keyname>Flajolet</keyname><forenames>Arthur</forenames></author><author><keyname>Blandin</keyname><forenames>Sebastien</forenames></author><author><keyname>Jaillet</keyname><forenames>Patrick</forenames></author></authors><title>Robust Adaptive Routing Under Uncertainty</title><categories>cs.DS math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding an optimal history-dependent routing
strategy on a directed graph weighted by stochastic arc costs when the
objective is to minimize the risk of spending more than a prescribed budget. To
help mitigate the impact of the lack of information on the arc cost probability
distributions, we introduce a robust counterpart where the distributions are
only known through confidence intervals on some statistics such as the mean,
the mean absolute deviation, and any quantile. Leveraging recent results in
distributionally robust optimization, we develop a general-purpose algorithm to
compute an approximate optimal strategy. To illustrate the benefits of the
robust approach, we run numerical experiments with field data from the
Singapore road network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3382</identifier>
 <datestamp>2014-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3382</id><created>2014-08-14</created><authors><author><keyname>Taylor</keyname><forenames>Colin</forenames></author><author><keyname>Veeramachaneni</keyname><forenames>Kalyan</forenames></author><author><keyname>O'Reilly</keyname><forenames>Una-May</forenames></author></authors><title>Likely to stop? Predicting Stopout in Massive Open Online Courses</title><categories>cs.CY cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding why students stopout will help in understanding how students
learn in MOOCs. In this report, part of a 3 unit compendium, we describe how we
build accurate predictive models of MOOC student stopout. We document a
scalable, stopout prediction methodology, end to end, from raw source data to
model analysis. We attempted to predict stopout for the Fall 2012 offering of
6.002x. This involved the meticulous and crowd-sourced engineering of over 25
predictive features extracted for thousands of students, the creation of
temporal and non-temporal data representations for use in predictive modeling,
the derivation of over 10 thousand models with a variety of state-of-the-art
machine learning techniques and the analysis of feature importance by examining
over 70000 models. We found that stop out prediction is a tractable problem.
Our models achieved an AUC (receiver operating characteristic
area-under-the-curve) as high as 0.95 (and generally 0.88) when predicting one
week in advance. Even with more difficult prediction problems, such as
predicting stop out at the end of the course with only one weeks' data, the
models attained AUCs of 0.7.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3432</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3432</id><created>2014-08-14</created><authors><author><keyname>Gafni</keyname><forenames>Eli</forenames></author></authors><title>Snapshot for Time: The One-Shot Case</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for one-shot problems - problems where a processor executes a
single operation-execution - timing constraints can be captured by conditions
on the relation between original outputs and supplementary snapshots. In
addition to the dictionary definition of the word snapshot, in distributed
computing snapshots also stand for a task that imposes relation among sets
which are output of processors. Hence, constrains relating the timing between
operation-executions of processors can be captured by the sets relation
representing a task.
  This allows to bring to bear techniques developed for tasks, to one-shot
objects. In particular, for the one-shot case the question of linearizability
is moot. Nevertheless, current proof techniques of object implementation
require the prover to provide linearization-points even in the one shot case.
Transforming the object into a task relieves the prover of an implementation
from the burden of finding the &quot;linearization-points,&quot; since if the task is
solvable, linearization points are guaranteed to exist. We exhibit this
advantage with a new algorithm to implement MWMR register in a SWMR system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3434</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3434</id><created>2014-08-14</created><authors><author><keyname>Kailkhura</keyname><forenames>Bhavya</forenames></author><author><keyname>Han</keyname><forenames>Yunghsiang S.</forenames></author><author><keyname>Brahma</keyname><forenames>Swastik</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Asymptotic Analysis of Distributed Bayesian Detection with Byzantine
  Data</title><categories>stat.AP cs.CR cs.GT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1307.3544</comments><doi>10.1109/LSP.2014.2365196</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we consider the problem of distributed Bayesian detection in
the presence of data falsifying Byzantines in the network. The problem of
distributed detection is formulated as a binary hypothesis test at the fusion
center (FC) based on 1-bit data sent by the sensors. Adopting Chernoff
information as our performance metric, we study the detection performance of
the system under Byzantine attack in the asymptotic regime. The expression for
minimum attacking power required by the Byzantines to blind the FC is obtained.
More specifically, we show that above a certain fraction of Byzantine attackers
in the network, the detection scheme becomes completely incapable of utilizing
the sensor data for detection. When the fraction of Byzantines is not
sufficient to blind the FC, we also provide closed form expressions for the
optimal attacking strategies for the Byzantines that most degrade the detection
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3438</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3438</id><created>2014-08-14</created><authors><author><keyname>Wang</keyname><forenames>Victoria</forenames></author><author><keyname>Tucker</keyname><forenames>John V.</forenames></author></authors><title>On the Role of Identity in Surveillance</title><categories>cs.CY cs.CR</categories><comments>Key Words: Surveillance, Identity, Social Sorting, Technology,
  Security</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surveillance is a process that observes behaviour, recognises properties and
identifies individuals. It has become a commonplace phenomenon in our everyday
life. Many surveillance practices depend on the use of advanced technologies to
collect, store and process data. We propose (i) an abstract definition of
surveillance; and (ii) an abstract definition of identity, designed to capture
the common structure of many disparate surveillance situations. We argue that
the notion of identity is fundamental to surveillance. Rather than having a
single identity, individuals have many identities, real and virtual, that are
used in different aspects of their lives. Most aspects of life are subject to
some form of surveillance, and observations and identities can be aggregated.
The notion of identity needs to be theorised. Our analysis is very general and,
at the same time, sufficiently precise to be the basis of mathematical models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3439</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3439</id><created>2014-08-14</created><authors><author><keyname>Wang</keyname><forenames>Victoria</forenames></author><author><keyname>Tucker</keyname><forenames>John V.</forenames></author></authors><title>Formalising Surveillance and Identity</title><categories>cs.CY cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surveillance is a social phenomenon that is general and commonplace, employed
by governments, companies and communities. Its ubiquity is due to technologies
for gathering and processing data; its strong and obvious effects raise
difficult social questions. We give a general definition of surveillance that
captures the notion in diverse situations and we illustrate it with some
disparate examples.A most important, if neglected,component idea is that of the
identity of the people or objects observed. We propose a general definition of
identifiers as data designed to specify the identity of an entity in some
context or for some purpose. We examine the ways identifiers depend upon other
identifiers and show the provenance of identifiers requires reductions between
identifiers and a special idea of personal identifier. The theory is formalised
mathematically. Finally, we reflect on the role of formal methods to give
insights in sociological contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3441</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3441</id><created>2014-08-14</created><authors><author><keyname>Kiran</keyname><forenames>Mariam</forenames></author></authors><title>Using FLAME Toolkit for Agent-Based Simulation: Case Study Sugarscape
  Model</title><categories>cs.MA</categories><comments>18 pages; 18 figures; technical report</comments><msc-class>91-04</msc-class><acm-class>C.1.4; I.2.11</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Social scientists have used agent-based models to understand how individuals
interact and behave in various political, ecological and economic scenarios.
Agent-based models are ideal for understanding such models involving
interacting individuals producing emergent phenomenon. Sugarscape is one of the
most famous examples of a social agent-based model which has been used to show
how societies grow in the real world.
  This paper builds on the Sugarscape model, using the Flexible Large scale
Agent-based modelling Environment (FLAME) to simulate three different scenarios
of the experiment, which are based on the Sugar and Citizen locations. FLAME is
an agent-based modelling framework which has previously been used to model
biological and economic models. The paper includes details on how the model was
written and the various parameters set for the simulation. The results of the
model simulated are processed for three scenarios and analysed to see what
affect the initial starting states of the agents had on the overall result
obtained through the model and the variance in simulation time of processing
the model on multicore architectures.
  The experiments highlight that there are limitations of the FLAME framework
and writing simulation models in general which are highly dependent on initial
starting states of a model, also raising further potential work which can be
built into the Sugarscape model to study other interesting phenomenon in social
and economic laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3443</identifier>
 <datestamp>2014-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3443</id><created>2014-08-14</created><updated>2014-10-08</updated><authors><author><keyname>Soulignac</keyname><forenames>Francisco J.</forenames></author></authors><title>Bounded, minimal, and short representations of unit interval and unit
  circular-arc graphs</title><categories>cs.DM</categories><comments>33 pages, 3 figures</comments><msc-class>68R10, 05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the unrestricted, minimal, and bounded representation problems
for unit interval (UIG) and unit circular-arc (UCA) graphs. In the unrestricted
version, a proper circular-arc (PCA) model $\cal M$ is given and the goal is to
obtain an equivalent UCA model $\cal U$. We show a linear time algorithm with
negative certification that can also be implemented to run in logspace. In the
bounded version, $\cal M$ is given together with some lower and upper bounds
that the beginning points of $\cal U$ must satisfy. We develop a linear space
$O(n^2)$ time algorithm for this problem. Finally, in the minimal version, the
circumference of the circle and the length of the arcs in $\cal U$ must be
simultaneously as minimum as possible. We prove that every UCA graph admits
such a minimal model, and give a polynomial time algorithm to find it. We also
consider the minimal representation problem for UIG graphs. As a bad result, we
show that the previous linear time algorithm fails to provide a minimal model
for some input graphs. We fix this algorithm but, unfortunately, it runs in
linear space $O(n^2)$ time. Finally, we apply the minimal representation
algorithms so as to find the minimum powers of paths and cycles that contain a
given UIG and UCA models, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3452</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3452</id><created>2014-08-14</created><authors><author><keyname>Cao</keyname><forenames>Zhengjun</forenames></author><author><keyname>Liu</keyname><forenames>Lihua</forenames></author></authors><title>A Note on the Bellare-Rivest Protocol for Translucent Cryptography</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We remark that the Bellare-Rivest protocol for translucent cryptography [J.
Cryptology (1999) 12: 117-139] can not truly enable the government to decrypt
partial encrypted communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3455</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3455</id><created>2014-08-14</created><authors><author><keyname>Shen</keyname><forenames>Hua-Wei</forenames></author><author><keyname>Barab&#xe1;si</keyname><forenames>Albert-L&#xe1;szl&#xf3;</forenames></author></authors><title>Collective credit allocation in science</title><categories>physics.soc-ph cs.DL</categories><comments>7 pages, 4 figures, 1 table, appears in Proceedings of the National
  Academy of Sciences of the United States of America, 2014</comments><doi>10.1073/pnas.1401992111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaboration among researchers is an essential component of the modern
scientific enterprise, playing a particularly important role in
multidisciplinary research. However, we continue to wrestle with allocating
credit to the coauthors of publications with multiple authors, since the
relative contribution of each author is difficult to determine. At the same
time, the scientific community runs an informal field-dependent credit
allocation process that assigns credit in a collective fashion to each work.
Here we develop a credit allocation algorithm that captures the coauthors'
contribution to a publication as perceived by the scientific community,
reproducing the informal collective credit allocation of science. We validate
the method by identifying the authors of Nobel-winning papers that are credited
for the discovery, independent of their positions in the author list. The
method can also compare the relative impact of researchers working in the same
field, even if they did not publish together. The ability to accurately measure
the relative credit of researchers could affect many aspects of credit
allocation in science, potentially impacting hiring, funding, and promotion
decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3456</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3456</id><created>2014-08-14</created><authors><author><keyname>Hill</keyname><forenames>Felix</forenames></author><author><keyname>Reichart</keyname><forenames>Roi</forenames></author><author><keyname>Korhonen</keyname><forenames>Anna</forenames></author></authors><title>SimLex-999: Evaluating Semantic Models with (Genuine) Similarity
  Estimation</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present SimLex-999, a gold standard resource for evaluating distributional
semantic models that improves on existing resources in several important ways.
First, in contrast to gold standards such as WordSim-353 and MEN, it explicitly
quantifies similarity rather than association or relatedness, so that pairs of
entities that are associated but not actually similar [Freud, psychology] have
a low rating. We show that, via this focus on similarity, SimLex-999
incentivizes the development of models with a different, and arguably wider
range of applications than those which reflect conceptual association. Second,
SimLex-999 contains a range of concrete and abstract adjective, noun and verb
pairs, together with an independent rating of concreteness and (free)
association strength for each pair. This diversity enables fine-grained
analyses of the performance of models on concepts of different types, and
consequently greater insight into how architectures can be improved. Further,
unlike existing gold standard evaluations, for which automatic approaches have
reached or surpassed the inter-annotator agreement ceiling, state-of-the-art
models perform well below this ceiling on SimLex-999. There is therefore plenty
of scope for SimLex-999 to quantify future improvements to distributional
semantic models, guiding the development of the next generation of
representation-learning architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3458</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3458</id><created>2014-08-14</created><updated>2015-08-29</updated><authors><author><keyname>Zhou</keyname><forenames>Bo</forenames></author><author><keyname>Cui</keyname><forenames>Ying</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author></authors><title>Stochastic Throughput Optimization for Two-hop Systems with Finite Relay
  Buffers</title><categories>cs.IT cs.NI math.IT</categories><comments>15 pages, double-column, 9 figures, 3 tables. Accepted by IEEE
  Transaction on Signal Processing</comments><doi>10.1109/TSP.2015.2452225</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal queueing control of multi-hop networks remains a challenging problem
even in the simplest scenarios. In this paper, we consider a two-hop
half-duplex relaying system with random channel connectivity. The relay is
equipped with a finite buffer. We focus on stochastic link selection and
transmission rate control to maximize the average system throughput subject to
a half-duplex constraint. We formulate this stochastic optimization problem as
an infinite horizon average cost Markov decision process (MDP), which is
well-known to be a difficult problem. By using sample-path analysis and
exploiting the specific problem structure, we first obtain an \emph{equivalent
Bellman equation} with reduced state and action spaces. By using \emph{relative
value iteration algorithm}, we analyze the properties of the value function of
the MDP. Then, we show that the optimal policy has a threshold-based structure
by characterizing the \emph{supermodularity} in the optimal control. Based on
the threshold-based structure and Markov chain theory, we further simplify the
original complex stochastic optimization problem to a static optimization
problem over a small discrete feasible set and propose a low-complexity
algorithm to solve the simplified static optimization problem by making use of
its special structure. Furthermore, we obtain the closed-form optimal threshold
for the symmetric case. The analytical results obtained in this paper also
provide design insights for two-hop relaying systems with multiple relays
equipped with finite relay buffers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3467</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3467</id><created>2014-08-15</created><authors><author><keyname>Xu</keyname><forenames>Qianqian</forenames></author><author><keyname>Xiong</keyname><forenames>Jiechao</forenames></author><author><keyname>Huang</keyname><forenames>Qingming</forenames></author><author><keyname>Yao</keyname><forenames>Yuan</forenames></author></authors><title>Robust Statistical Ranking: Theory and Algorithms</title><categories>stat.ME cs.LG stat.ML</categories><comments>16 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deeply rooted in classical social choice and voting theory, statistical
ranking with paired comparison data experienced its renaissance with the wide
spread of crowdsourcing technique. As the data quality might be significantly
damaged in an uncontrolled crowdsourcing environment, outlier detection and
robust ranking have become a hot topic in such data analysis. In this paper, we
propose a robust ranking framework based on the principle of Huber's robust
statistics, which formulates outlier detection as a LASSO problem to find
sparse approximations of the cyclic ranking projection in Hodge decomposition.
Moreover, simple yet scalable algorithms are developed based on Linearized
Bregman Iteration to achieve an even less biased estimator than LASSO.
Statistical consistency of outlier detection is established in both cases which
states that when the outliers are strong enough and in Erdos-Renyi random graph
sampling settings, outliers can be faithfully detected. Our studies are
supported by experiments with both simulated examples and real-world data. The
proposed framework provides us a promising tool for robust ranking with large
scale crowdsourcing data arising from computer vision, multimedia, machine
learning, sociology, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3469</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3469</id><created>2014-08-15</created><authors><author><keyname>Xie</keyname><forenames>Nan</forenames></author><author><keyname>Walsh</keyname><forenames>John MacLaren</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author></authors><title>Properties of an Aloha-like stability region</title><categories>cs.IT cs.NI math.IT</categories><comments>69 pages, 10 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well-known inner bound on the stability region of the finite-user slotted
Aloha protocol is the set of all arrival rates for which there exists some
choice of the contention probabilities such that the associated worst-case
service rate for each user exceeds the user's arrival rate, denoted $\Lambda$.
Although testing membership in $\Lambda$ of a given arrival rate can be posed
as a convex program, it is nonetheless of interest to understand the geometric
properties of this set. In this paper we develop new results of this nature,
including $i)$ several equivalent descriptions of $\Lambda$, $ii)$ a method to
construct a vector of contention probabilities to stabilize any stabilizable
arrival rate, $iii)$ the volume of $\Lambda$, $iv)$ explicit polyhedral,
spherical, and ellipsoid inner and outer bounds on $\Lambda$, and $v)$
characterization of the generalized convexity properties of a natural &quot;excess
rate&quot; function associated with $\Lambda$, including the convexity of the set of
contention probabilities that stabilize a given arrival rate vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3474</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3474</id><created>2014-08-15</created><authors><author><keyname>Avendi</keyname><forenames>M. R.</forenames></author></authors><title>Differential Modulation and Non-Coherent Detection in Wireless Relay
  Networks</title><categories>cs.IT math.IT</categories><comments>PhD Dissertation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The technique of cooperative communications is finding its way in the next
generations of many wireless communication applications. Due to the distributed
nature of cooperative networks, acquiring fading channels information for
coherent detection is more challenging than in the traditional point-to-point
communications. To bypass the requirement of channel information, differential
modulation together with non-coherent detection can be deployed. This thesis is
concerned with various issues related to differential modulation and
non-coherent detection in cooperative networks. Specifically, the thesis
examines the behaviour and robustness of non-coherent detection in mobile
environments (i.e., time-varying channels). The amount of channel variation is
related to the normalized Doppler shift which is a function of user's mobility.
The Doppler shift is used to distinguish between slow time-varying
(slow-fading) and rapid time-varying (fast-fading) channels. The performance of
several important relay topologies, including single-branch and multi-branch
dual-hop relaying with/without a direct link that employ amplify-and-forward
relaying and two-symbol non-coherent detection, is analyzed. For this purpose,
a time-series model is developed for characterizing the time-varying nature of
the cascaded channel encountered in amplify-and-forward relaying.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3500</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3500</id><created>2014-08-15</created><authors><author><keyname>Chen</keyname><forenames>Wei</forenames></author><author><keyname>Wang</keyname><forenames>Songbai</forenames></author><author><keyname>Qiu</keyname><forenames>Li</forenames></author></authors><title>When MIMO Control Meets MIMO Communication: A Majorization Condition for
  Networked Stabilizability</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we initiate the study of networked stabilization via a MIMO
communication scheme between the controller and the plant. Specifically, the
communication system is modeled as a MIMO transceiver, which consists of three
parts: an encoder, a MIMO channel, and a decoder. In the spirit of MIMO
communication, the number of SISO subchannels in the transceiver is often
greater than the number of data streams to be transmitted. Moreover, the
subchannel capacities are assumed to be fixed a priori. In this case, the
encoder/decoder pair gives an additional design freedom on top of the
controller, leading to a stabilization problem via coding/control co-design. It
turns out that how to take the best advantage of the coding mechanism is quite
crucial. From a demand/supply perspective, the design of the coding mechanism
boils down to reshaping the demands for communication resource from different
control inputs to match the given supplies. We study the problem for the case
of AWGN subchannels and fading subchannels, respectively. In both cases, we
arrive at a unified necessary and sufficient condition on the capacities of the
subchannels under which the coding/control co-design problem is solvable. The
condition is given in terms of a majorization type relation. As we go along,
systematic procedures are also put forward to implement the coding/control
co-design. A numerical example is presented to illustrate our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3502</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3502</id><created>2014-08-15</created><authors><author><keyname>Kostecki</keyname><forenames>Ryszard Pawe&#x142;</forenames></author></authors><title>L\&quot;uders' and quantum Jeffrey's rules as entropic projections</title><categories>quant-ph cs.IT math-ph math.IT math.MP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that the standard quantum mechanical description of a quantum state
change due to measurement, given by Lueders' rules, is a special case of the
constrained maximisation of a quantum relative entropy functional. This result
is a quantum analogue of the derivation of the Bayes--Laplace rule as a special
case of the constrained maximisation of relative entropy. The proof is provided
for the Umegaki relative entropy of density operators over a Hilbert space as
well as for the Araki relative entropy of normal states over a W*-algebra. We
also introduce a quantum analogue of Jeffrey's rule, derive it in the same way
as above, and discuss the meaning of these results for quantum bayesianism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3510</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3510</id><created>2014-08-15</created><authors><author><keyname>Arvind</keyname><forenames>Vikraman</forenames></author><author><keyname>Rattan</keyname><forenames>Gaurav</forenames></author></authors><title>Faster FPT Algorithm for Graph Isomorphism Parameterized by Eigenvalue
  Multiplicity</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a $O^*(k^{O(k)})$ time isomorphism testing algorithm for graphs of
eigenvalue multiplicity bounded by $k$ which improves on the previous best
running time bound of $O^*(2^{O(k^2/\log k)})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3526</identifier>
 <datestamp>2015-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3526</id><created>2014-08-15</created><updated>2015-08-21</updated><authors><author><keyname>Kennedy</keyname><forenames>Hugh L.</forenames></author></authors><title>Parallel software implementation of recursive multidimensional digital
  filters for point-target detection in cluttered infrared scenes</title><categories>cs.CV</categories><comments>To appear in Proc. 2015 IEEE International Conference on Acoustics,
  Speech and Signal Processing (ICASSP). Added header and DOI</comments><doi>10.1109/ICASSP.2015.7178137</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A technique for the enhancement of point targets in clutter is described. The
local 3-D spectrum at each pixel is estimated recursively. An optical
flow-field for the textured background is then generated using the 3-D
autocorrelation function and the local velocity estimates are used to apply
high-pass velocity-selective spatiotemporal filters, with finite impulse
responses (FIRs), to subtract the background clutter signal, leaving the
foreground target signal, plus noise. Parallel software implementations using a
multicore central processing unit (CPU) and a graphical processing unit (GPU)
are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3537</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3537</id><created>2014-08-15</created><authors><author><keyname>Dave</keyname><forenames>Dhaval</forenames></author><author><keyname>Dave</keyname><forenames>Pranav</forenames></author></authors><title>An Effective Black Hole Attack Detection Mechanism using Permutation
  Based Acknowledgement in MANET</title><categories>cs.NI</categories><comments>MANET, Black Hole, Permutation, Security, Ad-hoc network</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the evolution of wireless technology and use of mobile devices, Mobile
Ad-hoc Network has become popular among researchers to explore. A mobile ad-hoc
network (MANET) is a self-configuring network of mobile routers (and associated
hosts) connected by wireless links. The routers and hosts are free to move
randomly and organize themselves arbitrarily. It allows mobile nodes to
communicate directly without any centralized coordinator. Such network
scenarios cannot rely on centralized and organized connectivity, and can be
conceived as applications of Mobile Ad-Hoc Networks. Thus, MANET is vulnerable
due to its dynamic network topology, as any node become untrusted at any time.
The Black hole attack is one kind of security risk in which malicious node
advertises itself to have a shortest path for any destination, to forge data or
for DOS attack. In this paper, to detect such nodes effectively, we propose a
Permutation based Acknowledgement for most widely used reactive protocol ad-hoc
on demand distance vector routing AODV. This mechanism is enhancement of
Adaptive Acknowledgement (AACK) and TWO-ACK, here we have tried to show the
efficiency increment by decreasing number of messages routed in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3550</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3550</id><created>2014-08-13</created><authors><author><keyname>Sabatini</keyname><forenames>Fabio</forenames></author><author><keyname>Sarracino</keyname><forenames>Francesco</forenames></author></authors><title>Online networks and subjective well-being</title><categories>cs.CY cs.SI</categories><comments>40 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We argue that the use of online networks may threaten subjective well-being
in several ways, due to the inherent attributes of Internet-mediated
interaction and through its effects on social trust and sociability. We test
our hypotheses on a representative sample of the Italian population. We find a
significantly negative correlation between online networking and well-being.
This result is partially confirmed after accounting for endogeneity. We explore
the direct and indirect effects of the use of social networking sites (SNS) on
well-being in a SEM analysis. We find that online networking plays a positive
role in subjective well-being through its impact on physical interactions,
whereas SNS use is associated with lower social trust. The overall effect of
networking on individual welfare is significantly negative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3560</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3560</id><created>2014-08-15</created><updated>2014-08-23</updated><authors><author><keyname>Tamura</keyname><forenames>Kuniaki</forenames></author></authors><title>Completeness of Kozen's Axiomatization for the Modal mu-Calculus: A
  Simple Proof</title><categories>cs.LO cs.FL cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modal mu-calculus, introduced by Dexter Kozen, is an extension of modal
logic with fixpoint operators. Its axiomatization, Koz, was introduced at the
same time and is an extension of the minimal modal logic K with the so-called
Park fixpoint induction principle. It took more than a decade for the
completeness of Koz to be proven, finally achieved by Igor Walukiewicz.
However, his proof is fairly involved.
  In this article, we present an improved proof for the completeness of Koz
which, although similar to the original, is simpler and easier to understand.
  Keywords: The modal mu-calculus, completeness, parity games, parity automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3562</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3562</id><created>2014-08-15</created><authors><author><keyname>Hale</keyname><forenames>Scott A.</forenames></author><author><keyname>John</keyname><forenames>Peter</forenames></author><author><keyname>Margetts</keyname><forenames>Helen</forenames></author><author><keyname>Yasseri</keyname><forenames>Taha</forenames></author></authors><title>Investigating Political Participation and Social Information Using Big
  Data and a Natural Experiment</title><categories>physics.soc-ph cs.CY cs.SI physics.data-an</categories><comments>Prepared for delivery at the 2014 Annual Meeting of the American
  Political Science Association, August 28-31, 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social information is particularly prominent in digital settings where the
design of platforms can more easily give real-time information about the
behaviour of peers and reference groups and thereby stimulate political
activity. Changes to these platforms can generate natural experiments allowing
an assessment of the impact of changes in social information and design on
participation. This paper investigates the impact of the introduction of
trending information on the homepage of the UK government petitions platform.
Using interrupted time series and a regression discontinuity design, we find
that the introduction of the trending feature had no statistically significant
effect on the overall number of signatures per day, but that the distribution
of signatures across petitions changes: the most popular petitions gain even
more signatures at the expense of those with less signatories. We find
significant differences between petitions trending at different ranks, even
after controlling for each petition's individual growth prior to trending. The
findings suggest a non-negligible group of individuals visit the homepage of
the site looking for petitions to sign and therefore see the list of trending
petitions, and a significant proportion of this group responds to the social
information that it provides. These findings contribute to our understanding of
how social information, and the form in which it is presented, affects
individual political behaviour in digital settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3564</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3564</id><created>2014-08-15</created><authors><author><keyname>Mishra</keyname><forenames>Minati</forenames></author><author><keyname>Mishra</keyname><forenames>Priyadarsini</forenames></author><author><keyname>Adhikary</keyname><forenames>M. C.</forenames></author></authors><title>Digital Image Data Hiding Techniques: A Comparative Study</title><categories>cs.MM</categories><comments>11 pages, ANVESA - The Journal of F.M. University, ISSN-0974-715X.
  arXiv admin note: text overlap with
  http://dx.doi.org/10.1016/j.sigpro.2009.08.010 by other authors</comments><journal-ref>ANVESA,7(2), 105-115, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advancements in the field of digital image processing during the
last decade, digital image data hiding techniques such as watermarking,
Steganography have gained wide popularity. Digital image watermarking
techniques hide a small amount of data into a digital image which, later can be
retrieved using some specific retrieval algorithms to prove the copyright of a
piece of digital information whereas, Steganographic techniques are used to
hide a large amount of data secretly into some innocuous looking digital
medium. In this paper we are providing an up-to-date review of these data
hiding techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3570</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3570</id><created>2014-08-15</created><authors><author><keyname>Colman</keyname><forenames>Ewan R.</forenames></author><author><keyname>Rodgers</keyname><forenames>Geoff J.</forenames></author></authors><title>Local rewiring rules for evolving complex networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>8 pages, 5 figures</comments><doi>10.1016/j.physa.2014.08.046</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effects of link rewiring are considered for the class of directed
networks where each node has the same fixed out-degree. We model a network
generated by three mechanisms that are present in various networked systems;
growth, global rewiring and local rewiring. During a rewiring phase a node is
randomly selected, one of its out-going edges is detached from its destination
then re-attached to the network in one of two possible ways; either globally to
a randomly selected node, or locally to a descendant of a descendant of the
originally selected node. Although the probability of attachment to a node
increases with its connectivity, the probability of detachment also increases,
the result is an exponential degree distribution with a small number of
outlying nodes that have extremely large degree. We explain these outliers by
identifying the circumstances for which a set of nodes can grow to very high
degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3573</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3573</id><created>2014-08-15</created><authors><author><keyname>Tasli</keyname><forenames>H. Emrah</forenames></author><author><keyname>Ivan</keyname><forenames>Paul</forenames></author></authors><title>Turkish Presidential Elections TRT Publicity Speech Facial Expression
  Analysis</title><categories>cs.CV</categories><comments>2 pages 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, facial expressions of the three Turkish presidential
candidates Demirtas, Erdogan and Ihsanoglu (in alphabetical order) are analyzed
during the publicity speeches featured at TRT (Turkish Radio and Television) on
03.08.2014. FaceReader is used for the analysis where 3D modeling of the face
is achieved using the active appearance models (AAM). Over 500 landmark points
are tracked and analyzed for obtaining the facial expressions during the whole
speech. All source videos and the data are publicly available for research
purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3575</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3575</id><created>2014-08-12</created><authors><author><keyname>Kumar</keyname><forenames>Kamal</forenames></author><author><keyname>Verma</keyname><forenames>A. K.</forenames></author><author><keyname>Patel</keyname><forenames>R. B.</forenames></author></authors><title>Secure Multipath Routing Scheme using Key Pre-Distribution in Wireless
  Sensor Networks</title><categories>cs.NI</categories><comments>13 pages</comments><journal-ref>International Journal of Foundation in Computer Science &amp;
  Technology, Vol. 4, No. 4, pp. 49-61, 2014, Australia</journal-ref><doi>10.5121/ijfcst.2014.4404</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multipath routing in WSN has been a long wish in security scenario where
nodes on next-hop may be targeted to compromise. Many proposals of Multipath
routing has been proposed in ADHOC Networks but under constrained from keying
environment most seems ignorant. In WSN where crucial data is reported by nodes
in deployment area to their securely located Sink, route security has to be
guaranteed. Under dynamic load and selective attacks, availability of multiple
secure paths is a boon and increases the attacker efforts by many folds. We
propose to build a subset of neighbors as our front towards destination node.
We also identified forwarders for query by base station. The front is optimally
calculated to maintain the security credential and avail multiple paths.
According to our knowledge ours is first secure multipath routing protocol for
WSN. We established effectiveness of our proposal with mathematical analysis
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3586</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3586</id><created>2014-08-15</created><authors><author><keyname>Soeken</keyname><forenames>Mathias</forenames></author><author><keyname>Wille</keyname><forenames>Robert</forenames></author><author><keyname>Keszocze</keyname><forenames>Oliver</forenames></author><author><keyname>Miller</keyname><forenames>D. Michael</forenames></author><author><keyname>Drechsler</keyname><forenames>Rolf</forenames></author></authors><title>Embedding of Large Boolean Functions for Reversible Logic</title><categories>cs.ET</categories><comments>13 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversible logic represents the basis for many emerging technologies and has
recently been intensively studied. However, most of the Boolean functions of
practical interest are irreversible and must be embedded into a reversible
function before they can be synthesized. Thus far, an optimal embedding is
guaranteed only for small functions, whereas a significant overhead results
when large functions are considered. In this paper, we study this issue. We
prove that determining an optimal embedding is coNP-hard already for restricted
cases. Then, we propose heuristic and exact methods for determining both the
number of additional lines as well as a corresponding embedding. For the
approaches we considered sums of products and binary decision diagrams as
function representations. Experimental evaluations show the applicability of
the approaches for large functions. Consequently, the reversible embedding of
large functions is enabled as a precursor to subsequent synthesis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3587</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3587</id><created>2014-08-15</created><authors><author><keyname>Tan</keyname><forenames>Luchen</forenames></author><author><keyname>Clarke</keyname><forenames>Clarke L. A.</forenames></author></authors><title>A Family of Rank Similarity Measures based on Maximized Effectiveness
  Difference</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rank similarity measures provide a method for quantifying differences between
search engine results without the need for relevance judgments. For example,
the providers of a search service might use such measures to estimate the
impact of a proposed algorithmic change across a large number of queries -
perhaps millions - identifying those queries where the impact is greatest. In
this paper, we propose and validate a family of rank similarity measures, each
derived from an associated effectiveness measure. Each member of the family is
based on the maximization of effectiveness difference under this associated
measure. Computing this maximized effectiveness difference (MED) requires the
solution of an optimization problem that varies in difficulty, depending on the
associated measure. We present solutions for several standard effectiveness
measures, including nDCG, MAP, and ERR. Through an experimental validation, we
show that MED reveals meaningful differences between retrieval runs.
Mathematically, MED is a metric, regardless of the associated measure. Prior
work has established a number of other desiderata for rank similarity in the
context of search, and we demonstrate that MED satisfies these requirements.
Unlike previous proposals, MED allows us to directly translate assumptions
about user behavior from any established effectiveness measure to create a
corresponding rank similarity measure. In addition, MED cleanly accommodates
partial relevance judgments, and if complete relevance information is
available, it reduces to a simple difference between effectiveness values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3590</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3590</id><created>2014-08-15</created><authors><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Mark&#xf3;</keyname><forenames>Roland</forenames></author></authors><title>Complexity of Nondeterministic Graph Parameter Testing</title><categories>cs.DS math.CO</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the sample complexity of nondeterministically testable graph
parameters and improve existing bounds by several orders of magnitude. The
technique used would be also of independent interest. We also discuss some
generalization and the special case of nondeterministic testing with polynomial
sample size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3595</identifier>
 <datestamp>2015-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3595</id><created>2014-08-15</created><updated>2015-10-28</updated><authors><author><keyname>Lessard</keyname><forenames>Laurent</forenames></author><author><keyname>Recht</keyname><forenames>Benjamin</forenames></author><author><keyname>Packard</keyname><forenames>Andrew</forenames></author></authors><title>Analysis and Design of Optimization Algorithms via Integral Quadratic
  Constraints</title><categories>math.OC cs.NA cs.SY</categories><comments>The previous version of this paper quoted the wrong rate of
  Nesterov's optimal method when applied to strongly convex functions. With
  this correction, our bounds are now slightly better than those previously
  derived for Nesterov's method</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript develops a new framework to analyze and design iterative
optimization algorithms built on the notion of Integral Quadratic Constraints
(IQC) from robust control theory. IQCs provide sufficient conditions for the
stability of complicated interconnected systems, and these conditions can be
checked by semidefinite programming. We discuss how to adapt IQC theory to
study optimization algorithms, proving new inequalities about convex functions
and providing a version of IQC theory adapted for use by optimization
researchers. Using these inequalities, we derive numerical upper bounds on
convergence rates for the gradient method, the heavy-ball method, Nesterov's
accelerated method, and related variants by solving small, simple semidefinite
programming problems. We also briefly show how these techniques can be used to
search for optimization algorithms with desired performance characteristics,
establishing a new methodology for algorithm design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3596</identifier>
 <datestamp>2014-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3596</id><created>2014-08-13</created><authors><author><keyname>Serakos</keyname><forenames>Demetrios</forenames></author></authors><title>On BMD Target Tracking: Data Association and Data Fusion</title><categories>cs.SY math.PR</categories><comments>10 pages. Proceedings 2004 National Fire Control Symposium Kauai HI
  9-12 August 2004</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper we consider multitarget tracking with multiple sensors for BMD.
In a previous paper multitarget tracking with a single sensor was considered
[8]. A ballistic missile may be in several pieces, presenting multiple targets.
Besides the ground based or ship sensor there is also the missile seeker. We
consider algorithms for generating and maintaining the tracks needed for BMD. A
cue of a BM from a non-organic tracking system may also be received. We
consider whether the cue is already in the local track file or is a new track.
The cue information can improve the existing local track.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3598</identifier>
 <datestamp>2014-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3598</id><created>2014-08-15</created><updated>2014-11-13</updated><authors><author><keyname>Flaut</keyname><forenames>Cristina</forenames></author></authors><title>BCK-algebras arising from block codes</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we will provide an algorithm which allows us to find a
BCK-algebra starting from a given block code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3600</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3600</id><created>2014-08-11</created><updated>2015-03-14</updated><authors><author><keyname>Kim</keyname><forenames>Seunghyeon</forenames></author><author><keyname>Sung</keyname><forenames>Jaeyun</forenames></author><author><keyname>Foo</keyname><forenames>Mathias</forenames></author><author><keyname>Jin</keyname><forenames>Yong-Su</forenames></author><author><keyname>Kim</keyname><forenames>Pan-Jun</forenames></author></authors><title>Uncovering the nutritional landscape of food</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>Supplementary material is available at the journal website</comments><journal-ref>PLoS ONE 10(3): e0118697 (2015)</journal-ref><doi>10.1371/journal.pone.0118697</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent progresses in data-driven analysis methods, including network-based
approaches, are revolutionizing many classical disciplines. These techniques
can also be applied to food and nutrition, which must be studied to design
healthy diets. Using nutritional information from over 1,000 raw foods, we
systematically evaluated the nutrient composition of each food in regards to
satisfying daily nutritional requirements. The nutrient balance of a food was
quantified herein as nutritional fitness, using the food's frequency of
occurrence in nutritionally adequate food combinations. Nutritional fitness
offers prioritization of recommendable foods within a global network of foods,
in which foods are connected based on the similarities of their nutrient
compositions. We identified a number of key nutrients, such as choline and
alpha-linolenic acid, whose levels in foods can critically affect the foods'
nutritional fitness. Analogously, pairs of nutrients can have the same effect.
In fact, two nutrients can impact the nutritional fitness synergistically,
although the individual nutrients alone may not. This result, involving the
tendency among nutrients to show correlations in their abundances across foods,
implies a hidden layer of complexity when exploring for foods whose balance of
nutrients within pairs holistically helps meet nutritional requirements.
Interestingly, foods with high nutritional fitness successfully maintain this
nutrient balance. This effect expands our scope to a diverse repertoire of
nutrient-nutrient correlations, integrated under a common network framework
that yields unexpected yet coherent associations between nutrients. Our
nutrient-profiling approach combined with a network-based analysis provides a
more unbiased, global view of the relationships between foods and nutrients,
and can be extended towards nutritional policies, food marketing, and
personalized nutrition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3622</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3622</id><created>2014-08-15</created><updated>2014-08-17</updated><authors><author><keyname>Zhang</keyname><forenames>Hong</forenames></author><author><keyname>Sandu</keyname><forenames>Adrian</forenames></author><author><keyname>Tranquilli</keyname><forenames>Paul</forenames></author></authors><title>Application of approximate matrix factorization to high order linearly
  implicit Runge-Kutta methods</title><categories>cs.NA cs.CE math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linearly implicit Runge-Kutta methods with approximate matrix factorization
can solve efficiently large systems of differential equations that have a stiff
linear part, e.g. reaction-diffusion systems. However, the use of approximate
factorization usually leads to loss of accuracy, which makes it attractive only
for low order time integration schemes. This paper discusses the application of
approximate matrix factorization with high order methods; an inexpensive
correction procedure applied to each stage allows to retain the high order of
the underlying linearly implicit Runge-Kutta scheme. The accuracy and stability
of the methods are studied. Numerical experiments on reaction-diffusion type
problems of different sizes and with different degrees of stiffness illustrate
the efficiency of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3639</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3639</id><created>2014-08-15</created><authors><author><keyname>Liang</keyname><forenames>Ye</forenames></author></authors><title>Solving Polynomial Equations with Equation Constraints: the
  Zero-dimensional Case</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A zero-dimensional polynomial ideal may have a lot of complex zeros. But
sometimes, only some of them are needed. In this paper, for a zero-dimensional
ideal $I$, we study its complex zeros that locate in another variety
$\textbf{V}(J)$ where $J$ is an arbitrary ideal.
  The main problem is that for a point in $\textbf{V}(I) \cap
\textbf{V}(J)=\textbf{V}(I+J)$, its multiplicities w.r.t. $I$ and $I+J$ may be
different. Therefore, we cannot get the multiplicity of this point w.r.t. $I$
by studying $I + J$. A straightforward way is that first compute the points of
$\textbf{V}(I + J)$, then study their multiplicities w.r.t. $I$. But the former
step is difficult to realize exactly.
  In this paper, we propose a natural geometric explanation of the localization
of a polynomial ring corresponding to a semigroup order. Then, based on this
view, using the standard basis method and the border basis method, we introduce
a way to compute the complex zeros of $I$ in $\textbf{V}(J)$ with their
multiplicities w.r.t. $I$. As an application, we compute the sum of Milnor
numbers of the singular points on a polynomial hypersurface and work out all
the singular points on the hypersurface with their Milnor numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3645</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3645</id><created>2014-08-15</created><updated>2014-08-20</updated><authors><author><keyname>Ma&#xdf;berg</keyname><forenames>Jens</forenames></author></authors><title>The &quot;Game about Squares&quot; is NP-hard</title><categories>cs.CC math.CO</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the &quot;Game about Squares&quot; the task is to push unit squares on an integer
lattice onto corresponding dots. A square can only be moved into one given
direction. When a square is pushed onto a lattice point with an arrow the
direction of the square adopts the direction of the arrow. Moreover, squares
can push other squares. In this paper we study the decision problem, whether
all squares can be moved onto their corresponding dots by a finite number of
pushes. We prove that this problem is NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3651</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3651</id><created>2014-08-15</created><authors><author><keyname>Mirmomeni</keyname><forenames>Masoud</forenames></author><author><keyname>Punch</keyname><forenames>William F.</forenames></author><author><keyname>Adami</keyname><forenames>Christoph</forenames></author></authors><title>Is information a selectable trait?</title><categories>q-bio.PE cs.IT math.IT nlin.AO</categories><comments>23 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is little doubt in scientific circles that--counting from the origin of
life towards today--evolution has led to an increase in the amount of
information stored within the genomes of the biosphere. This trend of
increasing information on average likely holds for every successful line of
descent, but it is not clear whether this increase is due to a general law, or
whether it is a secondary effect linked to an overall increase in fitness.
Here, we use &quot;digital life&quot; evolution experiments to study whether information
is under selection if treated as an organismal trait, using the Price equation.
By measuring both sides of the equation individually in an adapting population,
the strength of selection on a trait appears as a &quot;gap&quot; between the two terms
of the right-hand-side of the Price equation. We find that information is
strongly selected (as it encodes all fitness-producing traits) by comparing the
strength of selection on information to a weakly selected trait (sequence
length), as well as to a neutral marker. We observe that while strength of
selection on arbitrary traits can vary during an experiment (including
reversing sign), information is a selectable trait that must increase in a
fixed environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3653</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3653</id><created>2014-08-15</created><authors><author><keyname>Taherzadeh</keyname><forenames>Mahmoud</forenames></author><author><keyname>Nikopour</keyname><forenames>Hosein</forenames></author><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Baligh</keyname><forenames>Hadi</forenames></author></authors><title>SCMA Codebook Design</title><categories>cs.IT math.IT</categories><comments>Accepted for IEEE VTC-fall 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multicarrier CDMA is a multiple access scheme in which modulated QAM symbols
are spread over OFDMA tones by using a generally complex spreading sequence.
Effectively, a QAM symbol is repeated over multiple tones. Low density
signature (LDS) is a version of CDMA with low density spreading sequences
allowing us to take advantage of a near optimal message passing algorithm (MPA)
receiver with practically feasible complexity. Sparse code multiple access
(SCMA) is a multi-dimensional codebook-based non-orthogonal spreading
technique. In SCMA, the procedure of bit to QAM symbol mapping and spreading
are combined together and incoming bits are directly mapped to
multi-dimensional codewords of SCMA codebook sets. Each layer has its dedicated
codebook. Shaping gain of a multi-dimensional constellation is one of the main
sources of the performance improvement in comparison to the simple repetition
of QAM symbols in LDS. Meanwhile, like LDS, SCMA enjoys the low complexity
reception techniques due to the sparsity of SCMA codewords. In this paper a
systematic approach is proposed to design SCMA codebooks mainly based on the
design principles of lattice constellations. Simulation results are presented
to show the performance gain of SCMA compared to LDS and OFDMA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3661</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3661</id><created>2014-08-15</created><authors><author><keyname>Ren</keyname><forenames>Jie</forenames></author><author><keyname>Boyle</keyname><forenames>Bradford D.</forenames></author><author><keyname>Ku</keyname><forenames>Gwanmo</forenames></author><author><keyname>Weber</keyname><forenames>Steven</forenames></author><author><keyname>Walsh</keyname><forenames>John MacLaren</forenames></author></authors><title>Overhead Performance Tradeoffs - A Resource Allocation Perspective</title><categories>cs.IT math.IT</categories><comments>70 pages, 18 figures, Submitted to IEEE Transactions on Information
  Theory on 2014-08-14</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key aspect of many resource allocation problems is the need for the
resource controller to compute a function, such as the max or arg max, of the
competing users metrics. Information must be exchanged between the competing
users and the resource controller in order for this function to be computed. In
many practical resource controllers the competing users' metrics are
communicated to the resource controller, which then computes the desired
extremization function. However, in this paper it is shown that information
rate savings can be obtained by recognizing that controller only needs to
determine the result of this extremization function. If the extremization
function is to be computed losslessly, the rate savings are shown in most cases
to be at most 2 bits independent of the number of competing users. Motivated by
the small savings in the lossless case, simple achievable schemes for both the
lossy and interactive variants of this problem are considered. It is shown that
both of these approaches have the potential to realize large rate savings,
especially in the case where the number of competing users is large. For the
lossy variant, it is shown that the proposed simple achievable schemes are in
fact close to the fundamental limit given by the rate distortion function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3676</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3676</id><created>2014-08-15</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>Mayne</keyname><forenames>Richard</forenames></author></authors><title>Actin automata: Phenomenology and localizations</title><categories>cs.ET nlin.CG</categories><doi>10.1142/S0218127415500303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Actin is a globular protein which forms long filaments in the eukaryotic
cytoskeleton, whose roles in cell function include structural support,
contractile activity to intracellular signalling. We model actin filaments as
two chains of one-dimensional binary-state semi-totalistic automaton arrays to
describe hypothetical signalling events therein. Each node of the actin
automaton takes state `0' (resting) or `1' (excited) and updates its state in
discrete time depending on its neighbour's states. We analyse the complete rule
space of actin automata using integral characteristics of space-time
configurations generated by these rules and compute state transition rules that
support travelling and mobile localizations. Approaches towards selection of
the localisation supporting rules using the global characteristics are
outlined. We find that some properties of actin automata rules may be predicted
using Shannon entropy, activity and incoherence of excitation between the
polymer chains. We also show that it is possible to infer whether a given rule
supports travelling or stationary localizations by looking at ratios of excited
neighbours are essential for generations of the localizations. We conclude by
applying biomolecular hypotheses to this model and discuss the significance of
our findings in context with cell signalling and emergent behaviour in cellular
computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3686</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3686</id><created>2014-08-15</created><updated>2016-02-12</updated><authors><author><keyname>Chandramouli</keyname><forenames>Paramanand</forenames></author><author><keyname>Favaro</keyname><forenames>Paolo</forenames></author><author><keyname>Perrone</keyname><forenames>Daniele</forenames></author></authors><title>Motion Deblurring for Plenoptic Images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address for the first time the issue of motion blur in light field images
captured from plenoptic cameras. We propose a solution to the estimation of a
sharp high resolution scene radiance given a blurry light field image, when the
motion blur point spread function is unknown, i.e., the so-called blind
deconvolution problem. In a plenoptic camera, the spatial sampling in each view
is not only decimated but also defocused. Consequently, current blind
deconvolution approaches for traditional cameras are not applicable. Due to the
complexity of the imaging model, we investigate first the case of uniform
(shift-invariant) blur of Lambertian objects, i.e., when objects are
sufficiently far away from the camera to be approximately invariant to depth
changes and their reflectance does not vary with the viewing direction. We
introduce a highly parallelizable model for light field motion blur that is
computationally and memory efficient. We then adapt a regularized blind
deconvolution approach to our model and demonstrate its performance on both
synthetic and real light field data. Our method handles practical issues in
real cameras such as radial distortion correction and alignment within an
energy minimization framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3690</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3690</id><created>2014-08-15</created><authors><author><keyname>Bulatov</keyname><forenames>Andrei A.</forenames></author></authors><title>Conservative constraint satisfaction re-revisited</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conservative constraint satisfaction problems (CSPs) constitute an important
particular case of the general CSP, in which the allowed values of each
variable can be restricted in an arbitrary way. Problems of this type are well
studied for graph homomorphisms. A dichotomy theorem characterizing
conservative CSPs solvable in polynomial time and proving that the remaining
ones are NP-complete was proved by Bulatov in 2003. Its proof, however, is
quite long and technical. A shorter proof of this result based on the absorbing
subuniverses technique was suggested by Barto in 2011. In this paper we give a
short elementary prove of the dichotomy theorem for the conservative CSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3693</identifier>
 <datestamp>2015-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3693</id><created>2014-08-15</created><updated>2015-05-13</updated><authors><author><keyname>Towfic</keyname><forenames>Zaid J.</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Stability and Performance Limits of Adaptive Primal-Dual Networks</title><categories>math.OC cs.DC cs.LG cs.MA</categories><comments>16 pages, 9 figures</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 63, no. 11, pp.
  2888-2903, Jun. 2015</journal-ref><doi>10.1109/TSP.2015.2415759</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies distributed primal-dual strategies for adaptation and
learning over networks from streaming data. Two first-order methods are
considered based on the Arrow-Hurwicz (AH) and augmented Lagrangian (AL)
techniques. Several revealing results are discovered in relation to the
performance and stability of these strategies when employed over adaptive
networks. The conclusions establish that the advantages that these methods have
for deterministic optimization problems do not necessarily carry over to
stochastic optimization problems. It is found that they have narrower stability
ranges and worse steady-state mean-square-error performance than primal methods
of the consensus and diffusion type. It is also found that the AH technique can
become unstable under a partial observation model, while the other techniques
are able to recover the unknown under this scenario. A method to enhance the
performance of AL strategies is proposed by tying the selection of the
step-size to their regularization parameter. It is shown that this method
allows the AL algorithm to approach the performance of consensus and diffusion
strategies but that it remains less stable than these other strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3696</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3696</id><created>2014-08-15</created><updated>2015-12-02</updated><authors><author><keyname>Haraguchi</keyname><forenames>Kazuya</forenames></author></authors><title>On A Generalization of &quot;Eight Blocks to Madness&quot;</title><categories>cs.DM math.CO</categories><comments>13 pages</comments><acm-class>G.2.1; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a puzzle such that a set of colored cubes is given as an
instance. Each cube has unit length on each edge and its surface is colored so
that what we call the Surface Color Condition is satisfied. Given a palette of
six colors, the condition requires that each face should have exactly one color
and all faces should have different colors from each other. The puzzle asks to
compose a 2x2x2 cube that satisfies the Surface Color Condition from eight
suitable cubes in the instance. Note that cubes and solutions have 30 varieties
respectively. In this paper, we give answers to three problems on the puzzle:
(i) For every subset of the 30 solutions, is there an instance that has the
subset exactly as its solution set? (ii) Create a maximum sized infeasible
instance (i.e., one having no solution). (iii) Create a minimum sized universal
instance (i.e., one having all 30 solutions). We solve the problems with the
help of a computer search. We show that the answer to (i) is no. For (ii) and
(iii), we show examples of the required instances, where their sizes are 23 and
12, respectively. The answer to (ii) solves one of the open problems that were
raised in [E.Berkove et al., &quot;An Analysis of the (Colored Cubes)^3 Puzzle,&quot;
Discrete Mathematics, 308 (2008) pp. 1033-1045].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3698</identifier>
 <datestamp>2015-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3698</id><created>2014-08-15</created><authors><author><keyname>Salamatian</keyname><forenames>Salman</forenames></author><author><keyname>Zhang</keyname><forenames>Amy</forenames></author><author><keyname>Calmon</keyname><forenames>Flavio du Pin</forenames></author><author><keyname>Bhamidipati</keyname><forenames>Sandilya</forenames></author><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>Kveton</keyname><forenames>Branislav</forenames></author><author><keyname>Oliveira</keyname><forenames>Pedro</forenames></author><author><keyname>Taft</keyname><forenames>Nina</forenames></author></authors><title>Managing your Private and Public Data: Bringing down Inference Attacks
  against your Privacy</title><categories>cs.CR</categories><doi>10.1109/JSTSP.2015.2442227</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a practical methodology to protect a user's private data, when he
wishes to publicly release data that is correlated with his private data, in
the hope of getting some utility. Our approach relies on a general statistical
inference framework that captures the privacy threat under inference attacks,
given utility constraints. Under this framework, data is distorted before it is
released, according to a privacy-preserving probabilistic mapping. This mapping
is obtained by solving a convex optimization problem, which minimizes
information leakage under a distortion constraint. We address practical
challenges encountered when applying this theoretical framework to real world
data. On one hand, the design of optimal privacy-preserving mechanisms requires
knowledge of the prior distribution linking private data and data to be
released, which is often unavailable in practice. On the other hand, the
optimization may become untractable and face scalability issues when data
assumes values in large size alphabets, or is high dimensional. Our work makes
three major contributions. First, we provide bounds on the impact on the
privacy-utility tradeoff of a mismatched prior. Second, we show how to reduce
the optimization size by introducing a quantization step, and how to generate
privacy mappings under quantization. Third, we evaluate our method on three
datasets, including a new dataset that we collected, showing correlations
between political convictions and TV viewing habits. We demonstrate that good
privacy properties can be achieved with limited distortion so as not to
undermine the original purpose of the publicly released data, e.g.
recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3704</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3704</id><created>2014-08-16</created><authors><author><keyname>Dasarathan</keyname><forenames>Sivaraman</forenames></author><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author><author><keyname>Banavar</keyname><forenames>Mahesh</forenames></author><author><keyname>Spanias</keyname><forenames>Andreas</forenames></author></authors><title>Robust Consensus in the Presence of Impulsive Channel Noise</title><categories>cs.SY cs.DC</categories><comments>24 pages, 7 figures, Submitted to Transactions on Signal Processing,
  Apr 2014 (Submitted, currently in review)</comments><doi>10.1109/TSP.2015.2408564</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A distributed average consensus algorithm robust to a wide range of impulsive
channel noise distributions is proposed. This work is the first of its kind in
the literature to propose a consensus algorithm which relaxes the requirement
of finite moments on the communication noise. It is shown that the nodes reach
consensus asymptotically to a finite random variable whose expectation is the
desired sample average of the initial observations with a variance that depends
on the step size of the algorithm and the receiver nonlinear function. The
asymptotic performance is characterized by deriving the asymptotic covariance
matrix using results from stochastic approximation theory. Simulations
corroborate our analytical findings and highlight the robustness of the
proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3709</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3709</id><created>2014-08-16</created><authors><author><keyname>Bagchi</keyname><forenames>Parama</forenames></author><author><keyname>Bhattacharjee</keyname><forenames>Debotosh</forenames></author><author><keyname>Nasipuri</keyname><forenames>Mita</forenames></author></authors><title>Robust 3D face recognition in presence of pose and partial occlusions or
  missing parts</title><categories>cs.CV</categories><comments>the paper is of 15 pages, International Journal in Foundations of
  Computer Science &amp; Technology (IJFCST), Vol.4, No.4, July 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a robust 3D face recognition system which can
handle pose as well as occlusions in real world. The system at first takes as
input, a 3D range image, simultaneously registers it using ICP(Iterative
Closest Point) algorithm. ICP used in this work, registers facial surfaces to a
common model by minimizing distances between a probe model and a gallery model.
However the performance of ICP relies heavily on the initial conditions. Hence,
it is necessary to provide an initial registration, which will be improved
iteratively and finally converge to the best alignment possible. Once the faces
are registered, the occlusions are automatically extracted by thresholding the
depth map values of the 3D image. After the occluded regions are detected,
restoration is done by Principal Component Analysis (PCA). The restored images,
after the removal of occlusions, are then fed to the recognition system for
classification purpose. Features are extracted from the reconstructed
non-occluded face images in the form of face normals. The experimental results
which were obtained on the occluded facial images from the Bosphorus 3D face
database, illustrate that our occlusion compensation scheme has attained a
recognition accuracy of 91.30%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3712</identifier>
 <datestamp>2015-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3712</id><created>2014-08-16</created><updated>2015-02-12</updated><authors><author><keyname>Rahimi-Keshari</keyname><forenames>Saleh</forenames></author><author><keyname>Lund</keyname><forenames>Austin P.</forenames></author><author><keyname>Ralph</keyname><forenames>Timothy C.</forenames></author></authors><title>What can quantum optics say about computational complexity theory?</title><categories>quant-ph cs.CC</categories><comments>5 pages, 1 figure</comments><journal-ref>Phys. Rev. Lett. 114, 060501 (2015)</journal-ref><doi>10.1103/PhysRevLett.114.060501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering the problem of sampling from the output photon-counting
probability distribution of a linear-optical network for input Gaussian states,
we obtain results that are of interest from both quantum theory and the
computational complexity theory point of view. We derive a general formula for
calculating the output probabilities, and by considering input thermal states,
we show that the output probabilities are proportional to permanents of
positive-semidefinite Hermitian matrices. It is believed that approximating
permanents of complex matrices in general is a #P-hard problem. However, we
show that these permanents can be approximated with an algorithm in BPP^NP
complexity class, as there exists an efficient classical algorithm for sampling
from the output probability distribution. We further consider input
squeezed-vacuum states and discuss the complexity of sampling from the
probability distribution at the output.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3717</identifier>
 <datestamp>2014-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3717</id><created>2014-08-16</created><updated>2014-12-18</updated><authors><author><keyname>Selva</keyname><forenames>J.</forenames></author></authors><title>FFT Interpolation from Nonuniform Samples Lying in a Regular Grid</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method to interpolate a periodic band-limited signal
from its samples lying at nonuniform positions in a regular grid, which is
based on the FFT and has the same complexity order as this last algorithm. This
kind of interpolation is usually termed &quot;the missing samples problem&quot; in the
literature, and there exists a wide variety of iterative and direct methods for
its solution. The one presented in this paper is a direct method that exploits
the properties of the so-called erasure polynomial, and it provides a
significant improvement on the most efficient method in the literature, which
seems to be the burst error recovery (BER) technique of Marvasti's et al. The
numerical stability and complexity of the method are evaluated numerically and
compared with the pseudo-inverse and BER solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3725</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3725</id><created>2014-08-16</created><updated>2015-04-17</updated><authors><author><keyname>Li</keyname><forenames>Kun</forenames></author><author><keyname>Meng</keyname><forenames>Max Q. -H.</forenames></author></authors><title>Object Structure from Manipulation via Particle Filter and Robot-based
  Active Learning</title><categories>cs.RO</categories><comments>This paper has been withdrawn due to incorrect article structure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To learn object models for robotic manipulation, unsupervised methods cannot
provide accurate object structural information and supervised methods require a
large amount of manually labeled training samples, thus interactive object
segmentation is developed to automate object modeling. In this article, we
formulate a novel dynamic process for interactive object segmentation, and
develop a solution based on particle filter and active learning so that a robot
can manipulate and learn object structures incrementally and automatically. We
demonstrate our method with a humanoidrobot on different types of objects, and
compare its segmentation performancewith established methods on selected
objects. The result shows that our approach allows more accurate object
modeling and reveals richer object structural information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3727</identifier>
 <datestamp>2015-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3727</id><created>2014-08-16</created><updated>2015-04-17</updated><authors><author><keyname>Li</keyname><forenames>Kun</forenames></author><author><keyname>Meng</keyname><forenames>Max Q. -H.</forenames></author></authors><title>Inverse Reinforcement Learning with Multi-Relational Chains for
  Robot-Centered Smart Home</title><categories>cs.RO cs.LG</categories><comments>This paper has been withdrawn due to incorrect article structure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a robot-centered smart home, the robot observes the home states with its
own sensors, and then it can change certain object states according to an
operator's commands for remote operations, or imitate the operator's behaviors
in the house for autonomous operations. To model the robot's imitation of the
operator's behaviors in a dynamic indoor environment, we use multi-relational
chains to describe the changes of environment states, and apply inverse
reinforcement learning to encoding the operator's behaviors with a learned
reward function. We implement this approach with a mobile robot, and do five
experiments to include increasing training days, object numbers, and action
types. Besides, a baseline method by directly recording the operator's
behaviors is also implemented, and comparison is made on the accuracy of home
state evaluation and the accuracy of robot action selection. The results show
that the proposed approach handles dynamic environment well, and guides the
robot's actions in the house more accurately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3731</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3731</id><created>2014-08-16</created><updated>2014-11-03</updated><authors><author><keyname>Jungiewicz</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>&#x141;opuszy&#x144;ski</keyname><forenames>Micha&#x142;</forenames></author></authors><title>Unsupervised Keyword Extraction from Polish Legal Texts</title><categories>cs.CL</categories><journal-ref>Lecture Notes in Computer Science, Volume 8686, Springer 2014, pp
  65-70</journal-ref><doi>10.1007/978-3-319-10888-9_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we present an application of the recently proposed unsupervised
keyword extraction algorithm RAKE to a corpus of Polish legal texts from the
field of public procurement. RAKE is essentially a language and domain
independent method. Its only language-specific input is a stoplist containing a
set of non-content words. The performance of the method heavily depends on the
choice of such a stoplist, which should be domain adopted. Therefore, we
complement RAKE algorithm with an automatic approach to selecting non-content
words, which is based on the statistical properties of term distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3732</identifier>
 <datestamp>2015-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3732</id><created>2014-08-16</created><updated>2015-09-23</updated><authors><author><keyname>Meyer</keyname><forenames>Florian</forenames></author><author><keyname>Wymeersch</keyname><forenames>Henk</forenames></author><author><keyname>Fr&#xf6;hle</keyname><forenames>Markus</forenames></author><author><keyname>Hlawatsch</keyname><forenames>Franz</forenames></author></authors><title>Distributed Estimation with Information-Seeking Control in Agent Network</title><categories>cs.SY</categories><comments>17 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a distributed, cooperative framework and method for Bayesian
estimation and control in decentralized agent networks. Our framework combines
joint estimation of time-varying global and local states with
information-seeking control optimizing the behavior of the agents. It is suited
to nonlinear and non-Gaussian problems and, in particular, to location-aware
networks. For cooperative estimation, a combination of belief propagation
message passing and consensus is used. For cooperative control, the negative
posterior joint entropy of all states is maximized via a gradient ascent. The
estimation layer provides the control layer with probabilistic information in
the form of sample representations of probability distributions. Simulation
results demonstrate intelligent behavior of the agents and excellent estimation
performance for a simultaneous self-localization and target tracking problem.
In a cooperative localization scenario with only one anchor, mobile agents can
localize themselves after a short time with an accuracy that is higher than the
accuracy of the performed distance measurements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3733</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3733</id><created>2014-08-16</created><authors><author><keyname>Hassan</keyname><forenames>Ehtesham</forenames></author><author><keyname>Shroff</keyname><forenames>Gautam</forenames></author><author><keyname>Agarwal</keyname><forenames>Puneet</forenames></author></authors><title>Multi-Sensor Event Detection using Shape Histograms</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular sensor data consists of multiple time-series arising from a number
of sensors. Using such multi-sensor data we would like to detect occurrences of
specific events that vehicles encounter, e.g., corresponding to particular
maneuvers that a vehicle makes or conditions that it encounters. Events are
characterized by similar waveform patterns re-appearing within one or more
sensors. Further such patterns can be of variable duration. In this work, we
propose a method for detecting such events in time-series data using a novel
feature descriptor motivated by similar ideas in image processing. We define
the shape histogram: a constant dimension descriptor that nevertheless captures
patterns of variable duration. We demonstrate the efficacy of using shape
histograms as features to detect events in an SVM-based, multi-sensor,
supervised learning scenario, i.e., multiple time-series are used to detect an
event. We present results on real-life vehicular sensor data and show that our
technique performs better than available pattern detection implementations on
our data, and that it can also be used to combine features from multiple
sensors resulting in better accuracy than using any single sensor. Since
previous work on pattern detection in time-series has been in the single series
context, we also present results using our technique on multiple standard
time-series datasets and show that it is the most versatile in terms of how it
ranks compared to other published results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3735</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3735</id><created>2014-08-16</created><authors><author><keyname>Alhawarat</keyname><forenames>Mohammad</forenames></author><author><keyname>Nazih</keyname><forenames>Waleed</forenames></author><author><keyname>Eldesouki</keyname><forenames>Mohammad</forenames></author></authors><title>Analysis of a chaotic spiking neural model: The NDS neuron</title><categories>cs.NE nlin.CD</categories><comments>Computer Science &amp; Information Technology, 2013, Vol. 4 No. 3</comments><doi>10.5121/csit.2013.3412</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Further analysis and experimentation is carried out in this paper for a
chaotic dynamic model, viz. the Nonlinear Dynamic State neuron (NDS). The
analysis and experimentations are performed to further understand the
underlying dynamics of the model and enhance it as well. Chaos provides many
interesting properties that can be exploited to achieve computational tasks.
Such properties are sensitivity to initial conditions, space filling, control
and synchronization.Chaos might play an important role in information
processing tasks in human brain as suggested by biologists. If artificial
neural networks (ANNs) is equipped with chaos then it will enrich the dynamic
behaviours of such networks. The NDS model has some limitations and can be
overcome in different ways. In this paper different approaches are followed to
push the boundaries of the NDS model in order to enhance it. One way is to
study the effects of scaling the parameters of the chaotic equations of the NDS
model and study the resulted dynamics. Another way is to study the method that
is used in discretization of the original R\&quot;{o}ssler that the NDS model is
based on. These approaches have revealed some facts about the NDS attractor and
suggest why such a model can be stabilized to large number of unstable periodic
orbits (UPOs) which might correspond to memories in phase space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3738</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3738</id><created>2014-08-16</created><updated>2014-08-19</updated><authors><author><keyname>Cui</keyname><forenames>Pengbi</forenames></author><author><keyname>Tang</keyname><forenames>Ming</forenames></author><author><keyname>Wu</keyname><forenames>Zhi-Xi</forenames></author></authors><title>Message spreading in networks with stickiness and persistence: Large
  clustering does not always facilitate large-scale diffusion</title><categories>physics.soc-ph cs.SI</categories><comments>12pages, 7 figures, Supporting Information (20 pages), accepted by
  Sci. Rep</comments><msc-class>60E15, 60G05</msc-class><acm-class>J.2.9; K.4.0</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Recent empirical studies have confirmed the key roles of complex contagion
mechanisms such as memory, social reinforcement, and decay effects in
information diffusion and behaviour spreading. Inspired by this fact, we here
propose a new agent--based model to capture the whole picture of the joint
action of the three mechanisms in information spreading, by quantifying the
complex contagion mechanisms as stickiness and persistence, and carry out
extensive simulations of the model on various networks. By numerical
simulations as well as theoretical analysis, we find that the stickiness of the
message determines the critical dynamics of message diffusion on tree-like
networks, whereas the persistence plays a decisive role on dense regular
lattices. In either network, the greater persistence can effectively make the
message more invasive. Of particular interest is that our research results
renew our previous knowledge that messages can spread broader in networks with
large clustering, which turns out to be only true when they can inform a
non-zero fraction of the population in the limit of large system size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3740</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3740</id><created>2014-08-16</created><authors><author><keyname>Xu</keyname><forenames>Yangyang</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author></authors><title>A fast patch-dictionary method for whole image recovery</title><categories>cs.CV math.OC</categories><msc-class>94A08, 94A12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various algorithms have been proposed for dictionary learning. Among those
for image processing, many use image patches to form dictionaries. This paper
focuses on whole-image recovery from corrupted linear measurements. We address
the open issue of representing an image by overlapping patches: the overlapping
leads to an excessive number of dictionary coefficients to determine. With very
few exceptions, this issue has limited the applications of image-patch methods
to the local kind of tasks such as denoising, inpainting, cartoon-texture
decomposition, super-resolution, and image deblurring, for which one can
process a few patches at a time. Our focus is global imaging tasks such as
compressive sensing and medical image recovery, where the whole image is
encoded together, making it either impossible or very ineffective to update a
few patches at a time.
  Our strategy is to divide the sparse recovery into multiple subproblems, each
of which handles a subset of non-overlapping patches, and then the results of
the subproblems are averaged to yield the final recovery. This simple strategy
is surprisingly effective in terms of both quality and speed. In addition, we
accelerate computation of the learned dictionary by applying a recent block
proximal-gradient method, which not only has a lower per-iteration complexity
but also takes fewer iterations to converge, compared to the current
state-of-the-art. We also establish that our algorithm globally converges to a
stationary point. Numerical results on synthetic data demonstrate that our
algorithm can recover a more faithful dictionary than two state-of-the-art
methods.
  Combining our whole-image recovery and dictionary-learning methods, we
numerically simulate image inpainting, compressive sensing recovery, and
deblurring. Our recovery is more faithful than those of a total variation
method and a method based on overlapping patches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3743</identifier>
 <datestamp>2014-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3743</id><created>2014-08-16</created><updated>2014-09-02</updated><authors><author><keyname>Finko</keyname><forenames>Oleg</forenames></author><author><keyname>Samoylenko</keyname><forenames>Dmitriy</forenames></author><author><keyname>Dichenko</keyname><forenames>Sergey</forenames></author><author><keyname>Eliseev</keyname><forenames>Nikolay</forenames></author></authors><title>Parallel generator of $q$-valued pseudorandom sequences based on
  arithmetic polynomials</title><categories>cs.CR</categories><comments>8 pages, 3 figures</comments><msc-class>94A55, 68W10, 03B50, 11A07, 11B50, 94A60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new method for parallel generation of $q$-valued pseudorandom sequence
based on the presentation of systems generating logical formulae by means of
arithmetic polynomials is proposed. Fragment consisting of $k$-elements of
$q$-valued pseudorandom sequence may be obtained by means of single calculation
of a single recursion numerical formula. It is mentioned that the method of the
&quot;arithmetization&quot; of generation may be used and further developed in order to
protect the encryption gears from cryptographic onset, resulting in the
initiating of mass hardware failures. The achieved results may be widely
applied to the realization of perspective high-performance cryptographic
facilities for information protection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3750</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3750</id><created>2014-08-16</created><authors><author><keyname>Ouellet</keyname><forenames>S&#xe9;bastien</forenames></author></authors><title>Real-time emotion recognition for gaming using deep convolutional
  network features</title><categories>cs.CV cs.LG cs.NE</categories><comments>6 pages, 8 figures, IEEE style</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of the present study is to explore the application of deep
convolutional network features to emotion recognition. Results indicate that
they perform similarly to other published models at a best recognition rate of
94.4%, and do so with a single still image rather than a video stream. An
implementation of an affective feedback game is also described, where a
classifier using these features tracks the facial expressions of a player in
real-time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3757</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3757</id><created>2014-08-16</created><authors><author><keyname>Sadr</keyname><forenames>Sanam</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author></authors><title>Tier Association Probability and Spectrum Partitioning for Maximum Rate
  Coverage in Multi-tier Heterogeneous Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>Accepted for publication in the IEEE Communications Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a wireless multi-tier heterogeneous network with orthogonal spectrum
allocation across tiers, we optimize the association probability and the
fraction of spectrum allocated to each tier so as to maximize rate coverage. In
practice, the association probability can be controlled using a biased received
signal power. The optimization problem is non-convex and we are forced to
explore locally optimal solutions. We make two contributions in this paper:
first, we show that there exists a relation between the first derivatives of
the objective function with respect to each of the optimization variables. This
can be used to simplify numerical solutions to the optimization problem.
Second, we explore the optimality of the intuitive solution that the fraction
of spectrum allocated to each tier should be equal to the tier association
probability. We show that, in this case, a closed-form solution exists.
Importantly, our numerical results show that there is essentially zero
performance loss. The results also illustrate the significant gains possible by
jointly optimizing the user association and the resource allocation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3764</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3764</id><created>2014-08-16</created><authors><author><keyname>Schwiebert</keyname><forenames>Loren</forenames></author><author><keyname>Hailat</keyname><forenames>Eyad</forenames></author><author><keyname>Rushaidat</keyname><forenames>Kamel</forenames></author><author><keyname>Mick</keyname><forenames>Jason</forenames></author><author><keyname>Potoff</keyname><forenames>Jeffrey</forenames></author></authors><title>An Efficient Cell List Implementation for Monte Carlo Simulation on GPUs</title><categories>cs.DC physics.comp-ph</categories><comments>30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximizing the performance potential of the modern day GPU architecture
requires judicious utilization of available parallel resources. Although
dramatic reductions can often be obtained through straightforward mappings,
further performance improvements often require algorithmic redesigns to more
closely exploit the target architecture. In this paper, we focus on efficient
molecular simulations for the GPU and propose a novel cell list algorithm that
better utilizes its parallel resources. Our goal is an efficient GPU
implementation of large-scale Monte Carlo simulations for the grand canonical
ensemble. This is a particularly challenging application because there is
inherently less computation and parallelism than in similar applications with
molecular dynamics. Consistent with the results of prior researchers, our
simulation results show traditional cell list implementations for Monte Carlo
simulations of molecular systems offer effectively no performance improvement
for small systems [5, 14], even when porting to the GPU. However for larger
systems, the cell list implementation offers significant gains in performance.
Furthermore, our novel cell list approach results in better performance for all
problem sizes when compared with other GPU implementations with or without cell
lists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3772</identifier>
 <datestamp>2015-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3772</id><created>2014-08-16</created><updated>2015-06-24</updated><authors><author><keyname>Minaee</keyname><forenames>Shervin</forenames></author><author><keyname>Abdolrashidi</keyname><forenames>AmirAli</forenames></author></authors><title>Highly Accurate Multispectral Palmprint Recognition Using Statistical
  and Wavelet Features</title><categories>cs.CV</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Palmprint is one of the most useful physiological biometrics that can be used
as a powerful means in personal recognition systems. The major features of the
palmprints are palm lines, wrinkles and ridges, and many approaches use them in
different ways towards solving the palmprint recognition problem. Here we have
proposed to use a set of statistical and wavelet-based features; statistical to
capture the general characteristics of palmprints; and wavelet-based to find
those information not evident in the spatial domain. Also we use two different
classification approaches, minimum distance classifier scheme and weighted
majority voting algorithm, to perform palmprint matching. The proposed method
is tested on a well-known palmprint dataset of 6000 samples and has shown an
impressive accuracy rate of 99.65\%-100\% for most scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3773</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3773</id><created>2014-08-16</created><authors><author><keyname>Sadr</keyname><forenames>Sanam</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author></authors><title>Partially-Distributed Resource Allocation in Small-Cell Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>Accepted on May 15, 2014 for publication in the IEEE Transactions on
  Wireless Communications</comments><doi>10.1109/TWC.2014.2327030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a four-stage hierarchical resource allocation scheme for the
downlink of a large-scale small-cell network in the context of orthogonal
frequency-division multiple access (OFDMA). Since interference limits the
capabilities of such networks, resource allocation and interference management
are crucial. However, obtaining the globally optimum resource allocation is
exponentially complex and mathematically intractable. Here, we develop a
partially decentralized algorithm to obtain an effective solution. The three
major advantages of our work are: 1) as opposed to a fixed resource allocation,
we consider load demand at each access point (AP) when allocating spectrum; 2)
to prevent overloaded APs, our scheme is dynamic in the sense that as the users
move from one AP to the other, so do the allocated resources, if necessary, and
such considerations generally result in huge computational complexity, which
brings us to the third advantage: 3) we tackle complexity by introducing a
hierarchical scheme comprising four phases: user association, load estimation,
interference management via graph coloring, and scheduling. We provide
mathematical analysis for the first three steps modeling the user and AP
locations as Poisson point processes. Finally, we provide results of numerical
simulations to illustrate the efficacy of our scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3775</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3775</id><created>2014-08-16</created><authors><author><keyname>Caleiro</keyname><forenames>Carlos</forenames></author><author><keyname>Marcos</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Volpe</keyname><forenames>Marco</forenames></author></authors><title>Bivalent semantics, generalized compositionality and analytic
  classic-like tableaux for finite-valued logics</title><categories>cs.LO</categories><msc-class>03B50 (Primary), 03B35 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is a contribution both to the theoretical foundations and to the
actual construction of efficient automatizable proof procedures for
non-classical logics. We focus here on the case of finite-valued logics, and
exhibit: (i) a mechanism for producing a classic-like description of them in
terms of an effective variety of bivalent semantics; (ii) a mechanism for
extracting, from the bivalent semantics so obtained, uniform
(classically-labeled) cut-free standard analytic tableaux with possibly
branching invertible rules and paired with proof strategies designed to
guarantee termination of the associated proof procedure; (iii) a mechanism to
also provide, for the same logics, uniform cut-based tableau systems with
linear rules. The latter tableau systems are shown to be adequate even when
restricted to analytic cuts, and they are also shown to polynomially simulate
truth-tables, a feature that is not enjoyed by the former standard type of
tableau systems (not even in the 2-valued case). The results are based on
useful generalizations of the notions of analyticity and compositionality, and
illustrate a theory that applies to many other classes of non-classical logics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3783</identifier>
 <datestamp>2014-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3783</id><created>2014-08-16</created><updated>2014-09-18</updated><authors><author><keyname>Toulis</keyname><forenames>Panos</forenames></author><author><keyname>Parkes</keyname><forenames>David C.</forenames></author></authors><title>Long-term causal effects of economic mechanisms on agent incentives</title><categories>cs.GT stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Economic mechanisms administer the allocation of resources to interested
agents based on their self-reported types. One objective in mechanism design is
to design a strategyproof process so that no agent will have an incentive to
misreport its type. However, typical analyses of the incentives properties of
mechanisms operate under strong, usually untestable assumptions. Empirical,
data-oriented approaches are, at best, under-developed. Furthermore,
mechanism/policy evaluation methods usually ignore the dynamic nature of a
multi-agent system and are thus inappropriate for estimating long-term effects.
We introduce the problem of estimating the causal effects of mechanisms on
incentives and frame it under the Rubin causal framework \citep{rubin74,
rubin78}. This raises unique technical challenges since the outcome of interest
(agent truthfulness) is confounded with strategic interactions and,
interestingly, is typically never observed under any mechanism. We develop a
methodology to estimate such causal effects that using a prior that is based on
a strategic equilibrium model. Working on the domain of kidney exchanges, we
show how to apply our methodology to estimate causal effects of kidney
allocation mechanisms on hospitals' incentives. Our results demonstrate that
the use of game-theoretic prior captures the dynamic nature of the kidney
exchange multiagent system and shrinks the estimates towards long-term effects,
thus improving upon typical methods that completely ignore agents' strategic
behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3800</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3800</id><created>2014-08-17</created><authors><author><keyname>Bahrami</keyname><forenames>Sajjad</forenames></author><author><keyname>Hodtani</keyname><forenames>Ghosheh Abed</forenames></author></authors><title>Capacity Bounds and a Certain Capacity Region for Special Three-Receiver
  Broadcast Channels with Side Information</title><categories>cs.IT math.IT</categories><comments>24 pages, 2 figures, Submitted to IET Communications Journal for
  possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fact that the results for 2-receiver broadcast channels (BCs) are not
generalized to the 3-receiver ones is of information theoretical importance. In
this paper we study two classes of discrete memoryless BCs with non-causal side
information (SI), i.e. multilevel BC (MBC) and 3-receiver less noisy BC. First,
we obtain an achievable rate region and a capacity outer bound for the MBC.
Second, we prove a special capacity region for the 3-receiver less noisy BC.
Third, the obtained special capacity region for the 3-receiver less noisy BC is
extended to continuous alphabet fading Gaussian version. It is worth mentioning
that the previous works are special cases of our works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3807</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3807</id><created>2014-08-17</created><authors><author><keyname>Barber</keyname><forenames>David</forenames></author></authors><title>On solving Ordinary Differential Equations using Gaussian Processes</title><categories>stat.ME cs.NA math.NA stat.CO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a set of Gaussian Process based approaches that can be used to
solve non-linear Ordinary Differential Equations. We suggest an explicit
probabilistic solver and two implicit methods, one analogous to Picard
iteration and the other to gradient matching. All methods have greater accuracy
than previously suggested Gaussian Process approaches. We also suggest a
general approach that can yield error estimates from any standard ODE solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3809</identifier>
 <datestamp>2014-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3809</id><created>2014-08-17</created><updated>2014-09-22</updated><authors><author><keyname>Rahmani</keyname><forenames>Hossein</forenames></author><author><keyname>Mahmood</keyname><forenames>Arif</forenames></author><author><keyname>Huynh</keyname><forenames>Du Q.</forenames></author><author><keyname>Mian</keyname><forenames>Ajmal</forenames></author></authors><title>HOPC: Histogram of Oriented Principal Components of 3D Pointclouds for
  Action Recognition</title><categories>cs.CV</categories><comments>ECCV 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing techniques for 3D action recognition are sensitive to viewpoint
variations because they extract features from depth images which change
significantly with viewpoint. In contrast, we directly process the pointclouds
and propose a new technique for action recognition which is more robust to
noise, action speed and viewpoint variations. Our technique consists of a novel
descriptor and keypoint detection algorithm. The proposed descriptor is
extracted at a point by encoding the Histogram of Oriented Principal Components
(HOPC) within an adaptive spatio-temporal support volume around that point.
Based on this descriptor, we present a novel method to detect Spatio-Temporal
Key-Points (STKPs) in 3D pointcloud sequences. Experimental results show that
the proposed descriptor and STKP detector outperform state-of-the-art
algorithms on three benchmark human activity datasets. We also introduce a new
multiview public dataset and show the robustness of our proposed method to
viewpoint variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3810</identifier>
 <datestamp>2014-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3810</id><created>2014-08-17</created><updated>2014-09-22</updated><authors><author><keyname>Rahmani</keyname><forenames>Hossein</forenames></author><author><keyname>Mahmood</keyname><forenames>Arif</forenames></author><author><keyname>Huynh</keyname><forenames>Du</forenames></author><author><keyname>Mian</keyname><forenames>Ajmal</forenames></author></authors><title>Action Classification with Locality-constrained Linear Coding</title><categories>cs.CV</categories><comments>ICPR 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an action classification algorithm which uses Locality-constrained
Linear Coding (LLC) to capture discriminative information of human body
variations in each spatiotemporal subsequence of a video sequence. Our proposed
method divides the input video into equally spaced overlapping spatiotemporal
subsequences, each of which is decomposed into blocks and then cells. We use
the Histogram of Oriented Gradient (HOG3D) feature to encode the information in
each cell. We justify the use of LLC for encoding the block descriptor by
demonstrating its superiority over Sparse Coding (SC). Our sequence descriptor
is obtained via a logistic regression classifier with L2 regularization. We
evaluate and compare our algorithm with ten state-of-the-art algorithms on five
benchmark datasets. Experimental results show that, on average, our algorithm
gives better accuracy than these ten algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3814</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3814</id><created>2014-08-17</created><authors><author><keyname>Devi</keyname><forenames>Oinam Binarani</forenames></author><author><keyname>Paul</keyname><forenames>Nissi S.</forenames></author><author><keyname>Singh</keyname><forenames>Y. Jayanta</forenames></author></authors><title>Robust Statistical Approach for Extraction of Moving Human Silhouettes
  from Videos</title><categories>cs.CV</categories><comments>10 pages, 5 figures</comments><journal-ref>International Journal on Information Theory (IJIT), Vol.3, No.3,
  July 2014, Pg.55-64</journal-ref><doi>10.5121/ijit.2014.3306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human pose estimation is one of the key problems in computer vision that has
been studied in the recent years. The significance of human pose estimation is
in the higher level tasks of understanding human actions applications such as
recognition of anomalous actions present in videos and many other related
applications. The human poses can be estimated by extracting silhouettes of
humans as silhouettes are robust to variations and it gives the shape
information of the human body. Some common challenges include illumination
changes, variation in environments, and variation in human appearances. Thus
there is a need for a robust method for human pose estimation. This paper
presents a study and analysis of approaches existing for silhouette extraction
and proposes a robust technique for extracting human silhouettes in video
sequences. Gaussian Mixture Model (GMM) A statistical approach is combined with
HSV (Hue, Saturation and Value) color space model for a robust background model
that is used for background subtraction to produce foreground blobs, called
human silhouettes. Morphological operations are then performed on foreground
blobs from background subtraction. The silhouettes obtained from this work can
be used in further tasks associated with human action interpretation and
activity processes like human action classification, human pose estimation and
action recognition or action interpretation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3818</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3818</id><created>2014-08-17</created><authors><author><keyname>Passoni</keyname><forenames>Lucia I.</forenames></author><author><keyname>Pra</keyname><forenames>Ana I. Dai</forenames></author><author><keyname>Meschino</keyname><forenames>Gustavo J.</forenames></author><author><keyname>Guzman</keyname><forenames>MArcelo</forenames></author><author><keyname>Weber</keyname><forenames>Chistian</forenames></author><author><keyname>Rabal</keyname><forenames>H&#xe9;ctor</forenames></author><author><keyname>Trivi</keyname><forenames>Marcelo</forenames></author></authors><title>Unsupervised learning segmentation for dynamic speckle activity images</title><categories>physics.optics cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the design of decision models based on Computational
Intelligence techniques applied to image sequences of dynamic laser speckle.
These models aim to identify image regions of biological specimens illuminated
by a coherent beam coming from a laser. The field image is pseudo colored using
a Self Organizing Map projection. This process is carried out using a set of
descriptors applied to the intensity variations along time in every pixel of an
image sequence. The models use descriptors selected to improve effectiveness,
depending on the specific application. We present two examples of the
application of the proposed techniques to assess biological tissues. The
results obtained are encouraging and significantly improve those obtained using
a single descriptor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3821</identifier>
 <datestamp>2015-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3821</id><created>2014-08-17</created><updated>2015-01-08</updated><authors><author><keyname>Markov</keyname><forenames>Igor L.</forenames></author></authors><title>Limits on Fundamental Limits to Computation</title><categories>cs.ET quant-ph</categories><comments>15 pages, 4 figures, 1 table</comments><journal-ref>Nature 512, 147-154 (14 August 2014)</journal-ref><doi>10.1038/nature13570</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An indispensable part of our lives, computing has also become essential to
industries and governments. Steady improvements in computer hardware have been
supported by periodic doubling of transistor densities in integrated circuits
over the last fifty years. Such Moore scaling now requires increasingly heroic
efforts, stimulating research in alternative hardware and stirring controversy.
To help evaluate emerging technologies and enrich our understanding of
integrated-circuit scaling, we review fundamental limits to computation: in
manufacturing, energy, physical space, design and verification effort, and
algorithms. To outline what is achievable in principle and in practice, we
recall how some limits were circumvented, compare loose and tight limits. We
also point out that engineering difficulties encountered by emerging
technologies may indicate yet-unknown limits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3829</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3829</id><created>2014-08-17</created><authors><author><keyname>Sharma</keyname><forenames>Richa</forenames></author><author><keyname>Nigam</keyname><forenames>Shweta</forenames></author><author><keyname>Jain</keyname><forenames>Rekha</forenames></author></authors><title>Opinion mining of movie reviews at document level</title><categories>cs.IR cs.CL</categories><comments>International Journal on Information Theory (IJIT), Vol.3, No.3, July
  2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The whole world is changed rapidly and using the current technologies
Internet becomes an essential need for everyone. Web is used in every field.
Most of the people use web for a common purpose like online shopping, chatting
etc. During an online shopping large number of reviews/opinions are given by
the users that reflect whether the product is good or bad. These reviews need
to be explored, analyse and organized for better decision making. Opinion
Mining is a natural language processing task that deals with finding
orientation of opinion in a piece of text with respect to a topic. In this
paper a document based opinion mining system is proposed that classify the
documents as positive, negative and neutral. Negation is also handled in the
proposed system. Experimental results using reviews of movies show the
effectiveness of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3838</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3838</id><created>2014-08-17</created><authors><author><keyname>Mishra</keyname><forenames>Minati</forenames></author><author><keyname>Routray</keyname><forenames>Ashanta Ranjan</forenames></author><author><keyname>Kumar</keyname><forenames>Sunit</forenames></author></authors><title>High Security Image Steganography with Modified Arnold cat map</title><categories>cs.CR cs.MM</categories><comments>5 pages, International Journal of Computer Applications,Volume 37,
  No.9, January 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information security is concerned with maintaining the secrecy, reliability
and accessibility of data. The main objective of information security is to
protect information and information system from unauthorized access,
revelation, disruption, alteration, annihilation and use. This paper uses
spatial domain LSB substitution method for information embedding and modified
forms of Arnold transform are applied twice in two different phases to ensure
security. The system is tested and validated against a series of standard
images and the results show that the method is highly secure and provides high
data hiding capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3843</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3843</id><created>2014-08-17</created><authors><author><keyname>Ghosh</keyname><forenames>Esha</forenames></author><author><keyname>Ohrimenko</keyname><forenames>Olga</forenames></author><author><keyname>Tamassia</keyname><forenames>Roberto</forenames></author></authors><title>Verifiable Member and Order Queries on a List in Zero-Knowledge</title><categories>cs.CR</categories><comments>arXiv admin note: substantial text overlap with arXiv:1405.0962</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a formal model for order queries on lists in zero knowledge in
the traditional authenticated data structure model. We call this model
Privacy-Preserving Authenticated List (PPAL). In this model, the queries are
performed on the list stored in the (untrusted) cloud where data integrity and
privacy have to be maintained. To realize an efficient authenticated data
structure, we first adapt consistent data query model. To this end we introduce
a formal model called Zero-Knowledge List (ZKL) scheme which generalizes
consistent membership queries in zero-knowledge to consistent membership and
order queries on a totally ordered set in zero knowledge. We present a
construction of ZKL based on zero-knowledge set and homomorphic integer
commitment scheme. Then we discuss why this construction is not as efficient as
desired in cloud applications and present an efficient construction of PPAL
based on bilinear accumulators and bilinear maps which is provably secure and
zero-knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3850</identifier>
 <datestamp>2015-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3850</id><created>2014-08-17</created><updated>2015-03-13</updated><authors><author><keyname>Duong</keyname><forenames>Manh Hong</forenames></author><author><keyname>Han</keyname><forenames>The Anh</forenames></author></authors><title>On the expected number of equilibria in a multi-player multi-strategy
  evolutionary game</title><categories>math.PR cs.GT math.DS q-bio.PE q-bio.QM</categories><comments>26 pages, 1 figure, 1 table. revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the mean number $E(n,d)$ of internal equilibria in
a general $d$-player $n$-strategy evolutionary game where the agents' payoffs
are normally distributed. First, we give a computationally implementable
formula for the general case. Next we characterize the asymptotic behavior of
$E(2,d)$, estimating its lower and upper bounds as $d$ increases. Two important
consequences are obtained from this analysis. On the one hand, we show that in
both cases the probability of seeing the maximal possible number of equilibria
tends to zero when $d$ or $n$ respectively goes to infinity. On the other hand,
we demonstrate that the expected number of stable equilibria is bounded within
a certain interval. Finally, for larger $n$ and $d$, numerical results are
provided and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3863</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3863</id><created>2014-08-17</created><updated>2014-08-20</updated><authors><author><keyname>Lange</keyname><forenames>Christoph</forenames></author><author><keyname>Di Iorio</keyname><forenames>Angelo</forenames></author></authors><title>Semantic Publishing Challenge -- Assessing the Quality of Scientific
  Output</title><categories>cs.DL cs.IR</categories><comments>To appear in: Valentina Presutti and Milan Stankovic and Erik Cambria
  and Reforgiato Recupero, Diego and Di Iorio, Angelo and Christoph Lange and
  Di Noia, Tommaso and Ivan Cantador (eds.). Semantic Web Evaluation Challenges
  2014. Number 457 in Communications in Computer and Information Science,
  Springer, 2014</comments><acm-class>H.3.7; I.7.4; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linked Open Datasets about scholarly publications enable the development and
integration of sophisticated end-user services; however, richer datasets are
still needed. The first goal of this Challenge was to investigate novel
approaches to obtain such semantic data. In particular, we were seeking methods
and tools to extract information from scholarly publications, to publish it as
LOD, and to use queries over this LOD to assess quality. This year we focused
on the quality of workshop proceedings, and of journal articles w.r.t. their
citation network. A third, open task, asked to showcase how such semantic data
could be exploited and how Semantic Web technologies could help in this
emerging context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3869</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3869</id><created>2014-08-17</created><authors><author><keyname>Dvorak</keyname><forenames>Zdenek</forenames></author><author><keyname>Norin</keyname><forenames>Sergey</forenames></author></authors><title>Treewidth of graphs with balanced separations</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that if every subgraph of a graph $G$ has a balanced separation of
order at most $a$ then $G$ has treewidth at most $105a$. This establishes a
linear dependence between the treewidth and the separation number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3873</identifier>
 <datestamp>2015-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3873</id><created>2014-08-17</created><updated>2015-01-14</updated><authors><author><keyname>Livi</keyname><forenames>Lorenzo</forenames></author><author><keyname>Rizzi</keyname><forenames>Antonello</forenames></author><author><keyname>Sadeghian</keyname><forenames>Alireza</forenames></author></authors><title>Classifying sequences by the optimized dissimilarity space embedding
  approach: a case study on the solubility analysis of the E. coli proteome</title><categories>cs.CV cs.AI physics.bio-ph q-bio.BM</categories><comments>10 pages, 49 references</comments><acm-class>I.5</acm-class><doi>10.3233/IFS-151550</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We evaluate a version of the recently-proposed classification system named
Optimized Dissimilarity Space Embedding (ODSE) that operates in the input space
of sequences of generic objects. The ODSE system has been originally presented
as a classification system for patterns represented as labeled graphs. However,
since ODSE is founded on the dissimilarity space representation of the input
data, the classifier can be easily adapted to any input domain where it is
possible to define a meaningful dissimilarity measure. Here we demonstrate the
effectiveness of the ODSE classifier for sequences by considering an
application dealing with the recognition of the solubility degree of the
Escherichia coli proteome. Solubility, or analogously aggregation propensity,
is an important property of protein molecules, which is intimately related to
the mechanisms underlying the chemico-physical process of folding. Each protein
of our dataset is initially associated with a solubility degree and it is
represented as a sequence of symbols, denoting the 20 amino acid residues. The
herein obtained computational results, which we stress that have been achieved
with no context-dependent tuning of the ODSE system, confirm the validity and
generality of the ODSE-based approach for structured data classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3881</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3881</id><created>2014-08-17</created><authors><author><keyname>Arandjelovic</keyname><forenames>Ognjen</forenames></author></authors><title>Fairer citation-based metrics</title><categories>cs.DL cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I describe a simple modification which can be applied to any citation
count-based index (e.g. Hirsch's h-index) quantifying a researcher's
publication output. The key idea behind the proposed approach is that the merit
for the citations of a paper should be distributed amongst its authors
according to their relative contributions. In addition to producing inherently
fairer metrics I show that the proposed modification has the potential to
partially normalize for the unfair effects of honorary authorship and thus
discourage this practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3904</identifier>
 <datestamp>2014-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3904</id><created>2014-08-18</created><updated>2014-09-08</updated><authors><author><keyname>Ma</keyname><forenames>Junjie</forenames></author><author><keyname>Yuan</keyname><forenames>Xiaojun</forenames></author><author><keyname>Ping</keyname><forenames>Li</forenames></author></authors><title>Turbo Compressed Sensing with Partial DFT Sensing Matrix</title><categories>cs.IT math.IT</categories><comments>IEEE Signal Processing Letters, (Volume:22, Issue: 2), Feb. 2015</comments><doi>10.1109/LSP.2014.2351822</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we propose a turbo compressed sensing algorithm with partial
discrete Fourier transform (DFT) sensing matrices. Interestingly, the state
evolution of the proposed algorithm is shown to be consistent with that derived
using the replica method. Numerical results demonstrate that the proposed
algorithm outperforms the well-known approximate message passing (AMP)
algorithm when a partial DFT sensing matrix is involved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3929</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3929</id><created>2014-08-18</created><authors><author><keyname>Mykhailenko</keyname><forenames>Oleksii</forenames></author></authors><title>Cone Crusher Model Identification Using Block-Oriented Systems with
  Orthonormal Basis Functions</title><categories>cs.SY</categories><comments>8 pages, 5 figures, International Journal of Control Theory and
  Computer Modeling (IJCTCM), Vol.4, No.3, July 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, block-oriented systems with linear parts based on Laguerre
functions is used to approximation of a cone crusher dynamics. Adaptive
recursive least squares algorithm is used to identification of Laguerre model.
Various structures of Hammerstein, Wiener, Hammerstein-Wiener models are tested
and the MATLAB simulation results are compared. The mean square error is used
for models validation. It has been found that Hammerstein-Wiener with
orthonormal basis functions improves the quality of approximation plant
dynamics. The mean square error for this model is 11% on average throughout the
considered range of the external disturbances amplitude. The analysis also
showed that Wiener model cannot provide sufficient approximation accuracy of
the cone crusher dynamics. During the process it is unstable due to the high
sensitivity to disturbances on the output. The Hammerstein-Wiener model will be
used to the design nonlinear model predictive control application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3930</identifier>
 <datestamp>2015-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3930</id><created>2014-08-18</created><updated>2015-09-04</updated><authors><author><keyname>Kang</keyname><forenames>Jaewook</forenames></author><author><keyname>Jung</keyname><forenames>Hyoyoung</forenames></author><author><keyname>Lee</keyname><forenames>Heung-No</forenames></author><author><keyname>Kim</keyname><forenames>Kiseon</forenames></author></authors><title>Bernoulli-Gaussian Approximate Message-Passing Algorithm for Compressed
  Sensing with 1D-Finite-Difference Sparsity</title><categories>cs.IT math.IT</categories><comments>17 pages, 13 figures, submitted to the IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a fast approximate message-passing (AMP) algorithm for
solving compressed sensing (CS) recovery problems with 1D-finite-difference
sparsity in term of MMSE estimation. The proposed algorithm, named ssAMP-BGFD,
is low-computational with its fast convergence and cheap per-iteration cost,
providing phase transition nearly approaching to the state-of-the-art. The
proposed algorithm is originated from a sum-product message-passing rule,
applying a Bernoulli-Gaussian (BG) prior, seeking an MMSE solution. The
algorithm construction includes not only the conventional AMP technique for the
measurement fidelity, but also suggests a simplified message-passing method to
promote the signal sparsity in finite-difference. Furthermore, we provide an
EM-tuning methodology to learn the BG prior parameters, suggesting how to use
some practical measurement matrices satisfying the RIP requirement under the
ssAMP-BGFD recovery. Extensive empirical results confirms performance of the
proposed algorithm, in phase transition, convergence speed, and CPU runtime,
compared to the recent algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3931</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3931</id><created>2014-08-18</created><authors><author><keyname>Baur</keyname><forenames>Sebastian</forenames></author><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author></authors><title>Arithmetic Distribution Matching</title><categories>cs.IT math.IT</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, arithmetic distribution matching (ADM) is presented. ADM
invertibly transforms a discrete memoryless source (DMS) into a target DMS. ADM
can be used for probabilistic shaping and for rate adaption. Opposed to
existing algorithms for distribution matching, ADM works online and can
transform arbitrarily long input sequences. It is shown analytically that as
the input length tends to infinity, the ADM output perfectly emulates the
target DMS with respect to the normalized informational divergence and the
entropy rate. Numerical results are presented that confirm the analytical
bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3934</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3934</id><created>2014-08-18</created><authors><author><keyname>Mosquera</keyname><forenames>Alejandro</forenames></author><author><keyname>Aouad</keyname><forenames>Lamine</forenames></author><author><keyname>Grzonkowski</keyname><forenames>Slawomir</forenames></author><author><keyname>Morss</keyname><forenames>Dylan</forenames></author></authors><title>On Detecting Messaging Abuse in Short Text Messages using Linguistic and
  Behavioral patterns</title><categories>cs.CL cs.AI cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of short text messages in social media and instant messaging has
become a popular communication channel during the last years. This rising
popularity has caused an increment in messaging threats such as spam, phishing
or malware as well as other threats. The processing of these short text message
threats could pose additional challenges such as the presence of lexical
variants, SMS-like contractions or advanced obfuscations which can degrade the
performance of traditional filtering solutions. By using a real-world SMS data
set from a large telecommunications operator from the US and a social media
corpus, in this paper we analyze the effectiveness of machine learning filters
based on linguistic and behavioral patterns in order to detect short text spam
and abusive users in the network. We have also explored different ways to deal
with short text message challenges such as tokenization and entity detection by
using text normalization and substring clustering techniques. The obtained
results show the validity of the proposed solution by enhancing baseline
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3942</identifier>
 <datestamp>2015-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3942</id><created>2014-08-18</created><updated>2015-06-23</updated><authors><author><keyname>Chen</keyname><forenames>Zheng</forenames></author><author><keyname>Qiu</keyname><forenames>Ling</forenames></author></authors><title>Analysis and Optimization of Cellular Network with Burst Traffic</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author due to missuse of queue
  model in Section Four</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the performance of cellular networks and study the
optimal base station (BS) density to reduce the network power consumption. In
contrast to previous works with similar purpose, we consider Poisson traffic
for users' traffic model. In such situation, each BS can be viewed as M/G/1
queuing model. Based on theory of stochastic geometry, we analyze users'
signal-to-interference-plus-noise-ratio (SINR) and obtain the average
transmission time of each packet. While most of the previous works on SINR
analysis in academia considered full buffer traffic, our analysis provides a
basic framework to estimate the performance of cellular networks with burst
traffic. We find that the users' SINR depends on the average transmission
probability of BSs, which is defined by a nonlinear equation. As it is
difficult to obtain the closed-form solution, we solve this nonlinear equation
by bisection method. Besides, we formulate the optimization problem to minimize
the area power consumption. An iteration algorithm is proposed to derive the
local optimal BS density, and the numerical result shows that the proposed
algorithm can converge to the global optimal BS density. At the end, the impact
of BS density on users' SINR and average packet delay will be discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3944</identifier>
 <datestamp>2014-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3944</id><created>2014-08-18</created><updated>2014-09-17</updated><authors><author><keyname>Marteau</keyname><forenames>Pierre-Fran&#xe7;ois</forenames><affiliation>IRISA</affiliation></author><author><keyname>Gibet</keyname><forenames>Sylvie</forenames><affiliation>IRISA</affiliation></author><author><keyname>Reverdy</keyname><forenames>Clement</forenames><affiliation>IRISA</affiliation></author></authors><title>Down-Sampling coupled to Elastic Kernel Machines for Efficient
  Recognition of Isolated Gestures</title><categories>cs.LG cs.HC</categories><comments>ICPR 2014, International Conference on Pattern Recognition, Stockholm
  : Sweden (2014)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the field of gestural action recognition, many studies have focused on
dimensionality reduction along the spatial axis, to reduce both the variability
of gestural sequences expressed in the reduced space, and the computational
complexity of their processing. It is noticeable that very few of these methods
have explicitly addressed the dimensionality reduction along the time axis.
This is however a major issue with regard to the use of elastic distances
characterized by a quadratic complexity. To partially fill this apparent gap,
we present in this paper an approach based on temporal down-sampling associated
to elastic kernel machine learning. We experimentally show, on two data sets
that are widely referenced in the domain of human gesture recognition, and very
different in terms of quality of motion capture, that it is possible to
significantly reduce the number of skeleton frames while maintaining a good
recognition rate. The method proves to give satisfactory results at a level
currently reached by state-of-the-art methods on these data sets. The
computational complexity reduction makes this approach eligible for real-time
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3955</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3955</id><created>2014-08-18</created><authors><author><keyname>Soeken</keyname><forenames>Mathias</forenames></author><author><keyname>Tague</keyname><forenames>Laura</forenames></author><author><keyname>Dueck</keyname><forenames>Gerhard W.</forenames></author><author><keyname>Drechsler</keyname><forenames>Rolf</forenames></author></authors><title>Ancilla-free synthesis of large reversible functions using binary
  decision diagrams</title><categories>cs.ET quant-ph</categories><comments>25 pages, 15 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The synthesis of reversible functions has been an intensively studied
research area in the last decade. Since almost all proposed approaches rely on
representations of exponential size (such as truth tables and permutations),
they cannot be applied efficiently to reversible functions with more than 15
variables.
  In this paper, we propose an ancilla-free synthesis approach based on Young
subgroups using symbolic function representations that can efficiently be
implemented with binary decision diagrams (BDDs). As a result, the algorithm
not only allows to synthesize large reversible functions without adding extra
lines, called ancilla, but also leads to significantly smaller circuits
compared to existing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3967</identifier>
 <datestamp>2015-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3967</id><created>2014-08-18</created><updated>2015-08-11</updated><authors><author><keyname>Zhang</keyname><forenames>Zhanpeng</forenames></author><author><keyname>Luo</keyname><forenames>Ping</forenames></author><author><keyname>Loy</keyname><forenames>Chen Change</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoou</forenames></author></authors><title>Learning Deep Representation for Face Alignment with Auxiliary
  Attributes</title><categories>cs.CV cs.LG</categories><comments>to be published in the IEEE Transactions on Pattern Analysis and
  Machine Intelligence (TPAMI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we show that landmark detection or face alignment task is not
a single and independent problem. Instead, its robustness can be greatly
improved with auxiliary information. Specifically, we jointly optimize landmark
detection together with the recognition of heterogeneous but subtly correlated
facial attributes, such as gender, expression, and appearance attributes. This
is non-trivial since different attribute inference tasks have different
learning difficulties and convergence rates. To address this problem, we
formulate a novel tasks-constrained deep model, which not only learns the
inter-task correlation but also employs dynamic task coefficients to facilitate
the optimization convergence when learning multiple complex tasks. Extensive
evaluations show that the proposed task-constrained learning (i) outperforms
existing face alignment methods, especially in dealing with faces with severe
occlusion and pose variation, and (ii) reduces model complexity drastically
compared to the state-of-the-art methods based on cascaded deep model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3976</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3976</id><created>2014-08-18</created><authors><author><keyname>Bartel</keyname><forenames>Alexandre</forenames><affiliation>SnT</affiliation></author><author><keyname>Klein</keyname><forenames>Jacques</forenames><affiliation>SnT</affiliation></author><author><keyname>Monperrus</keyname><forenames>Martin</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Traon</keyname><forenames>Yves Le</forenames><affiliation>SnT</affiliation></author></authors><title>Static Analysis for Extracting Permission Checks of a Large Scale
  Framework: The Challenges And Solutions for Analyzing Android</title><categories>cs.SE</categories><comments>IEEE Transactions on Software Engineering (2014). arXiv admin note:
  substantial text overlap with arXiv:1206.5829</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common security architecture is based on the protection of certain
resources by permission checks (used e.g., in Android and Blackberry). It has
some limitations, for instance, when applications are granted more permissions
than they actually need, which facilitates all kinds of malicious usage (e.g.,
through code injection). The analysis of permission-based framework requires a
precise mapping between API methods of the framework and the permissions they
require. In this paper, we show that naive static analysis fails miserably when
applied with off-the-shelf components on the Android framework. We then present
an advanced class-hierarchy and field-sensitive set of analyses to extract this
mapping. Those static analyses are capable of analyzing the Android framework.
They use novel domain specific optimizations dedicated to Android.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3977</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3977</id><created>2014-08-18</created><authors><author><keyname>C</keyname><forenames>Vandhana.</forenames></author><author><keyname>Bindhu</keyname><forenames>S. Hima</forenames></author><author><keyname>Renjith</keyname><forenames>P.</forenames></author><author><keyname>Sadagopan</keyname><forenames>N.</forenames></author><author><keyname>Supraja</keyname><forenames>B.</forenames></author></authors><title>Spanning Tree Enumeration in 2-trees: Sequential and Parallel
  Perspective</title><categories>cs.DM cs.DS</categories><comments>9 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a connected graph, a vertex separator is a set of vertices whose removal
creates at least two components. A vertex separator $S$ is minimal if it
contains no other separator as a strict subset and a minimum vertex separator
is a minimal vertex separator of least cardinality. A {\em clique} is a set of
mutually adjacent vertices. A 2-tree is a connected graph in which every
maximal clique is of size three and every minimal vertex separator is of size
two. A spanning tree of a graph $G$ is a connected and an acyclic subgraph of
$G$. In this paper, we focus our attention on two enumeration problems, both
from sequential and parallel perspective. In particular, we consider listing
all possible spanning trees of a 2-tree and listing all perfect elimination
orderings of a chordal graph. As far as enumeration of spanning trees is
concerned, our approach is incremental in nature and towards this end, we work
with the construction order of the 2-tree, i.e. enumeration of $n$-vertex trees
are from $n-1$ vertex trees, $n \geq 4$. Further, we also present a parallel
algorithm for spanning tree enumeration using $O(2^n)$ processors. To our
knowledge, this paper makes the first attempt in designing a parallel algorithm
for this problem. We conclude this paper by presenting a sequential and
parallel algorithm for enumerating all Perfect Elimination Orderings of a
chordal graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.3985</identifier>
 <datestamp>2014-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.3985</id><created>2014-08-18</created><authors><author><keyname>Eskander</keyname><forenames>George S.</forenames></author><author><keyname>Sabourin</keyname><forenames>Robert</forenames></author><author><keyname>Granger</keyname><forenames>Eric</forenames></author></authors><title>Offline Signature-Based Fuzzy Vault (OSFV: Review and New Results</title><categories>cs.CV cs.CR</categories><comments>This paper has been submitted to The 2014 IEEE Symposium on
  Computational Intelligence in Biometrics and Identity Management (CIBIM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An offline signature-based fuzzy vault (OSFV) is a bio-cryptographic
implementation that uses handwritten signature images as biometrics instead of
traditional passwords to secure private cryptographic keys. Having a reliable
OSFV implementation is the first step towards automating financial and legal
authentication processes, as it provides greater security of confidential
documents by means of the embedded handwritten signatures. The authors have
recently proposed the first OSFV implementation which is reviewed in this
paper. In this system, a machine learning approach based on the dissimilarity
representation concept is employed to select a reliable feature representation
adapted for the fuzzy vault scheme. Some variants of this system are proposed
for enhanced accuracy and security. In particular, a new method that adapts
user key size is presented. Performance of proposed methods are compared using
the Brazilian PUCPR and GPDS signature databases and results indicate that the
key-size adaptation method achieves a good compromise between security and
accuracy. While average system entropy is increased from 45-bits to about
51-bits, the AER (average error rate) is decreased by about 21%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4001</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4001</id><created>2014-08-18</created><authors><author><keyname>Simpson</keyname><forenames>Michael</forenames></author><author><keyname>Srinivasan</keyname><forenames>Venkatesh</forenames></author><author><keyname>Thomo</keyname><forenames>Alex</forenames></author></authors><title>Clearing Contamination in Large Networks</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we study the problem of clearing contamination spreading
through a large network where we model the problem as a graph searching game.
The problem can be summarized as constructing a search strategy that will leave
the graph clear of any contamination at the end of the searching process in as
few steps as possible. We show that this problem is NP-hard even on directed
acyclic graphs and provide an efficient approximation algorithm. We
experimentally observe the performance of our approximation algorithm in
relation to the lower bound on several large online networks including
Slashdot, Epinions and Twitter. The experiments reveal that in most cases our
algorithm performs near optimally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4002</identifier>
 <datestamp>2015-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4002</id><created>2014-08-18</created><updated>2015-07-14</updated><authors><author><keyname>Eltzner</keyname><forenames>Benjamin</forenames></author><author><keyname>Wollnik</keyname><forenames>Carina</forenames></author><author><keyname>Gottschlich</keyname><forenames>Carsten</forenames></author><author><keyname>Huckemann</keyname><forenames>Stephan</forenames></author><author><keyname>Rehfeldt</keyname><forenames>Florian</forenames></author></authors><title>The Filament Sensor for Near Real-Time Detection of Cytoskeletal Fiber
  Structures</title><categories>cs.CV</categories><comments>32 pages, 21 figures</comments><acm-class>I.4.3; I.4.6</acm-class><journal-ref>PLoS ONE 10(5): e0126346, May 2015</journal-ref><doi>10.1371/journal.pone.0126346</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A reliable extraction of filament data from microscopic images is of high
interest in the analysis of acto-myosin structures as early morphological
markers in mechanically guided differentiation of human mesenchymal stem cells
and the understanding of the underlying fiber arrangement processes. In this
paper, we propose the filament sensor (FS), a fast and robust processing
sequence which detects and records location, orientation, length and width for
each single filament of an image, and thus allows for the above described
analysis. The extraction of these features has previously not been possible
with existing methods. We evaluate the performance of the proposed FS in terms
of accuracy and speed in comparison to three existing methods with respect to
their limited output. Further, we provide a benchmark dataset of real cell
images along with filaments manually marked by a human expert as well as
simulated benchmark images. The FS clearly outperforms existing methods in
terms of computational runtime and filament extraction accuracy. The
implementation of the FS and the benchmark database are available as open
source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4005</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4005</id><created>2014-08-18</created><authors><author><keyname>Das</keyname><forenames>Kalyani</forenames></author></authors><title>Cactus Graphs and Some Algorithms</title><categories>cs.DM</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A cactus graph is a connected graph in which every block is either an edge or
a cycle. In this paper, we consider several problems of graph theory and
developed optimal algorithms to solve such problems on cactus graphs. The
running time of these algorithms is O(n), where n is the total number of
vertices of the graph. The cactus graph has many applications in real life
problems, especially in radio communication system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4036</identifier>
 <datestamp>2015-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4036</id><created>2014-08-18</created><updated>2015-04-07</updated><authors><author><keyname>de Verdi&#xe8;re</keyname><forenames>&#xc9;ric Colin</forenames></author><author><keyname>Hubard</keyname><forenames>Alfredo</forenames></author><author><keyname>de Mesmay</keyname><forenames>Arnaud</forenames></author></authors><title>Discrete Systolic Inequalities and Decompositions of Triangulated
  Surfaces</title><categories>math.CO cs.CG cs.DM math.MG</categories><comments>Major revision, incorporating many suggestions by the referees. To
  appear in Discrete and Computational Geometry</comments><msc-class>05C10, 68U05, 53C23, 57M15, 68R10</msc-class><acm-class>F.2.2; G.2.2; I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How much cutting is needed to simplify the topology of a surface? We provide
bounds for several instances of this question, for the minimum length of
topologically non-trivial closed curves, pants decompositions, and cut graphs
with a given combinatorial map in triangulated combinatorial surfaces (or their
dual cross-metric counterpart).
  Our work builds upon Riemannian systolic inequalities, which bound the
minimum length of non-trivial closed curves in terms of the genus and the area
of the surface. We first describe a systematic way to translate Riemannian
systolic inequalities to a discrete setting, and vice-versa. This implies a
conjecture by Przytycka and Przytycki from 1993, a number of new systolic
inequalities in the discrete setting, and the fact that a theorem of Hutchinson
on the edge-width of triangulated surfaces and Gromov's systolic inequality for
surfaces are essentially equivalent. We also discuss how these proofs
generalize to higher dimensions.
  Then we focus on topological decompositions of surfaces. Relying on ideas of
Buser, we prove the existence of pants decompositions of length
O(g^{3/2}n^{1/2}) for any triangulated combinatorial surface of genus g with n
triangles, and describe an O(gn)-time algorithm to compute such a
decomposition.
  Finally, we consider the problem of embedding a cut graph (or more generally
a cellular graph) with a given combinatorial map on a given surface. Using
random triangulations, we prove (essentially) that, for any choice of a
combinatorial map, there are some surfaces on which any cellular embedding with
that combinatorial map has length superlinear in the number of triangles of the
triangulated combinatorial surface. There is also a similar result for graphs
embedded on polyhedral triangulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4045</identifier>
 <datestamp>2015-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4045</id><created>2014-08-18</created><updated>2015-04-14</updated><authors><author><keyname>Awasthi</keyname><forenames>Pranjal</forenames></author><author><keyname>Bandeira</keyname><forenames>Afonso S.</forenames></author><author><keyname>Charikar</keyname><forenames>Moses</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Ravishankar</forenames></author><author><keyname>Villar</keyname><forenames>Soledad</forenames></author><author><keyname>Ward</keyname><forenames>Rachel</forenames></author></authors><title>Relax, no need to round: integrality of clustering formulations</title><categories>stat.ML cs.DS cs.LG math.ST stat.TH</categories><comments>30 pages, ITCS 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study exact recovery conditions for convex relaxations of point cloud
clustering problems, focusing on two of the most common optimization problems
for unsupervised clustering: $k$-means and $k$-median clustering. Motivations
for focusing on convex relaxations are: (a) they come with a certificate of
optimality, and (b) they are generic tools which are relatively parameter-free,
not tailored to specific assumptions over the input. More precisely, we
consider the distributional setting where there are $k$ clusters in
$\mathbb{R}^m$ and data from each cluster consists of $n$ points sampled from a
symmetric distribution within a ball of unit radius. We ask: what is the
minimal separation distance between cluster centers needed for convex
relaxations to exactly recover these $k$ clusters as the optimal integral
solution? For the $k$-median linear programming relaxation we show a tight
bound: exact recovery is obtained given arbitrarily small pairwise separation
$\epsilon &gt; 0$ between the balls. In other words, the pairwise center
separation is $\Delta &gt; 2+\epsilon$. Under the same distributional model, the
$k$-means LP relaxation fails to recover such clusters at separation as large
as $\Delta = 4$. Yet, if we enforce PSD constraints on the $k$-means LP, we get
exact cluster recovery at center separation $\Delta &gt; 2\sqrt2(1+\sqrt{1/m})$.
In contrast, common heuristics such as Lloyd's algorithm (a.k.a. the $k$-means
algorithm) can fail to recover clusters in this setting; even with arbitrarily
large cluster separation, k-means++ with overseeding by any constant factor
fails with high probability at exact cluster recovery. To complement the
theoretical analysis, we provide an experimental study of the recovery
guarantees for these various methods, and discuss several open problems which
these experiments suggest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4048</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4048</id><created>2014-08-18</created><updated>2015-11-15</updated><authors><author><keyname>Manurangsi</keyname><forenames>Pasin</forenames></author><author><keyname>Moshkovitz</keyname><forenames>Dana</forenames></author></authors><title>Improved Approximation Algorithms for Projection Games</title><categories>cs.DS</categories><comments>41 pages, 2 figure</comments><doi>10.1007/s00453-015-0088-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The projection games (aka Label-Cover) problem is of great importance to the
field of approximation algorithms, since most of the NP-hardness of
approximation results we know today are reductions from Label-Cover. In this
paper we design several approximation algorithms for projection games: 1. A
polynomial-time approximation algorithm that improves on the previous best
approximation by Charikar, Hajiaghayi and Karloff. 2. A sub-exponential time
algorithm with much tighter approximation for the case of smooth projection
games. 3. A polynomial-time approximation scheme (PTAS) for projection games on
planar graphs and a tight running time lower bound for such approximation
schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4049</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4049</id><created>2014-08-18</created><authors><author><keyname>Toscani</keyname><forenames>Giuseppe</forenames></author></authors><title>A strengthened entropy power inequality for log-concave densities</title><categories>cs.IT math.FA math.IT</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that Shannon's entropy--power inequality admits a strengthened
version in the case in which the densities are log-concave. In such a case, in
fact, one can extend the Blachman--Stam argument to obtain a sharp inequality
for the second derivative of Shannon's entropy functional with respect to the
heat semigroup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4067</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4067</id><created>2014-08-15</created><authors><author><keyname>A.</keyname><forenames>Krishna Murthy</forenames></author><author><keyname>Suresha</keyname></author><author><keyname>M</keyname><forenames>Anil Kumar K.</forenames></author></authors><title>Challenges and Issues in Adapting Web Contents on Small Screen Devices</title><categories>cs.HC</categories><journal-ref>International Journal of Information Processing Year 2014 Volume 8
  Issue 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In general, Web pages are intended for large screen devices using HTML
technology. Admittance of such Web pages on Small Screen Devices (SSDs) like
mobile phones, palmtops, tablets, PDA etc., is increasing with the support of
the current wireless technologies. However, SSDs have limited screen size,
memory capacity and bandwidth, which makes accessing the Website on SSDs
extremely difficult. There are many approaches have been proposed in literature
to regenerate HTML Web pages suitable for browsing on SSDs. These proposed
methods involve segment the Web page based on its semantic structure, followed
by noise removal based on block features and to utilize the hierarchy of the
content element to regenerate a page suitable for Small Screen Devices. But
World Wide Web consortium stated that, HTML does not provide a better
description of semantic structure of the web page contents. To overcome this
draw backs, Web developers started to develop Web pages using new technologies
like XML, Flash etc. It makes a way for new research methods. Therefore, we
require an approach to reconstruct these Web pages suitable for SSDs. However,
existing approaches in literature do not perform well for Web pages erected
using XML and Flash. In this paper, we have emphasized a few issues of the
existing approaches on XML, Flash Datasets and propose an approach that
performs better on data set comprising of Flash Web pages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4069</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4069</id><created>2014-08-18</created><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Abbott</keyname><forenames>Derek</forenames></author><author><keyname>Granqvist</keyname><forenames>Claes-Goran</forenames></author><author><keyname>Wen</keyname><forenames>He</forenames></author></authors><title>Facts, myths and fights about the KLJN classical physical key exchanger</title><categories>cs.ET cs.CR</categories><comments>in press</comments><journal-ref>Int. J. Mod. Phys. Conf. Ser. 33, 1460362 (2014)</journal-ref><doi>10.1142/S2010194514603627</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper deals with the Kirchhoff-law-Johnson-noise (KLJN) classical
statistical physical key exchange method and surveys criticism - often stemming
from a lack of understanding of its underlying premises or from other errors -
and our related responses against these, often unphysical, claims. Some of the
attacks are valid, however, an extended KLJN system remains protected against
all of them, implying that its unconditional security is not impacted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4072</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4072</id><created>2014-08-15</created><authors><author><keyname>Battle</keyname><forenames>Leilani</forenames></author><author><keyname>Benson</keyname><forenames>Edward</forenames></author><author><keyname>Parameswaran</keyname><forenames>Aditya</forenames></author><author><keyname>Wu</keyname><forenames>Eugene</forenames></author></authors><title>Indexing Cost Sensitive Prediction</title><categories>cs.LG cs.DB cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predictive models are often used for real-time decision making. However,
typical machine learning techniques ignore feature evaluation cost, and focus
solely on the accuracy of the machine learning models obtained utilizing all
the features available. We develop algorithms and indexes to support
cost-sensitive prediction, i.e., making decisions using machine learning models
taking feature evaluation cost into account. Given an item and a online
computation cost (i.e., time) budget, we present two approaches to return an
appropriately chosen machine learning model that will run within the specified
time on the given item. The first approach returns the optimal machine learning
model, i.e., one with the highest accuracy, that runs within the specified
time, but requires significant up-front precomputation time. The second
approach returns a possibly sub- optimal machine learning model, but requires
little up-front precomputation time. We study these two algorithms in detail
and characterize the scenarios (using real and synthetic data) in which each
performs well. Unlike prior work that focuses on a narrow domain or a specific
algorithm, our techniques are very general: they apply to any cost-sensitive
prediction scenario on any machine learning algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4073</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4073</id><created>2014-08-18</created><authors><author><keyname>Kaspi</keyname><forenames>Yonatan</forenames></author><author><keyname>Shayevitz</keyname><forenames>Ofer</forenames></author><author><keyname>Javidi</keyname><forenames>Tara</forenames></author></authors><title>Searching with Measurement Dependent Noise</title><categories>cs.IT math.IT</categories><comments>Information Theory Workshop (ITW) 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a target moving with a constant velocity on a unit-circumference
circle, starting from an arbitrary location. To acquire the target, any region
of the circle can be probed for its presence, but the associated measurement
noise increases with the size of the probed region. We are interested in the
expected time required to find the target to within some given resolution and
error probability. For a known velocity, we characterize the optimal tradeoff
between time and resolution (i.e., maximal rate), and show that in contrast to
the case of constant measurement noise, measurement dependent noise incurs a
multiplicative gap between adaptive search and non-adaptive search. Moreover,
our adaptive scheme attains the optimal rate-reliability tradeoff. We further
show that for optimal non-adaptive search, accounting for an unknown velocity
incurs a factor of two in rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4076</identifier>
 <datestamp>2015-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4076</id><created>2014-08-18</created><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Granqvist</keyname><forenames>Claes-Goran</forenames></author><author><keyname>Horvath</keyname><forenames>Tamas</forenames></author><author><keyname>Klappenecker</keyname><forenames>Andreas</forenames></author><author><keyname>Wen</keyname><forenames>He</forenames></author><author><keyname>Bezrukov</keyname><forenames>Sergey M.</forenames></author></authors><title>Bird's-eye view on Noise-Based Logic</title><categories>cs.ET</categories><comments>paper in press</comments><journal-ref>Int. J. Mod. Phys. Conf. Ser. 33, 1460363 (2014)</journal-ref><doi>10.1142/S2010194514603639</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Noise-based logic is a practically deterministic logic scheme inspired by the
randomness of neural spikes and uses a system of uncorrelated stochastic
processes and their superposition to represent the logic state. We briefly
discuss various questions such as (i) What does practical determinism mean?
(ii) Is noise-based logic a Turing machine? (iii) Is there hope to beat (the
dreams of) quantum computation by a classical physical noise-based processor,
and what are the minimum hardware requirements for that? Finally, (iv) we
address the problem of random number generators and show that the common belief
that quantum number generators are superior to classical (thermal) noise-based
generators is nothing but a myth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4077</identifier>
 <datestamp>2015-03-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4077</id><created>2014-08-18</created><authors><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author><author><keyname>Granqvist</keyname><forenames>Claes-Goran</forenames></author><author><keyname>Bezrukov</keyname><forenames>Sergey M.</forenames></author><author><keyname>Horvath</keyname><forenames>Tamas</forenames></author></authors><title>Brain: Biological noise-based logic</title><categories>cs.NE cs.ET</categories><comments>paper in press</comments><journal-ref>Advances in Cognitive Neurodynamics 2015, pp 319-322</journal-ref><doi>10.1007/978-94-017-9548-7_45</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Neural spikes in the brain form stochastic sequences, i.e., belong to the
class of pulse noises. This stochasticity is a counterintuitive feature because
extracting information - such as the commonly supposed neural information of
mean spike frequency - requires long times for reasonably low error
probability. The mystery could be solved by noise-based logic, wherein
randomness has an important function and allows large speed enhancements for
special-purpose tasks, and the same mechanism is at work for the brain logic
version of this concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4080</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4080</id><created>2014-08-18</created><authors><author><keyname>Kuusisto</keyname><forenames>Antti</forenames></author></authors><title>Team Semantics and Recursive Enumerability</title><categories>math.LO cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that dependence logic captures the complexity class NP, and
it has recently been shown that inclusion logic captures P on ordered models.
These results demonstrate that team semantics offers interesting new
possibilities for descriptive complexity theory. In order to properly
understand the connection between team semantics and descriptive complexity, we
introduce an extension D* of dependence logic that can define exactly all
recursively enumerable classes of finite models. Thus D* provides an approach
to computation alternative to Turing machines. The essential novel feature in
D* is an operator that can extend the domain of the considered model by a
finite number of fresh elements. Due to the close relationship between
generalized quantifiers and oracles, we also investigate generalized
quantifiers in team semantics. We show that monotone quantifiers of type (1)
can be canonically eliminated from quantifier extensions of first-order logic
by introducing corresponding generalized dependence atoms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4099</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4099</id><created>2014-08-18</created><authors><author><keyname>Barba</keyname><forenames>Luis</forenames></author><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author><author><keyname>De Carufel</keyname><forenames>Jean-Lou</forenames></author><author><keyname>Damian</keyname><forenames>Mirela</forenames></author><author><keyname>Fagerberg</keyname><forenames>Rolf</forenames></author><author><keyname>van Renssen</keyname><forenames>Andr&#xe9;</forenames></author><author><keyname>Taslakian</keyname><forenames>Perouz</forenames></author><author><keyname>Verdonschot</keyname><forenames>Sander</forenames></author></authors><title>Continuous Yao Graphs</title><categories>cs.CG</categories><comments>7 pages, 7 figures. Presented at CCCG 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a variation of the well-studied Yao graphs. Given
a set of points $S\subset \mathbb{R}^2$ and an angle $0 &lt; \theta \leq 2\pi$, we
define the continuous Yao graph $cY(\theta)$ with vertex set $S$ and angle
$\theta$ as follows. For each $p,q\in S$, we add an edge from $p$ to $q$ in
$cY(\theta)$ if there exists a cone with apex $p$ and aperture $\theta$ such
that $q$ is the closest point to $p$ inside this cone.
  We study the spanning ratio of $cY(\theta)$ for different values of $\theta$.
Using a new algebraic technique, we show that $cY(\theta)$ is a spanner when
$\theta \leq 2\pi /3$. We believe that this technique may be of independent
interest. We also show that $cY(\pi)$ is not a spanner, and that $cY(\theta)$
may be disconnected for $\theta &gt; \pi$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4100</identifier>
 <datestamp>2014-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4100</id><created>2014-08-18</created><authors><author><keyname>Ghasemi-Goojani</keyname><forenames>Shahab</forenames></author><author><keyname>Behroozi</keyname><forenames>Hamid</forenames></author></authors><title>On the Ice-Wine Problem: Recovering Linear Combination of Codewords over
  the Gaussian Multiple Access Channel</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Information Theory Workshop 2014(ITW 2014), Hobart,
  Australia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the Ice-Wine problem: Two transmitters send their
messages over the Gaussian Multiple-Access Channel (MAC) and a receiver aims to
recover a linear combination of codewords. The best known achievable
rate-region for this problem is due to [1],[2] as
$R_{i}\leq\frac{1}{2}\log\left(\frac{1}{2}+{\rm SNR}\right)$ $(i=1,2)$. In this
paper, we design a novel scheme using lattice codes and show that the rate
region of this problem can be improved. The main difference between our
proposed scheme with known schemes in [1],[2] is that instead of recovering the
sum of codewords at the decoder, a non-integer linear combination of codewords
is recovered. Comparing the achievable rate-region with the outer bound,
$R_{i}\leq\frac{1}{2}\log\left(1+{\rm SNR}\right)\,\,(i=1,2)$, we observe that
the achievable rate for each user is partially tight. Finally, by applying our
proposed scheme to the Gaussian Two Way Relay Channel (GTWRC), we show that the
best rate region for this problem can be improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4102</identifier>
 <datestamp>2015-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4102</id><created>2014-08-18</created><updated>2015-10-12</updated><authors><author><keyname>Choi</keyname><forenames>David S.</forenames></author></authors><title>Estimation of Monotone Treatment Effects in Network Experiments</title><categories>stat.ME cs.SI</categories><comments>new methods and data examples added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized experiments on social networks pose statistical challenges, due to
the possibility of interference between units. We propose new methods for
estimating attributable treatment effects in such settings. The methods do not
require partial interference, but instead require an identifying assumption
that is similar to requiring nonnegative treatment effects. Network or spatial
information can be used to customize the test statistic; in principle, this can
increase power without making assumptions on the data generating process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4111</identifier>
 <datestamp>2015-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4111</id><created>2014-08-15</created><updated>2015-12-16</updated><authors><author><keyname>Rakhshan</keyname><forenames>Ali</forenames></author><author><keyname>Ray</keyname><forenames>Evan</forenames></author><author><keyname>Pishro-Nik</keyname><forenames>Hossein</forenames></author></authors><title>A New Approach to Customization of Collision Warning Systems to
  Individual Drivers</title><categories>cs.OH stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the need for individualizing safety systems and proposes
an approach including the Real-Time estimation of the distribution of brake
response times for an individual driver. While maintaining high level of
safety, the collision warning system should send &quot;tailored&quot; responses to the
driver. This method could be the first step to show that safety applications
would potentially benefit from customizing to individual drivers'
characteristics using VANET. Our simulation results show that, as one of the
imminent and preliminary outcomes of the new improved system, the number of
false alarms will be reduced by more than 40%. We think this tactic can reach
to even beyond the safety applications for designing the future innovative
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4112</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4112</id><created>2014-08-17</created><authors><author><keyname>Baghouri</keyname><forenames>Mostafa</forenames></author><author><keyname>Chakkor</keyname><forenames>Saad</forenames></author><author><keyname>Hajraoui</keyname><forenames>Abderrahmane</forenames></author></authors><title>Ameliorate Threshold Distributed Energy Efficient Clustering Algorithm
  for Heterogeneous Wireless Sensor Networks</title><categories>cs.NI</categories><comments>5 pages,8 figures, (IJACSA) International Journal of Advanced
  Computer Science and Applications, Vol. 5, No. 5, 2014. arXiv admin note:
  text overlap with arXiv:1208.1982 by other authors</comments><doi>10.14569/IJACSA.2014.050413</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ameliorating the lifetime in heterogeneous wireless sensor network is an
important task because the sensor nodes are limited in the resource energy. The
best way to improve a WSN lifetime is the clustering based algorithms in which
each cluster is managed by a leader called Cluster Head. Each other node must
communicate with this CH to send the data sensing. The nearest base station
nodes must also send their data to their leaders, this causes a loss of energy.
In this paper, we propose a new approach to ameliorate a threshold distributed
energy efficient clustering protocol for heterogeneous wireless sensor networks
by excluding closest nodes to the base station in the clustering process. We
show by simulation in MATLAB that the proposed approach increases obviously the
number of the received packet messages and prolongs the lifetime of the network
compared to TDEEC protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4113</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4113</id><created>2014-08-17</created><updated>2016-01-06</updated><authors><author><keyname>Constantinou</keyname><forenames>Costas K.</forenames></author><author><keyname>Ellinas</keyname><forenames>Georgios</forenames></author><author><keyname>Panayiotou</keyname><forenames>Christos</forenames></author><author><keyname>Polycarpou</keyname><forenames>Marios</forenames></author></authors><title>Fast Shortest Path Routing in Transportation Networks with
  Time-Dependent Road Speeds</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current paper deals with the subject of shortest path routing in
transportation networks (in terms of travelling time), where the speed in
several of the network's roads is a function of the time interval. The main
contribution of the paper is a procedure that is faster compared to the
conventional approaches, that derives the road's traversal time according to
the time instant of departure, for the case where the road's speed has a
constant value inside each time interval (in general, different value for each
time interval). Furthermore, the case where the road's speed is a linear
function of time inside each time interval (in general, different linear
function for each time interval) is investigated. A procedure that derives the
road's traversal time according to the time instant of departure is proposed
for this case as well. The proposed procedures are combined with Dijkstra's
algorithm and the resulting algorithms, that are practically applicable and of
low complexity, provide optimal shortest path routing in the networks under
investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4143</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4143</id><created>2014-07-14</created><authors><author><keyname>Mohamed</keyname><forenames>Marghny H.</forenames></author><author><keyname>Abdelsamea</keyname><forenames>Mohammed M.</forenames></author></authors><title>Self Organization Map based Texture Feature Extraction for Efficient
  Medical Image Categorization</title><categories>cs.CV cs.NE</categories><comments>In Proceedings of the 4th ACM International Conference on Intelligent
  Computing and Information Systems, ICICIS 2009, Cairo, Egypt 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Texture is one of the most important properties of visual surface that helps
in discriminating one object from another or an object from background. The
self-organizing map (SOM) is an excellent tool in exploratory phase of data
mining. It projects its input space on prototypes of a low-dimensional regular
grid that can be effectively utilized to visualize and explore properties of
the data. This paper proposes an enhancement extraction method for accurate
extracting features for efficient image representation it based on SOM neural
network. In this approach, we apply three different partitioning approaches as
a region of interested (ROI) selection methods for extracting different
accurate textural features from medical image as a primary step of our
extraction method. Fisherfaces feature selection is used, for selecting
discriminated features form extracted textural features. Experimental result
showed the high accuracy of medical image categorization with our proposed
extraction method. Experiments held on Mammographic Image Analysis Society
(MIAS) dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4151</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4151</id><created>2014-08-18</created><authors><author><keyname>Shajaiah</keyname><forenames>Haya</forenames></author><author><keyname>Abdelhadi</keyname><forenames>Ahmed</forenames></author><author><keyname>Clancy</keyname><forenames>Charles</forenames></author></authors><title>A Price Selective Centralized Algorithm for Resource Allocation with
  Carrier Aggregation in LTE Cellular Networks</title><categories>cs.NI</categories><comments>Submitted to IEEE</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a resource allocation with carrier aggregation
optimization problem in long term evolution (LTE) cellular networks. In our
proposed model, users are running elastic or inelastic traffic. Each user
equipment (UE) is assigned an application utility function based on the type of
its application. Our objective is to allocate multiple carriers resources
optimally among users in their coverage area while giving the user the ability
to select one of the carriers to be its primary carrier and the others to be
its secondary carriers. The UE's decision is based on the carrier price per
unit bandwidth. We present a price selective centralized resource allocation
with carrier aggregation algorithm to allocate multiple carriers resources
optimally among users while providing a minimum price for the allocated
resources. In addition, we analyze the convergence of the algorithm with
different carriers rates. Finally, we present simulation results for the
performance of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4156</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4156</id><created>2014-08-18</created><authors><author><keyname>Kamali</keyname><forenames>Shahin</forenames></author><author><keyname>L&#xf3;pez-Ortiz</keyname><forenames>Alejandro</forenames></author></authors><title>Efficient Online Strategies for Renting Servers in the Cloud</title><categories>cs.DS</categories><comments>13 pages, 3 figures</comments><acm-class>F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Cloud systems, we often deal with jobs that arrive and depart in an online
manner. Upon its arrival, a job should be assigned to a server. Each job has a
size which defines the amount of resources that it needs. Servers have uniform
capacity and, at all times, the total size of jobs assigned to a server should
not exceed the capacity. This setting is closely related to the classic bin
packing problem. The difference is that, in bin packing, the objective is to
minimize the total number of used servers. In the Cloud, however, the charge
for each server is proportional to the length of the time interval it is rented
for, and the goal is to minimize the cost involved in renting all used servers.
Recently, certain bin packing strategies were considered for renting servers in
the Cloud [Li et al. SPAA'14]. There, it is proved that all Any-Fit bin packing
strategy has a competitive ratio of at least $\mu$, where $\mu$ is the max/min
interval length ratio of jobs. It is also shown that First Fit has a
competitive ratio of $2\mu + 13$ while Best Fit is not competitive at all. We
observe that the lower bound of $\mu$ extends to all online algorithms. We also
prove that, surprisingly, Next Fit algorithm has competitive ratio of at most
$2 \mu +1$. We also show that a variant of Next Fit achieves a competitive
ratio of $K \times max\{1,\mu/(K-1)\}+1$, where $K$ is a parameter of the
algorithm. In particular, if the value of $\mu$ is known, the algorithm has a
competitive ratio of $\mu+2$; this improves upon the existing upper bound of
$\mu+8$. Finally, we introduce a simple algorithm called Move To Front (MTF)
which has a competitive ratio of at most $6\mu + 7$ and also promising
average-case performance. We experimentally study the average-case performance
of different algorithms and observe that the typical behaviour of MTF is
distinctively better than other algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4178</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4178</id><created>2014-08-18</created><authors><author><keyname>Haddad</keyname><forenames>Majed</forenames></author><author><keyname>Wiecek</keyname><forenames>Piotr</forenames></author><author><keyname>Habachi</keyname><forenames>Oussama</forenames></author><author><keyname>Hayel</keyname><forenames>Yezekael</forenames></author></authors><title>Designing Energy Efficient Power Control for Multi-carrier Wireless
  Networks</title><categories>cs.IT math.IT</categories><comments>32 pages, 13 figures, Technical report. arXiv admin note: substantial
  text overlap with arXiv:1207.5853</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a hierarchical game approach to model the power control problem
where transmitters jointly choose their channel assignment and power control in
order to maximize their individual energy efficiency. We conduct a thorough
analysis of the existence, uniqueness and characterization of the Stackelberg
equilibrium. Interestingly, we formally show that a spectrum coordination
naturally occurs when users decide sequentially about their transmitting
carriers and powers, delivering a binary channel assignment. Analytical results
are provided for assessing and improving the performances in terms of energy
efficiency and spectrum utilization between the non-cooperative game (with
synchronous decision makers), the social welfare (in a centralized manner) and
the proposed Stackelberg game. Furthermore, we provide tight bounds on the
probability of no coordination and the spectral efficiency of such a model. We
show that the spectrum coordination capability induced by the proposed
hierarchical game model enables the wireless network to achieve the energy
efficiency improvement while still enjoying a high spectral efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4187</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4187</id><created>2014-08-18</created><authors><author><keyname>Zhang</keyname><forenames>Fan</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Closed-Form Delay-Optimal Power Control for Energy Harvesting Wireless
  System with Finite Energy Storage</title><categories>cs.IT math.IT</categories><comments>17 pages, 9 figures, 1 table. Accepted for publication in IEEE
  Transactions on Signal Processing</comments><doi>10.1109/TSP.2014.2355777</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider delay-optimal power control for an energy
harvesting wireless system with finite energy storage. The wireless system is
powered solely by a renewable energy source with bursty data arrivals, and is
characterized by a data queue and an energy queue. We consider a delay-optimal
power control problem and formulate an infinite horizon average cost Markov
Decision Process (MDP). To deal with the curse of dimensionality, we introduce
a virtual continuous time system and derive closed-form approximate priority
functions for the discrete time MDP at various operating regimes. Based on the
approximation, we obtain an online power control solution which is adaptive to
the channel state information as well as the data and energy queue state
information. The derived power control solution has a multi-level water-filling
structure, where the water level is determined jointly by the data and energy
queue lengths. We show through simulations that the proposed scheme has
significant performance gain compared with various baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4194</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4194</id><created>2014-08-18</created><authors><author><keyname>Burtch</keyname><forenames>Gordon</forenames></author><author><keyname>Ghose</keyname><forenames>Anindya</forenames></author><author><keyname>Wattal</keyname><forenames>Sunil</forenames></author></authors><title>The Hidden Cost of Accommodating Crowdfunder Privacy Preferences: A
  Randomized Field Experiment</title><categories>cs.SI cs.CY</categories><comments>Forthcoming, Management Science</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online crowdfunding has received a great deal of attention from entrepreneurs
and policymakers as a promising avenue to fostering entrepreneurship and
innovation. A notable aspect of this shift from an offline to an online setting
is that it brings increased visibility and traceability of transactions. Many
crowdfunding platforms therefore provide mechanisms that enable a campaign
contributor to conceal his or her identity or contribution amount from peers.
We study the impact of these information (privacy) control mechanisms on
crowdfunder behavior. Employing a randomized experiment at one of the largest
online crowdfunding platforms, we find evidence of both positive (e.g.,
comfort) and negative (e.g., privacy priming) causal effects. We find that
reducing access to information controls induces a net increase in fundraising,
yet this outcome results from two competing influences: treatment increases
willingness to engage with the platform (a 4.9% increase in the probability of
contribution) and simultaneously decreases the average contribution (a $5.81
decline). This decline derives from a publicity effect, wherein contributors
respond to a lack of privacy by tempering extreme contributions. We unravel the
causal mechanisms that drive the results and discuss the implications of our
findings for the design of online platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4215</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4215</id><created>2014-08-19</created><updated>2015-03-24</updated><authors><author><keyname>Nasir</keyname><forenames>Ali A.</forenames></author><author><keyname>Ngo</keyname><forenames>Duy T.</forenames></author><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>Kennedy</keyname><forenames>Rodney A.</forenames></author><author><keyname>Durrani</keyname><forenames>Salman</forenames></author></authors><title>Joint Resource Optimization for Multicell Networks with Wireless Energy
  Harvesting Relays</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper first considers a multicell network deployment where the base
station (BS) of each cell communicates with its cell-edge user with the
assistance of an amplify-and-forward (AF) relay node. Equipped with a power
splitter and a wireless energy harvester, the self-sustaining relay scavenges
radio frequency (RF) energy from the received signals to process and forward
the information. Our aim is to develop a resource allocation scheme that
jointly optimizes (i) BS transmit powers, (ii) received power splitting factors
for energy harvesting and information processing at the relays, and (iii) relay
transmit powers. In the face of strong intercell interference and limited radio
resources, we formulate three highly-nonconvex problems with the objectives of
sum-rate maximization, max-min throughput fairness and sum-power minimization.
To solve such challenging problems, we propose to apply the successive convex
approximation (SCA) approach and devise iterative algorithms based on geometric
programming and difference-of-convex-functions programming. The proposed
algorithms transform the nonconvex problems into a sequence of convex problems,
each of which is solved very efficiently by the interior-point method. We prove
that our algorithms converge to the locally optimal solutions that satisfy the
Karush-Kuhn-Tucker conditions of the original nonconvex problems. We then
extend our results to the case of decode-and-forward (DF) relaying with
variable timeslot durations. We show that our resource allocation solutions in
this case offer better throughput than that of the AF counterpart with equal
timeslot durations, albeit at a higher computational complexity. Numerical
results confirm that the proposed joint optimization solutions substantially
improve the network performance, compared with cases where the radio resource
parameters are individually optimized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4218</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4218</id><created>2014-08-19</created><authors><author><keyname>Lee</keyname><forenames>Yu-Hsien</forenames></author><author><keyname>Liu</keyname><forenames>Kuang-Hao</forenames></author></authors><title>Battery-Aware Relay Selection for Energy Harvesting Cooperative Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Globecom 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of energy harvesting (EH) nodes as cooperative relays is an emerging
solution for enabling green wireless systems. In this paper, we consider
multiple EH relay nodes harvesting energy from the radio frequency (RF) signal
received from the source and use that harvested energy to forward the source
information to the destination. Unlike conventional relays with fixed power
supplies, EH relays may not be permanently available to assist the source
transmission due to the limited energy conversion efficiency, the mismatch
between the charging and discharging profiles, and the finite energy storage
capacity. We propose the battery-aware relay selection (BARS) scheme, which
jointly considers the channel condition and the battery status for relay
selection. The outage probability of the proposed scheme is analyzed using a
Markov chain model. Simulations are performed to validate the analysis
accuracy. Through numerical results, we show that the proposed BARS scheme can
achieve full diversity order equal to the number of relays without the need of
fixed power cables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4222</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4222</id><created>2014-08-19</created><authors><author><keyname>Mota-Hernandez</keyname><forenames>Cinthya</forenames></author><author><keyname>Esquivel-Rodriguez</keyname><forenames>Luis</forenames></author><author><keyname>Alvarado-Corona</keyname><forenames>Rafael</forenames></author></authors><title>Can Artificial Neural Networks be Applied in Seismic Predicition?
  Preliminary Analysis Applying Radial Topology. Case: Mexico</title><categories>cs.NE physics.geo-ph</categories><comments>4 pages, Conference, in Spanish</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tectonic earthquakes of high magnitude can cause considerable losses in terms
of human lives, economic and infrastructure, among others. According to an
evaluation published by the U.S. Geological Survey, 30 is the number of
earthquakes which have greatly impacted Mexico from the end of the XIX century
to this one. Based upon data from the National Seismological Service, on the
period between January 1, 2006 and May 1, 2013 there have occurred 5,826
earthquakes which magnitude has been greater than 4.0 degrees on the Richter
magnitude scale (25.54% of the total of earthquakes registered on the national
territory), being the Pacific Plate and the Cocos Plate the most important
ones. This document describes the development of an Artificial Neural Network
(ANN) based on the radial topology which seeks to generate a prediction with an
error margin lower than 20% which can inform about the probability of a future
earthquake one of the main questions is: can artificial neural networks be
applied in seismic forecasting? It can be argued that research has the
potential to bring in the forecast seismic, more research is needed to
consolidate data and help mitigate the impact caused by such events linked with
society. Keywords--- Analysis, Mexico, Neural Artificial Networks, Seismicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4230</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4230</id><created>2014-08-19</created><updated>2014-08-20</updated><authors><author><keyname>Manne</keyname><forenames>Shiva</forenames></author><author><keyname>Pal</keyname><forenames>Manjish</forenames></author></authors><title>Fast Approximate Matrix Multiplication by Solving Linear Systems</title><categories>cs.DS</categories><acm-class>F.2; G.1.2</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we present novel deterministic algorithms for multiplying two
$n \times n$ matrices approximately. Given two matrices $A,B$ we return a
matrix $C'$ which is an \emph{approximation} to $C = AB$. We consider the
notion of approximate matrix multiplication in which the objective is to make
the Frobenius norm of the error matrix $C-C'$ arbitrarily small. Our main
contribution is to first reduce the matrix multiplication problem to solving a
set of linear equations and then use standard techniques to find an approximate
solution to that system in $\tilde{O}(n^2)$ time. To the best of our knowledge
this the first examination into designing quadratic time deterministic
algorithms for approximate matrix multiplication which guarantee arbitrarily
low \emph{absolute error} w.r.t. Frobenius norm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4238</identifier>
 <datestamp>2015-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4238</id><created>2014-08-19</created><updated>2015-06-20</updated><authors><author><keyname>Gao</keyname><forenames>Hui</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author><author><keyname>Ren</keyname><forenames>Yuan</forenames></author><author><keyname>Long</keyname><forenames>Wei</forenames></author><author><keyname>Lv</keyname><forenames>Tiejun</forenames></author></authors><title>Distributed User Scheduling for MIMO-Y Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, distributed user scheduling schemes are proposed for the
multi-user MIMO-Y channel, where three $N_{T}$-antenna users ($N_{T}=2N,\,3N$)
are selected from three clusters to exchange information via an $N_{R}$-antenna
amplify-and-forward (AF) relay ($N_{R}=3N$), and $N\geq1$ represents the number
of data stream(s) of each unicast transmission within the MIMO-Y channel. The
proposed schemes effectively harvest multi-user diversity (MuD) without the
need of global channel state information (CSI) or centralized computations. In
particular, a novel reference signal space (RSS) is proposed to enable the
distributed scheduling for both cluster-wise (CS) and group-wise (GS) patterns.
The minimum user-antenna (Min-UA) transmission with $N_{T}=2N$ is first
considered. Next, we consider an equal number of relay and user antenna (ER-UA)
transmission with ${N_{T}=3N}$, with the aim of reducing CSI overhead as
compared to Min-UA. For ER-UA transmission, the achievable MuD orders of the
proposed distributed scheduling schemes are analytically derived, which proves
the superiority and optimality of the proposed RSS-based distributed
scheduling. These results reveal some fundamental behaviors of MuD and the
performance-complexity tradeoff of user scheduling schemes in the MIMO-Y
channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4239</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4239</id><created>2014-08-19</created><authors><author><keyname>Kaltiokallio</keyname><forenames>Ossi</forenames></author><author><keyname>Yi&#x11f;itler</keyname><forenames>H&#xfc;seyin</forenames></author><author><keyname>J&#xe4;ntti</keyname><forenames>Riku</forenames></author></authors><title>Enhancing the Accuracy of Device-free Localization Using Spectral
  Properties of the RSS</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Received signal strength based device-free localization has attracted
considerable attention in the research society over the past years to locate
and track people who are not carrying any electronic device. Typically, the
person is localized using a spatial model that relates the time domain signal
strength measurements to the person's position. Alternatively, one could
exploit spectral properties of the received signal strength which reflects the
rate at which the wireless propagation medium is being altered, an opportunity
that has not been exploited in the related literature. In this paper, the power
spectral density of the signal strength measurements are related to the
person's position and velocity to augment the particle filter based tracking
algorithm with an additional measurement. The system performance is evaluated
using simulations and validated using experimental data. Compared to a system
relying solely on time domain measurements, the results suggest that the
robustness to parameter changes is increased while the tracking accuracy is
enhanced by 50% or more when 512 particles are used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4245</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4245</id><created>2014-08-19</created><authors><author><keyname>Ustalov</keyname><forenames>Dmitry</forenames></author></authors><title>Towards crowdsourcing and cooperation in linguistic resources</title><categories>cs.SI cs.CL</categories><comments>Initially submitted to RuSSIR 2014 (http://romip.ru/russir2014), 9
  pages, 2 figures</comments><acm-class>K.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linguistic resources can be populated with data through the use of such
approaches as crowdsourcing and gamification when motivated people are
involved. However, current crowdsourcing genre taxonomies lack the concept of
cooperation, which is the principal element of modern video games and may
potentially drive the annotators' interest. This survey on crowdsourcing
taxonomies and cooperation in linguistic resources provides recommendations on
using cooperation in existent genres of crowdsourcing and an evidence of the
efficiency of cooperation using a popular Russian linguistic resource created
through crowdsourcing as an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4263</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4263</id><created>2014-08-19</created><authors><author><keyname>Bova</keyname><forenames>Simone</forenames></author><author><keyname>Ganian</keyname><forenames>Robert</forenames></author><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Quantified Conjunctive Queries on Partially Ordered Sets</title><categories>cs.LO cs.DS</categories><comments>Accepted at IPEC 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computational problem of checking whether a quantified
conjunctive query (a first-order sentence built using only conjunction as
Boolean connective) is true in a finite poset (a reflexive, antisymmetric, and
transitive directed graph). We prove that the problem is already NP-hard on a
certain fixed poset, and investigate structural properties of posets yielding
fixed-parameter tractability when the problem is parameterized by the query.
Our main algorithmic result is that model checking quantified conjunctive
queries on posets of bounded width is fixed-parameter tractable (the width of a
poset is the maximum size of a subset of pairwise incomparable elements). We
complement our algorithmic result by complexity results with respect to classes
of finite posets in a hierarchy of natural poset invariants, establishing its
tightness in this sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4290</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4290</id><created>2014-08-19</created><authors><author><keyname>Kitaev</keyname><forenames>Sergey</forenames></author><author><keyname>Vajnovszki</keyname><forenames>Vincent</forenames></author></authors><title>Mahonian STAT on words</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2000, Babson and Steingr\'imsson introduced the notion of what is now
known as a permutation vincular pattern, and based on it they re-defined known
Mahonian statistics and introduced new ones, proving or conjecturing their
Mahonity. These conjectures were proved by Foata and Zeilberger in 2001, and by
Foata and Randrianarivony in 2006.
  In 2010, Burstein refined some of these results by giving a bijection between
permutations with a fixed value for the major index and those with the same
value for STAT, where STAT is one of the statistics defined and proved to be
Mahonian in the 2000 Babson and Steingr\'imsson's paper. Several other
statistics are preserved as well by Burstein's bijection.
  At the Formal Power Series and Algebraic Combinatorics Conference (FPSAC) in
2010, Burstein asked whether his bijection has other interesting properties. In
this paper, we not only show that Burstein's bijection preserves the Eulerian
statistic ides, but also use this fact, along with the bijection itself, to
prove Mahonity of the statistic STAT on words we introduce in this paper. The
words statistic STAT introduced by us here addresses a natural question on
existence of a Mahonian words analogue of STAT on permutations. While proving
Mahonity of our STAT on words, we prove a more general joint equidistribution
result involving two six-tuples of statistics on (dense) words, where
Burstein's bijection plays an important role.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4325</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4325</id><created>2014-08-19</created><authors><author><keyname>Zhang</keyname><forenames>Yangmuzi</forenames></author><author><keyname>Larlus</keyname><forenames>Diane</forenames></author><author><keyname>Perronnin</keyname><forenames>Florent</forenames></author></authors><title>What makes an Image Iconic? A Fine-Grained Case Study</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A natural approach to teaching a visual concept, e.g. a bird species, is to
show relevant images. However, not all relevant images represent a concept
equally well. In other words, they are not necessarily iconic. This observation
raises three questions. Is iconicity a subjective property? If not, can we
predict iconicity? And what exactly makes an image iconic? We provide answers
to these questions through an extensive experimental study on a challenging
fine-grained dataset of birds. We first show that iconicity ratings are
consistent across individuals, even when they are not domain experts, thus
demonstrating that iconicity is not purely subjective. We then consider an
exhaustive list of properties that are intuitively related to iconicity and
measure their correlation with these iconicity ratings. We combine them to
predict iconicity of new unseen images. We also propose a direct iconicity
predictor that is discriminatively trained with iconicity ratings. By combining
both systems, we get an iconicity prediction that approaches human performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4355</identifier>
 <datestamp>2015-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4355</id><created>2014-08-19</created><updated>2015-11-08</updated><authors><author><keyname>Guo</keyname><forenames>Jin-Li</forenames></author><author><keyname>Zhu</keyname><forenames>Xin-Yun</forenames></author></authors><title>Weighted Hypernetworks</title><categories>physics.soc-ph cs.SI</categories><comments>13 pages, 3 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Complex network theory has been used to study complex systems. However, many
real-life systems involve multiple kinds of objects . They can't be described
by simple graphs. In order to provide complete information of these systems, we
extend the concept of evolving models of complex networks to hypernetworks. In
this work, we firstly propose a non-uniform hypernetwork model with
attractiveness, and obtain the stationary average hyperdegree distribution of
the non-uniform hypernetwork. Furthermore, we develop a model for weighted
hypernetworks that couples the establishment of new hyperedges and nodes and
the weights' dynamical evolution. We obtain the stationary average hyperdegree
and hyperstrength distribution by using the hyperdegree distribution of the
hypernetwork model with attractiveness, respectively. In particular, the model
yields a nontrivial time evolution of nodes' properties and scale-free behavior
for the hyperdegree and hyperstrength distribution. It is expected that our
work may give help to the study of the hypernetworks in real-world systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4361</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4361</id><created>2014-08-19</created><authors><author><keyname>Zhang</keyname><forenames>Xinlin</forenames></author><author><keyname>Matthaiou</keyname><forenames>Michail</forenames></author><author><keyname>Coldrey</keyname><forenames>Mikael</forenames></author><author><keyname>Emil</keyname></author><author><keyname>Bj&#xf6;rnson</keyname></author></authors><title>Energy Efficiency Optimization in Hardware-Constrained Large-Scale MIMO
  Systems</title><categories>cs.IT math.IT</categories><comments>Accepted for publication at The Eleventh International Symposium on
  Wireless Communication Systems (ISWCS 2014), 5 pages, 3 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale multiple-input multiple-output (MIMO) communication systems can
bring substantial improvement in spectral efficiency and/or energy efficiency,
due to the excessive degrees-of-freedom and huge array gain. However,
large-scale MIMO is expected to deploy lower-cost radio frequency (RF)
components, which are particularly prone to hardware impairments.
Unfortunately, compensation schemes are not able to remove the impact of
hardware impairments completely, such that a certain amount of residual
impairments always exists. In this paper, we investigate the impact of residual
transmit RF impairments (RTRI) on the spectral and energy efficiency of
training-based point-to-point large-scale MIMO systems, and seek to determine
the optimal training length and number of antennas which maximize the energy
efficiency. We derive deterministic equivalents of the
signal-to-noise-and-interference ratio (SINR) with zero-forcing (ZF) receivers,
as well as the corresponding spectral and energy efficiency, which are shown to
be accurate even for small number of antennas. Through an iterative sequential
optimization, we find that the optimal training length of systems with RTRI can
be smaller compared to ideal hardware systems in the moderate SNR regime, while
larger in the high SNR regime. Moreover, it is observed that RTRI can
significantly decrease the optimal number of transmit and receive antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4362</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4362</id><created>2014-08-19</created><updated>2014-08-20</updated><authors><author><keyname>Gandica</keyname><forenames>Y.</forenames></author><author><keyname>Aidos</keyname><forenames>F. Sampaio dos</forenames></author><author><keyname>Carvalho</keyname><forenames>J.</forenames></author></authors><title>The dynamic nature of conflict in Wikipedia</title><categories>physics.soc-ph cs.SI</categories><comments>12 pages, 7 figures</comments><doi>10.1209/0295-5075/108/18003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The voluntary process of Wikipedia edition provides an environment where the
outcome is clearly a collective product of interactions involving a large
number of people. We propose a simple agent-based model, developed from real
data, to reproduce the collaborative process of Wikipedia edition. With a small
number of simple ingredients, our model mimics several interesting features of
real human behaviour, namely in the context of edit wars. We show that the
level of conflict is determined by a tolerance parameter, which measures the
editors' capability to accept different opinions and to change their own
opinion. We propose to measure conflict with a parameter based on mutual
reverts, which increases only in contentious situations. Using this parameter,
we find a distribution for the inter-peace periods that is heavy-tailed. The
effects of wiki-robots in the conflict levels and in the edition patterns are
also studied. Our findings are compared with previous parameters used to
measure conflicts in edit wars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4363</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4363</id><created>2014-08-19</created><authors><author><keyname>Mohedano</keyname><forenames>Eva</forenames><affiliation>Dublin City University</affiliation></author><author><keyname>Healy</keyname><forenames>Graham</forenames><affiliation>Dublin City University</affiliation></author><author><keyname>McGuinness</keyname><forenames>Kevin</forenames><affiliation>Dublin City University</affiliation></author><author><keyname>Giro-i-Nieto</keyname><forenames>Xavier</forenames><affiliation>Universitat Politecnica de Catalunya</affiliation></author><author><keyname>O'Connor</keyname><forenames>Noel E.</forenames><affiliation>Dublin City University</affiliation></author><author><keyname>Smeaton</keyname><forenames>Alan F.</forenames><affiliation>Dublin City University</affiliation></author></authors><title>Object Segmentation in Images using EEG Signals</title><categories>cs.CV cs.MM</categories><comments>This is a preprint version prior to submission for peer-review of the
  paper accepted to the 22nd ACM International Conference on Multimedia
  (November 3-7, 2014, Orlando, Florida, USA) for the High Risk High Reward
  session. 10 pages</comments><acm-class>H.1.2; I.4.6; C.3</acm-class><doi>10.1145/2647868.2654896</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the potential of brain-computer interfaces in segmenting
objects from images. Our approach is centered around designing an effective
method for displaying the image parts to the users such that they generate
measurable brain reactions. When an image region, specifically a block of
pixels, is displayed we estimate the probability of the block containing the
object of interest using a score based on EEG activity. After several such
blocks are displayed, the resulting probability map is binarized and combined
with the GrabCut algorithm to segment the image into object and background
regions. This study shows that BCI and simple EEG analysis are useful in
locating object boundaries in images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4364</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4364</id><created>2014-08-19</created><authors><author><keyname>Hunt</keyname><forenames>Fern Y.</forenames></author></authors><title>The Structure of Optimal and Near Optimal Target Sets in Consensus
  Models</title><categories>cs.DM</categories><comments>arXiv admin note: substantial text overlap with arXiv:1401.6963</comments><msc-class>05C69, 05C81, 05C90, 68M10, 90C27</msc-class><acm-class>G.2; G.3</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  We consider the problem of identifying a subset of nodes in a network that
will enable the fastest spread of information in a decentralized environment.In
a model of communication based on a random walk on an undirected graph, the
optimal set over all sets of the same or smaller cardinality minimizes the sum
of the mean first arrival times to the set by walkers starting at nodes outside
the set. The problem originates from the study of the spread of information or
consensus in a network and was introduced in this form by V.Borkar et al. in
2010. More generally, the work of A. Clark et al. in 2012 showed that
estimating the fastest rate of convergence to consensus of so-called leader
follower systems leads to a consideration of the same optimization problem.
  The set function $F$ to be minimized is supermodular and therefore the greedy
algorithm is commonly used to construct optimal sets or their approximations.
In this paper, the problem is reformulated so that the search for solutions is
restricted to optimal and near optimal subsets of the graph. We prove
sufficient conditions for the existence of a greedoid structure that contains
feasible optimal and near optimal sets. It is therefore possible we conjecture,
to search for optimal or near optimal sets by local moves in a stepwise manner
to obtain near optimal sets that are better approximations than the factor
$(1-1/e)$ degree of optimality guaranteed by the use of the greedy algorithm. A
simple example illustrates aspects of the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4389</identifier>
 <datestamp>2014-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4389</id><created>2014-08-19</created><updated>2014-11-13</updated><authors><author><keyname>Mei</keyname><forenames>Jincheng</forenames></author><author><keyname>Zhao</keyname><forenames>Kang</forenames></author><author><keyname>Lu</keyname><forenames>Bao-Liang</forenames></author></authors><title>On Unconstrained Quasi-Submodular Function Optimization</title><categories>cs.DS cs.NA math.OC</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the extensive application of submodularity, its generalizations are
constantly being proposed. However, most of them are tailored for special
problems. In this paper, we focus on quasi-submodularity, a universal
generalization, which satisfies weaker properties than submodularity but still
enjoys favorable performance in optimization. Similar to the diminishing return
property of submodularity, we first define a corresponding property called the
{\em single sub-crossing}, then we propose two algorithms for unconstrained
quasi-submodular function minimization and maximization, respectively. The
proposed algorithms return the reduced lattices in $\mathcal{O}(n)$ iterations,
and guarantee the objective function values are strictly monotonically
increased or decreased after each iteration. Moreover, any local and global
optima are definitely contained in the reduced lattices. Experimental results
verify the effectiveness and efficiency of the proposed algorithms on lattice
reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4409</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4409</id><created>2014-08-19</created><authors><author><keyname>Cahill</keyname><forenames>Jameson</forenames></author><author><keyname>Mixon</keyname><forenames>Dustin G.</forenames></author></authors><title>Robust width: A characterization of uniformly stable and robust
  compressed sensing</title><categories>cs.IT math.FA math.IT</categories><comments>24 pages</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Compressed sensing seeks to invert an underdetermined linear system by
exploiting additional knowledge of the true solution. Over the last decade,
several instances of compressed sensing have been studied for various
applications, and for each instance, reconstruction guarantees are available
provided the sensing operator satisfies certain sufficient conditions. In this
paper, we completely characterize the sensing operators which allow uniformly
stable and robust reconstruction by convex optimization for many of these
instances. The characterized sensing operators satisfy a new property we call
the robust width property, which simultaneously captures notions of widths from
approximation theory and of restricted eigenvalues from statistical regression.
We provide a geometric interpretation of this property, we discuss its
relationship with the restricted isometry property, and we apply techniques
from geometric functional analysis to find random matrices which satisfy the
property with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4423</identifier>
 <datestamp>2015-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4423</id><created>2014-08-18</created><updated>2015-02-27</updated><authors><author><keyname>Hannig</keyname><forenames>Frank</forenames></author><author><keyname>Koch</keyname><forenames>Dirk</forenames></author><author><keyname>Ziener</keyname><forenames>Daniel</forenames></author></authors><title>Proceedings of the First International Workshop on FPGAs for Software
  Programmers (FSP 2014)</title><categories>cs.AR cs.DC cs.PL</categories><comments>Website of the workshop: https://www12.cs.fau.de/ws/fsp2014/</comments><proxy>Frank Hannig</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the papers accepted at the First International Workshop
on FPGAs for Software Programmers (FSP 2014), held in Munich, Germany,
September 1st, 2014. FSP 2014 was co-located with the International Conference
on Field Programmable Logic and Applications (FPL).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4424</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4424</id><created>2014-08-19</created><authors><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author><author><keyname>Fu</keyname><forenames>Hu</forenames></author><author><keyname>Karlin</keyname><forenames>Anna</forenames></author></authors><title>Approximate Revenue Maximization in Interdependent Value Settings</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study revenue maximization in settings where agents' values are
interdependent: each agent receives a signal drawn from a correlated
distribution and agents' values are functions of all of the signals. We
introduce a variant of the generalized VCG auction with reserve prices and
random admission, and show that this auction gives a constant approximation to
the optimal expected revenue in matroid environments. Our results do not
require any assumptions on the signal distributions, however, they require the
value functions to satisfy a standard single-crossing property and a
concavity-type condition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4433</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4433</id><created>2014-08-19</created><authors><author><keyname>Krueger</keyname><forenames>Tyll</forenames></author><author><keyname>Montufar</keyname><forenames>Guido</forenames></author><author><keyname>Seiler</keyname><forenames>Ruedi</forenames></author><author><keyname>Siegmund-Schultze</keyname><forenames>Rainer</forenames></author></authors><title>Sequential Recurrence-Based Multidimensional Universal Source Coding of
  Lempel-Ziv Type</title><categories>cs.IT math.IT</categories><comments>9 pages, 4 figures, 3 algorithms</comments><msc-class>68P30</msc-class><acm-class>E.4; I.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define an algorithm that parses multidimensional arrays sequentially into
mainly unrepeated but nested multidimensional sub-arrays of increasing size,
and show that the resulting sub-block pointer encoder compresses almost every
realization of any finite-alphabet ergodic process on $\mathbb{Z}_{\geq0}^d$ to
the entropy, in the limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4435</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4435</id><created>2014-08-19</created><authors><author><keyname>Panahi</keyname><forenames>Ashkan</forenames></author><author><keyname>Str&#xf6;m</keyname><forenames>Marie</forenames></author><author><keyname>Viberg</keyname><forenames>Mats</forenames></author></authors><title>Wideband Waveform Design for Robust Target Detection</title><categories>stat.AP cs.IT math.IT</categories><comments>This paper is submitted for peer review to IEEE letters on signal
  processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future radar systems are expected to use waveforms of a high bandwidth, where
the main advantage is an improved range resolution. In this paper, a technique
to design robust wideband waveforms for a Multiple-Input-Single-Output system
is developed. The context is optimal detection of a single object with
partially unknown parameters. The waveforms are robust in the sense that, for a
single transmission, detection capability is maintained over an interval of
time-delay and time-scaling (Doppler) parameters. A solution framework is
derived, approximated, and formulated as an optimization by means of basis
expansion. In terms of probabilities of detection and false alarm, numerical
evaluation shows the efficiency of the proposed method when compared with a
Linear Frequency Modulated signal and a Gaussian pulse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4437</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4437</id><created>2014-08-19</created><authors><author><keyname>V&#xe4;&#xe4;n&#xe4;nen</keyname><forenames>Jouko</forenames></author></authors><title>The Logic of Approximate Dependence</title><categories>math.LO cs.LO</categories><msc-class>03B60</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend the treatment of functional dependence, the basic concept of
dependence logic, to include the possibility of dependence with a limited
number of exceptions. We call this approximate dependence. The main result of
the paper is a Completeness Theorem for approximate dependence atoms. We point
out some problematic features of this which suggests that we should consider
multi-teams, not just teams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4440</identifier>
 <datestamp>2014-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4440</id><created>2014-08-19</created><updated>2014-08-31</updated><authors><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author></authors><title>Are topic-specific search term, journal name and author name
  recommendations relevant for researchers?</title><categories>cs.DL cs.IR</categories><comments>4 pages, 1 figure, research paper accepted at EuroHCIR 2014 workshop
  in London. arXiv admin note: text overlap with arXiv:1101.1637</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a case study where researchers in the social
sciences (n=19) assess topical relevance for controlled search terms, journal
names and author names which have been compiled automatically by
bibliometric-enhanced information retrieval (IR) services. We call these
bibliometric-enhanced IR services Search Term Recommender (STR), Journal Name
Recommender (JNR) and Author Name Recommender (ANR) in this paper. The
researchers in our study (practitioners, PhD students and postdocs) were asked
to assess the top n pre-processed recommendations from each recommender for
specific research topics which have been named by them in an interview before
the experiment. Our results show clearly that the presented search term,
journal name and author name recommendations are highly relevant to the
researchers' topic and can easily be integrated for search in Digital
Libraries. The average precision for top ranked recommendations is 0.75 for
author names, 0.74 for search terms and 0.73 for journal names. The relevance
distribution differs largely across topics and researcher types. Practitioners
seem to favor author name recommendations while postdocs have rated author name
recommendations the lowest. In the experiment the small postdoc group (n=3)
favor journal name recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4443</identifier>
 <datestamp>2014-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4443</id><created>2014-08-19</created><authors><author><keyname>Zois</keyname><forenames>Daphney-Stavroula</forenames></author><author><keyname>Mitra</keyname><forenames>Urbashi</forenames></author></authors><title>Controlled Sensing: A Myopic Fisher Information Sensor Selection
  Algorithm</title><categories>cs.SY</categories><comments>6 pages, 3 figures, accepted in Globecom 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of state tracking with observation control
for a particular class of dynamical systems. The system state evolution is
described by a discrete-time, finite-state Markov chain, while the measurement
process is characterized by a controlled multi-variate Gaussian observation
model. The computational complexity of the optimal control strategy proposed in
our prior work proves to be prohibitive. A suboptimal, lower complexity
algorithm based on the Fisher information measure is proposed. Toward this end,
the preceding measure is generalized to account for multi-valued discrete
parameters and control inputs. A closed-form formula for our system model is
also derived. Numerical simulations are provided for a physical activity
tracking application showing the near-optimal performance of the proposed
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4461</identifier>
 <datestamp>2014-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4461</id><created>2014-08-19</created><updated>2014-08-22</updated><authors><author><keyname>Song</keyname><forenames>H. Francis</forenames></author><author><keyname>Wang</keyname><forenames>Xiao-Jing</forenames></author></authors><title>A simple, distance-dependent formulation of the Watts-Strogatz model for
  directed and undirected small-world networks</title><categories>cs.SI cond-mat.dis-nn physics.soc-ph</categories><comments>Added a note about G(n,m) vs. G(n,p) ER networks. Thanks to B.
  Sonnenschein for pointing this out</comments><journal-ref>Phys. Rev. E 90, 062801 (2014)</journal-ref><doi>10.1103/PhysRevE.90.062801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Small-world networks---complex networks characterized by a combination of
high clustering and short path lengths---are widely studied using the
paradigmatic model of Watts and Strogatz (WS). Although the WS model is already
quite minimal and intuitive, we describe an alternative formulation of the WS
model in terms of a distance-dependent probability of connection that further
simplifies, both practically and theoretically, the generation of directed and
undirected WS-type small-world networks. In addition to highlighting an
essential feature of the WS model that has previously been overlooked, this
alternative formulation makes it possible to derive exact expressions for
quantities such as the degree and motif distributions and global clustering
coefficient for both directed and undirected networks in terms of model
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4468</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4468</id><created>2014-08-19</created><authors><author><keyname>Toman</keyname><forenames>David</forenames></author><author><keyname>Weddell</keyname><forenames>Grant</forenames></author></authors><title>Undecidability of Finite Model Reasoning in DLFD</title><categories>cs.DB cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We resolve an open problem concerning finite logical implication for path
functional dependencies (PFDs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4487</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4487</id><created>2014-08-19</created><authors><author><keyname>Movahedi</keyname><forenames>Mahnush</forenames></author><author><keyname>Zamani</keyname><forenames>Mahdi</forenames></author></authors><title>On Optimal Decision-Making in Ant Colonies</title><categories>cs.DC cs.NE</categories><comments>Workshop on Biological Distributed Algorithms (BDA 2014)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Colonies of ants can collectively choose the best of several nests, even when
many of the active ants who organize the move visit only one site.
Understanding such a behavior can help us design efficient distributed decision
making algorithms. Marshall et al. propose a model for house-hunting in
colonies of ant Temnothorax albipennis. Unfortunately, their model does not
achieve optimal decision-making while laboratory experiments show that, in
fact, colonies usually achieve optimality during the house-hunting process. In
this paper, we argue that the model of Marshall et al. can achieve optimality
by including nest size information in their mathematical model. We use lab
results of Pratt et al. to re-define the differential equations of Marshall et
al. Finally, we sketch our strategy for testing the optimality of the new
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4490</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4490</id><created>2014-08-19</created><authors><author><keyname>Niknami</keyname><forenames>Mehrdad</forenames></author><author><keyname>Samaranayake</keyname><forenames>Samitha</forenames></author><author><keyname>Bayen</keyname><forenames>Alexandre</forenames></author></authors><title>Tractable Pathfinding for the Stochastic On-Time Arrival Problem</title><categories>cs.DS</categories><comments>Originally submitted to SODA'15 (July 7, 2014); this version includes
  typographical corrections and modifications to pre-processing via
  source/destination Arc-Potentials</comments><msc-class>68W99</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new technique for fast computation of the route that maximizes
the probability of on-time arrival in stochastic networks, also known as the
path-based stochastic on-time arrival (SOTA) problem. We utilize the solution
to the policy-based SOTA problem, which is of pseudopolynomial time complexity
in the time budget of the journey, as a heuristic for efficiently computing the
optimal path. We also introduce Arc-Potentials, an extension to the Arc-Flags
pre-processing algorithm, which improves the efficiency of the graph
pre-processing and reduces the computation time. Finally, we present extensive
numerical results demonstrating the effectiveness of our algorithm and observe
that its running time when given the policy (which can be efficiently obtained
using pre-processing) is almost always linear in the length of the optimal path
for our test networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4498</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4498</id><created>2014-08-19</created><authors><author><keyname>Jackson</keyname><forenames>Marcel</forenames></author><author><keyname>Stokes</keyname><forenames>Tim</forenames></author></authors><title>Monoids with tests and the algebra of possibly non-halting programs</title><categories>math.LO cs.LO</categories><comments>To appear in Journal of Logical and Algebraic Methods in Programming</comments><msc-class>20M20, 20M30, 08A70, 68Q60</msc-class><acm-class>F.3.1; F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the algebraic theory of computable functions, which can be viewed as
arising from possibly non-halting computer programs or algorithms, acting on
some state space, equipped with operations of composition, {\em if-then-else}
and {\em while-do} defined in terms of a Boolean algebra of conditions. It has
previously been shown that there is no finite axiomatisation of algebras of
partial functions under these operations alone, and this holds even if one
restricts attention to transformations (representing halting programs) rather
than partial functions, and omits {\em while-do} from the signature. In the
halting case, there is a natural &quot;fix&quot;, which is to allow composition of
halting programs with conditions, and then the resulting algebras admit a
finite axiomatisation. In the current setting such compositions are not
possible, but by extending the notion of {\em if-then-else}, we are able to
give finite axiomatisations of the resulting algebras of (partial) functions,
with {\em while-do} in the signature if the state space is assumed finite. The
axiomatisations are extended to consider the partial predicate of equality. All
algebras considered turn out to be enrichments of the notion of a (one-sided)
restriction semigroup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4504</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4504</id><created>2014-08-19</created><authors><author><keyname>Abdelsamea</keyname><forenames>Mohammed M.</forenames></author></authors><title>Unsupervised Parallel Extraction based Texture for Efficient Image
  Representation</title><categories>cs.CV</categories><comments>arXiv admin note: substantial text overlap with arXiv:1408.4143</comments><journal-ref>2011 International Conference on Signal, Image Processing and
  Applications With workshop of ICEEA 2011, IPCSIT vol.21 (2011), IACSIT Press,
  Singapore</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SOM is a type of unsupervised learning where the goal is to discover some
underlying structure of the data. In this paper, a new extraction method based
on the main idea of Concurrent Self-Organizing Maps (CSOM), representing a
winner-takes-all collection of small SOM networks is proposed. Each SOM of the
system is trained individually to provide best results for one class only. The
experiments confirm that the proposed features based CSOM is capable to
represent image content better than extracted features based on a single big
SOM and these proposed features improve the final decision of the CAD.
Experiments held on Mammographic Image Analysis Society (MIAS) dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4519</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4519</id><created>2014-08-20</created><authors><author><keyname>Renaud</keyname><forenames>Gareth</forenames></author></authors><title>Searchers Seeking: What Happens When you Frustrate Searchers?</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People searching for information occasionally experience difficulties finding
what they want on the Web. This might happen if they cannot quite come up with
the right search terms. What do searchers do when this happens? Intuitively one
imagines that they will try a number of associated search terms to zero in on
their intended search target. Certainly the provision of spelling suggestions
and related search terms assume that frustrated searchers will use these to
implement this strategy. Is this assumption correct? What do people really do?
  We ran an experiment where we asked people to find some relevant links, but
we prevented them from using the most obvious search terms, which we termed
taboo words. To make the experiment more interesting we also provided the
traditional forms of assistance: spelling suggestions and related search
suggestions. We assigned participants using a magic square to get no
assistance, one kind of assistance, or both. Forty eight people participated in
the experiment.
  What emerged from the analysis was that when people are frustrated in their
searching attempts, a minority soldier on, attempting to find other terms, but
the majority will stick with their original query term and simply progress from
page to page in a vain attempt to find something relevant. This confirms
findings by other researchers about the difficulties of query re-formulation.
Our finding will serve to inform the developers of user interfaces to search
engines, since it would be helpful if we could find a better way of supporting
frustrated searchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4522</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4522</id><created>2014-08-20</created><updated>2015-11-21</updated><authors><author><keyname>Song</keyname><forenames>Eva C.</forenames></author><author><keyname>Cuff</keyname><forenames>Paul</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>The Likelihood Encoder for Lossy Compression</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A likelihood encoder is studied in the context of lossy source compression.
The analysis of the likelihood encoder is based on the soft-covering lemma. It
is demonstrated that the use of a likelihood encoder together with the
soft-covering lemma yields simple achievability proofs for classical source
coding problems. The cases of the point-to-point rate-distortion function, the
rate-distortion function with side information at the decoder (i.e. the
Wyner-Ziv problem), and the multi-terminal source coding inner bound (i.e. the
Berger-Tung problem) are examined in this paper. Furthermore, a non-asymptotic
analysis is used for the point-to-point case to examine the upper bound on the
excess distortion provided by this method. The likelihood encoder is also
related to a recent alternative technique using properties of random binning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4523</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4523</id><created>2014-08-20</created><authors><author><keyname>Tashtoush</keyname><forenames>Yahya</forenames></author><author><keyname>Al-Maolegi</keyname><forenames>Mohammed</forenames></author><author><keyname>Arkok</keyname><forenames>Bassam</forenames></author></authors><title>The Correlation among Software Complexity Metrics with Case Study</title><categories>cs.SE</categories><comments>6 pages</comments><journal-ref>International Journal of Advanced Computer Research, 2014</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  People demand for software quality is growing increasingly, thus different
scales for the software are growing fast to handle the quality of software. The
software complexity metric is one of the measurements that use some of the
internal attributes or characteristics of software to know how they effect on
the software quality. In this paper, we cover some of more efficient software
complexity metrics such as Cyclomatic complexity, line of code and Hallstead
complexity metric. This paper presents their impacts on the software quality.
It also discusses and analyzes the correlation between them. It finally reveals
their relation with the number of errors using a real dataset as a case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4528</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4528</id><created>2014-08-20</created><authors><author><keyname>Lee</keyname><forenames>Junghoon</forenames></author><author><keyname>Tepedelenlioglu</keyname><forenames>Cihan</forenames></author></authors><title>Laplace Functional Ordering of Point Processes in Large-scale Wireless
  Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>30 pages, 5 figures, Submitted to IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic orders on point processes are partial orders which capture notions
like being larger or more variable. Laplace functional ordering of point
processes is a useful stochastic order for comparing spatial deployments of
wireless networks. It is shown that the ordering of point processes is
preserved under independent operations such as marking, thinning, clustering,
superposition, and random translation. Laplace functional ordering can be used
to establish comparisons of several performance metrics such as coverage
probability, achievable rate, and resource allocation even when closed form
expressions of such metrics are unavailable. Applications in several network
scenarios are also provided where tradeoffs between coverage and interference
as well as fairness and peakyness are studied. Monte-Carlo simulations are used
to supplement our analytical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4536</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4536</id><created>2014-08-20</created><authors><author><keyname>Benamou</keyname><forenames>Jean-David</forenames><affiliation>INRIA Paris-Rocquencourt</affiliation></author><author><keyname>Carlier</keyname><forenames>Guillaume</forenames><affiliation>CEREMADE</affiliation></author><author><keyname>M&#xe9;rigot</keyname><forenames>Quentin</forenames><affiliation>LJK</affiliation></author><author><keyname>Oudet</keyname><forenames>Edouard</forenames><affiliation>LJK</affiliation></author></authors><title>Discretization of functionals involving the Monge-Amp\`ere operator</title><categories>math.NA cs.NA</categories><comments>20 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gradient flows in the Wasserstein space have become a powerful tool in the
analysis of diffusion equations, following the seminal work of Jordan,
Kinderlehrer and Otto (JKO). The numerical applications of this formulation
have been limited by the difficulty to compute the Wasserstein distance in
dimension &gt;= 2. One step of the JKO scheme is equivalent to a variational
problem on the space of convex functions, which involves the Monge-Amp\`ere
operator. Convexity constraints are notably difficult to handle numerically,
but in our setting the internal energy plays the role of a barrier for these
constraints. This enables us to introduce a consistent discretization, which
inherits convexity properties of the continuous variational problem. We show
the effectiveness of our approach on nonlinear diffusion and crowd-motion
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4539</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4539</id><created>2014-08-20</created><authors><author><keyname>Maehara</keyname><forenames>Daiki</forenames></author><author><keyname>Tran</keyname><forenames>Gia Khanh</forenames></author><author><keyname>Sakaguchi</keyname><forenames>Kei</forenames></author><author><keyname>Araki</keyname><forenames>Kiyomichi</forenames></author><author><keyname>Furukawa</keyname><forenames>Minoru</forenames></author></authors><title>Experiments Validating the Effectiveness of Multi-point Wireless Energy
  Transmission with Carrier Shift Diversity</title><categories>cs.NI cs.IT math.IT</categories><comments>This paper is submitted to IEICE IEICE Transactions on
  Communications.l</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method to seamlessly extend the coverage of energy
supply field for wireless sensor networks in order to free sensors from wires
and batteries, where the multi-point scheme is employed to overcome path-loss
attenuation, while the carrier shift diversity is introduced to mitigate the
effect of interference between multiple wave sources. As we focus on the energy
transmission part, sensor or communication schemes are out of scope of this
paper. To verify the effectiveness of the proposed wireless energy
transmission, this paper conducts indoor experiments in which we compare the
power distribution and the coverage performance of different energy
transmission schemes including conventional single-point, simple multi-point
and our proposed multi-point scheme. To easily observe the effect of the
standing-wave caused by multipath and interference between multiple wave
sources, 3D measurements are performed in an empty room. The results of our
experiments together with those of a simulation that assumes a similar antenna
setting in free space environment show that the coverage of single-point and
multi-point wireless energy transmission without carrier shift diversity are
limited by path-loss, standing-wave created by multipath and interference
between multiple wave sources. On the other hand, the proposed scheme can
overcome power attenuation due to the path-loss as well as the effect of
standing-wave created by multipath and interference between multiple wave
sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4544</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4544</id><created>2014-08-20</created><authors><author><keyname>Avendi</keyname><forenames>M. R.</forenames></author><author><keyname>Haghighi</keyname><forenames>K.</forenames></author><author><keyname>Panahi</keyname><forenames>A.</forenames></author><author><keyname>Viberg</keyname><forenames>M.</forenames></author></authors><title>A NLLS Based Sub-Nyquist Rate Spectrum Sensing for Wideband Cognitive
  Radio</title><categories>cs.IT math.IT</categories><comments>IEEE Dyspan 2011. arXiv admin note: substantial text overlap with
  arXiv:1010.2157</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For systems and devices, such as cognitive radio and networks, that need to
be aware of available frequency bands, spectrum sensing has an important role.
A major challenge in this area is the requirement of a high sampling rate in
the sensing of a wideband signal. In this paper a wideband spectrum sensing
method is presented that utilizes a sub-Nyquist sampling scheme to bring
substantial savings in terms of the sampling rate. The correlation matrix of a
finite number of noisy samples is computed and used by a non-linear least
square (NLLS) estimator to detect the occupied and vacant channels of the
spectrum. We provide an expression for the detection threshold as a function of
sampling parameters and noise power. Also, a sequential forward selection
algorithm is presented to find the occupied channels with low complexity. The
method can be applied to both correlated and uncorrelated wideband multichannel
signals. A comparison with conventional energy detection using Nyquist-rate
sampling shows that the proposed scheme can yield similar performance for SNR
above 4 dB with a factor of 3 smaller sampling rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4551</identifier>
 <datestamp>2014-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4551</id><created>2014-08-20</created><updated>2014-11-08</updated><authors><author><keyname>Prabhakar</keyname><forenames>Bharat</forenames></author><author><keyname>Kulkarni</keyname><forenames>Ankur A.</forenames></author></authors><title>Dimensionality Reduction of Affine Variational Inequalities Using Random
  Projections</title><categories>math.OC cs.LG cs.SY</categories><comments>Submitted to Mathematical Programming Series A. Edited some typos
  from the previous version. Also added a bound on the lower dimension</comments><msc-class>90C33, 65K10, 80M50, 68W20, 68W25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for dimensionality reduction of an affine variational
inequality (AVI) defined over a compact feasible region. Centered around the
Johnson Lindenstrauss lemma, our method is a randomized algorithm that produces
with high probability an approximate solution for the given AVI by solving a
lower-dimensional AVI. The algorithm allows the lower dimension to be chosen
based on the quality of approximation desired. The algorithm can also be used
as a subroutine in an exact algorithm for generating an initial point close to
the solution. The lower-dimensional AVI is obtained by appropriately projecting
the original AVI on a randomly chosen subspace. The lower-dimensional AVI is
solved using standard solvers and from this solution an approximate solution to
the original AVI is recovered through an inexpensive process. Our numerical
experiments corroborate the theoretical results and validate that the algorithm
provides a good approximation at low dimensions and substantial savings in time
for an exact solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4565</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4565</id><created>2014-08-20</created><authors><author><keyname>Scheuner</keyname><forenames>Joel</forenames></author><author><keyname>Leitner</keyname><forenames>Philipp</forenames></author><author><keyname>Cito</keyname><forenames>Jurgen</forenames></author><author><keyname>Gall</keyname><forenames>Harald</forenames></author></authors><title>Cloud WorkBench - Infrastructure-as-Code Based Cloud Benchmarking</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To optimally deploy their applications, users of Infrastructure-as-a-Service
clouds are required to evaluate the costs and performance of different
combinations of cloud configurations to find out which combination provides the
best service level for their specific application. Unfortunately, benchmarking
cloud services is cumbersome and error-prone. In this paper, we propose an
architecture and concrete implementation of a cloud benchmarking Web service,
which fosters the definition of reusable and representative benchmarks. In
distinction to existing work, our system is based on the notion of
Infrastructure-as-Code, which is a state of the art concept to define IT
infrastructure in a reproducible, well-defined, and testable way. We
demonstrate our system based on an illustrative case study, in which we measure
and compare the disk IO speeds of different instance and storage types in
Amazon EC2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4576</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4576</id><created>2014-08-20</created><updated>2014-08-25</updated><authors><author><keyname>Yang</keyname><forenames>Sibei</forenames></author><author><keyname>Tao</keyname><forenames>Liangde</forenames></author><author><keyname>Gong</keyname><forenames>Bingchen</forenames></author></authors><title>Introduction to Clustering Algorithms and Applications</title><categories>cs.LG cs.CV</categories><comments>This paper has been withdrawn by the author due to unsuitable content</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Data clustering is the process of identifying natural groupings or clusters
within multidimensional data based on some similarity measure. Clustering is a
fundamental process in many different disciplines. Hence, researchers from
different fields are actively working on the clustering problem. This paper
provides an overview of the different representative clustering methods. In
addition, application of clustering in different field is briefly introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4587</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4587</id><created>2014-08-20</created><authors><author><keyname>Paolucci</keyname><forenames>Pier Stanislao</forenames></author><author><keyname>Bacivarov</keyname><forenames>Iuliana</forenames></author><author><keyname>Rai</keyname><forenames>Devendra</forenames></author><author><keyname>Schor</keyname><forenames>Lars</forenames></author><author><keyname>Thiele</keyname><forenames>Lothar</forenames></author><author><keyname>Yang</keyname><forenames>Hoeseok</forenames></author><author><keyname>Pastorelli</keyname><forenames>Elena</forenames></author><author><keyname>Ammendola</keyname><forenames>Roberto</forenames></author><author><keyname>Biagioni</keyname><forenames>Andrea</forenames></author><author><keyname>Frezza</keyname><forenames>Ottorino</forenames></author><author><keyname>Cicero</keyname><forenames>Francesca Lo</forenames></author><author><keyname>Lonardo</keyname><forenames>Alessandro</forenames></author><author><keyname>Simula</keyname><forenames>Francesco</forenames></author><author><keyname>Tosoratto</keyname><forenames>Laura</forenames></author><author><keyname>Vicini</keyname><forenames>Piero</forenames></author></authors><title>EURETILE D7.3 - Dynamic DAL benchmark coding, measurements on MPI
  version of DPSNN-STDP (distributed plastic spiking neural net) and
  improvements to other DAL codes</title><categories>cs.DC cs.CE cs.MS cs.NE q-bio.NC</categories><comments>34 pages. arXiv admin note: substantial text overlap with
  arXiv:1310.8478</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The EURETILE project required the selection and coding of a set of dedicated
benchmarks. The project is about the software and hardware architecture of
future many-tile distributed fault-tolerant systems. We focus on dynamic
workloads characterised by heavy numerical processing requirements. The
ambition is to identify common techniques that could be applied to both the
Embedded Systems and HPC domains. This document is the first public deliverable
of Work Package 7: Challenging Tiled Applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4590</identifier>
 <datestamp>2015-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4590</id><created>2014-08-20</created><updated>2015-08-30</updated><authors><author><keyname>Karakus</keyname><forenames>Can</forenames></author><author><keyname>Wang</keyname><forenames>I-Hsiang</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>Gaussian Interference Channel with Intermittent Feedback</title><categories>cs.IT math.IT</categories><comments>36 pages, 12 figures, appeared in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate how to exploit intermittent feedback for interference
management by studying the two-user Gaussian interference channel (IC). We
approximately characterize (within a universal constant) the capacity region
for the Gaussian IC with intermittent feedback. We exactly characterize the the
capacity region of the linear deterministic version of the problem, which gives
us insight into the Gaussian problem. We find that the characterization only
depends on the forward channel parameters and the marginal probability
distribution of each feedback link. The result shows that passive and
unreliable feedback can be harnessed to provide multiplicative capacity gain in
Gaussian interference channels. We find that when the feedback links are active
with sufficiently large probabilities, the perfect feedback sum-capacity is
achieved to within a constant gap. In contrast to other schemes developed for
interference channel with feedback, our achievable scheme makes use of
quantize-map-and-forward to relay the information obtained through feedback,
performs forward decoding, and does not use structured codes. We also develop
new outer bounds enabling us to obtain the (approximate) characterization of
the capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4599</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4599</id><created>2014-08-20</created><authors><author><keyname>Niethammer</keyname><forenames>Christoph</forenames></author><author><keyname>Becker</keyname><forenames>Stefan</forenames></author><author><keyname>Bernreuther</keyname><forenames>Martin</forenames></author><author><keyname>Buchholz</keyname><forenames>Martin</forenames></author><author><keyname>Eckhardt</keyname><forenames>Wolfgang</forenames></author><author><keyname>Heinecke</keyname><forenames>Alexander</forenames></author><author><keyname>Werth</keyname><forenames>Stephan</forenames></author><author><keyname>Bungartz</keyname><forenames>Hans-Joachim</forenames></author><author><keyname>Glass</keyname><forenames>Colin W.</forenames></author><author><keyname>Hasse</keyname><forenames>Hans</forenames></author><author><keyname>Vrabec</keyname><forenames>Jadran</forenames></author><author><keyname>Horsch</keyname><forenames>Martin</forenames></author></authors><title>ls1 mardyn: The massively parallel molecular dynamics code for large
  systems</title><categories>cs.CE cond-mat.soft physics.comp-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The molecular dynamics simulation code ls1 mardyn is presented. It is a
highly scalable code, optimized for massively parallel execution on
supercomputing architectures, and currently holds the world record for the
largest molecular simulation with over four trillion particles. It enables the
application of pair potentials to length and time scales which were previously
out of scope for molecular dynamics simulation. With an efficient dynamic load
balancing scheme, it delivers high scalability even for challenging
heterogeneous configurations. Presently, multi-center rigid potential models
based on Lennard-Jones sites, point charges and higher-order polarities are
supported. Due to its modular design, ls1 mardyn can be extended to new
physical models, methods, and algorithms, allowing future users to tailor it to
suit their respective needs. Possible applications include scenarios with
complex geometries, e.g. for fluids at interfaces, as well as non-equilibrium
molecular dynamics simulation of heat and mass transfer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4612</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4612</id><created>2014-08-20</created><authors><author><keyname>Pan</keyname><forenames>Indranil</forenames></author><author><keyname>Das</keyname><forenames>Saptarshi</forenames></author></authors><title>Kriging based Surrogate Modeling for Fractional Order Control of
  Microgrids</title><categories>cs.SY math.OC</categories><comments>9 pages, 13 figures. appears in Smart Grid, IEEE Transactions on,
  2014</comments><doi>10.1109/TSG.2014.2336771</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the use of fractional order (FO) controllers for a
microgrid. The microgrid employs various autonomous generation systems like
wind turbine generator (WTG), solar photovoltaic (PV), diesel energy generator
(DEG) and fuel-cells (FC). Other storage devices like the battery energy
storage system (BESS) and the flywheel energy storage system (FESS) are also
present in the power network. An FO control strategy is employed and the FO-PID
controller parameters are tuned with a global optimization algorithm to meet
system performance specifications. A kriging based surrogate modeling technique
is employed to alleviate the issue of expensive objective function evaluation
for the optimization based controller tuning. Numerical simulations are
reported to prove the validity of the proposed methods. The results for both
the FO and the integer order (IO) controllers are compared with standard
evolutionary optimization techniques and the relative merits and demerits of
the kriging based surrogate modeling are discussed. This kind of optimization
technique is not only limited to this specific case of microgrid control but
also can be ported to other computationally expensive power system optimization
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4622</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4622</id><created>2014-08-20</created><authors><author><keyname>Vazquez</keyname><forenames>Emmanuel</forenames></author><author><keyname>Bect</keyname><forenames>Julien</forenames></author></authors><title>A new integral loss function for Bayesian optimization</title><categories>stat.CO cs.LG math.OC stat.ML</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of maximizing a real-valued continuous function $f$
using a Bayesian approach. Since the early work of Jonas Mockus and Antanas
\v{Z}ilinskas in the 70's, the problem of optimization is usually formulated by
considering the loss function $\max f - M_n$ (where $M_n$ denotes the best
function value observed after $n$ evaluations of $f$). This loss function puts
emphasis on the value of the maximum, at the expense of the location of the
maximizer. In the special case of a one-step Bayes-optimal strategy, it leads
to the classical Expected Improvement (EI) sampling criterion. This is a
special case of a Stepwise Uncertainty Reduction (SUR) strategy, where the risk
associated to a certain uncertainty measure (here, the expected loss) on the
quantity of interest is minimized at each step of the algorithm. In this
article, assuming that $f$ is defined over a measure space $(\mathbb{X},
\lambda)$, we propose to consider instead the integral loss function
$\int_{\mathbb{X}} (f - M_n)_{+}\, d\lambda$, and we show that this leads, in
the case of a Gaussian process prior, to a new numerically tractable sampling
criterion that we call $\rm EI^2$ (for Expected Integrated Expected
Improvement). A numerical experiment illustrates that a SUR strategy based on
this new sampling criterion reduces the error on both the value and the
location of the maximizer faster than the EI-based strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4626</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4626</id><created>2014-08-20</created><authors><author><keyname>R&#xfc;egg</keyname><forenames>Ulf</forenames></author><author><keyname>Kieffer</keyname><forenames>Steve</forenames></author><author><keyname>Dwyer</keyname><forenames>Tim</forenames></author><author><keyname>Marriott</keyname><forenames>Kim</forenames></author><author><keyname>Wybrow</keyname><forenames>Michael</forenames></author></authors><title>Stress-Minimizing Orthogonal Layout of Data Flow Diagrams with Ports</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a fundamentally different approach to orthogonal layout of data
flow diagrams with ports. This is based on extending constrained stress
majorization to cater for ports and flow layout. Because we are minimizing
stress we are able to better display global structure, as measured by several
criteria such as stress, edge-length variance, and aspect ratio. Compared to
the layered approach, our layouts tend to exhibit symmetries, and eliminate
inter-layer whitespace, making the diagrams more compact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4628</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4628</id><created>2014-08-20</created><authors><author><keyname>Martins</keyname><forenames>Ruben</forenames></author><author><keyname>Joshi</keyname><forenames>Saurabh</forenames></author><author><keyname>Manquinho</keyname><forenames>Vasco</forenames></author><author><keyname>Lynce</keyname><forenames>Ines</forenames></author></authors><title>Incremental Cardinality Constraints for MaxSAT</title><categories>cs.LO cs.AI</categories><comments>18 pages, 4 figures, 1 table. Final version published in Principles
  and Practice of Constraint Programming (CP) 2014</comments><doi>10.1007/978-3-319-10428-7_39</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum Satisfiability (MaxSAT) is an optimization variant of the Boolean
Satisfiability (SAT) problem. In general, MaxSAT algorithms perform a
succession of SAT solver calls to reach an optimum solution making extensive
use of cardinality constraints. Many of these algorithms are non-incremental in
nature, i.e. at each iteration the formula is rebuilt and no knowledge is
reused from one iteration to another. In this paper, we exploit the knowledge
acquired across iterations using novel schemes to use cardinality constraints
in an incremental fashion. We integrate these schemes with several MaxSAT
algorithms. Our experimental results show a significant performance boost for
these algo- rithms as compared to their non-incremental counterparts. These
results suggest that incremental cardinality constraints could be beneficial
for other constraint solving domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4630</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4630</id><created>2014-08-20</created><authors><author><keyname>Linowitz</keyname><forenames>Benjamin</forenames></author><author><keyname>Satriano</keyname><forenames>Matthew</forenames></author><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author></authors><title>A non-commutative analogue of the Odlyzko bounds and bounds on
  performance for space-time lattice codes</title><categories>cs.IT math.IT math.NT math.RA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers space-time coding over several independently Rayleigh
faded blocks. In particular we will concentrate on giving upper bounds for the
coding gain of lattice space-time codes as the number of blocks grow. This
problem was previously considered in the single antenna case by Bayer et al. in
2006. Crucial to their work was Odlyzko's bound on the discriminant of an
algebraic number field, as this provides an upper bound for the normalized
coding gain of number field codes. In the MIMO context natural codes are
constructed from division algebras defined over number fields and the coding
gain is measured by the discriminant of the corresponding (non-commutative)
algebra. In this paper we will develop analogues of the Odlyzko bounds in this
context and show how these bounds limit the normalized coding gain of a very
general family of division algebra based space-time codes. These bounds can
also be used as benchmarks in practical code design and as tools to analyze
asymptotic bounds of performance as the number of independently faded blocks
increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4644</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4644</id><created>2014-08-20</created><authors><author><keyname>Riehle</keyname><forenames>Dirk</forenames></author><author><keyname>Kolassa</keyname><forenames>Carsten</forenames></author><author><keyname>Salim</keyname><forenames>Michel A.</forenames></author></authors><title>Developer Belief vs. Reality: The Case of the Commit Size Distribution</title><categories>cs.SE</categories><comments>12 pages, 9 figures, 5 tables. Software Engineering 2012, GI-Edition
  Lecture Notes in Informatics, pp.59-70, 2012</comments><acm-class>D.2.8; D.2.9; D.m</acm-class><journal-ref>Software Engineering 2012, GI-Edition Lecture Notes in
  Informatics, pp.59-70, ISSN 1617-5468, ISBN 978-88579-292-5,2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of software development tools follows from what the developers of
such tools believe is true about software development. A key aspect of such
beliefs is the size of code contributions (commits) to a software project. In
this paper, we show that what tool developers think is true about the size of
code contributions is different by more than an order of magnitude from
reality. We present this reality, called the commit size distribution, for a
large sample of open source and selected closed source projects. We suggest
that these new empirical insights will help improve software development tools
by aligning underlying design assumptions closer with reality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4649</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4649</id><created>2014-08-20</created><authors><author><keyname>Liu</keyname><forenames>Jian-Guo</forenames></author><author><keyname>Ren</keyname><forenames>Zhuo-Ming</forenames></author><author><keyname>Guo</keyname><forenames>Qiang</forenames></author></authors><title>Ranking the spreading influence in complex networks</title><categories>physics.soc-ph cs.SI</categories><comments>6 pages, 3 figures</comments><journal-ref>Physica A 392 (2013) 4154-4159</journal-ref><doi>10.1016/j.physa.2013.04.037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying the node spreading influence in networks is an important task to
optimally use the network structure and ensure the more efficient spreading in
information. In this paper, by taking into account the shortest distance
between a target node and the node set with the highest $k$-core value, we
present an improved method to generate the ranking list to evaluate the node
spreading influence. Comparing with the epidemic process results for four real
networks and the Barab\'{a}si-Albert network, the parameterless method could
identify the node spreading influence more accurately than the ones generated
by the degree $k$, closeness centrality, $k$-shell and mixed degree
decomposition methods. This work would be helpful for deeply understanding the
node importance of a network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4673</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4673</id><created>2014-08-20</created><authors><author><keyname>Majdodin</keyname><forenames>Rooholah</forenames></author></authors><title>Horn functions and the AFP Algorithm</title><categories>cs.LG</categories><msc-class>68Q32, 68T27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is described why multiple refinements with each negative counterexample
does not improve the complexity of the AFP Algorithm. Also Canonical normal
formulas for Horn functions are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4681</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4681</id><created>2014-08-20</created><authors><author><keyname>Ramezanian</keyname><forenames>Rasoul</forenames></author></authors><title>Non-predetermined Model Theory</title><categories>math.LO cs.LO</categories><comments>6 pages</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduce a new model theory call non-predetermined model theory
where functions and relations need not to be determined already and they are
determined through time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4692</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4692</id><created>2014-08-20</created><authors><author><keyname>Freytag</keyname><forenames>Alexander</forenames></author><author><keyname>R&#xfc;hle</keyname><forenames>Johannes</forenames></author><author><keyname>Bodesheim</keyname><forenames>Paul</forenames></author><author><keyname>Rodner</keyname><forenames>Erik</forenames></author><author><keyname>Denzler</keyname><forenames>Joachim</forenames></author></authors><title>Seeing through bag-of-visual-word glasses: towards understanding
  quantization effects in feature extraction methods</title><categories>cs.CV</categories><comments>An abstract version of this paper was accepted for the ICPR FEAST
  Workshop</comments><report-no>TR-FSU-INF-CV-2014-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vector-quantized local features frequently used in bag-of-visual-words
approaches are the backbone of popular visual recognition systems due to both
their simplicity and their performance. Despite their success,
bag-of-words-histograms basically contain low-level image statistics (e.g.,
number of edges of different orientations). The question remains how much
visual information is &quot;lost in quantization&quot; when mapping visual features to
code words? To answer this question, we present an in-depth analysis of the
effect of local feature quantization on human recognition performance. Our
analysis is based on recovering the visual information by inverting quantized
local features and presenting these visualizations with different codebook
sizes to human observers. Although feature inversion techniques are around for
quite a while, to the best of our knowledge, our technique is the first
visualizing especially the effect of feature quantization. Thereby, we are now
able to compare single steps in common image classification pipelines to human
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4700</identifier>
 <datestamp>2015-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4700</id><created>2014-08-20</created><authors><author><keyname>Alodeh</keyname><forenames>Maha</forenames></author><author><keyname>Chatzinotas</keyname><forenames>Symeon</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Constructive Multiuser Interference in Symbol Level Precoding for the
  MISO Downlink Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing</comments><doi>10.1109/TSP.2015.2404302</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problem of interference among the simultaneous
multiuser transmissions in the downlink of multiple antennas systems. Using
symbol level precoding, a new approach towards the multiuser interference is
discussed along this paper. The concept of exploiting the interference between
the spatial multiuser transmissions by jointly utilizing the data information
(DI) and channel state information (CSI), in order to design symbol-level
precoders, is proposed. In this direction, the interference among the data
streams is transformed under certain conditions to useful signal that can
improve the signal to interference noise ratio (SINR) of the downlink
transmissions. We propose a maximum ratio transmission (MRT) based algorithm
that jointly exploits DI and CSI to glean the benefits from constructive
multiuser interference. Subsequently, a relation between the constructive
interference downlink transmission and physical layer multicasting is
established. In this context, novel constructive interference precoding
techniques that tackle the transmit power minimization (min power) with
individual SINR constraints at each user's receivers is proposed. Furthermore,
fairness through maximizing the weighted minimum SINR (max min SINR) of the
users is addressed by finding the link between the min power and max min SINR
problems. Moreover, heuristic precoding techniques are proposed to tackle the
weighted sum rate problem. Finally, extensive numerical results show that the
proposed schemes outperform other state of the art techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4701</identifier>
 <datestamp>2014-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4701</id><created>2014-08-20</created><updated>2014-11-28</updated><authors><author><keyname>Lehtom&#xe4;ki</keyname><forenames>J.</forenames></author><author><keyname>Makkonen</keyname><forenames>I.</forenames></author><author><keyname>Caro</keyname><forenames>M. A.</forenames></author><author><keyname>Harju</keyname><forenames>A.</forenames></author><author><keyname>Lopez-Acevedo</keyname><forenames>O.</forenames></author></authors><title>Orbital-Free Density Functional Theory Implementation with the Projector
  Augmented-Wave Method</title><categories>physics.comp-ph cs.CE cs.MS physics.chem-ph</categories><comments>accepted in Journal of Chemical Physics</comments><journal-ref>J. Chem. Phys. 141, 234102 (2014)</journal-ref><doi>10.1063/1.4903450</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a computational scheme for orbital-free density functional theory
(OFDFT) that simultaneously provides access to all-electron values and
preserves the OFDFT linear scaling as a function of the system size. Using the
projector augmented-wave method (PAW) in combination with real-space methods we
overcome some obstacles faced by other available implementation schemes.
Specifically, the advantages of using the PAW method are two fold. First, PAW
reproduces all-electron values offering freedom in adjusting the convergence
parameters and the atomic setups allow tuning the numerical accuracy per
element. Second, PAW can provide a solution to some of the convergence problems
exhibited in other OFDFT implementations based on Kohn-Sham codes. Using PAW
and real-space methods, our orbital-free results agree with the reference
all-electron values with a mean absolute error of 10~meV and the number of
iterations required by the self-consistent cycle is comparable to the KS
method. The comparison of all-electron and pseudopotential bulk modulus and
lattice constant reveal an enormous difference, demonstrating that in order to
assess the performance of OFDFT functionals it is necessary to use
implementations that obtain all-electron values. The proposed combination of
methods is the most promising route currently available. We finally show that a
parametrized kinetic energy functional can give lattice constants and bulk
moduli comparable in accuracy to those obtained by the KS PBE method,
exemplified with the case of diamond.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4703</identifier>
 <datestamp>2015-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4703</id><created>2014-08-20</created><authors><author><keyname>Sparavigna</keyname><forenames>Amelia Carolina</forenames></author></authors><title>GIMP and Wavelets for Medical Image Processing: Enhancing Images of the
  Fundus of the Eye</title><categories>cs.CV</categories><comments>Keywords: Image processing, Retina, Retina Vessels, GIMP,
  AstroFracTool, Iris, Wavelets</comments><journal-ref>ijSciences, 2014, Volume 3, Issue 8, pages 35-47</journal-ref><doi>10.18483/ijSci.556</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The visual analysis of retina and of its vascular characteristics is
important in the diagnosis and monitoring of diseases of visual perception. In
the related medical diagnoses, the digital processing of the fundus images is
used to obtain the segmentation of retinal vessels. However, an image
segmentation is often requiring methods based on peculiar or complex
algorithms: in this paper we will show some alternative approaches obtained by
applying freely available tools to enhance, without a specific segmentation,
the images of the fundus of the eye. We will see in particular, that combining
the use of GIMP, the GNU Image Manipulation Program, with the wavelet filter of
Iris, a program well-known for processing astronomical images, the result is
giving images which can be alternative of those obtained from segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4712</identifier>
 <datestamp>2015-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4712</id><created>2014-08-20</created><updated>2015-01-22</updated><authors><author><keyname>Shao</keyname><forenames>Wen-Ze</forenames></author><author><keyname>Li</keyname><forenames>Hai-Bo</forenames></author><author><keyname>Elad</keyname><forenames>Michael</forenames></author></authors><title>Bi-l0-l2-Norm Regularization for Blind Motion Deblurring</title><categories>cs.CV</categories><comments>32 pages, 16 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In blind motion deblurring, leading methods today tend towards highly
non-convex approximations of the l0-norm, especially in the image
regularization term. In this paper, we propose a simple, effective and fast
approach for the estimation of the motion blur-kernel, through a bi-l0-l2-norm
regularization imposed on both the intermediate sharp image and the
blur-kernel. Compared with existing methods, the proposed regularization is
shown to be more effective and robust, leading to a more accurate motion
blur-kernel and a better final restored image. A fast numerical scheme is
deployed for alternatingly computing the sharp image and the blur-kernel, by
coupling the operator splitting and augmented Lagrangian methods. Experimental
results on both a benchmark image dataset and real-world motion blurred images
show that the proposed approach is highly competitive with state-of-the- art
methods in both deblurring effectiveness and computational efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4714</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4714</id><created>2014-08-20</created><authors><author><keyname>Li</keyname><forenames>Cong</forenames></author><author><keyname>Georgiopoulos</keyname><forenames>Michael</forenames></author><author><keyname>Anagnostopoulos</keyname><forenames>Georgios C.</forenames></author></authors><title>Conic Multi-Task Classification</title><categories>cs.LG</categories><comments>Accepted by European Conference on Machine Learning and Principles
  and Practice of Knowledge Discovery in Databases (ECMLPKDD)-2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, Multi-task Learning (MTL) models optimize the average of
task-related objective functions, which is an intuitive approach and which we
will be referring to as Average MTL. However, a more general framework,
referred to as Conic MTL, can be formulated by considering conic combinations
of the objective functions instead; in this framework, Average MTL arises as a
special case, when all combination coefficients equal 1. Although the advantage
of Conic MTL over Average MTL has been shown experimentally in previous works,
no theoretical justification has been provided to date. In this paper, we
derive a generalization bound for the Conic MTL method, and demonstrate that
the tightest bound is not necessarily achieved, when all combination
coefficients equal 1; hence, Average MTL may not always be the optimal choice,
and it is important to consider Conic MTL. As a byproduct of the generalization
bound, it also theoretically explains the good experimental results of previous
relevant works. Finally, we propose a new Conic MTL model, whose conic
combination coefficients minimize the generalization bound, instead of choosing
them heuristically as has been done in previous methods. The rationale and
advantage of our model is demonstrated and verified via a series of experiments
by comparing with several other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4715</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4715</id><created>2014-08-20</created><authors><author><keyname>Andrade</keyname><forenames>Hugo A.</forenames></author><author><keyname>Hogg</keyname><forenames>Simon</forenames></author><author><keyname>Ahrends</keyname><forenames>Stephan</forenames></author></authors><title>Making FPGAs Accessible to Scientists and Engineers as Domain Expert
  Software Programmers with LabVIEW</title><categories>cs.SE cs.DC cs.OS cs.PL</categories><comments>Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</comments><proxy>Frank Hannig</proxy><report-no>FSP/2014/02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a graphical programming framework, LabVIEW, and
associated language and libraries, as well as programming techniques and
patterns that we have found useful in making FPGAs accessible to scientists and
engineers as domain expert software programmers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4721</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4721</id><created>2014-08-20</created><authors><author><keyname>Schmid</keyname><forenames>Moritz</forenames></author><author><keyname>Reiche</keyname><forenames>Oliver</forenames></author><author><keyname>Schmitt</keyname><forenames>Christian</forenames></author><author><keyname>Hannig</keyname><forenames>Frank</forenames></author><author><keyname>Teich</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Code Generation for High-Level Synthesis of Multiresolution Applications
  on FPGAs</title><categories>cs.CV cs.DC cs.PL</categories><comments>Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</comments><proxy>Frank Hannig</proxy><report-no>FSP/2014/04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiresolution Analysis (MRA) is a mathematical method that is based on
working on a problem at different scales. One of its applications is medical
imaging where processing at multiple scales, based on the concept of Gaussian
and Laplacian image pyramids, is a well-known technique. It is often applied to
reduce noise while preserving image detail on different levels of granularity
without modifying the filter kernel. In scientific computing, multigrid methods
are a popular choice, as they are asymptotically optimal solvers for elliptic
Partial Differential Equations (PDEs). As such algorithms have a very high
computational complexity that would overwhelm CPUs in the presence of real-time
constraints, application-specific processors come into consideration for
implementation. Despite of huge advancements in leveraging productivity in the
respective fields, designers are still required to have detailed knowledge
about coding techniques and the targeted architecture to achieve efficient
solutions. Recently, the HIPAcc framework was proposed as a means for automatic
code generation of image processing algorithms, based on a Domain-Specific
Language (DSL). From the same code base, it is possible to generate code for
efficient implementations on several accelerator technologies including
different types of Graphics Processing Units (GPUs) as well as reconfigurable
logic (FPGAs). In this work, we demonstrate the ability of HIPAcc to generate
code for the implementation of multiresolution applications on FPGAs and
embedded GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4725</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4725</id><created>2014-08-20</created><authors><author><keyname>Skalicky</keyname><forenames>Sam</forenames></author><author><keyname>Schmidt</keyname><forenames>Andrew G.</forenames></author><author><keyname>French</keyname><forenames>Matthew</forenames></author></authors><title>High Level Hardware/Software Embedded System Design with Redsharc</title><categories>cs.SE cs.DC</categories><comments>Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</comments><proxy>Frank Hannig</proxy><report-no>FSP/2014/05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As tools for designing multiple processor systems-on-chips (MPSoCs) continue
to evolve to meet the demands of developers, there exist systematic gaps that
must be bridged to provide a more cohesive hardware/software development
environment. We present Redsharc to address these problems and enable: system
generation, software/hardware compilation and synthesis, run-time control and
execution of MPSoCs. The efforts presented in this paper extend our previous
work to provide a rich API, build infrastructure, and runtime enabling
developers to design a system of simultaneously executing kernels in software
or hardware, that communicate seamlessly. In this work we take Redsharc further
to support a broader class of applications across a larger number of devices
requiring a more unified system development environment and build
infrastructure. To accomplish this we leverage existing tools and extend
Redsharc with build and control infrastructure to relieve the burden of system
development allowing software programmers to focus their efforts on application
and kernel development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4745</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4745</id><created>2014-08-20</created><authors><author><keyname>Kaiser</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author><author><keyname>Rabinovich</keyname><forenames>Roman</forenames></author><author><keyname>Siebertz</keyname><forenames>Sebastian</forenames></author></authors><title>Directed Width Measures and Monotonicity of Directed Graph Searching</title><categories>cs.DM math.CO</categories><msc-class>68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider generalisations of tree width to directed graphs, that attracted
much attention in the last fifteen years. About their relative strength with
respect to &quot;bounded width in one measure implies bounded width in the other&quot;
many problems remain unsolved. Only some results separating directed width
measures are known. We give an almost complete picture of this relation. For
this, we consider the cops and robber games characterising DAG-width and
directed tree width (up to a constant factor). For DAG-width games, it is an
open question whether the robber-monotonicity cost (the difference between the
minimal numbers of cops capturing the robber in the general and in the monotone
case) can be bounded by any function. Examples show that this function (if it
exists) is at least $f(k) &gt; 4k/3$ (Kreutzer, Ordyniak 2008). We approach a
solution by defining weak monotonicity and showing that if $k$ cops win weakly
monotonically, then $O(k^2)$ cops win monotonically. It follows that bounded
Kelly-width implies bounded DAG-width, which has been open since the definition
of Kelly-width by Hunter and Kreutzer in 2008. For directed tree width games we
show that, unexpectedly, the cop-monotonicity cost (no cop revisits any vertex)
is not bounded by any function. This separates directed tree width from D-width
defined by Safari in 2005, refuting his conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4747</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4747</id><created>2014-08-20</created><authors><author><keyname>Banerjee</keyname><forenames>Taposh</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal. V.</forenames></author></authors><title>Data-Efficient Minimax Quickest Change Detection in a Decentralized
  System</title><categories>math.ST cs.IT math.IT math.PR stat.TH</categories><comments>Submitted to Sequential Analysis, Aug. 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sensor network is considered where a sequence of random variables is
observed at each sensor. At each time step, a processed version of the
observations is transmitted from the sensors to a common node called the fusion
center. At some unknown point in time the distribution of the observations at
all the sensor nodes changes. The objective is to detect this change in
distribution as quickly as possible, subject to constraints on the false alarm
rate and the cost of observations taken at each sensor. Minimax problem
formulations are proposed for the above problem. A data-efficient algorithm is
proposed in which an adaptive sampling strategy is used at each sensor to
control the cost of observations used before change. To conserve the cost of
communication an occasional binary digit is transmitted from each sensor to the
fusion center. It is shown that the proposed algorithm is globally
asymptotically optimal for the proposed formulations, as the false alarm rate
goes to zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4749</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4749</id><created>2014-08-20</created><authors><author><keyname>Davis</keyname><forenames>Joshua</forenames></author><author><keyname>Frost</keyname><forenames>Victor S.</forenames></author></authors><title>A Covert Channel Using Named Resources</title><categories>cs.CR</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A network covert channel is created that uses resource names such as
addresses to convey information, and that approximates typical user behavior in
order to blend in with its environment. The channel correlates available
resource names with a user defined code-space, and transmits its covert message
by selectively accessing resources associated with the message codes. In this
paper we focus on an implementation of the channel using the Hypertext Transfer
Protocol (HTTP) with Uniform Resource Locators (URLs) as the message names,
though the system can be used in conjunction with a variety of protocols. The
covert channel does not modify expected protocol structure as might be detected
by simple inspection, and our HTTP implementation emulates transaction level
web user behavior in order to avoid detection by statistical or behavioral
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4751</identifier>
 <datestamp>2014-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4751</id><created>2014-08-20</created><updated>2014-08-23</updated><authors><author><keyname>Davis</keyname><forenames>Joshua</forenames></author></authors><title>A Proposed System for Covert Communication to Distant and Broad
  Geographical Areas</title><categories>cs.CR</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A covert communication system is developed that modulates Morse code
characteristics and that delivers its mes- sage economically and to
geographically remote areas using radio and EchoLink. Our system allows a
covert message to be sent to a receiving individual by hiding it in an existing
carrier Morse code message. The carrier need not be sent directly to the
receiving person, though the receiver must have access to the signal.
Illustratively, we propose that our system may be used as an alternative means
of implementing numbers stations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4753</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4753</id><created>2014-08-20</created><authors><author><keyname>Alday</keyname><forenames>Phillip M.</forenames></author></authors><title>Be Careful When Assuming the Obvious: Commentary on &quot;The placement of
  the head that minimizes online memory: a complex systems approach&quot;</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ferrer-i-Cancho (2015) presents a mathematical model of both the synchronic
and diachronic nature of word order based on the assumption that memory costs
are a never decreasing function of distance and a few very general linguistic
assumptions. However, even these minimal and seemingly obvious assumptions are
not as safe as they appear in light of recent typological and psycholinguistic
evidence. The interaction of word order and memory has further depths to be
explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4776</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4776</id><created>2014-08-15</created><authors><author><keyname>Ushakov</keyname><forenames>Vitaly</forenames></author></authors><title>Implementation of Program Part at Automated Workplace for a Teaching
  Department</title><categories>cs.CY</categories><comments>7 pages, 18 figures</comments><journal-ref>Proceeding of 15th Conference of Open Innovations Association
  FRUCT, Saint-Petersburg, Russia, 21-25 April 2014, pp. 214-220</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of improving the efficiency of the teaching department through
the development of teaching department work area is described. Development of
an automated workplace of a teaching department who allows to realize
monitoring of progress of students, monitoring of mastering of disciplines by
students, is synchronized with an automated workplace of the teacher of the
higher school and autocompletes the report of movement of the contingent.
Besides, the designed system allows to increase efficiency and efficiency of
activities of employees of a teaching department.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4780</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4780</id><created>2014-08-20</created><authors><author><keyname>Yuen</keyname><forenames>Horace</forenames></author></authors><title>Simple explanation on why QKD keys have not been proved secure</title><categories>quant-ph cs.CR</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple counter-example is given on the prevalent interpretation of the
trace distance criterion as failure probability in quantum key distribution
protocols. A summary of its ramifications is listed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4792</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4792</id><created>2014-08-20</created><authors><author><keyname>Anwar</keyname><forenames>Adnan</forenames></author><author><keyname>Mahmood</keyname><forenames>Abdun Naser</forenames></author></authors><title>Enhanced Estimation of Autoregressive Wind Power Prediction Model Using
  Constriction Factor Particle Swarm Optimization</title><categories>cs.CE cs.NE</categories><comments>The 9th IEEE Conference on Industrial Electronics and Applications
  (ICIEA) 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate forecasting is important for cost-effective and efficient monitoring
and control of the renewable energy based power generation. Wind based power is
one of the most difficult energy to predict accurately, due to the widely
varying and unpredictable nature of wind energy. Although Autoregressive (AR)
techniques have been widely used to create wind power models, they have shown
limited accuracy in forecasting, as well as difficulty in determining the
correct parameters for an optimized AR model. In this paper, Constriction
Factor Particle Swarm Optimization (CF-PSO) is employed to optimally determine
the parameters of an Autoregressive (AR) model for accurate prediction of the
wind power output behaviour. Appropriate lag order of the proposed model is
selected based on Akaike information criterion. The performance of the proposed
PSO based AR model is compared with four well-established approaches;
Forward-backward approach, Geometric lattice approach, Least-squares approach
and Yule-Walker approach, that are widely used for error minimization of the AR
model. To validate the proposed approach, real-life wind power data of
\textit{Capital Wind Farm} was obtained from Australian Energy Market Operator.
Experimental evaluation based on a number of different datasets demonstrate
that the performance of the AR model is significantly improved compared with
benchmark methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4793</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4793</id><created>2014-08-19</created><authors><author><keyname>Matteis</keyname><forenames>Luca</forenames></author></authors><title>Restpark: Minimal RESTful API for Retrieving RDF Triples</title><categories>cs.DB</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  How do RDF datasets currently get published on the Web? They are either
available as large RDF files, which need to be downloaded and processed
locally, or they exist behind complex SPARQL endpoints. By providing a RESTful
API that can access triple data, we allow users to query a dataset through a
simple interface based on just a couple of HTTP parameters. If RDF resources
were published this way we could quickly build applications that depend on
these datasets, without having to download and process them locally. This is
what Restpark is: a set of HTTP GET parameters that servers need to handle, and
respond with JSON-LD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4797</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4797</id><created>2014-08-20</created><authors><author><keyname>Chung</keyname><forenames>Adrian J.</forenames></author><author><keyname>Cobden</keyname><forenames>Kathryn</forenames></author><author><keyname>Jervis</keyname><forenames>Mark</forenames></author><author><keyname>Langhammer</keyname><forenames>Martin</forenames></author><author><keyname>Pasca</keyname><forenames>Bogdan</forenames></author></authors><title>Tools and Techniques for Efficient High-Level System Design on FPGAs</title><categories>cs.OH</categories><comments>Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</comments><proxy>Frank Hannig</proxy><report-no>FSP/2014/01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order for FPGAs to be successful outside traditional markets, tools which
enable software programmers to achieve high levels of system performance while
abstracting away the FPGA-specific details are needed. DSPB Builder Advanced
(DSPBA) is one such tool. DSPBA provides model-based design environment using
Matlab's Simulink frontend that decouples the fully-algorithmic design
description from the details of FPGA system generation. DSPBA offers several
levels of debugging: from Simulink scopes to bit-accurate-simulation and silver
reference models. It also offers the most comprehensive set of fixed-point,
floating-point and signal-processing IPs available today. The combination of 7
floating-point precisions, fused-datapath support, custom operator support and
automated folding allows exploring the best tradeoffs between accuracy, size
and throughput. The DSPBA backend protects users from the details of
device-dependent operator mapping offering both efficiency and prompt support
for new devices and features such as the Arria10 floating-point cores. The
collection of features available in DSPBA allows both unexperienced and expert
users to efficiently migrate performance-crucial systems to the FPGA
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4817</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4817</id><created>2014-08-20</created><authors><author><keyname>Zhou</keyname><forenames>Zhenyu</forenames></author><author><keyname>Dong</keyname><forenames>Mianxiong</forenames></author><author><keyname>Ota</keyname><forenames>Kaoru</forenames></author><author><keyname>Shi</keyname><forenames>Ruifeng</forenames></author><author><keyname>Liu</keyname><forenames>Zhiheng</forenames></author><author><keyname>Sato</keyname><forenames>Takuro</forenames></author></authors><title>A Game-Theoretic Approach to Energy-Efficient Resource Allocation in
  Device-to-Device Underlay Communications</title><categories>cs.GT cs.NI</categories><comments>submitted to IET Communications. arXiv admin note: substantial text
  overlap with arXiv:1405.1963, arXiv:1407.1556</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the numerous benefits brought by Device-to-Device (D2D)
communications, the introduction of D2D into cellular networks poses many new
challenges in the resource allocation design due to the co-channel interference
caused by spectrum reuse and limited battery life of User Equipments (UEs).
Most of the previous studies mainly focus on how to maximize the Spectral
Efficiency (SE) and ignore the energy consumption of UEs. In this paper, we
study how to maximize each UE's Energy Efficiency (EE) in an
interference-limited environment subject to its specific Quality of Service
(QoS) and maximum transmission power constraints. We model the resource
allocation problem as a noncooperative game, in which each player is
self-interested and wants to maximize its own EE. A distributed
interference-aware energy-efficient resource allocation algorithm is proposed
by exploiting the properties of the nonlinear fractional programming. We prove
that the optimum solution obtained by the proposed algorithm is the Nash
equilibrium of the noncooperative game. We also analyze the tradeoff between EE
and SE and derive closed-form expressions for EE and SE gaps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4837</identifier>
 <datestamp>2015-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4837</id><created>2014-08-20</created><updated>2015-03-03</updated><authors><author><keyname>Thrampoulidis</keyname><forenames>Christos</forenames></author><author><keyname>Oymak</keyname><forenames>Samet</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>The Gaussian min-max theorem in the Presence of Convexity</title><categories>cs.IT math.IT math.PR</categories><comments>Significantly extended second version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian comparison theorems are useful tools in probability theory; they are
essential ingredients in the classical proofs of many results in empirical
processes and extreme value theory. More recently, they have been used
extensively in the analysis of non-smooth optimization problems that arise in
the recovery of structured signals from noisy linear observations. We refer to
such problems as Primary Optimization (PO) problems. A prominent role in the
study of the (PO) problems is played by Gordon's Gaussian min-max theorem (GMT)
which provides probabilistic lower bounds on the optimal cost via a simpler
Auxiliary Optimization (AO) problem. Motivated by resent work of M. Stojnic, we
show that under appropriate convexity assumptions the (AO) problem allows one
to tightly bound both the optimal cost, as well as the norm of the solution of
the (PO). As an application, we use our result to develop a general framework
to tightly characterize the performance (e.g. squared-error) of a wide class of
convex optimization algorithms used in the context of noisy signal recovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4841</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4841</id><created>2014-08-20</created><authors><author><keyname>Chen</keyname><forenames>He</forenames></author><author><keyname>Zhou</keyname><forenames>Xiangyun</forenames></author><author><keyname>Li</keyname><forenames>Yonghui</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Vucetic</keyname><forenames>Branka</forenames></author></authors><title>Wireless-Powered Cooperative Communications via a Hybrid Relay</title><categories>cs.IT math.IT</categories><comments>Conference submission accepted by ITW 2014, 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a wireless-powered cooperative communication
network, which consists of a hybrid access-point (AP), a hybrid relay, and an
information source. In contrast to the conventional cooperative networks, the
source in the considered network is assumed to have no embedded energy supply.
Thus, it first needs to harvest energy from the signals broadcast by the AP
and/or relay, which have constant power supply, in the downlink (DL) before
transmitting the information to the AP in the uplink (UL). The hybrid relay can
not only help to forward information in the UL but also charge the source with
wireless energy transfer in the DL. Considering different possible operations
of the hybrid relay, we propose two cooperative protocols for the considered
network. We jointly optimize the time and power allocation for DL energy
transfer and UL information transmission to maximize the system throughput of
the proposed protocols. Numerical results are presented to compare the
performance of the proposed protocols and illustrate the impacts of system
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4846</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4846</id><created>2014-08-20</created><authors><author><keyname>Cao</keyname><forenames>Zhengjun</forenames></author><author><keyname>Liu</keyname><forenames>Lihua</forenames></author></authors><title>Remarks on the Cryptographic Primitive of Attribute-based Encryption</title><categories>cs.CR</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attribute-based encryption (ABE) which allows users to encrypt and decrypt
messages based on user attributes is a type of one-to-many encryption. Unlike
the conventional one-to-one encryption which has no intention to exclude any
partners of the intended receiver from obtaining the plaintext, an ABE system
tries to exclude some unintended recipients from obtaining the plaintext
whether they are partners of some intended recipients. We remark that this
requirement for ABE is very hard to meet. An ABE system cannot truly exclude
some unintended recipients from decryption because some users can exchange
their decryption keys in order to maximize their own interests. The flaw
discounts the importance of the cryptographic primitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4849</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4849</id><created>2014-08-20</created><authors><author><keyname>Anwar</keyname><forenames>Adnan</forenames></author><author><keyname>Mahmood</keyname><forenames>A. N.</forenames></author></authors><title>Swarm Intelligence Based Multi-phase OPF For Peak Power Loss Reduction
  In A Smart Grid</title><categories>cs.CE cs.NE</categories><comments>IEEE PES GM 2014, Washington DC, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently there has been increasing interest in improving smart grids
efficiency using computational intelligence. A key challenge in future smart
grid is designing Optimal Power Flow tool to solve important planning problems
including optimal DG capacities. Although, a number of OPF tools exists for
balanced networks there is a lack of research for unbalanced multi-phase
distribution networks. In this paper, a new OPF technique has been proposed for
the DG capacity planning of a smart grid. During the formulation of the
proposed algorithm, multi-phase power distribution system is considered which
has unbalanced loadings, voltage control and reactive power compensation
devices. The proposed algorithm is built upon a co-simulation framework that
optimizes the objective by adapting a constriction factor Particle Swarm
optimization. The proposed multi-phase OPF technique is validated using IEEE
8500-node benchmark distribution system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4853</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4853</id><created>2014-08-20</created><authors><author><keyname>de Lamare</keyname><forenames>R. C.</forenames></author><author><keyname>Neto</keyname><forenames>R. Sampaio</forenames></author></authors><title>Detection and Estimation Algorithms in Massive MIMO Systems</title><categories>cs.IT math.IT</categories><comments>7 figures, 14 pages. arXiv admin note: substantial text overlap with
  arXiv:1310.7282</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This book chapter reviews signal detection and parameter estimation
techniques for multiuser multiple-antenna wireless systems with a very large
number of antennas, known as massive multi-input multi-output (MIMO) systems.
We consider both centralized antenna systems (CAS) and distributed antenna
systems (DAS) architectures in which a large number of antenna elements are
employed and focus on the uplink of a mobile cellular system. In particular, we
focus on receive processing techniques that include signal detection and
parameter estimation problems and discuss the specific needs of massive MIMO
systems. Simulation results illustrate the performance of detection and
estimation algorithms under several scenarios of interest. Key problems are
discussed and future trends in massive MIMO systems are pointed out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4859</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4859</id><created>2014-08-20</created><authors><author><keyname>Lee</keyname><forenames>Kooktae</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Raktim</forenames></author></authors><title>Optimal Switching Synthesis for Jump Linear Systems with Gaussian
  initial state uncertainty</title><categories>cs.SY math.OC</categories><comments>ASME Dynamic Systems and Control Conference (DSCC), 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a method to design an optimal switching sequence for jump
linear systems with given Gaussian initial state uncertainty. In the practical
perspective, the initial state contains some uncertainties that come from
measurement errors or sensor inaccuracies and we assume that the type of this
uncertainty has the form of Gaussian distribution. In order to cope with
Gaussian initial state uncertainty and to measure the system performance,
Wasserstein metric that defines the distance between probability density
functions is used. Combining with the receding horizon framework, an optimal
switching sequence for jump linear systems can be obtained by minimizing the
objective function that is expressed in terms of Wasserstein distance. The
proposed optimal switching synthesis also guarantees the mean square stability
for jump linear systems. The validations of the proposed methods are verified
by examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4862</identifier>
 <datestamp>2015-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4862</id><created>2014-08-20</created><updated>2015-07-07</updated><authors><author><keyname>Mazumdar</keyname><forenames>Arya</forenames></author></authors><title>Storage Capacity of Repairable Networks</title><categories>cs.IT cs.DM cs.NI math.IT</categories><comments>This is an extended version of an ISIT 2014 paper. Accepted in IEEE
  Transactions in information theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a model of a distributed storage system that is
locally recoverable from any single server failure. Unlike the usual local
recovery model of codes for distributed storage, this model accounts for the
fact that each server or storage node in a network is connectible to only some,
and not all other, nodes. This may happen for reasons such as physical
separation, inhomogeneity in storage platforms etc. We estimate the storage
capacity of both undirected and directed networks under this model and propose
some constructive schemes. From a coding theory point of view, we show that
this model is approximately dual of the well-studied index coding problem.
  Further in this paper, we extend the above model to handle multiple server
failures. Among other results, we provide an upper bound on the minimum
pairwise distance of a set of words that can be stored in a graph with the
local repair guarantee. The well-known impossibility bounds on the distance of
locally recoverable codes follow from our result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4878</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4878</id><created>2014-08-21</created><authors><author><keyname>Werth</keyname><forenames>Stephan</forenames></author><author><keyname>St&#xf6;bener</keyname><forenames>Katrin</forenames></author><author><keyname>Klein</keyname><forenames>Peter</forenames></author><author><keyname>K&#xfc;fer</keyname><forenames>Karl-Heinz</forenames></author><author><keyname>Horsch</keyname><forenames>Martin</forenames></author><author><keyname>Hasse</keyname><forenames>Hans</forenames></author></authors><title>Molecular modelling and simulation of the surface tension of real
  quadrupolar fluids</title><categories>physics.comp-ph cond-mat.soft cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Molecular modelling and simulation of the surface tension of fluids with
force fields is discussed. 29 real fluids are studied, including nitrogen,
oxygen, carbon dioxide, carbon monoxide, fluorine, chlorine, bromine, iodine,
ethane, ethylene, acetylene, propyne, propylene, propadiene, carbon disulfide,
sulfur hexafluoride, and many refrigerants. The fluids are represented by
two-centre Lennard-Jones plus point quadrupole models from the literature.
These models were adjusted only to experimental data of the vapour pressure and
saturated liquid density so that the results for the surface tension are
predictions. The deviations between the predictions and experimental data for
the surface tension are of the order of 20 percent. The surface tension is
usually overestimated by the models. For further improvements, data on the
surface tension can be included in the model development. A suitable strategy
for this is multi-criteria optimization based on Pareto sets. This is
demonstrated using the model for carbon dioxide as an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4882</identifier>
 <datestamp>2014-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4882</id><created>2014-08-21</created><updated>2014-10-22</updated><authors><author><keyname>Hosseinmardi</keyname><forenames>Homa</forenames></author><author><keyname>Rafiq</keyname><forenames>Rahat Ibn</forenames></author><author><keyname>Li</keyname><forenames>Shaosong</forenames></author><author><keyname>Yang</keyname><forenames>Zhili</forenames></author><author><keyname>Han</keyname><forenames>Richard</forenames></author><author><keyname>Mishra</keyname><forenames>Shivakant</forenames></author><author><keyname>Lv</keyname><forenames>Qin</forenames></author></authors><title>A Comparison of Common Users across Instagram and Ask.fm to Better
  Understand Cyberbullying</title><categories>cs.SI cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines users who are common to two popular online social
networks, Instagram and Ask.fm, that are often used for cyberbullying. An
analysis of the negativity and positivity of word usage in posts by common
users of these two social networks is performed. These results are normalized
in comparison to a sample of typical users in both networks. We also examine
the posting activity of common user profiles and consider its correlation with
negativity. Within the Ask.fm social network, which allows anonymous posts, the
relationship between anonymity and negativity is further explored.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4899</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4899</id><created>2014-08-21</created><authors><author><keyname>Mahajan</keyname><forenames>Ginika</forenames></author><author><keyname>Ashima</keyname></author></authors><title>Software Cloning in Extreme Programming Environment</title><categories>cs.SE</categories><comments>14 pages</comments><journal-ref>International Journal of Research in Engineering &amp; Applied
  Sciences, VOl 2, Issue 2,2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software systems are evolving by adding new functions and modifying existing
functions over time. Through the evolution, the structure of software is
becoming more complex and so the understandability and maintainability of
software systems is deteriorating day by day. These are not only important but
one of the most expensive activities in software development. Refactoring has
often been applied to the software to improve them. One of the targets of
refactoring is to limit Code Cloning because it hinders software maintenance
and affects its quality. And in order to cope with the constant changes,
refactoring is seen as an essential component of Extreme Programming. Agile
Methods use refactoring as important key practice and are first choice for
developing clone-free code. This paper summarizes my overview talk on software
cloning analysis. It first discusses the notion of code cloning, types of
clones, reasons, its consequences and analysis. It highlights Code Cloning in
Extreme Programming Environment and finds Clone Detection as effective tool for
Refactoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4900</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4900</id><created>2014-08-21</created><authors><author><keyname>Lindzey</keyname><forenames>Nathan</forenames></author></authors><title>Speeding Up Graph Algorithms via Switching Classes</title><categories>cs.DS</categories><comments>To appear in IWOCA 2014: 25th International Workshop on Combinatorial
  Algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph $G$, a vertex switch of $v \in V(G)$ results in a new graph
where neighbors of $v$ become nonneighbors and vice versa. This operation gives
rise to an equivalence relation over the set of labeled digraphs on $n$
vertices. The equivalence class of $G$ with respect to the switching operation
is commonly referred to as $G$'s switching class. The algebraic and
combinatorial properties of switching classes have been studied in depth;
however, they have not been studied as thoroughly from an algorithmic point of
view. The intent of this work is to further investigate the algorithmic
properties of switching classes. In particular, we show that switching classes
can be used to asymptotically speed up several super-linear unweighted graph
algorithms. The current techniques for speeding up graph algorithms are all
somewhat involved insofar that they employ sophisticated pre-processing,
data-structures, or use &quot;word tricks&quot; on the RAM model to achieve at most a
$O(\log(n))$ speed up for sufficiently dense graphs. Our methods are much
simpler and can result in super-polylogarithmic speedups. In particular, we
achieve better bounds for diameter, transitive closure, bipartite maximum
matching, and general maximum matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4901</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4901</id><created>2014-08-21</created><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Cahan</keyname><forenames>Casey</forenames></author><author><keyname>Gretton</keyname><forenames>Charles</forenames></author><author><keyname>Kilby</keyname><forenames>Phillip</forenames></author><author><keyname>Mattei</keyname><forenames>Nicholas</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>A Study of Proxies for Shapley Allocations of Transport Costs</title><categories>cs.GT cs.AI cs.MA math.OC</categories><comments>51 Pages: 1-35 Main Document, 36-51 Appendices A--E</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose and evaluate a number of solutions to the problem of calculating
the cost to serve each location in a single-vehicle transport setting. Such
cost to serve analysis has application both strategically and operationally in
transportation. The problem is formally given by the traveling salesperson game
(TSG), a cooperative total utility game in which agents correspond to locations
in a traveling salesperson problem (TSP). The cost to serve a location is an
allocated portion of the cost of an optimal tour. The Shapley value is one of
the most important normative division schemes in cooperative games, giving a
principled and fair allocation both for the TSG and more generally. We consider
a number of direct and sampling-based procedures for calculating the Shapley
value, and present the first proof that approximating the Shapley value of the
TSG within a constant factor is NP-hard. Treating the Shapley value as an ideal
baseline allocation, we then develop six proxies for that value which are
relatively easy to compute. We perform an experimental evaluation using
Synthetic Euclidean games as well as games derived from real-world tours
calculated for fast-moving consumer goods scenarios. Our experiments show that
several computationally tractable allocation techniques correspond to good
proxies for the Shapley value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4902</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4902</id><created>2014-08-21</created><authors><author><keyname>Alam</keyname><forenames>Md. Jawaherul</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Kobourov</keyname><forenames>Stephen G.</forenames></author><author><keyname>Pupyrev</keyname><forenames>Sergey</forenames></author></authors><title>Balanced Circle Packings for Planar Graphs</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study balanced circle packings and circle-contact representations for
planar graphs, where the ratio of the largest circle's diameter to the smallest
circle's diameter is polynomial in the number of circles. We provide a number
of positive and negative results for the existence of such balanced
configurations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4908</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4908</id><created>2014-08-21</created><updated>2015-05-12</updated><authors><author><keyname>Reshef</keyname><forenames>Yakir A.</forenames></author><author><keyname>Reshef</keyname><forenames>David N.</forenames></author><author><keyname>Sabeti</keyname><forenames>Pardis C.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author></authors><title>Theoretical Foundations of Equitability and the Maximal Information
  Coefficient</title><categories>stat.ME cs.IT math.IT math.ST q-bio.QM stat.ML stat.TH</categories><comments>46 pages, 3 figures, 2 tables. This paper has been subsumed by
  arXiv:1505.02213 and arXiv:1505.02212. Please cite those papers instead</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maximal information coefficient (MIC) is a tool for finding the strongest
pairwise relationships in a data set with many variables (Reshef et al., 2011).
MIC is useful because it gives similar scores to equally noisy relationships of
different types. This property, called {\em equitability}, is important for
analyzing high-dimensional data sets.
  Here we formalize the theory behind both equitability and MIC in the language
of estimation theory. This formalization has a number of advantages. First, it
allows us to show that equitability is a generalization of power against
statistical independence. Second, it allows us to compute and discuss the
population value of MIC, which we call MIC_*. In doing so we generalize and
strengthen the mathematical results proven in Reshef et al. (2011) and clarify
the relationship between MIC and mutual information. Introducing MIC_* also
enables us to reason about the properties of MIC more abstractly: for instance,
we show that MIC_* is continuous and that there is a sense in which it is a
canonical &quot;smoothing&quot; of mutual information. We also prove an alternate,
equivalent characterization of MIC_* that we use to state new estimators of it
as well as an algorithm for explicitly computing it when the joint probability
density function of a pair of random variables is known. Our hope is that this
paper provides a richer theoretical foundation for MIC and equitability going
forward.
  This paper will be accompanied by a forthcoming companion paper that performs
extensive empirical analysis and comparison to other methods and discusses the
practical aspects of both equitability and the use of MIC and its related
statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4910</identifier>
 <datestamp>2015-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4910</id><created>2014-08-21</created><updated>2015-02-02</updated><authors><author><keyname>Zhao</keyname><forenames>Kai</forenames></author><author><keyname>Musolesi</keyname><forenames>Mirco</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Rao</keyname><forenames>Weixiong</forenames></author><author><keyname>Tarkoma</keyname><forenames>Sasu</forenames></author></authors><title>Explaining the Power-law Distribution of Human Mobility Through
  Transportation Modality Decomposition</title><categories>physics.soc-ph cs.SI physics.data-an</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human mobility has been empirically observed to exhibit Levy flight
characteristics and behaviour with power-law distributed jump size. The
fundamental mechanisms behind this behaviour has not yet been fully explained.
In this paper, we analyze urban human mobility and we propose to explain the
Levy walk behaviour observed in human mobility patterns by decomposing them
into different classes according to the different transportation modes, such as
Walk/Run, Bicycle, Train/Subway or Car/Taxi/Bus. Our analysis is based on two
real-life GPS datasets containing approximately 10 and 20 million GPS samples
with transportation mode information. We show that human mobility can be
modelled as a mixture of different transportation modes, and that these single
movement patterns can be approximated by a lognormal distribution rather than a
power-law distribution. Then, we demonstrate that the mixture of the decomposed
lognormal flight distributions associated with each modality is a power-law
distribution, providing an explanation to the emergence of Levy Walk patterns
that characterize human mobility patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4925</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4925</id><created>2014-08-21</created><authors><author><keyname>Chen</keyname><forenames>Scott Deeann</forenames></author></authors><title>A Crude Analysis of Twitch Plays Pokemon</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We model and study the game mechanisms and human behavior of the anarchy mode
in Twitch Plays Pokemon with a pure-jump continuous-time Markov process. We
computed the winning probability and expected game time for $1$ player and $N$
players and identified when collaboration helps. A numerical plug-in example is
also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4933</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4933</id><created>2014-08-21</created><authors><author><keyname>Aichholzer</keyname><forenames>Oswin</forenames></author><author><keyname>Hackl</keyname><forenames>Thomas</forenames></author><author><keyname>Lutteropp</keyname><forenames>Sarah</forenames></author><author><keyname>Mchedlidze</keyname><forenames>Tamara</forenames></author><author><keyname>Vogtenhuber</keyname><forenames>Birgit</forenames></author></authors><title>Embedding Four-directional Paths on Convex Point Sets</title><categories>cs.CG</categories><comments>11 pages, full conference version including all proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A directed path whose edges are assigned labels &quot;up&quot;, &quot;down&quot;, &quot;right&quot;, or
&quot;left&quot; is called \emph{four-directional}, and \emph{three-directional} if at
most three out of the four labels are used. A \emph{direction-consistent
embedding} of an \mbox{$n$-vertex} four-directional path $P$ on a set $S$ of
$n$ points in the plane is a straight-line drawing of $P$ where each vertex of
$P$ is mapped to a distinct point of $S$ and every edge points to the direction
specified by its label. We study planar direction-consistent embeddings of
three- and four-directional paths and provide a complete picture of the problem
for convex point sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4939</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4939</id><created>2014-08-21</created><authors><author><keyname>Arap</keyname><forenames>Omer</forenames></author><author><keyname>Swany</keyname><forenames>Martin</forenames></author></authors><title>Offloading MPI Parallel Prefix Scan (MPI_Scan) with the NetFPGA</title><categories>cs.DC</categories><comments>Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</comments><proxy>Frank Hannig</proxy><report-no>FSP/2014/06</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel programs written using the standard Message Passing Interface (MPI)
frequently depend upon the ability to efficiently execute collective
operations. MPI_Scan is a collective operation defined in MPI that implements
parallel prefix scan which is very useful primitive operation in several
parallel applications. This operation can be very time consuming. In this
paper, we explore the use of hardware programmable network interface cards
utilizing standard media access protocols for offloading the MPI_Scan operation
to the underlying network. Our work is based upon the NetFPGA - a programmable
network interface with an on-board Virtex FPGA and four Ethernet interfaces. We
have implemented a network-level MPI_Scan operation using the NetFPGA for use
in MPI environments. This paper compares the performance of this implementation
with MPI over Ethernet for a small configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4942</identifier>
 <datestamp>2014-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4942</id><created>2014-08-21</created><authors><author><keyname>Dwivedi</keyname><forenames>Shri Prakash</forenames></author></authors><title>Computing Multiplicative Order and Primitive Root in Finite Cyclic Group</title><categories>cs.SC cs.DS</categories><comments>8 pages</comments><doi>10.1109/IC3.2014.6897161</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiplicative order of an element $a$ of group $G$ is the least positive
integer $n$ such that $a^n=e$, where $e$ is the identity element of $G$. If the
order of an element is equal to $|G|$, it is called generator or primitive
root. This paper describes the algorithms for computing multiplicative order
and primitive root in $\mathbb{Z}^*_{p}$, we also present a logarithmic
improvement over classical algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4944</identifier>
 <datestamp>2014-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4944</id><created>2014-08-21</created><updated>2014-09-12</updated><authors><author><keyname>Gupta</keyname><forenames>Neelima</forenames></author><author><keyname>Gupta</keyname><forenames>Shubham</forenames></author></authors><title>Approximation algorithms for Capacitated Facility Location Problem with
  Penalties</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of capacitated facility location
problem with penalties (CapFLPP) paid per unit of unserved demand. In case of
uncapacitated FLP with penalties demands of a client are either entirely met or
are entirely rejected and penalty is paid. In the uncapacitated case, there is
no reason to serve a client partially. Whereas, in case of CapFLPP, it may be
beneficial to serve a client partially instead of not serving at all and, pay
the penalty for the unmet demand. Charikar et. al.
\cite{charikar2001algorithms}, Jain et. al. \cite{jain2003greedy} and Xu- Xu
\cite{xu2009improved} gave $3$, $2$ and $1.8526$ approximation, respectively,
for the uncapacitated case . We present $(5.83 + \epsilon)$ factor for the case
of uniform capacities and $(8.532 + \epsilon)$ factor for non-uniform
capacities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4955</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4955</id><created>2014-08-21</created><authors><author><keyname>Lust</keyname><forenames>Thibaut</forenames></author><author><keyname>Meskens</keyname><forenames>Nadine</forenames></author><author><keyname>Ahues</keyname><forenames>Mario</forenames></author></authors><title>Predicting academic success in Belgium and France Comparison and
  integration of variables related to student behavior</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Having observed low success rates among first-year university students in
both Belgium and France, we develop prediction models in this paper in order to
identify, at the earliest possible stage, those students who are at risk of
failing at the end of the academic year. We applied different data mining
techniques to predict the students' academic success. We find that it is very
difficult to predict success by only considering the variables related to
behavior during classes, and that it is necessary to add variables related to
personal history, involvement in and behavior during their studies, and
perceptions of academic life, to obtain good-quality results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4959</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4959</id><created>2014-08-21</created><authors><author><keyname>Willenberg</keyname><forenames>Ruediger</forenames></author><author><keyname>Chow</keyname><forenames>Paul</forenames></author></authors><title>A Software Parallel Programming Approach to FPGA-Accelerated Computing</title><categories>cs.DC</categories><comments>Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</comments><proxy>Frank Hannig</proxy><report-no>FSP/2014/08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an effort to incorporate reconfigurable logic (FPGA)
components into a software programming model. For this purpose, we have
implemented a hardware engine for remote memory communication between hardware
computation nodes and CPUs. The hardware engine is compatible with the API of
GASNet, a popular communication library used for parallel computing
applications. We have further implemented our own x86 and ARMv7 software
versions of the GASNet Core API, enabling us to write distributed applications
with software and hardware GASNet components transparently communicating with
each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4963</identifier>
 <datestamp>2015-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4963</id><created>2014-08-21</created><updated>2015-05-05</updated><authors><author><keyname>Buzaglo</keyname><forenames>Sarit</forenames></author><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Optimal Permutation Codes and the Kendall's $\tau$-Metric</title><categories>cs.IT math.IT</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rank modulation scheme has been proposed for efficient writing and
storing data in non-volatile memory storage. Error-correction in the rank
modulation scheme is done by considering permutation codes. In this paper we
consider codes in the set of all permutations on $n$ elements, $S_n$, using the
Kendall's $\tau$-metric. We will consider either optimal codes such as perfect
codes or concepts related to optimal codes. We prove that there are no perfect
single-error-correcting codes in $S_n$, where $n&gt;4$ is a prime or $4\leq n\leq
10$. We also prove that if such a code exists for $n$ which is not a prime then
the code should have some uniform structure. We consider optimal anticodes and
diameter perfect codes in $S_n$. As a consequence we obtain a new upper bound
on the size of a code in $S_n$ with even minimum Kendall's $\tau$-distance. We
define some variations of the Kendall's $\tau$-metric and consider the related
codes. Specifically, we present perfect single-error-correcting codes in $S_5$
for these variations. Furthermore, using these variations we present larger
codes than the known ones in $S_5$ and $S_7$ with the Kendall's $\tau$-metric.
These codes have a large automorphism group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4964</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4964</id><created>2014-08-21</created><authors><author><keyname>Segal</keyname><forenames>Oren</forenames></author><author><keyname>Margala</keyname><forenames>Martin</forenames></author><author><keyname>Chalamalasetti</keyname><forenames>Sai Rahul</forenames></author><author><keyname>Wright</keyname><forenames>Mitch</forenames></author></authors><title>High Level Programming for Heterogeneous Architectures</title><categories>cs.PF cs.PL</categories><comments>Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</comments><proxy>Frank Hannig</proxy><report-no>FSP/2014/10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents an effort to bridge the gap between abstract high level
programming and OpenCL by extending an existing high level Java programming
framework (APARAPI), based on OpenCL, so that it can be used to program FPGAs
at a high level of abstraction and increased ease of programmability. We run
several real world algorithms to assess the performance of the framework on
both a low end and a high end system. On the low end and high end systems
respectively we observed up to 78-80 percent power reduction and 4.8X-5.3X
speed increase running NBody simulation, as well as up to 65-80 percent power
reduction and 6.2X-7X speed increase for a KMeans, MapReduce algorithm running
on top of the Hadoop framework and APARAPI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4965</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4965</id><created>2014-08-21</created><authors><author><keyname>Inggs</keyname><forenames>Gordon</forenames></author><author><keyname>Thomas</keyname><forenames>David</forenames></author><author><keyname>Luk</keyname><forenames>Wayne</forenames></author></authors><title>A Domain Specific Approach to Heterogeneous Computing: From Availability
  to Accessibility</title><categories>cs.CE cs.DC cs.PF cs.PL</categories><comments>Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</comments><proxy>Frank Hannig</proxy><report-no>FSP/2014/11</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We advocate a domain specific software development methodology for
heterogeneous computing platforms such as Multicore CPUs, GPUs and FPGAs. We
argue that three specific benefits are realised from adopting such an approach:
portable, efficient implementations across heterogeneous platforms; domain
specific metrics of quality that characterise platforms in a form software
developers will understand; automatic, optimal partitioning across the
available computing resources. These three benefits allow a development
methodology for software developers where they describe their computational
problems in a single, easy to understand form, and after a modeling procedure
on the available resources, select how they would like to trade between various
domain specific metrics. Our work on the Forward Financial Framework ($F^3$)
demonstrates this methodology in practise. We are able to execute a range of
computational finance option pricing tasks efficiently upon a wide range of
CPU, GPU and FPGA computing platforms. We can also create accurate financial
domain metric models of walltime latency and statistical confidence.
Furthermore, we believe that we can support automatic, optimal partitioning
using this execution and modelling capability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4966</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4966</id><created>2014-08-21</created><updated>2015-06-25</updated><authors><author><keyname>Dubuisson</keyname><forenames>Jimmy</forenames></author><author><keyname>Eckmann</keyname><forenames>Jean-Pierre</forenames></author><author><keyname>Agazzi</keyname><forenames>Andrea</forenames></author></authors><title>Diffusion Fingerprints</title><categories>stat.ML cs.IR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce, test and discuss a method for classifying and clustering data
modeled as directed graphs. The idea is to start diffusion processes from any
subset of a data collection, generating corresponding distributions for
reaching points in the network. These distributions take the form of
high-dimensional numerical vectors and capture essential topological properties
of the original dataset. We show how these diffusion vectors can be
successfully applied for getting state-of-the-art accuracies in the problem of
extracting pathways from metabolic networks. We also provide a guideline to
illustrate how to use our method for classification problems, and discuss
important details of its implementation. In particular, we present a simple
dimensionality reduction technique that lowers the computational cost of
classifying diffusion vectors, while leaving the predictive power of the
classification process substantially unaltered. Although the method has very
few parameters, the results we obtain show its flexibility and power. This
should make it helpful in many other contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4969</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4969</id><created>2014-08-21</created><authors><author><keyname>Miyajima</keyname><forenames>Takaaki</forenames></author><author><keyname>Thomas</keyname><forenames>David</forenames></author><author><keyname>Amano</keyname><forenames>Hideharu</forenames></author></authors><title>An Automatic Mixed Software Hardware Pipeline Builder for CPU-FPGA
  Platforms</title><categories>cs.DC cs.SY</categories><comments>Presented at First International Workshop on FPGAs for Software
  Programmers (FSP 2014) (arXiv:1408.4423)</comments><proxy>Frank Hannig</proxy><report-no>FSP/2014/13</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our toolchain for accelerating application called Courier-FPGA, is designed
for utilize the processing power of CPU-FPGA platforms for software programmers
and non-expert users. It automatically gathers runtime information of library
functions from a running target binary, and constructs the function call graph
including input-output data. Then, it uses corresponding predefined hardware
modules if these are ready for FPGA and prepares software functions on CPU by
using Pipeline Generator. The Pipeline Generator builds a pipeline control
program by using Intel Threading Building Block to run both hardware modules
and software functions in parallel. Finally, Courier-FPGA dynamically replaces
the original functions in the binary and accelerates it by using the built
pipeline. Courier-FPGA performs these acceleration processes without user
intervention, source code tweaks or re-compilations of the binary. We describe
the technical details of this mixed software hardware pipeline on CPU-FPGA
platforms in this paper. In our case study, Courier-FPGA was used to accelerate
a corner detection using the Harris-Stephens method application binary on the
Zynq platform. A series of functions were off-loaded, and speed up 15.36 times
was achieved by using the built pipeline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4974</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4974</id><created>2014-08-21</created><authors><author><keyname>Kolassa</keyname><forenames>Carsten</forenames></author><author><keyname>Riehle</keyname><forenames>Dirk</forenames></author><author><keyname>Salim</keyname><forenames>Michel A.</forenames></author></authors><title>A Model of the Commit Size Distribution of Open Source</title><categories>cs.SE</categories><comments>17 pages, 7 figures. Proceedings of the 39th International Conference
  on Current Trends in Theory and Practice of Computer Science (SOFSEM 2013),
  LNCS 7741. Page 52-66. Springer Verlag, 2013</comments><acm-class>D.2.8; D.2.9; D.m</acm-class><journal-ref>Proceedings of the 39th International Conference on Current Trends
  in Theory and Practice of Computer Science (SOFSEM 2013), LNCS 7741. Page
  52-66. Springer Verlag, 2013</journal-ref><doi>10.1007/978-3-642-35843-2_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental unit of work in programming is the code contribution (&quot;commit&quot;)
that a developer makes to the code base of the project in work. We use
statistical methods to derive a model of the probabilistic distribution of
commit sizes in open source projects and we show that the model is applicable
to different project sizes. We use both graphical as well as statistical
methods to validate the goodness of fit of our model. By measuring and modeling
a fundamental dimension of programming we help improve software development
tools and our understanding of software development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4978</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4978</id><created>2014-08-21</created><authors><author><keyname>Kolassa</keyname><forenames>Carsten</forenames></author><author><keyname>Riehle</keyname><forenames>Dirk</forenames></author><author><keyname>Salim</keyname><forenames>Michel A.</forenames></author></authors><title>The Empirical Commit Frequency Distribution of Open Source Projects</title><categories>cs.SE</categories><comments>8 pages, 7 figures. WikiSym '13 Proceedings of the 9th International
  Symposium on Open Collaboration</comments><acm-class>D.2.8; D.2.9; D.m</acm-class><journal-ref>Proceedings of the 2013 Joint International Symposium on Wikis and
  Open Collaboration (WikiSym + OpenSym 2013). Page 18:1--18:8. ACM, 2013</journal-ref><doi>10.1145/2491055.2491073</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental unit of work in programming is the code contribution (&quot;commit&quot;)
that a developer makes to the code base of the project in work. An author's
commit frequency describes how often that author commits. Knowing the
distribution of all commit frequencies is a fundamental part of understanding
software development processes. This paper presents a detailed quantitative
analysis of commit frequencies in open-source software development. The
analysis is based on a large sample of open source projects, and presents the
overall distribution of commit frequencies. We analyze the data to show the
differences between authors and projects by project size; we also includes a
comparison of successful and non successful projects and we derive an activity
indicator from these analyses. By measuring a fundamental dimension of
programming we help improve software development tools and our understanding of
software development. We also validate some fundamental assumptions about
software development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4986</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4986</id><created>2014-08-21</created><authors><author><keyname>Kolassa</keyname><forenames>Carsten</forenames></author><author><keyname>Dieckow</keyname><forenames>David</forenames></author><author><keyname>Hirsch</keyname><forenames>Michael</forenames></author><author><keyname>Creutzburg</keyname><forenames>Uwe</forenames></author><author><keyname>Siemers</keyname><forenames>Christian</forenames></author><author><keyname>Rumpe</keyname><forenames>Bernhard</forenames></author></authors><title>Objektorientierte Graphendarstellung von Simulink-Modellen zur einfachen
  Analyse und Transformation</title><categories>cs.SE</categories><comments>10 pages in German, 7 figures. AALE 2013 in Stralsund Germany, 10.
  Fachkonferenz, Das Forum f\&quot;ur Fachleute der Automatisierungstechnik aus
  Hochschulen und Wirtschaft, 2013</comments><journal-ref>Tagungsband AALE 2013, 10. Fachkonferenz, Das Forum f\&quot;ur
  Fachleute der Automatisierungstechnik aus Hochschulen und Wirtschaft, pages
  277-286, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In software and hardware development MATLAB and Simulink are used to model
cyber physical systems for many years, , especially in automation technology
and the automotive industry. Compliance with the required product quality and
project efficiency is facilitated by analyzing and transforming Simulink
models. The existing API, provided by MATLAB is only suitable for programmatic
changing of Simulink models. We show using our own tool which is used in
industry, how such as a Simulink model can be edited more easily. For this
purpose the model, is converted to an object-oriented class structure that
provides convenient access and editing APIs and allows applying well-known
algorithms and analyses from graph theory directly. It is also designed as a
bi-directional tool, so it transforms a Simulink model into a graph
representation and vice versa.
  -----
  In der Software- und Hardwareentwicklung wird seit Jahren verst\&quot;arkt MATLAB
und Simulink f\&quot;ur die Modellierung von cyberphysikalischen Systemen,
insbesondere in der Automatisierungstechnik und der Automobilindustrie
eingesetzt. Die Einhaltung der notwendigen Produktqualit\&quot;at und
Projekteffizienz wird durch Analysen und Transformationen auf Simulink-Modellen
erleichtert. Die bestehende, von MATLAB bereitgestellte, API ist f\&quot;ur die
programmatische Ver\&quot;anderung von Simulink-Modellen nur bedingt geeignet. Wir
zeigen deshalb anhand eines eigenen, im industriellen Einsatz befindlichen
Werkzeugs, wie ein Simulink-Modell leichter bearbeitet werden kann. Dazu wird
es in eine objektorientierte Klassenstruktur \&quot;uberf\&quot;uhrt, die einen
komfortablen Zugang und Bearbeitungs-APIs bietet und es erlaubt bekannte
Algorithmen und Analysen aus der Graphentheorie direkt anzuwenden. Das Werkzeug
ist bidirektional entworfen, es transformiert also ein Simulink-Modell in eine
Graphenrepresentation und umgekehrt.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4992</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4992</id><created>2014-08-21</created><authors><author><keyname>Farhat</keyname><forenames>Soha</forenames><affiliation>IRISA, UL</affiliation></author><author><keyname>Ellatif</keyname><forenames>Samhat Abed</forenames><affiliation>UL</affiliation></author><author><keyname>Lahoud</keyname><forenames>Samer</forenames><affiliation>IRISA</affiliation></author><author><keyname>Cousin</keyname><forenames>Bernard</forenames><affiliation>IRISA</affiliation></author></authors><title>Best Operator Policy in a Heterogeneous Wireless Network</title><categories>cs.NI</categories><comments>ICeND, Beyrouth : Lebanon (2014)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we perform a business analysis of our hybrid decision
algorithm for the selection of the access in a multi-operator networks
environment. We investigate the ability of the operator to express his strategy
and influence the access selection for his client. In this purpose, we study
two important coefficients of the previously proposed cost function, Wu and
Wop, and show that the value of these coefficients is not arbitrary. Simulation
results show that the value of the ratio Wu/Wop enables a selection decision
respecting operator's strategy and it affects the achieved global profit for
all cooperating operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.4994</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.4994</id><created>2014-08-21</created><authors><author><keyname>Pham</keyname><forenames>Khanh</forenames></author><author><keyname>Lee</keyname><forenames>Kyungchun</forenames></author></authors><title>Interference Alignment for Multicell Multiuser MIMO Uplink Channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing, Jan., 2014</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a linear interference alignment (IA) scheme which can be
used for uplink channels in a general multicell multiuser MIMO cellular
network. The proposed scheme aims to align interference caused by signals from
a set of transmitters into a subspace which is established by the signals from
only a subset of those transmitters, thereby effectively reducing the number of
interfering transmitters. The total degrees of freedom (DoF) achievable by the
proposed scheme is given in closed-form expression, and a numerical analysis
shows that the proposed scheme can achieve the optimal DoF in certain scenarios
and provides a higher total DoF than other related schemes in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5001</identifier>
 <datestamp>2014-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5001</id><created>2014-08-21</created><updated>2014-10-01</updated><authors><author><keyname>van Hoek</keyname><forenames>Wilko</forenames></author><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author></authors><title>Is Evaluating Visual Search Interfaces in Digital Libraries Still an
  Issue?</title><categories>cs.IR cs.DL cs.HC</categories><comments>10 pages, 2 figures, LWA Workshop 2014</comments><msc-class>68U35</msc-class><acm-class>H.3.7; H.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although various visual interfaces for digital libraries have been developed
in prototypical systems, very few of these visual approaches have been
integrated into today's digital libraries. In this position paper we argue that
this is most likely due to the fact that the evaluation results of most visual
systems lack comparability. There is no fix standard on how to evaluate visual
interactive user interfaces. Therefore it is not possible to identify which
approach is more suitable for a certain context. We feel that the comparability
of evaluation results could be improved by building a common evaluation setup
consisting of a reference system, based on a standardized corpus with fixed
tasks and a panel for possible participants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5027</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5027</id><created>2014-08-21</created><authors><author><keyname>Minder</keyname><forenames>Lorenz</forenames></author><author><keyname>Sauerwald</keyname><forenames>Thomas</forenames></author><author><keyname>Wegner</keyname><forenames>Sven-Ake</forenames></author></authors><title>Asymptotic bounds on the equilateral dimension of hypercubes</title><categories>cs.DM math.CO</categories><comments>6 pages</comments><msc-class>Primary 05C12, Secondary 11H71, 51B20</msc-class><journal-ref>Graphs Combin. 31, no. 5, 1629-1636 (2015)</journal-ref><doi>10.1007/s00373-014-1473-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subset of the finite dimensional hypercube is said to be equilateral if the
distance of any two distinct points equals a fixed value. The equilateral
dimension of the hypercube is defined as the maximal size of its equilateral
subsets. We study asymptotic bounds on the latter quantity considered as a
function of two variables, namely dimension and distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5028</identifier>
 <datestamp>2015-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5028</id><created>2014-08-21</created><updated>2015-09-25</updated><authors><author><keyname>Zeilberger</keyname><forenames>Noam</forenames><affiliation>MSR-Inria</affiliation></author><author><keyname>Giorgetti</keyname><forenames>Alain</forenames><affiliation>FEMTO-ST Institute</affiliation></author></authors><title>A correspondence between rooted planar maps and normal planar lambda
  terms</title><categories>cs.LO math.CO</categories><comments>Corrected title field in metadata</comments><proxy>LMCS</proxy><journal-ref>LMCS 11 (3:22) 2015</journal-ref><doi>10.2168/LMCS-11(3:22)2015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rooted planar map is a connected graph embedded in the 2-sphere, with one
edge marked and assigned an orientation. A term of the pure lambda calculus is
said to be linear if every variable is used exactly once, normal if it contains
no beta-redexes, and planar if it is linear and the use of variables moreover
follows a deterministic stack discipline. We begin by showing that the sequence
counting normal planar lambda terms by a natural notion of size coincides with
the sequence (originally computed by Tutte) counting rooted planar maps by
number of edges. Next, we explain how to apply the machinery of string diagrams
to derive a graphical language for normal planar lambda terms, extracted from
the semantics of linear lambda calculus in symmetric monoidal closed categories
equipped with a linear reflexive object or a linear reflexive pair. Finally,
our main result is a size-preserving bijection between rooted planar maps and
normal planar lambda terms, which we establish by explaining how Tutte
decomposition of rooted planar maps (into vertex maps, maps with an isthmic
root, and maps with a non-isthmic root) may be naturally replayed in linear
lambda calculus, as certain surgeries on the string diagrams of normal planar
lambda terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5057</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5057</id><created>2014-08-21</created><authors><author><keyname>Fritschek</keyname><forenames>Rick</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>Upper Bounds and Duality Relations of the Linear Deterministic Sum
  Capacity for Cellular Systems</title><categories>cs.IT math.IT</categories><comments>6 pages, to appear in IEEE ICC 2014, Sydney, Australia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The MAC-BC duality of information theory and wireless communications is an
intriguing concept for efficient algorithm design. However, no concept is known
so far for the important cellular channel. To make progress on this front, we
consider in this paper the linear deterministic cellular channel. In
particular, we prove duality of a network with two interfering MACs in each
cell and a network with two interfering BCs in each cell. The operational
region is confined to the weak interference regime. First, achievable schemes
as well as upper bounds will be provided. These bounds are the same for both
channels. We will show, that for specific cases the upper bound corresponds to
the achievable scheme and hence establishing a duality relationship between
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5069</identifier>
 <datestamp>2015-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5069</id><created>2014-08-21</created><updated>2014-08-28</updated><authors><author><keyname>Bagchi</keyname><forenames>Amitabha</forenames></author><author><keyname>Pinotti</keyname><forenames>Cristina</forenames></author><author><keyname>Galhotra</keyname><forenames>Sainyam</forenames></author><author><keyname>Mangla</keyname><forenames>Tarun</forenames></author></authors><title>Optimal Radius for Connectivity in Duty-Cycled Wireless Sensor Networks</title><categories>cs.NI math.PR</categories><comments>To appear in ACM Transactions on Sensor Networks. Brief version
  appeared in Proc. of ACM MSWIM 2013</comments><msc-class>60K35</msc-class><acm-class>C.2.1</acm-class><journal-ref>ACM T Sensor Network 11(2):36, (February 2015)</journal-ref><doi>10.1145/2663353</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the condition on transmission radius needed to achieve
connectivity in duty-cycled wireless sensor networks (briefly, DC-WSN). First,
we settle a conjecture of Das et. al. (2012) and prove that the connectivity
condition on Random Geometric Graphs (RGG), given by Gupta and Kumar (1989),
can be used to derive a weak sufficient condition to achieve connectivity in
DC-WSN. To find a stronger result, we define a new vertex-based random
connection model which is of independent interest. Following a proof technique
of Penrose (1991) we prove that when the density of the nodes approaches
infinity then a finite component of size greater than 1 exists with probability
0 in this model. We use this result to obtain an optimal condition on node
transmission radius which is both necessary and sufficient to achieve
connectivity and is hence optimal. The optimality of such a radius is also
tested via simulation for two specific duty-cycle schemes, called the
contiguous and the random selection duty-cycle scheme. Finally, we design a
minimum-radius duty-cycling scheme that achieves connectivity with a
transmission radius arbitrarily close to the one required in Random Geometric
Graphs. The overhead in this case is that we have to spend some time computing
the schedule.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5072</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5072</id><created>2014-08-21</created><authors><author><keyname>Fritschek</keyname><forenames>Rick</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>Enabling the Multi-User Generalized Degrees of Freedom in the Gaussian
  Cellular Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in IEEE ITW 2014, Hobart, Australia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been major progress over the last decade in understanding the
classical interference channel (IC). Recent key results show that constant bit
gap capacity results can be obtained from linear deterministic models (LDMs).
However, it is widely unrecognized that the time-invariant, frequency-flat
cellular channel, which contains the IC as a special case, possesses some
additional generalized degrees of freedom (GDoF) due to multi-user operation.
This was proved for the LDM cellular channel very recently but is an open
question for the corresponding Gaussian counterpart. In this paper, we close
this gap and provide an achievable sum-rate for the Gaussian cellular channel
which is within a constant bit gap of the LDM sum capacity. We show that the
additional GDoFs from the LDM cellular channel carry over. This is enabled by
signal scale alignment. In particular, the multi-user gain reduces the
interference by half in the 2-user per cell case compared to the IC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5079</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5079</id><created>2014-08-21</created><authors><author><keyname>Kulkarni</keyname><forenames>Varsha S.</forenames></author></authors><title>Temporal Evolution of Social Innovation</title><categories>physics.soc-ph cs.SI nlin.AO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Acceptance of an innovation can occur through mutliple exposures to
individuals who have already accepted it. Presented here is a model to trace
the evolution of an innovation in a social network with a preference $\lambda$,
amidst topological constraints specified mainly by connectivity, $k$ and
population size, $N_k$. With the interplay between properties of innovation and
network structure, the model attempts to explain the variations in patterns of
innovations across social networks. Time in which the propagation attains
highest velocity depends on $\lambda^{-2}k^{-2}N_{k}^{1/2}$. Dynamics in random
networks may lead or lag behind that in scale-free networks depending on the
average connectivity. Hierarchical propagation is evident across connectivity
classes within scale-free networks, as well as across random networks with
distinct topological indices. For highly preferred innovations, the hierarchy
observed within scale-free networks tends to be insignificant. The results have
implications for administering innovations in finite size networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5082</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5082</id><created>2014-08-20</created><authors><author><keyname>Zhao</keyname><forenames>Jun</forenames></author><author><keyname>Ya&#x11f;an</keyname><forenames>Osman</forenames></author><author><keyname>Gligor</keyname><forenames>Virgil</forenames></author></authors><title>On Topological Properties of Wireless Sensor Networks under the
  q-Composite Key Predistribution Scheme with On/Off Channels</title><categories>cs.CR cs.DM math.CO math.PR physics.data-an</categories><comments>Best Student Paper Finalist in IEEE International Symposium on
  Information Theory (ISIT) 2014</comments><msc-class>05C80, 60B20</msc-class><acm-class>G.2.2; C.2.1</acm-class><doi>10.1109/ISIT.2014.6875009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The q-composite key predistribution scheme [1] is used prevalently for secure
communications in large-scale wireless sensor networks (WSNs). Prior work
[2]-[4] explores topological properties of WSNs employing the q-composite
scheme for q = 1 with unreliable communication links modeled as independent
on/off channels. In this paper, we investigate topological properties related
to the node degree in WSNs operating under the q-composite scheme and the
on/off channel model. Our results apply to general q and are stronger than
those reported for the node degree in prior work even for the case of q being
1. Specifically, we show that the number of nodes with certain degree
asymptotically converges in distribution to a Poisson random variable, present
the asymptotic probability distribution for the minimum degree of the network,
and establish the asymptotically exact probability for the property that the
minimum degree is at least an arbitrary value. Numerical experiments confirm
the validity of our analytical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5091</identifier>
 <datestamp>2015-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5091</id><created>2014-08-21</created><updated>2015-11-03</updated><authors><author><keyname>Kuang</keyname><forenames>Quan</forenames></author><author><keyname>Utschick</keyname><forenames>Wolfgang</forenames></author><author><keyname>Dotzler</keyname><forenames>Andreas</forenames></author></authors><title>Optimal Joint User Association and Resource Allocation in Heterogeneous
  Networks via Sparsity Pursuit</title><categories>cs.NI cs.IT math.IT</categories><comments>revised to TSP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the joint user association and resource allocation in
heterogeneous networks (HetNets) from a novel perspective, motivated by and
generalizing the idea of fractional frequency reuse. By treating the multi-cell
multi-user resource allocation as resource partitioning among multiple reuse
patterns, we propose a unified framework to analyze and compare a wide range of
user association and resource allocation strategies for HetNets, and provide an
optimal benchmark for network performance. The enabling mechanisms are a novel
formulation to consider all possible interference patterns or any pre-defined
subset of patterns, and efficient sparsity-pursuit algorithms to find the
solution. A notable feature of this formulation is that the patterns remain
fixed during the resource optimization process. This creates a favorable
opportunity for convex formulations while still considering interference
coupling. More importantly, in view of the fact that multi-cell resource
allocation is very computational demanding, our framework provides a systematic
way to trade off performance for the reduction of computational complexity by
restricting the candidate patterns to a small number of feature patterns.
Relying on the sparsity-pursuit capability of the proposed algorithms, we
develop a practical guideline to identify the feature patterns. Numerical
results show that the identified feature patterns can significantly improve the
existing strategies, and jointly optimizing the user association and resource
allocation indeed brings considerable gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5093</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5093</id><created>2014-06-20</created><authors><author><keyname>Jia</keyname><forenames>Yangqing</forenames></author><author><keyname>Shelhamer</keyname><forenames>Evan</forenames></author><author><keyname>Donahue</keyname><forenames>Jeff</forenames></author><author><keyname>Karayev</keyname><forenames>Sergey</forenames></author><author><keyname>Long</keyname><forenames>Jonathan</forenames></author><author><keyname>Girshick</keyname><forenames>Ross</forenames></author><author><keyname>Guadarrama</keyname><forenames>Sergio</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Caffe: Convolutional Architecture for Fast Feature Embedding</title><categories>cs.CV cs.LG cs.NE</categories><comments>Tech report for the Caffe software at http://github.com/BVLC/Caffe/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Caffe provides multimedia scientists and practitioners with a clean and
modifiable framework for state-of-the-art deep learning algorithms and a
collection of reference models. The framework is a BSD-licensed C++ library
with Python and MATLAB bindings for training and deploying general-purpose
convolutional neural networks and other deep models efficiently on commodity
architectures. Caffe fits industry and internet-scale media needs by CUDA GPU
computation, processing over 40 million images a day on a single K40 or Titan
GPU ($\approx$ 2.5 ms per image). By separating model representation from
actual implementation, Caffe allows experimentation and seamless switching
among platforms for ease of development and deployment from prototyping
machines to cloud environments. Caffe is maintained and developed by the
Berkeley Vision and Learning Center (BVLC) with the help of an active community
of contributors on GitHub. It powers ongoing research projects, large-scale
industrial applications, and startup prototypes in vision, speech, and
multimedia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5094</identifier>
 <datestamp>2014-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5094</id><created>2014-08-21</created><updated>2014-08-26</updated><authors><author><keyname>Calvanese</keyname><forenames>Diego</forenames></author><author><keyname>Montali</keyname><forenames>Marco</forenames></author><author><keyname>Estanol</keyname><forenames>Montserrat</forenames></author><author><keyname>Teniente</keyname><forenames>Ernest</forenames></author></authors><title>Verifiable UML Artifact-Centric Business Process Models (Extended
  Version)</title><categories>cs.DB cs.SE</categories><comments>Extended version of &quot;Verifiable UML Artifact-Centric Business Process
  Models&quot; - to appear in the Proceedings of CIKM 2014</comments><doi>10.1145/2661829.2662050</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artifact-centric business process models have gained increasing momentum
recently due to their ability to combine structural (i.e., data related) with
dynamical (i.e., process related) aspects. In particular, two main lines of
research have been pursued so far: one tailored to business artefact modeling
languages and methodologies, the other focused on the foundations for their
formal verification. In this paper, we merge these two lines of research, by
showing how recent theoretical decidability results for verification can be
fruitfully transferred to a concrete UML-based modeling methodology. In
particular, we identify additional steps in the methodology that, in
significant cases, guarantee the possibility of verifying the resulting models
against rich first-order temporal properties. Notably, our results can be
seamlessly transferred to different languages for the specification of the
artifact lifecycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5096</identifier>
 <datestamp>2015-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5096</id><created>2014-08-21</created><updated>2015-02-16</updated><authors><author><keyname>Braverman</keyname><forenames>Vladimir</forenames></author><author><keyname>Chestnut</keyname><forenames>Stephen R.</forenames></author></authors><title>Universal sketches for the frequency negative moments and other
  decreasing streaming sums</title><categories>cs.DS</categories><comments>19 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a stream with frequencies $f_d$, for $d\in[n]$, we characterize the
space necessary for approximating the frequency negative moments $F_p=\sum
|f_d|^p$, where $p&lt;0$ and the sum is taken over all items $d\in[n]$ with
nonzero frequency, in terms of $n$, $\epsilon$, and $m=\sum |f_d|$. To
accomplish this, we actually prove a much more general result. Given any
nonnegative and nonincreasing function $g$, we characterize the space necessary
for any streaming algorithm that outputs a $(1\pm\epsilon)$-approximation to
$\sum g(|f_d|)$, where again the sum is over items with nonzero frequency. The
storage required is expressed in the form of the solution to a relatively
simple nonlinear optimization problem, and the algorithm is universal for
$(1\pm\epsilon)$-approximations to any such sum where the applied function is
nonnegative, nonincreasing, and has the same or smaller space complexity as
$g$. This partially answers an open question of Nelson (IITK Workshop Kanpur,
2009).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5098</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5098</id><created>2014-08-21</created><authors><author><keyname>Farhat</keyname><forenames>Soha</forenames><affiliation>IRISA, UL</affiliation></author><author><keyname>Cousin</keyname><forenames>Bernard</forenames><affiliation>IRISA</affiliation></author><author><keyname>Lahoud</keyname><forenames>Samer</forenames><affiliation>IRISA</affiliation></author><author><keyname>Ellatif</keyname><forenames>Samhat Abed</forenames><affiliation>UL</affiliation></author></authors><title>Hybrid Decision Algorithm for Access Selection in Multi-operator
  Networks</title><categories>cs.NI</categories><comments>WCNC, Istanbul : Turkey (2014)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a hybrid decision algorithm for the selection of
the access in multi-operator networks environment, where competing operators
share their radio access networks to meet traffic and data rate demands. The
proposed algorithm guarantees the user satisfaction and a global gain for all
cooperating operators. Simulation results prove the efficiency of the proposed
scheme and show that the cooperation between operators achieves benefits to
both users and operators; user acceptance as well as the operator resource
utilization and the operator revenue increase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5099</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5099</id><created>2014-08-21</created><authors><author><keyname>Cohen</keyname><forenames>Michael B.</forenames></author><author><keyname>Lee</keyname><forenames>Yin Tat</forenames></author><author><keyname>Musco</keyname><forenames>Cameron</forenames></author><author><keyname>Musco</keyname><forenames>Christopher</forenames></author><author><keyname>Peng</keyname><forenames>Richard</forenames></author><author><keyname>Sidford</keyname><forenames>Aaron</forenames></author></authors><title>Uniform Sampling for Matrix Approximation</title><categories>cs.DS cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random sampling has become a critical tool in solving massive matrix
problems. For linear regression, a small, manageable set of data rows can be
randomly selected to approximate a tall, skinny data matrix, improving
processing time significantly. For theoretical performance guarantees, each row
must be sampled with probability proportional to its statistical leverage
score. Unfortunately, leverage scores are difficult to compute.
  A simple alternative is to sample rows uniformly at random. While this often
works, uniform sampling will eliminate critical row information for many
natural instances. We take a fresh look at uniform sampling by examining what
information it does preserve. Specifically, we show that uniform sampling
yields a matrix that, in some sense, well approximates a large fraction of the
original. While this weak form of approximation is not enough for solving
linear regression directly, it is enough to compute a better approximation.
  This observation leads to simple iterative row sampling algorithms for matrix
approximation that run in input-sparsity time and preserve row structure and
sparsity at all intermediate steps. In addition to an improved understanding of
uniform sampling, our main proof introduces a structural result of independent
interest: we show that every matrix can be made to have low coherence by
reweighting a small subset of its rows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5108</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5108</id><created>2014-08-21</created><authors><author><keyname>Houston</keyname><forenames>Robin</forenames></author></authors><title>Tackling the Minimal Superpermutation Problem</title><categories>math.CO cs.DS</categories><comments>5 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A superpermutation on $n$ symbols is a string that contains each of the $n!$
permutations of the $n$ symbols as a contiguous substring. The shortest
superpermutation on $n$ symbols was conjectured to have length $\sum_{i=1}^n
i!$. The conjecture had been verified for $n \leq 5$. We disprove it by
exhibiting an explicit counterexample for $n=6$. This counterexample was found
by encoding the problem as an instance of the (asymmetric) Traveling Salesman
Problem, and searching for a solution using a powerful heuristic solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5124</identifier>
 <datestamp>2014-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5124</id><created>2014-08-21</created><authors><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>The Matthew effect in empirical data</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI q-bio.PE</categories><comments>15 two-column pages, 7 figures; accepted for publication in Journal
  of the Royal Society Interface</comments><journal-ref>J. R. Soc. Interface 11 (2014) 20140378</journal-ref><doi>10.1098/rsif.2014.0378</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Matthew effect describes the phenomenon that in societies the rich tend
to get richer and the potent even more powerful. It is closely related to the
concept of preferential attachment in network science, where the more connected
nodes are destined to acquire many more links in the future than the auxiliary
nodes. Cumulative advantage and success-breads-success also both describe the
fact that advantage tends to beget further advantage. The concept is behind the
many power laws and scaling behaviour in empirical data, and it is at the heart
of self-organization across social and natural sciences. Here we review the
methodology for measuring preferential attachment in empirical data, as well as
the observations of the Matthew effect in patterns of scientific collaboration,
socio-technical and biological networks, the propagation of citations, the
emergence of scientific progress and impact, career longevity, the evolution of
common English words and phrases, as well as in education and brain
development. We also discuss whether the Matthew effect is due to chance or
optimisation, for example related to homophily in social systems or efficacy in
technological systems, and we outline possible directions for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5192</identifier>
 <datestamp>2014-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5192</id><created>2014-08-21</created><authors><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Immorlica</keyname><forenames>Nicole</forenames></author><author><keyname>Lucier</keyname><forenames>Brendan</forenames></author><author><keyname>Weinberg</keyname><forenames>S. Matthew</forenames></author></authors><title>Reaching Consensus via non-Bayesian Asynchronous Learning in Social
  Networks</title><categories>cs.GT cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the outcomes of information aggregation in online social networks.
Our main result is that networks with certain realistic structural properties
avoid information cascades and enable a population to effectively aggregate
information. In our model, each individual in a network holds a private,
independent opinion about a product or idea, biased toward a ground truth.
Individuals declare their opinions asynchronously, can observe the stated
opinions of their neighbors, and are free to update their declarations over
time. Supposing that individuals conform with the majority report of their
neighbors, we ask whether the population will eventually arrive at consensus on
the ground truth. We show that the answer depends on the network structure:
there exist networks for which consensus is unlikely, or for which declarations
converge on the incorrect opinion with positive probability. On the other hand,
we prove that for networks that are sparse and expansive, the population will
converge to the correct opinion with high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1408.5196</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1408.5196</id><created>2014-08-21</created><authors><author><keyname>Zhou</keyname><forenames>Ming-Yang</forenames></author><author><keyname>Zhuo</keyname><forenames>Zhao</forenames></author><author><keyname>Cai</keyname><forenames>Shi-Min</forenames></author><author><keyname>Fu</keyname><forenames>Zhong-Qian</forenames></author></authors><title>Community structure revealed by phase locking</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>8 pages, 5 figures, 2 tables</comments><journal-ref>Chaos 24(3), 033128, 2014</journal-ref><doi>10.1063/1.4894764</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community structure can naturally emerge in paths to synchronization, and
scratching it from the paths is a tough issue that accounts for the diverse
dynamics of synchronization. In this paper, with assumption that the
synchronization on complex networks is made up of local and collective
processes, we proposed a scheme to lock the local synchronization (phase
locking) at a stable state meanwhile suppress the collective synchronization
based on Kuramoto model. Through this scheme, the network dynamics only
contains the local synchronization, which suggests that the nodes in the same
community synchronize together and these synchronization clusters well reveal
the community structure of network. Furthermore, by analyzing the paths to
synchronization, the relations or overlaps among different communities are also
obtained. Thus, the community detection based on the scheme is performed on
five real networks and the observed community structures are much more apparent
than modularity-based fast algorithm. Our results not only provide a deep
insight to understand the synchronization dynamics on complex network but also
enlarge the research scope of community detection.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="64000" completeListSize="102538">1122234|65001</resumptionToken>
</ListRecords>
</OAI-PMH>
