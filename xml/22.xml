<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:50:26Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|21001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5111</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5111</id><created>2011-04-27</created><authors><author><keyname>Dietzfelbinger</keyname><forenames>Martin</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Rink</keyname><forenames>Michael</forenames></author></authors><title>Cuckoo Hashing with Pages</title><categories>cs.DS</categories><comments>18 pages, 6 figures, 6 tables</comments><acm-class>E.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although cuckoo hashing has significant applications in both theoretical and
practical settings, a relevant downside is that it requires lookups to multiple
locations. In many settings, where lookups are expensive, cuckoo hashing
becomes a less compelling alternative. One such standard setting is when memory
is arranged in large pages, and a major cost is the number of page accesses. We
propose the study of cuckoo hashing with pages, advocating approaches where
each key has several possible locations, or cells, on a single page, and
additional choices on a second backup page. We show experimentally that with k
cell choices on one page and a single backup cell choice, one can achieve
nearly the same loads as when each key has k+1 random cells to choose from,
with most lookups requiring just one page access, even when keys are placed
online using a simple algorithm. While our results are currently experimental,
they suggest several interesting new open theoretical questions for cuckoo
hashing with pages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5117</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5117</id><created>2011-04-27</created><updated>2011-05-07</updated><authors><author><keyname>Bavirisetti</keyname><forenames>Teja Damodaram</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Maximum Rate of 3- and 4-Real-Symbol ML Decodable Unitary Weight STBCs</title><categories>cs.IT math.IT</categories><comments>To be presented at ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown recently that the maximum rate of a 2-real-symbol
(single-complex-symbol) maximum likelihood (ML) decodable, square space-time
block codes (STBCs) with unitary weight matrices is $\frac{2a}{2^a}$ complex
symbols per channel use (cspcu) for $2^a$ number of transmit antennas
\cite{KSR}. These STBCs are obtained from Unitary Weight Designs (UWDs). In
this paper, we show that the maximum rates for 3- and 4-real-symbol
(2-complex-symbol) ML decodable square STBCs from UWDs, for $2^{a}$ transmit
antennas, are $\frac{3(a-1)}{2^{a}}$ and $\frac{4(a-1)}{2^{a}}$ cspcu,
respectively. STBCs achieving this maximum rate are constructed. A set of
sufficient conditions on the signal set, required for these codes to achieve
full-diversity are derived along with expressions for their coding gain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5133</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5133</id><created>2011-04-27</created><authors><author><keyname>Janssen</keyname><forenames>Jeroen</forenames></author><author><keyname>Schockaert</keyname><forenames>Steven</forenames></author><author><keyname>Vermeir</keyname><forenames>Dirk</forenames></author><author><keyname>De Cock</keyname><forenames>Martine</forenames></author></authors><title>Reducing Fuzzy Answer Set Programming to Model Finding in Fuzzy Logics</title><categories>cs.PL cs.LO</categories><msc-class>68N17</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years answer set programming has been extended to deal with
multi-valued predicates. The resulting formalisms allows for the modeling of
continuous problems as elegantly as ASP allows for the modeling of discrete
problems, by combining the stable model semantics underlying ASP with fuzzy
logics. However, contrary to the case of classical ASP where many efficient
solvers have been constructed, to date there is no efficient fuzzy answer set
programming solver. A well-known technique for classical ASP consists of
translating an ASP program $P$ to a propositional theory whose models exactly
correspond to the answer sets of $P$. In this paper, we show how this idea can
be extended to fuzzy ASP, paving the way to implement efficient fuzzy ASP
solvers that can take advantage of existing fuzzy logic reasoners. To appear in
Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5139</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5139</id><created>2011-04-27</created><authors><author><keyname>Limam</keyname><forenames>Hela</forenames></author><author><keyname>Akaichi</keyname><forenames>Jalel</forenames></author></authors><title>Web services synchronization health care application</title><categories>cs.DB</categories><comments>18 pages, 12 figures</comments><doi>10.5121/ijwest.2011.2204</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the advance of Web Services technologies and the emergence of Web
Services into the information space, tremendous opportunities for empowering
users and organizations appear in various application domains including
electronic commerce, travel, intelligence information gathering and analysis,
health care, digital government, etc. In fact, Web services appear to be s
solution for integrating distributed, autonomous and heterogeneous information
sources. However, as Web services evolve in a dynamic environment which is the
Internet many changes can occur and affect them. A Web service is affected when
one or more of its associated information sources is affected by schema
changes. Changes can alter the information sources contents but also their
schemas which may render Web services partially or totally undefined. In this
paper, we propose a solution for integrating information sources into Web
services. Then we tackle the Web service synchronization problem by
substituting the affected information sources. Our work is illustrated with a
healthcare case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5147</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5147</id><created>2011-04-27</created><updated>2011-07-11</updated><authors><author><keyname>Mobilia</keyname><forenames>Mauro</forenames></author></authors><title>Fixation and Polarization in a Three-Species Opinion Dynamics Model</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI nlin.AO q-bio.PE</categories><comments>6 pages in EPL format, 3 color figures (6 panels). Minor
  modifications. To appear in EPL (Europhysics Letters)</comments><msc-class>60J28, 91A22, 92Dxx, 60J60, 91A25</msc-class><journal-ref>EPL (Europhysics Letters) Vol. 95, 50002 (2011)</journal-ref><doi>10.1209/0295-5075/95/50002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the dynamics of cultural change and diversity, we generalize the
three-species constrained voter model on a complete graph introduced in [J.
Phys. A 37, 8479 (2004)]. In this opinion dynamics model, a population of size
N is composed of &quot;leftists&quot; and &quot;rightists&quot; that interact with &quot;centrists&quot;: a
leftist and centrist can both become leftists with rate (1+q)/2 or centrists
with rate (1-q)/2 (and similarly for rightists and centrists), where q denotes
the bias towards extremism (q&gt;0) or centrism (q&lt;0). This system admits three
absorbing fixed points and a &quot;polarization&quot; line along which a frozen mixture
of leftists and rightists coexist. In the realm of Fokker-Planck equation, and
using a mapping onto a population genetics model, we compute the fixation
probability of ending in every absorbing state and the mean times for these
events. We therefore show, especially in the limit of weak bias and large
population size when |q|~1/N and N&gt;&gt;1, how fluctuations alter the mean field
predictions: polarization is likely when q&gt;0, but there is always a finite
probability to reach a consensus; the opposite happens when q&lt;0. Our findings
are corroborated by stochastic simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5150</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5150</id><created>2011-04-27</created><authors><author><keyname>Krichen</keyname><forenames>Mariem</forenames></author><author><keyname>Cohen</keyname><forenames>Johanne</forenames></author><author><keyname>Barth</keyname><forenames>Dominique</forenames></author></authors><title>File Transfer Application For Sharing Femto Access</title><categories>cs.NI cs.LG</categories><comments>15 pages, 9 figures; extended version from Conference ISCIS 2011</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In wireless access network optimization, today's main challenges reside in
traffic offload and in the improvement of both capacity and coverage networks.
The operators are interested in solving their localized coverage and capacity
problems in areas where the macro network signal is not able to serve the
demand for mobile data. Thus, the major issue for operators is to find the best
solution at reasonable expanses. The femto cell seems to be the answer to this
problematic. In this work (This work is supported by the COMET project AWARE.
http://www.ftw.at/news/project-start-for-aware-ftw), we focus on the problem of
sharing femto access between a same mobile operator's customers. This problem
can be modeled as a game where service requesters customers (SRCs) and service
providers customers (SPCs) are the players.
  This work addresses the sharing femto access problem considering only one SPC
using game theory tools. We consider that SRCs are static and have some similar
and regular connection behavior. We also note that the SPC and each SRC have a
software embedded respectively on its femto access, user equipment (UE).
  After each connection requested by a SRC, its software will learn the
strategy increasing its gain knowing that no information about the other SRCs
strategies is given. The following article presents a distributed learning
algorithm with incomplete information running in SRCs software. We will then
answer the following questions for a game with $N$ SRCs and one SPC: how many
connections are necessary for each SRC in order to learn the strategy
maximizing its gain? Does this algorithm converge to a stable state? If yes,
does this state a Nash Equilibrium and is there any way to optimize the
learning process duration time triggered by SRCs software?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5170</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5170</id><created>2011-04-27</created><updated>2012-11-11</updated><authors><author><keyname>Harshan</keyname><forenames>J.</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>A Novel Power Allocation Scheme for Two-User GMAC with Finite Input
  Constellations</title><categories>cs.IT cs.NI math.IT</categories><comments>To appear in IEEE Transactions on Wireless Communications, 10 pages
  and 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constellation Constrained (CC) capacity regions of two-user Gaussian Multiple
Access Channels (GMAC) have been recently reported, wherein an appropriate
angle of rotation between the constellations of the two users is shown to
enlarge the CC capacity region. We refer to such a scheme as the Constellation
Rotation (CR) scheme. In this paper, we propose a novel scheme called the
Constellation Power Allocation (CPA) scheme, wherein the instantaneous transmit
power of the two users are varied by maintaining their average power
constraints. We show that the CPA scheme offers CC sum capacities equal (at low
SNR values) or close (at high SNR values) to those offered by the CR scheme
with reduced decoding complexity for QAM constellations. We study the
robustness of the CPA scheme for random phase offsets in the channel and
unequal average power constraints for the two users. With random phase offsets
in the channel, we show that the CC sum capacity offered by the CPA scheme is
more than the CR scheme at high SNR values. With unequal average power
constraints, we show that the CPA scheme provides maximum gain when the power
levels are close, and the advantage diminishes with the increase in the power
difference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5183</identifier>
 <datestamp>2011-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5183</id><created>2011-04-27</created><updated>2011-07-04</updated><authors><author><keyname>Simon</keyname><forenames>Emile</forenames></author><author><keyname>Wertz</keyname><forenames>Vincent</forenames></author></authors><title>Direct search methods for an open problem of optimization in systems and
  control</title><categories>math.OC cs.SY</categories><comments>15 pages, 1 figure, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The motivation of this work is to illustrate the efficiency of some often
overlooked alternatives to deal with optimization problems in systems and
control. In particular, we will consider a problem for which an iterative
linear matrix inequality algorithm (ILMI) has been proposed recently. As it
often happens, this algorithm does not have guaranteed global convergence and
therefore many methods may perform better. We will put forward how some general
purpose optimization solvers are more suited than the ILMI. This is illustrated
with the considered problem and example, but the general observations remain
valid for many similar situations in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5186</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5186</id><created>2011-04-27</created><authors><author><keyname>Oymak</keyname><forenames>Samet</forenames></author><author><keyname>Hassibi</keyname><forenames>Babak</forenames></author></authors><title>Finding Dense Clusters via &quot;Low Rank + Sparse&quot; Decomposition</title><categories>stat.ML cs.IT math.IT</categories><comments>19 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding &quot;densely connected clusters&quot; in a graph is in general an important
and well studied problem in the literature \cite{Schaeffer}. It has various
applications in pattern recognition, social networking and data mining
\cite{Duda,Mishra}. Recently, Ames and Vavasis have suggested a novel method
for finding cliques in a graph by using convex optimization over the adjacency
matrix of the graph \cite{Ames, Ames2}. Also, there has been recent advances in
decomposing a given matrix into its &quot;low rank&quot; and &quot;sparse&quot; components
\cite{Candes, Chandra}. In this paper, inspired by these results, we view
&quot;densely connected clusters&quot; as imperfect cliques, where imperfections
correspond missing edges, which are relatively sparse. We analyze the problem
in a probabilistic setting and aim to detect disjointly planted clusters. Our
main result basically suggests that, one can find \emph{dense} clusters in a
graph, as long as the clusters are sufficiently large. We conclude by
discussing possible extensions and future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5200</identifier>
 <datestamp>2014-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5200</id><created>2011-04-27</created><updated>2014-04-30</updated><authors><author><keyname>Halldorsson</keyname><forenames>Magnus M.</forenames></author><author><keyname>Mitra</keyname><forenames>Pradipta</forenames></author></authors><title>Nearly Optimal Bounds for Distributed Wireless Scheduling in the SINR
  Model</title><categories>cs.DS cs.NI</categories><comments>Expanded and improved version of ICALP 2011 conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the wireless scheduling problem in the SINR model. More
specifically, given a set of $n$ links, each a sender-receiver pair, we wish to
partition (or \emph{schedule}) the links into the minimum number of slots, each
satisfying interference constraints allowing simultaneous transmission. In the
basic problem, all senders transmit with the same uniform power.
  We give a distributed $O(\log n)$-approximation algorithm for the scheduling
problem, matching the best ratio known for centralized algorithms. It holds in
arbitrary metric space and for every length-monotone and sublinear power
assignment. It is based on an algorithm of Kesselheim and V\&quot;ocking, whose
analysis we improve by a logarithmic factor. We show that every distributed
algorithm uses $\Omega(\log n)$ slots to schedule certain instances that
require only two slots, which implies that the best possible absolute
performance guarantee is logarithmic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5214</identifier>
 <datestamp>2011-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5214</id><created>2011-04-27</created><authors><author><keyname>Kawarabayashi</keyname><forenames>Ken-ichi</forenames></author><author><keyname>Klein</keyname><forenames>Philip N.</forenames></author><author><keyname>Sommer</keyname><forenames>Christian</forenames></author></authors><title>Linear-Space Approximate Distance Oracles for Planar, Bounded-Genus, and
  Minor-Free Graphs</title><categories>cs.DS cs.DM</categories><doi>10.1007/978-3-642-22006-7_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A (1 + eps)-approximate distance oracle for a graph is a data structure that
supports approximate point-to-point shortest-path-distance queries. The most
relevant measures for a distance-oracle construction are: space, query time,
and preprocessing time. There are strong distance-oracle constructions known
for planar graphs (Thorup, JACM'04) and, subsequently, minor-excluded graphs
(Abraham and Gavoille, PODC'06). However, these require Omega(eps^{-1} n lg n)
space for n-node graphs. We argue that a very low space requirement is
essential. Since modern computer architectures involve hierarchical memory
(caches, primary memory, secondary memory), a high memory requirement in effect
may greatly increase the actual running time. Moreover, we would like data
structures that can be deployed on small mobile devices, such as handhelds,
which have relatively small primary memory. In this paper, for planar graphs,
bounded-genus graphs, and minor-excluded graphs we give distance-oracle
constructions that require only O(n) space. The big O hides only a fixed
constant, independent of \epsilon and independent of genus or size of an
excluded minor. The preprocessing times for our distance oracle are also faster
than those for the previously known constructions. For planar graphs, the
preprocessing time is O(n lg^2 n). However, our constructions have slower query
times. For planar graphs, the query time is O(eps^{-2} lg^2 n). For our
linear-space results, we can in fact ensure, for any delta &gt; 0, that the space
required is only 1 + delta times the space required just to represent the graph
itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5226</identifier>
 <datestamp>2011-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5226</id><created>2011-04-27</created><authors><author><keyname>Chen</keyname><forenames>Ho-Lin</forenames></author><author><keyname>Doty</keyname><forenames>David</forenames></author></authors><title>Parallelism and Time in Hierarchical Self-Assembly</title><categories>cs.CC cs.DS q-bio.MN</categories><comments>previously was combined with this paper but they have now been split:
  http://arxiv.org/abs/1011.3493</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the role that parallelism plays in time complexity of Winfree's
abstract Tile Assembly Model (aTAM), a model of molecular algorithmic
self-assembly. In the &quot;hierarchical&quot; aTAM, two assemblies, both consisting of
multiple tiles, are allowed to aggregate together, whereas in the &quot;seeded&quot;
aTAM, tiles attach one at a time to a growing assembly. Adleman, Cheng, Goel,
and Huang (&quot;Running Time and Program Size for Self-Assembled Squares&quot;, STOC
2001) showed how to assemble an n x n square in O(n) time in the seeded aTAM
using O(log n / log log n) unique tile types, where both of these parameters
are optimal. They asked whether the hierarchical aTAM could allow a tile system
to use the ability to form large assemblies in parallel before they attach to
break the Omega(n) lower bound for assembly time. We show that there is a tile
system with the optimal O(log n / log log n) tile types that assembles an n x n
square using O(log^2 n) parallel &quot;stages&quot;, which is close to the optimal
Omega(log n) stages, forming the final n x n square from four n/2 x n/2
squares, which are themselves recursively formed from n/4 x n/4 squares, etc.
However, despite this nearly maximal parallelism, the system requires
superlinear time to assemble the square. We extend the definition of *partial
order tile systems* studied by Adleman et al. in a natural way to hierarchical
assembly and show that no hierarchical partial order tile system can build any
shape with diameter N in less than time Omega(N), demonstrating that in this
case the hierarchical model affords no speedup whatsoever over the seeded
model. We strengthen the Omega(N) time lower bound for deterministic seeded
systems of Adleman et al. to nondeterministic seeded systems. Finally, we show
that for infinitely many n, a tile system can assemble an n x n' rectangle,
with n &gt; n', in time O(n^{4/5} log n), breaking the linear-time lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5240</identifier>
 <datestamp>2012-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5240</id><created>2011-04-27</created><updated>2012-04-26</updated><authors><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Zheng</keyname><forenames>Gan</forenames></author><author><keyname>Bengtsson</keyname><forenames>Mats</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Robust Monotonic Optimization Framework for Multicell MISO Systems</title><categories>cs.IT math.IT</categories><comments>Published in IEEE Transactions on Signal Processing, 16 pages, 9
  figures, 2 tables</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 60, no. 5, pp.
  2508-2523, May 2012</journal-ref><doi>10.1109/TSP.2012.2184099</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of multiuser systems is both difficult to measure fairly and
to optimize. Most resource allocation problems are non-convex and NP-hard, even
under simplifying assumptions such as perfect channel knowledge, homogeneous
channel properties among users, and simple power constraints. We establish a
general optimization framework that systematically solves these problems to
global optimality. The proposed branch-reduce-and-bound (BRB) algorithm handles
general multicell downlink systems with single-antenna users, multiantenna
transmitters, arbitrary quadratic power constraints, and robustness to channel
uncertainty. A robust fairness-profile optimization (RFO) problem is solved at
each iteration, which is a quasi-convex problem and a novel generalization of
max-min fairness. The BRB algorithm is computationally costly, but it shows
better convergence than the previously proposed outer polyblock approximation
algorithm. Our framework is suitable for computing benchmarks in general
multicell systems with or without channel uncertainty. We illustrate this by
deriving and evaluating a zero-forcing solution to the general problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5243</identifier>
 <datestamp>2013-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5243</id><created>2011-04-27</created><updated>2011-09-20</updated><authors><author><keyname>Treibig</keyname><forenames>Jan</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author><author><keyname>Hofmann</keyname><forenames>Hannes G.</forenames></author><author><keyname>Hornegger</keyname><forenames>Joachim</forenames></author><author><keyname>Wellein</keyname><forenames>Gerhard</forenames></author></authors><title>Pushing the limits for medical image reconstruction on recent standard
  multicore processors</title><categories>cs.PF cs.DC</categories><comments>13 pages, 9 figures. Revised and extended version</comments><doi>10.1177/1094342012442424</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Volume reconstruction by backprojection is the computational bottleneck in
many interventional clinical computed tomography (CT) applications. Today
vendors in this field replace special purpose hardware accelerators by standard
hardware like multicore chips and GPGPUs. Medical imaging algorithms are on the
verge of employing High Performance Computing (HPC) technology, and are
therefore an interesting new candidate for optimization. This paper presents
low-level optimizations for the backprojection algorithm, guided by a thorough
performance analysis on four generations of Intel multicore processors
(Harpertown, Westmere, Westmere EX, and Sandy Bridge).
  We choose the RabbitCT benchmark, a standardized testcase well supported in
industry, to ensure transparent and comparable results. Our aim is to provide
not only the fastest possible implementation but also compare to performance
models and hardware counter data in order to fully understand the results. We
separate the influence of algorithmic optimizations, parallelization, SIMD
vectorization, and microarchitectural issues and pinpoint problems with current
SIMD instruction set extensions on standard CPUs (SSE, AVX). The use of
assembly language is mandatory for best performance. Finally we compare our
results to the best GPGPU implementations available for this open competition
benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5246</identifier>
 <datestamp>2013-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5246</id><created>2011-04-27</created><updated>2013-03-01</updated><authors><author><keyname>Cand&#xe8;s</keyname><forenames>Emmanuel J.</forenames></author><author><keyname>Davenport</keyname><forenames>Mark A.</forenames></author></authors><title>How well can we estimate a sparse vector?</title><categories>cs.IT math.IT math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The estimation of a sparse vector in the linear model is a fundamental
problem in signal processing, statistics, and compressive sensing. This paper
establishes a lower bound on the mean-squared error, which holds regardless of
the sensing/design matrix being used and regardless of the estimation
procedure. This lower bound very nearly matches the known upper bound one gets
by taking a random projection of the sparse vector followed by an $\ell_1$
estimation procedure such as the Dantzig selector. In this sense, compressive
sensing techniques cannot essentially be improved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5247</identifier>
 <datestamp>2011-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5247</id><created>2011-04-27</created><updated>2011-11-22</updated><authors><author><keyname>Stanoev</keyname><forenames>Angel</forenames></author><author><keyname>Smilkov</keyname><forenames>Daniel</forenames></author><author><keyname>Kocarev</keyname><forenames>Ljupco</forenames></author></authors><title>Identifying communities by influence dynamics in social networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>10 pages, 6 figures</comments><journal-ref>Phys. Rev. E 84, 046102 (2011)</journal-ref><doi>10.1103/PhysRevE.84.046102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communities are not static; they evolve, split and merge, appear and
disappear, i.e. they are product of dynamical processes that govern the
evolution of the network. A good algorithm for community detection should not
only quantify the topology of the network, but incorporate the dynamical
processes that take place on the network. We present a novel algorithm for
community detection that combines network structure with processes that support
creation and/or evolution of communities. The algorithm does not embrace the
universal approach but instead tries to focus on social networks and model
dynamic social interactions that occur on those networks. It identifies
leaders, and communities that form around those leaders. It naturally supports
overlapping communities by associating each node with a membership vector that
describes node's involvement in each community. This way, in addition to
overlapping communities, we can identify nodes that are good followers to their
leader, and also nodes with no clear community involvement that serve as a
proxy between several communities and are equally as important. We run the
algorithm for several real social networks which we believe represent a good
fraction of the wide body of social networks and discuss the results including
other possible applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5256</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5256</id><created>2011-04-27</created><authors><author><keyname>Ding</keyname><forenames>Shilin</forenames></author></authors><title>Learning Undirected Graphical Models with Structure Penalty</title><categories>cs.AI cs.LG</categories><comments>20 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In undirected graphical models, learning the graph structure and learning the
functions that relate the predictive variables (features) to the responses
given the structure are two topics that have been widely investigated in
machine learning and statistics. Learning graphical models in two stages will
have problems because graph structure may change after considering the
features. The main contribution of this paper is the proposed method that
learns the graph structure and functions on the graph at the same time. General
graphical models with binary outcomes conditioned on predictive variables are
proved to be equivalent to multivariate Bernoulli model. The reparameterization
of the potential functions in graphical model by conditional log odds ratios in
multivariate Bernoulli model offers advantage in the representation of the
conditional independence structure in the model. Additionally, we impose a
structure penalty on groups of conditional log odds ratios to learn the graph
structure. These groups of functions are designed with overlaps to enforce
hierarchical function selection. In this way, we are able to shrink higher
order interactions to obtain a sparse graph structure. Simulation studies show
that the method is able to recover the graph structure. The analysis of county
data from Census Bureau gives interesting relations between unemployment rate,
crime and others discovered by the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5257</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5257</id><created>2011-04-27</created><updated>2011-09-23</updated><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Kara</keyname><forenames>Jan</forenames></author><author><keyname>Martin</keyname><forenames>Barnaby</forenames></author></authors><title>The Complexity of Surjective Homomorphism Problems -- a Survey</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey known results about the complexity of surjective homomorphism
problems, studied in the context of related problems in the literature such as
list homomorphism, retraction and compaction. In comparison with these
problems, surjective homomorphism problems seem to be harder to classify and we
examine especially three concrete problems that have arisen from the
literature, two of which remain of open complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5259</identifier>
 <datestamp>2011-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5259</id><created>2011-04-27</created><updated>2011-06-08</updated><authors><author><keyname>Frieze</keyname><forenames>Alan</forenames></author><author><keyname>Tsourakakis</keyname><forenames>Charalampos E.</forenames></author></authors><title>High Degree Vertices, Eigenvalues and Diameter of Random Apollonian
  Networks</title><categories>cs.SI cs.DM math.CO physics.soc-ph</categories><comments>(1) 18 pages, 6 figures (2) Updates in 2nd version: added references,
  corrected typos and simplifications. For more details check
  http://www.math.cmu.edu/~ctsourak/apolarxiv.txt</comments><msc-class>68R10, 68R05, 68P05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we analyze basic properties of Random Apollonian Networks
\cite{zhang,zhou}, a popular stochastic model which generates planar graphs
with power law properties. Specifically, let $k$ be a constant and $\Delta_1
\geq \Delta_2 \geq .. \geq \Delta_k$ be the degrees of the $k$ highest degree
vertices. We prove that at time $t$, for any function $f$ with $f(t)
\rightarrow +\infty$ as $t \rightarrow +\infty$, $\frac{t^{1/2}}{f(t)} \leq
\Delta_1 \leq f(t)t^{1/2}$ and for $i=2,...,k=O(1)$, $\frac{t^{1/2}}{f(t)} \leq
\Delta_i \leq \Delta_{i-1} - \frac{t^{1/2}}{f(t)}$ with high probability
(\whp). Then, we show that the $k$ largest eigenvalues of the adjacency matrix
of this graph satisfy $\lambda_k = (1\pm o(1))\Delta_k^{1/2}$ \whp.
Furthermore, we prove a refined upper bound on the asymptotic growth of the
diameter, i.e., that \whp the diameter $d(G_t)$ at time $t$ satisfies $d(G_t)
\leq \rho \log{t}$ where $\frac{1}{\rho}=\eta$ is the unique solution greater
than 1 of the equation $\eta - 1 - \log{\eta} = \log{3}$. Finally, we
investigate other properties of the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5268</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5268</id><created>2011-04-27</created><updated>2011-10-02</updated><authors><author><keyname>Lam</keyname><forenames>Henry</forenames></author><author><keyname>Liu</keyname><forenames>Zhenming</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Sun</keyname><forenames>Xiaorui</forenames></author><author><keyname>Wang</keyname><forenames>Yajun</forenames></author></authors><title>Information Dissemination via Random Walks in d-Dimensional Space</title><categories>math.PR cs.DM</categories><comments>58 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a natural information dissemination problem for multiple mobile
agents in a bounded Euclidean space. Agents are placed uniformly at random in
the $d$-dimensional space $\{-n, ..., n\}^d$ at time zero, and one of the
agents holds a piece of information to be disseminated. All the agents then
perform independent random walks over the space, and the information is
transmitted from one agent to another if the two agents are sufficiently close.
We wish to bound the total time before all agents receive the information (with
high probability). Our work extends Pettarin et al.'s work (Infectious random
walks, arXiv:1007.1604v2, 2011), which solved the problem for $d \leq 2$. We
present tight bounds up to polylogarithmic factors for the case $d = 3$. (While
our results extend to higher dimensions, for space and readability
considerations we provide only the case $d=3$ here.) Our results show the
behavior when $d \geq 3$ is qualitatively different from the case $d \leq 2$.
In particular, as the ratio between the volume of the space and the number of
agents varies, we show an interesting phase transition for three dimensions
that does not occur in one or two dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5275</identifier>
 <datestamp>2011-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5275</id><created>2011-04-27</created><updated>2011-08-26</updated><authors><author><keyname>Ampadu</keyname><forenames>Clement</forenames></author></authors><title>A Quantum Analogue of Parrondo's Game</title><categories>quant-ph cs.GT</categories><msc-class>81T25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the discrete-time quantum walk in the plane, and present a
quantum implementation of Parrondo's game for four players. Physical
significance of the game strategies are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5280</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5280</id><created>2011-04-27</created><authors><author><keyname>Zhang</keyname><forenames>Zhilin</forenames></author><author><keyname>Rao</keyname><forenames>Bhaskar D.</forenames></author></authors><title>Iterative Reweighted Algorithms for Sparse Signal Recovery with
  Temporally Correlated Source Vectors</title><categories>stat.ML cs.IT math.IT</categories><comments>Accepted by ICASSP 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Iterative reweighted algorithms, as a class of algorithms for sparse signal
recovery, have been found to have better performance than their non-reweighted
counterparts. However, for solving the problem of multiple measurement vectors
(MMVs), all the existing reweighted algorithms do not account for temporal
correlation among source vectors and thus their performance degrades
significantly in the presence of correlation. In this work we propose an
iterative reweighted sparse Bayesian learning (SBL) algorithm exploiting the
temporal correlation, and motivated by it, we propose a strategy to improve
existing reweighted $\ell_2$ algorithms for the MMV problem, i.e. replacing
their row norms with Mahalanobis distance measure. Simulations show that the
proposed reweighted SBL algorithm has superior performance, and the proposed
improvement strategy is effective for existing reweighted $\ell_2$ algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5284</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5284</id><created>2011-04-27</created><authors><author><keyname>da Luz</keyname><forenames>Antonio</forenames></author><author><keyname>Valle</keyname><forenames>Eduardo</forenames></author><author><keyname>Araujo</keyname><forenames>Arnaldo</forenames></author></authors><title>Content-Based Spam Filtering on Video Sharing Social Networks</title><categories>cs.CV cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we are concerned with the detection of spam in video sharing
social networks. Specifically, we investigate how much visual content-based
analysis can aid in detecting spam in videos. This is a very challenging task,
because of the high-level semantic concepts involved; of the assorted nature of
social networks, preventing the use of constrained a priori information; and,
what is paramount, of the context dependent nature of spam. Content filtering
for social networks is an increasingly demanded task: due to their popularity,
the number of abuses also tends to increase, annoying the user base and
disrupting their services. We systematically evaluate several approaches for
processing the visual information: using static and dynamic (motionaware)
features, with and without considering the context, and with or without latent
semantic analysis (LSA). Our experiments show that LSA is helpful, but taking
the context into consideration is paramount. The whole scheme shows good
results, showing the feasibility of the concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5286</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5286</id><created>2011-04-27</created><authors><author><keyname>Farahmand</keyname><forenames>Shahrokh</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author><author><keyname>Angelosante</keyname><forenames>Daniele</forenames></author></authors><title>Doubly Robust Smoothing of Dynamical Processes via Outlier Sparsity
  Constraints</title><categories>cs.SY math.OC stat.AP</categories><comments>Submitted to IEEE Trans. on Signal Processing</comments><doi>10.1109/TSP.2011.2161300</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coping with outliers contaminating dynamical processes is of major importance
in various applications because mismatches from nominal models are not uncommon
in practice. In this context, the present paper develops novel fixed-lag and
fixed-interval smoothing algorithms that are robust to outliers simultaneously
present in the measurements {\it and} in the state dynamics. Outliers are
handled through auxiliary unknown variables that are jointly estimated along
with the state based on the least-squares criterion that is regularized with
the $\ell_1$-norm of the outliers in order to effect sparsity control. The
resultant iterative estimators rely on coordinate descent and the alternating
direction method of multipliers, are expressed in closed form per iteration,
and are provably convergent. Additional attractive features of the novel doubly
robust smoother include: i) ability to handle both types of outliers; ii)
universality to unknown nominal noise and outlier distributions; iii)
flexibility to encompass maximum a posteriori optimal estimators with reliable
performance under nominal conditions; and iv) improved performance relative to
competing alternatives at comparable complexity, as corroborated via simulated
tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5288</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5288</id><created>2011-04-27</created><authors><author><keyname>Farahmand</keyname><forenames>Shahrokh</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author><author><keyname>Leus</keyname><forenames>Geert</forenames></author><author><keyname>Tian</keyname><forenames>Zhi</forenames></author></authors><title>Tracking Target Signal Strengths on a Grid using Sparsity</title><categories>cs.SY math.OC stat.AP</categories><comments>Submitted to IEEE Trans. on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-target tracking is mainly challenged by the nonlinearity present in the
measurement equation, and the difficulty in fast and accurate data association.
To overcome these challenges, the present paper introduces a grid-based model
in which the state captures target signal strengths on a known spatial grid
(TSSG). This model leads to \emph{linear} state and measurement equations,
which bypass data association and can afford state estimation via
sparsity-aware Kalman filtering (KF). Leveraging the grid-induced sparsity of
the novel model, two types of sparsity-cognizant TSSG-KF trackers are
developed: one effects sparsity through $\ell_1$-norm regularization, and the
other invokes sparsity as an extra measurement. Iterative extended KF and
Gauss-Newton algorithms are developed for reduced-complexity tracking, along
with accurate error covariance updates for assessing performance of the
resultant sparsity-aware state estimators. Based on TSSG state estimates, more
informative target position and track estimates can be obtained in a follow-up
step, ensuring that track association and position estimation errors do not
propagate back into TSSG state estimates. The novel TSSG trackers do not
require knowing the number of targets or their signal strengths, and exhibit
considerably lower complexity than the benchmark hidden Markov model filter,
especially for a large number of targets. Numerical simulations demonstrate
that sparsity-cognizant trackers enjoy improved root mean-square error
performance at reduced complexity when compared to their sparsity-agnostic
counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5304</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5304</id><created>2011-04-28</created><authors><author><keyname>Michel</keyname><forenames>Vincent</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Gramfort</keyname><forenames>Alexandre</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Varoquaux</keyname><forenames>Ga&#xeb;l</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Eger</keyname><forenames>Evelyn</forenames><affiliation>INRIA Saclay - Ile de France, LM-Orsay</affiliation></author><author><keyname>Keribin</keyname><forenames>Christine</forenames><affiliation>INRIA Saclay - Ile de France, LM-Orsay</affiliation></author><author><keyname>Thirion</keyname><forenames>Bertrand</forenames><affiliation>LNAO, INRIA Saclay - Ile de France</affiliation></author></authors><title>A supervised clustering approach for fMRI-based inference of brain
  states</title><categories>cs.CV</categories><proxy>ccsd</proxy><journal-ref>Pattern Recognition (2011)</journal-ref><doi>10.1016/j.patcog.2011.04.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method that combines signals from many brain regions observed in
functional Magnetic Resonance Imaging (fMRI) to predict the subject's behavior
during a scanning session. Such predictions suffer from the huge number of
brain regions sampled on the voxel grid of standard fMRI data sets: the curse
of dimensionality. Dimensionality reduction is thus needed, but it is often
performed using a univariate feature selection procedure, that handles neither
the spatial structure of the images, nor the multivariate nature of the signal.
By introducing a hierarchical clustering of the brain volume that incorporates
connectivity constraints, we reduce the span of the possible spatial
configurations to a single tree of nested regions tailored to the signal. We
then prune the tree in a supervised setting, hence the name supervised
clustering, in order to extract a parcellation (division of the volume) such
that parcel-based signal averages best predict the target information.
Dimensionality reduction is thus achieved by feature agglomeration, and the
constructed features now provide a multi-scale representation of the signal.
Comparisons with reference methods on both simulated and real data show that
our approach yields higher prediction accuracy than standard voxel-based
approaches. Moreover, the method infers an explicit weighting of the regions
involved in the regression or classification task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5327</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5327</id><created>2011-04-28</created><authors><author><keyname>Wagner</keyname><forenames>Noam</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Feuer</keyname><forenames>Arie</forenames></author><author><keyname>Danin</keyname><forenames>Gilad</forenames></author><author><keyname>Friedman</keyname><forenames>Zvi</forenames></author></authors><title>Xampling in Ultrasound Imaging</title><categories>cs.IT math.IT physics.med-ph</categories><comments>17 pages, 9 Figures. Introduced in SPIE Medical Imaging Conference,
  Orlando Florida, 2011</comments><journal-ref>Proc. SPIE 7968, 796818 (2011)</journal-ref><doi>10.1117/12.877818</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent developments of new medical treatment techniques put challenging
demands on ultrasound imaging systems in terms of both image quality and raw
data size. Traditional sampling methods result in very large amounts of data,
thus, increasing demands on processing hardware and limiting the exibility in
the post-processing stages. In this paper, we apply Compressed Sensing (CS)
techniques to analog ultrasound signals, following the recently developed
Xampling framework. The result is a system with significantly reduced sampling
rates which, in turn, means significantly reduced data size while maintaining
the quality of the resulting images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5335</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5335</id><created>2011-04-28</created><authors><author><keyname>Brihaye</keyname><forenames>Thomas</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author><author><keyname>Geeraerts</keyname><forenames>Gilles</forenames></author><author><keyname>Ouaknine</keyname><forenames>Jo&#xeb;l</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Worrell</keyname><forenames>James</forenames></author></authors><title>On Reachability for Hybrid Automata over Bounded Time</title><categories>cs.LO</categories><comments>20 pages. Full version of the ICALP 2011 proceedings paper</comments><journal-ref>Proceedings of ICALP 2011, LNCS</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the time-bounded version of the reachability problem
for hybrid automata. This problem asks whether a given hybrid automaton can
reach a given target location within T time units, where T is a constant
rational value. We show that, in contrast to the classical (unbounded)
reachability problem, the timed-bounded version is decidable for rectangular
hybrid automata provided only non-negative rates are allowed. This class of
systems is of practical interest and subsumes, among others, the class of
stopwatch automata. We also show that the problem becomes undecidable if either
diagonal constraints or both negative and positive rates are allowed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5344</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5344</id><created>2011-04-28</created><updated>2011-10-02</updated><authors><author><keyname>Takaguchi</keyname><forenames>Taro</forenames></author><author><keyname>Nakamura</keyname><forenames>Mitsuhiro</forenames></author><author><keyname>Sato</keyname><forenames>Nobuo</forenames></author><author><keyname>Yano</keyname><forenames>Kazuo</forenames></author><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author></authors><title>Predictability of conversation partners</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>38 pages, 19 figures</comments><journal-ref>Phys. Rev. X 1, 011008 (2011)</journal-ref><doi>10.1103/PhysRevX.1.011008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent developments in sensing technologies have enabled us to examine the
nature of human social behavior in greater detail. By applying an information
theoretic method to the spatiotemporal data of cell-phone locations, [C. Song
et al. Science 327, 1018 (2010)] found that human mobility patterns are
remarkably predictable. Inspired by their work, we address a similar
predictability question in a different kind of human social activity:
conversation events. The predictability in the sequence of one's conversation
partners is defined as the degree to which one's next conversation partner can
be predicted given the current partner. We quantify this predictability by
using the mutual information. We examine the predictability of conversation
events for each individual using the longitudinal data of face-to-face
interactions collected from two company offices in Japan. Each subject wears a
name tag equipped with an infrared sensor node, and conversation events are
marked when signals are exchanged between sensor nodes in close proximity. We
find that the conversation events are predictable to some extent; knowing the
current partner decreases the uncertainty about the next partner by 28.4% on
average. Much of the predictability is explained by long-tailed distributions
of interevent intervals. However, a predictability also exists in the data,
apart from the contribution of their long-tailed nature. In addition, an
individual's predictability is correlated with the position in the static
social network derived from the data. Individuals confined in a community - in
the sense of an abundance of surrounding triangles - tend to have low
predictability, and those bridging different communities tend to have high
predictability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5361</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5361</id><created>2011-04-28</created><updated>2011-05-01</updated><authors><author><keyname>Razgon</keyname><forenames>Igor</forenames></author></authors><title>Large Isolating Cuts Shrink the Multiway Cut</title><categories>cs.DM</categories><comments>Marcin Piliczuk has communicated to me a negative answer to the first
  open question. The graph was designed for a different purpose in
  collaboration with Marek Cygan, Jakub Wojtaszczyk, Micha{\l} Pilipczuk but,
  after a slight modification, suited to answer the question</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a preprocessing algorithm for the multiway cut problem that
establishes its polynomial kernelizability when the difference between the
parameter $k$ and the size of the smallest isolating cut is at most $log(k)$.
To the best of our knowledge, this is the first progress towards kernelization
of the multiway cut problem. We pose two open questions that, if answered
affirmatively, would imply, combined with the proposed result, unconditional
polynomial kernelizability of the multiway cut problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5362</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5362</id><created>2011-04-28</created><updated>2011-04-29</updated><authors><author><keyname>Kempe</keyname><forenames>Andr&#xe9;</forenames></author></authors><title>Selected Operations, Algorithms, and Applications of n-Tape Weighted
  Finite-State Machines</title><categories>cs.FL cs.CL</categories><comments>15 pages, 7 figures, LaTeX (+ .eps)</comments><acm-class>F.1.1; I.2.7</acm-class><journal-ref>Proc. FSMNLP 2009, Pretoria, South Africa. July 21-24. (invited
  talk)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A weighted finite-state machine with n tapes (n-WFSM) defines a rational
relation on n strings. It is a generalization of weighted acceptors (one tape)
and transducers (two tapes).
  After recalling some basic definitions about n-ary weighted rational
relations and n-WFSMs, we summarize some central operations on these relations
and machines, such as join and auto-intersection. Unfortunately, due to Post's
Correspondence Problem, a fully general join or auto-intersection algorithm
cannot exist. We recall a restricted algorithm for a class of n-WFSMs.
  Through a series of practical applications, we finally investigate the
augmented descriptive power of n-WFSMs and their join, compared to classical
transducers and their composition. Some applications are not feasible with the
latter. The series includes: the morphological analysis of Semitic languages,
the preservation of intermediate results in transducer cascades, the induction
of morphological rules from corpora, the alignment of lexicon entries, the
automatic extraction of acronyms and their meaning from corpora, and the search
for cognates in a bilingual lexicon.
  All described operations and applications have been implemented with Xerox's
WFSC tool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5368</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5368</id><created>2011-04-28</created><authors><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Masuzawa</keyname><forenames>Toshimitsu</forenames><affiliation>Department of Information and Computer sciences Osaka University</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6, IUF</affiliation></author></authors><title>Maximum Metric Spanning Tree made Byzantine Tolerant</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-stabilization is a versatile approach to fault-tolerance since it
permits a distributed system to recover from any transient fault that
arbitrarily corrupts the contents of all memories in the system. Byzantine
tolerance is an attractive feature of distributed systems that permits to cope
with arbitrary malicious behaviors. This paper focus on systems that are both
self-stabilizing and Byzantine tolerant. We consider the well known problem of
constructing a maximum metric tree in this context. Combining these two
properties is known to induce many impossibility results. In this paper, we
provide first two impossibility results about the construction of maximum
metric tree in presence of transients and (permanent) Byzantine faults. Then,
we provide a new self-stabilizing protocol that provides optimal containment of
an arbitrary number of Byzantine faults.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5369</identifier>
 <datestamp>2011-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5369</id><created>2011-04-28</created><updated>2011-12-21</updated><authors><author><keyname>Simon</keyname><forenames>Emile</forenames></author></authors><title>Optimal static output feedback design through direct search</title><categories>math.OC cs.SY</categories><comments>See the version 2 http://arxiv.org/abs/1104.5369v2 for the 50th
  CDC-ECC 2011 paper. This third version is the beamer presentation that was
  given at the conference. Note that this presentation gives additional
  interesting elements. For more details, see also the paper on
  http://arxiv.org/abs/1109.5966 (and future version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper and associated presentation is to put forward
derivative-free optimization methods for control design. The important element,
still ignored at the end of 2011 in systems and control (i.e. this element has
apparently never been used so far in the systems and control litterature), is
that derivative-free optimization methods were relatively recently proven to
converge not only on smooth objective functions but also on most non-smooth and
discontinuous objective functions. This opens an avenue of posibilities for
solving problems unyielding to classical optimization techniques.
  Original abstract:
  This paper investigates the performance of using a direct search method to
design optimal Static Output Feedback (SOF) controllers for Linear Time
Invariant (LTI) systems. Considering the old age of both SOF problems and
direct search methods, surprisingly good performances will be obtained compared
to a state-of-the-art method. The motivation is to emphasize the fact that
direct search methods are too much neglected by the control community. These
methods are very rich for practical purposes on a lot of complex problems
unyielding to classical optimization techniques, like linear matrix
inequalities, thanks to their ability to explore even non-smooth functions on
non-convex feasible sets.
  Again, the key element here are the relatively new strong theoretical
convergence guarantees of derivatie-free methods. Thanks to these, using such
optimization methods is superior to other methods without convergence
guarantees (like most iterative LMI schemes).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5377</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5377</id><created>2011-04-28</created><authors><author><keyname>Hienert</keyname><forenames>Daniel</forenames></author><author><keyname>Zapilko</keyname><forenames>Benjamin</forenames></author><author><keyname>Schaer</keyname><forenames>Philipp</forenames></author><author><keyname>Mathiak</keyname><forenames>Brigitte</forenames></author></authors><title>VIZGR: Combining Data on a Visual Level</title><categories>cs.HC</categories><comments>To be published in Proceedings of 7th International Conference on Web
  Information Systems and Technologies (WEBIST), 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel method to connect data on the visualization
level. In general, visualizations are a dead end, when it comes to reusability.
Yet, users prefer to work with visualizations as evidenced by WYSIWYG editors.
To enable users to work with their data in a way that is intuitive to them, we
have created Vizgr. Vizgr.com offers basic visualization methods, like graphs,
tag clouds, maps and time lines. But unlike normal data visualizations, these
can be re-used, connected to each other and to web sites. We offer a simple
opportunity to combine diverse data structures, such as geo-locations and
networks, with each other by a mouse click. In an evaluation, we found that
over 85 % of the participants were able to use and understand this technology
without any training or explicit instructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5384</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5384</id><created>2011-04-28</created><updated>2011-08-16</updated><authors><author><keyname>Lyons</keyname><forenames>Daniel</forenames></author><author><keyname>Calliess</keyname><forenames>Jan-P.</forenames></author><author><keyname>Hanebeck</keyname><forenames>Uwe D.</forenames></author></authors><title>Chance-constrained Model Predictive Control for Multi-Agent Systems</title><categories>cs.SY cs.MA math.OC</categories><comments>33 pages, 5 figures, revised version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider stochastic model predictive control of a multi-agent systems with
constraints on the probabilities of inter-agent collisions. We first study a
sample-based approximation of the collision probabilities and use this
approximation to formulate constraints for the stochastic control problem. This
approximation will converge as the number of samples goes to infinity, however,
the complexity of the resulting control problem is so high that this approach
proves unsuitable for control under real-time requirements. To alleviate the
computational burden we propose a second approach that uses probabilistic
bounds to determine regions with increased probability of presence for each
agent and formulate constraints for the control problem that guarantee that
these regions will not overlap. We prove that the resulting problem is
conservative for the original problem with probabilistic constraints, ie. every
control strategy that is feasible under our new constraints will automatically
be feasible for the original problem. Furthermore we show in simulations in a
UAV path planning scenario that our proposed approach grants significantly
better run-time performance compared to a controller with the sample-based
approximation with only a small degree of sub-optimality resulting from the
conservativeness of our new approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5387</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5387</id><created>2011-04-28</created><authors><author><keyname>Rashed</keyname><forenames>M. Z.</forenames></author><author><keyname>Hassan</keyname><forenames>Ahmed E.</forenames></author><author><keyname>Sharaf</keyname><forenames>Ahmed I.</forenames></author></authors><title>Model based system engineering approach of a lightweight embedded TCP/IP</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of embedded software is growing very rapidly. Accessing the internet
is a necessary service which has large range of applications in many fields.
The Internet is based on TCP/IP which is a very important stack. Although
TCP/IP is very important there is not a software engineering model describing
it. The common method in modeling and describing TCP/IP is RFCs which is not
sufficient for software engineer and developers. Therefore there is a need for
software engineering approach to help engineers and developers to customize
their own web based applications for embedded systems. This research presents a
model based system engineering approach of lightweight TCP/IP. The model
contains the necessary phases for developing a lightweight TCP/IP for embedded
systems. The proposed model is based on SysML as a model based system
engineering language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5391</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5391</id><created>2011-04-28</created><authors><author><keyname>Liu</keyname><forenames>Quan</forenames></author><author><keyname>Wang</keyname><forenames>Kehao</forenames></author><author><keyname>Chen</keyname><forenames>Lin</forenames></author></authors><title>On Optimality of Greedy Policy for a Class of Standard Reward Function
  of Restless Multi-armed Bandit Problem</title><categories>cs.LG cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper,we consider the restless bandit problem, which is one of the
most well-studied generalizations of the celebrated stochastic multi-armed
bandit problem in decision theory. However, it is known be PSPACE-Hard to
approximate to any non-trivial factor. Thus the optimality is very difficult to
obtain due to its high complexity. A natural method is to obtain the greedy
policy considering its stability and simplicity. However, the greedy policy
will result in the optimality loss for its intrinsic myopic behavior generally.
In this paper, by analyzing one class of so-called standard reward function, we
establish the closed-form condition about the discounted factor \beta such that
the optimality of the greedy policy is guaranteed under the discounted expected
reward criterion, especially, the condition \beta = 1 indicating the optimality
of the greedy policy under the average accumulative reward criterion. Thus, the
standard form of reward function can easily be used to judge the optimality of
the greedy policy without any complicated calculation. Some examples in
cognitive radio networks are presented to verify the effectiveness of the
mathematical result in judging the optimality of the greedy policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5392</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5392</id><created>2011-04-28</created><authors><author><keyname>Marzolla</keyname><forenames>Moreno</forenames></author><author><keyname>Mirandola</keyname><forenames>Raffaela</forenames></author></authors><title>A Framework for QoS-aware Execution of Workflows over the Cloud</title><categories>cs.DC cs.PF</categories><journal-ref>Proc. 2nd International Conference on Cloud Computing and Services
  Science (CLOSER 2012), Frank Leymann, Ivan Ivanov, Marten Von Sideren, Tony
  Shan (Editors), April 18-21 2012, Porto, Portugal, ISBN 978-989-8565-05-1,
  pp. 216--221</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Cloud Computing paradigm is providing system architects with a new
powerful tool for building scalable applications. Clouds allow allocation of
resources on a &quot;pay-as-you-go&quot; model, so that additional resources can be
requested during peak loads and released after that. However, this flexibility
asks for appropriate dynamic reconfiguration strategies. In this paper we
describe SAVER (qoS-Aware workflows oVER the Cloud), a QoS-aware algorithm for
executing workflows involving Web Services hosted in a Cloud environment. SAVER
allows execution of arbitrary workflows subject to response time constraints.
SAVER uses a passive monitor to identify workload fluctuations based on the
observed system response time. The information collected by the monitor is used
by a planner component to identify the minimum number of instances of each Web
Service which should be allocated in order to satisfy the response time
constraint. SAVER uses a simple Queueing Network (QN) model to identify the
optimal resource allocation. Specifically, the QN model is used to identify
bottlenecks, and predict the system performance as Cloud resources are
allocated or released. The parameters used to evaluate the model are those
collected by the monitor, which means that SAVER does not require any
particular knowledge of the Web Services and workflows being executed. Our
approach has been validated through numerical simulations, whose results are
reported in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5400</identifier>
 <datestamp>2011-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5400</id><created>2011-04-28</created><updated>2011-11-14</updated><authors><author><keyname>Porat</keyname><forenames>Ely</forenames></author><author><keyname>Shalem</keyname><forenames>Bar</forenames></author></authors><title>A cuckoo hashing variant with improved memory utilization and insertion
  time</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cuckoo hashing [4] is a multiple choice hashing scheme in which each item can
be placed in multiple locations, and collisions are resolved by moving items to
their alternative locations. In the classical implementation of two-way cuckoo
hashing, the memory is partitioned into contiguous disjoint fixed-size buckets.
Each item is hashed to two buckets, and may be stored in any of the positions
within those buckets. Ref. [2] analyzed a variation in which the buckets are
contiguous and overlap. However, many systems retrieve data from secondary
storage in same-size blocks called pages. Fetching a page is a relatively
expensive process; but once a page is fetched, its contents can be accessed
orders of magnitude faster. We utilize this property of memory retrieval,
presenting a variant of cuckoo hashing incorporating the following constraint:
each bucket must be fully contained in a single page, but buckets are not
necessarily contiguous. Empirical results show that this modification increases
memory utilization and decreases the number of iterations required to insert an
item. If each item is hashed to two buckets of capacity two, the page size is
8, and each bucket is fully contained in a single page, the memory utilization
equals 89.71% in the classical contiguous disjoint bucket variant, 93.78% in
the contiguous overlapping bucket variant, and increases to 97.46% in our new
non-contiguous bucket variant. When the memory utilization is 92% and we use
breadth first search to look for a vacant position, the number of iterations
required to insert a new item is dramatically reduced from 545 in the
contiguous overlapping buckets variant to 52 in our new non-contiguous bucket
variant. In addition to the empirical results, we present a theoretical lower
bound on the memory utilization of our variation as a function of the page
size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5415</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5415</id><created>2011-04-28</created><updated>2011-08-20</updated><authors><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Pan</keyname><forenames>Guangming</forenames></author><author><keyname>Chen</keyname><forenames>Jung-Chieh</forenames></author><author><keyname>Guo</keyname><forenames>Mei-Hui</forenames></author></authors><title>A Deterministic Equivalent for the Analysis of Small Cell Networks</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author, since we have reworked
  on the organization to improve the presentation as well as readability. In
  addition, to properly reflect the main purpose of this work, we have changed
  the paper title to: A Deterministic Equivalent for the Analysis of
  Non-Gaussian Correlated MIMO Multiple Access Channels</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To properly reflect the main purpose of this work, we have changed the paper
title to: A Deterministic Equivalent for the Analysis of Non-Gaussian
Correlated MIMO Multiple Access Channels
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5422</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5422</id><created>2011-04-28</created><updated>2011-09-26</updated><authors><author><keyname>Lu</keyname><forenames>Jie</forenames></author><author><keyname>Tang</keyname><forenames>Choon Yik</forenames></author></authors><title>Zero-Gradient-Sum Algorithms for Distributed Convex Optimization: The
  Continuous-Time Case</title><categories>cs.SY cs.DC math.OC</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a set of continuous-time distributed algorithms that
solve unconstrained, separable, convex optimization problems over undirected
networks with fixed topologies. The algorithms are developed using a Lyapunov
function candidate that exploits convexity, and are called Zero-Gradient-Sum
(ZGS) algorithms as they yield nonlinear networked dynamical systems that
evolve invariantly on a zero-gradient-sum manifold and converge asymptotically
to the unknown optimizer. We also describe a systematic way to construct ZGS
algorithms, show that a subset of them actually converge exponentially, and
obtain lower and upper bounds on their convergence rates in terms of the
network topologies, problem characteristics, and algorithm parameters,
including the algebraic connectivity, Laplacian spectral radius, and function
curvatures. The findings of this paper may be regarded as a natural
generalization of several well-known algorithms and results for distributed
consensus, to distributed convex optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5456</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5456</id><created>2011-04-28</created><updated>2011-06-19</updated><authors><author><keyname>Ordentlich</keyname><forenames>Or</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author></authors><title>Interference Alignment at Finite SNR for Time-Invariant Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An achievable rate region, based on lattice interference alignment, is
derived for a class of time-invariant Gaussian interference channels with more
than two users. The result is established via a new coding theorem for the
two-user Gaussian multiple-access channel where both users use a single linear
code. The class of interference channels treated is such that all interference
channel gains are rational. For this class of interference channels, beyond
recovering the known results on the degrees of freedom, an explicit rate region
is derived for finite signal-to-noise ratios, shedding light on the nature of
previously established asymptotic results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5466</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5466</id><created>2011-04-28</created><authors><author><keyname>Burfoot</keyname><forenames>Daniel</forenames></author></authors><title>Notes on a New Philosophy of Empirical Science</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>Draft Version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This book presents a methodology and philosophy of empirical science based on
large scale lossless data compression. In this view a theory is scientific if
it can be used to build a data compression program, and it is valuable if it
can compress a standard benchmark database to a small size, taking into account
the length of the compressor itself. This methodology therefore includes an
Occam principle as well as a solution to the problem of demarcation. Because of
the fundamental difficulty of lossless compression, this type of research must
be empirical in nature: compression can only be achieved by discovering and
characterizing empirical regularities in the data. Because of this, the
philosophy provides a way to reformulate fields such as computer vision and
computational linguistics as empirical sciences: the former by attempting to
compress databases of natural images, the latter by attempting to compress
large text databases. The book argues that the rigor and objectivity of the
compression principle should set the stage for systematic progress in these
fields. The argument is especially strong in the context of computer vision,
which is plagued by chronic problems of evaluation.
  The book also considers the field of machine learning. Here the traditional
approach requires that the models proposed to solve learning problems be
extremely simple, in order to avoid overfitting. However, the world may contain
intrinsically complex phenomena, which would require complex models to
understand. The compression philosophy can justify complex models because of
the large quantity of data being modeled (if the target database is 100 Gb, it
is easy to justify a 10 Mb model). The complex models and abstractions learned
on the basis of the raw data (images, language, etc) can then be reused to
solve any specific learning problem, such as face recognition or machine
translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5474</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5474</id><created>2011-04-28</created><updated>2011-07-26</updated><authors><author><keyname>Aksoy</keyname><forenames>Sinan</forenames></author><author><keyname>Azzam</keyname><forenames>Adam</forenames></author><author><keyname>Coppersmith</keyname><forenames>Chaya</forenames></author><author><keyname>Glass</keyname><forenames>Julie</forenames></author><author><keyname>Karaali</keyname><forenames>Gizem</forenames></author><author><keyname>Zhao</keyname><forenames>Xueying</forenames></author><author><keyname>Zhu</keyname><forenames>Xinjing</forenames></author></authors><title>Coalitions and Cliques in the School Choice Problem</title><categories>math.OC cs.SI math.CO physics.soc-ph</categories><msc-class>90C27, 91A40</msc-class><journal-ref>Involve 8 (2015) 801-823</journal-ref><doi>10.2140/involve.2015.8.801</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The school choice mechanism design problem focuses on assignment mechanisms
matching students to public schools in a given school district. The well-known
Gale Shapley Student Optimal Stable Matching Mechanism (SOSM) is the most
efficient stable mechanism proposed so far as a solution to this problem.
However its inefficiency is well-documented, and recently the Efficiency
Adjusted Deferred Acceptance Mechanism (EADAM) was proposed as a remedy for
this weakness. In this note we describe two related adjustments to SOSM with
the intention to address the same inefficiency issue. In one we create possibly
artificial coalitions among students where some students modify their
preference profiles in order to improve the outcome for some other students.
Our second approach involves trading cliques among students where those
involved improve their assignments by waiving some of their priorities. The
coalition method yields the EADAM outcome among other Pareto dominations of the
SOSM outcome, while the clique method yields all possible Pareto optimal Pareto
dominations of SOSM. The clique method furthermore incorporates a natural
solution to the problem of breaking possible ties within preference and
priority profiles. We discuss the practical implications and limitations of our
approach in the final section of the article.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5510</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5510</id><created>2011-04-28</created><authors><author><keyname>Saeed</keyname><forenames>Fahad</forenames></author><author><keyname>Pisitkun</keyname><forenames>Trairak</forenames></author><author><keyname>Knepper</keyname><forenames>Mark A.</forenames></author><author><keyname>Hoffert</keyname><forenames>Jason D.</forenames></author></authors><title>Mining Temporal Patterns from iTRAQ Mass Spectrometry(LC-MS/MS) Data</title><categories>q-bio.QM cs.CE cs.DB cs.DS q-bio.MN</categories><comments>12 pages, 10 figures, The Proceedings of the ISCA 3rd International
  Conference on Bioinformatics and Computational Biology (BiCoB), pp 152-159
  New Orleans, Louisiana, USA, March 23-25, 2011 (ISBN: 978-1-880843-81-9)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale proteomic analysis is emerging as a powerful technique in biology
and relies heavily on data acquired by state-of-the-art mass spectrometers. As
with any other field in Systems Biology, computational tools are required to
deal with this ocean of data. iTRAQ (isobaric Tags for Relative and Absolute
quantification) is a technique that allows simultaneous quantification of
proteins from multiple samples. Although iTRAQ data gives useful insights to
the biologist, it is more complex to perform analysis and draw biological
conclusions because of its multi-plexed design. One such problem is to find
proteins that behave in a similar way (i.e. change in abundance) among various
time points since the temporal variations in the proteomics data reveal
important biological information. Distance based methods such as Euclidian
distance or Pearson coefficient, and clustering techniques such as k-mean etc,
are not able to take into account the temporal information of the series. In
this paper, we present an linear-time algorithm for clustering similar patterns
among various iTRAQ time course data irrespective of their absolute values. The
algorithm, referred to as Temporal Pattern Mining(TPM), maps the data from a
Cartesian plane to a discrete binary plane. After the mapping a dynamic
programming technique allows mining of similar data elements that are
temporally closer to each other. The proposed algorithm accurately clusters
iTRAQ data that are temporally closer to each other with more than 99%
accuracy. Experimental results for different problem sizes are analyzed in
terms of quality of clusters, execution time and scalability for large data
sets. An example from our proteomics data is provided at the end to demonstrate
the performance of the algorithm and its ability to cluster temporal series
irrespective of their distance from each other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5517</identifier>
 <datestamp>2012-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5517</id><created>2011-04-28</created><updated>2012-12-04</updated><authors><author><keyname>Elmasry</keyname><forenames>Amr</forenames></author><author><keyname>He</keyname><forenames>Meng</forenames></author><author><keyname>Munro</keyname><forenames>J. Ian</forenames></author><author><keyname>Nicholson</keyname><forenames>Patrick K.</forenames></author></authors><title>Dynamic Range Majority Data Structures</title><categories>cs.DS cs.DB</categories><comments>16 pages, Preliminary version appeared in ISAAC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set $P$ of coloured points on the real line, we study the problem of
answering range $\alpha$-majority (or &quot;heavy hitter&quot;) queries on $P$. More
specifically, for a query range $Q$, we want to return each colour that is
assigned to more than an $\alpha$-fraction of the points contained in $Q$. We
present a new data structure for answering range $\alpha$-majority queries on a
dynamic set of points, where $\alpha \in (0,1)$. Our data structure uses O(n)
space, supports queries in $O((\lg n) / \alpha)$ time, and updates in $O((\lg
n) / \alpha)$ amortized time. If the coordinates of the points are integers,
then the query time can be improved to $O(\lg n / (\alpha \lg \lg n) +
(\lg(1/\alpha))/\alpha))$. For constant values of $\alpha$, this improved query
time matches an existing lower bound, for any data structure with
polylogarithmic update time. We also generalize our data structure to handle
sets of points in d-dimensions, for $d \ge 2$, as well as dynamic arrays, in
which each entry is a colour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5532</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5532</id><created>2011-04-28</created><authors><author><keyname>Barmpoutis</keyname><forenames>Dionysios</forenames></author><author><keyname>Murray</keyname><forenames>Richard M.</forenames></author></authors><title>Extremal Properties of Complex Networks</title><categories>q-bio.MN cond-mat.stat-mech cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the structure of connected graphs with the minimum and maximum
average distance, radius, diameter, betweenness centrality, efficiency and
resistance distance, given their order and size. We find tight bounds on these
graph qualities for any arbitrary number of nodes and edges and analytically
derive the form and properties of such networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5533</identifier>
 <datestamp>2011-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5533</id><created>2011-04-28</created><updated>2011-09-16</updated><authors><author><keyname>Angelino</keyname><forenames>Elaine</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Thaler</keyname><forenames>Justin</forenames></author></authors><title>External-Memory Multimaps</title><categories>cs.DS</categories><comments>Accepted to ISAAC 2011. 22 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many data structures support dictionaries, also known as maps or associative
arrays, which store and manage a set of key-value pairs. A \emph{multimap} is
generalization that allows multiple values to be associated with the same key.
For example, the inverted file data structure that is used prevalently in the
infrastructure supporting search engines is a type of multimap, where words are
used as keys and document pointers are used as values. We study the multimap
abstract data type and how it can be implemented efficiently online in external
memory frameworks, with constant expected I/O performance. The key technique
used to achieve our results is a combination of cuckoo hashing using buckets
that hold multiple items with a multiqueue implementation to cope with varying
numbers of values per key. Our external-memory results are for the standard
two-level memory model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5534</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5534</id><created>2011-04-28</created><authors><author><keyname>Yu</keyname><forenames>F. Richard</forenames></author><author><keyname>Sun</keyname><forenames>Bo</forenames></author><author><keyname>Krishnamurthy</keyname><forenames>Vikram</forenames></author><author><keyname>Ali</keyname><forenames>Saqib</forenames></author></authors><title>QoS Provisioning for Multimedia Transmission in Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cognitive radio (CR) networks, the perceived reduction of application
layer quality of service (QoS), such as multimedia distortion, by secondary
users may impede the success of CR technologies. Most previous work in CR
networks ignores application layer QoS. In this paper we take an integrated
design approach to jointly optimize multimedia intra refreshing rate, an
application layer parameter, together with access strategy, and spectrum
sensing for multimedia transmission in a CR system with time varying wireless
channels. Primary network usage and channel gain are modeled as a finite state
Markov process. With channel sensing and channel state information errors, the
system state cannot be directly observed. We formulate the QoS optimization
problem as a partially observable Markov decision process (POMDP). A low
complexity dynamic programming framework is presented to obtain the optimal
policy. Simulation results show the effectiveness of the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5538</identifier>
 <datestamp>2012-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5538</id><created>2011-04-28</created><authors><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author><author><keyname>Prokopenko</keyname><forenames>Mikhail</forenames></author></authors><title>Complex Networks</title><categories>cs.NE cs.SI nlin.AO physics.soc-ph</categories><comments>7 pages, in press</comments><journal-ref>Artificial Life 17(4):259--261. 2011</journal-ref><doi>10.1162/artl_e_00037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Introduction to the Special Issue on Complex Networks, Artificial Life
journal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5539</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5539</id><created>2011-04-28</created><authors><author><keyname>Yu</keyname><forenames>F. Richard</forenames></author><author><keyname>Tang</keyname><forenames>Helen</forenames></author><author><keyname>Huang</keyname><forenames>Minyi</forenames></author><author><keyname>Mason</keyname><forenames>Peter</forenames></author><author><keyname>Li</keyname><forenames>Zhiqiang</forenames></author></authors><title>Distributed Cooperative Spectrum Sensing in Mobile Ad Hoc Networks with
  Cognitive Radios</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cognitive radio mobile ad hoc networks (CR-MANETs), secondary users can
cooperatively sense the spectrum to detect the presence of primary users. In
this chapter, we propose a fully distributed and scalable cooperative spectrum
sensing scheme based on recent advances in consensus algorithms. In the
proposed scheme, the secondary users can maintain coordination based on only
local information exchange without a centralized common receiver. We use the
consensus of secondary users to make the final decision. The proposed scheme is
essentially based on recent advances in consensus algorithms that have taken
inspiration from complex natural phenomena including flocking of birds,
schooling of fish, swarming of ants and honeybees. Unlike the existing
cooperative spectrum sensing schemes, there is no need for a centralized
receiver in the proposed schemes, which make them suitable in distributed
CR-MANETs. Simulation results show that the proposed consensus schemes can have
significant lower missing detection probabilities and false alarm probabilities
in CR-MANETs. It is also demonstrated that the proposed scheme not only has
proven sensitivity in detecting the primary user's presence, but also has
robustness in choosing a desirable decision threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5544</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5544</id><created>2011-04-28</created><authors><author><keyname>Conlon</keyname><forenames>David</forenames></author><author><keyname>Fox</keyname><forenames>Jacob</forenames></author><author><keyname>Sudakov</keyname><forenames>Benny</forenames></author></authors><title>Erdos-Hajnal-type theorems in hypergraphs</title><categories>math.CO cs.DM</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Erdos-Hajnal conjecture states that if a graph on n vertices is H-free,
that is, it does not contain an induced copy of a given graph H, then it must
contain either a clique or an independent set of size n^{d(H)}, where d(H) &gt; 0
depends only on the graph H. Except for a few special cases, this conjecture
remains wide open. However, it is known that a H-free graph must contain a
complete or empty bipartite graph with parts of polynomial size. We prove an
analogue of this result for 3-uniform hypergraphs, showing that if a 3-uniform
hypergraph on n vertices is H-free, for any given H, then it must contain a
complete or empty tripartite subgraph with parts of order c(log n)^{1/2 +
d(H)}, where d(H) &gt; 0 depends only on H. This improves on the bound of c(log
n)^{1/2}, which holds in all 3-uniform hypergraphs, and, up to the value of the
constant d(H), is best possible. We also prove that, for k &gt; 3, no analogue of
the standard Erdos-Hajnal conjecture can hold in k-uniform hypergraphs. That
is, there are k-uniform hypergraphs H and sequences of H-free hypergraphs which
do not contain cliques or independent sets of size appreciably larger than one
would normally expect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5546</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5546</id><created>2011-04-28</created><authors><author><keyname>Kanoria</keyname><forenames>Yashodhan</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>Optimal coding for the deletion channel with small deletion probability</title><categories>cs.IT math.IT</categories><comments>45 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The deletion channel is the simplest point-to-point communication channel
that models lack of synchronization. Input bits are deleted independently with
probability d, and when they are not deleted, they are not affected by the
channel. Despite significant effort, little is known about the capacity of this
channel, and even less about optimal coding schemes. In this paper we develop a
new systematic approach to this problem, by demonstrating that capacity can be
computed in a series expansion for small deletion probability. We compute three
leading terms of this expansion, and find an input distribution that achieves
capacity up to this order. This constitutes the first optimal coding result for
the deletion channel.
  The key idea employed is the following: We understand perfectly the deletion
channel with deletion probability d=0. It has capacity 1 and the optimal input
distribution is i.i.d. Bernoulli(1/2). It is natural to expect that the channel
with small deletion probabilities has a capacity that varies smoothly with d,
and that the optimal input distribution is obtained by smoothly perturbing the
i.i.d. Bernoulli(1/2) process. Our results show that this is indeed the case.
We think that this general strategy can be useful in a number of capacity
calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5553</identifier>
 <datestamp>2011-12-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5553</id><created>2011-04-29</created><updated>2011-12-13</updated><authors><author><keyname>Hosseini</keyname><forenames>Kianoush</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj S.</forenames></author></authors><title>Resource Allocation for Selection-Based Cooperative OFDM Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers resource allocation to achieve max-min fairness in a
selection-based orthogonal frequency division multiplexing network wherein
source nodes are assisted by fixed decode-and-forward relays. The joint problem
of transmission strategy selection, relay assignment, and power allocation is a
combinatorial problem with exponential complexity. To develop effective
solutions to these questions, we approach these problems in two stages. The
first set of problems assume ideal source-relay channels; this simplification
helps illustrate our general methodology and also why our solutions provide
tight bounds. We then formulate the general problem of transmission strategy
selection, relay assignment, and power allocation at the sources and relays
considering all communication channels, i.e., finite power source-relay
channels. In both sets of problems mentioned so far, transmissions over
subcarriers are assumed to be independent. However, given the attendant
problems of synchronization and the implementation using a FFT/IFFT pair,
resource allocation at the subcarrier level appears impractical. We, therefore,
consider resource allocation at the level of an entire OFDM block. While
optimal resource management requires an exhaustive search, we develop tight
bounds with lower complexity. Finally, we propose a decentralized block-based
relaying scheme. Simulation results using the COST-231 channel model show that
this scheme yields close-to-optimal performance while offering many
computational benefits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5557</identifier>
 <datestamp>2011-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5557</id><created>2011-04-29</created><updated>2011-11-15</updated><authors><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author></authors><title>Randomized algorithms for matrices and data</title><categories>cs.DS</categories><comments>Review article, 54 pages, 198 references. Version appearing as a
  monograph in Now Publishers' &quot;Foundations and Trends in Machine Learning&quot;
  series</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized algorithms for very large matrix problems have received a great
deal of attention in recent years. Much of this work was motivated by problems
in large-scale data analysis, and this work was performed by individuals from
many different research communities. This monograph will provide a detailed
overview of recent work on the theory of randomized matrix algorithms as well
as the application of those ideas to the solution of practical problems in
large-scale data analysis. An emphasis will be placed on a few simple core
ideas that underlie not only recent theoretical advances but also the
usefulness of these tools in large-scale data applications. Crucial in this
context is the connection with the concept of statistical leverage. This
concept has long been used in statistical regression diagnostics to identify
outliers; and it has recently proved crucial in the development of improved
worst-case matrix algorithms that are also amenable to high-quality numerical
implementation and that are useful to domain scientists. Randomized methods
solve problems such as the linear least-squares problem and the low-rank matrix
approximation problem by constructing and operating on a randomized sketch of
the input matrix. Depending on the specifics of the situation, when compared
with the best previously-existing deterministic algorithms, the resulting
randomized algorithms have worst-case running time that is asymptotically
faster; their numerical implementations are faster in terms of clock-time; or
they can be implemented in parallel computing environments where existing
numerical algorithms fail to run at all. Numerous examples illustrating these
observations will be described in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5566</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5566</id><created>2011-04-29</created><updated>2011-08-11</updated><authors><author><keyname>Szeider</keyname><forenames>Stefan</forenames></author></authors><title>Limits of Preprocessing</title><categories>cs.AI cs.CC</categories><comments>This is a slightly longer version of a paper that appeared in the
  proceedings of AAAI 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a first theoretical analysis of the power of polynomial-time
preprocessing for important combinatorial problems from various areas in AI. We
consider problems from Constraint Satisfaction, Global Constraints,
Satisfiability, Nonmonotonic and Bayesian Reasoning. We show that, subject to a
complexity theoretic assumption, none of the considered problems can be reduced
by polynomial-time preprocessing to a problem kernel whose size is polynomial
in a structural problem parameter of the input, such as induced width or
backdoor size. Our results provide a firm theoretical boundary for the
performance of polynomial-time preprocessing algorithms for the considered
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5578</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5578</id><created>2011-04-29</created><authors><author><keyname>Lee</keyname><forenames>Conrad</forenames></author><author><keyname>Reid</keyname><forenames>Fergal</forenames></author><author><keyname>McDaid</keyname><forenames>Aaron</forenames></author><author><keyname>Hurley</keyname><forenames>Neil</forenames></author></authors><title>Seeding for pervasively overlapping communities</title><categories>physics.soc-ph cs.SI</categories><comments>8 Pages</comments><acm-class>H.2.8</acm-class><doi>10.1103/PhysRevE.83.066107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In some social and biological networks, the majority of nodes belong to
multiple communities. It has recently been shown that a number of the
algorithms that are designed to detect overlapping communities do not perform
well in such highly overlapping settings. Here, we consider one class of these
algorithms, those which optimize a local fitness measure, typically by using a
greedy heuristic to expand a seed into a community. We perform synthetic
benchmarks which indicate that an appropriate seeding strategy becomes
increasingly important as the extent of community overlap increases. We find
that distinct cliques provide the best seeds. We find further support for this
seeding strategy with benchmarks on a Facebook network and the yeast
interactome.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5597</identifier>
 <datestamp>2012-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5597</id><created>2011-04-29</created><updated>2012-04-24</updated><authors><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Mulzer</keyname><forenames>Wolfgang</forenames></author></authors><title>A Static Optimality Transformation with Applications to Planar Point
  Location</title><categories>cs.CG cs.DS</categories><comments>13 pages, 1 figure, a preliminary version appeared at SoCG 2011</comments><acm-class>E.1; F.2.2</acm-class><journal-ref>International Journal of Computational Geometry and Applications
  (IJCGA), 22(4), 2012, pp. 327-340</journal-ref><doi>10.1142/S0218195912600084</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last decade, there have been several data structures that, given a
planar subdivision and a probability distribution over the plane, provide a way
for answering point location queries that is fine-tuned for the distribution.
All these methods suffer from the requirement that the query distribution must
be known in advance.
  We present a new data structure for point location queries in planar
triangulations. Our structure is asymptotically as fast as the optimal
structures, but it requires no prior information about the queries. This is a
2D analogue of the jump from Knuth's optimum binary search trees (discovered in
1971) to the splay trees of Sleator and Tarjan in 1985. While the former need
to know the query distribution, the latter are statically optimal. This means
that we can adapt to the query sequence and achieve the same asymptotic
performance as an optimum static structure, without needing any additional
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5601</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5601</id><created>2011-04-29</created><authors><author><keyname>Mannor</keyname><forenames>Shie</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John</forenames></author></authors><title>Mean-Variance Optimization in Markov Decision Processes</title><categories>cs.LG cs.AI</categories><comments>A full version of an ICML 2011 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider finite horizon Markov decision processes under performance
measures that involve both the mean and the variance of the cumulative reward.
We show that either randomized or history-based policies can improve
performance. We prove that the complexity of computing a policy that maximizes
the mean reward under a variance constraint is NP-hard for some cases, and
strongly NP-hard for others. We finally offer pseudopolynomial exact and
approximation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5603</identifier>
 <datestamp>2011-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5603</id><created>2011-04-29</created><updated>2011-10-18</updated><authors><author><keyname>Furuichi</keyname><forenames>S.</forenames></author><author><keyname>Mitroi</keyname><forenames>F. -C.</forenames></author></authors><title>Mathematical inequalities for some divergences</title><categories>cond-mat.stat-mech cs.IT math.CA math.IT</categories><comments>18 pages</comments><msc-class>94A17, 26D15</msc-class><journal-ref>Physica A 391 (2012) 388--400</journal-ref><doi>10.1016/j.physa.2011.07.052</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Divergences often play important roles for study in information science so
that it is indispensable to investigate their fundamental properties. There is
also a mathematical significance of such results. In this paper, we introduce
some parametric extended divergences combining Jeffreys divergence and Tsallis
entropy defined by generalized logarithmic functions, which lead to new
inequalities. In addition, we give lower bounds for one-parameter extended
Fermi-Dirac and Bose-Einstein divergences. Finally, we establish some
inequalities for the Tsallis entropy, the Tsallis relative entropy and some
divergences by the use of the Young's inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5608</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5608</id><created>2011-04-29</created><authors><author><keyname>Guan</keyname><forenames>Quansheng</forenames></author><author><keyname>Yu</keyname><forenames>F. Richard</forenames></author><author><keyname>Jiang</keyname><forenames>Shengming</forenames></author></authors><title>Topology Control and Routing in Mobile Ad Hoc Networks with Cognitive
  Radios</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio (CR) technology will have significant impacts on upper layer
performance in mobile ad hoc networks (MANETs). In this paper, we study
topology control and routing in CR-MANETs. We propose a distributed
Prediction-based Cognitive Topology Control (PCTC) scheme to provision
cognition capability to routing in CR-MANETs. PCTC is a midware-like
cross-layer module residing between CR module and routing. The proposed PCTC
scheme uses cognitive link availability prediction, which is aware of the
interference to primary users, to predict the available duration of links in
CR-MANETs. Based on the link prediction, PCTC constructs an efficient and
reliable topology, which is aimed at mitigating re-routing frequency and
improving end-to-end network performance such as throughput and delay.
Simulation results are presented to show the effectiveness of the proposed
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5616</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5616</id><created>2011-04-29</created><updated>2011-08-22</updated><authors><author><keyname>Meerwald</keyname><forenames>Peter</forenames></author><author><keyname>Furon</keyname><forenames>Teddy</forenames></author></authors><title>Towards joint decoding of binary Tardos fingerprinting codes</title><categories>cs.IT cs.CR math.IT</categories><comments>submitted to IEEE Trans. on Information Forensics and Security. -
  typos corrected, one new plot, references added about ECC based
  fingerprinting codes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The class of joint decoder of probabilistic fingerprinting codes is of utmost
importance in theoretical papers to establish the concept of fingerprint
capacity. However, no implementation supporting a large user base is known to
date. This article presents an iterative decoder which is, as far as we are
aware of, the first practical attempt towards joint decoding. The
discriminative feature of the scores benefits on one hand from the
side-information of previously accused users, and on the other hand, from
recently introduced universal linear decoders for compound channels. Neither
the code construction nor the decoder make precise assumptions about the
collusion (size or strategy). The extension to incorporate soft outputs from
the watermarking layer is straightforward. An extensive experimental work
benchmarks the very good performance and offers a clear comparison with
previous state-of-the-art decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5617</identifier>
 <datestamp>2012-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5617</id><created>2011-04-29</created><updated>2012-05-29</updated><authors><author><keyname>Colombo</keyname><forenames>Diego</forenames></author><author><keyname>Maathuis</keyname><forenames>Marloes H.</forenames></author><author><keyname>Kalisch</keyname><forenames>Markus</forenames></author><author><keyname>Richardson</keyname><forenames>Thomas S.</forenames></author></authors><title>Learning high-dimensional directed acyclic graphs with latent and
  selection variables</title><categories>stat.ME cs.LG math.ST stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/11-AOS940 the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOS-AOS940</report-no><journal-ref>Annals of Statistics 2012, Vol. 40, No. 1, 294-321</journal-ref><doi>10.1214/11-AOS940</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning causal information between random
variables in directed acyclic graphs (DAGs) when allowing arbitrarily many
latent and selection variables. The FCI (Fast Causal Inference) algorithm has
been explicitly designed to infer conditional independence and causal
information in such settings. However, FCI is computationally infeasible for
large graphs. We therefore propose the new RFCI algorithm, which is much faster
than FCI. In some situations the output of RFCI is slightly less informative,
in particular with respect to conditional independence information. However, we
prove that any causal information in the output of RFCI is correct in the
asymptotic limit. We also define a class of graphs on which the outputs of FCI
and RFCI are identical. We prove consistency of FCI and RFCI in sparse
high-dimensional settings, and demonstrate in simulations that the estimation
performances of the algorithms are very similar. All software is implemented in
the R-package pcalg.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5634</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5634</id><created>2011-04-29</created><authors><author><keyname>Gemsa</keyname><forenames>Andreas</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author><author><keyname>Rutter</keyname><forenames>Ignaz</forenames></author></authors><title>Consistent Labeling of Rotating Maps</title><categories>cs.CG</categories><comments>17 pages, 10 figures. Extended version of paper to appear in Proc.
  11th International Symposium Algorithms and Data Structures (WADS'11), New
  York, USA, 2011</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic maps that allow continuous map rotations, e.g., on mobile devices,
encounter new issues unseen in static map labeling before. We study the
following dynamic map labeling problem: The input is a static, labeled map,
i.e., a set P of points in the plane with attached non-overlapping horizontal
rectangular labels. The goal is to find a consistent labeling of P under
rotation that maximizes the number of visible labels for all rotation angles
such that the labels remain horizontal while the map is rotated. A labeling is
consistent if a single active interval of angles is selected for each label
such that labels neither intersect each other nor occlude points in P at any
rotation angle. We first introduce a general model for labeling rotating maps
and derive basic geometric properties of consistent solutions. We show
NP-completeness of the active interval maximization problem even for
unit-square labels. We then present a constant-factor approximation for this
problem based on line stabbing, and refine it further into an efficient
polynomial-time approximation scheme (EPTAS). Finally, we extend the EPTAS to
the more general setting of rectangular labels of bounded size and aspect
ratio.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5636</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5636</id><created>2011-04-29</created><authors><author><keyname>Betoule</keyname><forenames>Christophe</forenames></author><author><keyname>Bonald</keyname><forenames>Thomas</forenames></author><author><keyname>Clavier</keyname><forenames>Remi</forenames></author><author><keyname>Rossi</keyname><forenames>Dario</forenames></author><author><keyname>Rossini</keyname><forenames>Giuseppe</forenames></author><author><keyname>Thouenon</keyname><forenames>Gilles</forenames></author></authors><title>Adaptive Probabilistic Flooding for Multipath Routing</title><categories>cs.NI</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we develop a distributed source routing algorithm for topology
discovery suitable for ISP transport networks, that is however inspired by
opportunistic algorithms used in ad hoc wireless networks. We propose a
plug-and-play control plane, able to find multiple paths toward the same
destination, and introduce a novel algorithm, called adaptive probabilistic
flooding, to achieve this goal. By keeping a small amount of state in routers
taking part in the discovery process, our technique significantly limits the
amount of control messages exchanged with flooding -- and, at the same time, it
only minimally affects the quality of the discovered multiple path with respect
to the optimal solution. Simple analytical bounds, confirmed by results
gathered with extensive simulation on four realistic topologies, show our
approach to be of high practical interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5642</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5642</id><created>2011-04-29</created><authors><author><keyname>Fanelli</keyname><forenames>Angelo</forenames></author><author><keyname>Moscardelli</keyname><forenames>Luca</forenames></author><author><keyname>Skopalik</keyname><forenames>Alexander</forenames></author></authors><title>On the Impact of Fair Best Response Dynamics</title><categories>cs.GT cs.CC cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we completely characterize how the frequency with which each
player participates in the game dynamics affects the possibility of reaching
efficient states, i.e., states with an approximation ratio within a constant
factor from the price of anarchy, within a polynomially bounded number of best
responses. We focus on the well known class of congestion games and we show
that, if each player is allowed to play at least once and at most $\beta$ times
any $T$ best responses, states with approximation ratio $O(\beta)$ times the
price of anarchy are reached after $T \lceil \log \log n \rceil$ best
responses, and that such a bound is essentially tight also after exponentially
many ones. One important consequence of our result is that the fairness among
players is a necessary and sufficient condition for guaranteeing a fast
convergence to efficient states. This answers the important question of the
maximum order of $\beta$ needed to fast obtain efficient states, left open by
[9,10] and [3], in which fast convergence for constant $\beta$ and very slow
convergence for $\beta=O(n)$ have been shown, respectively. Finally, we show
that the structure of the game implicitly affects its performances. In
particular, we show that in the symmetric setting, in which all players share
the same set of strategies, the game always converges to an efficient state
after a polynomial number of best responses, regardless of the frequency each
player moves with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5643</identifier>
 <datestamp>2012-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5643</id><created>2011-04-29</created><updated>2012-12-06</updated><authors><author><keyname>Albenque</keyname><forenames>Marie</forenames><affiliation>LIX</affiliation></author><author><keyname>Gerin</keyname><forenames>Lucas</forenames><affiliation>MODAL'X</affiliation></author></authors><title>On the algebraic numbers computable by some generalized Ehrenfest urns</title><categories>cs.DC</categories><proxy>ccsd</proxy><journal-ref>Discrete Mathematics and Theoretical Computer Science 14, 2 (2012)
  271-284</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article deals with some stochastic population protocols, motivated by
theoretical aspects of distributed computing. We modelize the problem by a
large urn of black and white balls from which at every time unit a fixed number
of balls are drawn and their colors are changed according to the number of
black balls among them. When the time and the number of balls both tend to
infinity the proportion of black balls converges to an algebraic number. We
prove that, surprisingly enough, not every algebraic number can be &quot;computed&quot;
this way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5646</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5646</id><created>2011-04-29</created><updated>2013-02-19</updated><authors><author><keyname>Burghelea</keyname><forenames>Dan</forenames></author><author><keyname>Dey</keyname><forenames>Tamal K.</forenames></author></authors><title>Persistence for Circle Valued Maps</title><categories>math.AT cs.CG cs.DS</categories><comments>A complete algorithm to compute barcodes and Jordan cells is provided
  in this version. The paper is accepted in in the journal Discrete &amp;
  Computational Geometry. arXiv admin note: text overlap with arXiv:1210.3092
  by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study circle valued maps and consider the persistence of the homology of
their fibers. The outcome is a finite collection of computable invariants which
answer the basic questions on persistence and in addition encode the topology
of the source space and its relevant subspaces. Unlike persistence of real
valued maps, circle valued maps enjoy a different class of invariants called
Jordan cells in addition to bar codes. We establish a relation between the
homology of the source space and of its relevant subspaces with these
invariants and provide a new algorithm to compute these invariants from an
input matrix that encodes a circle valued map on an input simplicial complex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5660</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5660</id><created>2011-04-29</created><authors><author><keyname>Kamei</keyname><forenames>Sayaka</forenames><affiliation>MIS</affiliation></author><author><keyname>Lamani</keyname><forenames>Anissa</forenames><affiliation>MIS</affiliation></author><author><keyname>Ooshita</keyname><forenames>Fukuhito</forenames><affiliation>LIP6</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Asynchronous mobile robot gathering from symmetric configurations
  without global multiplicity detection</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a set of k autonomous robots that are endowed with visibility
sensors (but that are otherwise unable to communicate) and motion actuators.
Those robots must collaborate to reach a sin- gle vertex that is unknown
beforehand, and to remain there hereafter. Previous works on gathering in
ring-shaped networks suggest that there exists a tradeoff between the size of
the set of potential initial configurations, and the power of the sensing
capabilities of the robots (i.e. the larger the initial configuration set, the
most powerful the sensor needs to be). We prove that there is no such trade
off. We propose a gathering protocol for an odd number of robots in a
ring-shaped network that allows symmetric but not periodic configurations as
initial configurations, yet uses only local weak multiplicity detection. Robots
are assumed to be anonymous and oblivious, and the execution model is the
non-atomic CORDA model with asynchronous fair scheduling. Our protocol allows
the largest set of initial configurations (with respect to impossibility
results) yet uses the weakest multiplicity detector to date. The time
complexity of our protocol is O(n2), where n denotes the size of the ring.
Compared to previous work that also uses local weak multiplicity detection, we
do not have the constraint that k &lt; n/2 (here, we simply have 2 &lt; k &lt; n - 3).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5687</identifier>
 <datestamp>2011-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5687</id><created>2011-04-29</created><updated>2011-06-29</updated><authors><author><keyname>Rothkopf</keyname><forenames>Constantin</forenames></author><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author></authors><title>Preference elicitation and inverse reinforcement learning</title><categories>stat.ML cs.LG</categories><comments>13 pages, 4 figures; ECML 2011</comments><report-no>EPFL-REPORT-165975</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We state the problem of inverse reinforcement learning in terms of preference
elicitation, resulting in a principled (Bayesian) statistical formulation. This
generalises previous work on Bayesian inverse reinforcement learning and allows
us to obtain a posterior distribution on the agent's preferences, policy and
optionally, the obtained reward sequence, from observations. We examine the
relation of the resulting approach to other statistical methods for inverse
reinforcement learning via analysis and experimental results. We show that
preferences can be determined accurately, even if the observed agent's policy
is sub-optimal with respect to its own preferences. In that case, significantly
improved policies with respect to the agent's preferences are obtained,
compared to both other methods and to the performance of the demonstrated
policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5700</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5700</id><created>2011-04-29</created><authors><author><keyname>Taneja</keyname><forenames>Inder Jeet</forenames></author></authors><title>A Sequence of Inequalities among Difference of Symmetric Divergence
  Measures</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we have considered two one parametric generalizations. These
two generalizations have in articular the well known measures such as:
J-divergence, Jensen-Shannon divergence and Arithmetic-Geometric mean
divergence. These three measures are with logarithmic expressions. Also, we
have particular cases the measures such as: Hellinger discrimination, symmetric
chi-square divergence, and triangular discrimination. These three measures are
also well-known in the literature of statistics, and are without logarithmic
expressions. Still, we have one more non logarithmic measure as particular case
calling it d-divergence. These seven measures bear an interesting inequality.
Based on this inequality, we have considered different difference of divergence
measures and established a sequence of inequalities among themselves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1104.5705</identifier>
 <datestamp>2011-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1104.5705</id><created>2011-04-29</created><authors><author><keyname>Janakiraman</keyname><forenames>T. N.</forenames></author><author><keyname>Thilak</keyname><forenames>A. Senthil</forenames></author></authors><title>A Multi-Hop Weighted Clustering of Homogenous MANETs Using Combined
  Closeness Index</title><categories>cs.DM math.CO</categories><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  3, No. 2, April 2011, 253-270</journal-ref><doi>10.5121/ijwmn.2011.3220</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new multi-hop weighted clustering procedure is proposed for
homogeneous Mobile Ad hoc networks. The algorithm generates double star
embedded non-overlapping cluster structures, where each cluster is managed by a
leader node and a substitute for the leader node (in case of failure of leader
node). The weight of a node is a linear combination of six different graph
theoretic parameters which deal with the communication capability of a node
both in terms of quality and quantity, the relative closeness relationship
between network nodes and the maximum and average distance traversed by a node
for effective communication. This paper deals with the design and analysis of
the algorithm and some of the graph theoretic/structural properties of the
clusters obtained are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0007</identifier>
 <datestamp>2011-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0007</id><created>2011-04-29</created><updated>2011-09-12</updated><authors><author><keyname>Weinstein</keyname><forenames>Marvin</forenames></author><author><keyname>Auerbach</keyname><forenames>Assa</forenames></author><author><keyname>Chandra</keyname><forenames>V. Ravi</forenames></author></authors><title>Reducing Memory Cost of Exact Diagonalization using Singular Value
  Decomposition</title><categories>cond-mat.str-el cond-mat.stat-mech cs.DS hep-lat</categories><comments>7 pages, 8 figures</comments><journal-ref>Phys. Rev. E 84, 056701 (2011)</journal-ref><doi>10.1103/PhysRevE.84.056701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a modified Lanczos algorithm to diagonalize lattice Hamiltonians
with dramatically reduced memory requirements, {\em without restricting to
variational ansatzes}. The lattice of size $N$ is partitioned into two
subclusters. At each iteration the Lanczos vector is projected into two sets of
$n_{{\rm svd}}$ smaller subcluster vectors using singular value decomposition.
For low entanglement entropy $S_{ee}$, (satisfied by short range Hamiltonians),
the truncation error is expected to vanish as $\exp(-n_{{\rm
svd}}^{1/S_{ee}})$. Convergence is tested for the Heisenberg model on Kagom\'e
clusters of 24, 30 and 36 sites, with no lattice symmetries exploited, using
less than 15GB of dynamical memory. Generalization of the Lanczos-SVD algorithm
to multiple partitioning is discussed, and comparisons to other techniques are
given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0010</identifier>
 <datestamp>2013-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0010</id><created>2011-04-29</created><updated>2012-12-04</updated><authors><author><keyname>Thakur</keyname><forenames>Gaurav</forenames></author><author><keyname>Brevdo</keyname><forenames>Eugene</forenames></author><author><keyname>Fu&#x10d;kar</keyname><forenames>Neven S.</forenames></author><author><keyname>Wu</keyname><forenames>Hau-Tieng</forenames></author></authors><title>The Synchrosqueezing algorithm for time-varying spectral analysis:
  robustness properties and new paleoclimate applications</title><categories>math.CA cs.CE cs.NA physics.data-an</categories><comments>to appear in Signal Processing</comments><msc-class>42C40, 65T99, 62M15, 86A04</msc-class><journal-ref>Signal Processing 93:1079-1094, 2013</journal-ref><doi>10.1016/j.sigpro.2012.11.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the stability properties of the Synchrosqueezing transform, a
time-frequency signal analysis method that can identify and extract oscillatory
components with time-varying frequency and amplitude. We show that
Synchrosqueezing is robust to bounded perturbations of the signal and to
Gaussian white noise. These results justify its applicability to noisy or
nonuniformly sampled data that is ubiquitous in engineering and the natural
sciences. We also describe a practical implementation of Synchrosqueezing and
provide guidance on tuning its main parameters. As a case study in the
geosciences, we examine characteristics of a key paleoclimate change in the
last 2.5 million years, where Synchrosqueezing provides significantly improved
insights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0011</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0011</id><created>2011-04-29</created><authors><author><keyname>Madani</keyname><forenames>Ramtin</forenames></author><author><keyname>Ayremlou</keyname><forenames>Ali</forenames></author><author><keyname>Amini</keyname><forenames>Arash</forenames></author><author><keyname>Marvasti</keyname><forenames>Farrokh</forenames></author></authors><title>Optimized Spline Interpolation</title><categories>cs.MM</categories><comments>IEEE Transactions on Signal Processing, Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the problem of designing compact support
interpolation kernels for a given class of signals. By using calculus of
variations, we simplify the optimization problem from an infinite nonlinear
problem to a finite dimensional linear case, and then find the optimum compact
support function that best approximates a given filter in the least square
sense (l2 norm). The benefit of compact support interpolants is the low
computational complexity in the interpolation process while the optimum compact
support interpolant gaurantees the highest achivable Signal to Noise Ratio
(SNR). Our simulation results confirm the superior performance of the proposed
splines compared to other conventional compact support interpolants such as
cubic spline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0022</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0022</id><created>2011-04-29</created><updated>2011-05-03</updated><authors><author><keyname>Song</keyname><forenames>Yi</forenames></author><author><keyname>Xie</keyname><forenames>Jiang</forenames></author></authors><title>Optimal Power Control for Concurrent Transmissions of Location-aware
  Mobile Cognitive Radio Ad Hoc Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a cognitive radio (CR) network, CR users intend to operate over the same
spectrum band licensed to legacy networks. A tradeoff exists between protecting
the communications in legacy networks and maximizing the throughput of CR
transmissions, especially when CR links are unstable due to the mobility of CR
users. Because of the non-zero probability of false detection and
implementation complexity of spectrum sensing, in this paper, we investigate a
sensing-free spectrum sharing scenario for mobile CR ad hoc networks to improve
the frequency reuse by incorporating the location awareness capability in CR
networks. We propose an optimal power control algorithm for the CR transmitter
to maximize the concurrent transmission region of CR users especially in mobile
scenarios. Under the proposed power control algorithm, the mobile CR network
achieves maximized throughput without causing harmful interference to primary
users in the legacy network. Simulation results show that the proposed optimal
power control algorithm outperforms the algorithm with the fixed power policy
in terms of increasing the packet delivery ratio in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0023</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0023</id><created>2011-04-29</created><authors><author><keyname>Lu</keyname><forenames>Lu</forenames></author></authors><title>Survey of Cognitive Radio Techniques in Wireless Network</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, I surveyed the cognitive radio technique in wireless
networks. Researched several kinds of cognitive techniques about their
advantages and disadvantages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0031</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0031</id><created>2011-04-29</created><updated>2011-05-03</updated><authors><author><keyname>Song</keyname><forenames>Yi</forenames></author><author><keyname>Xie</keyname><forenames>Jiang</forenames></author></authors><title>Performance Analysis of Spectrum Handoff for Cognitive Radio Ad Hoc
  Networks without Common Control Channel under Homogeneous Primary Traffic</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE INFOCOM 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio (CR) technology is regarded as a promising solution to the
spectrum scarcity problem. Due to the spectrum varying nature of CR networks,
unlicensed users are required to perform spectrum handoffs when licensed users
reuse the spectrum. In this paper, we study the performance of the spectrum
handoff process in a CR ad hoc network under homogeneous primary traffic. We
propose a novel three dimensional discrete-time Markov chain to characterize
the process of spectrum handoffs and analyze the performance of unlicensed
users. Since in real CR networks, a dedicated common control channel is not
practical, in our model, we implement a network coordination scheme where no
dedicated common control channel is needed. Moreover, in wireless
communications, collisions among simultaneous transmissions cannot be
immediately detected and the whole collided packets need to be retransmitted,
which greatly affects the network performance. With this observation, we also
consider the retransmissions of the collided packets in our proposed
discrete-time Markov chain. In addition, besides the random channel selection
scheme, we study the impact of different channel selection schemes on the
performance of the spectrum handoff process. Furthermore, we also consider the
spectrum sensing delay in our proposed Markov model and investigate its effect
on the network performance. We validate the numerical results obtained from our
proposed Markov model against simulation and investigate other parameters of
interest in the spectrum handoff scenario. Our proposed analytical model can be
applied to various practical network scenarios. It also provides new insights
on the process of spectrum handoffs. Currently, no existing analysis has
considered the comprehensive aspects of spectrum handoff as what we consider in
this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0032</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0032</id><created>2011-04-29</created><authors><author><keyname>Song</keyname><forenames>Yi</forenames></author><author><keyname>Xie</keyname><forenames>Jiang</forenames></author></authors><title>On the Spectrum Handoff for Cognitive Radio Ad Hoc Networks without
  Common Control Channel</title><categories>cs.IT math.IT</categories><comments>book chapter of Cognitive Radio Mobile Ad Hoc Networks, Springer,
  July 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio (CR) technology is a promising solution to enhance the
spectrum utilization by enabling unlicensed users to exploit the spectrum in an
opportunistic manner. Since unlicensed users are temporary visitors to the
licensed spectrum, they are required to vacate the spectrum when a licensed
user reclaims it. Due to the randomness of the appearance of licensed users,
disruptions to both licensed and unlicensed communications are often difficult
to prevent. In this chapter, a proactive spectrum handoff framework for CR ad
hoc networks is proposed to address these concerns. In the proposed framework,
channel switching policies and a proactive spectrum handoff protocol are
proposed to let unlicensed users vacate a channel before a licensed user
utilizes it to avoid unwanted interference. Network coordination schemes for
unlicensed users are also incorporated into the spectrum handoff protocol
design to realize channel rendezvous. Moreover, a distributed channel selection
scheme to eliminate collisions among unlicensed users is proposed. In our
proposed framework, unlicensed users coordinate with each other without using a
common control channel. We compare our proposed proactive spectrum handoff
protocol with a reactive spectrum handoff protocol, under which unlicensed
users switch channels after collisions with licensed transmissions occur.
Simulation results show that our proactive spectrum handoff outperforms the
reactive spectrum handoff approach in terms of higher throughput and fewer
collisions to licensed users. In addition, we propose a novel three dimensional
discrete-time Markov chain to characterize the process of reactive spectrum
handoffs and analyze the performance of unlicensed users. We validate the
numerical results obtained from our proposed Markov model against simulation
and investigate other parameters of interest in the spectrum handoff scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0034</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0034</id><created>2011-04-29</created><authors><author><keyname>Cheng</keyname><forenames>Wenchi</forenames></author><author><keyname>Zhang</keyname><forenames>Xi</forenames></author><author><keyname>Zhang</keyname><forenames>Hailin</forenames></author></authors><title>Full Duplex Wireless Communications for Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a key in cognitive radio networks (CRNs), dynamic spectrum access needs to
be carefully designed to minimize the interference and delay to the
\emph{primary} (licensed) users. One of the main challenges in dynamic spectrum
access is to determine when the \emph{secondary} (unlicensed) users can use the
spectrum. In particular, when the secondary user is using the spectrum, if the
primary user becomes active to use the spectrum, it is usually hard for the
secondary user to detect the primary user instantaneously, thus causing
unexpected interference and delay to primary users. The secondary user cannot
detect the presence of primary users instantaneously because the secondary user
is unable to detect the spectrum at the same time while it is transmitting. To
solve this problem, we propose the full duplex wireless communications scheme
for CRNs. In particular, we employ the Antennas Cancellation (AC), the RF
Interference Cancellation (RIC), and the Digital Interference Cancellation
(DIC) techniques for secondary users so that the secondary user can scan for
active primary users while it is transmitting. Once detecting the presence of
primary users, the secondary user will release the spectrum instantaneously to
avoid the interference and delay to primary users. We analyze the packet loss
rate of primary users in wireless full duplex CRNs, and compare them with the
packet loss rate of primary users in wireless half duplex CRNs. Our analyses
and simulations show that using our developped wireless full duplex CRNs, the
packet loss rate of primary users can be significantly decreased as compared
with that of primary users by using the half duplex CRNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0035</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0035</id><created>2011-04-29</created><authors><author><keyname>Du</keyname><forenames>Qinghe</forenames></author><author><keyname>Zhang</keyname><forenames>Xi</forenames></author></authors><title>Base-Station Selections for QoS Provisioning Over Distributed Multi-User
  MIMO Links in Wireless Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the QoS-aware BS-selection and the corresponding
resource-allocation schemes for downlink multi-user transmissions over the
distributed multiple-input-multiple-output (MIMO) links, where multiple
location-independent base-stations (BS), controlled by a central server,
cooperatively transmit data to multiple mobile users. Our proposed schemes aim
at minimizing the BS usages and reducing the interfering range of the
distributed MIMO transmissions, while satisfying diverse statistical delay-QoS
requirements for all users, which are characterized by the delay-bound
violation probability and the effective capacity technique. Specifically, we
propose two BS-usage minimization frameworks to develop the QoS-aware
BS-selection schemes and the corresponding wireless resource-allocation
algorithms across multiple mobile users. The first framework applies the joint
block-diagonalization (BD) and probabilistic transmission (PT) to implement
multiple access over multiple mobile users, while the second one employs
time-division multiple access (TDMA) approach to control multiple users' links.
We then derive the optimal BS-selection schemes for these two frameworks,
respectively. In addition, we further discuss the PT-only based BS-selection
scheme. Also conducted is a set of simulation evaluations to comparatively
study the average BS-usage and interfering range of our proposed schemes and to
analyze the impact of QoS constraints on the BS selections for distributed MIMO
transmissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0036</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0036</id><created>2011-04-29</created><authors><author><keyname>Rothvo&#xdf;</keyname><forenames>Thomas</forenames></author></authors><title>Some 0/1 polytopes need exponential size extended formulations</title><categories>math.CO cs.CC cs.DM</categories><msc-class>52B11</msc-class><acm-class>G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that there are 0/1 polytopes P that do not admit a compact LP
formulation. More precisely we show that for every n there is a sets X
\subseteq {0,1}^n such that conv(X) must have extension complexity at least
2^{n/2 * (1-o(1))}. In other words, every polyhedron Q that can be linearly
projected on conv(X) must have exponentially many facets.
  In fact, the same result also applies if conv(X) is restricted to be a
matroid polytope.
  Conditioning on NP not contained in P_{/poly}, our result rules out the
existence of any compact formulation for the TSP polytope, even if the
formulation may contain arbitrary real numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0043</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0043</id><created>2011-04-29</created><authors><author><keyname>Gondara</keyname><forenames>Mandeep Kaur</forenames></author><author><keyname>Kadam</keyname><forenames>Sanjay</forenames></author></authors><title>Requirements of Vertical Handoff Mechanism in 4G Wireless Networks</title><categories>cs.NI</categories><comments>10 pages,1 figure,2 tables</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  3, No. 2, April 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of wireless communication is increasing day by day throughout
the world due to cellular and broadband technologies. Everyone around the world
would like to be connected seamlessly anytime anywhere through the best
network. The 4G wireless system must have the capability to provide high data
transfer rates, quality of services and seamless mobility. In 4G, there are a
large variety of heterogeneous networks. The users for variety of applications
would like to utilize heterogeneous networks on the basis of their preferences
such as real time, high availability and high bandwidth. When connections have
to switch between heterogeneous networks for performance and high availability
reasons, seamless vertical handoff is necessary. The requirements like
capability of the network, handoff latency, network cost, network conditions,
power consumption and user's preferences must be taken into consideration
during vertical handoff. In this paper, we have extracted the requirements of a
vertical handoff from the literature surveyed. The evaluation of the existing
work is also being done on the basis of required parameters for vertical
handoff. A sophisticated, adaptive and intelligent approach is required to
implement the vertical handoff mechanism in 4G wireless networks to produce an
effective service for the user by considering dynamic and non dynamic
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0049</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0049</id><created>2011-04-30</created><authors><author><keyname>Patel</keyname><forenames>Anup</forenames></author><author><keyname>Sharma</keyname><forenames>Niveeta</forenames></author><author><keyname>Eirinaki</keyname><forenames>Magdalini</forenames></author></authors><title>Negative Database for Data Security</title><categories>cs.DB</categories><comments>appeared in Proceedings of the International Conference on Computing
  in Engineering, Science and Information (ICC 2009), April 2009, Fullerton,
  California</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data Security is a major issue in any web-based application. There have been
approaches to handle intruders in any system, however, these approaches are not
fully trustable; evidently data is not totally protected. Real world databases
have information that needs to be securely stored. The approach of generating
negative database could help solve such problem. A Negative Database can be
defined as a database that contains huge amount of data consisting of
counterfeit data along with the real data. Intruders may be able to get access
to such databases, but, as they try to extract information, they will retrieve
data sets that would include both the actual and the negative data. In this
paper we present our approach towards implementing the concept of negative
database to help prevent data theft from malicious users and provide efficient
data retrieval for all valid users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0051</identifier>
 <datestamp>2014-01-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0051</id><created>2011-04-30</created><updated>2012-03-06</updated><authors><author><keyname>Hu</keyname><forenames>Bao-Gang</forenames></author></authors><title>What are the Differences between Bayesian Classifiers and
  Mutual-Information Classifiers?</title><categories>cs.IT math.IT</categories><comments>(2nd version: 19 pages, 5 figures, 7 tables. Theorems on Bayesian
  classifiers are extended to multiple variables. Appendix B for &quot;Tighter
  bounds between the conditional entropy and Bayesian error in binary
  classifications&quot; are added, in which Fano's bound is shown numerically to be
  very tight)</comments><journal-ref>IEEE Transactions on Neural Networks and Learning Systems, 25(2):
  249-264, 2014</journal-ref><doi>10.1109/TNNLS.2013.2274799</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, both Bayesian classifiers and mutual information classifiers
are examined for binary classifications with or without a reject option. The
general decision rules in terms of distinctions on error types and reject types
are derived for Bayesian classifiers. A formal analysis is conducted to reveal
the parameter redundancy of cost terms when abstaining classifications are
enforced. The redundancy implies an intrinsic problem of &quot;non-consistency&quot; for
interpreting cost terms. If no data is given to the cost terms, we demonstrate
the weakness of Bayesian classifiers in class-imbalanced classifications. On
the contrary, mutual-information classifiers are able to provide an objective
solution from the given data, which shows a reasonable balance among error
types and reject types. Numerical examples of using two types of classifiers
are given for confirming the theoretical differences, including the
extremely-class-imbalanced cases. Finally, we briefly summarize the Bayesian
classifiers and mutual-information classifiers in terms of their application
advantages, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0054</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0054</id><created>2011-04-30</created><updated>2012-12-02</updated><authors><author><keyname>Zhu</keyname><forenames>Weiping</forenames></author><author><keyname>Deng</keyname><forenames>Ke</forenames></author></authors><title>Loss Tomography from Tree Topologies to General Topologies</title><categories>cs.NI</categories><comments>will be submitted for publication. arXiv admin note: substantial text
  overlap with arXiv:1009.2557</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Loss tomography has received considerable attention in recent years and a
number of estimators based on maximum likelihood (ML) or Bayesian principles
have been proposed. Almost all of the estimators are devoted to the tree
topology despite the general topology is more common in practice. There has
been few likelihood function devoted to the general topology, not to mention
the estimator. To overcome this, two sets of sufficient statistics for the tree
and general topologies, respectively, are proposed in this paper. Using the
statistics, two likelihood functions, one for a topology, are proposed here and
subsequently two likelihood equations for the general topology, one is
link-based and the other is path-based, are obtained. In addition, a dependence
between subtrees in terms of their estimates is identified for the general
topology and a divide-and-conquer strategy is proposed to deal with the
dependence, which divides a general network into two types of independent
trees. Further, two algorithms, one for a type of the independent trees, are
proposed to estimate the loss rates of each type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0057</identifier>
 <datestamp>2012-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0057</id><created>2011-04-30</created><updated>2012-10-01</updated><authors><author><keyname>Zhu</keyname><forenames>Weiping</forenames></author></authors><title>A Closed Form Maximum Likelihood Estimator to End-to-End Loss Rate
  Estimation</title><categories>cs.NI</categories><comments>this paper has been withdrawn by the author becausse it has been
  published in a conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Loss tomography has been studied for more than 10 years and a number of
estimators have been proposed. The estimators can be divided into two classes:
maximum likelihood and non-maximum likelihood. The maximum likelihood
estimators rely on the maximum likelihood principle to ensure the accuracy of
the estimates obtained by the estimators. Unfortunately, all of the maximum
likelihood estimators need to use an iterative procedure to search the solution
space for the maximum or to solve a high degree polynomial. An iterative
procedure can be computationally expensive and may even converge to a local
maximum. On the other hand, the non-maximum likelihood estimators pursue closed
form solutions by scarifying the accuracy of estimates. To overcome the
pitfalls, we, in this paper, propose a closed form and maximum likelihood
estimator to estimate the loss rate of a link in a network. The closed form
solution is built on the discovery of a connection between the number of probes
passing a link and the number of probes passing its parent. The proposed
estimator is applicable to both the tree topology and the general one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0058</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0058</id><created>2011-04-30</created><authors><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames></author></authors><title>Impact of the Optimum Routing and Least Overhead Routing Approaches on
  Minimum Hop Routes and Connected Dominating Sets in Mobile Ad Hoc Networks I</title><categories>cs.NI</categories><comments>17 pages, 19 figures, 6 tables</comments><journal-ref>International Journal of Wireless and Mobile Networks, vol. 3, no.
  2, pp. 196-212, April 2011</journal-ref><doi>10.5121/ijwmn.2011.3216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication protocols for mobile ad hoc networks (MANETs) follow either an
Optimum Routing Approach (ORA) or the Least Overhead Routing Approach (LORA):
With ORA, protocols tend to determine and use the optimal communication
structure at every time instant; whereas with LORA, a protocol tends to use a
chosen communication structure as long as it exists. In this paper, we study
the impact of the ORA and LORA strategies on minimum hop routes and minimum
connected dominating sets (MCDS) in MANETs. Our primary hypothesis is that the
LORA strategy could yield routes with a larger time-averaged hop count and MCDS
node size when compared to the minimum hop count of routes and the node size of
the MCDS determined using the ORA strategy. Our secondary hypothesis is that
the impact of ORA vs. LORA also depends on how long the communication structure
is being used. Our hypotheses are evaluated using extensive simulations under
diverse conditions of network density, node mobility and mobility models such
as the Random Waypoint model, City Section model and the Manhattan model. In
the case of minimum hop routes, which exist for relatively a much longer time
compared to the MCDS, the hop count of routes maintained according to LORA,
even though not dramatically high, is appreciably larger (6-12%) than those
maintained according to ORA; on the other hand, the number of nodes
constituting a MCDS maintained according to LORA is only at most 6% larger than
the node size of a MCDS maintained under the ORA strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0060</identifier>
 <datestamp>2012-06-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0060</id><created>2011-04-30</created><updated>2012-06-19</updated><authors><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Signal Processing in Large Systems: a New Paradigm</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a long time, detection and parameter estimation methods for signal
processing have relied on asymptotic statistics as the number $n$ of
observations of a population grows large comparatively to the population size
$N$, i.e. $n/N\to \infty$. Modern technological and societal advances now
demand the study of sometimes extremely large populations and simultaneously
require fast signal processing due to accelerated system dynamics. This results
in not-so-large practical ratios $n/N$, sometimes even smaller than one. A
disruptive change in classical signal processing methods has therefore been
initiated in the past ten years, mostly spurred by the field of large
dimensional random matrix theory. The early works in random matrix theory for
signal processing applications are however scarce and highly technical. This
tutorial provides an accessible methodological introduction to the modern tools
of random matrix theory and to the signal processing methods derived from them,
with an emphasis on simple illustrative examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0061</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0061</id><created>2011-04-30</created><authors><author><keyname>Ali</keyname><forenames>Ishtiaq</forenames></author><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames></author></authors><title>Virtual Machines and Networks - Installation, Performance Study,
  Advantages and Virtualization Options</title><categories>cs.NI</categories><journal-ref>International Journal of Network Security and its Applications,
  vol. 3, no. 1, pp. 1-15, January 2011</journal-ref><doi>10.5121/ijnsa.2011.3101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The interest in virtualization has been growing rapidly in the IT industry
because of inherent benefits like better resource utilization and ease of
system manageability. The experimentation and use of virtualization as well as
the simultaneous deployment of virtual software are increasingly getting
popular and in use by educational institutions for research and teaching. This
paper stresses on the potential advantages associated with virtualization and
the use of virtual machines for scenarios, which cannot be easily implemented
and/or studied in a traditional academic network environment, but need to be
explored and experimented by students to meet the raising needs and
knowledge-base demanded by the IT industry. In this context, we discuss various
aspects of virtualization - starting from the working principle of virtual
machines, installation procedure for a virtual guest operating system on a
physical host operating system, virtualization options and a performance study
measuring the throughput obtained on a network of virtual machines and physical
host machines. In addition, the paper extensively evaluates the use of virtual
machines and virtual networks in an academic environment and also specifically
discusses sample projects on network security, which may not be feasible enough
to be conducted in a physical network of personal computers; but could be
conducted only using virtual machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0065</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0065</id><created>2011-04-30</created><authors><author><keyname>Chandesris</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Dennunzio</keyname><forenames>Alberto</forenames></author><author><keyname>Formenti</keyname><forenames>Enrico</forenames></author><author><keyname>Manzoni</keyname><forenames>Luca</forenames></author></authors><title>Computational Aspects of Asynchronous CA</title><categories>cs.FL nlin.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work studies some aspects of the computational power of fully
asynchronous cellular automata (ACA). We deal with some notions of simulation
between ACA and Turing Machines. In particular, we characterize the updating
sequences specifying which are &quot;universal&quot;, i.e., allowing a (specific family
of) ACA to simulate any TM on any input. We also consider the computational
cost of such simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0066</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0066</id><created>2011-04-30</created><authors><author><keyname>Torres</keyname><forenames>Bolivar</forenames></author><author><keyname>Pang</keyname><forenames>Qing</forenames></author><author><keyname>Skelton</keyname><forenames>Gordon</forenames></author><author><keyname>Bridges</keyname><forenames>Scott</forenames></author><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames></author></authors><title>Integration of an RFID Reader to a Wireless Sensor Network and using it
  to Identify an Individual Carrying RFID Tags</title><categories>cs.NI</categories><journal-ref>International Journal of Ad hoc, Sensor and Ubiquitous Computing,
  vol. 1, no. 4, pp. 1-15, December 2010</journal-ref><doi>10.5121/ijasuc.2010.1401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this research is to integrate an RFID (Radio Frequency
Identification) reader into a Wireless Sensor Network (WSN) to authorize or
keep track of people carrying RFID tags. The objective was accomplished by
integrating hardware and software. The hardware consisted of two WSN nodes -
the RFID node connected to one of the WSN nodes, and a computer connected to
the other WSN node. For the RFID equipment, we used the SM130-EK kit, which
included the RFID reader and the RFID tags; and for the WSN, we used the
Synapse Network Evaluation kit, which included the two sensor nodes. The
software consisted of a program module developed in Python to control the
microprocessors of the nodes; and a database controlled by a simple program to
manage the tag IDs of people wearing them. The WSN and RFID nodes were
connected through I2C interfacing. Also, the work of sending commands to the
RFID node, to make it read a tag and send it back to the computer, was
accomplished by the Python code developed which also controls the data signals.
At the computer, the received tag ID is evaluated with other existing tag IDs
on the database, to check if that tag has authorization or not to be in the
covered area. Our research has the potential of being adapted for use with
secure real-time access control applications involving WSN and RFID
technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0069</identifier>
 <datestamp>2012-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0069</id><created>2011-04-30</created><updated>2012-03-30</updated><authors><author><keyname>Salvaneschi</keyname><forenames>Guido</forenames></author><author><keyname>Ghezzi</keyname><forenames>Carlo</forenames></author><author><keyname>Pradella</keyname><forenames>Matteo</forenames></author></authors><title>Context-Oriented Programming: A Programming Paradigm for Autonomic
  Systems</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic software adaptability is one of the central features leveraged by
autonomic computing. However, developing software that changes its behavior at
run time adapting to the operational conditions is a challenging task. Several
approaches have been proposed in the literature to attack this problem at
different and complementary abstraction levels: software architecture,
middleware, and programming level. We focus on the support that ad-hoc
programming language constructs may provide to support dynamically adaptive
behaviors. We introduce context-oriented programming languages and we present a
framework that positions the supported paradigm in the MAPE-K autonomic loop.
We discuss the advantages of using context-oriented programming languages
instead of other mainstream approaches based on dynamic aspect oriented
programming languages and present a case study that shows how the proposed
programming style naturally fits dynamic adaptation requirements. Finally, we
discuss some known problems and outline a number of open research challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0074</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0074</id><created>2011-04-30</created><updated>2011-05-25</updated><authors><author><keyname>Sharma</keyname><forenames>Rajesh</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author></authors><title>SuperNova: Super-peers Based Architecture for Decentralized Online
  Social Networks</title><categories>cs.SI cs.DC physics.soc-ph</categories><comments>20 Pages, 10 Figures</comments><msc-class>68-02</msc-class><acm-class>B.4.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have seen several earnest initiatives from both academic
researchers as well as open source communities to implement and deploy
decentralized online social networks (DOSNs). The primary motivations for DOSNs
are privacy and autonomy from big brotherly service providers. The promise of
decentralization is complete freedom for end-users from any service providers
both in terms of keeping privacy about content and communication, and also from
any form of censorship. However decentralization introduces many challenges.
One of the principal problems is to guarantee availability of data even when
the data owner is not online, so that others can access the said data even when
a node is offline or down. In this paper, we argue that a pragmatic design
needs to explicitly allow for and leverage on system heterogeneity, and provide
incentives for the resource rich participants in the system to contribute such
resources. To that end we introduce SuperNova - a super-peer based DOSN
architecture. While proposing the SuperNova architecture, we envision a dynamic
system driven by incentives and reputation, however, investigation of such
incentives and reputation, and its effect on determining peer behaviors is a
subject for our future study. In this paper we instead investigate the efficacy
of a super-peer based system at any time point (a snap-shot of the envisioned
dynamic system), that is to say, we try to quantify the performance of
SuperNova system given any (fixed) mix of peer population and strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0079</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0079</id><created>2011-04-30</created><authors><author><keyname>Shapi'i</keyname><forenames>Azrulhizam</forenames></author><author><keyname>Sulaiman</keyname><forenames>Riza</forenames></author><author><keyname>Hasan</keyname><forenames>Mohammad Khatim</forenames></author><author><keyname>Kassim</keyname><forenames>Abdul Yazid Mohd</forenames></author></authors><title>An Automated Size Recognition Technique for Acetabular Implant in Total
  Hip Replacement</title><categories>cs.CV</categories><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT), Vol 3, No 2, April 2011</journal-ref><doi>10.5121/ijcsit.2011.3218</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preoperative templating in Total Hip Replacement (THR) is a method to
estimate the optimal size and position of the implant. Today, observational
(manual) size recognition techniques are still used to find a suitable implant
for the patient. Therefore, a digital and automated technique should be
developed so that the implant size recognition process can be effectively
implemented. For this purpose, we have introduced the new technique for
acetabular implant size recognition in THR preoperative planning based on the
diameter of acetabulum size. This technique enables the surgeon to recognise a
digital acetabular implant size automatically. Ten randomly selected X-rays of
unidentified patients were used to test the accuracy and utility of an
automated implant size recognition technique. Based on the testing result, the
new technique yielded very close results to those obtained by the observational
method in nine studies (90%).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0086</identifier>
 <datestamp>2011-07-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0086</id><created>2011-04-30</created><updated>2011-07-06</updated><authors><author><keyname>Coons</keyname><forenames>Michael</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>A Pattern Sequence Approach to Stern's Sequence</title><categories>math.NT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let w be a binary string and let a_w (n) be the number of occurrences of the
word w in the binary expansion of n. As usual we let s(n) denote the Stern
sequence; that is, s(0)=0, s(1)=1, and for n &gt;= 1, s(2n)=s(n) and
s(2n+1)=s(n)+s(n+1). In this note, we show that s(n) = a_1 (n) + \sum_{w in 1
(0+1)*} s([w bar]) a_{w1} (n) where w bar denotes the complement of w (obtained
by sending 0 to 1 and 1 to 0, and [w] denotes the integer specified by the word
w interpreted in base 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0087</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0087</id><created>2011-04-30</created><authors><author><keyname>Ghorpade</keyname><forenames>Sudhir R.</forenames></author><author><keyname>Johnsen</keyname><forenames>Trygve</forenames></author><author><keyname>Patil</keyname><forenames>Arunkumar R.</forenames></author><author><keyname>Pillai</keyname><forenames>Harish K.</forenames></author></authors><title>Higher weights of Grassmann codes in terms of properties of Schubert
  unions</title><categories>math.AG cs.IT math.CO math.IT</categories><comments>12 pages, 5 figures</comments><msc-class>14M15, 05E15, 94B27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe the higher weights of the Grassmann codes $G(2,m)$ over finite
fields ${\mathbb F}_q$ in terms of properties of Schubert unions, and in each
case we determine the weight as the minimum of two explicit polynomial
expressions in $q$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0099</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0099</id><created>2011-04-30</created><authors><author><keyname>Du</keyname><forenames>Qinghe</forenames></author><author><keyname>Huang</keyname><forenames>Yi</forenames></author><author><keyname>Ren</keyname><forenames>Pinyi</forenames></author><author><keyname>Zhang</keyname><forenames>Chao</forenames></author></authors><title>Statistical Delay Control and QoS-Driven Power Allocation Over Two-Hop
  Wireless Relay Links</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The time-varying feature of wireless channels usually makes the hard delay
bound for data transmissions unrealistic to guarantee. In contrast, the
statistically-bounded delay with a small violation probability has been widely
used for delay quality-of-service (QoS) characterization and evaluation. While
existing research mainly focused on the statistical-delay control in single-hop
links, in this paper we propose the QoS-driven power-allocation scheme over
two-hop wireless relay links to statistically upper-bound the end-to-end delay
under the decodeand- forward (DF) relay transmissions. Specifically, by
applying the effective capacity and effective bandwidth theories, we first
analyze the delay-bound violation probability over two tops each with
independent service processes. Then, we show that an efficient approach for
statistical-delay guarantees is to make the delay distributions of both hops
identical, which, however, needs to be obtained through asymmetric resource
allocations over the two hops. Motivated by this fact, we formulate and solve
an optimization problem aiming at minimizing the average power consumptions to
satisfy the specified end-to-end delay-bound violation probability over two-hop
relay links. Also conducted is a set of simulations results to show the impact
of the QoS requirements, traffic load, and position of the relay node on the
power allocation under our proposed optimal scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0101</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0101</id><created>2011-04-30</created><authors><author><keyname>Wang</keyname><forenames>Yichen</forenames></author><author><keyname>Ren</keyname><forenames>Pinyi</forenames></author><author><keyname>Du</keyname><forenames>Qinghe</forenames></author><author><keyname>Zhang</keyname><forenames>Chao</forenames></author></authors><title>A Multi-Channel Diversity Based MAC Protocol for Power-Constrained
  Cognitive Ad Hoc Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major challenges in the medium access control (MAC) protocol
design over cognitive Ad Hoc networks (CAHNs) is how to efficiently utilize
multiple opportunistic channels, which vary dynamically and are subject to
limited power resources. To overcome this challenge, in this paper we first
propose a novel diversity technology called \emph{Multi-Channel Diversity}
(MCD), allowing each secondary node to use multiple channels simultaneously
with only one radio per node under the upperbounded power. Using the proposed
MCD, we develop a MCD based MAC (MCD-MAC) protocol, which can efficiently
utilize available channel resources through joint power-channel allocation.
Particularly, we convert the joint power-channel allocation to the
Multiple-Choice Knapsack Problem, such that we can obtain the optimal
transmission strategy to maximize the network throughput through dynamic
programming. Simulation results show that our proposed MCD-MAC protocol can
significantly increase the network throughput as compared to the existing
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0103</identifier>
 <datestamp>2013-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0103</id><created>2011-04-30</created><updated>2013-08-21</updated><authors><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author></authors><title>A Simple Proof of the Existence of a Planar Separator</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a simple proof of the existence of a planar separator by showing
that it is an easy consequence of the circle packing theorem. We also reprove
other results on separators, including:
  (A) There is a simple cycle separator if the planar graph is triangulated.
Furthermore, if each face has at most $d$ edges on its boundary, then there is
a cycle separator of size O(sqrt{d n}).
  (B) For a set of n balls in R^d, that are k-ply, there is a separator, in the
intersection graph of the balls, of size O(k^{1/d}n^{1-1/d}).
  (C) The k nearest neighbor graph of a set of n points in R^d contains a
separator of size O(k^{1/d} n^{1-1/d}).
  The new proofs are (arguably) significantly simpler than previous proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0106</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0106</id><created>2011-04-30</created><authors><author><keyname>Tobin-Hochstadt</keyname><forenames>Sam</forenames></author><author><keyname>Van Horn</keyname><forenames>David</forenames></author></authors><title>Semantic Solutions to Program Analysis Problems</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Problems in program analysis can be solved by developing novel program
semantics and deriving abstractions conventionally. For over thirty years,
higher-order program analysis has been sold as a hard problem. Its solutions
have required ingenuity and complex models of approximation. We claim that this
difficulty is due to premature focus on abstraction and propose a new approach
that emphasizes semantics. Its simplicity enables new analyses that are beyond
the current state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0116</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0116</id><created>2011-04-30</created><authors><author><keyname>Zhang</keyname><forenames>Chao</forenames></author><author><keyname>Ren</keyname><forenames>Pinyi</forenames></author><author><keyname>Peng</keyname><forenames>Jingbo</forenames></author><author><keyname>Wei</keyname><forenames>Guo</forenames></author><author><keyname>Du</keyname><forenames>Qinghe</forenames></author><author><keyname>Wang</keyname><forenames>Yichen</forenames></author></authors><title>Optimal Relay Power Allocation for Amplify-and-Forward Relay Networks
  with Non-linear Power Amplifiers</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an optimal relay power allocation of an
Amplify-and-Forward relay networks with non-linear power amplifiers. Based on
Bussgang Linearization Theory, we depict the non-linear amplifying process into
a linear system, which lets analyzing system performance easier. To obtain
spatial diversity, we design a complete practical framework of a non-linear
distortion aware receiver. Consider a total relay power constraint, we propose
an optimal power allocation scheme to maximum the receiver signal-to-noise
ratio. Simulation results show that proposed optimal relay power allocation
indeed can improve the system capacity and resist the non-linear distortion. It
is also verified that the proposed transmission scheme outperforms other
transmission schemes without considering non-linear distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0119</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0119</id><created>2011-04-30</created><updated>2012-11-21</updated><authors><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author><author><keyname>Hayden</keyname><forenames>Patrick</forenames></author><author><keyname>Guha</keyname><forenames>Saikat</forenames></author></authors><title>Quantum trade-off coding for bosonic communication</title><categories>quant-ph cs.IT math.IT</categories><comments>20 pages, 7 figures, v2 has a new figure and a proof that the regions
  are optimal for the lossy bosonic channel if the entropy photon-number
  inequality is true; v3, submission to Physical Review A (see related work at
  http://link.aps.org/doi/10.1103/PhysRevLett.108.140501); v4, final version
  accepted into Physical Review A</comments><journal-ref>Physical Review A 86, 062306 (2012)</journal-ref><doi>10.1103/PhysRevA.86.062306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The trade-off capacity region of a quantum channel characterizes the optimal
net rates at which a sender can communicate classical, quantum, and entangled
bits to a receiver by exploiting many independent uses of the channel, along
with the help of the same resources. Similarly, one can consider a trade-off
capacity region when the noiseless resources are public, private, and secret
key bits. In [Phys. Rev. Lett. 108, 140501 (2012)], we identified these
trade-off rate regions for the pure-loss bosonic channel and proved that they
are optimal provided that a longstanding minimum output entropy conjecture is
true. Additionally, we showed that the performance gains of a trade-off coding
strategy when compared to a time-sharing strategy can be quite significant. In
the present paper, we provide detailed derivations of the results announced
there, and we extend the application of these ideas to thermalizing and
amplifying bosonic channels. We also derive a &quot;rule of thumb&quot; for trade-off
coding, which determines how to allocate photons in a coding strategy if a
large mean photon number is available at the channel input. Our results on the
amplifying bosonic channel also apply to the &quot;Unruh channel&quot; considered in the
context of relativistic quantum information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0121</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0121</id><created>2011-04-30</created><authors><author><keyname>Murtagh</keyname><forenames>Fionn</forenames></author><author><keyname>Contreras</keyname><forenames>Pedro</forenames></author></authors><title>Methods of Hierarchical Clustering</title><categories>cs.IR cs.CV math.ST stat.ML stat.TH</categories><comments>21 pages, 2 figures, 1 table, 69 references</comments><msc-class>62H30</msc-class><acm-class>H.3.3; H.2.8; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey agglomerative hierarchical clustering algorithms and discuss
efficient implementations that are available in R and other software
environments. We look at hierarchical self-organizing maps, and mixture models.
We review grid-based clustering, focusing on hierarchical density-based
approaches. Finally we describe a recently developed very efficient (linear
time) hierarchical clustering algorithm, which can also be viewed as a
hierarchical grid-based algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0141</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0141</id><created>2011-05-01</created><authors><author><keyname>Gondara</keyname><forenames>Mandeep Kaur</forenames></author></authors><title>Access Control Mechanisms for Semantic Web services-A Discussion on
  Requirements &amp; Future Directions</title><categories>cs.OH</categories><comments>5 Pages,1 Figure</comments><journal-ref>International journal of emerging technologies and applications in
  engineering, technology and sciences (IJ-ETA-ETS)ISSN: 0974-3588 | Jan 2011
  -- June 2011 | Volume 4 : Issue 1 | Pages: 338-342</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic Web is an open, distributed, and dynamic environment where access to
resources cannot be controlled in a safe manner unless the access decision
takes into account during discovery of web services. Security becomes the
crucial factor for the adoption of the semantic based web services. An access
control means that the users must fulfill certain conditions in order to gain
access over web services. Access control is important in both perspectives i.e.
legal and security point of view. This paper discusses important requirements
for effective access control in semantic web services which have been extracted
from the literature surveyed. I have also discussed open research issues in
this context, focusing on access control policies and models in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0149</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0149</id><created>2011-05-01</created><authors><author><keyname>Khajeh-Hosseini</keyname><forenames>Ali</forenames></author><author><keyname>Sommerville</keyname><forenames>Ian</forenames></author><author><keyname>Bogaerts</keyname><forenames>Jurgen</forenames></author><author><keyname>Teregowda</keyname><forenames>Pradeep</forenames></author></authors><title>Decision Support Tools for Cloud Migration in the Enterprise</title><categories>cs.DC</categories><comments>To appear in IEEE CLOUD 2011</comments><acm-class>C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes two tools that aim to support decision making during the
migration of IT systems to the cloud. The first is a modeling tool that
produces cost estimates of using public IaaS clouds. The tool enables IT
architects to model their applications, data and infrastructure requirements in
addition to their computational resource usage patterns. The tool can be used
to compare the cost of different cloud providers, deployment options and usage
scenarios. The second tool is a spreadsheet that outlines the benefits and
risks of using IaaS clouds from an enterprise perspective; this tool provides a
starting point for risk assessment. Two case studies were used to evaluate the
tools. The tools were useful as they informed decision makers about the costs,
benefits and risks of using the cloud.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0153</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0153</id><created>2011-05-01</created><authors><author><keyname>Moertini</keyname><forenames>Veronica S.</forenames></author><author><keyname>Athuri</keyname><forenames>Asdi A.</forenames></author><author><keyname>Kemit</keyname><forenames>Hery M.</forenames></author><author><keyname>Saputro</keyname><forenames>Nico</forenames></author></authors><title>The Development of Electronic Payment System for Universities in
  Indonesia: On Resolving Key Success Factors</title><categories>cs.SE</categories><comments>18 pages, 8 tables, 5 figures</comments><msc-class>68U35, 68M11</msc-class><acm-class>H.1.0; H.4.0; D.2.1; D.2.10</acm-class><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT), Vol 3, No 2, April 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is known that IT projects are high-risk. To achieve project success, the
strategies to avoid and reduce risks must be designed meticulously and
implemented accordingly. This paper presents methods for avoiding and reducing
risks throughout the development of an information system, specifically
electronic payment system to handle tuition in the universities in Indonesia.
The university policies, regulations and system models are design in such a way
to resolve the project key success factors. By implementing the proposed
methods, the system has been successfully developed and currently operated. The
research is conducted in Parahyangan Catholic University, Bandung, Indonesia.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0155</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0155</id><created>2011-05-01</created><updated>2011-05-30</updated><authors><author><keyname>Lu</keyname><forenames>Lu</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author></authors><title>Optimal Decoding Algorithm for Asynchronous Physical-Layer Network
  Coding</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key issue in physical-layer network coding (PNC) is how to deal with the
asynchrony between signals transmitted by multiple transmitters. That is,
symbols transmitted by different transmitters could arrive at the receiver with
symbol misalignment as well as relative carrier-phase offset. In this paper, 1)
we propose and investigate a general framework based on belief propagation (BP)
that can effectively deal with symbol and phase asynchronies; 2) we show that
for BPSK and QPSK modulations, our BP method can significantly reduce the SNR
penalty due to asynchrony compared with prior methods; 3) we find that symbol
misalignment makes the system performance less sensitive and more robust
against carrier-phase offset. Observation 3) has the following practical
implication. It is relatively easier to control symbol timing than
carrier-phase offset. Our results indicate that if we could control the symbol
offset in PNC, it would actually be advantageous to deliberately introduce
symbol misalignment to desensitize the system to phase offset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0158</identifier>
 <datestamp>2011-09-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0158</id><created>2011-05-01</created><updated>2011-09-22</updated><authors><author><keyname>Balduzzi</keyname><forenames>David</forenames></author></authors><title>Detecting emergent processes in cellular automata with excess
  information</title><categories>cs.IT math.IT nlin.CG q-bio.NC</categories><comments>8 pages, 6 figures</comments><report-no>Advance in Artificial Life, ECAL 2011</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many natural processes occur over characteristic spatial and temporal scales.
This paper presents tools for (i) flexibly and scalably coarse-graining
cellular automata and (ii) identifying which coarse-grainings express an
automaton's dynamics well, and which express its dynamics badly. We apply the
tools to investigate a range of examples in Conway's Game of Life and Hopfield
networks and demonstrate that they capture some basic intuitions about emergent
processes. Finally, we formalize the notion that a process is emergent if it is
better expressed at a coarser granularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0165</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0165</id><created>2011-05-01</created><updated>2011-09-09</updated><authors><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author></authors><title>Quantum counter automata</title><categories>cs.CC quant-ph</categories><comments>A revised version. 16 pages. A preliminary version of this paper
  appeared as A. C. Cem Say, Abuzer Yakary{\i}lmaz, and \c{S}efika
  Y\&quot;{u}zsever. Quantum one-way one-counter automata. In R\={u}si\c{n}\v{s}
  Freivalds, editor, Randomized and quantum computation, pages 25--34, 2010
  (Satellite workshop of MFCS and CSL 2010)</comments><journal-ref>Int. J. Found. Comput. Sci. 23, 1099 (2012)</journal-ref><doi>10.1142/S012905411250013X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The question of whether quantum real-time one-counter automata (rtQ1CAs) can
outperform their probabilistic counterparts has been open for more than a
decade. We provide an affirmative answer to this question, by demonstrating a
non-context-free language that can be recognized with perfect soundness by a
rtQ1CA. This is the first demonstration of the superiority of a quantum model
to the corresponding classical one in the real-time case with an error bound
less than 1. We also introduce a generalization of the rtQ1CA, the quantum
one-way one-counter automaton (1Q1CA), and show that they too are superior to
the corresponding family of probabilistic machines. For this purpose, we
provide general definitions of these models that reflect the modern approach to
the definition of quantum finite automata, and point out some problems with
previous results. We identify several remaining open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0167</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0167</id><created>2011-05-01</created><updated>2012-11-15</updated><authors><author><keyname>Niu</keyname><forenames>Gang</forenames></author><author><keyname>Dai</keyname><forenames>Bo</forenames></author><author><keyname>Yamada</keyname><forenames>Makoto</forenames></author><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author></authors><title>SERAPH: Semi-supervised Metric Learning Paradigm with Hyper Sparsity</title><categories>stat.ML cs.AI</categories><comments>The same paper has been submitted to arXiv by ICML 2012. See
  http://arxiv.org/abs/1206.4614</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a general information-theoretic approach called Seraph
(SEmi-supervised metRic leArning Paradigm with Hyper-sparsity) for metric
learning that does not rely upon the manifold assumption. Given the probability
parameterized by a Mahalanobis distance, we maximize the entropy of that
probability on labeled data and minimize it on unlabeled data following entropy
regularization, which allows the supervised and unsupervised parts to be
integrated in a natural and meaningful way. Furthermore, Seraph is regularized
by encouraging a low-rank projection induced from the metric. The optimization
of Seraph is solved efficiently and stably by an EM-like scheme with the
analytical E-Step and convex M-Step. Experiments demonstrate that Seraph
compares favorably with many well-known global and local metric learning
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0187</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0187</id><created>2011-05-01</created><authors><author><keyname>Mohanty</keyname><forenames>Rakesh</forenames></author><author><keyname>Tripathy</keyname><forenames>Sasmita</forenames></author></authors><title>An Improved Move-To-Front(IMTF) Off-line Algorithm for the List
  Accessing Problem</title><categories>cs.DS</categories><comments>6 pages, 4 Figures</comments><journal-ref>International Journal of Advanced Computing and
  Communications(IJACC), January, 2011, Vol. 3, No. 1, pp-19-24</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the List Accessing Problem, Move-To-Front(MTF) algorithm has been proved
to be the best performing online list accessing algorithm till date in the
literature[10]. In this paper, we have made a comprehensive analysis of MTF
algorithm and developed an Improved-MTF (IMTF) offline algorithm. We have
generated two new types of data set and devise a new method of experimental
analysis for our proposed algorithm. Our experimental analysis shows that IMTF
is performing better than MTF algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0190</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0190</id><created>2011-05-01</created><authors><author><keyname>Rossi</keyname><forenames>M.</forenames></author><author><keyname>Tulino</keyname><forenames>A. M.</forenames></author><author><keyname>Simeone</keyname><forenames>O.</forenames></author><author><keyname>Haimovich</keyname><forenames>A. M.</forenames></author></authors><title>Non-Convex Utility Maximization in Gaussian MISO Broadcast and
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>4 pages, 1 figure. To appear in proceeding of ICASSP 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Utility (e.g., sum-rate) maximization for multiantenna broadcast and
interference channels (with one antenna at the receivers) is known to be in
general a non-convex problem, if one limits the scope to linear (beamforming)
strategies at transmitter and receivers. In this paper, it is shown that, under
some standard assumptions, most notably that the utility function is decreasing
with the interference levels at the receivers, a global optimal solution can be
found with reduced complexity via a suitably designed Branch-and-Bound method.
Although infeasible for real-time implementation, this procedure enables a
non-heuristic and systematic assessment of suboptimal techniques. A suboptimal
strategy is then proposed that, when applied to sum-rate maximization, reduces
to the well-known distributed pricing techniques. Finally, numerical results
are provided that compare global optimal solutions with suboptimal (pricing)
techniques for sum-rate maximization problems, leading to insight into issues
such as the robustness against bad initializations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0200</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0200</id><created>2011-05-01</created><authors><author><keyname>Pyunninen</keyname><forenames>Sergey Alexandrovich</forenames></author></authors><title>Comparative analysis of the accuracy of the distance to the observed
  object for geometric methods</title><categories>cs.OH</categories><comments>5 pages; 2 figures; I International Scientific and Practical
  Conference &quot;Science and Education&quot; (15 april 2011) in Sankt-Peterburg, Russia</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The article presents a comparative analysis of the accuracy of the distance
to the observed object for geometric methods in noisy observations of
bearings-only information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0208</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0208</id><created>2011-05-01</created><authors><author><keyname>Sakhnovich</keyname><forenames>Lev</forenames></author></authors><title>Algorithmic entropy, thermodynamics, and game interpretation</title><categories>cs.IT math-ph math.IT math.LO math.MP math.PR</categories><msc-class>03D32, 68P30, 54C30, 91A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Basic relations for the mean length and algorithmic entropy are obtained by
solving a new extremal problem. Using this extremal problem, they are obtained
in a most simple and general way. The length and entropy are considered as two
players of a new type of a game, in which we follow the scheme of our previous
work on thermodynamic characteristics in quantum and classical approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0214</identifier>
 <datestamp>2014-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0214</id><created>2011-05-01</created><updated>2011-12-22</updated><authors><author><keyname>Cotilla-Sanchez</keyname><forenames>Eduardo</forenames></author><author><keyname>Hines</keyname><forenames>Paul D. H.</forenames></author><author><keyname>Barrows</keyname><forenames>Clayton</forenames></author><author><keyname>Blumsack</keyname><forenames>Seth</forenames></author></authors><title>Comparing the Topological and Electrical Structure of the North American
  Electric Power Infrastructure</title><categories>physics.soc-ph cs.SI</categories><journal-ref>IEEE Systems Journal, vol. 6, no. 4, 2012</journal-ref><doi>10.1109/JSYST.2012.2183033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The topological (graph) structure of complex networks often provides valuable
information about the performance and vulnerability of the network. However,
there are multiple ways to represent a given network as a graph. Electric power
transmission and distribution networks have a topological structure that is
straightforward to represent and analyze as a graph. However, simple graph
models neglect the comprehensive connections between components that result
from Ohm's and Kirchhoff's laws. This paper describes the structure of the
three North American electric power interconnections, from the perspective of
both topological and electrical connectivity. We compare the simple topology of
these networks with that of random (Erdos and Renyi, 1959),
preferential-attachment (Barabasi and Albert, 1999) and small-world (Watts and
Strogatz, 1998) networks of equivalent sizes and find that power grids differ
substantially from these abstract models in degree distribution, clustering,
diameter and assortativity, and thus conclude that these topological forms may
be misleading as models of power systems. To study the electrical connectivity
of power systems, we propose a new method for representing electrical structure
using electrical distances rather than geographic connections. Comparisons of
these two representations of the North American power networks reveal notable
differences between the electrical and topological structure of electric power
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0215</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0215</id><created>2011-05-01</created><authors><author><keyname>Mahmood</keyname><forenames>Kashif</forenames></author><author><keyname>Vehkaper&#xe4;</keyname><forenames>Mikko</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author></authors><title>Cross-Layer Modeling of Randomly Spread CDMA Using Stochastic Network
  Calculus</title><categories>cs.NI</categories><comments>File submitted to PIMRC has 5 pages. 3 figures, Submitted to
  PIMRC,2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Code-division multiple-access (CDMA) has the potential to support traffic
sources with a wide range of quality of service (QoS) requirements. The traffic
carrying capacity of CDMA channels under QoS constraints (such as delay
guarantee) is, however, less well-understood. In this work, we propose a method
based on stochastic network calculus and large system analysis to quantify the
maximum traffic that can be carried by a multiuser CDMA network under the QoS
constraints. At the physical layer, we have linear minimum-mean square error
receivers and adaptive modulation and coding, while the channel service process
is modeled by using a finite-state Markov chain. We study the impact of delay
requirements, violation probability and the user load on the traffic carrying
capacity under different signal strengths. A key insight provided by the
numerical results is as to how much one has to back-off from capacity under the
different delay requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0232</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0232</id><created>2011-05-01</created><authors><author><keyname>Sahai</keyname><forenames>Ankur</forenames></author></authors><title>Online Assignment Algorithms for Dynamic Bipartite Graphs</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes the problem of assigning weights to edges incrementally
in a dynamic complete bipartite graph consisting of producer and consumer
nodes. The objective is to minimize the overall cost while satisfying certain
constraints. The cost and constraints are functions of attributes of the edges,
nodes and online service requests. Novelty of this work is that it models
real-time distributed resource allocation using an approach to solve this
theoretical problem. This paper studies variants of this assignment problem
where the edges, producers and consumers can disappear and reappear or their
attributes can change over time. Primal-Dual algorithms are used for solving
these problems and their competitive ratios are evaluated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0233</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0233</id><created>2011-05-01</created><authors><author><keyname>Sahai</keyname><forenames>Ankur</forenames></author></authors><title>Derandomization of Online Assignment Algorithms for Dynamic Graphs</title><categories>cs.CC cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper analyzes different online algorithms for the problem of assigning
weights to edges in a fully-connected bipartite graph that minimizes the
overall cost while satisfying constraints. Edges in this graph may disappear
and reappear over time. Performance of these algorithms is measured using
simulations. This paper also attempts to derandomize the randomized online
algorithm for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0234</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0234</id><created>2011-05-01</created><authors><author><keyname>Lin</keyname><forenames>Cheng-Chung</forenames></author><author><keyname>Sandrasegaran</keyname><forenames>Kumbesan</forenames></author><author><keyname>Ramli</keyname><forenames>Huda Adibah Mohd</forenames></author><author><keyname>Basukala</keyname><forenames>Riyaj</forenames></author></authors><title>Optimized Performance Evaluation of LTE Hard Handover Algorithm with
  Average RSRP Constraint</title><categories>cs.NI</categories><comments>16 pages, 9 figures, International Journal of Wireless &amp; Mobile
  Networks (IJWMN)</comments><doi>10.5121/ijwmn.2011.3201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hard handover mechanism is adopted to be used in 3GPP Long Term Evolution
(3GPP LTE) in order to reduce the complexity of the LTE network architecture.
This mechanism comes with degradation in system throughput as well as a higher
system delay. This paper proposes a new handover algorithm known as LTE Hard
Handover Algorithm with Average Received Signal Reference Power (RSRP)
Constraint (LHHAARC) in order to minimize number of handovers and the system
delay as well as maximize the system throughput. An optimized system
performance of the LHHAARC is evaluated and compared with three well-known
handover algorithms via computer simulation. The simulation results show that
the LHHAARC outperforms three well-known handover algorithms by having less
number of average handovers per UE per second, shorter total system delay
whilst maintaining a higher total system throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0240</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0240</id><created>2011-05-02</created><updated>2011-08-12</updated><authors><author><keyname>Kowshik</keyname><forenames>Hemant</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Optimal Function Computation in Directed and Undirected Graphs</title><categories>cs.IT cs.NI math.IT</categories><comments>submitted to IEEE Transactions on Information Theory, April 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of information aggregation in sensor networks, where
one is interested in computing a function of the sensor measurements. We allow
for block processing and study in-network function computation in directed
graphs and undirected graphs. We study how the structure of the function
affects the encoding strategies, and the effect of interactive information
exchange.
  We begin by considering a directed graph G = (V, E) on the sensor nodes,
where the goal is to determine the optimal encoders on each edge which achieve
function computation at the collector node. Our goal is to characterize the
rate region in R^{|E|}, i.e., the set of points for which there exist feasible
encoders with given rates which achieve zero-error computation for
asymptotically large block length. We determine the solution for directed
trees, specifying the optimal encoder and decoder for each edge. For general
directed acyclic graphs, we provide an outer bound on the rate region by
finding the disambiguation requirements for each cut, and describe examples
where this outer bound is tight.
  Next, we address the scenario where nodes are connected in an undirected tree
network, and every node wishes to compute a given symmetric Boolean function of
the sensor data. Undirected edges permit interactive computation, and we
therefore study the effect of interaction on the aggregation and communication
strategies. We focus on sum-threshold functions, and determine the minimum
worst-case total number of bits to be exchanged on each edge. The optimal
strategy involves recursive in-network aggregation which is reminiscent of
message passing. In the case of general graphs, we present a cutset lower
bound, and an achievable scheme based on aggregation along trees. For complete
graphs, we prove that the complexity of this scheme is no more than twice that
of the optimal scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0247</identifier>
 <datestamp>2012-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0247</id><created>2011-05-02</created><updated>2012-01-26</updated><authors><author><keyname>Bayraktar</keyname><forenames>Erhan</forenames></author><author><keyname>Ludkovski</keyname><forenames>Michael</forenames></author></authors><title>Liquidation in Limit Order Books with Controlled Intensity</title><categories>q-fin.TR cs.SY math.OC</categories><comments>23 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a framework for solving optimal liquidation problems in limit
order books. In particular, order arrivals are modeled as a point process whose
intensity depends on the liquidation price. We set up a stochastic control
problem in which the goal is to maximize the expected revenue from liquidating
the entire position held. We solve this optimal liquidation problem for
power-law and exponential-decay order book models and discuss several
extensions. We also consider the continuous selling (or fluid) limit when the
trading units are ever smaller and the intensity is ever larger. This limit
provides an analytical approximation to the value function and the optimal
solution. Using techniques from viscosity solutions we show that the discrete
state problem and its optimal solution converge to the corresponding quantities
in the continuous selling limit uniformly on compacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0251</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0251</id><created>2011-05-02</created><authors><author><keyname>Bisen</keyname><forenames>Dhananjay</forenames></author><author><keyname>Sharma</keyname><forenames>Dr. Sanjeev</forenames></author></authors><title>Improve performance of tcp new reno over mobile ad-hoc network using
  abra</title><categories>cs.NI</categories><doi>10.5121/ijwmn.2011.3209</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In a mobile ad hoc network, temporary link failures and route changes occur
frequently. With the assumption that all packet losses are due to congestion,
TCP performs poorly in such an environment. There are many versions of TCP
which modified time to time as per need. In this paper modifications introduced
on TCP New Reno over mobile ad-hoc networks using calculation of New
Retransmission Time out (RTO), to improve performance in term of congestion
control. To calculate New RTO, adaptive backoff response approach (ABRA) in TCP
New Reno was applied which suggest ABRA New Reno. It utilizes an ABRA by which
congestion window and slow start threshold values were decreased whenever an
acknowledgement is received and new backoff value calculate from smoothed round
trip time. Evaluation based on comparative study of ABRA New Reno with other
TCP Variants like New Reno and Reno was done using realistic parameters like
TCP Packet Received, Packet Drop, Packets Retransmitted, Throughput, and Packet
Delivery Ratio calculated by varying attributes of Node Speed, Number of Nodes
and Pause Time. Implementation and simulations were performed in QualNet 4.0
simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0256</identifier>
 <datestamp>2013-02-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0256</id><created>2011-05-02</created><updated>2013-02-06</updated><authors><author><keyname>Alpay</keyname><forenames>Daniel</forenames></author><author><keyname>Jorgensen</keyname><forenames>Palle</forenames></author><author><keyname>Lewkowicz</keyname><forenames>Izchak</forenames></author></authors><title>Easy-to-compute parameterizations of all wavelet filters: input-output
  and state-space</title><categories>math.CV cs.SY math.OC</categories><comments>The present version is better coordinated with another work of us on
  the same subject, entitled Extending wavelet filters. Infinite dimensions,
  the non-rational case and indefinite-inner product spaces, and also available
  on arxiv at: http://arxiv.org/abs/1106.2303</comments><msc-class>42C40, 26C15, 93B15, 94C05, 65T60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We here use notions from the theory linear shift-invariant dynamical systems
to provide an easy-to-compute characterization of all rational wavelet filters.
For a given N bigger or equql to 2, the number of inputs, the construction is
based on a factorization to an elementary wavelet filter along with of m
elementary unitary matrices. We shall call this m the index of the filter. It
turns out that the resulting wavelet filter is of McMillan degree
$N((N-1)/2+m).
  Rational wavelet filters bounded at infinity, admit state space realization.
The above input-output parameterization is exploited for a step-by-step
construction (where in each the index m is increased by one) of state space
model of wavelet filters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0257</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0257</id><created>2011-05-02</created><updated>2011-08-11</updated><authors><author><keyname>Kim</keyname><forenames>Youngdo</forenames></author><author><keyname>Jeong</keyname><forenames>Hawoong</forenames></author></authors><title>Map equation for link community</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>9 pages,5 figures</comments><journal-ref>Phys. Rev. E 84, 026110 (2011)</journal-ref><doi>10.1103/PhysRevE.84.026110</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community structure exists in many real-world networks and has been reported
being related to several functional properties of the networks. The
conventional approach was partitioning nodes into communities, while some
recent studies start partitioning links instead of nodes to find overlapping
communities of nodes efficiently. We extended the map equation method, which
was originally developed for node communities, to find link communities in
networks. This method is tested on various kinds of networks and compared with
the metadata of the networks, and the results show that our method can identify
the overlapping role of nodes effectively. The advantage of this method is that
the node community scheme and link community scheme can be compared
quantitatively by measuring the unknown information left in the networks
besides the community structure. It can be used to decide quantitatively
whether or not the link community scheme should be used instead of the node
community scheme. Furthermore, this method can be easily extended to the
directed and weighted networks since it is based on the random walk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0259</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0259</id><created>2011-05-02</created><authors><author><keyname>Maines</keyname><forenames>Lara</forenames></author><author><keyname>Piva</keyname><forenames>Matteo</forenames></author><author><keyname>Rimoldi</keyname><forenames>Anna</forenames></author><author><keyname>Sala</keyname><forenames>Massimiliano</forenames></author></authors><title>On the provable security of BEAR and LION schemes</title><categories>cs.CR cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BEAR, LION and LIONESS are block ciphers presented by Biham and Anderson
(1996), inspired by the famous Luby-Rackoff constructions of block ciphers from
other cryptographic primitives (1988). The ciphers proposed by Biham and
Anderson are based on one stream cipher and one hash function. Good properties
of the primitives ensure good properties of the block cipher. In particular,
they are able to prove that their ciphers are immune to any efficient
known-plaintext key-recovery attack that can use as input only one
plaintext-ciphertext pair. Our contribution is showing that these ciphers are
actually immune to any efficient known-plaintext key-recovery attack that can
use as input any number of plaintext-ciphertext pairs. We are able to get this
improvement by using slightly weaker hypotheses on the primitives. We also
discuss the attack by Morin (1996).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0275</identifier>
 <datestamp>2011-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0275</id><created>2011-05-02</created><updated>2011-09-22</updated><authors><author><keyname>Wang</keyname><forenames>Hui</forenames></author><author><keyname>Huang</keyname><forenames>Jinyuan</forenames></author><author><keyname>Xu</keyname><forenames>Xiaomin</forenames></author><author><keyname>Xiao</keyname><forenames>Yanghua</forenames></author><author><keyname>Wang</keyname><forenames>Wei</forenames></author></authors><title>Robustness of Complex Networks against Attacks Guided by Damage</title><categories>physics.soc-ph cs.SI</categories><comments>12 pages, 12 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Extensive researches have been dedicated to investigating the performance of
real networks and synthetic networks against random failures or intentional
attack guided by degree (degree attack). Degree is one of straightforward
measures to characterize the vitality of a vertex in maintaining the integrity
of the network but not the only one. Damage, the decrease of the largest
component size that was caused by the removal of a vertex, intuitively is a
more destructive guide for intentional attack on networks since the network
functionality is usually measured by the largest component size. However, it is
surprising to find that little is known about behaviors of real networks or
synthetic networks against intentional attack guided by damage (damage attack),
in which adversaries always choose the vertex with the largest damage to
attack.
  In this article, we dedicate our efforts to understanding damage attack and
behaviors of real networks as well as synthetic networks against this attack.
To this end, existing attacking models, statistical properties of damage in
complex networks are first revisited. Then, we present the empirical analysis
results about behaviors of complex networks against damage attack with the
comparisons to degree attack. It is surprising to find a cross-point for
diverse networks before which damage attack is more destructive than degree
attack. Further investigation shows that the existence of cross-point can be
attributed to the fact that: degree attack tends produce networks with more
heterogenous damage distribution than damage attack. Results in this article
strongly suggest that damage attack is one of most destructive attacks and
deserves our research efforts.Our understandings about damage attack may also
shed light on efficient solutions to protect real networks against damage
attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0283</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0283</id><created>2011-05-02</created><updated>2011-05-03</updated><authors><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>Rojas</keyname><forenames>Julio</forenames></author><author><keyname>Wong</keyname><forenames>Sulan</forenames></author><author><keyname>Hanawal</keyname><forenames>Manjesh Kumar</forenames></author><author><keyname>Xu</keyname><forenames>Yuedong</forenames></author></authors><title>Net Neutrality and Quality of Service</title><categories>cs.NI</categories><comments>16 pages, 0 figure, 1 table</comments><journal-ref>Proc. of ICST Conf. Game Theory for Networks 2011, April 16-18
  2011, Shanghai, China</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  2010 has witnessed many public consultations around the world concerning Net
neutrality. A second legislative phase that may follow, could involve various
structural changes in the Internet. The status that the Internet access has in
Europe as a universal service evolves as the level of quality of service (QoS)
to be offered improves. If guarantees on QoS are to be imposed, as requested by
several economic actors, it would require introducing new indicators of quality
of services, as well as regulation legislation and monitoring of the offered
levels of QoS. This tendency in Europe may change the nature of the Internet
from a best effort network to, perhaps, a more expensive one, that offers
guaranteed performance. This paper presents an overview of the above issues as
well as an overview of recent research on net-neutrality, with an emphasis on
game theoretical approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0285</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0285</id><created>2011-05-02</created><updated>2011-05-04</updated><authors><author><keyname>Wang</keyname><forenames>Tao</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>WSR Maximized Resource Allocation in Multiple DF Relays Aided OFDMA
  Downlink Transmission</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>13 pages and 14 figures, to appear in IEEE Transactions Signal
  Processing</comments><doi>10.1109/TSP.2011.2153196</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the weighted sum rate (WSR) maximized resource
allocation (RA) constrained by a system sum power in an orthogonal frequency
division multiple access (OFDMA) downlink transmission system assisted by
multiple decode-and-forward (DF) relays. In particular, multiple relays may
cooperate with the source for every relay-aided transmission. A two-step
algorithm is proposed to find the globally optimum RA. In the first step, the
optimum source/relay power and assisting relays that maximize the rate is found
for every combination of subcarrier and destination, assuming a sum power is
allocated to the transmission at that subcarrier to that destination in the
relay-aided transmission mode and the direct mode, respectively. In the second
step, a convex-optimization based algorithm is designed to find the globally
optimum assignment of destination, transmission mode, and sum power for each
subcarrier to maximize the WSR. Combining the RAs found in the two steps, the
globally optimum RA can be found. In addition, we show that the optimum RA in
the second step can readily be derived when the system sum power is very high.
The effectiveness of the proposed algorithm is illustrated by numerical
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0286</identifier>
 <datestamp>2013-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0286</id><created>2011-05-02</created><authors><author><keyname>Ruan</keyname><forenames>Liangzhong</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author></authors><title>Dynamic Interference Mitigation for Generalized Partially Connected
  Quasi-static MIMO Interference Channel</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures, accepted by IEEE Transaction on Signal
  Processing</comments><doi>10.1109/ACSSC.2011.6190019</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent works on MIMO interference channels have shown that interference
alignment can significantly increase the achievable degrees of freedom (DoF) of
the network. However, most of these works have assumed a fully connected
interference graph. In this paper, we investigate how the partial connectivity
can be exploited to enhance system performance in MIMO interference networks.
We propose a novel interference mitigation scheme which introduces constraints
for the signal subspaces of the precoders and decorrelators to mitigate &quot;many&quot;
interference nulling constraints at a cost of &quot;little&quot; freedoms in precoder and
decorrelator design so as to extend the feasibility region of the interference
alignment scheme. Our analysis shows that the proposed algorithm can
significantly increase system DoF in symmetric partially connected MIMO
interference networks. We also compare the performance of the proposed scheme
with various baselines and show via simulations that the proposed algorithms
could achieve significant gain in the system performance of randomly connected
interference networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0288</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0288</id><created>2011-05-02</created><authors><author><keyname>Slota</keyname><forenames>Martin</forenames></author><author><keyname>Leite</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Swift</keyname><forenames>Terrance</forenames></author></authors><title>Splitting and Updating Hybrid Knowledge Bases (Extended Version)</title><categories>cs.AI</categories><comments>64 pages; extended version of the paper accepted for ICLP 2011</comments><journal-ref>Theory and Practice of Logic Programming, 11(4-5), 801-819, 2011</journal-ref><doi>10.1017/S1471068411000317</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the years, nonmonotonic rules have proven to be a very expressive and
useful knowledge representation paradigm. They have recently been used to
complement the expressive power of Description Logics (DLs), leading to the
study of integrative formal frameworks, generally referred to as hybrid
knowledge bases, where both DL axioms and rules can be used to represent
knowledge. The need to use these hybrid knowledge bases in dynamic domains has
called for the development of update operators, which, given the substantially
different way Description Logics and rules are usually updated, has turned out
to be an extremely difficult task.
  In [SL10], a first step towards addressing this problem was taken, and an
update operator for hybrid knowledge bases was proposed. Despite its
significance -- not only for being the first update operator for hybrid
knowledge bases in the literature, but also because it has some applications -
this operator was defined for a restricted class of problems where only the
ABox was allowed to change, which considerably diminished its applicability.
Many applications that use hybrid knowledge bases in dynamic scenarios require
both DL axioms and rules to be updated.
  In this paper, motivated by real world applications, we introduce an update
operator for a large class of hybrid knowledge bases where both the DL
component as well as the rule component are allowed to dynamically change. We
introduce splitting sequences and splitting theorem for hybrid knowledge bases,
use them to define a modular update semantics, investigate its basic
properties, and illustrate its use on a realistic example about cargo imports.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0296</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0296</id><created>2011-05-02</created><authors><author><keyname>Li</keyname><forenames>Yang D.</forenames></author></authors><title>A Formal Model of Anonymous Systems</title><categories>cs.DC</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We put forward a formal model of anonymous systems. And we concentrate on the
anonymous failure detectors in our model. In particular, we give three examples
of anonymous failure detectors and show that they can be used to solve the
consensus problem and that they are equivalent to their classic counterparts.
Moreover, we show some relationship among them and provide a simple
classification of anonymous failure detectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0319</identifier>
 <datestamp>2012-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0319</id><created>2011-05-02</created><updated>2012-11-13</updated><authors><author><keyname>Wiese</keyname><forenames>Moritz</forenames></author><author><keyname>Boche</keyname><forenames>Holger</forenames></author></authors><title>The Arbitrarily Varying Multiple-Access Channel with Conferencing
  Encoders</title><categories>cs.IT math.IT</categories><comments>12 pages, accepted for publication in IEEE Transaction on Information
  Theory</comments><journal-ref>IEEE Transactions on Information Theory, 2012</journal-ref><doi>10.1109/TIT.2012.2229779</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive the capacity region of arbitrarily varying multiple-access channels
with conferencing encoders for both deterministic and random coding. For a
complete description it is sufficient that one conferencing capacity is
positive. We obtain a dichotomy: either the channel's deterministic capacity
region is zero or it equals the two-dimensional random coding region. We
determine exactly when either case holds. We also discuss the benefits of
conferencing. We give the example of an AV-MAC which does not achieve any
non-zero rate pair without encoder cooperation, but the two-dimensional random
coding capacity region if conferencing is possible. Unlike compound
multiple-access channels, arbitrarily varying multiple-access channels may
exhibit a discontinuous increase of the capacity region when conferencing in at
least one direction is enabled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0322</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0322</id><created>2011-05-02</created><updated>2013-03-03</updated><authors><author><keyname>Fukui</keyname><forenames>Toshio</forenames></author></authors><title>A Computational Model for the Direct Execution of General Specifications
  with Multi-way Constraints</title><categories>cs.PL cs.SE</categories><comments>21 pages, 15 figures</comments><acm-class>D.2.0; D.3.2; D.3.3; F.1.1; F.1.2; F.4.1; I.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a computational model for the direct execution of
general specifications with multi-way constraints. Although this computational
model has a similar structure to existing constraint programming models, it is
not meant for solving constraint satisfaction problems but rather for the
simulation of social systems and to continue to execute assigned processes.
Because of this similar structure, it is applicable to the spectrum of the
constraint solver, which is purple in this model. Essentially, it is a
technology that can speed up the construction of large-scale network systems.
This model can be efficiently executed to directly describe design content in a
simple way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0324</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0324</id><created>2011-05-02</created><updated>2011-11-06</updated><authors><author><keyname>Faqeeh</keyname><forenames>Ali</forenames></author><author><keyname>Samani</keyname><forenames>Keivan Aghababaei</forenames></author></authors><title>Community detection based on &quot;clumpiness&quot; matrix in complex networks</title><categories>physics.soc-ph cs.SI</categories><comments>18 pages and 13 figures</comments><doi>10.1016/j.physa.2011.12.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The &quot;clumpiness&quot; matrix of a network is used to develop a method to identify
its community structure. A &quot;projection space&quot; is constructed from the
eigenvectors of the clumpiness matrix and a border line is defined using some
kind of angular distance in this space. The community structure of the network
is identified using this borderline and/or hierarchical clustering methods. The
performance of our algorithm is tested on some computer-generated and
real-world networks. The accuracy of the results is checked using normalized
mutual information. The effect of community size heterogeneity on the accuracy
of the method is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0332</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0332</id><created>2011-05-02</created><authors><author><keyname>Ramya</keyname><forenames>C.</forenames></author><author><keyname>Kavitha</keyname><forenames>G.</forenames></author><author><keyname>Shreedhara</keyname><forenames>Dr. K. S.</forenames></author></authors><title>Recalling of Images using Hopfield Neural Network Model</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, an effort has been made for storing and recalling
images with Hopfield Neural Network Model of auto-associative memory. Images
are stored by calculating a corresponding weight matrix. Thereafter, starting
from an arbitrary configuration, the memory will settle on exactly that stored
image, which is nearest to the starting configuration in terms of Hamming
distance. Thus given an incomplete or corrupted version of a stored image, the
network is able to recall the corresponding original image. The storing of the
objects has been performed according to the Hopfield algorithm explained below.
Once the net has completely learnt this set of input patterns, a set of testing
patterns containing degraded images will be given to the net. Then the Hopfield
net will tend to recall the closest matching pattern for the given degraded
image. The simulated results show that Hopfield model is the best for storing
and recalling images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0350</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0350</id><created>2011-05-02</created><authors><author><keyname>Ramya</keyname><forenames>C.</forenames></author><author><keyname>Kavitha</keyname><forenames>G.</forenames></author><author><keyname>Shreedhara</keyname><forenames>Dr. K. S.</forenames></author></authors><title>Preprocessing: A Prerequisite for Discovering Patterns in Web Usage
  Mining Process</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web log data is usually diverse and voluminous. This data must be assembled
into a consistent, integrated and comprehensive view, in order to be used for
pattern discovery. Without properly cleaning, transforming and structuring the
data prior to the analysis, one cannot expect to find meaningful patterns. As
in most data mining applications, data preprocessing involves removing and
filtering redundant and irrelevant data, removing noise, transforming and
resolving any inconsistencies. In this paper, a complete preprocessing
methodology having merging, data cleaning, user/session identification and data
formatting and summarization activities to improve the quality of data by
reducing the quantity of data has been proposed. To validate the efficiency of
the proposed preprocessing methodology, several experiments are conducted and
the results show that the proposed methodology reduces the size of Web access
log files down to 73-82% of the initial size and offers richer logs that are
structured for further stages of Web Usage Mining (WUM). So preprocessing of
raw data in this WUM process is the central theme of this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0354</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0354</id><created>2011-05-02</created><updated>2011-05-08</updated><authors><author><keyname>Rothenberg</keyname><forenames>Robert</forenames></author></authors><title>Modality for Free: Notes on Adding the Tarskian M\&quot;{o}glichkeit to
  Substructural Logics</title><categories>math.LO cs.LO</categories><comments>8 pages, work in progress</comments><msc-class>03</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We briefly examine the modal formulae that can be derived in Multiplicative
Additive Linear Logic (MALL) and some extensions by using Tarksi's extensional
modal operators. We also breifly compare this with a substructural form of the
modal logic K.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0355</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0355</id><created>2011-05-02</created><authors><author><keyname>Kaya</keyname><forenames>Y\ilmaz</forenames></author><author><keyname>Uyar</keyname><forenames>Murat</forenames></author><author><keyname>Tek\D{j}n</keyname><forenames>Ramazan</forenames></author></authors><title>A Novel Crossover Operator for Genetic Algorithms: Ring Crossover</title><categories>cs.NE</categories><comments>5 pages, 3 fgigures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The genetic algorithm (GA) is an optimization and search technique based on
the principles of genetics and natural selection. A GA allows a population
composed of many individuals to evolve under specified selection rules to a
state that maximizes the &quot;fitness&quot; function. In that process, crossover
operator plays an important role. To comprehend the GAs as a whole, it is
necessary to understand the role of a crossover operator. Today, there are a
number of different crossover operators that can be used in GAs. However, how
to decide what operator to use for solving a problem? A number of test
functions with various levels of difficulty has been selected as a test polygon
for determine the performance of crossover operators. In this paper, a novel
crossover operator called 'ring crossover' is proposed. In order to evaluate
the efficiency and feasibility of the proposed operator, a comparison between
the results of this study and results of different crossover operators used in
GAs is made through a number of test functions with various levels of
difficulty. Results of this study clearly show significant differences between
the proposed operator and the other crossover operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0362</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0362</id><created>2011-04-29</created><authors><author><keyname>Bouallegue</keyname><forenames>Najoua Achoura And Ridha</forenames></author></authors><title>Impact of Limited Feedback on MIMO-OFDM Systems using Joint Beamforming</title><categories>cs.OH</categories><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  3, No. 2, April 2011, 39-45</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In multi input multi output antenna systems, beamforming is a technique for
guarding against the negative effects of fading. However, this technique
requires the transmitter to have perfect knowledge of the channel which is
often not available a priori. A solution to overcome this problem is to design
the beamforming vector using a limited number of feedback bits sent from the
receiver to the transmitter. In the case of limited feedback, the beamforming
vector is limited to lie in a codebook that is known to both the transmitter
and receiver.When the feedback is strictly limited, important issues are how to
quantize the information needed at the transmitter and how much improvement in
associated performance can be obtained as a function of the amount of feedback
available.In this paper channel quantization schema using simple approach to
codebook design (random vector quantization)is illustrated. Performance results
show that even with a few bits of feedback, performance can be close to that
with perfect channel knowledge at the transmitter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0377</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0377</id><created>2011-05-02</created><authors><author><keyname>Bera</keyname><forenames>Rabindranath</forenames></author><author><keyname>Sarkar</keyname><forenames>Subir Kumar</forenames></author><author><keyname>Sharma</keyname><forenames>Bikash</forenames></author><author><keyname>Sur</keyname><forenames>Samarendra Nath</forenames></author><author><keyname>Bhaskar</keyname><forenames>Debasish</forenames></author><author><keyname>Bera</keyname><forenames>Soumyasree</forenames></author></authors><title>WiMAX Based 60 GHz Millimeter-Wave Communication for Intelligent
  Transport System Applications</title><categories>cs.IT math.IT</categories><journal-ref>International Journal of Wireless &amp; Mobile Networks (IJWMN) Vol.
  3, No. 2, April 2011, 214-223</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the successful worldwide deployment of 3rd generation mobile
communication, security aspects are ensured partly. Researchers are now looking
for 4G mobile for its deployment with high data rate, enhanced security and
reliability so that world should look for CALM, Continuous Air interface for
Long and Medium range communication. This CALM will be a reliable high data
rate secured mobile communication to be deployed for car to car communication
(C2C) for safety application. This paper reviewed the WiMAX ,&amp; 60 GHz RF
carrier for C2C. The system is tested at SMIT laboratory with multimedia
transmission and reception. With proper deployment of this 60 GHz system on
vehicles, the existing commercial products for 802.11P will be required to be
replaced or updated soon .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0379</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0379</id><created>2011-05-02</created><authors><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author></authors><title>Self-Repairing Codes for Distributed Storage - A Projective Geometric
  Construction</title><categories>cs.DC cs.IT math.IT</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-Repairing Codes (SRC) are codes designed to suit the need of coding for
distributed networked storage: they not only allow stored data to be recovered
even in the presence of node failures, they also provide a repair mechanism
where as little as two live nodes can be contacted to regenerate the data of a
failed node. In this paper, we propose a new instance of self-repairing codes,
based on constructions of spreads coming from projective geometry. We study
some of their properties to demonstrate the suitability of these codes for
distributed networked storage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0381</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0381</id><created>2011-05-02</created><updated>2011-05-03</updated><authors><author><keyname>D'Angelo</keyname><forenames>Gabriele</forenames></author></authors><title>Parallel and Distributed Simulation: Five W's (and One H)</title><categories>cs.DC cs.MA</categories><comments>MIMOS DSIMday 2011, Universita di Roma Tor Vergata, February 25,2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well known golden rule of journalism (and many other fields too) is that if
you want to know the full story about something you have to answer all the five
W's (Who, What, When, Where, Why) and the H (How). This extended abstract is
about what is missing in parallel and distributed simulation and how this
affects its popularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0382</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0382</id><created>2011-05-02</created><authors><author><keyname>Pelossof</keyname><forenames>Raphael</forenames></author><author><keyname>Ying</keyname><forenames>Zhiliang</forenames></author></authors><title>Rapid Learning with Stochastic Focus of Attention</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method to stop the evaluation of a decision making process when
the result of the full evaluation is obvious. This trait is highly desirable
for online margin-based machine learning algorithms where a classifier
traditionally evaluates all the features for every example. We observe that
some examples are easier to classify than others, a phenomenon which is
characterized by the event when most of the features agree on the class of an
example. By stopping the feature evaluation when encountering an easy to
classify example, the learning algorithm can achieve substantial gains in
computation. Our method provides a natural attention mechanism for learning
algorithms. By modifying Pegasos, a margin-based online learning algorithm, to
include our attentive method we lower the number of attributes computed from
$n$ to an average of $O(\sqrt{n})$ features without loss in prediction
accuracy. We demonstrate the effectiveness of Attentive Pegasos on MNIST data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0390</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0390</id><created>2011-05-02</created><authors><author><keyname>Bakshi</keyname><forenames>Tuli</forenames></author><author><keyname>Sarkar</keyname><forenames>Bijan</forenames></author></authors><title>MCA Based Performance Evaluation of Project Selection</title><categories>cs.SE</categories><comments>9 Pages,1 Figure, 7 Tables</comments><doi>10.5121/ijsea.2011.2202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-criteria decision support systems are used in various fields of human
activities. In every alternative multi-criteria decision making problem can be
represented by a set of properties or constraints. The properties can be
qualitative &amp; quantitative. For measurement of these properties, there are
different unit, as well as there are different optimization techniques.
Depending upon the desired goal, the normalization aims for obtaining reference
scales of values of these properties. This paper deals with a new additive
ratio assessment method. In order to make the appropriate decision and to make
a proper comparison among the available alternatives Analytic Hierarchy Process
(AHP) and ARAS have been used. The uses of AHP is for analysis the structure of
the project selection problem and to assign the weights of the properties and
the ARAS method is used to obtain the final ranking and select the best one
among the projects. To illustrate the above mention methods survey data on the
expansion of optical fibre for a telecommunication sector is used. The decision
maker can also used different weight combination in the decision making process
according to the demand of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0392</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0392</id><created>2011-05-02</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author></authors><title>Tracking Moving Objects with Few Handovers</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the online problem of assigning a moving point to a base-station
region that contains it. For instance, the moving object could represent a
cellular phone and the base station could represent the coverage zones of cell
towers. Our goal is to minimize the number of handovers that occur when the
point moves outside its assigned region and must be assigned to a new region.
We study this problem in terms of competitive analysis and we measure the
competitive ratio of our algorithms as a function of the ply of the system of
regions, that is, the maximum number of regions that cover any single point. In
the offline version of this problem, when object motions are known in advance,
a simple greedy strategy suffices to determine an optimal assignment of objects
to base stations, with as few handovers as possible. For the online version of
this problem for moving points in one dimension, we present a deterministic
algorithm that achieves a competitive ratio of O(log ply) with respect to the
optimal algorithm, and we show that no better ratio is possible. For two or
more dimensions, we present a randomized online algorithm that achieves a
competitive ratio of O(log ply) with respect to the optimal algorithm, and a
deterministic algorithm that achieves a competitive ratio of O(ply); again, we
show that no better ratio is possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0393</identifier>
 <datestamp>2013-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0393</id><created>2011-05-02</created><updated>2013-11-12</updated><authors><author><keyname>Krueger</keyname><forenames>Tyll</forenames></author><author><keyname>Montufar</keyname><forenames>Guido</forenames></author><author><keyname>Seiler</keyname><forenames>Ruedi</forenames></author><author><keyname>Siegmund-Schultze</keyname><forenames>Rainer</forenames></author></authors><title>Universally Typical Sets for Ergodic Sources of Multidimensional Data</title><categories>cs.IT math.IT</categories><comments>15 pages, 1 figure. To appear in Kybernetika. This replacement
  corrects typos and slightly strengthens the main theorem</comments><msc-class>94A24, 62D05, 94A08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We lift important results about universally typical sets, typically sampled
sets, and empirical entropy estimation in the theory of samplings of discrete
ergodic information sources from the usual one-dimensional discrete-time
setting to a multidimensional lattice setting. We use techniques of packings
and coverings with multidimensional windows to construct sequences of
multidimensional array sets which in the limit build the generated samples of
any ergodic source of entropy rate below an $h_0$ with probability one and
whose cardinality grows at most at exponential rate $h_0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0398</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0398</id><created>2011-05-02</created><authors><author><keyname>Buchin</keyname><forenames>Kevin</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author><author><keyname>N&#xf6;llenburg</keyname><forenames>Martin</forenames></author><author><keyname>Silveira</keyname><forenames>Rodrigo I.</forenames></author></authors><title>Adjacency-Preserving Spatial Treemaps</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rectangular layouts, subdivisions of an outer rectangle into smaller
rectangles, have many applications in visualizing spatial information, for
instance in rectangular cartograms in which the rectangles represent geographic
or political regions. A spatial treemap is a rectangular layout with a
hierarchical structure: the outer rectangle is subdivided into rectangles that
are in turn subdivided into smaller rectangles. We describe algorithms for
transforming a rectangular layout that does not have this hierarchical
structure, together with a clustering of the rectangles of the layout, into a
spatial treemap that respects the clustering and also respects to the extent
possible the adjacencies of the input layout.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0401</identifier>
 <datestamp>2011-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0401</id><created>2011-05-02</created><authors><author><keyname>Cheng</keyname><forenames>Wenchi</forenames></author><author><keyname>Zhang</keyname><forenames>Xi</forenames></author><author><keyname>Zhang</keyname><forenames>Hailin</forenames></author><author><keyname>Wang</keyname><forenames>Qiang</forenames></author></authors><title>On-Demand Based Wireless Resources Trading for Green Communications</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of Green Communications is to reduce the energy consumption of
the communication system as much as possible without compromising the quality
of service (QoS) for users. An effective approach for Green Wireless
Communications is On-Demand strategy, which scales power consumption with the
volume and location of user demand. Applying the On-Demand Communications
model, we propose a novel scheme -- Wireless Resource Trading, which
characterizes the trading relationship among different wireless resources for a
given number of performance metrics. According to wireless resource trading
relationship, different wireless resources can be consumed for the same set of
performance metrics. Therefore, to minimize the energy consumption for given
performance metrics, we can trade the other type of wireless resources for the
energy resource under the demanded performance metrics. Based on the wireless
resource trading relationship, we derive the optimal energy-bandwidth and
energy-time wireless resource trading relationship for green wireless
communications. We also develop an adaptive trading strategy by using different
bandwidths or different delays for different transmission distances with
available bandwidths and acceptable delay bounds in wireless networks. Our
conducted simulations show that the energy consumption of wireless networks can
be significantly reduced with our proposed wireless resources trading scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0417</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0417</id><created>2011-05-02</created><authors><author><keyname>Ross</keyname><forenames>Kevin</forenames></author><author><keyname>Bambos</keyname><forenames>Nicholas</forenames></author><author><keyname>Michailidis</keyname><forenames>George</forenames></author></authors><title>Cone Schedules for Processing Systems in Fluctuating Environments</title><categories>cs.NI cs.SY math.OC</categories><comments>25 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a generalized processing system having several queues, where the
available service rate combinations are fluctuating over time due to
reliability and availability variations. The objective is to allocate the
available resources, and corresponding service rates, in response to both
workload and service capacity considerations, in order to maintain the long
term stability of the system. The service configurations are completely
arbitrary, including negative service rates which represent forwarding and
service-induced cross traffic. We employ a trace-based trajectory asymptotic
technique, which requires minimal assumptions about the arrival dynamics of the
system.
  We prove that cone schedules, which leverage the geometry of the queueing
dynamics, maximize the system throughput for a broad class of processing
systems, even under adversarial arrival processes. We study the impact of
fluctuating service availability, where resources are available only some of
the time, and the schedule must dynamically respond to the changing available
service rates, establishing both the capacity of such systems and the class of
schedules which will stabilize the system at full capacity. The rich geometry
of the system dynamics leads to important insights for stability, performance
and scalability, and substantially generalizes previous findings.
  The processing system studied here models a broad variety of computer,
communication and service networks, including varying channel conditions and
cross-traffic in wireless networking, and call centers with fluctuating
capacity. The findings have implications for bandwidth and processor allocation
in communication networks and workforce scheduling in congested call centers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0433</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0433</id><created>2011-05-02</created><authors><author><keyname>Ananth</keyname><forenames>Prabhanjan</forenames></author><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author></authors><title>On Gr\&quot;obner Basis Detection for Zero-dimensional Ideals</title><categories>cs.CC</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gr\&quot;obner basis detection (GBD) is defined as follows: Given a set of
polynomials, decide whether there exists -and if &quot;yes&quot; find- a term order such
that the set of polynomials is a Gr\&quot;obner basis. This problem was shown to be
NP-hard by Sturmfels and Wiegelmann. We show that GBD when studied in the
context of zero dimensional ideals is also NP-hard. An algorithm to solve GBD
for zero dimensional ideals is also proposed which runs in polynomial time if
the number of indeterminates is a constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0438</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0438</id><created>2011-05-02</created><authors><author><keyname>Reinhard</keyname><forenames>Vincent</forenames></author><author><keyname>Cohen</keyname><forenames>Johanne</forenames></author><author><keyname>Tomasik</keyname><forenames>Joanna</forenames></author><author><keyname>Barth</keyname><forenames>Dominique</forenames></author><author><keyname>Weisser</keyname><forenames>Marc-Antoine</forenames></author></authors><title>Performance improvement of an optical network providing services based
  on multicast</title><categories>cs.DC cs.DM</categories><comments>16 pages, 13 figures, extended version from Conference ISCIS 2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Operators of networks covering large areas are confronted with demands from
some of their customers who are virtual service providers. These providers may
call for the connectivity service which fulfils the specificity of their
services, for instance a multicast transition with allocated bandwidth. On the
other hand, network operators want to make profit by trading the connectivity
service of requested quality to their customers and to limit their
infrastructure investments (or do not invest anything at all).
  We focus on circuit switching optical networks and work on repetitive
multicast demands whose source and destinations are {\em \`a priori} known by
an operator. He may therefore have corresponding trees &quot;ready to be allocated&quot;
and adapt his network infrastructure according to these recurrent
transmissions. This adjustment consists in setting available branching routers
in the selected nodes of a predefined tree. The branching nodes are
opto-electronic nodes which are able to duplicate data and retransmit it in
several directions. These nodes are, however, more expensive and more energy
consuming than transparent ones.
  In this paper we are interested in the choice of nodes of a multicast tree
where the limited number of branching routers should be located in order to
minimize the amount of required bandwidth. After formally stating the problem
we solve it by proposing a polynomial algorithm whose optimality we prove. We
perform exhaustive computations to show an operator gain obtained by using our
algorithm. These computations are made for different methods of the multicast
tree construction. We conclude by giving dimensioning guidelines and outline
our further work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0442</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0442</id><created>2011-05-02</created><authors><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Wang</keyname><forenames>Meng</forenames></author><author><keyname>Tang</keyname><forenames>Ao</forenames></author></authors><title>On State Estimation with Bad Data Detection</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of state estimation through
observations possibly corrupted with both bad data and additive observation
noises. A mixed $\ell_1$ and $\ell_2$ convex programming is used to separate
both sparse bad data and additive noises from the observations. Through using
the almost Euclidean property for a linear subspace, we derive a new
performance bound for the state estimation error under sparse bad data and
additive observation noises. Our main contribution is to provide sharp bounds
on the almost Euclidean property of a linear subspace, using the
&quot;escape-through-a-mesh&quot; theorem from geometric functional analysis. We also
propose and numerically evaluate an iterative convex programming approach to
performing bad data detections in nonlinear electrical power networks problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0452</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0452</id><created>2011-05-02</created><updated>2011-08-11</updated><authors><author><keyname>Pappas</keyname><forenames>Nikolaos</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author><author><keyname>Traganitis</keyname><forenames>Apostolos</forenames></author></authors><title>Relay-Assisted Multiple Access with Multi-Packet Reception Capability
  and Simultaneous Transmission and Reception</title><categories>cs.IT math.IT</categories><comments>A shorter version accepted for publication at IEEE Information Theory
  Workshop 2011. This version has all the proofs omitted in the conference
  version due to space limitations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we examine the operation of a node relaying packets from a
number of users to a destination node. We assume multi-packet reception
capabilities for the relay and the destination node. The relay node can
transmit and receive at the same time, so the problem of self interference
arises. The relay does not have packets of its own and the traffic at the
source nodes is considered saturated. The relay node stores a source packet
that it receives successfully in its queue when the transmission to the
destination node has failed. We obtain analytical expressions for the
characteristics of the relay's queue (such as arrival and service rate of the
relay's queue), the stability condition and the average length of the queue as
functions of the probabilities of transmissions, the self interference
coefficient and the outage probabilities of the links. We study the impact of
the relay node and the self interference coefficient on the throughput per
user-source as well as the aggregate throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0464</identifier>
 <datestamp>2012-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0464</id><created>2011-05-02</created><updated>2012-04-03</updated><authors><author><keyname>Boutsidis</keyname><forenames>Christos</forenames></author></authors><title>Improved Low-rank Matrix Decompositions via the Subsampled Randomized
  Hadamard Transform</title><categories>cs.DS</categories><comments>This paper has been withdrawn; an updated study is available by
  Boutsidis and Gittens: http://arxiv.org/abs/1204.0062</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We comment on two randomized algorithms for constructing low-rank matrix
decompositions. Both algorithms employ the Subsampled Randomized Hadamard
Transform [14]. The first algorithm appeared recently in [9]; here, we provide
a novel analysis that significantly improves the approximation bound obtained
in [9]. A preliminary version of the second algorithm appeared in [7]; here, we
present a mild modification of this algorithm that achieves the same
approximation bound but significantly improves the corresponding running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0469</identifier>
 <datestamp>2012-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0469</id><created>2011-05-02</created><updated>2012-01-18</updated><authors><author><keyname>Radicchi</keyname><forenames>Filippo</forenames></author><author><keyname>Baronchelli</keyname><forenames>Andrea</forenames></author><author><keyname>Amaral</keyname><forenames>Luis A. N.</forenames></author></authors><title>Rationality, irrationality and escalating behavior in lowest unique bid
  auctions</title><categories>physics.soc-ph cs.SI</categories><comments>36 pages, 30 figures, 5 tables</comments><journal-ref>PloS ONE 7, e29910 (2012)</journal-ref><doi>10.1371/journal.pone.0029910</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information technology has revolutionized the traditional structure of
markets. The removal of geographical and time constraints has fostered the
growth of online auction markets, which now include millions of economic agents
worldwide and annual transaction volumes in the billions of dollars. Here, we
analyze bid histories of a little studied type of online auctions --- lowest
unique bid auctions. Similarly to what has been reported for foraging animals
searching for scarce food, we find that agents adopt Levy flight search
strategies in their exploration of &quot;bid space&quot;. The Levy regime, which is
characterized by a power-law decaying probability distribution of step lengths,
holds over nearly three orders of magnitude. We develop a quantitative model
for lowest unique bid online auctions that reveals that agents use nearly
optimal bidding strategies. However, agents participating in these auctions do
not optimize their financial gain. Indeed, as long as there are many auction
participants, a rational profit optimizing agent would choose not to
participate in these auction markets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0471</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0471</id><created>2011-05-02</created><authors><author><keyname>Karasuyama</keyname><forenames>Masayuki</forenames></author><author><keyname>Takeuchi</keyname><forenames>Ichiro</forenames></author></authors><title>Suboptimal Solution Path Algorithm for Support Vector Machine</title><categories>cs.LG</categories><comments>A shorter version of this paper is submitted to ICML 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a suboptimal solution path algorithm for the Support Vector
Machine. The solution path algorithm is an effective tool for solving a
sequence of a parametrized optimization problems in machine learning. The path
of the solutions provided by this algorithm are very accurate and they satisfy
the optimality conditions more strictly than other SVM optimization algorithms.
In many machine learning application, however, this strict optimality is often
unnecessary, and it adversely affects the computational efficiency. Our
algorithm can generate the path of suboptimal solutions within an arbitrary
user-specified tolerance level. It allows us to control the trade-off between
the accuracy of the solution and the computational cost. Moreover, We also show
that our suboptimal solutions can be interpreted as the solution of a
\emph{perturbed optimization problem} from the original one. We provide some
theoretical analyses of our algorithm based on this novel interpretation. The
experimental results also demonstrate the effectiveness of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0473</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0473</id><created>2011-05-02</created><authors><author><keyname>Hu</keyname><forenames>Donglin</forenames></author><author><keyname>Mao</keyname><forenames>Shiwen</forenames></author></authors><title>A Sensing Error Aware MAC Protocol for Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>21 page, technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radios (CR) are intelligent radio devices that can sense the radio
environment and adapt to changes in the radio environment. Spectrum sensing and
spectrum access are the two key CR functions. In this paper, we present a
spectrum sensing error aware MAC protocol for a CR network collocated with
multiple primary networks. We explicitly consider both types of sensing errors
in the CR MAC design, since such errors are inevitable for practical spectrum
sensors and more important, such errors could have significant impact on the
performance of the CR MAC protocol. Two spectrum sensing polices are presented,
with which secondary users collaboratively sense the licensed channels. The
sensing policies are then incorporated into p-Persistent CSMA to coordinate
opportunistic spectrum access for CR network users. We present an analysis of
the interference and throughput performance of the proposed CR MAC, and find
the analysis highly accurate in our simulation studies. The proposed sensing
error aware CR MAC protocol outperforms two existing approaches with
considerable margins in our simulations, which justify the importance of
considering spectrum sensing errors in CR MAC design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0474</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0474</id><created>2011-05-03</created><authors><author><keyname>Kiwi</keyname><forenames>Marcos</forenames></author><author><keyname>Soto</keyname><forenames>Jos&#xe9; A.</forenames></author></authors><title>Generalizations and Variants of the Largest Non-crossing Matching
  Problem in Random Bipartite Graphs</title><categories>math.CO cs.DM</categories><comments>32 pages, 5 figures</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are interested in the statistics of the length of the longest increasing
subsequence of 2-rowed lexicographically sorted arrays chosen according to
distinct families of distributions D = (D_n)_n, and when n goes to infinity.
This framework encompasses well studied problems such as the so called Longest
Increasing Subsequence problem, the Longest Common Subsequence problem,
problems concerning directed bond percolation models, among others. We define
several natural families of distinct distributions and characterize the
asymptotic behavior of the expected length of a longest increasing subsequence
chosen according to them. In particular, we consider generalizations to d-rowed
arrays as well as symmetry restricted two-rowed arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0476</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0476</id><created>2011-05-03</created><authors><author><keyname>Huang</keyname><forenames>Yingsong</forenames></author><author><keyname>Mao</keyname><forenames>Shiwen</forenames></author><author><keyname>Li</keyname><forenames>Yihan</forenames></author></authors><title>Downlink Power Allocation for Stored Variable-Bit-Rate Videos</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problem of power allocation for streaming
multiple variable-bit-rate (VBR) videos in the downlink of a cellular network.
We consider a deterministic model for VBR video traffic and finite playout
buffer at the mobile users. The objective is to derive the optimal downlink
power allocation for the VBR video sessions, such that the video data can be
delivered in a timely fashion without causing playout buffer overflow and
underflow. The formulated problem is a nonlinear nonconvex optimization
problem. We analyze the convexity conditions for the formulated problem and
propose a two-step greedy approach to solve the problem. We also develop a
distributed algorithm based on the dual decomposition technique. The
performance of the proposed algorithms are validated with simulations using VBR
video traces under realistic scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0477</identifier>
 <datestamp>2012-05-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0477</id><created>2011-05-03</created><updated>2012-04-30</updated><authors><author><keyname>Lin</keyname><forenames>Bingkai</forenames></author><author><keyname>Chen</keyname><forenames>Yijia</forenames></author></authors><title>The parameterized complexity of k-edge induced subgraphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that finding a $k$-edge induced subgraph is fixed-parameter
tractable, thereby answering an open problem of Leizhen Cai. Our algorithm is
based on several combinatorial observations, Gauss' famous \emph{Eureka}
theorem [Andrews, 86], and a generalization of the well-known fpt-algorithm for
the model-checking problem for first-order logic on graphs with locally bounded
tree-width due to Frick and Grohe [Frick and Grohe, 01]. On the other hand, we
show that two natural counting versions of the problem are hard. Hence, the
$k$-edge induced subgraph problem is one of the rare known examples in
parameterized complexity that are easy for decision while hard for counting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0479</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0479</id><created>2011-05-03</created><authors><author><keyname>Vaya</keyname><forenames>Shailesh</forenames></author></authors><title>Faster Gossiping in Bidirectional Radio Networks with Large Labels</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider unknown ad-hoc radio networks, when the underlying network is
bidirectional and nodes can have polynomially large labels. For this model, we
present a deterministic protocol for gossiping which takes $O(n \lg^2 n \lg \lg
n)$ rounds. This improves upon the previous best result for deterministic
gossiping for this model by [Gasienec, Potapov, Pagourtizis, Deterministic
Gossiping in Radio Networks with Large labels, ESA (2002)], who present a
protocol of round complexity $O(n \lg^3 n \lg \lg n)$ for this problem. This
resolves open problem posed in [Gasienec, Efficient gossiping in radio
networks, SIROCCO (2009)], who cite bridging gap between lower and upper bounds
for this problem as an important objective. We emphasize that a salient feature
of our protocol is its simplicity, especially with respect to the previous best
known protocol for this problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0491</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0491</id><created>2011-05-03</created><authors><author><keyname>Gael</keyname><forenames>Le Bellego</forenames><affiliation>TIMC</affiliation></author><author><keyname>Bucki</keyname><forenames>Marek</forenames><affiliation>TIMC</affiliation></author><author><keyname>Bricault</keyname><forenames>Ivan</forenames><affiliation>TIMC</affiliation></author><author><keyname>Troccaz</keyname><forenames>Jocelyne</forenames><affiliation>TIMC</affiliation></author></authors><title>Using a smart phone for information rendering in Computer-Aided Surgery</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>Human-Computer Interaction International 2011, HCII'2011, Orlando
  : United States (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer-aided surgery intensively uses the concept of navigation: after
having collected CT data from a patient and transferred them to the operating
room coordinate system, the surgical instrument (a puncture needle for
instance) is localized and its position is visualized with respect to the
patient organs which are not directly visible. This approach is very similar to
the GPS paradigm. Traditionally, three orthogonal slices in the patient data
are presented on a distant screen. Sometimes a 3D representation is also added.
In this study we evaluated the potential of adding a smart phone as a
man-machine interaction device. Different experiments involving operators
puncturing a phantom are reported in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0510</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0510</id><created>2011-05-03</created><authors><author><keyname>Chebotarev</keyname><forenames>P. Yu.</forenames></author><author><keyname>Loginov</keyname><forenames>A. K.</forenames></author><author><keyname>Tsodikova</keyname><forenames>Ya. Yu.</forenames></author><author><keyname>Lezina</keyname><forenames>Z. M.</forenames></author><author><keyname>Borzenko</keyname><forenames>V. I.</forenames></author></authors><title>Voting in a Stochastic Environment: The Case of Two Groups</title><categories>cs.MA cs.SI cs.SY math.OC physics.soc-ph</categories><comments>11 pages, 4 figures. A preliminary version of a journal paper</comments><msc-class>91B12, 91B70</msc-class><journal-ref>Automation and Remote Control 72 (2011), No. 7, 1537-1547</journal-ref><doi>10.1134/S0005117911070198</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social dynamics determined by voting in a stochastic environment is analyzed
for a society composed of two cohesive groups of similar size. Within the model
of random walks determined by voting, explicit formulas are derived for the
capital increments of the groups against the parameters of the environment and
&quot;claim thresholds&quot; of the groups. The &quot;unanimous acceptance&quot; and &quot;unanimous
rejection&quot; group rules are considered as the voting procedures. Claim
thresholds are evaluated that are most beneficial to the participants of the
groups and to the society as a whole.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0515</identifier>
 <datestamp>2012-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0515</id><created>2011-05-03</created><updated>2012-12-09</updated><authors><author><keyname>Sohn</keyname><forenames>Yunkyu</forenames></author><author><keyname>Choi</keyname><forenames>Jung-Kyoo</forenames></author><author><keyname>Ahn</keyname><forenames>T. K.</forenames></author></authors><title>Core-Periphery Segregation in Evolving Prisoner's Dilemma Networks</title><categories>q-bio.PE cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dense cooperative networks are an essential element of social capital for a
prosperous society. These networks enable individuals to overcome collective
action dilemmas by enhancing trust. In many biological and social settings,
network structures evolve endogenously as agents exit relationships and build
new ones. However, the process by which evolutionary dynamics lead to
self-organization of dense cooperative networks has not been explored. Our
large group prisoner's dilemma experiments with exit and partner choice options
show that core-periphery segregation of cooperators and defectors drives the
emergence of cooperation. Cooperators' Quit-for-Tat and defectors' Roving
strategy lead to a highly asymmetric core and periphery structure. Densely
connected to each other, cooperators successfully isolate defectors and earn
larger payoffs than defectors. Our analysis of the topological characteristics
of evolving networks illuminates how social capital is generated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0540</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0540</id><created>2011-05-03</created><updated>2011-05-05</updated><authors><author><keyname>Kpotufe</keyname><forenames>Samory</forenames></author><author><keyname>von Luxburg</keyname><forenames>Ulrike</forenames></author></authors><title>Pruning nearest neighbor cluster trees</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nearest neighbor (k-NN) graphs are widely used in machine learning and data
mining applications, and our aim is to better understand what they reveal about
the cluster structure of the unknown underlying distribution of points.
Moreover, is it possible to identify spurious structures that might arise due
to sampling variability?
  Our first contribution is a statistical analysis that reveals how certain
subgraphs of a k-NN graph form a consistent estimator of the cluster tree of
the underlying distribution of points. Our second and perhaps most important
contribution is the following finite sample guarantee. We carefully work out
the tradeoff between aggressive and conservative pruning and are able to
guarantee the removal of all spurious cluster structures at all levels of the
tree while at the same time guaranteeing the recovery of salient clusters. This
is the first such finite sample result in the context of clustering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0545</identifier>
 <datestamp>2013-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0545</id><created>2011-05-03</created><updated>2013-01-08</updated><authors><author><keyname>Ferretti</keyname><forenames>Stefano</forenames></author></authors><title>On the Degree Distribution of Faulty Peer-to-Peer Overlays</title><categories>cs.DC</categories><comments>A revised version is published in ICST Transactions on Complex
  Systems, ICST, Vol.12, 1-20, 2012,
  http://eudl.eu/doi/10.4108/trans.comsys.2012.10-12.e2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an analytical framework to model fault-tolerance in
unstructured peer-to-peer overlays, represented as complex networks. We define
a distributed protocol peers execute for managing the overlay and reacting to
node faults. Based on the protocol, evolution equations are defined and
manipulated by resorting to generating functions. Obtained outcomes provide
insights on the nodes' degree probability distribution. From the study of the
degree distribution, it is possible to estimate other important metrics of the
peer-to-peer overlay, such as the diameter of the network. We study different
networks, characterized by three specific desired degree distributions, i.e.
nets with nodes having a fixed desired degree, random graphs and scale-free
networks. All these networks are assessed via the analytical tool and
simulation as well. Results show that the approach can be factually employed to
dynamically tune the average attachment rate at peers so that they maintain
their own desired degree and, in general, the desired network topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0548</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0548</id><created>2011-05-03</created><authors><author><keyname>Rabe</keyname><forenames>Florian</forenames></author><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author></authors><title>A Scalable Module System</title><categories>cs.LO</categories><comments>This is a preprint of the main paper on the MMT language</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symbolic and logic computation systems ranging from computer algebra systems
to theorem provers are finding their way into science, technology, mathematics
and engineering. But such systems rely on explicitly or implicitly represented
mathematical knowledge that needs to be managed to use such systems
effectively.
  While mathematical knowledge management (MKM) &quot;in the small&quot; is well-studied,
scaling up to large, highly interconnected corpora remains difficult. We hold
that in order to realize MKM &quot;in the large&quot;, we need representation languages
and software architectures that are designed systematically with large-scale
processing in mind.
  Therefore, we have designed and implemented the MMT language -- a module
system for mathematical theories. MMT is designed as the simplest possible
language that combines a module system, a foundationally uncommitted formal
semantics, and web-scalable implementations. Due to a careful choice of
representational primitives, MMT allows us to integrate existing representation
languages for formal mathematical knowledge in a simple, scalable formalism. In
particular, MMT abstracts from the underlying mathematical and logical
foundations so that it can serve as a standardized representation format for a
formal digital library. Moreover, MMT systematically separates logic-dependent
and logic-independent concerns so that it can serve as an interface layer
between computation systems and MKM systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0558</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0558</id><created>2011-05-03</created><authors><author><keyname>Tagiew</keyname><forenames>Rustam</forenames></author></authors><title>If more than Analytical Modeling is Needed to Predict Real Agents'
  Strategic Interaction</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the research on the interdisciplinary research
infrastructure for understanding human reasoning in game-theoretic terms.
Strategic reasoning is considered to impact human decision making in social,
economical and competitive interactions. The provided introduction explains and
connects concepts from AI, game theory and psychology. First result is a
concept of interdisciplinary game description language as a part of the focused
interdisciplinary research infrastructure. The need of this domain-specific
language is motivated and is aimed to accelerate the current developments. As
second result, the paper provides a summary of ongoing research and its
significance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0569</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0569</id><created>2011-05-03</created><authors><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Random Beamforming over Correlated Fading Channels</title><categories>cs.IT math.IT</categories><comments>35 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a multiple-input multiple-output (MIMO) multiple access channel
(MAC) from several multi-antenna transmitters to a multi-antenna receiver. The
fading channels between the transmitters and the receiver are modeled by random
matrices, composed of independent column vectors with zero mean and different
covariance matrices. Each transmitter is assumed to send multiple data streams
with a random precoding matrix extracted from a Haar-distributed matrix. For
this general channel model, we derive deterministic approximations of the
normalized mutual information, the normalized sum-rate with
minimum-mean-square-error (MMSE) detection and the
signal-to-interference-plus-noise-ratio (SINR) of the MMSE decoder, which
become arbitrarily tight as all system parameters grow infinitely large at the
same speed. In addition, we derive the asymptotically optimal power allocation
under individual or sum-power constraints. Our results allow us to tackle the
problem of optimal stream control in interference channels which would be
intractable in any finite setting. Numerical results corroborate our analysis
and verify its accuracy for realistic system dimensions. Moreover, the
techniques applied in this paper constitute a novel contribution to the field
of large random matrix theory and could be used to study even more involved
channel models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0608</identifier>
 <datestamp>2012-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0608</id><created>2011-05-03</created><authors><author><keyname>Wu</keyname><forenames>Bang Ye</forenames></author></authors><title>A simpler and more efficient algorithm for the next-to-shortest path
  problem</title><categories>cs.DS</categories><comments>Partial result appeared in COCOA2010</comments><doi>10.1007/s00453-011-9601-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an undirected graph $G=(V,E)$ with positive edge lengths and two
vertices $s$ and $t$, the next-to-shortest path problem is to find an $st$-path
which length is minimum amongst all $st$-paths strictly longer than the
shortest path length. In this paper we show that the problem can be solved in
linear time if the distances from $s$ and $t$ to all other vertices are given.
Particularly our new algorithm runs in $O(|V|\log |V|+|E|)$ time for general
graphs, which improves the previous result of $O(|V|^2)$ time for sparse
graphs, and takes only linear time for unweighted graphs, planar graphs, and
graphs with positive integer edge lengths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0611</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0611</id><created>2011-05-03</created><authors><author><keyname>Baratchart</keyname><forenames>Laurent</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Enqvist</keyname><forenames>Per</forenames><affiliation>KTH</affiliation></author><author><keyname>Gombani</keyname><forenames>Andrea</forenames><affiliation>ISIB - CNR</affiliation></author><author><keyname>Olivi</keyname><forenames>Martine</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Minimal symmetric Darlington synthesis</title><categories>math.OC cs.SY</categories><proxy>ccsd</proxy><journal-ref>Math. Control Signals Syst. 19 (2007) 283-311</journal-ref><doi>10.1007/s00498-007-0020-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the symmetric Darlington synthesis of a p x p rational symmetric
Schur function S with the constraint that the extension is of size 2p x 2p.
Under the assumption that S is strictly contractive in at least one point of
the imaginary axis, we determine the minimal McMillan degree of the extension.
In particular, we show that it is generically given by the number of zeros of
odd multiplicity of I-SS*. A constructive characterization of all such
extensions is provided in terms of a symmetric realization of S and of the
outer spectral factor of I-SS*. The authors's motivation for the problem stems
from Surface Acoustic Wave filters where physical constraints on the
electro-acoustic scattering matrix naturally raise this mathematical issue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0624</identifier>
 <datestamp>2012-03-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0624</id><created>2011-05-03</created><updated>2012-03-27</updated><authors><author><keyname>Neigenfind</keyname><forenames>Jost</forenames></author><author><keyname>Grimbs</keyname><forenames>Sergio</forenames></author><author><keyname>Nikoloski</keyname><forenames>Zoran</forenames></author></authors><title>Biochemical network decomposition reveals absolute concentration
  robustness</title><categories>q-bio.MN cs.DS math.AC math.CA math.CO math.DS</categories><comments>46 pages, 13 figures, 2 tables, 93 equations This paper has been
  withdrawn by the author due to complete rework</comments><msc-class>92C42 (Primary) 93C15, 13P25, 68R10, 34A30 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robustness of biochemical systems has become one of the central questions in
Systems Biology, although it is notoriously difficult to formally capture its
multifaceted nature. Maintenance of normal system function depends not only on
the stoichiometry of the underlying interrelated components, but also on a
multitude of kinetic parameters. For given parameter values, recent findings
have aimed at characterizing the property of the system components to exhibit
same concentrations in the resulting steady states, termed absolute
concentration robustness (ACR). However, the existing method for determining
system components exhibiting ACR is applicable only to one class of mass-action
networks for which this property can be confirmed, but not discarded. Here we
design a new method which relies on biochemical network decompositions into
subnetworks, called elementary flux modes, to identify ACR in a broader class
of mass-action networks by using only the given stoichiometry. This approach
reduces the problem of determining ACR to that of solving parameterized systems
of linear equations, rendering it amenable to networks of larger sizes. Our
unified framework will be helpful in analyzing this biologically important type
of robustness as well as detection of novel systemic properties independent of
the kinetic parameters for more complex biochemical networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0638</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0638</id><created>2011-05-03</created><authors><author><keyname>Chen</keyname><forenames>Xiaojun</forenames></author><author><keyname>Ge</keyname><forenames>Dongdong</forenames></author><author><keyname>Wang</keyname><forenames>Zizhuo</forenames></author><author><keyname>Ye</keyname><forenames>Yinyu</forenames></author></authors><title>Complexity of Unconstrained L_2-L_p Minimization</title><categories>cs.CC stat.CO</categories><msc-class>90C26, 90C51</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the unconstrained $L_2$-$L_p$ minimization: find a minimizer of
$\|Ax-b\|^2_2+\lambda \|x\|^p_p$ for given $A \in R^{m\times n}$, $b\in R^m$
and parameters $\lambda&gt;0$, $p\in [0,1)$. This problem has been studied
extensively in variable selection and sparse least squares fitting for high
dimensional data. Theoretical results show that the minimizers of the
$L_2$-$L_p$ problem have various attractive features due to the concavity and
non-Lipschitzian property of the regularization function $\|\cdot\|^p_p$. In
this paper, we show that the $L_q$-$L_p$ minimization problem is strongly
NP-hard for any $p\in [0,1)$ and $q\ge 1$, including its smoothed version. On
the other hand, we show that, by choosing parameters $(p,\lambda)$ carefully, a
minimizer, global or local, will have certain desired sparsity. We believe that
these results provide new theoretical insights to the studies and applications
of the concave regularized optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0649</identifier>
 <datestamp>2013-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0649</id><created>2011-05-03</created><updated>2012-08-11</updated><authors><author><keyname>Houshmand</keyname><forenames>Monireh</forenames></author><author><keyname>Hosseini-Khayat</keyname><forenames>Saied</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Minimal-memory, non-catastrophic, polynomial-depth quantum convolutional
  encoders</title><categories>quant-ph cs.IT math.IT</categories><comments>Continuation and expansion of arXiv:1011.5535; 21 pages, 2 figures;
  v2 includes an elementary proof that the encoders in this paper are
  non-recursive in addition to being non-catastrophic; v3, accepted into IEEE
  Transactions on Information Theory</comments><journal-ref>IEEE Transactions on Information Theory vol. 59, no. 2, pages
  1198-1210 (February 2013)</journal-ref><doi>10.1109/TIT.2012.2220520</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum convolutional coding is a technique for encoding a stream of quantum
information before transmitting it over a noisy quantum channel. Two important
goals in the design of quantum convolutional encoders are to minimize the
memory required by them and to avoid the catastrophic propagation of errors. In
a previous paper, we determined minimal-memory, non-catastrophic,
polynomial-depth encoders for a few exemplary quantum convolutional codes. In
this paper, we elucidate a general technique for finding an encoder of an
arbitrary quantum convolutional code such that the encoder possesses these
desirable properties. We also provide an elementary proof that these encoders
are non-recursive. Finally, we apply our technique to many quantum
convolutional codes from the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0650</identifier>
 <datestamp>2014-10-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0650</id><created>2011-05-03</created><authors><author><keyname>Lierler</keyname><forenames>Yuliya</forenames></author><author><keyname>Truszczynski</keyname><forenames>Miroslaw</forenames></author></authors><title>Transition Systems for Model Generators - A Unifying Approach</title><categories>cs.AI</categories><comments>30 pages; Accepted for presentation at ICLP 2011 and for publication
  in Theory and Practice of Logic Programming; contains the appendix with
  proofs</comments><acm-class>D.1.16; I.2.8</acm-class><journal-ref>Theory and Practice of Logic Programming, volume 11, issue 4-5, pp
  629 - 646, 2011</journal-ref><doi>10.1017/S1471068411000214</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental task for propositional logic is to compute models of
propositional formulas. Programs developed for this task are called
satisfiability solvers. We show that transition systems introduced by
Nieuwenhuis, Oliveras, and Tinelli to model and analyze satisfiability solvers
can be adapted for solvers developed for two other propositional formalisms:
logic programming under the answer-set semantics, and the logic PC(ID). We show
that in each case the task of computing models can be seen as &quot;satisfiability
modulo answer-set programming,&quot; where the goal is to find a model of a theory
that also is an answer set of a certain program. The unifying perspective we
develop shows, in particular, that solvers CLASP and MINISATID are closely
related despite being developed for different formalisms, one for answer-set
programming and the latter for the logic PC(ID).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0653</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0653</id><created>2011-05-03</created><authors><author><keyname>Schneider</keyname><forenames>Christoph</forenames></author><author><keyname>Wehler</keyname><forenames>Joachim</forenames></author></authors><title>Model Checking of Boolean Process Models</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the field of Business Process Management formal models for the control
flow of business processes have been designed since more than 15 years. Which
methods are best suited to verify the bulk of these models? The first step is
to select a formal language which fixes the semantics of the models. We adopt
the language of Boolean systems as reference language for Boolean process
models. Boolean systems form a simple subclass of coloured Petri nets. Their
characteristics are low tokens to model explicitly states with a subsequent
skipping of activations and arbitrary logical rules of type AND, XOR, OR etc.
to model the split and join of the control flow. We apply model checking as a
verification method for the safeness and liveness of Boolean systems. Model
checking of Boolean systems uses the elementary theory of propositional logic,
no modal operators are needed. Our verification builds on a finite complete
prefix of a certain T-system attached to the Boolean system. It splits the
processes of the Boolean system into a finite set of base processes of bounded
length. Their behaviour translates to formulas from propositional logic. Our
verification task consists in checking the satisfiability of these formulas. In
addition we have implemented our model checking algorithm as a java program.
The time needed to verify a given Boolean system depends critically on the
number of initial tokens. Because the algorithm has to solve certain
SAT-problems, polynomial complexity cannot be expected. The paper closes with
the model checking of some Boolean process models which have been designed as
Event-driven Process Chains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0661</identifier>
 <datestamp>2011-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0661</id><created>2011-05-03</created><authors><author><keyname>Mol</keyname><forenames>Jan David</forenames></author><author><keyname>Romein</keyname><forenames>John W.</forenames></author></authors><title>The LOFAR Beam Former: Implementation and Performance Analysis</title><categories>cs.DC astro-ph.IM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional radio telescopes use large, steel dishes to observe radio
sources. The LOFAR radio telescope is different, and uses tens of thousands of
fixed, non-movable antennas instead, a novel design that promises
ground-breaking research in astronomy. The antennas observe omnidirectionally,
and sky sources are observed by signal-processing techniques that combine the
data from all antennas.
  Another new feature of LOFAR is the elaborate use of software to do signal
processing in real time, where traditional telescopes use custom-built
hardware. The use of software leads to an instrument that is inherently more
flexible. However, the enormous data rate (198 Gb/s of input data) and
processing requirements compel the use of a supercomputer: we use an IBM Blue
Gene/P.
  This paper presents a collection of new processing pipelines, collectively
called the beam-forming pipelines, that greatly enhance the functionality of
the telescope. Where our first pipeline could only correlate data to create sky
images, the new pipelines allow the discovery of unknown pulsars, observations
of known pulsars, and (in the future), to observe cosmic rays and study
transient events. Unlike traditional telescopes, we can observe in hundreds of
directions simultaneously. This is useful, for example, to search the sky for
new pulsars. The use of software allows us to quickly add new functionality and
to adapt to new insights that fully exploit the novel features and the power of
our unique instrument. We also describe our optimisations to use the Blue
Gene/P at very high efficiencies, maximising the effectiveness of the entire
telescope. A thorough performance study identifies the limits of our system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0668</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0668</id><created>2011-05-03</created><updated>2011-05-05</updated><authors><author><keyname>Mandal</keyname><forenames>Partha Sarathi</forenames></author><author><keyname>Ghosh</keyname><forenames>Anil K.</forenames></author></authors><title>Secure Position Verification for Wireless Sensor Networks in Noisy
  Channels</title><categories>cs.DC</categories><comments>16 pages, The paper has been accepted for presentation at the 10th
  International Conference on Ad Hoc Networks and Wireless (ADHOC NOW 2011)
  July 18-20, 2011, Paderborn, Germany</comments><msc-class>DS, DC</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Position verification in wireless sensor networks (WSNs) is quite tricky in
presence of attackers (malicious sensor nodes), who try to break the
verification protocol by reporting their incorrect positions (locations) during
the verification stage. In the literature of WSNs, most of the existing methods
of position verification have used trusted verifiers, which are in fact
vulnerable to attacks by malicious nodes. They also depend on some distance
estimation techniques, which are not accurate in noisy channels (mediums). In
this article, we propose a secure position verification scheme for WSNs in
noisy channels without relying on any trusted entities. Our verification scheme
detects and filters out all malicious nodes from the network with very high
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0673</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0673</id><created>2011-05-03</created><authors><author><keyname>Danescu-Niculescu-Mizil</keyname><forenames>Cristian</forenames></author><author><keyname>Gamon</keyname><forenames>Michael</forenames></author><author><keyname>Dumais</keyname><forenames>Susan</forenames></author></authors><title>Mark My Words! Linguistic Style Accommodation in Social Media</title><categories>cs.CL cs.SI</categories><comments>Talk slides available at http://www.cs.cornell.edu/~cristian/www2011</comments><journal-ref>Proceedings of WWW, pp. 141--150, 2009</journal-ref><doi>10.1145/1963405.1963509</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The psycholinguistic theory of communication accommodation accounts for the
general observation that participants in conversations tend to converge to one
another's communicative behavior: they coordinate in a variety of dimensions
including choice of words, syntax, utterance length, pitch and gestures. In its
almost forty years of existence, this theory has been empirically supported
exclusively through small-scale or controlled laboratory studies. Here we
address this phenomenon in the context of Twitter conversations. Undoubtedly,
this setting is unlike any other in which accommodation was observed and, thus,
challenging to the theory. Its novelty comes not only from its size, but also
from the non real-time nature of conversations, from the 140 character length
restriction, from the wide variety of social relation types, and from a design
that was initially not geared towards conversation at all. Given such
constraints, it is not clear a priori whether accommodation is robust enough to
occur given the constraints of this new environment. To investigate this, we
develop a probabilistic framework that can model accommodation and measure its
effects. We apply it to a large Twitter conversational dataset specifically
developed for this task. This is the first time the hypothesis of linguistic
style accommodation has been examined (and verified) in a large scale, real
world setting. Furthermore, when investigating concepts such as stylistic
influence and symmetry of accommodation, we discover a complexity of the
phenomenon which was never observed before. We also explore the potential
relation between stylistic influence and network features commonly associated
with social status.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0697</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0697</id><created>2011-05-03</created><authors><author><keyname>Rodriguez</keyname><forenames>Manuel Gomez</forenames></author><author><keyname>Balduzzi</keyname><forenames>David</forenames></author><author><keyname>Sch&#xf6;lkopf</keyname><forenames>Bernhard</forenames></author></authors><title>Uncovering the Temporal Dynamics of Diffusion Networks</title><categories>cs.SI cs.DS cs.IR physics.soc-ph</categories><comments>To appear in the 28th International Conference on Machine Learning
  (ICML), 2011. Website: http://www.stanford.edu/~manuelgr/netrate/</comments><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time plays an essential role in the diffusion of information, influence and
disease over networks. In many cases we only observe when a node copies
information, makes a decision or becomes infected -- but the connectivity,
transmission rates between nodes and transmission sources are unknown.
Inferring the underlying dynamics is of outstanding interest since it enables
forecasting, influencing and retarding infections, broadly construed. To this
end, we model diffusion processes as discrete networks of continuous temporal
processes occurring at different rates. Given cascade data -- observed
infection times of nodes -- we infer the edges of the global diffusion network
and estimate the transmission rates of each edge that best explain the observed
data. The optimization problem is convex. The model naturally (without
heuristics) imposes sparse solutions and requires no parameter tuning. The
problem decouples into a collection of independent smaller problems, thus
scaling easily to networks on the order of hundreds of thousands of nodes.
Experiments on real and synthetic data show that our algorithm both recovers
the edges of diffusion networks and accurately estimates their transmission
rates from cascade data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0699</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0699</id><created>2011-05-03</created><authors><author><keyname>Zahedi</keyname><forenames>Morteza</forenames></author><author><keyname>Manashty</keyname><forenames>Ali Reza</forenames></author></authors><title>Robust Sign Language Recognition System Using ToF Depth Cameras</title><categories>cs.MM</categories><comments>6 Pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT), Vol. 1, No. 3, 50-55, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sign language recognition is a difficult task, yet required for many
applications in real-time speed. Using RGB cameras for recognition of sign
languages is not very successful in practical situations and accurate 3D
imaging requires expensive and complex instruments. With introduction of
Time-of-Flight (ToF) depth cameras in recent years, it has become easier to
scan the environment for accurate, yet fast depth images of the objects without
the need of any extra calibrating object. In this paper, a robust system for
sign language recognition using ToF depth cameras is presented for converting
the recorded signs to a standard and portable XML sign language named SiGML for
easy transferring and converting to real-time 3D virtual characters animations.
Feature extraction using moments and classification using nearest neighbor
classifier are used to track hand gestures and significant result of 100% is
achieved for the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0703</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0703</id><created>2011-05-03</created><updated>2012-06-07</updated><authors><author><keyname>Zhang</keyname><forenames>Xiaojie</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Adaptive Cut Generation Algorithm for Improved Linear Programming
  Decoding of Binary Linear Codes</title><categories>cs.IT math.IT</categories><doi>10.1109/TIT.2012.2204955</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear programming (LP) decoding approximates maximum-likelihood (ML)
decoding of a linear block code by relaxing the equivalent ML integer
programming (IP) problem into a more easily solved LP problem. The LP problem
is defined by a set of box constraints together with a set of linear
inequalities called &quot;parity inequalities&quot; that are derived from the constraints
represented by the rows of a parity-check matrix of the code and can be added
iteratively and adaptively. In this paper, we first derive a new necessary
condition and a new sufficient condition for a violated parity inequality
constraint, or &quot;cut,&quot; at a point in the unit hypercube. Then, we propose a new
and effective algorithm to generate parity inequalities derived from certain
additional redundant parity check (RPC) constraints that can eliminate
pseudocodewords produced by the LP decoder, often significantly improving the
decoder error-rate performance. The cut-generating algorithm is based upon a
specific transformation of an initial parity-check matrix of the linear block
code. We also design two variations of the proposed decoder to make it more
efficient when it is combined with the new cut-generating algorithm. Simulation
results for several low-density parity-check (LDPC) codes demonstrate that the
proposed decoding algorithms significantly narrow the performance gap between
LP decoding and ML decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0706</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0706</id><created>2011-05-03</created><updated>2013-03-14</updated><authors><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Turner</keyname><forenames>D. Z.</forenames></author></authors><title>A mixed formulation for a modification to Darcy equation based on Picard
  linearization and numerical solutions to large-scale realistic problems</title><categories>cs.NA math.NA</categories><comments>The earlier versions of this paper on arXiv were under the title: &quot;A
  mixed formulation for a modification to Darcy equation with applications to
  enhanced oil recovery and carbon-dioxide sequestration.&quot; The title has
  changed at the suggestion of a journal reviewer, as the new title better
  reflects the main contributions of this paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a modification to Darcy equation by taking into
account the dependence of viscosity on the pressure. We present a stabilized
mixed formulation for the resulting governing equations. Equal-order
interpolation for the velocity and pressure is considered, and shown to be
stable (which is not the case under the classical mixed formulation). The
proposed mixed formulation is tested using a wide variety of numerical
examples. The proposed formulation is also implemented in a parallel setting,
and the performance of the formulation for large-scale problems is illustrated
using a representative problem. Two practical and technologically important
problems, one each on enhanced oil recovery and geological carbon-dioxide
sequestration, are solved using the proposed formulation. The numerical
examples show that the predictions based on Darcy model are qualitatively and
quantitatively different from that of the predictions based on the modified
Darcy model, which takes into account the dependence of the viscosity on the
pressure. In particular, the numerical example on the geological carbon-dioxide
sequestration shows that Darcy model over-predicts the leakage into an
abandoned well when compared to that of the modified Darcy model. On the other
hand, the modified Darcy model predicts higher pressures and higher pressure
gradients near the injection well. These predictions have dire consequences in
predicting damage and fracture zones, and designing the seal, whose integrity
is crucial to the safety of a geological carbon-dioxide sequestration
geosystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0707</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0707</id><created>2011-05-03</created><authors><author><keyname>Chitnis</keyname><forenames>Rajesh</forenames></author><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author><author><keyname>Liaghat</keyname><forenames>Vahid</forenames></author></authors><title>Parameterized Complexity of Problems in Coalitional Resource Games</title><categories>cs.AI cs.CC cs.GT</categories><comments>This is the full version of a paper that will appear in the
  proceedings of AAAI 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coalition formation is a key topic in multi-agent systems. Coalitions enable
agents to achieve goals that they may not have been able to achieve on their
own. Previous work has shown problems in coalitional games to be
computationally hard. Wooldridge and Dunne (Artificial Intelligence 2006)
studied the classical computational complexity of several natural decision
problems in Coalitional Resource Games (CRG) - games in which each agent is
endowed with a set of resources and coalitions can bring about a set of goals
if they are collectively endowed with the necessary amount of resources. The
input of coalitional resource games bundles together several elements, e.g.,
the agent set Ag, the goal set G, the resource set R, etc. Shrot, Aumann and
Kraus (AAMAS 2009) examine coalition formation problems in the CRG model using
the theory of Parameterized Complexity. Their refined analysis shows that not
all parts of input act equal - some instances of the problem are indeed
tractable while others still remain intractable.
  We answer an important question left open by Shrot, Aumann and Kraus by
showing that the SC Problem (checking whether a Coalition is Successful) is
W[1]-hard when parameterized by the size of the coalition. Then via a single
theme of reduction from SC, we are able to show that various problems related
to resources, resource bounds and resource conflicts introduced by Wooldridge
et al are 1. W[1]-hard or co-W[1]-hard when parameterized by the size of the
coalition. 2. para-NP-hard or co-para-NP-hard when parameterized by |R|. 3. FPT
when parameterized by either |G| or |Ag|+|R|.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0709</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0709</id><created>2011-05-03</created><authors><author><keyname>Boutsidis</keyname><forenames>Christos</forenames></author></authors><title>Topics in Matrix Sampling Algorithms</title><categories>cs.DS</categories><comments>PhD Thesis, 150 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study three fundamental problems of Linear Algebra, lying in the heart of
various Machine Learning applications, namely: 1)&quot;Low-rank Column-based Matrix
Approximation&quot;. We are given a matrix A and a target rank k. The goal is to
select a subset of columns of A and, by using only these columns, compute a
rank k approximation to A that is as good as the rank k approximation that
would have been obtained by using all the columns; 2) &quot;Coreset Construction in
Least-Squares Regression&quot;. We are given a matrix A and a vector b. Consider the
(over-constrained) least-squares problem of minimizing ||Ax-b||, over all
vectors x in D. The domain D represents the constraints on the solution and can
be arbitrary. The goal is to select a subset of the rows of A and b and, by
using only these rows, find a solution vector that is as good as the solution
vector that would have been obtained by using all the rows; 3) &quot;Feature
Selection in K-means Clustering&quot;. We are given a set of points described with
respect to a large number of features. The goal is to select a subset of the
features and, by using only this subset, obtain a k-partition of the points
that is as good as the partition that would have been obtained by using all the
features. We present novel algorithms for all three problems mentioned above.
Our results can be viewed as follow-up research to a line of work known as
&quot;Matrix Sampling Algorithms&quot;. [Frieze, Kanna, Vempala, 1998] presented the
first such algorithm for the Low-rank Matrix Approximation problem. Since then,
such algorithms have been developed for several other problems, e.g. Graph
Sparsification and Linear Equation Solving. Our contributions to this line of
research are: (i) improved algorithms for Low-rank Matrix Approximation and
Regression (ii) algorithms for a new problem domain (K-means Clustering).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0725</identifier>
 <datestamp>2011-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0725</id><created>2011-05-03</created><updated>2011-06-09</updated><authors><author><keyname>Zhang</keyname><forenames>Zhilin</forenames></author><author><keyname>Rao</keyname><forenames>Bhaskar D.</forenames></author></authors><title>Exploiting Correlation in Sparse Signal Recovery Problems: Multiple
  Measurement Vectors, Block Sparsity, and Time-Varying Sparsity</title><categories>stat.CO cs.IT math.IT stat.ML</categories><comments>Extended abstract for ICML 2011 Structured Sparsity: Learning and
  Inference Workshop. Experiment codes can be downloaded from:
  http://dsp.ucsd.edu/~zhilin/papers/ICMLworkshop_code.zip</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A trend in compressed sensing (CS) is to exploit structure for improved
reconstruction performance. In the basic CS model, exploiting the clustering
structure among nonzero elements in the solution vector has drawn much
attention, and many algorithms have been proposed. However, few algorithms
explicitly consider correlation within a cluster. Meanwhile, in the multiple
measurement vector (MMV) model correlation among multiple solution vectors is
largely ignored. Although several recently developed algorithms consider the
exploitation of the correlation, these algorithms need to know a priori the
correlation structure, thus limiting their effectiveness in practical problems.
  Recently, we developed a sparse Bayesian learning (SBL) algorithm, namely
T-SBL, and its variants, which adaptively learn the correlation structure and
exploit such correlation information to significantly improve reconstruction
performance. Here we establish their connections to other popular algorithms,
such as the group Lasso, iterative reweighted $\ell_1$ and $\ell_2$ algorithms,
and algorithms for time-varying sparsity. We also provide strategies to improve
these existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0728</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0728</id><created>2011-05-03</created><updated>2011-12-14</updated><authors><author><keyname>Qin</keyname><forenames>Zhiwei</forenames></author><author><keyname>Goldfarb</keyname><forenames>Donald</forenames></author></authors><title>Structured Sparsity via Alternating Direction Methods</title><categories>math.OC cs.AI stat.ML</categories><journal-ref>Journal of Machine Learning Research 13 (2012) 1435-1468</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of sparse learning problems in high dimensional feature
space regularized by a structured sparsity-inducing norm which incorporates
prior knowledge of the group structure of the features. Such problems often
pose a considerable challenge to optimization algorithms due to the
non-smoothness and non-separability of the regularization term. In this paper,
we focus on two commonly adopted sparsity-inducing regularization terms, the
overlapping Group Lasso penalty $l_1/l_2$-norm and the $l_1/l_\infty$-norm. We
propose a unified framework based on the augmented Lagrangian method, under
which problems with both types of regularization and their variants can be
efficiently solved. As the core building-block of this framework, we develop
new algorithms using an alternating partial-linearization/splitting technique,
and we prove that the accelerated versions of these algorithms require
$O(\frac{1}{\sqrt{\epsilon}})$ iterations to obtain an $\epsilon$-optimal
solution. To demonstrate the efficiency and relevance of our algorithms, we
test them on a collection of data sets and apply them to two real-world
problems to compare the relative merits of the two norms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0738</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0738</id><created>2011-05-04</created><authors><author><keyname>Son</keyname><forenames>Kyuho</forenames></author><author><keyname>Lee</keyname><forenames>Soohwan</forenames></author><author><keyname>Yi</keyname><forenames>Yung</forenames></author><author><keyname>Chong</keyname><forenames>Song</forenames></author></authors><title>REFIM: A Practical Interference Management in Heterogeneous Wireless
  Access Networks</title><categories>cs.NI</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the increasing demand of capacity in wireless cellular networks, the
small cells such as pico and femto cells are becoming more popular to enjoy a
spatial reuse gain, and thus cells with different sizes are expected to coexist
in a complex manner. In such a heterogeneous environment, the role of
interference management (IM) becomes of more importance, but technical
challenges also increase, since the number of cell-edge users, suffering from
severe interference from the neighboring cells, will naturally grow. In order
to overcome low performance and/or high complexity of existing static and other
dynamic IM algorithms, we propose a novel low-complex and fully distributed IM
scheme, called REFIM, in the downlink of heterogeneous multi-cell networks. We
first formulate a general optimization problem that turns out to require
intractable computation complexity for global optimality. To have a practical
solution with low computational and signaling overhead, which is crucial for
low-cost small-cell solutions, e.g., femto cells, in REFIM, we decompose it
into per-BS problems based on the notion of reference user and reduce feedback
overhead over backhauls both temporally and spatially. We evaluate REFIM
through extensive simulations under various configurations, including the
scenarios from a real deployment of BSs. We show that, compared to the schemes
without IM, REFIM can yield more than 40% throughput improvement of cell-edge
users while increasing the overall performance by 10~107%. This is equal to
about 95% performance of the existing centralized IM algorithm that is known to
be near-optimal but hard to implement in practice due to prohibitive
complexity. We also present that as long as interference is managed well, the
spectrum sharing policy can outperform the best spectrum splitting policy where
the number of subchannels is optimally divided between macro and femto cells.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0745</identifier>
 <datestamp>2012-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0745</id><created>2011-05-04</created><updated>2012-10-19</updated><authors><author><keyname>Bouchard</keyname><forenames>Bruno</forenames></author><author><keyname>Nutz</keyname><forenames>Marcel</forenames></author></authors><title>Weak Dynamic Programming for Generalized State Constraints</title><categories>math.OC cs.SY math.AP math.PR q-fin.RM</categories><comments>36 pages;forthcoming in 'SIAM Journal on Control and Optimization'</comments><msc-class>93E20, 49L20, 49L25, 35K55</msc-class><journal-ref>SIAM Journal on Control and Optimization, Vol. 50, No. 6, pp.
  3344-3373, 2012</journal-ref><doi>10.1137/110852942</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a dynamic programming principle for stochastic optimal control
problems with expectation constraints. A weak formulation, using test functions
and a probabilistic relaxation of the constraint, avoids restrictions related
to a measurable selection but still implies the Hamilton-Jacobi-Bellman
equation in the viscosity sense. We treat open state constraints as a special
case of expectation constraints and prove a comparison theorem to obtain the
equation for closed state constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0755</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0755</id><created>2011-05-04</created><authors><author><keyname>Yun</keyname><forenames>Hyokun</forenames></author></authors><title>Using Logistic Regression to Analyze the Balance of a Game: The Case of
  StarCraft II</title><categories>stat.AP cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, the market size of online game has been increasing astonishingly
fast, and so does the importance of good game design. In online games, usually
a human user competes with others, so the fairness of the game system to all
users is of great importance not to lose interests of users on the game.
Furthermore, the emergence and success of electronic sports (e-sports) and
professional gaming which specially talented gamers compete with others draws
more attention on whether they are competing in the fair environment. No matter
how fierce the debates are in the game-design community, it is rarely the case
that one employs statistical analysis to answer this question seriously. But
considering the fact that we can easily gather large amount of user behavior
data on games, it seems potentially beneficial to make use of this data to aid
making decisions on design problems of games. Actually, modern games do not aim
to perfectly design the game at once: rather, they first release the game, and
then monitor users' behavior to better balance the game. In such a scenario,
statistical analysis can be particularly helpful. Specifically, we chose to
analyze the balance of StarCraft II, which is a very successful
recently-released real-time strategy (RTS) game. It is a central icon in
current e-Sports and professional gaming community: from April 1st to 15th,
there were 18 tournaments of StarCraft II. However, there is endless debate on
whether the winner of the tournament is actually superior to others, or it is
largely due to certain design flaws of the game. In this paper, we aim to
answer such a question using traditional statistical tool, logistic regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0768</identifier>
 <datestamp>2012-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0768</id><created>2011-05-04</created><updated>2012-06-26</updated><authors><author><keyname>Nordio</keyname><forenames>Martin</forenames></author><author><keyname>Estler</keyname><forenames>H. -Christian</forenames></author><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author></authors><title>Collaborative Software Development on the Web</title><categories>cs.SE</categories><comments>15 pages, 5 figures</comments><acm-class>D.2.9; D.2.4; D.2.5; I.7.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software development environments (IDEs) have not followed the IT industry's
inexorable trend towards distribution. They do too little to address the
problems raised by today's increasingly distributed projects; neither do they
facilitate collaborative and interactive development practices. A consequence
is the continued reliance of today's IDEs on paradigms such as traditional
configuration management, which were developed for earlier modes of operation
and hamper collaborative projects. This contribution describes a new paradigm:
cloud-based development, which caters to the specific needs of distributed and
collaborative projects. The CloudStudio IDE embodies this paradigm by enabling
developers to work on a shared project repository. Configuration management
becomes unobtrusive; it replaces the explicit update-modify-commit cycle by
interactive editing and real-time conflict tracking and management. A case
study involving three teams of pairs demonstrates the usability of CloudStudio
and its advantages for collaborative software development over traditional
configuration management practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0769</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0769</id><created>2011-05-04</created><authors><author><keyname>Tauboeck</keyname><forenames>Georg</forenames></author></authors><title>Complex-Valued Random Vectors and Channels: Entropy, Divergence, and
  Capacity</title><categories>cs.IT math.IT</categories><comments>33 pages, 1 figure, slightly modified version of first paper revision
  submitted to IEEE Trans. Inf. Theory on October 31, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent research has demonstrated significant achievable performance gains by
exploiting circularity/non-circularity or propeness/improperness of
complex-valued signals. In this paper, we investigate the influence of these
properties on important information theoretic quantities such as entropy,
divergence, and capacity. We prove two maximum entropy theorems that strengthen
previously known results. The proof of the former theorem is based on the
so-called circular analog of a given complex-valued random vector. Its
introduction is supported by a characterization theorem that employs a minimum
Kullback-Leibler divergence criterion. In the proof of latter theorem, on the
other hand, results about the second-order structure of complex-valued random
vectors are exploited. Furthermore, we address the capacity of multiple-input
multiple-output (MIMO) channels. Regardless of the specific distribution of the
channel parameters (noise vector and channel matrix, if modeled as random), we
show that the capacity-achieving input vector is circular for a broad range of
MIMO channels (including coherent and noncoherent scenarios). Finally, we
investigate the situation of an improper and Gaussian distributed noise vector.
We compute both capacity and capacity-achieving input vector and show that
improperness increases capacity, provided that the complementary covariance
matrix is exploited. Otherwise, a capacity loss occurs, for which we derive an
explicit expression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0785</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0785</id><created>2011-05-04</created><authors><author><keyname>Hassani</keyname><forenames>S. Hamed</forenames></author><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author></authors><title>Coupled Graphical Models and Their Thresholds</title><categories>cs.IT cond-mat.stat-mech cs.DM math.IT</categories><comments>In proceedings of ITW 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The excellent performance of convolutional low-density parity-check codes is
the result of the spatial coupling of individual underlying codes across a
window of growing size, but much smaller than the length of the individual
codes. Remarkably, the belief-propagation threshold of the coupled ensemble is
boosted to the maximum-a-posteriori one of the individual system. We
investigate the generality of this phenomenon beyond coding theory: we couple
general graphical models into a one-dimensional chain of large individual
systems. For the later we take the Curie-Weiss, random field Curie-Weiss,
$K$-satisfiability, and $Q$-coloring models. We always find, based on
analytical as well as numerical calculations, that the message passing
thresholds of the coupled systems come very close to the static ones of the
individual models. The remarkable properties of convolutional low-density
parity-check codes are a manifestation of this very general phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0791</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0791</id><created>2011-05-04</created><authors><author><keyname>Chambers</keyname><forenames>Erin Wolf</forenames></author><author><keyname>Fekete</keyname><forenames>S&#xe1;ndor P.</forenames></author><author><keyname>Hoffmann</keyname><forenames>Hella-Franziska</forenames></author><author><keyname>Marinakis</keyname><forenames>Dimitri</forenames></author><author><keyname>Mitchell</keyname><forenames>Joseph S. B.</forenames></author><author><keyname>Srinivasan</keyname><forenames>Venkatesh</forenames></author><author><keyname>Stege</keyname><forenames>Ulrike</forenames></author><author><keyname>Whitesides</keyname><forenames>Sue</forenames></author></authors><title>Connecting a Set of Circles with Minimum Sum of Radii</title><categories>cs.CG cs.DS</categories><comments>14 pages, 8 figures, conference version to appear in Proceedings of
  the 12th Algorithms and Data Structures Symposium (WADS 2011)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of assigning radii to a given set of points in the
plane, such that the resulting set of circles is connected, and the sum of
radii is minimized. We show that the problem is polynomially solvable if a
connectivity tree is given. If the connectivity tree is unknown, the problem is
NP-hard if there are upper bounds on the radii and open otherwise. We give
approximation guarantees for a variety of polynomial-time algorithms, describe
upper and lower bounds (which are matching in some of the cases), provide
polynomial-time approximation schemes, and conclude with experimental results
and open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0796</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0796</id><created>2011-05-04</created><updated>2012-01-11</updated><authors><author><keyname>Cioaba</keyname><forenames>Sebastian M.</forenames></author><author><keyname>Kim</keyname><forenames>Kijung</forenames></author><author><keyname>Koolen</keyname><forenames>Jack H.</forenames></author></authors><title>On a conjecture of Brouwer involving the connectivity of strongly
  regular graphs</title><categories>math.CO cs.DM</categories><comments>25 pages, 1 table; accepted to JCTA; revised version contains a new
  section on copolar and Delta spaces</comments><msc-class>05E30, 05C40, 05C50, 51E14, 51E12, 15A18</msc-class><doi>10.1016/j.jcta.2012.01.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study a conjecture of Andries E. Brouwer from 1996
regarding the minimum number of vertices of a strongly regular graph whose
removal disconnects the graph into non-singleton components.
  We show that strongly regular graphs constructed from copolar spaces and from
the more general spaces called $\Delta$-spaces are counterexamples to Brouwer's
Conjecture. Using J.I. Hall's characterization of finite reduced copolar
spaces, we find that the triangular graphs $T(m)$, the symplectic graphs
$Sp(2r,q)$ over the field $\mathbb{F}_q$ (for any $q$ prime power), and the
strongly regular graphs constructed from the hyperbolic quadrics $O^{+}(2r,2)$
and from the elliptic quadrics $O^{-}(2r,2)$ over the field $\mathbb{F}_2$,
respectively, are counterexamples to Brouwer's Conjecture. For each of these
graphs, we determine precisely the minimum number of vertices whose removal
disconnects the graph into non-singleton components. While we are not aware of
an analogue of Hall's characterization theorem for $\Delta$-spaces, we show
that complements of the point graphs of certain finite generalized quadrangles
are point graphs of $\Delta$-spaces and thus, yield other counterexamples to
Brouwer's Conjecture.
  We prove that Brouwer's Conjecture is true for many families of strongly
regular graphs including the conference graphs, the generalized quadrangles
$GQ(q,q)$ graphs, the lattice graphs, the Latin square graphs, the strongly
regular graphs with smallest eigenvalue -2 (except the triangular graphs) and
the primitive strongly regular graphs with at most 30 vertices except for few
cases.
  We leave as an open problem determining the best general lower bound for the
minimum size of a disconnecting set of vertices of a strongly regular graph,
whose removal disconnects the graph into non-singleton components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0807</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0807</id><created>2011-05-04</created><updated>2011-12-20</updated><authors><author><keyname>Hassani</keyname><forenames>S. Hamed</forenames></author><author><keyname>Macris</keyname><forenames>Nicolas</forenames></author><author><keyname>Urbanke</keyname><forenames>Ruediger</forenames></author></authors><title>Chains of Mean Field Models</title><categories>cs.DM cond-mat.stat-mech cs.IT math.IT</categories><doi>10.1088/1742-5468/2012/02/P02011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a collection of Curie-Weiss (CW) spin systems, possibly with a
random field, each of which is placed along the positions of a one-dimensional
chain. The CW systems are coupled together by a Kac-type interaction in the
longitudinal direction of the chain and by an infinite range interaction in the
direction transverse to the chain. Our motivations for studying this model come
from recent findings in the theory of error correcting codes based on spatially
coupled graphs. We find that, although much simpler than the codes, the model
studied here already displays similar behaviors. We are interested in the van
der Waals curve in a regime where the size of each Curie-Weiss model tends to
infinity, and the length of the chain and range of the Kac interaction are
large but finite. Below the critical temperature, and with appropriate boundary
conditions, there appears a series of equilibrium states representing kink-like
interfaces between the two equilibrium states of the individual system. The van
der Waals curve oscillates periodically around the Maxwell plateau. These
oscillations have a period inversely proportional to the chain length and an
amplitude exponentially small in the range of the interaction; in other words
the spinodal points of the chain model lie exponentially close to the phase
transition threshold. The amplitude of the oscillations is closely related to a
Peierls-Nabarro free energy barrier for the motion of the kink along the chain.
Analogies to similar phenomena and their possible algorithmic significance for
graphical models of interest in coding theory and theoretical computer science
are pointed out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0812</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0812</id><created>2011-05-04</created><updated>2012-02-02</updated><authors><author><keyname>Esquivel</keyname><forenames>Alcides Viamontes</forenames></author><author><keyname>Rosvall</keyname><forenames>Martin</forenames></author></authors><title>Compression of Flow Can Reveal Overlapping-Module Organization in
  Networks</title><categories>physics.soc-ph cs.IT cs.SI math.IT</categories><comments>11 pages</comments><journal-ref>Phys. Rev. X 1, 021025 (2011)</journal-ref><doi>10.1103/PhysRevX.1.021025</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  To better understand the overlapping modular organization of large networks
with respect to flow, here we introduce the map equation for overlapping
modules. In this information-theoretic framework, we use the correspondence
between compression and regularity detection. The generalized map equation
measures how well we can compress a description of flow in the network when we
partition it into modules with possible overlaps. When we minimize the
generalized map equation over overlapping network partitions, we detect modules
that capture flow and determine which nodes at the boundaries between modules
should be classified in multiple modules and to what degree. With a novel
greedy search algorithm, we find that some networks, for example, the neural
network of C. Elegans, are best described by modules dominated by hard
boundaries, but that others, for example, the sparse European road network,
have a highly overlapping modular organization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0819</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0819</id><created>2011-04-30</created><updated>2012-02-25</updated><authors><author><keyname>Pigolotti</keyname><forenames>Simone</forenames></author><author><keyname>Bernhardsson</keyname><forenames>Sebastian</forenames></author><author><keyname>Juul</keyname><forenames>Jeppe</forenames></author><author><keyname>Galster</keyname><forenames>Gorm</forenames></author><author><keyname>Vivo</keyname><forenames>Pierpaolo</forenames></author></authors><title>Equilibrium strategy and population-size effects in lowest unique bid
  auctions</title><categories>cs.GT physics.soc-ph q-fin.GN</categories><comments>6 pag. - 7 figs - added Supplementary Material. Changed affiliations.
  Published version</comments><journal-ref>Phys. Rev. Lett. 108, 088701 (2012)</journal-ref><doi>10.1103/PhysRevLett.108.088701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In lowest unique bid auctions, $N$ players bid for an item. The winner is
whoever places the \emph{lowest} bid, provided that it is also unique. We use a
grand canonical approach to derive an analytical expression for the equilibrium
distribution of strategies. We then study the properties of the solution as a
function of the mean number of players, and compare them with a large dataset
of internet auctions. The theory agrees with the data with striking accuracy
for small population size $N$, while for larger $N$ a qualitatively different
distribution is observed. We interpret this result as the emergence of two
different regimes, one in which adaptation is feasible and one in which it is
not. Our results question the actual possibility of a large population to adapt
and find the optimal strategy when participating in a collective game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0821</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0821</id><created>2011-05-04</created><authors><author><keyname>Arsinte</keyname><forenames>Radu</forenames></author><author><keyname>Ilioaei</keyname><forenames>Ciprian</forenames></author></authors><title>Considerations and Results in Multimedia and DVB Application Development
  on Philips Nexperia Platform</title><categories>cs.CV</categories><comments>3 pages, 1 figure</comments><journal-ref>Scientific Bulletin of the &quot;Politehnica&quot; University Timi\c{s}oara,
  Transaction on Electronics and Telecomunications, Tom 49(63), Fascicola 2,
  2004, pag. 138-141</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents some experiments regarding applications development on
high performance media processors included in Philips Nexperia Family. The
PNX1302 dedicated DVB-T kit used has some limitations. Our work has succeeded
to overcome these limitations and to make possible a general-purpose use of
this kit. For exemplification two typical applications, important both for
multimedia and DVB, are analyzed: MPEG2 video stream decoding and MP3 audio
decoding. These original implementations are compared (in speed, memory
requirements and costs) with Philips Nexperia Library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0826</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0826</id><created>2011-05-04</created><authors><author><keyname>Arsinte</keyname><forenames>Radu</forenames></author><author><keyname>Lupu</keyname><forenames>Eugen</forenames></author></authors><title>Streaming Multimedia Information Using the Features of the DVB-S Card</title><categories>cs.MM cs.CV</categories><comments>4 pages, 5 figures</comments><journal-ref>Scientific Bulletin of the &quot;Politehnica&quot; University Timi\c{s}oara,
  Transaction on Electronics and Telecomunications, Tom 51(65), Fascicola 1-2,
  pag. 181-184, 2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a study of audio-video streaming using the additional
possibilities of a DVB-S card. The board used for experiments (Technisat
SkyStar 2) is one of the most frequently used cards for this purpose. Using the
main blocks of the board's software support it is possible the implement a
really useful and full functional system for audio-video streaming. The
streaming is possible to be implemented either for decoded MPEG stream or for
transport stream. In this last case it is possible to view not only a program,
but any program from the same multiplex. This allows us to implement
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0830</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0830</id><created>2011-05-04</created><updated>2011-05-05</updated><authors><author><keyname>Graf</keyname><forenames>Franz</forenames></author><author><keyname>Kriegel</keyname><forenames>Hans-Peter</forenames></author><author><keyname>Schubert</keyname><forenames>Matthias</forenames></author></authors><title>Maximum Gain Round Trips with Cost Constraints</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Searching for optimal ways in a network is an important task in multiple
application areas such as social networks, co-citation graphs or road networks.
In the majority of applications, each edge in a network is associated with a
certain cost and an optimal way minimizes the cost while fulfilling a certain
property, e.g connecting a start and a destination node. In this paper, we want
to extend pure cost networks to so-called cost-gain networks. In this type of
network, each edge is additionally associated with a certain gain. Thus, a way
having a certain cost additionally provides a certain gain. In the following,
we will discuss the problem of finding ways providing maximal gain while
costing less than a certain budget. An application for this type of problem is
the round trip problem of a traveler: Given a certain amount of time, which is
the best round trip traversing the most scenic landscape or visiting the most
important sights? In the following, we distinguish two cases of the problem.
The first does not control any redundant edges and the second allows a more
sophisticated handling of edges occurring more than once. To answer the maximum
round trip queries on a given graph data set, we propose unidirectional and
bidirectional search algorithms. Both types of algorithms are tested for the
use case named above on real world spatial networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0845</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0845</id><created>2011-05-04</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Schnoor</keyname><forenames>Henning</forenames></author></authors><title>A Simplest Undecidable Modal Logic</title><categories>cs.LO cs.CC</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modal logics are widely used in computer science. The complexity of their
satisfiability problems has been an active field of research since the 1970s.
We prove that even very &quot;simple&quot; modal logics can be undecidable: We show that
there is an undecidable modal logic that can be obtained by restricting the
allowed models with a first-order formula in which only universal quantifiers
appear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0857</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0857</id><created>2011-05-04</created><authors><author><keyname>Foster</keyname><forenames>Dean</forenames></author><author><keyname>Kakade</keyname><forenames>Sham</forenames></author><author><keyname>Salakhutdinov</keyname><forenames>Ruslan</forenames></author></authors><title>Domain Adaptation: Overfitting and Small Sample Statistics</title><categories>cs.LG</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the prevalent problem when a test distribution differs from the
training distribution. We consider a setting where our training set consists of
a small number of sample domains, but where we have many samples in each
domain. Our goal is to generalize to a new domain. For example, we may want to
learn a similarity function using only certain classes of objects, but we
desire that this similarity function be applicable to object classes not
present in our training sample (e.g. we might seek to learn that &quot;dogs are
similar to dogs&quot; even though images of dogs were absent from our training set).
Our theoretical analysis shows that we can select many more features than
domains while avoiding overfitting by utilizing data-dependent variance
properties. We present a greedy feature selection algorithm based on using
T-statistics. Our experiments validate this theory showing that our T-statistic
based greedy feature selection is more robust at avoiding overfitting than the
classical greedy procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0881</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0881</id><created>2011-05-04</created><authors><author><keyname>Dai</keyname><forenames>Wanyang</forenames></author></authors><title>A New Class of Backward Stochastic Partial Differential Equations with
  Jumps and Applications</title><categories>math.PR cs.SY math-ph math.AP math.MP math.OC math.ST stat.TH</categories><comments>22 pagea, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We formulate a new class of stochastic partial differential equations
(SPDEs), named high-order vector backward SPDEs (B-SPDEs) with jumps, which
allow the high-order integral-partial differential operators into both drift
and diffusion coefficients. Under certain type of Lipschitz and linear growth
conditions, we develop a method to prove the existence and uniqueness of
adapted solution to these B-SPDEs with jumps. Comparing with the existing
discussions on conventional backward stochastic (ordinary) differential
equations (BSDEs), we need to handle the differentiability of adapted triplet
solution to the B-SPDEs with jumps, which is a subtle part in justifying our
main results due to the inconsistency of differential orders on two sides of
the B-SPDEs and the partial differential operator appeared in the diffusion
coefficient. In addition, we also address the issue about the B-SPDEs under
certain Markovian random environment and employ a B-SPDE with strongly
nonlinear partial differential operator in the drift coefficient to illustrate
the usage of our main results in finance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0902</identifier>
 <datestamp>2011-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0902</id><created>2011-05-04</created><authors><author><keyname>Conway</keyname><forenames>Drew</forenames></author></authors><title>Modeling Network Evolution Using Graph Motifs</title><categories>stat.ME cs.SI physics.soc-ph stat.CO</categories><comments>33 pages, 7 pages, GMM code available at:
  https://github.com/drewconway/GMM</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Network structures are extremely important to the study of political science.
Much of the data in its subfields are naturally represented as networks. This
includes trade, diplomatic and conflict relationships. The social structure of
several organization is also of interest to many researchers, such as the
affiliations of legislators or the relationships among terrorist. A key aspect
of studying social networks is understanding the evolutionary dynamics and the
mechanism by which these structures grow and change over time. While current
methods are well suited to describe static features of networks, they are less
capable of specifying models of change and simulating network evolution. In the
following paper I present a new method for modeling network growth and
evolution. This method relies on graph motifs to generate simulated network
data with particular structural characteristic. This technique departs notably
from current methods both in form and function. Rather than a closed-form
model, or stochastic implementation from a single class of graphs, the proposed
&quot;graph motif model&quot; provides a framework for building flexible and complex
models of network evolution. The paper proceeds as follows: first a brief
review of the current literature on network modeling is provided to place the
graph motif model in context. Next, the graph motif model is introduced, and a
simple example is provided. As a proof of concept, three classic random graph
models are recovered using the graph motif modeling method: the Erdos-Renyi
binomial random graph, the Watts-Strogatz &quot;small world&quot; model, and the
Barabasi-Albert preferential attachment model. In the final section I discuss
the results of these simulations and subsequent advantage and disadvantages
presented by using this technique to model social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0903</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0903</id><created>2011-05-04</created><authors><author><keyname>Byers</keyname><forenames>John W.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Potamias</keyname><forenames>Michalis</forenames></author><author><keyname>Zervas</keyname><forenames>Georgios</forenames></author></authors><title>A Month in the Life of Groupon</title><categories>cs.SI</categories><comments>6 pages</comments><doi>10.1016/j.elerap.2012.11.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Groupon has become the latest Internet sensation, providing daily deals to
customers in the form of discount offers for restaurants, ticketed events,
appliances, services, and other items. We undertake a study of the economics of
daily deals on the web, based on a dataset we compiled by monitoring Groupon
over several weeks. We use our dataset to characterize Groupon deal purchases,
and to glean insights about Groupon's operational strategy. Our focus is on
purchase incentives. For the primary purchase incentive, price, our regression
model indicates that demand for coupons is relatively inelastic, allowing room
for price-based revenue optimization. More interestingly, mining our dataset,
we find evidence that Groupon customers are sensitive to other, &quot;soft&quot;,
incentives, e.g., deal scheduling and duration, deal featuring, and limited
inventory. Our analysis points to the importance of considering incentives
other than price in optimizing deal sites and similar systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0914</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0914</id><created>2011-05-04</created><updated>2011-08-12</updated><authors><author><keyname>Restrepo</keyname><forenames>Ricardo</forenames></author><author><keyname>Shin</keyname><forenames>Jinwoo</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author><author><keyname>Vigoda</keyname><forenames>Eric</forenames></author><author><keyname>Yang</keyname><forenames>Linji</forenames></author></authors><title>Improved Mixing Condition on the Grid for Counting and Sampling
  Independent Sets</title><categories>math.PR cs.DM</categories><comments>Corrected a few small typos in earlier version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the hard-core model defined on independent sets, where each
independent set I in a graph G is weighted proportionally to $\lambda^{|I|}$,
for a positive real parameter $\lambda$. For large $\lambda$, computing the
partition function (namely, the normalizing constant which makes the weighting
a probability distribution on a finite graph) on graphs of maximum degree $D\ge
3$, is a well known computationally challenging problem. More concretely, let
$\lambda_c(T_D)$ denote the critical value for the so-called uniqueness
threshold of the hard-core model on the infinite D-regular tree; recent
breakthrough results of Dror Weitz (2006) and Allan Sly (2010) have identified
$\lambda_c(T_D)$ as a threshold where the hardness of estimating the above
partition function undergoes a computational transition.
  We focus on the well-studied particular case of the square lattice
$\integers^2$, and provide a new lower bound for the uniqueness threshold, in
particular taking it well above $\lambda_c(T_4)$. Our technique refines and
builds on the tree of self-avoiding walks approach of Weitz, resulting in a new
technical sufficient criterion (of wider applicability) for establishing strong
spatial mixing (and hence uniqueness) for the hard-core model. Our new
criterion achieves better bounds on strong spatial mixing when the graph has
extra structure, improving upon what can be achieved by just using the maximum
degree. Applying our technique to $\integers^2$ we prove that strong spatial
mixing holds for all $\lambda&lt;2.3882$, improving upon the work of Weitz that
held for $\lambda&lt;27/16=1.6875$. Our results imply a fully-polynomial
deterministic approximation algorithm for estimating the partition function, as
well as rapid mixing of the associated Glauber dynamics to sample from the
hard-core distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0934</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0934</id><created>2011-05-04</created><authors><author><keyname>Pennanen</keyname><forenames>Teemu</forenames></author><author><keyname>Perkki&#xf6;</keyname><forenames>Ari-Pekka</forenames></author></authors><title>Stochastic programs without duality gaps</title><categories>math.OC cs.SY q-fin.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies dynamic stochastic optimization problems parametrized by a
random variable. Such problems arise in many applications in operations
research and mathematical finance. We give sufficient conditions for the
existence of solutions and the absence of a duality gap. Our proof uses
extended dynamic programming equations, whose validity is established under new
relaxed conditions that generalize certain no-arbitrage conditions from
mathematical finance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0966</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0966</id><created>2011-05-04</created><authors><author><keyname>Turon</keyname><forenames>Aaron</forenames></author><author><keyname>Wand</keyname><forenames>Mitchell</forenames></author></authors><title>A resource analysis of the pi-calculus</title><categories>cs.PL cs.DC</categories><comments>Preliminary version for MFPS 2011</comments><msc-class>68Q55</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new treatment of the pi-calculus based on the semantic theory of
separation logic, continuing a research program begun by Hoare and O'Hearn.
Using a novel resource model that distinguishes between public and private
ownership, we refactor the operational semantics so that sending, receiving,
and allocating are commands that influence owned resources. These ideas lead
naturally to two denotational models: one for safety and one for liveness. Both
models are fully abstract for the corresponding observables, but more
importantly both are very simple. The close connections with the model theory
of separation logic (in particular, with Brookes's action trace model) give
rise to a logic of processes and resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0972</identifier>
 <datestamp>2012-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0972</id><created>2011-05-05</created><authors><author><keyname>Xu</keyname><forenames>Zhixiang Eddie</forenames></author><author><keyname>Weinberger</keyname><forenames>Kilian Q.</forenames></author><author><keyname>Sha</keyname><forenames>Fei</forenames></author></authors><title>Rapid Feature Learning with Stacked Linear Denoisers</title><categories>cs.LG cs.AI stat.ML</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate unsupervised pre-training of deep architectures as feature
generators for &quot;shallow&quot; classifiers. Stacked Denoising Autoencoders (SdA),
when used as feature pre-processing tools for SVM classification, can lead to
significant improvements in accuracy - however, at the price of a substantial
increase in computational cost. In this paper we create a simple algorithm
which mimics the layer by layer training of SdAs. However, in contrast to SdAs,
our algorithm requires no training through gradient descent as the parameters
can be computed in closed-form. It can be implemented in less than 20 lines of
MATLABTMand reduces the computation time from several hours to mere seconds. We
show that our feature transformation reliably improves the results of SVM
classification significantly on all our data sets - often outperforming SdAs
and even deep neural networks in three out of four deep learning benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0974</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0974</id><created>2011-05-05</created><authors><author><keyname>Tabatabaei</keyname><forenames>Seyed Salim</forenames></author><author><keyname>Coates</keyname><forenames>Mark</forenames></author><author><keyname>Rabbat</keyname><forenames>Michael</forenames></author></authors><title>GANC: Greedy Agglomerative Normalized Cut</title><categories>cs.AI</categories><comments>Submitted to Pattern Recognition. 27 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a graph clustering algorithm that aims to minimize the
normalized cut criterion and has a model order selection procedure. The
performance of the proposed algorithm is comparable to spectral approaches in
terms of minimizing normalized cut. However, unlike spectral approaches, the
proposed algorithm scales to graphs with millions of nodes and edges. The
algorithm consists of three components that are processed sequentially: a
greedy agglomerative hierarchical clustering procedure, model order selection,
and a local refinement.
  For a graph of n nodes and O(n) edges, the computational complexity of the
algorithm is O(n log^2 n), a major improvement over the O(n^3) complexity of
spectral methods. Experiments are performed on real and synthetic networks to
demonstrate the scalability of the proposed approach, the effectiveness of the
model order selection procedure, and the performance of the proposed algorithm
in terms of minimizing the normalized cut metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0979</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0979</id><created>2011-05-05</created><updated>2011-10-07</updated><authors><author><keyname>Ananth</keyname><forenames>Prabhanjan</forenames></author><author><keyname>Nasre</keyname><forenames>Meghana</forenames></author><author><keyname>Sarpatwar</keyname><forenames>Kanthi K</forenames></author></authors><title>Hardness and Parameterized Algorithms on Rainbow Connectivity problem</title><categories>cs.DM cs.CC</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A path in an edge colored graph is said to be a rainbow path if no two edges
on the path have the same color. An edge colored graph is (strongly) rainbow
connected if there exists a (geodesic) rainbow path between every pair of
vertices. The (strong) rainbow connectivity of a graph G, denoted by (src(G),
respectively) rc(G) is the smallest number of colors required to edge color the
graph such that G is (strongly) rainbow connected. In this paper we study the
rainbow connectivity problem and the strong rainbow connectivity problem from a
computational point of view. Our main results can be summarised as below:
  1) For every fixed k &gt;= 3, it is NP-Complete to decide whether src(G) &lt;= k
even when the graph G is bipartite.
  2) For every fixed odd k &gt;= 3, it is NP-Complete to decide whether rc(G) &lt;=
k. This resolves one of the open problems posed by Chakraborty et al. (J. Comb.
Opt., 2011) where they prove the hardness for the even case.
  3) The following problem is fixed parameter tractable: Given a graph G,
determine the maximum number of pairs of vertices that can be rainbow connected
using two colors.
  4) For a directed graph G, it is NP-Complete to decide whether rc(G) &lt;= 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0985</identifier>
 <datestamp>2012-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0985</id><created>2011-05-05</created><authors><author><keyname>Glass</keyname><forenames>Olivier</forenames><affiliation>CEREMADE</affiliation></author><author><keyname>Han-Kwan</keyname><forenames>Daniel</forenames><affiliation>DMA</affiliation></author></authors><title>On the controllability of the Vlasov-Poisson system in the presence of
  external force fields</title><categories>math.AP cs.SY math.OC</categories><proxy>ccsd</proxy><journal-ref>Journal of Differential Equations (2012) Volume 252, Issue 10,
  Pages 5453-5491</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we are interested in the controllability of Vlasov-Poisson
systems in the presence of an external force field (namely a bounded force
field or a magnetic field), by means of a local interior control. We are able
to extend the results of [7], where the only present force was the
self-consistent electric field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.0991</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.0991</id><created>2011-05-05</created><authors><author><keyname>Zhu</keyname><forenames>Qiang</forenames></author><author><keyname>Wang</keyname><forenames>Xinke</forenames></author><author><keyname>Ren</keyname><forenames>Juanjuan</forenames></author></authors><title>Extra connectivity measures of 3-ary n-cubes</title><categories>cs.DM cs.DC</categories><comments>10 pages, 2 figures</comments><msc-class>05CXX</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The h-extra connectivity is an important parameter to measure the reliability
and fault tolerance ability of large interconnection networks. The k-ary n-cube
is an important interconnection network of parallel computing systems. The
1-restricted connectivity of k-ary n-cubes has been obtained by Chen et al. for
k &gt; 3 in [Y.-C. Chen, J. J. M. Tan, Restricted connectivity for three families
of interconnection networks, Applied Mathematics and Computation 188 (2)
(2007)1848--1855]. Nevertheless, the h-extra connectivity of 3-ary n-cubes has
not been obtained yet. In this paper we prove that the 1-extra connectivity of
a 3-ary n-cube is 4n-3 for n&gt; 1 and the 2-extra connectivity of 3-ary n-cube is
6n-7 for n&gt; 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1014</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1014</id><created>2011-05-05</created><authors><author><keyname>Martina</keyname><forenames>Maurizio</forenames></author><author><keyname>Masera</keyname><forenames>Guido</forenames></author></authors><title>Improving Network-on-Chip-based turbo decoder architectures</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work novel results concerning Network-on-Chip-based turbo decoder
architectures are presented. Stemming from previous publications, this work
concentrates first on improving the throughput by exploiting adaptive-bandwidth
reduction techniques. This technique shows in the best case an improvement of
more than 60 Mb/s. Moreover, it is known that double-binary turbo decoders
require higher area than binary ones. This characteristic has the negative
effect of increasing the data width of the network nodes. Thus, the second
contribution of this work is to reduce the network complexity to support
doublebinary codes, by exploiting bit-level and pseudo-floating-point
representation of the extrinsic information. These two techniques allow for an
area reduction of up to more than the 40% with a performance degradation of
about 0.2 dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1028</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1028</id><created>2011-05-05</created><authors><author><keyname>Cabibihan</keyname><forenames>John-John</forenames></author></authors><title>Patient-Specific Prosthetic Fingers by Remote Collaboration - A Case
  Study</title><categories>cs.RO physics.med-ph</categories><comments>Open Access article</comments><journal-ref>Public Library of Science, PLoS ONE 6(5):e19508, 2011</journal-ref><doi>10.1371/journal.pone.0019508</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The concealment of amputation through prosthesis usage can shield an amputee
from social stigma and help improve the emotional healing process especially at
the early stages of hand or finger loss. However, the traditional techniques in
prosthesis fabrication defy this as the patients need numerous visits to the
clinics for measurements, fitting and follow-ups. This paper presents a method
for constructing a prosthetic finger through online collaboration with the
designer. The main input from the amputee comes from the Computer Tomography
(CT) data in the region of the affected and the non-affected fingers. These
data are sent over the internet and the prosthesis is constructed using
visualization, computer-aided design and manufacturing tools. The finished
product is then shipped to the patient. A case study with a single patient
having an amputated ring finger at the proximal interphalangeal joint shows
that the proposed method has a potential to address the patient's psychosocial
concerns and minimize the exposure of the finger loss to the public.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1033</identifier>
 <datestamp>2013-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1033</id><created>2011-05-05</created><updated>2011-06-25</updated><authors><author><keyname>Tamuz</keyname><forenames>Omer</forenames></author><author><keyname>Liu</keyname><forenames>Ce</forenames></author><author><keyname>Belongie</keyname><forenames>Serge</forenames></author><author><keyname>Shamir</keyname><forenames>Ohad</forenames></author><author><keyname>Kalai</keyname><forenames>Adam Tauman</forenames></author></authors><title>Adaptively Learning the Crowd Kernel</title><categories>cs.LG</categories><comments>9 pages, 7 figures, Accepted to the 28th International Conference on
  Machine Learning (ICML), 2011</comments><journal-ref>The 28th International Conference on Machine Learning, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an algorithm that, given n objects, learns a similarity matrix
over all n^2 pairs, from crowdsourced data alone. The algorithm samples
responses to adaptively chosen triplet-based relative-similarity queries. Each
query has the form &quot;is object 'a' more similar to 'b' or to 'c'?&quot; and is chosen
to be maximally informative given the preceding responses. The output is an
embedding of the objects into Euclidean space (like MDS); we refer to this as
the &quot;crowd kernel.&quot; SVMs reveal that the crowd kernel captures prominent and
subtle features across a number of domains, such as &quot;is striped&quot; among neckties
and &quot;vowel vs. consonant&quot; among letters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1058</identifier>
 <datestamp>2011-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1058</id><created>2011-05-05</created><updated>2011-05-06</updated><authors><author><keyname>Masucci</keyname><forenames>A. P.</forenames></author></authors><title>Formal vs self-organised knowledge systems: a network approach</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>research paper</comments><journal-ref>Physica A 390 (2011) 4652-4659</journal-ref><doi>10.1016/j.physa.2011.06.074</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we consider the topological analysis of symbolic formal systems
in the framework of network theory. In particular we analyse the network
extracted by Principia Mathematica of B. Russell and A.N. Whitehead, where the
vertices are the statements and two statements are connected with a directed
link if one statement is used to demonstrate the other one. We compare the
obtained network with other directed acyclic graphs, such as a scientific
citation network and a stochastic model. We also introduce a novel topological
ordering for directed acyclic graphs and we discuss its properties in respect
to the classical one. The main result is the observation that formal systems of
knowledge topologically behave similarly to self-organised systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1062</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1062</id><created>2011-05-05</created><updated>2011-10-19</updated><authors><author><keyname>Frahm</keyname><forenames>K. M.</forenames></author><author><keyname>Georgeot</keyname><forenames>B.</forenames></author><author><keyname>Shepelyansky</keyname><forenames>D. L.</forenames></author></authors><title>Universal Emergence of PageRank</title><categories>cs.IR cond-mat.stat-mech nlin.CD</categories><comments>research at http://www.quantware.ups-tlse.fr/ 18 pages, 7 figures
  discussion updates</comments><journal-ref>J. Phys. A: Math. Theor. 44 (2011) 465101</journal-ref><doi>10.1088/1751-8113/44/46/465101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The PageRank algorithm enables to rank the nodes of a network through a
specific eigenvector of the Google matrix, using a damping parameter $\alpha
\in ]0,1[$. Using extensive numerical simulations of large web networks, with a
special accent on British University networks, we determine numerically and
analytically the universal features of PageRank vector at its emergence when
$\alpha \rightarrow 1$. The whole network can be divided into a core part and a
group of invariant subspaces. For $ \alpha \rightarrow 1$ the PageRank
converges to a universal power law distribution on the invariant subspaces
whose size distribution also follows a universal power law. The convergence of
PageRank at $ \alpha \rightarrow 1$ is controlled by eigenvalues of the core
part of the Google matrix which are extremely close to unity leading to large
relaxation times as for example in spin glasses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1071</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1071</id><created>2011-05-05</created><updated>2011-12-18</updated><authors><author><keyname>Yao</keyname><forenames>Andrew C.</forenames></author><author><keyname>Zhao</keyname><forenames>Yunlei</forenames></author></authors><title>A New Family of Practical Non-Malleable Diffie-Hellman Protocols</title><categories>cs.CR cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptography algorithm standards play a key role both to the practice of
information security and to cryptography theory research. Among them, the MQV
and HMQV protocols ((H)MQV, in short) are a family of (implicitly
authenticated) Diffie-Hellman key-exchange (DHKE) protocols that are widely
standardized and deployed. In this work, from some new perspectives and
approaches and under some new design rationales and insights, we develop a new
family of practical implicitly authenticated DHKE protocols, which enjoy
notable performance among security, privacy, efficiency and easy deployment. We
make detailed comparisons between our new DHKE protocols and (H)MQV, showing
that the newly developed protocols outperform HMQV in most aspects. Along the
way, guided by our new design rationales, we also identify a new vulnerability
(H)MQV, which brings some new perspectives (e.g., computational fairness) to
the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1072</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1072</id><created>2011-05-05</created><authors><author><keyname>Barisevi&#x10d;ius</keyname><forenames>G.</forenames></author><author><keyname>Tamulynas</keyname><forenames>B.</forenames></author></authors><title>English-Lithuanian-English Machine Translation lexicon and engine:
  current state and future work</title><categories>cs.CL</categories><journal-ref>Informacin\.{e}s technologijos 2006 : conference proceedings /
  Kaunas University of Technology. T. 1. Kaunas : Technologija, 2006. p.
  109-112</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article overviews the current state of the English-Lithuanian-English
machine translation system. The first part of the article describes the
problems that system poses today and what actions will be taken to solve them
in the future. The second part of the article tackles the main issue of the
translation process. Article briefly overviews the word sense disambiguation
for MT technique using Google.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1074</identifier>
 <datestamp>2012-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1074</id><created>2011-05-05</created><updated>2012-03-21</updated><authors><author><keyname>Thanou</keyname><forenames>Dorina</forenames></author><author><keyname>Kokiopoulou</keyname><forenames>Effrosyni</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Progressive quantization in distributed average consensus</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of distributed average consensus in a sensor network
where sensors exchange quantized information with their neighbors. We propose a
novel quantization scheme that exploits the increasing correlation between the
values exchanged by the sensors throughout the iterations of the consensus
algorithm. A low complexity, uniform quantizer is implemented in each sensor,
and refined quantization is achieved by progressively reducing the quantization
intervals during the convergence of the consensus algorithm. We propose a
recurrence relation for computing the quantization parameters that depend on
the network topology and the communication rate. We further show that the
recurrence relation can lead to a simple exponential model for the size of the
quantization step size over the iterations, whose parameters can be computed a
priori. Finally, simulation results demonstrate the effectiveness of the
progressive quantization scheme that leads to the consensus solution even at
low communication rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1086</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1086</id><created>2011-04-16</created><authors><author><keyname>Upadhyay</keyname><forenames>Sumit Kumar</forenames></author><author><keyname>Kumar</keyname><forenames>Shiv Datt</forenames></author><author><keyname>Lal</keyname><forenames>Ramji</forenames></author></authors><title>Public Key Protocol Based on Amalgamated Free Product</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the spirit of Diffie Hellman the concept of a protocol algebra is
introduced using certain amalgamated free product of Braid group B and Thompson
group T together with a nilpotent subgroup H of index 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1109</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1109</id><created>2011-05-05</created><authors><author><keyname>Habib</keyname><forenames>Michel</forenames></author><author><keyname>To</keyname><forenames>Thu-Hien</forenames></author></authors><title>On a conjecture of compatibility of multi-states characters</title><categories>cs.DS q-bio.PE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perfect phylogeny consisting of determining the compatibility of a set of
characters is known to be NP-complete. We propose in this article a conjecture
on the necessary and sufficient conditions of compatibility: Given a set
$\mathcal{C}$ of $r$-states full characters, there exists a function $f(r)$
such that $\mathcal{C}$ is compatible iff every set of $f(r)$ characters of
$\mathcal{C}$ is compatible. Some previous work showed that $f(2)=2$, $f(3)=3$
and $f(r) \ge r-1$. Gusfield et al. 09 conjectured that $f(r) = r$ for any $r
\ge 2$. In this paper, we present an example showing that $f(4) \ge 5$ and then
a closure operation for chordal sandwich graphs. The later problem is a common
approach of perfect phylogeny. This operation can be the first step to simplify
the problem before solving some particular cases $f(4), f(5), ... $, and
determining the function $f(r)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1117</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1117</id><created>2011-05-05</created><updated>2011-11-07</updated><authors><author><keyname>P&#xe9;rez-Escudero</keyname><forenames>Alfonso</forenames></author><author><keyname>de Polavieja</keyname><forenames>Gonzalo G.</forenames></author></authors><title>Collective Animal Behavior from Bayesian Estimation and Probability
  Matching</title><categories>q-bio.QM cs.SI nlin.AO physics.data-an physics.soc-ph q-bio.NC</categories><comments>19 pages, including Supplemental Figures and Supplemental Text. In
  press in PLoS Computational Biology</comments><journal-ref>PLoS Comput Biol 7(11): e1002282 (2011)</journal-ref><doi>10.1371/journal.pcbi.1002282</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Animals living in groups make movement decisions that depend, among other
factors, on social interactions with other group members. Our present
understanding of social rules in animal collectives is mainly based on
empirical fits to observations, with less emphasis in obtaining
first-principles approaches that allow their derivation. Here we show that
patterns of collective decisions can be derived from the basic ability of
animals to make probabilistic estimations in the presence of uncertainty. We
build a decision-making model with two stages: Bayesian estimation and
probabilistic matching. In the first stage, each animal makes a Bayesian
estimation of which behavior is best to perform taking into account personal
information about the environment and social information collected by observing
the behaviors of other animals. In the probability matching stage, each animal
chooses a behavior with a probability equal to the Bayesian-estimated
probability that this behavior is the most appropriate one. This model derives
very simple rules of interaction in animal collectives that depend only on two
types of reliability parameters, one that each animal assigns to the other
animals and another given by the quality of the non-social information. We test
our model by obtaining theoretically a rich set of observed collective patterns
of decisions in three-spined sticklebacks, Gasterosteus aculeatus, a shoaling
fish species. The quantitative link shown between probabilistic estimation and
collective rules of behavior allows a better contact with other fields such as
foraging, mate selection, neurobiology and psychology, and gives predictions
for experiments directly testing the relationship between estimation and
collective behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1141</identifier>
 <datestamp>2011-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1141</id><created>2011-05-05</created><authors><author><keyname>Gunnells</keyname><forenames>Paul E.</forenames></author></authors><title>On the cryptanalysis of the generalized simultaneous conjugacy search
  problem and the security of the Algebraic Eraser</title><categories>cs.CR math.GR</categories><msc-class>94A60 (Primary), 20F10, 20F36, 68P25 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Algebraic Eraser (AE) is a cryptographic primitive that can be used to
obscure information in certain algebraic cryptosystems. The Colored Burau Key
Agreement Protocol (CBKAP), which is built on the AE, was introduced by I.
Anshel, M. Anshel, D. Goldfeld, and S. Lemieux in 2006 as a protocol suitable
for use on platforms with constrained computational resources, such as RFID and
wireless sensors. In 2009 A. Myasnikov and A. Ushnakov proposed an attack on
CBKAP that attempts to defeat the generalized simultaneous conjugacy search
problem, which is the public-key computational problem underlying CBKAP. In
this paper we investigate the effectiveness of this attack. Our findings are
that success of the attack only comes from applying it to short keys, and that
with appropriate keys the attack fails in 100% of cases and does not pose a
threat against CBKAP. Moreover, the attack makes assumptions about CBKAP that
do not hold in practical implementations, and thus does not represent a threat
to the use of CBKAP in applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1178</identifier>
 <datestamp>2012-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1178</id><created>2011-05-05</created><authors><author><keyname>Tarlow</keyname><forenames>Daniel</forenames></author><author><keyname>Givoni</keyname><forenames>Inmar E.</forenames></author><author><keyname>Zemel</keyname><forenames>Richard S.</forenames></author><author><keyname>Frey</keyname><forenames>Brendan J.</forenames></author></authors><title>Interpreting Graph Cuts as a Max-Product Algorithm</title><categories>cs.LG cs.DS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The maximum a posteriori (MAP) configuration of binary variable models with
submodular graph-structured energy functions can be found efficiently and
exactly by graph cuts. Max-product belief propagation (MP) has been shown to be
suboptimal on this class of energy functions by a canonical counterexample
where MP converges to a suboptimal fixed point (Kulesza &amp; Pereira, 2008).
  In this work, we show that under a particular scheduling and damping scheme,
MP is equivalent to graph cuts, and thus optimal. We explain the apparent
contradiction by showing that with proper scheduling and damping, MP always
converges to an optimal fixed point. Thus, the canonical counterexample only
shows the suboptimality of MP with a particular suboptimal choice of schedule
and damping. With proper choices, MP is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1186</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1186</id><created>2011-05-05</created><authors><author><keyname>Karaman</keyname><forenames>Sertac</forenames></author><author><keyname>Frazzoli</keyname><forenames>Emilio</forenames></author></authors><title>Sampling-based Algorithms for Optimal Motion Planning</title><categories>cs.RO</categories><comments>76 pages, 26 figures, to appear in International Journal of Robotics
  Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  During the last decade, sampling-based path planning algorithms, such as
Probabilistic RoadMaps (PRM) and Rapidly-exploring Random Trees (RRT), have
been shown to work well in practice and possess theoretical guarantees such as
probabilistic completeness. However, little effort has been devoted to the
formal analysis of the quality of the solution returned by such algorithms,
e.g., as a function of the number of samples. The purpose of this paper is to
fill this gap, by rigorously analyzing the asymptotic behavior of the cost of
the solution returned by stochastic sampling-based algorithms as the number of
samples increases. A number of negative results are provided, characterizing
existing algorithms, e.g., showing that, under mild technical conditions, the
cost of the solution returned by broadly used sampling-based algorithms
converges almost surely to a non-optimal value. The main contribution of the
paper is the introduction of new algorithms, namely, PRM* and RRT*, which are
provably asymptotically optimal, i.e., such that the cost of the returned
solution converges almost surely to the optimum. Moreover, it is shown that the
computational complexity of the new algorithms is within a constant factor of
that of their probabilistically complete (but not asymptotically optimal)
counterparts. The analysis in this paper hinges on novel connections between
stochastic sampling-based path planning algorithms and the theory of random
geometric graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1187</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1187</id><created>2011-05-05</created><authors><author><keyname>Zhang</keyname><forenames>Zhenliang</forenames></author><author><keyname>Pezeshki</keyname><forenames>Ali</forenames></author><author><keyname>Moran</keyname><forenames>William</forenames></author><author><keyname>Howard</keyname><forenames>Stephen D.</forenames></author><author><keyname>Chong</keyname><forenames>Edwin K. P.</forenames></author></authors><title>Error Probability Bounds for Balanced Binary Relay Trees</title><categories>cs.IT math.IT stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the detection error probability associated with a balanced binary
relay tree, where the leaves of the tree correspond to $N$ identical and
independent detectors. The root of the tree represents a fusion center that
makes the overall detection decision. Each of the other nodes in the tree are
relay nodes that combine two binary messages to form a single output binary
message. In this way, the information from the detectors is aggregated into the
fusion center via the intermediate relay nodes. In this context, we describe
the evolution of Type I and Type II error probabilities of the binary data as
it propagates from the leaves towards the root. Tight upper and lower bounds
for the total error probability at the fusion center as functions of $N$ are
derived. These characterize how fast the total error probability converges to 0
with respect to $N$, even if the individual sensors have error probabilities
that converge to 1/2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1191</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1191</id><created>2011-05-05</created><authors><author><keyname>Kumar</keyname><forenames>Bimal Aklesh</forenames></author></authors><title>Software Architecture for Fiji National University Campus Information
  Systems</title><categories>cs.SE</categories><journal-ref>Indian Jounal of Computer Science and Engineering vol.2 no.2
  (2011), 255-261</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software Architecture defines the overview of the system which consists of
various components and their relationships among the software. Architectural
design is very important in the development of large scale software solution
and plays a very active role in achieving business goals, quality and reusable
solution. It is often difficult to choose the best software architecture for
your system from the several candidate types available. In this paper we look
at the several architectural types and compare them based on the key
requirements of our system, and select the most appropriate architecture for
the implementation of campus information systems at Fiji National University.
Finally we provide details of proposed architecture and outline future plans
for implementation of our system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1215</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1215</id><created>2011-05-05</created><updated>2012-02-01</updated><authors><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Schweller</keyname><forenames>Robert T.</forenames></author><author><keyname>Summers</keyname><forenames>Scott M.</forenames></author></authors><title>Efficient Squares and Turing Universality at Temperature 1 with a Unique
  Negative Glue</title><categories>cs.ET cs.CG</categories><comments>Original version appeared in DNA Computing 17. This is an updated,
  journal version with a pair of new results and several other changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Is Winfree's abstract Tile Assembly Model (aTAM) &quot;powerful?&quot; Well, if certain
tiles are required to &quot;cooperate&quot; in order to be able to bind to a growing tile
assembly (a.k.a., temperature 2 self-assembly), then Turing universal
computation and the efficient self-assembly of $N \times N$ squares is
achievable in the aTAM (Rotemund and Winfree, STOC 2000). So yes, in a
computational sense, the aTAM is quite powerful! However, if one completely
removes this cooperativity condition (a.k.a., temperature 1 self-assembly),
then the computational &quot;power&quot; of the aTAM (i.e., its ability to support Turing
universal computation and the efficient self-assembly of $N \times N$ squares)
becomes unknown. On the plus side, the aTAM, at temperature 1, isn't only
Turing universal but also supports the efficient self-assembly $N \times N$
squares if self-assembly is allowed to utilize three spatial dimensions (Fu,
Schweller and Cook, SODA 2011). We investigate the theoretical &quot;power&quot; of a
seemingly simple, restrictive class of tile assembly systems (TASs) in which
(1) the absolute value of every glue strength is 1, (2) there's a single
negative strength glue type and (3) unequal glues can't interact. We call these
the \emph{restricted glue} TASs (rgTAS). We first show the tile complexity of
producing an $N \times N$ square with an rgTAS is $O(\frac{\log n}{\log \log
n})$. We also prove that rgTASs are Turing universal with a construction that
simulates an arbitrary Turing machine. Next, we provide results for a variation
of the rgTAS class, partially restricted glue TASs, which is similar except
that the magnitude of the negative glue's strength can only assumed to be $\ge
1$. These results consist of a construction with $O(\log n)$ tile complexity
for building $N \times N$ squares, and one which simulates a Turing machine but
with a greater scaling factor than for the rgTAS construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1226</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1226</id><created>2011-05-06</created><authors><author><keyname>Barisevi&#x10d;ius</keyname><forenames>G.</forenames></author><author><keyname>Tamulynas</keyname><forenames>B.</forenames></author></authors><title>Multilingual lexicon design tool and database management system for MT</title><categories>cs.CL</categories><journal-ref>Proceedings of the 2nd Baltic Conference on Human Language
  Technologies, April 4-5, 2005, Tallin, Estonia. Tallin : Tallin University of
  Technology, 2005. ISBN 9985894839. p. 219-224</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents the design and development of English-Lithuanian-English
dictionarylexicon tool and lexicon database management system for MT. The
system is oriented to support two main requirements: to be open to the user and
to describe much more attributes of speech parts as a regular dictionary that
are required for the MT. Programming language Java and database management
system MySql is used to implement the designing tool and lexicon database
respectively. This solution allows easily deploying this system in the
Internet. The system is able to run on various OS such as: Windows, Linux, Mac
and other OS where Java Virtual Machine is supported. Since the modern lexicon
database managing system is used, it is not a problem accessing the same
database for several users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1227</identifier>
 <datestamp>2014-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1227</id><created>2011-05-06</created><updated>2012-04-19</updated><authors><author><keyname>Rafols</keyname><forenames>Ismael</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>O'Hare</keyname><forenames>Alice</forenames></author><author><keyname>Nightingale</keyname><forenames>Paul</forenames></author><author><keyname>Stirling</keyname><forenames>Andy</forenames></author></authors><title>How journal rankings can suppress interdisciplinary research. A
  comparison between Innovation Studies and Business &amp; Management</title><categories>cs.DL physics.soc-ph</categories><comments>41 pages, 10 figures</comments><journal-ref>Research Policy, Volume 41, Issue 7, September 2012, Pages
  1262-1282</journal-ref><doi>10.1016/j.wasman.2012.01.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study provides quantitative evidence on how the use of journal rankings
can disadvantage interdisciplinary research in research evaluations. Using
publication and citation data, it compares the degree of interdisciplinarity
and the research performance of a number of Innovation Studies units with that
of leading Business &amp; Management schools in the UK. On the basis of various
mappings and metrics, this study shows that: (i) Innovation Studies units are
consistently more interdisciplinary in their research than Business &amp;
Management schools; (ii) the top journals in the Association of Business
Schools' rankings span a less diverse set of disciplines than lower-ranked
journals; (iii) this results in a more favourable assessment of the performance
of Business &amp; Management schools, which are more disciplinary-focused. This
citation-based analysis challenges the journal ranking-based assessment. In
short, the investigation illustrates how ostensibly 'excellence-based' journal
rankings exhibit a systematic bias in favour of mono-disciplinary research. The
paper concludes with a discussion of implications of these phenomena, in
particular how the bias is likely to affect negatively the evaluation and
associated financial resourcing of interdisciplinary research organisations,
and may result in researchers becoming more compliant with disciplinary
authority over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1234</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1234</id><created>2011-05-06</created><updated>2011-05-24</updated><authors><author><keyname>Al-Saadoon</keyname><forenames>Ghossoon. M. W.</forenames></author><author><keyname>Al-Bayatti</keyname><forenames>Hilal M. Y.</forenames></author></authors><title>A Comparison of Trojan Virus Behavior in Linux and Windows Operating
  Systems</title><categories>cs.CR</categories><comments>7 Pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT), Vol. 1, No. 3, 56-62, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trojan virus attacks pose one of the most serious threats to computer
security. A Trojan horse is typically separated into two parts - a server and a
client. It is the client that is cleverly disguised as significant software and
positioned in peer-to-peer file sharing networks, or unauthorized download
websites. The most common means of infection is through email attachments. The
developer of the virus usually uses various spamming techniques in order to
distribute the virus to unsuspecting users. Malware developers use chat
software as another method to spread their Trojan horse viruses such as Yahoo
Messenger and Skype. The objective of this paper is to explore the network
packet information and detect the behavior of Trojan attacks to monitoring
operating systems such as Windows and Linux. This is accomplished by detecting
and analyzing the Trojan infected packet from a network segment -which passes
through email attachment- before attacking a host computer. The results that
have been obtained to detect information and to store infected packets through
monitoring when using the web browser also compare the behaviors of Linux and
Windows using the payload size after implementing the Wireshark sniffer packet
results. Conclusions of the figures analysis from the packet captured data to
analyze the control bit, and check the behavior of the control bits, and the
usability of the operating systems Linux and Windows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1242</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1242</id><created>2011-05-06</created><authors><author><keyname>Kowshik</keyname><forenames>Hemant</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Optimal Computation of Symmetric Boolean Functions in Collocated
  Networks</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider collocated wireless sensor networks, where each node has a
Boolean measurement and the goal is to compute a given Boolean function of
these measurements. We first consider the worst case setting and study optimal
block computation strategies for computing symmetric Boolean functions. We
study three classes of functions: threshold functions, delta functions and
interval functions. We provide exactly optimal strategies for the first two
classes, and a scaling law order-optimal strategy with optimal preconstant for
interval functions. We also extend the results to the case of integer
measurements and certain integer-valued functions. We use lower bounds from
communication complexity theory, and provide an achievable scheme using
information theoretic tools.
  Next, we consider the case where nodes measurements are random and drawn from
independent Bernoulli distributions. We address the problem of optimal function
computation so as to minimize the expected total number of bits that are
transmitted. In the case of computing a single instance of a Boolean threshold
function, we show the surprising result that the optimal order of transmissions
depends in an extremely simple way on the values of previously transmitted
bits, and the ordering of the marginal probabilities of the Boolean variables.
  The approach presented can be generalized to the case where each node has a
block of measurements, though the resulting problem is somewhat harder, and we
conjecture the optimal strategy. We further show how to generalize to a pulse
model of communication. One can also consider the related problem of
approximate computation given a fixed number of bits. In this case, the optimal
strategy is significantly different, and lacks an elegant characterization.
However, for the special case of the parity function, we show that the greedy
strategy is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1246</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1246</id><created>2011-05-06</created><authors><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>High-SNR Capacity of Wireless Communication Channels in the Noncoherent
  Setting: A Primer</title><categories>cs.IT math.IT</categories><comments>To appear in Int. J. Electron. Commun. (AE\&quot;U), Aug. 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper, mostly tutorial in nature, deals with the problem of
characterizing the capacity of fading channels in the high signal-to-noise
ratio (SNR) regime. We focus on the practically relevant noncoherent setting,
where neither transmitter nor receiver know the channel realizations, but both
are aware of the channel law. We present, in an intuitive and accessible form,
two tools, first proposed by Lapidoth &amp; Moser (2003), of fundamental importance
to high-SNR capacity analysis: the duality approach and the escape-to-infinity
property of capacity-achieving distributions. Furthermore, we apply these tools
to refine some of the results that appeared previously in the literature and to
simplify the corresponding proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1247</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1247</id><created>2011-05-06</created><authors><author><keyname>Chattopadhyay</keyname><forenames>Manojit</forenames><affiliation>Pailan College of Management &amp; Technology</affiliation></author><author><keyname>Chattopadhyay</keyname><forenames>Surajit</forenames><affiliation>Pailan College of Management &amp; Technology</affiliation></author><author><keyname>Dan</keyname><forenames>Pranab K.</forenames><affiliation>West Bengal University of Technology</affiliation></author></authors><title>Machine-Part cell formation through visual decipherable clustering of
  Self Organizing Map</title><categories>cs.AI</categories><comments>18 pages,3 table, 4 figures</comments><journal-ref>The International Journal of Advanced Manufacturing Technology,
  2011, Volume 52, Numbers 9-12, 1019-1030</journal-ref><doi>10.1007/s00170-010-2802-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine-part cell formation is used in cellular manufacturing in order to
process a large variety, quality, lower work in process levels, reducing
manufacturing lead-time and customer response time while retaining flexibility
for new products. This paper presents a new and novel approach for obtaining
machine cells and part families. In the cellular manufacturing the fundamental
problem is the formation of part families and machine cells. The present paper
deals with the Self Organising Map (SOM) method an unsupervised learning
algorithm in Artificial Intelligence, and has been used as a visually
decipherable clustering tool of machine-part cell formation. The objective of
the paper is to cluster the binary machine-part matrix through visually
decipherable cluster of SOM color-coding and labelling via the SOM map nodes in
such a way that the part families are processed in that machine cells. The
Umatrix, component plane, principal component projection, scatter plot and
histogram of SOM have been reported in the present work for the successful
visualization of the machine-part cell formation. Computational result with the
proposed algorithm on a set of group technology problems available in the
literature is also presented. The proposed SOM approach produced solutions with
a grouping efficacy that is at least as good as any results earlier reported in
the literature and improved the grouping efficacy for 70% of the problems and
found immensely useful to both industry practitioners and researchers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1248</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1248</id><created>2011-05-06</created><authors><author><keyname>Briest</keyname><forenames>Patrick</forenames></author><author><keyname>Degener</keyname><forenames>Bastian</forenames></author><author><keyname>Kempkes</keyname><forenames>Barbara</forenames></author><author><keyname>Kling</keyname><forenames>Peter</forenames></author><author><keyname>Pietrzyk</keyname><forenames>Peter</forenames></author></authors><title>A Distributed Approximation Algorithm for the Metric Uncapacitated
  Facility Location Problem in the Congest Model</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a randomized distributed approximation algorithm for the metric
uncapacitated facility location problem. The algorithm is executed on a
bipartite graph in the Congest model yielding a (1.861 + epsilon) approximation
factor, where epsilon is an arbitrary small positive constant. It needs
O(n^{3/4}log_{1+epsilon}^2(n) communication rounds with high probability (n
denoting the number of facilities and clients). To the best of our knowledge,
our algorithm currently has the best approximation factor for the facility
location problem in a distributed setting. It is based on a greedy sequential
approximation algorithm by Jain et al. (J. ACM 50(6), pages: 795-824, 2003).
The main difficulty in executing this sequential algorithm lies in dealing with
situations, where multiple facilities are eligible for opening, but (in order
to preserve the approximation factor of the sequential algorithm) only a subset
of them can actually be opened. Note that while the presented runtime bound of
our algorithm is &quot;with high probability&quot;, the approximation factor is not &quot;in
expectation&quot; but always guaranteed to be (1.861 + epsilon). Thus, our main
contribution is a sublinear time selection mechanism that, while increasing the
approximation factor by an arbitrary small additive term, allows us to decide
which of the eligible facilities to open.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1256</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1256</id><created>2011-05-06</created><updated>2011-05-14</updated><authors><author><keyname>Metcalfe</keyname><forenames>George</forenames><affiliation>University of Bern</affiliation></author><author><keyname>Olivetti</keyname><forenames>Nicola</forenames><affiliation>Paul Cezanne University</affiliation></author></authors><title>Towards a Proof Theory of G\&quot;odel Modal Logics</title><categories>math.LO cs.LO</categories><proxy>LMCS</proxy><acm-class>cs.LO</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 17,
  2011) lmcs:972</journal-ref><doi>10.2168/LMCS-7(2:10)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analytic proof calculi are introduced for box and diamond fragments of basic
modal fuzzy logics that combine the Kripke semantics of modal logic K with the
many-valued semantics of G\&quot;odel logic. The calculi are used to establish
completeness and complexity results for these fragments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1261</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1261</id><created>2011-05-06</created><authors><author><keyname>Scheibler</keyname><forenames>Robin</forenames></author><author><keyname>Hurley</keyname><forenames>Paul</forenames></author><author><keyname>Chebira</keyname><forenames>Amina</forenames></author></authors><title>Pruned Continuous Haar Transform of 2D Polygonal Patterns with
  Application to VLSI Layouts</title><categories>cs.CE cs.CG cs.DS</categories><comments>4 pages, 5 figures, 1 algorithm</comments><journal-ref>R. Scheibler, P. Hurley, and A. Chebira, &quot;Pruned Continuous Haar
  Transform of 2D Polygonal Patterns with Application to VLSI Layouts,&quot; Proc.
  of the 2010 IRAST Int. Cong. on Comp. App. and Computational Sci. (CACS
  2010), pp. 984--987, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an algorithm for the efficient computation of the continuous
Haar transform of 2D patterns that can be described by polygons. These patterns
are ubiquitous in VLSI processes where they are used to describe design and
mask layouts. There, speed is of paramount importance due to the magnitude of
the problems to be solved and hence very fast algorithms are needed. We show
that by techniques borrowed from computational geometry we are not only able to
compute the continuous Haar transform directly, but also to do it quickly. This
is achieved by massively pruning the transform tree and thus dramatically
decreasing the computational load when the number of vertices is small, as is
the case for VLSI layouts. We call this new algorithm the pruned continuous
Haar transform. We implement this algorithm and show that for patterns found in
VLSI layouts the proposed algorithm was in the worst case as fast as its
discrete counterpart and up to 12 times faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1279</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1279</id><created>2011-05-06</created><authors><author><keyname>Wang</keyname><forenames>Fanggang</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Wireless MIMO Switching with Network Coding</title><categories>cs.IT cs.NI math.IT</categories><comments>This manuscript is an extention work of our previous paper &quot;Wireless
  MIMO Switching&quot; and also with some results of a talk given in CUHK. The major
  extention is that physical-layer network coding is used and significantly
  improves the throughput performance</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a generic switching problem, a switching pattern consists of a one-to-one
mapping from a set of inputs to a set of outputs (i.e., a permutation). We
propose and investigate a wireless switching framework in which a multi-antenna
relay is responsible for switching traffic among a set of $N$ stations. We
refer to such a relay as a MIMO switch. With beamforming and linear detection,
the MIMO switch controls which stations are connected to which other stations.
Each beamforming matrix realizes a permutation pattern among the stations. We
refer to the corresponding permutation matrix as a switch matrix. By scheduling
a set of different switch matrices, full connectivity among the stations can be
established. In this paper, we focus on &quot;fair switching&quot; in which equal amounts
of traffic are to be delivered for all $N(N-1)$ ordered pairs of stations. In
particular, we investigate how the system throughput can be maximized. In
general, for large $N$ the number of possible switch matrices (i.e.,
permutations) is huge, making the scheduling problem combinatorially
challenging. We show that for the cases of N=4 and 5, only a subset of $N-1$
switch matrices need to be considered in the scheduling problem to achieve good
throughput. We conjecture that this will be the case for large $N$ as well.
This conjecture, if valid, implies that for practical purposes, fair-switching
scheduling is not an intractable problem. We also investigate MIMO switching
with physical-layer network coding in this paper. We find that it can improve
throughput appreciably.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1293</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1293</id><created>2011-05-06</created><authors><author><keyname>Gawron</keyname><forenames>Piotr</forenames></author><author><keyname>G&#x142;omb</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>Miszczak</keyname><forenames>Jaros&#x142;aw Adam</forenames></author><author><keyname>Pucha&#x142;a</keyname><forenames>Zbigniew</forenames></author></authors><title>Eigengestures for natural human computer interface</title><categories>cs.HC</categories><comments>10 pages, 3 figures</comments><journal-ref>Advances in Intelligent and Soft Computing, 2011, Volume 103/2011,
  49-56</journal-ref><doi>10.1007/978-3-642-23169-8_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the application of Principal Component Analysis for data acquired
during the design of a natural gesture interface. We investigate the concept of
an eigengesture for motion capture hand gesture data and present the
visualisation of principal components obtained in the course of conducted
experiments. We also show the influence of dimensionality reduction on
reconstructed gesture data quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1302</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1302</id><created>2011-05-06</created><authors><author><keyname>Park</keyname><forenames>Wooram</forenames></author><author><keyname>Chirikjian</keyname><forenames>Gregory S.</forenames></author></authors><title>A Modified Cross Correlation Algorithm for Reference-free Image
  Alignment of Non-Circular Projections in Single-Particle Electron Microscopy</title><categories>q-bio.QM cs.CV math.NA</categories><comments>29pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a modified cross correlation method to align images
from the same class in single-particle electron microscopy of highly
non-spherical structures. In this new method, First we coarsely align
projection images, and then re-align the resulting images using the cross
correlation (CC) method. The coarse alignment is obtained by matching the
centers of mass and the principal axes of the images. The distribution of
misalignment in this coarse alignment can be quantified based on the
statistical properties of the additive background noise. As a consequence, the
search space for re-alignment in the cross correlation method can be reduced to
achieve better alignment. In order to overcome problems associated with false
peaks in the cross correlations function, we use artificially blurred images
for the early stage of the iterative cross correlation method and segment the
intermediate class average from every iteration step. These two additional
manipulations combined with the reduced search space size in the cross
correlation method yield better alignments for low signal-to-noise ratio images
than both classical cross correlation and maximum likelihood(ML) methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1306</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1306</id><created>2011-05-06</created><updated>2011-08-08</updated><authors><author><keyname>D&#x119;owski</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>Excess entropy in natural language: present state and perspectives</title><categories>cs.IT cs.CL math.IT</categories><comments>12 pages; no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review recent progress in understanding the meaning of mutual information
in natural language. Let us define words in a text as strings that occur
sufficiently often. In a few previous papers, we have shown that a power-law
distribution for so defined words (a.k.a. Herdan's law) is obeyed if there is a
similar power-law growth of (algorithmic) mutual information between adjacent
portions of texts of increasing length. Moreover, the power-law growth of
information holds if texts describe a complicated infinite (algorithmically)
random object in a highly repetitive way, according to an analogous power-law
distribution. The described object may be immutable (like a mathematical or
physical constant) or may evolve slowly in time (like cultural heritage). Here
we reflect on the respective mathematical results in a less technical way. We
also discuss feasibility of deciding to what extent these results apply to the
actual human communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1325</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1325</id><created>2011-05-06</created><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Grigorescu</keyname><forenames>Elena</forenames></author><author><keyname>Raghavendra</keyname><forenames>Prasad</forenames></author><author><keyname>Shapira</keyname><forenames>Asaf</forenames></author></authors><title>Testing Odd-Cycle-Freeness in Boolean Functions</title><categories>cs.DS cs.DM math.CO</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Call a function f : F_2^n -&gt; {0,1} odd-cycle-free if there are no x_1, ...,
x_k in F_2^n with k an odd integer such that f(x_1) = ... = f(x_k) = 1 and x_1
+ ... + x_k = 0. We show that one can distinguish odd-cycle-free functions from
those eps-far from being odd-cycle-free by making poly(1/eps) queries to an
evaluation oracle. To obtain this result, we use connections between basic
Fourier analysis and spectral graph theory to show that one can reduce testing
odd-cycle-freeness of Boolean functions to testing bipartiteness of dense
graphs. Our work forms part of a recent sequence of works that shows
connections between testability of properties of Boolean functions and of graph
properties. We also prove that there is a canonical tester for
odd-cycle-freeness making poly(1/eps) queries, meaning that the testing
algorithm operates by picking a random linear subspace of dimension O(log
1/eps) and then checking if the restriction of the function to the subspace is
odd-cycle-free or not. The test is analyzed by studying the effect of random
subspace restriction on the Fourier coefficients of a function. Our work
implies that testing odd-cycle-freeness using a canonical tester instead of an
arbitrary tester incurs no more than a polynomial blowup in the query
complexity. The question of whether a canonical tester with polynomial blowup
exists for all linear-invariant properties remains an open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1328</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1328</id><created>2011-05-06</created><authors><author><keyname>Wicaksana</keyname><forenames>I Wayan Simri</forenames><affiliation>Gunadarma University</affiliation></author></authors><title>Matchmaking Semantic Based for Information System Interoperability</title><categories>cs.NI</categories><comments>Gunadarma University; ICEEI2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike the traditional model of information pull, matchmaking is base on a
cooperative partnership between information providers and consumers, assisted
by an intelligent facilitator (the matchmaker). Refer to some experiments, the
matchmaking to be most useful in two different ways: locating information
sources or services that appear dynamically and notification of information
changes. Effective information and services sharing in distributed such as P2P
based environments raises many challenges, including discovery and localization
of resources, exchange over heterogeneous sources, and query processing. One
traditional approach for dealing with some of the above challenges is to create
unified integrated schemas or services to combine the heterogeneous sources.
This approach does not scale well when applied in dynamic distributed
environments and has many drawbacks related to the large numbers of sources.
The main issues in matchmaking are how to represent advertising and request,
and how to calculate possibility matching between advertising and request. The
advertising and request can represent data or services by using many model of
representation. In this paper, we address an approach of matchmaking by
considering semantic agreement between sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1347</identifier>
 <datestamp>2011-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1347</id><created>2011-05-06</created><authors><author><keyname>Genin</keyname><forenames>Daniel</forenames></author><author><keyname>Nakassis</keyname><forenames>Tassos</forenames></author></authors><title>Modeling queuing dynamics of TCP: a simple model and its empirical
  validation</title><categories>cs.NI</categories><acm-class>C.2.2</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Understanding queuing dynamics of TCP is important for correct router buffer
sizing as well as for optimizing the performance of the TCP protocol itself.
However, modeling of buffer content dynamics under TCP has received relatively
little attention given its importance. Commonly used queuing models are based
on overly simplistic assumptions about the packet arrival process. As a
consequence, there are no quantitatively accurate closed loop TCP models
capable of predicting performance even for a single link shared by multiple
flows. Our present paper aims to close this gap by proposing a simple TCP
queuing model, which is based on experimental observations and validated by
extensive packet level simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1361</identifier>
 <datestamp>2011-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1361</id><created>2011-05-06</created><updated>2011-11-22</updated><authors><author><keyname>Banerjee</keyname><forenames>Taposh</forenames></author><author><keyname>Veeravalli</keyname><forenames>Venugopal V.</forenames></author></authors><title>Data-Efficient Quickest Change Detection with On-Off Observation Control</title><categories>math.ST cs.IT math.IT math.OC stat.TH</categories><comments>Preliminary version of this paper has been presented at ITA Workshop
  UCSD 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we extend the Shiryaev's quickest change detection formulation
by also accounting for the cost of observations used before the change point.
The observation cost is captured through the average number of observations
used in the detection process before the change occurs. The objective is to
select an on-off observation control policy, that decides whether or not to
take a given observation, along with the stopping time at which the change is
declared, so as to minimize the average detection delay, subject to constraints
on both the probability of false alarm and the observation cost. By considering
a Lagrangian relaxation of the constraint problem, and using dynamic
programming arguments, we obtain an \textit{a posteriori} probability based
two-threshold algorithm that is a generalized version of the classical Shiryaev
algorithm. We provide an asymptotic analysis of the two-threshold algorithm and
show that the algorithm is asymptotically optimal, i.e., the performance of the
two-threshold algorithm approaches that of the Shiryaev algorithm, for a fixed
observation cost, as the probability of false alarm goes to zero. We also show,
using simulations, that the two-threshold algorithm has good observation
cost-delay trade-off curves, and provides significant reduction in observation
cost as compared to the naive approach of fractional sampling, where samples
are skipped randomly. Our analysis reveals that, for practical choices of
constraints, the two thresholds can be set independent of each other: one based
on the constraint of false alarm and another based on the observation cost
constraint alone.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1363</identifier>
 <datestamp>2015-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1363</id><created>2011-05-06</created><authors><author><keyname>Dai</keyname><forenames>Wanyang</forenames></author></authors><title>Heavy traffic limit theorems for a queue with Poisson ON/OFF long-range
  dependent sources and general service time distribution</title><categories>math.PR cs.IT math.IT math.ST stat.TH</categories><comments>19 pages, to appear in Acta Mathematicae Applicatae Sinica, English
  Series, and the final publication will be available at springlink.com</comments><journal-ref>Acta Mathematicae Applicatae Sinica, English Series, Vol. 28, No.
  4, 807-822, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Internet environment, traffic flow to a link is typically modeled by
superposition of ON/OFF based sources. During each ON-period for a particular
source, packets arrive according to a Poisson process and packet sizes (hence
service times) can be generally distributed. In this paper, we establish heavy
traffic limit theorems to provide suitable approximations for the system under
first-in first-out (FIFO) and work conserving service discipline, which state
that, when the lengths of both ON- and OFF-periods are lightly tailed, the
sequences of the scaled queue length and workload processes converge weakly to
short-range dependent reflecting Gaussian processes, and when the lengths of
ON- and/or OFF periods are heavily tailed with infinite variance, the sequences
converge weakly to either reflecting fractional Brownian motions (FBMs) or
certain type of long-range dependent reflecting Gaussian processes depending on
the choice of scaling as the number of superposed sources tends to infinity.
Moreover, the sequences exhibit a state space collapse-like property when the
number of sources is large enough, which is a kind of extension of the
well-known Little's law for M/M/1 queueing system. Theory to justify the
approximations is based on appropriate heavy traffic conditions which
essentially mean that the service rate closely approaches the arrival rate when
the number of input sources tends to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1364</identifier>
 <datestamp>2013-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1364</id><created>2011-05-06</created><updated>2012-04-05</updated><authors><author><keyname>Bertossi</keyname><forenames>Leopoldo</forenames></author><author><keyname>Li</keyname><forenames>Lechen</forenames></author></authors><title>Achieving Data Privacy through Secrecy Views and Null-Based Virtual
  Updates</title><categories>cs.DB cs.LO</categories><comments>Minor revisions of journal resubmission, 2012</comments><acm-class>H.2; F.4.1</acm-class><journal-ref>IEEE Transaction on Knowledge and Data Engineering, 2013,
  25(5):987-1000</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There may be sensitive information in a relational database, and we might
want to keep it hidden from a user or group thereof. In this work, sensitive
data is characterized as the contents of a set of secrecy views. For a user
without permission to access that sensitive data, the database instance he
queries is updated to make the contents of the views empty or contain only
tuples with null values. In particular, if this user poses a query about any of
these views, no meaningful information is returned. Since the database is not
expected to be physically changed to produce this result, the updates are only
virtual. And also minimal in a precise way. These minimal updates are reflected
in the secrecy view contents, and also in the fact that query answers, while
being privacy preserving, are also maximally informative. Virtual updates are
based on the use of null values as used in the SQL standard. We provide the
semantics of secrecy views and the virtual updates. The different ways in which
the underlying database is virtually updated are specified as the models of a
logic program with stable model semantics. The program becomes the basis for
the computation of the &quot;secret answers&quot; to queries, i.e. those that do not
reveal the sensitive information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1369</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1369</id><created>2011-05-06</created><authors><author><keyname>Buti</keyname><forenames>Federico</forenames><affiliation>School of Science and Technology University of Camerino</affiliation></author><author><keyname>De Donato</keyname><forenames>Massimo Callisto</forenames><affiliation>School of Science and Technology University of Camerino</affiliation></author><author><keyname>Corradini</keyname><forenames>Flavio</forenames><affiliation>School of Science and Technology University of Camerino</affiliation></author><author><keyname>Di Berardini</keyname><forenames>Maria Rita</forenames><affiliation>School of Science and Technology University of Camerino</affiliation></author><author><keyname>Vogler</keyname><forenames>Walter</forenames><affiliation>Institut f&#xfc;r Informatik Universit&#xe4;t Augsburg</affiliation></author></authors><title>Evaluating the Efficiency of Asynchronous Systems with FASE</title><categories>cs.LO</categories><comments>14 pages, 5 figures. A preliminary version has been presented as
  extended abstract in Pre-Proc. of The 1st Int. Workshop on Quantitative
  Formal Methods, pp.101-106, Technische Universiteit Eindhoven, 2009</comments><acm-class>D.2.2; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present FASE (Faster Asynchronous Systems Evaluation), a
tool for evaluating the worst-case efficiency of asynchronous systems. The tool
is based on some well-established results in the setting of a timed process
algebra (PAFAS: a Process Algebra for Faster Asynchronous Systems). To show the
applicability of FASE to concrete meaningful examples, we consider three
implementations of a bounded buffer and use FASE to automatically evaluate
their worst-case efficiency. We finally contrast our results with previous ones
where the efficiency of the same implementations has already been considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1370</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1370</id><created>2011-05-06</created><authors><author><keyname>De Donato</keyname><forenames>Massimo Callisto</forenames><affiliation>Scuola di Scienze e Tecnologie, Sezione Informatica. Universit&#xe0; di Camerino</affiliation></author><author><keyname>Di Berardini</keyname><forenames>Maria Rita</forenames><affiliation>Scuola di Scienze e Tecnologie, Sezione Informatica. Universit&#xe0; di Camerino</affiliation></author></authors><title>A Framework for the Evaluation of Worst-Case System Efficiency</title><categories>cs.LO cs.DS</categories><comments>5 Pages. In ICTCS 2010: 12th Italian Conference on Theoretical
  Computer Science, University of Camerino, Camerino, 2010</comments><msc-class>D.2.2, D.2.4</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present FASE (Fast Asynchronous Systems Evaluation), a tool
for evaluating worst-case efficiency of asynchronous systems. This tool
implements some well-established results in the setting of a timed CCS-like
process algebra: PAFAS (a Process Algebra for Faster Asynchronous Systems).
Moreover, we discuss some new solutions that are useful to improve the
applicability of FASE to concrete meaningful examples. We finally use fase to
evaluate the efficiency of three different implementations of a bounded buffer
and compare our results with previous ones obtained when the same
implementations have been contrasted according to an efficiency preorder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1376</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1376</id><created>2011-05-06</created><authors><author><keyname>Chevalier</keyname><forenames>Yannick</forenames><affiliation>IRIT</affiliation></author></authors><title>Finitary Deduction Systems</title><categories>cs.LO</categories><comments>30 pages. Work begun while in the CASSIS Project, INRIA Nancy Grand
  Est</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptographic protocols are the cornerstone of security in distributed
systems. The formal analysis of their properties is accordingly one of the
focus points of the security community, and is usually split among two groups.
In the first group, one focuses on trace-based security properties such as
confidentiality and authentication, and provides decision procedures for the
existence of attacks for an on-line attackers. In the second group, one focuses
on equivalence properties such as privacy and guessing attacks, and provides
decision procedures for the existence of attacks for an offline attacker. In
all cases the attacker is modeled by a deduction system in which his possible
actions are expressed. We present in this paper a notion of finitary deduction
systems that aims at relating both approaches. We prove that for such deduction
systems, deciding equivalence properties for on-line attackers can be reduced
to deciding reachability properties in the same setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1380</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1380</id><created>2011-05-06</created><updated>2011-05-21</updated><authors><author><keyname>Calvert</keyname><forenames>Wesley</forenames><affiliation>Southern Illinois University</affiliation></author><author><keyname>Kramer</keyname><forenames>Ken</forenames><affiliation>Queens College &amp; Graduate Center, CUNY</affiliation></author><author><keyname>Miller</keyname><forenames>Russell</forenames><affiliation>Queens College &amp; Graduate Center, CUNY</affiliation></author></authors><title>Noncomputable functions in the Blum-Shub-Smale model</title><categories>cs.LO math.LO</categories><proxy>LMCS</proxy><acm-class>F.1.1, F.1.3, I.1.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 24,
  2011) lmcs:1226</journal-ref><doi>10.2168/LMCS-7(2:15)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Working in the Blum-Shub-Smale model of computation on the real numbers, we
answer several questions of Meer and Ziegler. First, we show that, for each
natural number d, an oracle for the set of algebraic real numbers of degree at
most d is insufficient to allow an oracle BSS-machine to decide membership in
the set of algebraic numbers of degree d + 1. We add a number of further
results on relative computability of these sets and their unions. Then we show
that the halting problem for BSS-computation is not decidable below any
countable oracle set, and give a more specific condition, related to the
cardinalities of the sets, necessary for relative BSS-computability. Most of
our results involve the technique of using as input a tuple of real numbers
which is algebraically independent over both the parameters and the oracle of
the machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1383</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1383</id><created>2011-05-06</created><authors><author><keyname>Allen</keyname><forenames>Terry</forenames></author><author><keyname>Goudeseune</keyname><forenames>Camille</forenames></author></authors><title>Topological Considerations for Tuning and Fingering Stringed Instruments</title><categories>cs.SD math.GN</categories><comments>8 pages, 3 figures</comments><msc-class>14P10</msc-class><acm-class>F.4.0; H.5.5; G.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a formal language for assigning pitches to strings for fingered
multi-string instruments, particularly the six-string guitar. Given the
instrument's tuning (the strings' open pitches) and the compass of the fingers
of the hand stopping the strings, the formalism yields a framework for
simultaneously optimizing three things: the mapping of pitches to strings, the
choice of instrument tuning, and the key of the composition. Final optimization
relies on heuristics idiomatic to the tuning, the particular musical style, and
the performer's proficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1386</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1386</id><created>2011-05-06</created><authors><author><keyname>Steingrube</keyname><forenames>Silke</forenames></author><author><keyname>Timme</keyname><forenames>Marc</forenames></author><author><keyname>Woergoetter</keyname><forenames>Florentin</forenames></author><author><keyname>Manoonpong</keyname><forenames>Poramate</forenames></author></authors><title>Self-organized adaptation of a simple neural circuit enables complex
  robot behaviour</title><categories>cond-mat.dis-nn cs.AI cs.RO nlin.CD q-bio.NC</categories><comments>16 pages, non-final version, for final see Nature Physics homepage</comments><journal-ref>Nature Phys. 6:224 (2010)</journal-ref><doi>10.1038/nphys1860</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Controlling sensori-motor systems in higher animals or complex robots is a
challenging combinatorial problem, because many sensory signals need to be
simultaneously coordinated into a broad behavioural spectrum. To rapidly
interact with the environment, this control needs to be fast and adaptive.
Current robotic solutions operate with limited autonomy and are mostly
restricted to few behavioural patterns. Here we introduce chaos control as a
new strategy to generate complex behaviour of an autonomous robot. In the
presented system, 18 sensors drive 18 motors via a simple neural control
circuit, thereby generating 11 basic behavioural patterns (e.g., orienting,
taxis, self-protection, various gaits) and their combinations. The control
signal quickly and reversibly adapts to new situations and additionally enables
learning and synaptic long-term storage of behaviourally useful motor
responses. Thus, such neural control provides a powerful yet simple way to
self-organize versatile behaviours in autonomous agents with many degrees of
freedom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1406</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1406</id><created>2011-05-06</created><authors><author><keyname>Wicaksana</keyname><forenames>I Wayan Simri</forenames><affiliation>Gunadarma University</affiliation></author><author><keyname>Wahyudi</keyname><forenames>Bambang</forenames><affiliation>Gunadarma University</affiliation></author></authors><title>Comparison Latent Semantic and WordNet Approach for Semantic Similarity
  Calculation</title><categories>cs.IR</categories><comments>Keywords: latent semantic, interoperability, WordNet</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information exchange among many sources in Internet is more autonomous,
dynamic and free. The situation drive difference view of concepts among
sources. For example, word 'bank' has meaning as economic institution for
economy domain, but for ecology domain it will be defined as slope of river or
lake. In this aper, we will evaluate latent semantic and WordNet approach to
calculate semantic similarity. The evaluation will be run for some concepts
from different domain with reference by expert or human. Result of the
evaluation can provide a contribution for mapping of concept, query rewriting,
interoperability, etc.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1407</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1407</id><created>2011-05-06</created><authors><author><keyname>Salahuddin</keyname><forenames>Nur Sultan</forenames><affiliation>University of Burgundy</affiliation><affiliation>Gunadarma University</affiliation></author><author><keyname>Paindavoine</keyname><forenames>Michel</forenames><affiliation>University of Burgundy</affiliation></author><author><keyname>Huda</keyname><forenames>Nurul</forenames><affiliation>Gunadarma University</affiliation></author><author><keyname>Parmentier</keyname><forenames>Michel</forenames><affiliation>University of Franche-Comte</affiliation></author></authors><title>Design of Thin-Film-Transistor (TFT) arrays using current mirror
  circuits for Flat Panel Detectors (FPDs)</title><categories>cs.OH</categories><journal-ref>ICEEI2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We designed 4x4 matrix TFTs arrays using current mirror amplifiers.
Advantages of current mirror amplifiers are they need less requiring switches
and the conversion time is short. The TFTs arrays 4x4 matrix using current
mirror circuits have been fabricated and tested with success. The TFTs array
directly can process signals coming from 16 pixels in the same node. This
enables us to make the summation of the light intensities of close pixels
during a reading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1411</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1411</id><created>2011-05-06</created><authors><author><keyname>Ernastuti</keyname><affiliation>Gunadarma University</affiliation></author><author><keyname>Vajnovzki</keyname><forenames>Vincent</forenames><affiliation>Universit&#xe9; de Bourgogne</affiliation></author></authors><title>Embeddings of Linear Arrays, Rings and 2-D Meshes on Extended Lucas Cube
  Networks</title><categories>cs.NI</categories><comments>4 pages, Proceedings of the International Conference on Electrical
  Engineering and Informatics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Fibonacci string is a length n binary string containing no two consecutive
1s. Fibonacci cubes (FC), Extended Fibonacci cubes (ELC) and Lucas cubes (LC)
are subgraphs of hypercube defined in terms of Fibonacci strings. All these
cubes were introduced in the last ten years as models for interconnection
networks and shown that their network topology posseses many interesting
properties that are important in parallel processor network design and parallel
applications. In this paper, we propose a new family of Fibonacci-like cube,
namely Extended Lucas Cube (ELC). We address the following network simulation
problem : Given a linear array, a ring or a two-dimensional mesh; how can its
nodes be assigned to ELC nodes so as to keep their adjacent nodes near each
other in ELC ?. We first show a simple fact that there is a Hamiltonian path
and cycle in any ELC. We prove that any linear array and ring network can be
embedded into its corresponding optimum ELC (the smallest ELC with at least the
number of nodes in the ring) with dilation 1, which is optimum for most cases.
Then, we describe dilation 1 embeddings of a class of meshes into their
corresponding optimum ELC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1412</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1412</id><created>2011-05-06</created><authors><author><keyname>Salahuddin</keyname><forenames>Nur Sultan</forenames><affiliation>University of Burgundy</affiliation><affiliation>Gunadarma University</affiliation></author><author><keyname>Paindavoine</keyname><forenames>Michel</forenames><affiliation>University of Burgundy</affiliation></author><author><keyname>Heruseto</keyname><forenames>Brahmantyo</forenames><affiliation>Gunadarma University</affiliation></author><author><keyname>Parmentier</keyname><forenames>Michel</forenames><affiliation>University of Franche-Comte</affiliation></author></authors><title>Development of Active Pixel Photodiode Sensors for Gamma Camera
  Application</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We designed new photodiodes sensors including current mirror amplifiers.
These photodiodes have been fabricated using a CMOS 0.6 micrometers process
from Austria Micro System (AMS). The Photodiode areas are respectiveley 1mm x
1mm and 0.4mm x 0.4mm with fill factor 98 % and total chip area is 2 square
millimetres. The sensor pixels show a logarithmic response in illumination and
are capable of detecting very low blue light (less than 0.5 lux) . These
results allow to use our sensor in new Gamma Camera solid-state concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1421</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1421</id><created>2011-05-07</created><updated>2011-09-04</updated><authors><author><keyname>Feng</keyname><forenames>A. -X.</forenames></author><author><keyname>Fu</keyname><forenames>C. -H.</forenames></author><author><keyname>Xu</keyname><forenames>X. -L.</forenames></author><author><keyname>Liu</keyname><forenames>Ai-Fen</forenames></author><author><keyname>Chang</keyname><forenames>H.</forenames></author><author><keyname>He</keyname><forenames>D. -R.</forenames></author><author><keyname>Feng</keyname><forenames>G. -L.</forenames></author></authors><title>An Empirical Investigation on Important Subgraphs in
  Cooperation-Competition networks</title><categories>physics.soc-ph cs.SI</categories><comments>14 pages and 14 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Subgraphs are very important for understanding structure and function of
complex networks. Dyad and triad are the elementary subgraphs. We focus on the
distribution of their act degree defined as the number of activities, events or
organizations they join, which indicates the importance of the subgraphs. The
empirical studies show that, in a lot of real world systems, the dyad or triad
act degree distributions follow &quot;shifted power law&quot; (SPL), where {\alpha} and
{\gamma} are constants. We defined a &quot;heterogeneity index&quot;, H, to describe how
it is uneven and analytically deduced the correlation between H and {\alpha}
and {\gamma}. This manuscript, which shows the details of the empirical
studies, serves as an online supplement of a paper submitted to a journal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1424</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1424</id><created>2011-05-07</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author><author><keyname>Mayer</keyname><forenames>Pascal</forenames></author><author><keyname>Verlan</keyname><forenames>Sergey</forenames></author></authors><title>DNA Circuits Based on Isothermal Constrained Loop Extension DNA
  Amplification</title><categories>cs.ET q-bio.OT</categories><comments>14 pages, 6 figures</comments><msc-class>68Q05, 68Q45, 68Q85, 92B20</msc-class><acm-class>F.1.1; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first describe the isothermal constrained loop extension
DNA amplification (ICLEDA), which is a new variant of amplification combining
the advantages of rolling circle amplification (RCA) and of strand displacement
amplification (SDA). Then, we formalize this process in terms of the theory of
formal languages and show, on the basis of this formulation, how to manage OR
and AND gates. We then explain how to introduce negation, which allows us to
prove that, in principle, it is possible to implement the computation of any
boolean function on DNA strands using ICLEDA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1436</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1436</id><created>2011-05-07</created><authors><author><keyname>Chen</keyname><forenames>Jingchao</forenames></author></authors><title>Solving Rubik's Cube Using SAT Solvers</title><categories>cs.AI</categories><comments>13 pages</comments><journal-ref>SPA 2011: SAT for Practical Applications</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Rubik's Cube is an easily-understood puzzle, which is originally called the
&quot;magic cube&quot;. It is a well-known planning problem, which has been studied for a
long time. Yet many simple properties remain unknown. This paper studies
whether modern SAT solvers are applicable to this puzzle. To our best
knowledge, we are the first to translate Rubik's Cube to a SAT problem. To
reduce the number of variables and clauses needed for the encoding, we replace
a naive approach of 6 Boolean variables to represent each color on each facelet
with a new approach of 3 or 2 Boolean variables. In order to be able to solve
quickly Rubik's Cube, we replace the direct encoding of 18 turns with the layer
encoding of 18-subtype turns based on 6-type turns. To speed up the solving
further, we encode some properties of two-phase algorithm as an additional
constraint, and restrict some move sequences by adding some constraint clauses.
Using only efficient encoding cannot solve this puzzle. For this reason, we
improve the existing SAT solvers, and develop a new SAT solver based on
PrecoSAT, though it is suited only for Rubik's Cube. The new SAT solver
replaces the lookahead solving strategy with an ALO (\emph{at-least-one})
solving strategy, and decomposes the original problem into sub-problems. Each
sub-problem is solved by PrecoSAT. The empirical results demonstrate both our
SAT translation and new solving technique are efficient. Without the efficient
SAT encoding and the new solving technique, Rubik's Cube will not be able to be
solved still by any SAT solver. Using the improved SAT solver, we can find
always a solution of length 20 in a reasonable time. Although our solver is
slower than Kociemba's algorithm using lookup tables, but does not require a
huge lookup table.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1472</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1472</id><created>2011-05-07</created><authors><author><keyname>Jozwiak</keyname><forenames>G.</forenames></author><author><keyname>Henrykowski</keyname><forenames>A.</forenames></author><author><keyname>Masalska</keyname><forenames>A.</forenames></author><author><keyname>Gotszalk</keyname><forenames>T.</forenames></author><author><keyname>Ritz</keyname><forenames>I.</forenames></author><author><keyname>Steigmann</keyname><forenames>H.</forenames></author></authors><title>The regularized blind tip reconstruction algorithm as a scanning probe
  microscopy tip metrology method</title><categories>physics.ins-det cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of an accurate tip radius and shape characterization is very
important for determination of surface mechanical and chemical properties on
the basis of the scanning probe microscopy measurements. We think that the most
favorable methods for this purpose are blind tip reconstruction methods, since
they do not need any calibrated characterizers and might be performed on an
ordinary SPM setup. As in many other inverse problems also in case of these
methods the stability of the solution in presence of vibrational and electronic
noise needs application of so called regularization techniques. In this paper
the novel regularization technique (Regularized Blind Tip Reconstruction -
RBTR) for blind tip reconstruction algorithm is presented. It improves the
quality of the solution in presence of isotropic and anisotropic noise. The
superiority of our approach is proved on the basis of computer simulations and
analysis of images of the Budget Sensors TipCheck calibration standard. In case
of characterization of real AFM probes as a reference method the high
resolution scanning electron microscopy was chosen and we obtain good
qualitative correspondence of both methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1482</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1482</id><created>2011-05-07</created><authors><author><keyname>Choi</keyname><forenames>J. W.</forenames></author><author><keyname>Shim</keyname><forenames>B.</forenames></author><author><keyname>Singer</keyname><forenames>A. C.</forenames></author></authors><title>Efficient Soft-Input Soft-Output Tree Detection Via an Improved Path
  Metric</title><categories>cs.IT math.IT</categories><comments>16 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tree detection techniques are often used to reduce the complexity of a
posteriori probability (APP) detection in high dimensional multi-antenna
wireless communication systems. In this paper, we introduce an efficient
soft-input soft-output tree detection algorithm that employs a new type of
look-ahead path metric in the computation of its branch pruning (or sorting).
While conventional path metrics depend only on symbols on a visited path, the
new path metric accounts for unvisited parts of the tree in advance through an
unconstrained linear estimator and adds a bias term that reflects the
contribution of as-yet undecided symbols. By applying the linear estimate-based
look-ahead path metric to an M-algorithm that selects the best M paths for each
level of the tree we develop a new soft-input soft-output tree detector, called
an improved soft-input soft-output M-algorithm (ISS-MA). Based on an analysis
of the probability of correct path loss, we show that the improved path metric
offers substantial performance gain over the conventional path metric. We also
demonstrate through simulations that the ISS-MA provides a better
performance-complexity trade-off than existing soft-input soft-output detection
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1486</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1486</id><created>2011-05-07</created><authors><author><keyname>Megill</keyname><forenames>Norman D.</forenames></author><author><keyname>Pavicic</keyname><forenames>Mladen</forenames></author></authors><title>Estimating Bernoulli trial probability from a small sample</title><categories>cs.DC math.PR stat.CO</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard textbook method for estimating the probability of a biased coin
from finite tosses implicitly assumes the sample sizes are large and gives
incorrect results for small samples. We describe the exact solution, which is
correct for any sample size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1488</identifier>
 <datestamp>2014-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1488</id><created>2011-05-07</created><updated>2014-04-14</updated><authors><author><keyname>Dokuchaev</keyname><forenames>Nikolai</forenames></author></authors><title>The structure of optimal portfolio strategies for continuous time
  markets</title><categories>q-fin.PM cs.SY math.OC math.PR</categories><msc-class>93E20, 91G10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies problem of continuous time optimal portfolio selection for
a incom- plete market diffusion model. It is shown that, under some mild
conditions, near optimal strategies for investors with different performance
criteria can be constructed using a limited number of fixed processes (mutual
funds), for a market with a larger number of available risky stocks. In other
words, a dimension reduction is achieved via a relaxed version of the Mutual
Fund Theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1504</identifier>
 <datestamp>2014-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1504</id><created>2011-05-08</created><updated>2014-04-19</updated><authors><author><keyname>Mehta</keyname><forenames>Mahima</forenames></author><author><keyname>Aliu</keyname><forenames>Osianoh Glenn</forenames></author><author><keyname>Karandikar</keyname><forenames>Abhay</forenames></author><author><keyname>Imran</keyname><forenames>Muhammad Ali</forenames></author></authors><title>A Self-Organized Resource Allocation using Inter-Cell Interference
  Coordination (ICIC) in Relay-Assisted Cellular Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multi-cell scenario, the inter-cell interference (ICI) is detrimental in
achieving the intended system performance, in particular for the edge users.
There is paucity of work available in literature on ICI coordination (ICIC) for
relay-assisted cellular networks (RACN). In this paper, we do a survey on the
ICIC schemes in cellular networks and RACN. We then propose a self-organized
resource allocation plan for RACN to improve the edge user's performance by
ICIC. We compare the performance of reuse-1, reuse-3, soft frequency reuse
(SFR) scheme, proposed plan with and without relays. The performance metrics
for comparison are edge user's spectral efficiency, their
signal-to-interference-and-noise ratio (SINR) and system's area spectral
efficiency. We show by the simulation results that our proposed plan performs
better than the existing resource allocation schemes in static allocation
scenario. Next, we propose to make our resource allocation plan dynamic and
self-organized. The distinct features of our proposed plan are: One, it
achieves a trade-off between the system's area spectral efficiency and the edge
user's spectral efficiency performance. Secondly, it introduces a novel concept
of interfering neighbor set to achieve ICIC by local interaction between the
entities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1505</identifier>
 <datestamp>2011-07-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1505</id><created>2011-05-08</created><updated>2011-07-05</updated><authors><author><keyname>Gohari</keyname><forenames>Amin Aminzadeh</forenames></author><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author></authors><title>Generating Dependent Random Variables Over Networks</title><categories>cs.IT math.IT</categories><comments>26 pages, A shorter version was submitted to IEEE ITW 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of generation of dependent random
variables, known as the &quot;coordination capacity&quot; [4,5], in multiterminal
networks. In this model $m$ nodes of the network are observing i.i.d.
repetitions of $X^{(1)}$, $X^{(2)}$,..., $X^{(m)}$ distributed according to
$q(x^{(1)},...,x^{(m)})$. Given a joint distribution
$q(x^{(1)},...,x^{(m)},y^{(1)},...,y^{(m)})$, the final goal of the $i^{th}$
node is to construct the i.i.d. copies of $Y^{(i)}$ after the communication
over the network where $X^{(1)}$, $X^{(2)}$,..., $X^{(m)}, Y^{(1)}$,
$Y^{(2)}$,..., $Y^{(m)}$ are jointly distributed according to
$q(x^{(1)},...,x^{(m)},y^{(1)},...,y^{(m)})$. To do this, the nodes can
exchange messages over the network at rates not exceeding the capacity
constraints of the links. This problem is difficult to solve even for the
special case of two nodes. In this paper we prove new inner and outer bounds on
the achievable rates for networks with two nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1515</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1515</id><created>2011-05-08</created><authors><author><keyname>Pentikousis</keyname><forenames>Kostas</forenames></author><author><keyname>Ag&#xfc;ero</keyname><forenames>Ram&#xf3;n</forenames></author><author><keyname>Gebert</keyname><forenames>Jens</forenames></author><author><keyname>Galache</keyname><forenames>Jos&#xe9; Antonio</forenames></author><author><keyname>Blume</keyname><forenames>Oliver</forenames></author><author><keyname>P&#xe4;&#xe4;kk&#xf6;nen</keyname><forenames>Pekka</forenames></author></authors><title>The Ambient Networks Heterogeneous Access Selection Architecture</title><categories>cs.NI</categories><comments>Proc. First Ambient Networks Workshop on Mobility, Multiaccess, and
  Network Management (M2NM), Sydney, Australia, October 2007, pp. 49-54</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Forthcoming wireless communications will be characterized by the ubiquity of
multiaccess. Despite the inherently increased complexity, end-users should be
able to take advantage of the most suitable access network. Thus, access
selection in an environment with different overlapping radio technologies is of
central interest and an architecture is needed that performs equally well on
single- and multi-operator scenarios, considers several parameters, and
respects the principle of layering. In this paper, we introduce the Ambient
Networks heterogeneous access selection architecture explaining how it meets
such requirements. We present the essential architectural components and
explain their interactions. We illustrate how the proposed architecture works
in practice and discuss recent results form our prototype-based validation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1516</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1516</id><created>2011-05-08</created><authors><author><keyname>Blume</keyname><forenames>Oliver</forenames></author><author><keyname>Surtees</keyname><forenames>Abigail</forenames></author><author><keyname>Aguero</keyname><forenames>Ramon</forenames></author><author><keyname>Perera</keyname><forenames>Eranga</forenames></author><author><keyname>Pentikousis</keyname><forenames>Kostas</forenames></author></authors><title>A Generic Signaling Framework for Seamless Mobility in Heterogeneous
  Wireless Networks</title><categories>cs.NI</categories><comments>Proc. First Ambient Networks Workshop on Mobility, Multiaccess, and
  Network Management (M2NM), Sydney, Australia, October 2007, pp. 31-36</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years several wireless communication standards have been developed
and more are expected, each with different scope in terms of spatial coverage,
radio access capabilities, and mobility support. Heterogeneous networks combine
multiple of these radio interfaces both in network infrastructure and in user
equipment which requires a new multi-radio framework, enabling mobility and
handover management for multiple RATs. The use of heterogeneous networks can
capitalize on the overlapping coverage and allow user devices to take advantage
of the fact that there are multiple radio interfaces. This paper presents the
functional architecture for such a framework and proposes a generic signaling
exchange applicable to a range of different handover management protocols that
enables seamless mobility. The interworking of radio resource management,
access selection and mobility management is defined in a generic and modular
way, which is extensible for future protocols and standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1518</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1518</id><created>2011-05-08</created><authors><author><keyname>Eisl</keyname><forenames>Jochen</forenames></author><author><keyname>Georgiades</keyname><forenames>Michael</forenames></author><author><keyname>Jokikyyny</keyname><forenames>Tony</forenames></author><author><keyname>Boreli</keyname><forenames>Roksana</forenames></author><author><keyname>Perera</keyname><forenames>Eranga</forenames></author><author><keyname>Pentikousis</keyname><forenames>Kostas</forenames></author></authors><title>Management of Multiple Mobility Protocols and Tools in Dynamically
  Configurable Networks</title><categories>cs.NI</categories><comments>Proc. First Ambient Networks Workshop on Mobility, Multiaccess, and
  Network Management (M2NM), Sydney, Australia, October 2007, pp. 73-78</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Solutions for mobility management in wireless networks have been investigated
and proposed in various research projects and standardization bodies. With the
continuing deployment of different access networks, the wider range of
applications tailored for a mobile environment, and a larger diversity of
wireless end systems, it emerged that a single mobility protocol (such as
Mobile IP) is not sufficient to handle the different requirements adequately.
Thus a solution is needed to manage multiple mobility protocols in end systems
and network nodes, to detect and select the required protocols, versions and
optional features, and enable control on running daemons. For this purpose a
mobility toolbox has been developed as part of the EU funded Ambient Networks
project. This paper describes this modular management approach and illustrates
the additional benefits a mobility protocol can gain by using state transfer as
an example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1520</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1520</id><created>2011-05-08</created><authors><author><keyname>Xie</keyname><forenames>Kai</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Jing</keyname><affiliation>Tiffany</affiliation></author><author><keyname>Li</keyname></author></authors><title>Linear Analog Codes: The Good and The Bad</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to IEEE Globecom 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the theory of linear analog error correction coding. Since
classical concepts of minimum Hamming distance and minimum Euclidean distance
fail in the analog context, a new metric, termed the &quot;minimum (squared
Euclidean) distance ratio,&quot; is defined. It is shown that linear analog codes
that achieve the largest possible value of minimum distance ratio also achieve
the smallest possible mean square error (MSE). Based on this achievability, a
concept of &quot;maximum distance ratio expansible (MDRE)&quot; is established, in a
spirit similar to maximum distance separable (MDS). Existing codes are
evaluated, and it is shown that MDRE and MDS can be simultaneously achieved
through careful design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1534</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1534</id><created>2011-05-08</created><authors><author><keyname>Sperl</keyname><forenames>Thomas</forenames></author></authors><title>Taking the redpill: Artificial Evolution in native x86 systems</title><categories>cs.NE q-bio.PE</categories><comments>21 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In analogon to successful artificial evolution simulations as Tierra or
avida, this text presents a way to perform artificial evolution in a native x86
system. The implementation of the artificial chemistry and first results of
statistical experiments are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1541</identifier>
 <datestamp>2012-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1541</id><created>2011-05-08</created><updated>2011-06-09</updated><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>An Analysis of Routing Disruption Attack on Dynamic Source Routing
  Protocol</title><categories>cs.CR cs.NI</categories><comments>This paper is withdrawn since the results of simulations presented
  are found to erroneous under certain network topologies. We have corrected
  the mathematical model and have submitted the corrected version to a
  journal.)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamic Source Routing (DSR) is a well known source routing protocol for ad
hoc networks. The algorithm depends on the cooperative participation of the
nodes that enables route discovery from a source node to a destination node.
However, if a group of nodes do not cooperate, the performance of the DSR
protocol may be severely degraded. This paper presents a probabilistic attack
model on the DSR protocol and analyses its effect on the routing performance.
Simulations results of the model show that the effect of the attack is
catastrophic only if a large number of nodes are compromised and there is no
detection mechanism. As an interesting observation, the analysis also shows
that the attack model can also be used to improve the performance of the DSR
protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1561</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1561</id><created>2011-05-08</created><updated>2011-08-03</updated><authors><author><keyname>Liu</keyname><forenames>Yang</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Jing</keyname><affiliation>Tiffany</affiliation></author><author><keyname>Li</keyname></author><author><keyname>Xie</keyname><forenames>Kai</forenames></author></authors><title>Efficient Image Transmission Through Analog Error Correction</title><categories>cs.MM</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new paradigm for image transmission through analog
error correction codes. Conventional schemes rely on digitizing images through
quantization (which inevitably causes significant bandwidth expansion) and
transmitting binary bit-streams through digital error correction codes (which
do not automatically differentiate the different levels of significance among
the bits). To strike a better overall performance in terms of transmission
efficiency and quality, we propose to use a single analog error correction code
in lieu of digital quantization, digital code and digital modulation. The key
is to get analog coding right. We show that this can be achieved by cleverly
exploiting an elegant &quot;butterfly&quot; property of chaotic systems. Specifically, we
demonstrate a tail-biting triple-branch baker's map code and its
maximum-likelihood decoding algorithm. Simulations show that the proposed
analog code can actually outperform digital turbo code, one of the best codes
known to date. The results and findings discussed in this paper speak volume
for the promising potential of analog codes, in spite of their rather short
history.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1562</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1562</id><created>2011-05-08</created><authors><author><keyname>Puttarak</keyname><forenames>Nattakan</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Kaewprapha</keyname><forenames>Phisan</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Ng</keyname><forenames>Boon Chong</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Jing</keyname><affiliation>Tiffany</affiliation></author><author><keyname>Li</keyname></author></authors><title>A New Class of MDS Erasure Codes Based on Graphs</title><categories>cs.IT math.IT</categories><comments>in Proceeding of IEEE Global Communications Conference (GLOBECOM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum distance separable (MDS) array codes are XOR-based optimal erasure
codes that are particularly suitable for use in disk arrays. This paper
develops an innovative method to build MDS array codes from an elegant class of
nested graphs, termed \textit{complete-graph-of-rings (CGR)}. We discuss a
systematic and concrete way to transfer these graphs to array codes, unveil an
interesting relation between the proposed map and the renowned perfect
1-factorization, and show that the proposed CGR codes subsume B-codes as their
&quot;contracted&quot; codes. These new codes, termed \textit{CGR codes}, and their dual
codes are simple to describe, and require minimal encoding and decoding
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1564</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1564</id><created>2011-05-08</created><authors><author><keyname>Briscoe</keyname><forenames>Gerard</forenames></author></authors><title>Complex Adaptive Digital EcoSystems</title><categories>cs.MA</categories><comments>8 pages, 12 figures, conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate an abstract conceptualisation of DigitalEcosystems from a
computer science perspective. We then provide a conceptual framework for the
cross pollination of ideas, concepts and understanding between different
classes of ecosystems through the universally applicable principles of Complex
Adaptive Systems (CAS) modelling. A framework to assist the cross-disciplinary
collaboration of research into Digital Ecosystems, including Digital
BusinessEcosystems (DBEs) and Digital Knowledge Ecosystems (DKEs). So, we have
defined the key steps towards a theoretical framework for Digital Ecosystems,
that is compatible with the diverse theoretical views prevalent. Therefore, a
theoretical edifice that can unify the diverse efforts within Digital
Ecosystems research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1569</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1569</id><created>2011-05-08</created><authors><author><keyname>Chandran</keyname><forenames>Bala G.</forenames></author><author><keyname>Hochbaum</keyname><forenames>Dorit S.</forenames></author></authors><title>Practical and theoretical improvements for bipartite matching using the
  pseudoflow algorithm</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the pseudoflow algorithm for maximum flow is particularly
efficient for the bipartite matching problem both in theory and in practice. We
develop several implementations of the pseudoflow algorithm for bipartite
matching, and compare them over a wide set of benchmark instances to
state-of-the-art implementations of push-relabel and augmenting path algorithms
that are specifically designed to solve these problems. The experiments show
that the pseudoflow variants are in most cases faster than the other
algorithms.
  We also show that one particular implementation---the matching pseudoflow
algorithm---is theoretically efficient. For a graph with $n$ nodes, $m$ arcs,
$n_1$ the size of the smaller set in the bipartition, and the maximum matching
value $\kappa \leq n_1$, the algorithm's complexity given input in the form of
adjacency lists is $O(\min{n_1\kappa,m} + \sqrt{\kappa}\min{\kappa^2,m})$.
Similar algorithmic ideas are shown to work for an adaptation of Hopcroft and
Karp's bipartite matching algorithm with the same complexity. Using boolean
operations on words of size $\lambda$, the complexity of the pseudoflow
algorithm is further improved to $O(\min{n_1\kappa, \frac{n_1n_2}{\lambda}, m}
+ \kappa^2 + \frac{\kappa^{2.5}}{\lambda})$. This run time is faster than for
previous algorithms such as Cheriyan and Mehlhorn's algorithm of complexity
$O(\frac{n^{2.5}}{\lambda})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1572</identifier>
 <datestamp>2012-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1572</id><created>2011-05-08</created><updated>2011-06-01</updated><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author><author><keyname>Chowdhury</keyname><forenames>Piyali Roy</forenames></author><author><keyname>Sengupta</keyname><forenames>Indranil</forenames></author></authors><title>Some Aspects of Quantum Cryptography and Network Security</title><categories>cs.CR cs.NI</categories><comments>This was withdrawn because the key distribution figures Figure 1 and
  3 in the paper are technically incorrect</comments><journal-ref>International Journal HIT Transaction on ECCN (Electronics,
  Communication, Computers and Networking), pp. 27-36. Volume 1, No: 1, January
  2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum mechanics is the current best description of the world as we know it.
Experiments have shown that quantum predictions are accurate up ten places of
decimal. In quantum cryptography much work has been devoted to the study of
Quantum Key Distribution (QKD). The purpose of QKD is to securely distribute
secret keys between the users in a network. As a result, several quantum
cryptographic protocols have been implemented and tested after the advent of
quantum computing. In this paper, we have given a brief overview of QKD, and
some practical networks that integrate QKD in the current Internet security
architecture. We have also discussed some aspects of quantum network security
with particular attention to Byzantine Agreement Protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1574</identifier>
 <datestamp>2012-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1574</id><created>2011-05-08</created><updated>2011-08-03</updated><authors><author><keyname>Vladimirov</keyname><forenames>Igor G.</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>A Dynamic Programming Approach to Finite-horizon Coherent Quantum LQG
  Control</title><categories>quant-ph cs.SY math.DS math.OC</categories><comments>22 pages, 1 figure; a brief version of this paper has been accepted
  for publication in the Proceedings of the Australian Control Conference,
  10-11 November 2011, Melbourne, Australia</comments><msc-class>81Q93, 81S25, 93E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is concerned with the coherent quantum Linear Quadratic Gaussian
(CQLQG) control problem for time-varying quantum plants governed by linear
quantum stochastic differential equations over a bounded time interval. A
controller is sought among quantum linear systems satisfying physical
realizability (PR) conditions. The latter describe the dynamic equivalence of
the system to an open quantum harmonic oscillator and relate its state-space
matrices to the free Hamiltonian, coupling and scattering operators of the
oscillator. Using the Hamiltonian parameterization of PR controllers, the CQLQG
problem is recast into an optimal control problem for a deterministic system
governed by a differential Lyapunov equation. The state of this subsidiary
system is the symmetric part of the quantum covariance matrix of the
plant-controller state vector. The resulting covariance control problem is
treated using dynamic programming and Pontryagin's minimum principle. The
associated Hamilton-Jacobi-Bellman equation for the minimum cost function
involves Frechet differentiation with respect to matrix-valued variables. The
gain matrices of the CQLQG optimal controller are shown to satisfy a
quasi-separation property as a weaker quantum counterpart of the
filtering/control decomposition of classical LQG controllers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1586</identifier>
 <datestamp>2013-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1586</id><created>2011-05-09</created><updated>2011-06-05</updated><authors><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>Treewidth of Cartesian Products of Highly Connected Graphs</title><categories>math.CO cs.DM</categories><journal-ref>J. Graph Theory 73.3:318-321, 2013</journal-ref><doi>10.1002/jgt.21677</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The following theorem is proved: For all $k$-connected graphs $G$ and $H$
each with at least $n$ vertices, the treewidth of the cartesian product of $G$
and $H$ is at least $k(n -2k+2)-1$. For $n\gg k$ this lower bound is
asymptotically tight for particular graphs $G$ and $H$. This theorem
generalises a well known result about the treewidth of planar grid graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1595</identifier>
 <datestamp>2012-04-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1595</id><created>2011-05-09</created><updated>2012-04-23</updated><authors><author><keyname>Arratia</keyname><forenames>Argimiro</forenames></author><author><keyname>Mariju&#xe1;n</keyname><forenames>Carlos</forenames></author></authors><title>Ranking pages and the topology of the web</title><categories>cs.DM math.CO</categories><comments>27 pages, 5 figures. Revised version. Corrected some typos, and
  improve the presentation on the bidirectional case and further complex
  structures (section 8 and on): we extend the fmla for PR to any general
  bidirectional trees by considering the contribution to PR of the additional
  structure hanging from the end nodes of bidirectional arcs (the subtrees)</comments><msc-class>05C99, 68R10, 94C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents our studies on the rearrangement of links from the
structure of websites for the purpose of improving the valuation of a page or
group of pages as established by a ranking function as Google's PageRank. We
build our topological taxonomy starting from unidirectional and bidirectional
rooted trees, and up to more complex hierarchical structures as cyclical rooted
trees (obtained by closing cycles on bidirectional trees) and PR--digraph
rooted trees (digraphs whose condensation digraph is a rooted tree that behave
like cyclical rooted trees). We give different modifications on the structure
of these trees and its effect on the valuation given by the PageRank function.
We derive closed formulas for the PageRank of the root of various types of
trees, and establish a hierarchy of these topologies in terms of PageRank. We
show that the PageRank of the root of cyclical and PR--digraph trees basically
depends on the number of vertices per level and the number of cycles of
distinct lengths among levels, and we give a closed vector formula to compute
PageRank.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1601</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1601</id><created>2011-05-09</created><updated>2011-05-10</updated><authors><author><keyname>Bringer</keyname><forenames>Julien</forenames></author><author><keyname>Chabanne</keyname><forenames>Herv&#xe9;</forenames></author></authors><title>Code Reverse Engineering problem for Identification Codes</title><categories>cs.CR cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory on January,
  25th, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At ITW'10, Bringer et al. suggest to strengthen their previous identification
protocol by extending the Code Reverse Engineering (CRE) problem to
identification codes. We first extend security results by Tillich et al. on
this very problem. We then prove the security of this protocol using
information theoretical arguments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1622</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1622</id><created>2011-05-09</created><authors><author><keyname>De Marco</keyname><forenames>Gianluca</forenames></author><author><keyname>Kranakis</keyname><forenames>Evangelos</forenames></author><author><keyname>Wiener</keyname><forenames>Gabor</forenames></author></authors><title>Computing Majority with Triple Queries</title><categories>cs.DS</categories><comments>22 pages, 1 figure, conference version to appear in proceedings of
  the 17th Annual International Computing and Combinatorics Conference (COCOON
  2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a bin containing $n$ balls colored with two colors. In a $k$-query,
$k$ balls are selected by a questioner and the oracle's reply is related
(depending on the computation model being considered) to the distribution of
colors of the balls in this $k$-tuple; however, the oracle never reveals the
colors of the individual balls. Following a number of queries the questioner is
said to determine the majority color if it can output a ball of the majority
color if it exists, and can prove that there is no majority if it does not
exist. We investigate two computation models (depending on the type of replies
being allowed). We give algorithms to compute the minimum number of 3-queries
which are needed so that the questioner can determine the majority color and
provide tight and almost tight upper and lower bounds on the number of queries
needed in each case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1633</identifier>
 <datestamp>2011-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1633</id><created>2011-05-09</created><updated>2011-11-08</updated><authors><author><keyname>B&#xe9;chennec</keyname><forenames>Jean-Luc</forenames></author><author><keyname>Cassez</keyname><forenames>Franck</forenames></author></authors><title>Computation of WCET using Program Slicing and Real-Time Model-Checking</title><categories>cs.SE</categories><comments>31 pages. Extended with slicing and other minor changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing accurate WCET on modern complex architectures is a challenging
task. This problem has been devoted a lot of attention in the last decade but
there are still some open issues. First, the control flow graph (CFG) of a
binary program is needed to compute the WCET and this CFG is built using some
internal knowledge of the compiler that generated the binary code; moreover
once constructed the CFG has to be manually annotated with loop bounds. Second,
the algorithms to compute the WCET (combining Abstract Interpretation and
Integer Linear Programming) are tailored for specific architectures: changing
the architecture (e.g. replacing an ARM7 by an ARM9) requires the design of a
new ad hoc algorithm. Third, the tightness of the computed results (obtained
using the available tools) are not compared to actual execution times measured
on the real hardware. In this paper we address the above mentioned problems. We
first describe a fully automatic method to compute a CFG based solely on the
binary program to analyse. Second, we describe the model of the hardware as a
product of timed automata, and this model is independent from the program
description. The model of a program running on a hardware is obtained by
synchronizing (the automaton of) the program with the (timed automata) model of
the hardware. Computing the WCET is reduced to a reachability problem on the
synchronised model and solved using the model-checker UPPAAL. Finally, we
present a rigorous methodology that enables us to compare our computed results
to actual execution times measured on a real platform, the ARM920T.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1639</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1639</id><created>2011-05-09</created><authors><author><keyname>Yu</keyname><forenames>Yong</forenames></author><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Guizhen</forenames></author></authors><title>List (d,1)-total labelling of graphs embedded in surfaces</title><categories>math.CO cs.DM</categories><comments>6 pages</comments><msc-class>05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The (d,1)-total labelling of graphs was introduced by Havet and Yu. In this
paper, we consider the list version of (d,1)-total labelling of graphs. Let G
be a graph embedded in a surface with Euler characteristic $\epsilon$ whose
maximum degree $\Delta(G)$ is sufficiently large. We prove that the (d,1)-total
choosability $C_{d,1}^T(G)$ of $G$ is at most $\Delta(G)+2d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1641</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1641</id><created>2011-05-09</created><authors><author><keyname>Magoc</keyname><forenames>Tanja</forenames></author><author><keyname>Magoc</keyname><forenames>Dejan</forenames></author></authors><title>Neural network to identify individuals at health risk</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The risk of diseases such as heart attack and high blood pressure could be
reduced by adequate physical activity. However, even though majority of general
population claims to perform some physical exercise, only a minority exercises
enough to keep a healthy living style. Thus, physical inactivity has become one
of the major concerns of public health in the past decade. Research shows that
the highest decrease in physical activity is noticed from high school to
college. Thus, it is of great importance to quickly identify college students
at health risk due to physical inactivity. Research also shows that the level
of physical activity of an individual is highly correlated to demographic
features such as race and gender, as well as self motivation and support from
family and friends. This information could be collected from each student via a
20 minute questionnaire, but the time needed to distribute and analyze each
questionnaire is infeasible on a collegiate campus. Thus, we propose an
automatic identifier of students at risk, so that these students could easier
be targeted by collegiate campuses and physical activity promotion departments.
We present in this paper preliminary results of a supervised backpropagation
multilayer neural network for classifying students into at-risk or not at-risk
group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1651</identifier>
 <datestamp>2011-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1651</id><created>2011-05-09</created><updated>2011-07-11</updated><authors><author><keyname>Huang</keyname><forenames>Haiping</forenames></author><author><keyname>Zhou</keyname><forenames>Haijun</forenames></author></authors><title>Combined local search strategy for learning in networks of binary
  synapses</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT</categories><comments>7 pages, 4 figures, figures and references added</comments><journal-ref>EPL, 96 (2011) 58003</journal-ref><doi>10.1209/0295-5075/96/58003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning in networks of binary synapses is known to be an NP-complete
problem. A combined stochastic local search strategy in the synaptic weight
space is constructed to further improve the learning performance of a single
random walker. We apply two correlated random walkers guided by their Hamming
distance and associated energy costs (the number of unlearned patterns) to
learn a same large set of patterns. Each walker first learns a small part of
the whole pattern set (partially different for both walkers but with the same
amount of patterns) and then both walkers explore their respective weight
spaces cooperatively to find a solution to classify the whole pattern set
correctly. The desired solutions locate at the common parts of weight spaces
explored by these two walkers. The efficiency of this combined strategy is
supported by our extensive numerical simulations and the typical Hamming
distance as well as energy cost is estimated by an annealed computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1657</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1657</id><created>2011-05-09</created><updated>2012-01-16</updated><authors><author><keyname>Atig</keyname><forenames>Mohamed Faouzi</forenames></author><author><keyname>Ganty</keyname><forenames>Pierre</forenames></author></authors><title>Approximating Petri Net Reachability Along Context-free Traces</title><categories>cs.FL cs.LO</categories><comments>16 pages</comments><doi>10.4230/LIPIcs.FSTTCS.2011.152</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem asking whether the intersection of a context-free
language (CFL) and a Petri net language (PNL) is empty. Our contribution to
solve this long-standing problem which relates, for instance, to the
reachability analysis of recursive programs over unbounded data domain, is to
identify a class of CFLs called the finite-index CFLs for which the problem is
decidable. The k-index approximation of a CFL can be obtained by discarding all
the words that cannot be derived within a budget k on the number of occurrences
of non-terminals. A finite-index CFL is thus a CFL which coincides with its
k-index approximation for some k. We decide whether the intersection of a
finite-index CFL and a PNL is empty by reducing it to the reachability problem
of Petri nets with weak inhibitor arcs, a class of systems with infinitely many
states for which reachability is known to be decidable. Conversely, we show
that the reachability problem for a Petri net with weak inhibitor arcs reduces
to the emptiness problem of a finite-index CFL intersected with a PNL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1658</identifier>
 <datestamp>2013-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1658</id><created>2011-05-09</created><updated>2013-11-08</updated><authors><author><keyname>Villard</keyname><forenames>Joffrey</forenames></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author></authors><title>Secure Multiterminal Source Coding with Side Information at the
  Eavesdropper</title><categories>cs.IT math.IT</categories><comments>26 pages, 16 figures, 2 tables</comments><journal-ref>Information Theory, IEEE Transactions on , vol.59, no.6,
  pp.3668,3692, June 2013</journal-ref><doi>10.1109/TIT.2013.2245394</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of secure multiterminal source coding with side information at
the eavesdropper is investigated. This scenario consists of a main encoder
(referred to as Alice) that wishes to compress a single source but
simultaneously satisfying the desired requirements on the distortion level at a
legitimate receiver (referred to as Bob) and the equivocation rate --average
uncertainty-- at an eavesdropper (referred to as Eve). It is further assumed
the presence of a (public) rate-limited link between Alice and Bob. In this
setting, Eve perfectly observes the information bits sent by Alice to Bob and
has also access to a correlated source which can be used as side information. A
second encoder (referred to as Charlie) helps Bob in estimating Alice's source
by sending a compressed version of its own correlated observation via a
(private) rate-limited link, which is only observed by Bob. For instance, the
problem at hands can be seen as the unification between the Berger-Tung and the
secure source coding setups. Inner and outer bounds on the so called
rates-distortion-equivocation region are derived. The inner region turns to be
tight for two cases: (i) uncoded side information at Bob and (ii) lossless
reconstruction of both sources at Bob --secure distributed lossless
compression. Application examples to secure lossy source coding of Gaussian and
binary sources in the presence of Gaussian and binary/ternary (resp.) side
informations are also considered. Optimal coding schemes are characterized for
some cases of interest where the statistical differences between the side
information at the decoders and the presence of a non-zero distortion at Bob
can be fully exploited to guarantee secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1668</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1668</id><created>2011-05-09</created><authors><author><keyname>Cai</keyname><forenames>Kai</forenames></author><author><keyname>Ishii</keyname><forenames>Hideaki</forenames></author></authors><title>Convergence Time Analysis of Quantized Gossip Consensus on Digraphs</title><categories>cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have recently proposed quantized gossip algorithms which solve the
consensus and averaging problems on directed graphs with the least restrictive
connectivity requirements. In this paper we study the convergence time of these
algorithms. To this end, we investigate the shrinking time of the smallest
interval that contains all states for the consensus algorithm, and the decay
time of a suitable Lyapunov function for the averaging algorithm. The
investigation leads us to characterizing the convergence time by the hitting
time in certain special Markov chains. We simplify the structures of state
transition by considering the special case of complete graphs, where every edge
can be activated with an equal probability, and derive polynomial upper bounds
on convergence time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1693</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1693</id><created>2011-05-09</created><authors><author><keyname>Bandyopadhyay</keyname><forenames>Debasis</forenames></author><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>Internet of Things: Applications and Challenges in Technology and
  Standardization</title><categories>cs.CY cs.NI</categories><comments>24 pages, 3 figures; Special Issue: Distributed and Secure Cloud
  Clustering (DISC)</comments><journal-ref>Springer International Journal of Wireless Personal
  Communications, Vol. 58, No. 1, pp. 49 -- 69, May 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The phrase Internet of Things (IoT) heralds a vision of the future Internet
where connecting physical things, from banknotes to bicycles, through a network
will let them take an active part in the Internet, exchanging information about
themselves and their surroundings. This will give immediate access to
information about the physical world and the objects in it leading to
innovative services and increase in efficiency and productivity. This paper
studies the state-of-the-art of IoT and presents the key technological
drivers,potential applications, challenges and future research areas in the
domain of IoT. IoT definitions from different perspective in academic and
industry communities are also discussed and compared. Finally some major issues
of future research in IoT are identified and discussed briefly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1697</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1697</id><created>2011-05-09</created><updated>2012-06-06</updated><authors><author><keyname>Kovacs</keyname><forenames>Edith</forenames></author><author><keyname>Szantai</keyname><forenames>Tamas</forenames></author></authors><title>Vine copulas as a mean for the construction of high dimensional
  probability distribution associated to a Markov Network</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>the paper will be presented at the 4th Workshop on Vine Copula
  Distributions and Applications, May 11-12, 2011, Technische Universitat
  Muenchen</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building higher-dimensional copulas is generally recognized as a difficult
problem. Regular-vines using bivariate copulas provide a flexible class of
high-dimensional dependency models. In large dimensions, the drawback of the
model is the exponentially increasing complexity. Recognizing some of the
conditional independences is a possibility for reducing the number of levels of
the pair-copula decomposition, and hence to simplify its construction Aas et al
(2009). The idea of using conditional independences was already performed under
elliptical copula assumptions Hanea, Kurowicka and Cooke (2006), Kurowicka and
Cooke (2002) and in the case of DAGs in a recent work Bauer, Czado and Klein
(2011). We provide a method which uses some of the conditional independences
encoded by the Markov network underlying the variables. We give a theorem which
under some graph conditions makes possible to derive pair-copula decomposition
of the probability density function associated to a Markov network. As the
underlying Markov network is usually unknown, we first have to discover it from
the sample data. Using our results published in Szantai and Kovacs (2008) and
Kovacs and Szantai (2010a) we will show how to derive a multidimensional copula
model exploiting the information on conditional independences hidden in the
sample data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1702</identifier>
 <datestamp>2011-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1702</id><created>2011-05-09</created><updated>2011-06-07</updated><authors><author><keyname>Sadrzadeh</keyname><forenames>Mehrnoosh</forenames></author><author><keyname>Grefenstette</keyname><forenames>Edward</forenames></author></authors><title>A Compositional Distributional Semantics, Two Concrete Constructions,
  and some Experimental Evaluations</title><categories>cs.CL math.CT</categories><comments>13 pages, to be presented at QI'11, to be published in LNCS
  (Springer)</comments><msc-class>68T50</msc-class><acm-class>G.1.3; H.3.1; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an overview of the hybrid compositional distributional model of
meaning, developed in Coecke et al. (arXiv:1003.4394v1 [cs.CL]), which is based
on the categorical methods also applied to the analysis of information flow in
quantum protocols. The mathematical setting stipulates that the meaning of a
sentence is a linear function of the tensor products of the meanings of its
words. We provide concrete constructions for this definition and present
techniques to build vector spaces for meaning vectors of words, as well as that
of sentences. The applicability of these methods is demonstrated via a toy
vector space as well as real data from the British National Corpus and two
disambiguation experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1704</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1704</id><created>2011-04-26</created><authors><author><keyname>Skvortsov</keyname><forenames>Evgeny</forenames></author><author><keyname>Tipikin</keyname><forenames>Evgeny</forenames></author></authors><title>Experimental Study of the Shortest Reset Word of Random Automata</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe an approach to finding the shortest reset word of a
finite synchronizing automaton by using a SAT solver. We use this approach to
perform an experimental study of the length of the shortest reset word of a
finite synchronizing automaton. The largest automata we considered had 100
states. The results of the experiments allow us to formulate a hypothesis that
the length of the shortest reset word of a random finite automaton with $n$
states and 2 input letters with high probability is sublinear with respect to
$n$ and can be estimated as $1.95 n^{0.55}.$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1720</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1720</id><created>2011-05-09</created><authors><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author><author><keyname>Mirza</keyname><forenames>Abdulrahman</forenames></author></authors><title>Software Vulnerabilities, Banking Threats, Botnets and Malware
  Self-Protection Technologies</title><categories>cs.NI cs.CR cs.IT math.IT</categories><comments>5 pages</comments><msc-class>www.IJCSI.org</msc-class><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 1, January 2011, 236-241</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information security is the protection of information from a wide range of
threats in order to ensure success business continuity by minimizing risks and
maximizing the return of investments and business opportunities. In this paper,
we study and discuss the software vulnerabilities, banking threats, botnets and
propose the malware self-protection technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1728</identifier>
 <datestamp>2011-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1728</id><created>2011-05-09</created><updated>2011-11-15</updated><authors><author><keyname>Sarychev</keyname><forenames>Andrey</forenames></author></authors><title>Controllability of the cubic Schroedinger equation via a low-dimensional
  source term</title><categories>math.OC cs.SY math.AP</categories><comments>28 pages; added references; substantial change of main results,
  formulated now for NLS on a torus of arbitrary dimension</comments><msc-class>93B05 (Primary) 93C20, 35Q55, 93B27 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study controllability of $d$-dimensional defocusing cubic Schroedinger
equation under periodic boundary conditions. The control is applied additively,
via a source term, which is a linear combination of few complex exponentials
(modes) with time-variant coefficients - controls. We manage to prove that
controlling at most $2^d$ modes one can achieve controllability of the equation
in any finite-dimensional projection of the evolution space
$H^{s}(\mathbb{T}^d), \ s&gt;d/2$, as well as approximate controllability in
$H^{s}(\mathbb{T}^d)$. We also present negative result regarding exact
controllability of cubic Schroedinger equation via a finite-dimensional source
term.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1733</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1733</id><created>2011-05-09</created><updated>2011-07-17</updated><authors><author><keyname>Abbas</keyname><forenames>Houssam</forenames></author><author><keyname>Fainekos</keyname><forenames>Georgios</forenames></author></authors><title>Linear Hybrid System Falsification With Descent</title><categories>cs.SY math.OC</categories><comments>Tech report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of local search for the falsification
of hybrid automata with affine dynamics. Namely, if we are given a sequence of
locations and a maximum simulation time, we return the trajectory that comes
the closest to the unsafe set. In order to solve this problem, we formulate it
as a differentiable optimization problem which we solve using Sequential
Quadratic Programming. The purpose of developing such a local search method is
to combine it with high level stochastic optimization algorithms in order to
falsify hybrid systems with complex discrete dynamics and high dimensional
continuous spaces. Experimental results indicate that indeed the local search
procedure improves upon the results of pure stochastic optimization algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1736</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1736</id><created>2011-05-09</created><authors><author><keyname>Mohanty</keyname><forenames>Rakesh</forenames></author><author><keyname>Behera</keyname><forenames>H. S.</forenames></author><author><keyname>Patwari</keyname><forenames>Khusbu</forenames></author><author><keyname>Dash</keyname><forenames>Monisha</forenames></author><author><keyname>Prasanna</keyname><forenames>M. Lakshmi</forenames></author></authors><title>Priority Based Dynamic Round Robin (PBDRR) Algorithm with Intelligent
  Time Slice for Soft Real Time Systems</title><categories>cs.OS</categories><comments>5 pages</comments><journal-ref>International Journal of Advanced Computer Science and
  Applications(IJACSA), Vol. 2 No. 2, February 2011 2011, 46-50</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a new variant of Round Robin (RR) algorithm is proposed which
is suitable for soft real time systems. RR algorithm performs optimally in
timeshared systems, but it is not suitable for soft real time systems. Because
it gives more number of context switches, larger waiting time and larger
response time. We have proposed a novel algorithm, known as Priority Based
Dynamic Round Robin Algorithm(PBDRR),which calculates intelligent time slice
for individual processes and changes after every round of execution. The
proposed scheduling algorithm is developed by taking dynamic time quantum
concept into account. Our experimental results show that our proposed algorithm
performs better than algorithm in [8] in terms of reducing the number of
context switches, average waiting time and average turnaround time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1743</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1743</id><created>2011-05-09</created><authors><author><keyname>Van Horn</keyname><forenames>David</forenames></author><author><keyname>Might</keyname><forenames>Matthew</forenames></author></authors><title>Abstracting Abstract Machines: A Systematic Approach to Higher-Order
  Program Analysis</title><categories>cs.PL</categories><comments>Communications of the ACM, Research Highlight</comments><acm-class>F.3.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predictive models are fundamental to engineering reliable software systems.
However, designing conservative, computable approximations for the behavior of
programs (static analyses) remains a difficult and error-prone process for
modern high-level programming languages. What analysis designers need is a
principled method for navigating the gap between semantics and analytic models:
analysis designers need a method that tames the interaction of complex
languages features such as higher-order functions, recursion, exceptions,
continuations, objects and dynamic allocation.
  We contribute a systematic approach to program analysis that yields novel and
transparently sound static analyses. Our approach relies on existing
derivational techniques to transform high-level language semantics into
low-level deterministic state-transition systems (with potentially infinite
state spaces). We then perform a series of simple machine refactorings to
obtain a sound, computable approximation, which takes the form of a
non-deterministic state-transition systems with finite state spaces. The
approach scales up uniformly to enable program analysis of realistic language
features, including higher-order functions, tail calls, conditionals, side
effects, exceptions, first-class continuations, and even garbage collection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1745</identifier>
 <datestamp>2011-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1745</id><created>2011-05-09</created><authors><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>Analysis of Alternative Metrics for the PAPR Problem in OFDM
  Transmission</title><categories>cs.IT math.IT</categories><comments>5 pages, IEEE International Symposium on Information Theory (ISIT),
  2011, accepted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effective PAPR of the transmit signal is the standard metric to capture
the effect of nonlinear distortion in OFDM transmission. A common rule of thumb
is the log$(N)$ barrier where $N$ is the number of subcarriers which has been
theoretically analyzed by many authors. Recently, new alternative metrics have
been proposed in practice leading potentially to different system design rules
which are theoretically analyzed in this paper. One of the main findings is
that, most surprisingly, the log$(N)$ barrier turns out to be much too
conservative: e.g. for the so-called amplifier-oriented metric the scaling is
rather $\log[ \log(N)]$. To prove this result, new upper bounds on the PAPR
distribution for coded systems are presented as well as a theorem relating PAPR
results to these alternative metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1749</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1749</id><created>2011-05-09</created><updated>2011-05-21</updated><authors><author><keyname>Hester</keyname><forenames>Todd</forenames></author><author><keyname>Quinlan</keyname><forenames>Michael</forenames></author><author><keyname>Stone</keyname><forenames>Peter</forenames></author></authors><title>A Real-Time Model-Based Reinforcement Learning Architecture for Robot
  Control</title><categories>cs.AI cs.RO cs.SE</categories><comments>Added a reference Presents a real-time parallel architecture for
  model-based reinforcement learning methods</comments><acm-class>D.2.11; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reinforcement Learning (RL) is a method for learning decision-making tasks
that could enable robots to learn and adapt to their situation on-line. For an
RL algorithm to be practical for robotic control tasks, it must learn in very
few actions, while continually taking those actions in real-time. Existing
model-based RL methods learn in relatively few actions, but typically take too
much time between each action for practical on-line learning. In this paper, we
present a novel parallel architecture for model-based RL that runs in real-time
by 1) taking advantage of sample-based approximate planning methods and 2)
parallelizing the acting, model learning, and planning processes such that the
acting process is sufficiently fast for typical robot control cycles. We
demonstrate that algorithms using this architecture perform nearly as well as
methods using the typical sequential architecture when both are given unlimited
time, and greatly out-perform these methods on tasks that require real-time
actions such as controlling an autonomous vehicle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1767</identifier>
 <datestamp>2011-09-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1767</id><created>2011-05-09</created><updated>2011-09-11</updated><authors><author><keyname>Pinheiro</keyname><forenames>D.</forenames></author><author><keyname>Pinto</keyname><forenames>A. A.</forenames></author><author><keyname>Xanthopoulos</keyname><forenames>S. Z.</forenames></author><author><keyname>Yannacopoulos</keyname><forenames>A. N.</forenames></author></authors><title>A projected gradient dynamical system modeling the dynamics of
  bargaining</title><categories>q-fin.TR cs.SY math.DS math.OC</categories><comments>31 pages, 6 figures</comments><msc-class>37N40, 91B26, 91B24, 90C30, 90C31</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a projected gradient dynamical system as a model for a bargaining
scheme for an asset for which the two interested agents have personal
valuations which do not initially coincide. The personal valuations are formed
using subjective beliefs concerning the future states of the world and the
reservation prices are calculated using expected utility theory. The agents are
not rigid concerning their subjective probabilities and are willing to update
them under the pressure to reach finally an agreement concerning the asset. The
proposed projected dynamical system, on the space of probability measures,
provides a model for the evolution of the agents beliefs during the bargaining
period and is constructed so that agreement is reached under the minimum
possible deviation of both agents from their initial beliefs. The convergence
results are shown using techniques from convex dynamics and Lyapunov function
theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1811</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1811</id><created>2011-05-09</created><authors><author><keyname>Douglas</keyname><forenames>Niall</forenames></author></authors><title>User Mode Memory Page Allocation: A Silver Bullet For Memory Allocation?</title><categories>cs.OS cs.PF</categories><comments>10 pages. Rejected from ISMM11</comments><acm-class>D.4.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This paper proposes a novel solution: the elimination of paged virtual memory
and partial outsourcing of memory page allocation and manipulation from the
operating system kernel into the individual process' user space - a user mode
page allocator - which allows an application to have direct, bare metal access
to the page mappings used by the hardware Memory Management Unit (MMU) for its
part of the overall address space. A user mode page allocator based emulation
of the mmap() abstraction layer of dlmalloc is then benchmarked against the
traditional kernel mode implemented mmap() in a series of synthetic Monte-Carlo
and real world application settings. Given the superb synthetic and positive
real world results from the profiling conducted, this paper proposes that with
proper operating system and API support one could gain a further order higher
performance again while keeping allocator performance invariant to the amount
of memory being allocated or freed i.e. a 100x performance improvement or more
in some common use cases. It is rare that through a simple and easy to
implement API and operating system structure change one can gain a Silver
Bullet with the potential for a second one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1815</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1815</id><created>2011-05-09</created><authors><author><keyname>Douglas</keyname><forenames>Niall</forenames></author></authors><title>User Mode Memory Page Management: An old idea applied anew to the memory
  wall problem</title><categories>cs.OS cs.PF</categories><comments>6 pages. Rejected from MSPC11</comments><acm-class>C.4; D.4.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  It is often said that one of the biggest limitations on computer performance
is memory bandwidth (i.e.&quot;the memory wall problem&quot;). In this position paper, I
argue that if historical trends in computing evolution (where growth in
available capacity is exponential and reduction in its access latencies is
linear) continue as they have, then this view is wrong - in fact we ought to be
concentrating on reducing whole system memory access latencies wherever
possible, and by &quot;whole system&quot; I mean that we ought to look at how software
can be unnecessarily wasteful with memory bandwidth due to legacy design
decisions. To this end I conduct a feasibility study to determine whether we
ought to virtualise the MMU for each application process such that it has
direct access to its own MMU page tables and the memory allocated to a process
is managed exclusively by the process and not the kernel. I find under typical
conditions that nearly scale invariant performance to memory allocation size is
possible such that hundreds of megabytes of memory can be allocated, relocated,
swapped and deallocated in almost the same time as kilobytes (e.g. allocating
8Mb is 10x quicker under this experimental allocator than a conventional
allocator, and resizing a 128Kb block to 256Kb block is 4.5x faster). I find
that first time page access latencies are improved tenfold; moreover, because
the kernel page fault handler is never called, the lack of cache pollution
improves whole application memory access latencies increasing performance by up
to 2x. Finally, I try binary patching existing applications to use the
experimental allocation technique, finding almost universal performance
improvements without having to recompile these applications to make better use
of the new facilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1822</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1822</id><created>2011-05-09</created><authors><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author><author><keyname>DePascale</keyname><forenames>Paolo</forenames></author></authors><title>On the Preliminary Design of Multiple Gravity-Assist Trajectories</title><categories>math.OC cs.NE cs.SY physics.space-ph</categories><journal-ref>Journal of Spacecraft and Rockets, Vol. 42, No. 4, pp. 794-805,
  2006</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the preliminary design of multiple gravity-assist trajectories
is formulated as a global optimization problem. An analysis of the structure of
the solution space reveals a strong multimodality, which is strictly dependent
on the complexity of the model. On the other hand it is shown how an
oversimplification could prevent finding potentially interesting solutions. A
trajectory model, which represents a compromise between model completeness and
optimization problem complexity is then presented. The exploration of the
resulting solution space is performed through a novel global search approach,
which hybridizes an evolutionary based algorithm with a systematic branching
strategy. This approach allows an efficient exploration of complex solution
domains by automatically balancing local convergence and global search. A
number of difficult multiple gravity-assist trajectory design cases
demonstrates the effectiveness of the proposed methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1823</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1823</id><created>2011-05-09</created><authors><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author><author><keyname>Campagnola</keyname><forenames>Stefano</forenames></author></authors><title>Design of Low-Thrust Gravity Assist Trajectories to Europa</title><categories>math.OC cs.SY</categories><journal-ref>Journal of the British Interplanetary Society, Vol. 62, No. 1, pp.
  15-31, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design of a mission to Europa using solar electric
propulsion as main source of thrust. A direct transcription method based on
Finite Elements in Time was used for the design and optimisation of the entire
low-thrust gravity assist transfer from the Earth to Europa. Prior to that, a
global search algorithm was used to generate a set of suitable first guess
solutions for the transfer to Jupiter, and for the capture in the Jovian
system. In particular, a fast deterministic search algorithm was developed to
find the most promising set of swing-bys to reach Jupiter A second fast search
algorithm was developed to find the best sequence of swing-bys of the Jovian
moons. After introducing the global search algorithms and the direct
transcription through Finite Elements in Time, the paper presents a number of
first guess Solutions and a fully optimised transfer from the Earth to Europa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1824</identifier>
 <datestamp>2011-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1824</id><created>2011-05-09</created><updated>2011-12-03</updated><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Harrenstein</keyname><forenames>Paul</forenames></author><author><keyname>Pyrga</keyname><forenames>Evangelia</forenames></author></authors><title>Individual-based stability in hedonic games depending on the best or
  worst players</title><categories>cs.GT</categories><comments>16 pages</comments><msc-class>91A12, 68Q15</msc-class><acm-class>F.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider coalition formation games in which each player has preferences
over the other players and his preferences over coalitions are based on the
best player ($\mathcal{B}$-/B-hedonic games) or the worst player
($\mathcal{W}$/W-hedonic games) in the coalition. We show that for
$\mathcal{B}$-hedonic games, an individually stable partition is guaranteed to
exist and can be computed efficiently. Similarly, there exists a
polynomial-time algorithm which returns a Nash stable partition (if one exists)
for $\mathcal{B}$-hedonic games with strict preferences. Both $\mathcal{W}$-
and W-hedonic games are equivalent if individual rationality is assumed. It is
also shown that for B- or $\mathcal{W}$-hedonic games, checking whether a Nash
stable partition or an individually stable partition exists is NP-complete even
in some cases for strict preferences. We identify a key source of
intractability in compact coalition formation games in which preferences over
players are extended to preferences over coalitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1827</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1827</id><created>2011-05-09</created><updated>2011-05-24</updated><authors><author><keyname>Kerr</keyname><forenames>Gregory</forenames></author></authors><title>Dissecting a Small InfiniBand Application Using the Verbs API</title><categories>cs.DC cs.NI</categories><comments>18 pages, 5 figures</comments><acm-class>D.1.3; C.2.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  InfiniBand is a switched fabric interconnect. The InfiniBand specification
does not define an API. However the OFED package, libibverbs, has become the
default API on Linux and Solaris systems. Sparse documentation exists for the
verbs API. The simplest InfiniBand program provided by OFED, ibv_rc_pingpong,
is about 800 lines long. The semantics of using the verbs API for this program
is not obvious to the first time reader. This paper will dissect the
ibv_rc_pingpong program in an attempt to make clear to users how to interact
with verbs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1829</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1829</id><created>2011-05-09</created><authors><author><keyname>Vasile</keyname><forenames>Massimiliano</forenames></author><author><keyname>Bernelli-Zazzera</keyname><forenames>Franco</forenames></author></authors><title>Optimizing low-thrust and gravity assist maneuvers to design
  interplanetary trajectories</title><categories>math.OC cs.SY</categories><journal-ref>The Journal of the astronautical sciences 2003, vol. 51, no1, pp.
  13-35</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a direct method based on a transcription by finite elements in
time has been used to design optimal interplanetary trajectories, exploiting a
combination of gravity assist maneuvers and low-thrust propulsion. A multiphase
parametric approach has been used to introduce swing-bys, treated as coast
phases between two thrusted or coasting trajectory arcs. Gravity maneuvers are
at first modeled with a linked-conic approximation and then introduced through
a full three-dimensional propagation including perturbations by the Sun. The
method is successfully applied to the design of a mission to planet Mercury,
for which different options corresponding to different sequences of gravity
maneuvers or launch opportunities are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1842</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1842</id><created>2011-05-09</created><updated>2011-08-04</updated><authors><author><keyname>Gall</keyname><forenames>Francois Le</forenames></author><author><keyname>Yoshida</keyname><forenames>Yuichi</forenames></author></authors><title>Property Testing for Cyclic Groups and Beyond</title><categories>cs.DS cs.CC quant-ph</categories><comments>15 pages, full version of a paper to appear in the proceedings of
  COCOON'11. v2: Ref. [14] added and a few modifications to Appendix A done</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the problem of testing if an input (Gamma,*), where Gamma
is a finite set of unknown size and * is a binary operation over Gamma given as
an oracle, is close to a specified class of groups. Friedl et al. [Efficient
testing of groups, STOC'05] have constructed an efficient tester using
poly(log|Gamma|) queries for the class of abelian groups. We focus in this
paper on subclasses of abelian groups, and show that these problems are much
harder: Omega(|Gamma|^{1/6}) queries are necessary to test if the input is
close to a cyclic group, and Omega(|Gamma|^c) queries for some constant c are
necessary to test more generally if the input is close to an abelian group
generated by k elements, for any fixed integer k&gt;0. We also show that knowledge
of the size of the ground set Gamma helps only for k=1, in which case we
construct an efficient tester using poly(log|Gamma|) queries; for any other
value k&gt;1 the query complexity remains Omega(|Gamma|^c). All our upper and
lower bounds hold for both the edit distance and the Hamming distance. These
are, to the best of our knowledge, the first nontrivial lower bounds for such
group-theoretic problems in the property testing model and, in particular, they
imply the first exponential separations between the classical and quantum query
complexities of testing closeness to classes of groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1846</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1846</id><created>2011-05-09</created><authors><author><keyname>Bania</keyname><forenames>Piotr</forenames></author></authors><title>Securing The Kernel via Static Binary Rewriting and Program Shepherding</title><categories>cs.CR</categories><comments>10 pages, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent Microsoft security bulletins show that kernel vulnerabilities are
becoming more and more important security threats. Despite the pretty extensive
security mitigations many of the kernel vulnerabilities are still exploitable.
Successful kernel exploitation typically grants the attacker maximum privilege
level and results in total machine compromise.
  To protect against kernel exploitation, we have developed a tool which
statically rewrites the Microsoft Windows kernel as well as other kernel level
modules. Such rewritten binary files allow us to monitor control flow transfers
during operating system execution. At this point we are able to detect whether
selected control transfer flow is valid or should be considered as an attack
attempt. Our solution is especially directed towards preventing remote kernel
exploitation attempts. Additionally, many of the local privilege escalation
attacks are also blocked (also due to additional mitigation techniques we have
implemented). Our tool was tested with Microsoft Windows XP, Windows Vista and
Windows 7 (under both virtual and physical machines) on IA-32 compatible
processors. Our apparatus is also completely standalone and does not require
any third party software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1853</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1853</id><created>2011-05-10</created><authors><author><keyname>Liu</keyname><forenames>Ying</forenames></author><author><keyname>Chandrasekaran</keyname><forenames>Venkat</forenames></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Willsky</keyname><forenames>Alan S.</forenames></author></authors><title>Feedback Message Passing for Inference in Gaussian Graphical Models</title><categories>stat.ML cs.AI</categories><comments>30 pages</comments><doi>10.1109/TSP.2012.2195656</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While loopy belief propagation (LBP) performs reasonably well for inference
in some Gaussian graphical models with cycles, its performance is
unsatisfactory for many others. In particular for some models LBP does not
converge, and in general when it does converge, the computed variances are
incorrect (except for cycle-free graphs for which belief propagation (BP) is
non-iterative and exact). In this paper we propose {\em feedback message
passing} (FMP), a message-passing algorithm that makes use of a special set of
vertices (called a {\em feedback vertex set} or {\em FVS}) whose removal
results in a cycle-free graph. In FMP, standard BP is employed several times on
the cycle-free subgraph excluding the FVS while a special message-passing
scheme is used for the nodes in the FVS. The computational complexity of exact
inference is $O(k^2n)$, where $k$ is the number of feedback nodes, and $n$ is
the total number of nodes. When the size of the FVS is very large, FMP is
intractable. Hence we propose {\em approximate FMP}, where a pseudo-FVS is used
instead of an FVS, and where inference in the non-cycle-free graph obtained by
removing the pseudo-FVS is carried out approximately using LBP. We show that,
when approximate FMP converges, it yields exact means and variances on the
pseudo-FVS and exact means throughout the remainder of the graph. We also
provide theoretical results on the convergence and accuracy of approximate FMP.
In particular, we prove error bounds on variance computation. Based on these
theoretical results, we design efficient algorithms to select a pseudo-FVS of
bounded size. The choice of the pseudo-FVS allows us to explicitly trade off
between efficiency and accuracy. Experimental results show that using a
pseudo-FVS of size no larger than $\log(n)$, this procedure converges much more
often, more quickly, and provides more accurate results than LBP on the entire
graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1884</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1884</id><created>2011-05-10</created><authors><author><keyname>Kuipers</keyname><forenames>J.</forenames></author><author><keyname>Vermaseren</keyname><forenames>J. A. M.</forenames></author></authors><title>About a conjectured basis for Multiple Zeta Values</title><categories>math-ph cs.SC math.MP</categories><comments>6 pages</comments><report-no>Nikhef 11-008</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We confirm a conjecture about the construction of basis elements for the
multiple zeta values (MZVs) at weight 27 and weight 28. Both show as expected
one element that is twofold extended. This is done with some lengthy computer
algebra calculations using TFORM to determine explicit bases for the MZVs at
these weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1885</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1885</id><created>2011-05-10</created><authors><author><keyname>Frigeri</keyname><forenames>Alessandro</forenames></author><author><keyname>Speranza</keyname><forenames>Gisella</forenames></author></authors><title>&quot;Eppur si muove&quot;, Software Libero e Ricerca Riproducibile</title><categories>cs.CY</categories><comments>The article is in Italian. ISSN:2037-1217</comments><journal-ref>Studi Umbri (2) 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes similarities of the scientific method and the free
open source software development, and how reproducibility is the key of an
healthy scientific production.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1891</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1891</id><created>2011-05-10</created><updated>2011-05-27</updated><authors><author><keyname>Shuman</keyname><forenames>David I</forenames></author><author><keyname>Vandergheynst</keyname><forenames>Pierre</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Chebyshev Polynomial Approximation for Distributed Signal Processing</title><categories>cs.DC cs.NI</categories><comments>8 pages, 5 figures, to appear in the Proceedings of the IEEE
  International Conference on Distributed Computing in Sensor Systems (DCOSS),
  June, 2011, Barcelona, Spain</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unions of graph Fourier multipliers are an important class of linear
operators for processing signals defined on graphs. We present a novel method
to efficiently distribute the application of these operators to the
high-dimensional signals collected by sensor networks. The proposed method
features approximations of the graph Fourier multipliers by shifted Chebyshev
polynomials, whose recurrence relations make them readily amenable to
distributed computation. We demonstrate how the proposed method can be used in
a distributed denoising task, and show that the communication requirements of
the method scale gracefully with the size of the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1894</identifier>
 <datestamp>2012-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1894</id><created>2011-05-10</created><updated>2012-03-12</updated><authors><author><keyname>Zeh</keyname><forenames>Alexander</forenames></author><author><keyname>Wachter</keyname><forenames>Antonia</forenames></author><author><keyname>Bezzateev</keyname><forenames>Sergey</forenames></author></authors><title>Decoding Cyclic Codes up to a New Bound on the Minimum Distance</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new lower bound on the minimum distance of q-ary cyclic codes is proposed.
This bound improves upon the Bose-Chaudhuri-Hocquenghem (BCH) bound and, for
some codes, upon the Hartmann-Tzeng (HT) bound. Several Boston bounds are
special cases of our bound. For some classes of codes the bound on the minimum
distance is refined. Furthermore, a quadratic-time decoding algorithm up to
this new bound is developed. The determination of the error locations is based
on the Euclidean Algorithm and a modified Chien search. The error evaluation is
done by solving a generalization of Forney's formula.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1901</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1901</id><created>2011-05-10</created><authors><author><keyname>Shanmugavelayutham</keyname><forenames>G. Jeyakumar C.</forenames></author></authors><title>Convergence Analysis of Differential Evolution Variants on Unconstrained
  Global Optimization Functions</title><categories>cs.NE</categories><comments>12 Pages, 1 Figure, 10 Tables</comments><journal-ref>Internation Journal of Artifical Intelligence and Applications,
  2011</journal-ref><doi>10.5121/ijaia.2011.2209</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an empirical study on convergence nature of
Differential Evolution (DE) variants to solve unconstrained global optimization
problems. The aim is to identify the competitive nature of DE variants in
solving the problem at their hand and compare. We have chosen fourteen
benchmark functions grouped by feature: unimodal and separable, unimodal and
nonseparable, multimodal and separable, and multimodal and nonseparable.
Fourteen variants of DE were implemented and tested on fourteen benchmark
problems for dimensions of 30. The competitiveness of the variants are
identified by the Mean Objective Function value, they achieved in 100 runs. The
convergence nature of the best and worst performing variants are analyzed by
measuring their Convergence Speed (Cs) and Quality Measure (Qm).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1906</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1906</id><created>2011-05-10</created><authors><author><keyname>Yu</keyname><forenames>Yong</forenames></author><author><keyname>Wang</keyname><forenames>Guanghui</forenames></author><author><keyname>Liu</keyname><forenames>Guizhen</forenames></author></authors><title>List version of ($p$,1)-total labellings</title><categories>math.CO cs.DM</categories><comments>11 pages, 2 figures</comments><msc-class>05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ($p$,1)-total number $\lambda_p^T(G)$ of a graph $G$ is the width of the
smallest range of integers that suffices to label the vertices and the edges of
$G$ such that no two adjacent vertices have the same label, no two incident
edges have the same label and the difference between the labels of a vertex and
its incident edges is at least $p$. In this paper we consider the list version.
Let $L(x)$ be a list of possible colors for all $x\in V(G)\cup E(G)$. Define
$C_{p,1}^T(G)$ to be the smallest integer $k$ such that for every list
assignment with $|L(x)|=k$ for all $x\in V(G)\cup E(G)$, $G$ has a
($p$,1)-total labelling $c$ such that $c(x)\in L(x)$ for all $x\in V(G)\cup
E(G)$. We call $C_{p,1}^T(G)$ the ($p$,1)-total labelling choosability and $G$
is list $L$-($p$,1)-total labelable. In this paper, we present a conjecture on
the upper bound of $C_{p,1}^T$. Furthermore, we study this parameter for paths
and trees in Section 2. We also prove that $C_{p,1}^T(K_{1,n})\leq n+2p-1$ for
star $K_{1,n}$ with $p\geq2, n\geq3$ in Section 3 and $C_{p,1}^T(G)\leq
\Delta+2p-1$ for outerplanar graph with $\Delta\geq p+3$ in Section 4.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1908</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1908</id><created>2011-05-10</created><authors><author><keyname>Yu</keyname><forenames>Yong</forenames></author><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Wang</keyname><forenames>Guanghui</forenames></author><author><keyname>Li</keyname><forenames>Jinbo</forenames></author></authors><title>(2,1)-Total labeling of planar graphs with large maximum degree</title><categories>math.CO cs.DM</categories><comments>9 pages, 1 figure</comments><msc-class>05C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ($d$,1)-total labelling of graphs was introduced by Havet and Yu. In this
paper, we prove that, for planar graph $G$ with maximum degree $\Delta\geq12$
and $d=2$, the (2,1)-total labelling number $\lambda_2^T(G)$ is at most
$\Delta+2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1917</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1917</id><created>2011-05-10</created><authors><author><keyname>Mazloumian</keyname><forenames>Amin</forenames></author><author><keyname>Eom</keyname><forenames>Young-Ho</forenames></author><author><keyname>Helbing</keyname><forenames>Dirk</forenames></author><author><keyname>Lozano</keyname><forenames>Sergi</forenames></author><author><keyname>Fortunato</keyname><forenames>Santo</forenames></author></authors><title>How citation boosts promote scientific paradigm shifts and Nobel Prizes</title><categories>physics.soc-ph cs.DL cs.SI</categories><comments>6 pages, 6 figures</comments><journal-ref>PLoS One 6(5), e18975 (2011)</journal-ref><doi>10.1371/journal.pone.0018975</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nobel Prizes are commonly seen to be among the most prestigious achievements
of our times. Based on mining several million citations, we quantitatively
analyze the processes driving paradigm shifts in science. We find that
groundbreaking discoveries of Nobel Prize Laureates and other famous scientists
are not only acknowledged by many citations of their landmark papers.
Surprisingly, they also boost the citation rates of their previous
publications. Given that innovations must outcompete the rich-gets-richer
effect for scientific citations, it turns out that they can make their way only
through citation cascades. A quantitative analysis reveals how and why they
happen. Science appears to behave like a self-organized critical system, in
which citation cascades of all sizes occur, from continuous scientific progress
all the way up to scientific revolutions, which change the way we see our
world. Measuring the &quot;boosting effect&quot; of landmark papers, our analysis reveals
how new ideas and new players can make their way and finally triumph in a world
dominated by established paradigms. The underlying &quot;boost factor&quot; is also
useful to discover scientific breakthroughs and talents much earlier than
through classical citation analysis, which by now has become a widespread
method to measure scientific excellence, influencing scientific careers and the
distribution of research funds. Our findings reveal patterns of collective
social behavior, which are also interesting from an attention economics
perspective. Understanding the origin of scientific authority may therefore
ultimately help to explain, how social influence comes about and why the value
of goods depends so strongly on the attention they attract.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1922</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1922</id><created>2011-05-10</created><updated>2012-02-08</updated><authors><author><keyname>Geiselhart</keyname><forenames>Roman</forenames></author><author><keyname>Wirth</keyname><forenames>Fabian R.</forenames></author></authors><title>Numerical Construction of LISS Lyapunov Functions under a Small Gain
  Condition</title><categories>math.NA cs.SY math.OC</categories><comments>30 pages, 7 figures, 4 tables</comments><journal-ref>Mathematics of Control, Signals, and Systems (MCSS), Volume 24,
  Numbers 1-2 (2012), 3-32</journal-ref><doi>10.1007/s00498-012-0082-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the stability analysis of large-scale interconnected systems it is
frequently desirable to be able to determine a decay point of the gain
operator, i.e., a point whose image under the monotone operator is strictly
smaller than the point itself. The set of such decay points plays a crucial
role in checking, in a semi-global fashion, the local input-to-state stability
of an interconnected system and in the numerical construction of a LISS
Lyapunov function. We provide a homotopy algorithm that computes a decay point
of a monotone op- erator. For this purpose we use a fixed point algorithm and
provide a function whose fixed points correspond to decay points of the
monotone operator. The advantage to an earlier algorithm is demonstrated.
Furthermore an example is given which shows how to analyze a given perturbed
interconnected system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1929</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1929</id><created>2011-05-10</created><authors><author><keyname>Suchanek</keyname><forenames>Fabian</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Varde</keyname><forenames>Aparna</forenames><affiliation>QUT</affiliation></author><author><keyname>Nayak</keyname><forenames>Richi</forenames><affiliation>QUT</affiliation></author><author><keyname>Senellart</keyname><forenames>Pierre</forenames></author></authors><title>The Hidden Web, XML and Semantic Web: A Scientific Data Management
  Perspective</title><categories>cs.AI</categories><comments>EDBT - Tutorial (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The World Wide Web no longer consists just of HTML pages. Our work sheds
light on a number of trends on the Internet that go beyond simple Web pages.
The hidden Web provides a wealth of data in semi-structured form, accessible
through Web forms and Web services. These services, as well as numerous other
applications on the Web, commonly use XML, the eXtensible Markup Language. XML
has become the lingua franca of the Internet that allows customized markups to
be defined for specific domains. On top of XML, the Semantic Web grows as a
common structured data source. In this work, we first explain each of these
developments in detail. Using real-world examples from scientific domains of
great interest today, we then demonstrate how these new developments can assist
the managing, harvesting, and organization of data on the Web. On the way, we
also illustrate the current research avenues in these domains. We believe that
this effort would help bridge multiple database tracks, thereby attracting
researchers with a view to extend database technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1930</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1930</id><created>2011-05-10</created><authors><author><keyname>Nica</keyname><forenames>Anisoara</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Suchanek</keyname><forenames>Fabian</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Varde</keyname><forenames>Aparna</forenames></author></authors><title>Emerging multidisciplinary research across database management systems</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>SIGMOD REcords (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The database community is exploring more and more multidisciplinary avenues:
Data semantics overlaps with ontology management; reasoning tasks venture into
the domain of artificial intelligence; and data stream management and
information retrieval shake hands, e.g., when processing Web click-streams.
These new research avenues become evident, for example, in the topics that
doctoral students choose for their dissertations. This paper surveys the
emerging multidisciplinary research by doctoral students in database systems
and related areas. It is based on the PIKM 2010, which is the 3rd Ph.D.
workshop at the International Conference on Information and Knowledge
Management (CIKM). The topics addressed include ontology development, data
streams, natural language processing, medical databases, green energy, cloud
computing, and exploratory search. In addition to core ideas from the workshop,
we list some open research questions in these multidisciplinary areas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1943</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1943</id><created>2011-05-10</created><authors><author><keyname>Hoydis</keyname><forenames>Jakob</forenames></author><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>Asymptotic Analysis of Double-Scattering Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, submitted to the Annual Asilomar Conference on
  Signals, Systems, and Computers, Pacific Grove, CA, USA, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a multiple-input multiple-output (MIMO) multiple access channel
(MAC), where the channel between each transmitter and the receiver is modeled
by the doubly-scattering channel model. Based on novel techniques from random
matrix theory, we derive deterministic approximations of the mutual
information, the signal-to-noise-plus-interference-ratio (SINR) at the output
of the minimum-mean-square-error (MMSE) detector and the sum-rate with MMSE
detection which are almost surely tight in the large system limit. Moreover, we
derive the asymptotically optimal transmit covariance matrices. Our simulation
results show that the asymptotic analysis provides very close approximations
for realistic system dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1945</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1945</id><created>2011-05-10</created><authors><author><keyname>Keyvanpour</keyname><forenames>MohammadReza</forenames><affiliation>Department of Computer Engineering Al-Zahra University</affiliation></author><author><keyname>Moradi</keyname><forenames>Somayyeh Seifi</forenames><affiliation>Department of Computer Engineering Islamic Azad University</affiliation></author></authors><title>Classification and Evaluation the Privacy Preserving Data Mining
  Techniques by using a Data Modification-based Framework</title><categories>cs.CR</categories><journal-ref>International Journal on Computer Science and Engineering
  (IJCSE)Vol. 3 No. 2 Feb 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the data mining techniques have met a serious challenge due
to the increased concerning and worries of the privacy, that is, protecting the
privacy of the critical and sensitive data. Different techniques and algorithms
have been already presented for Privacy Preserving data mining, which could be
classified in three common approaches: Data modification approach, Data
sanitization approach and Secure Multi-party Computation approach. This paper
presents a Data modification- based Framework for classification and evaluation
of the privacy preserving data mining techniques. Based on our framework the
techniques are divided into two major groups, namely perturbation approach and
anonymization approach. Also in proposed framework, eight functional criteria
will be used to analyze and analogically assessment of the techniques in these
two major groups. The proposed framework provides a good basis for more
accurate comparison of the given techniques to privacy preserving data mining.
In addition, this framework allows recognizing the overlapping amount for
different approaches and identifying modern approaches in this field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1948</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1948</id><created>2011-05-10</created><authors><author><keyname>keyvanpour</keyname><forenames>Mohammadreza</forenames><affiliation>Department of Computer Engineering, Alzahra University, Tehran, Iran</affiliation></author><author><keyname>Izadpanah</keyname><forenames>Najva</forenames><affiliation>Department of Computer Engineering, Islamic Azad University, Qazvin Branch, Qazvin, Iran</affiliation></author></authors><title>Analytical Classification of Multimedia Index Structures by Using a
  Partitioning Method-Based Framework</title><categories>cs.MM</categories><journal-ref>The International Journal of Multimedia &amp; Its Applications (IJMA)
  Vol.3, No.1, February 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the advances in hardware technology and increase in production of
multimedia data in many applications, during the last decades, multimedia
databases have become increasingly important. Contentbased multimedia retrieval
is one of an important research area in the field of multimedia databases. Lots
of research on this field has led to proposition of different kinds of index
structures to support fast and efficient similarity search to retrieve
multimedia data from these databases. Due to variety and plenty of proposed
index structures, we suggest a systematic framework based on partitioning
method used in these structures to classify multimedia index structures, and
then we evaluated these structures based on important functional measures. We
hope this proposed framework will lead to empirical and technical comparison of
multimedia index structures and development of more efficient structures at
future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1950</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1950</id><created>2011-05-10</created><authors><author><keyname>Kholghi</keyname><forenames>Mahnoosh</forenames><affiliation>Department of Electronic, Computer and IT, Islamic Azad University, Qazvin Branch, Qazvin, Iran and member of Young Researchers Club</affiliation></author><author><keyname>Keyvanpour</keyname><forenames>Mohammadreza</forenames><affiliation>Department of Computer Engineering Alzahra University Tehran, Iran</affiliation></author></authors><title>An analytical framework for data stream mining techniques based on
  challenges and requirements</title><categories>cs.DB</categories><journal-ref>International Journal of Engineering Science and Technology
  (IJEST)Vol. 3 No. 3 Mar 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A growing number of applications that generate massive streams of data need
intelligent data processing and online analysis. Real-time surveillance
systems, telecommunication systems, sensor networks and other dynamic
environments are such examples. The imminent need for turning such data into
useful information and knowledge augments the development of systems,
algorithms and frameworks that address streaming challenges. The storage,
querying and mining of such data sets are highly computationally challenging
tasks. Mining data streams is concerned with extracting knowledge structures
represented in models and patterns in non stopping streams of information.
Generally, two main challenges are designing fast mining methods for data
streams and need to promptly detect changing concepts and data distribution
because of highly dynamic nature of data streams. The goal of this article is
to analyze and classify the application of diverse data mining techniques in
different challenges of data stream mining. In this paper, we present the
theoretical foundations of data stream analysis and propose an analytical
framework for data stream mining techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1951</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1951</id><created>2011-05-10</created><updated>2011-09-05</updated><authors><author><keyname>Konen</keyname><forenames>Wolfgang</forenames></author></authors><title>Self-configuration from a Machine-Learning Perspective</title><categories>nlin.AO cs.LG stat.ML</categories><comments>12 pages, 5 figures, Dagstuhl seminar 11181 &quot;Organic Computing -
  Design of Self-Organizing Systems&quot;, May 2011</comments><report-no>DPA-11181</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of machine learning is to provide solutions which are trained by
data or by experience coming from the environment. Many training algorithms
exist and some brilliant successes were achieved. But even in structured
environments for machine learning (e.g. data mining or board games), most
applications beyond the level of toy problems need careful hand-tuning or human
ingenuity (i.e. detection of interesting patterns) or both. We discuss several
aspects how self-configuration can help to alleviate these problems. One aspect
is the self-configuration by tuning of algorithms, where recent advances have
been made in the area of SPO (Sequen- tial Parameter Optimization). Another
aspect is the self-configuration by pattern detection or feature construction.
Forming multiple features (e.g. random boolean functions) and using algorithms
(e.g. random forests) which easily digest many fea- tures can largely increase
learning speed. However, a full-fledged theory of feature construction is not
yet available and forms a current barrier in machine learning. We discuss
several ideas for systematic inclusion of feature construction. This may lead
to partly self-configuring machine learning solutions which show robustness,
flexibility, and fast learning in potentially changing environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1967</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1967</id><created>2011-05-10</created><authors><author><keyname>Hahanov</keyname><forenames>Vladimir</forenames></author><author><keyname>Litvinova</keyname><forenames>Eugenia</forenames></author><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author><author><keyname>Guz</keyname><forenames>Olesya</forenames></author></authors><title>Algebra-Logical Repair Method for FPGA Logic Blocks</title><categories>cs.AR</categories><comments>7 pages</comments><journal-ref>Journal of Radioelectronics and Informatics, No.2, Vol. 45, pp.
  49-56, April -- June 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algebra-logical repair method for FPGA functional logic blocks on the
basis of solving the coverage problem is proposed. It is focused on
implementation into Infrastructure IP for system-on-a chip and
system-in-package. A method is designed for providing the operability of FPGA
blocks and digital system as a whole. It enables to obtain exact and optimal
solution associated with the minimum number of spares needed to repair the FPGA
logic components with multiple faults.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1969</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1969</id><created>2011-05-10</created><authors><author><keyname>Einolghozati</keyname><forenames>Arash</forenames></author><author><keyname>Sardari</keyname><forenames>Mohsen</forenames></author><author><keyname>Beirami</keyname><forenames>Ahmad</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>Capacity of Discrete Molecular Diffusion Channels</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In diffusion-based molecular communications, messages can be conveyed via the
variation in the concentration of molecules in the medium. In this paper, we
intend to analyze the achievable capacity in transmission of information from
one node to another in a diffusion channel. We observe that because of the
molecular diffusion in the medium, the channel possesses memory. We then model
the memory of the channel by a two-step Markov chain and obtain the equations
describing the capacity of the diffusion channel. By performing a numerical
analysis, we obtain the maximum achievable rate for different levels of the
transmitter power, i.e., the molecule production rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1973</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1973</id><created>2011-05-10</created><authors><author><keyname>Hahanov</keyname><forenames>Vladimir</forenames></author><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author><author><keyname>Guz</keyname><forenames>Olesya</forenames></author></authors><title>Brain-like infrastructure for embedded SoC diagnosis</title><categories>cs.AR</categories><comments>5 pages</comments><journal-ref>IEEE International Conference on Automation Quality and Testing
  Robotics (AQTR), 28-30 May 2010, Cluj-Napoca, Romania</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes high-speed multiprocessor architecture for the
concurrent analyzing information represented in analytic, graph- and table
forms of associative relations to search, recognize and make a decision in
n-dimensional vector discrete space. Vector-logical process models of actual
applications,for which the quality of solution is estimated by the proposed
integral non-arithmetical metric of the interaction between Boolean vectors,
are described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1982</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1982</id><created>2011-05-10</created><authors><author><keyname>Khadilkar</keyname><forenames>Vaibhav</forenames></author><author><keyname>Kantarcioglu</keyname><forenames>Murat</forenames></author><author><keyname>Thuraisingham</keyname><forenames>Bhavani</forenames></author><author><keyname>Mehrotra</keyname><forenames>Sharad</forenames></author></authors><title>Secure Data Processing in a Hybrid Cloud</title><categories>cs.DC</categories><comments>16 pages (13 pages + 3 page appendix), 5 figures</comments><acm-class>D.4.6; H.3.3; H.3.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cloud computing has made it possible for a user to be able to select a
computing service precisely when needed. However, certain factors such as
security of data and regulatory issues will impact a user's choice of using
such a service. A solution to these problems is the use of a hybrid cloud that
combines a user's local computing capabilities (for mission- or
organization-critical tasks) with a public cloud (for less influential tasks).
We foresee three challenges that must be overcome before the adoption of a
hybrid cloud approach: 1) data design: How to partition relations in a hybrid
cloud? The solution to this problem must account for the sensitivity of
attributes in a relation as well as the workload of a user; 2) data security:
How to protect a user's data in a public cloud with encryption while enabling
query processing over this encrypted data? and 3) query processing: How to
execute queries efficiently over both, encrypted and unencrypted data? This
paper addresses these challenges and incorporates their solutions into an
add-on tool for a Hadoop and Hive based cloud computing infrastructure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1985</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1985</id><created>2011-05-10</created><updated>2011-05-15</updated><authors><author><keyname>Meurer</keyname><forenames>Benedikt</forenames></author></authors><title>A Step-indexed Semantic Model of Types for the Call-by-Name Lambda
  Calculus</title><categories>cs.PL</categories><comments>5 pages, 6 figures</comments><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Step-indexed semantic models of types were proposed as an alternative to
purely syntactic safety proofs using subject-reduction. Building upon the work
by Appel and others, we introduce a generalized step-indexed model for the
call-by-name lambda calculus. We also show how to prove type safety of general
recursion in our call-by-name model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.1999</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.1999</id><created>2011-05-10</created><authors><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author><author><keyname>Xia</keyname><forenames>Yong</forenames></author></authors><title>New Heuristic Rounding Approaches to the Quadratic Assignment Problem</title><categories>cs.CC</categories><comments>4 Pages</comments><journal-ref>Apr. 2010, Volume 7, No.4 (Serial No.65), Journal of Communication
  and Computer, ISSN 1548-7709, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quadratic assignment problem is one of the great challenges in combinatorial
optimization. It has many applications in Operations research and Computer
Science. In this paper, the author extends the most-used rounding approach to a
one-parametric optimization model for the quadratic assignment problems. A
near-optimum parameter is also predestinated. The numerical experiments confirm
the efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2002</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2002</id><created>2011-05-10</created><authors><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author><author><keyname>Mirza</keyname><forenames>Abdulrahman</forenames></author></authors><title>Security Risks and Modern Cyber Security Technologies for Corporate
  Networks</title><categories>cs.CR cs.NI</categories><comments>5 pages</comments><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 9, No. 1, January 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article aims to highlight current trends on the market of corporate
antivirus solutions. Brief overview of modern security threats that can destroy
IT environment is provided as well as a typical structure and features of
antivirus suits for corporate users presented on the market. The general
requirements for corporate products are determined according to the last report
from av-comparatives.org [1]. The detailed analysis of new features is provided
based on an overview of products available on the market nowadays. At the end,
an enumeration of modern trends in antivirus industry for corporate users
completes this article. Finally, the main goal of this article is to stress an
attention about new trends suggested by AV vendors in their solutions in order
to protect customers against newest security threats.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2003</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2003</id><created>2011-05-10</created><updated>2012-02-12</updated><authors><author><keyname>Cormode</keyname><forenames>Graham</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Thaler</keyname><forenames>Justin</forenames></author></authors><title>Practical Verified Computation with Streaming Interactive Proofs</title><categories>cs.DS cs.CC cs.CR</categories><comments>39 pages, 12 figures, 2 tables. Accepted to ITCS 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When delegating computation to a service provider, as in cloud computing, we
seek some reassurance that the output is correct and complete. Yet recomputing
the output as a check is inefficient and expensive, and it may not even be
feasible to store all the data locally. We are therefore interested in proof
systems which allow a service provider to prove the correctness of its output
to a streaming (sublinear space) user, who cannot store the full input or
perform the full computation herself.
  Our approach is two-fold. First, we describe a carefully chosen instantiation
of one of the most efficient general-purpose constructions for arbitrary
computations (streaming or otherwise), due to Goldwasser, Kalai, and Rothblum.
This requires several new insights to make the methodology more practical. Our
main contribution is in achieving a prover who runs in time O(S(n) log S(n)),
where S(n) is the size of an arithmetic circuit computing the function of
interest. Our experimental results demonstrate that a practical general-purpose
protocol for verifiable computation may be significantly closer to reality than
previously realized.
  Second, we describe techniques that achieve genuine scalability for protocols
fine-tuned for specific important problems in streaming and database
processing. Focusing in particular on non-interactive protocols for problems
ranging from matrix-vector multiplication to bipartite perfect matching, we
build on prior work to achieve a prover who runs in nearly linear-time, while
obtaining optimal tradeoffs between communication cost and the user's working
memory. Existing techniques required (substantially) superlinear time for the
prover. We argue that even if general-purpose methods improve, fine-tuned
protocols will remain valuable in real-world settings for key problems, and
hence special attention to specific problems is warranted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2013</identifier>
 <datestamp>2012-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2013</id><created>2011-05-10</created><authors><author><keyname>Fritzsche</keyname><forenames>B.</forenames></author><author><keyname>Kirstein</keyname><forenames>B.</forenames></author><author><keyname>Roitberg</keyname><forenames>I. Ya.</forenames></author><author><keyname>Sakhnovich</keyname><forenames>A. L.</forenames></author></authors><title>Weyl theory and explicit solutions of direct and inverse problems for a
  Dirac system with rectangular matrix potential</title><categories>math.SP cs.SY math.CA math.OC</categories><msc-class>34B20, 34L40, 15A15, 93B15</msc-class><journal-ref>Oper. Matrices 7:1 (2013), 183-196</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A non-classical Weyl theory is developed for Dirac systems with rectangular
matrix potentials. The notion of the Weyl function is introduced and the
corresponding direct problem is treated. Furthermore, explicit solutions of the
direct and inverse problems are obtained for the case of rational Weyl matrix
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2017</identifier>
 <datestamp>2011-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2017</id><created>2011-05-10</created><authors><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author></authors><title>Potential Games for Energy-Efficient Resource Allocation in
  Multipoint-to-Multipoint CDMA Wireless Data Networks</title><categories>cs.IT math.IT</categories><comments>Submitted to Physical Communication, ELSEVIER</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of noncooperative resource allocation in a
multipoint-to-multipoint cellular network is considered in this paper. The
considered scenario is general enough to represent several key instances of
modern wireless networks such as a multicellular network, a peer-to-peer
network (interference channel), and a wireless network equipped with
femtocells. In particular, the problem of joint transmit waveforms adaptation,
linear receiver design, and transmit power control is examined. Several utility
functions to be maximized are considered, and, among them, we cite the received
SINR, and the transmitter energy efficiency, which is measured in bit/Joule,
and represents the number of successfully delivered bits for each energy unit
used for transmission. Resorting to the theory of potential games,
noncooperative games admitting Nash equilibria in multipoint-to-multipoint
cellular networks regardless of the channel coefficient realizations are
designed. Computer simulations confirm that the considered games are
convergent, and show the huge benefits that resource allocation schemes can
bring to the performance of wireless data networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2040</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2040</id><created>2011-05-10</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Ene</keyname><forenames>Alina</forenames></author></authors><title>Submodular Cost Allocation Problem and Applications</title><categories>cs.DS cs.DM</categories><comments>Extended abstract to appear in Proceedings of ICALP, July 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Minimum Submodular-Cost Allocation problem (MSCA). In this
problem we are given a finite ground set $V$ and $k$ non-negative submodular
set functions $f_1 ,..., f_k$ on $V$. The objective is to partition $V$ into
$k$ (possibly empty) sets $A_1 ,..., A_k$ such that the sum $\sum_{i=1}^k
f_i(A_i)$ is minimized. Several well-studied problems such as the non-metric
facility location problem, multiway-cut in graphs and hypergraphs, and uniform
metric labeling and its generalizations can be shown to be special cases of
MSCA. In this paper we consider a convex-programming relaxation obtained via
the Lov\'asz-extension for submodular functions. This allows us to understand
several previous relaxations and rounding procedures in a unified fashion and
also develop new formulations and approximation algorithms for several
problems. In particular, we give a $(1.5 - 1/k)$-approximation for the
hypergraph multiway partition problem. We also give a $\min\{2(1-1/k),
H_{\Delta}\}$-approximation for the hypergraph multiway cut problem when
$\Delta$ is the maximum hyperedge size. Both problems generalize the multiway
cut problem in graphs and the hypergraph cut problem is approximation
equivalent to the node-weighted multiway cut problem in graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2048</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2048</id><created>2011-05-10</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Ene</keyname><forenames>Alina</forenames></author></authors><title>Approximation Algorithms for Submodular Multiway Partition</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study algorithms for the Submodular Multiway Partition problem (SubMP). An
instance of SubMP consists of a finite ground set $V$, a subset of $k$ elements
$S = \{s_1,s_2,...,s_k\}$ called terminals, and a non-negative submodular set
function $f:2^V\rightarrow \mathbb{R}_+$ on $V$ provided as a value oracle. The
goal is to partition $V$ into $k$ sets $A_1,...,A_k$ such that for $1 \le i \le
k$, $s_i \in A_i$ and $\sum_{i=1}^k f(A_i)$ is minimized. SubMP generalizes
some well-known problems such as the Multiway Cut problem in graphs and
hypergraphs, and the Node-weighed Multiway Cut problem in graphs. SubMP for
arbitrarysubmodular functions (instead of just symmetric functions) was
considered by Zhao, Nagamochi and Ibaraki \cite{ZhaoNI05}. Previous algorithms
were based on greedy splitting and divide and conquer strategies. In very
recent work \cite{ChekuriE11} we proposed a convex-programming relaxation for
SubMP based on the Lov\'asz-extension of a submodular function and showed its
applicability for some special cases. In this paper we obtain the following
results for arbitrary submodular functions via this relaxation. (i) A
2-approximation for SubMP. This improves the $(k-1)$-approximation from
\cite{ZhaoNI05} and (ii) A $(1.5-1/k)$-approximation for SubMP when $f$ is
symmetric. This improves the $2(1-1/k)$-approximation from
\cite{Queyranne99,ZhaoNI05}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2054</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2054</id><created>2011-05-10</created><updated>2012-02-14</updated><authors><author><keyname>Grubb</keyname><forenames>Alexander</forenames></author><author><keyname>Bagnell</keyname><forenames>J. Andrew</forenames></author></authors><title>Generalized Boosting Algorithms for Convex Optimization</title><categories>cs.LG stat.ML</categories><comments>Extended version of paper presented at the International Conference
  on Machine Learning, 2011. 9 pages + appendix with proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boosting is a popular way to derive powerful learners from simpler hypothesis
classes. Following previous work (Mason et al., 1999; Friedman, 2000) on
general boosting frameworks, we analyze gradient-based descent algorithms for
boosting with respect to any convex objective and introduce a new measure of
weak learner performance into this setting which generalizes existing work. We
present the weak to strong learning guarantees for the existing gradient
boosting work for strongly-smooth, strongly-convex objectives under this new
measure of performance, and also demonstrate that this work fails for
non-smooth objectives. To address this issue, we present new algorithms which
extend this boosting approach to arbitrary convex loss functions and give
corresponding weak to strong convergence results. In addition, we demonstrate
experimental results that support our analysis and demonstrate the need for the
new algorithms we present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2062</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2062</id><created>2011-05-10</created><updated>2011-07-05</updated><authors><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author></authors><title>Scalar Quantization with Random Thresholds</title><categories>cs.IT math.IT</categories><comments>4 pages, 2 figures</comments><journal-ref>IEEE Signal Processing Letters, vol. 18, no. 9, pp. 525-528,
  September 2011</journal-ref><doi>10.1109/LSP.2011.2161867</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The distortion-rate performance of certain randomly-designed scalar
quantizers is determined. The central results are the mean-squared error
distortion and output entropy for quantizing a uniform random variable with
thresholds drawn independently from a uniform distribution. The distortion is
at most 6 times that of an optimal (deterministically-designed) quantizer, and
for a large number of levels the output entropy is reduced by approximately
(1-gamma)/(ln 2) bits, where gamma is the Euler-Mascheroni constant. This shows
that the high-rate asymptotic distortion of these quantizers in an
entropy-constrained context is worse than the optimal quantizer by at most a
factor of 6 exp(-2(1-gamma)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2090</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2090</id><created>2011-05-10</created><updated>2011-06-26</updated><authors><author><keyname>Chakraborty</keyname><forenames>Ayon</forenames></author><author><keyname>Mitra</keyname><forenames>Swarup Kumar</forenames></author><author><keyname>Naskar</keyname><forenames>Mrinal Kanti</forenames></author></authors><title>Energy Efficient Routing in Wireless Sensor Networks: A Genetic Approach</title><categories>cs.NI math.OC</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in equation 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to a crucial sign error in
equation 1
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2091</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2091</id><created>2011-05-10</created><updated>2011-06-26</updated><authors><author><keyname>Chakraborty</keyname><forenames>Kaushik</forenames></author><author><keyname>Chakraborty</keyname><forenames>Ayon</forenames></author><author><keyname>Mitra</keyname><forenames>Swarup Kumar</forenames></author><author><keyname>Naskar</keyname><forenames>Mrinal Kanti</forenames></author></authors><title>ROOT: Energy Efficient Routing through Optimized Tree in Sensor Networks</title><categories>cs.NI math.OC</categories><comments>This paper has been withdrawn by the author due to a crucial sign
  error in equation 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to a crucial sign error in
equation 1
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2095</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2095</id><created>2011-05-10</created><authors><author><keyname>Sahidullah</keyname><forenames>Md.</forenames></author><author><keyname>Saha</keyname><forenames>Goutam</forenames></author></authors><title>In Search of Autocorrelation Based Vocal Cord Cues for Speaker
  Identification</title><categories>cs.HC</categories><comments>Proceedings of 2nd International Conference on RF &amp; Signal Processing
  Systems - RSPS 2010</comments><journal-ref>International Journal of Communication Engineering Applications,
  Volume: 1, Page: 5-11, Year: 2011, Month: February</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate a technique to find out vocal source based
features from the LP residual of speech signal for automatic speaker
identification. Autocorrelation with some specific lag is computed for the
residual signal to derive these features. Compared to traditional features like
MFCC, PLPCC which represent vocal tract information, these features represent
complementary vocal cord information. Our experiment in fusing these two
sources of information in representing speaker characteristics yield better
speaker identification accuracy. We have used Gaussian mixture model (GMM)
based speaker modeling and results are shown on two public databases to
validate our proposition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2096</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2096</id><created>2011-05-10</created><updated>2011-05-22</updated><authors><author><keyname>Jose</keyname><forenames>Jubin</forenames></author><author><keyname>Mitliagkas</keyname><forenames>Ioannis</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Sum Capacity of Gaussian Interfering Multiple Access Channels in the Low
  Interference Regime</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn due to an incorrect proof</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn due to an incorrect proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2114</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2114</id><created>2011-05-11</created><updated>2011-05-18</updated><authors><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author><author><keyname>Lu</keyname><forenames>Hsiao-feng</forenames></author></authors><title>An algebraic look into MAC-DMT of lattice space-time codes</title><categories>cs.IT math.IT math.NT</categories><comments>Will appear in ISIT 2011. Missing proof and some clarification added
  on 18th of May</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we are concentrating on the diversity-multiplexing gain
trade-off (DMT) of some space-time lattice codes. First we give a DMT bound for
lattice codes having restricted dimension. We then recover the well known
results of the DMT of algebraic number field codes and the Alamouti code by
using the union bound and see that these codes do achieve the previously
mentioned bound. During our analysis interesting connections to the Dedekind's
zeta-function and to the unit group of algebraic number fields are revealed.
Finally we prove that both the number field codes and Alamouti code are in some
sense optimal codes in the multiple access channel (MAC).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2171</identifier>
 <datestamp>2011-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2171</id><created>2011-05-11</created><updated>2011-06-21</updated><authors><author><keyname>Calamoneri</keyname><forenames>Tiziana</forenames></author><author><keyname>Petreschi</keyname><forenames>Rossella</forenames></author><author><keyname>Sinaimeri</keyname><forenames>Blerina</forenames></author></authors><title>On relaxing the constraints in pairwise compatibility graphs</title><categories>cs.DM</categories><comments>12 pages, 7 figures</comments><msc-class>68R10</msc-class><acm-class>G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph $G$ is called a pairwise compatibility graph (PCG) if there exists an
edge weighted tree $T$ and two non-negative real numbers $d_{min}$ and
$d_{max}$ such that each leaf $l_u$ of $T$ corresponds to a vertex $u \in V$
and there is an edge $(u,v) \in E$ if and only if $d_{min} \leq d_T (l_u, l_v)
\leq d_{max}$ where $d_T (l_u, l_v)$ is the sum of the weights of the edges on
the unique path from $l_u$ to $l_v$ in $T$. In this paper we analyze the class
of PCG in relation with two particular subclasses resulting from the the cases
where $\dmin=0$ (LPG) and $\dmax=+\infty$ (mLPG). In particular, we show that
the union of LPG and mLPG does not coincide with the whole class PCG, their
intersection is not empty, and that neither of the classes LPG and mLPG is
contained in the other. Finally, as the graphs we deal with belong to the more
general class of split matrogenic graphs, we focus on this class of graphs for
which we try to establish the membership to the PCG class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2176</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2176</id><created>2011-05-11</created><authors><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author></authors><title>A Framework for Optimization under Limited Information</title><categories>math.OC cs.IT cs.LG cs.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many real world problems, optimization decisions have to be made with
limited information. The decision maker may have no a priori or posteriori data
about the often nonconvex objective function except from on a limited number of
points that are obtained over time through costly observations. This paper
presents an optimization framework that takes into account the information
collection (observation), estimation (regression), and optimization
(maximization) aspects in a holistic and structured manner. Explicitly
quantifying the information acquired at each optimization step using the
entropy measure from information theory, the (nonconvex) objective function to
be optimized (maximized) is modeled and estimated by adopting a Bayesian
approach and using Gaussian processes as a state-of-the-art regression method.
The resulting iterative scheme allows the decision maker to solve the problem
by expressing preferences for each aspect quantitatively and concurrently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2202</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2202</id><created>2011-05-11</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>On Symmetry of Independence Polynomials</title><categories>cs.DM math.CO</categories><comments>16 pages, 13 figures</comments><msc-class>05C31 (Primary), 05C69 (Secondary)</msc-class><acm-class>G.2.2; G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An independent set in a graph is a set of pairwise non-adjacent vertices, and
alpha(G) is the size of a maximum independent set in the graph G. A matching is
a set of non-incident edges, while mu(G) is the cardinality of a maximum
matching.
  If s_{k} is the number of independent sets of cardinality k in G, then
I(G;x)=s_{0}+s_{1}x+s_{2}x^{2}+...+s_{\alpha(G)}x^{\alpha(G)} is called the
independence polynomial of G (Gutman and Harary, 1983). If
$s_{j}=s_{\alpha-j}$, 0=&lt; j =&lt; alpha(G), then I(G;x) is called symmetric (or
palindromic). It is known that the graph G*2K_{1} obtained by joining each
vertex of G to two new vertices, has a symmetric independence polynomial
(Stevanovic, 1998). In this paper we show that for every graph G and for each
non-negative integer k =&lt; mu(G), one can build a graph H, such that: G is a
subgraph of H, I(H;x) is symmetric, and I(G*2K_{1};x)=(1+x)^{k}*I(H;x).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2211</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2211</id><created>2011-05-11</created><authors><author><keyname>Alpcan</keyname><forenames>Tansu</forenames></author></authors><title>Dual Control with Active Learning using Gaussian Process Regression</title><categories>math.OC cs.IT cs.LG cs.SY math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many real world problems, control decisions have to be made with limited
information. The controller may have no a priori (or even posteriori) data on
the nonlinear system, except from a limited number of points that are obtained
over time. This is either due to high cost of observation or the highly
non-stationary nature of the system. The resulting conflict between information
collection (identification, exploration) and control (optimization,
exploitation) necessitates an active learning approach for iteratively
selecting the control actions which concurrently provide the data points for
system identification. This paper presents a dual control approach where the
information acquired at each control step is quantified using the entropy
measure from information theory and serves as the training input to a
state-of-the-art Gaussian process regression (Bayesian learning) method. The
explicit quantification of the information obtained from each data point allows
for iterative optimization of both identification and control objectives. The
approach developed is illustrated with two examples: control of logistic map as
a chaotic system and position control of a cart with inverted pendulum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2213</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2213</id><created>2011-05-10</created><authors><author><keyname>Badidi</keyname><forenames>Elarbi</forenames></author><author><keyname>Esmahi</keyname><forenames>Larbi</forenames></author></authors><title>A Cloud-based Approach for Context Information Provisioning</title><categories>cs.DC</categories><comments>8 Pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT) , ISSN: 2221-0741, Vol. 1, No. 3, 63-70, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a result of the phenomenal proliferation of modern mobile Internet-enabled
devices and the widespread utilization of wireless and cellular data networks,
mobile users are increasingly requiring services tailored to their current
context. High-level context information is typically obtained from context
services that aggregate raw context information sensed by various sensors and
mobile devices. Given the massive amount of sensed data, traditional context
services are lacking the necessary resources to store and process these data,
as well as to disseminate high-level context information to a variety of
potential context consumers. In this paper, we propose a novel framework for
context information provisioning, which relies on deploying context services on
the cloud and using context brokers to mediate between context consumers and
context services using a publish/subscribe model. Moreover, we describe a
multi-attributes decision algorithm for the selection of potential context
services that can fulfill context consumers' requests for context information.
The algorithm calculates the score of each context service, per context
information type, based on the quality-of-service (QoS) and quality-of-context
information (QoC) requirements expressed by the context consumer. One of the
benefits of the approach is that context providers can scale up and down, in
terms of cloud resources they use, depending on current demand for context
information. Besides, the selection algorithm allows ranking context services
by matching their QoS and QoC offers against the QoS and QoC requirements of
the context consumer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2214</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2214</id><created>2011-05-11</created><authors><author><keyname>Breslavsky</keyname><forenames>I. D.</forenames></author></authors><title>An improved mathematical model of social group competition</title><categories>physics.soc-ph cs.SI</categories><comments>3 pages, 1 figure</comments><msc-class>91D10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An improved mathematical model of social group competition is proposed. The
utility obtained by a member of a certain group from each other member is
assumed to be group size-dependent. Obtained results are close to available
census data. It is shown that a significant fraction of population can be
affiliated in a group with lower maximal specific utility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2225</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2225</id><created>2011-05-11</created><authors><author><keyname>Skibski</keyname><forenames>Oskar</forenames></author></authors><title>Steady Marginality: A Uniform Approach to Shapley Value for Games with
  Externalities</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Shapley value is one of the most important solution concepts in
cooperative game theory. In coalitional games without externalities, it allows
to compute a unique payoff division that meets certain desirable fairness
axioms. However, in many realistic applications where externalities are
present, Shapley's axioms fail to indicate such a unique division.
Consequently, there are many extensions of Shapley value to the environment
with externalities proposed in the literature built upon additional axioms. Two
important such extensions are &quot;externality-free&quot; value by Pham Do and Norde and
value that &quot;absorbed all externalities&quot; by McQuillin. They are good reference
points in a space of potential payoff divisions for coalitional games with
externalities as they limit the space at two opposite extremes. In a recent,
important publication, De Clippel and Serrano presented a marginality-based
axiomatization of the value by Pham Do Norde. In this paper, we propose a dual
approach to marginality which allows us to derive the value of McQuillin. Thus,
we close the picture outlined by De Clippel and Serrano.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2228</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2228</id><created>2011-05-11</created><authors><author><keyname>Borradaile</keyname><forenames>Glencora</forenames></author><author><keyname>Klein</keyname><forenames>Philip N.</forenames></author><author><keyname>Mozes</keyname><forenames>Shay</forenames></author><author><keyname>Nussbaum</keyname><forenames>Yahav</forenames></author><author><keyname>Wulff-Nilsen</keyname><forenames>Christian</forenames></author></authors><title>Multiple-Source Multiple-Sink Maximum Flow in Directed Planar Graphs in
  Near-Linear Time</title><categories>cs.DM cs.DS</categories><comments>18 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an O(n log^3 n) algorithm that, given an n-node directed planar graph
with arc capacities, a set of source nodes, and a set of sink nodes, finds a
maximum flow from the sources to the sinks. Previously, the fastest algorithms
known for this problem were those for general graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2243</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2243</id><created>2011-05-11</created><authors><author><keyname>M&#xe9;riaux</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Kieffer</keyname><forenames>Michel</forenames></author></authors><title>More about Base Station Location Games</title><categories>cs.NI cs.GT</categories><comments>ValueTools '11: 6th International Conference on Performance
  Evaluation Methodologies and Tools, May 2011, Paris, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of locating base stations in a certain area
which is highly populated by mobile stations; each mobile station is assumed to
select the closest base station. Base stations are modeled by players who
choose their best location for maximizing their uplink throughput. The approach
of this paper is to make some simplifying assumptions in order to get
interpretable analytical results and insights to the problem under study.
Specifically, a relatively complete Nash equilibrium (NE) analysis is conducted
(existence, uniqueness, determination, and efficiency). Then, assuming that the
base station location can be adjusted dynamically, the best-response dynamics
and reinforcement learning algorithm are applied, discussed, and illustrated
through numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2246</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2246</id><created>2011-05-11</created><updated>2011-08-09</updated><authors><author><keyname>Cirstea</keyname><forenames>Corina</forenames><affiliation>University of Southampton</affiliation></author><author><keyname>Kupke</keyname><forenames>Clemens</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Pattinson</keyname><forenames>Dirk</forenames><affiliation>Imperial College London</affiliation></author></authors><title>EXPTIME Tableaux for the Coalgebraic mu-Calculus</title><categories>cs.LO math.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, F.3.1, F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 3 (August 11,
  2011) lmcs:784</journal-ref><doi>10.2168/LMCS-7(3:03)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The coalgebraic approach to modal logic provides a uniform framework that
captures the semantics of a large class of structurally different modal logics,
including e.g. graded and probabilistic modal logics and coalition logic. In
this paper, we introduce the coalgebraic mu-calculus, an extension of the
general (coalgebraic) framework with fixpoint operators. Our main results are
completeness of the associated tableau calculus and EXPTIME decidability for
guarded formulas. Technically, this is achieved by reducing satisfiability to
the existence of non-wellfounded tableaux, which is in turn equivalent to the
existence of winning strategies in parity games. Our results are parametric in
the underlying class of models and yield, as concrete applications, previously
unknown complexity bounds for the probabilistic mu-calculus and for an
extension of coalition logic with fixpoints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2254</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2254</id><created>2011-05-11</created><authors><author><keyname>Bonnabel</keyname><forenames>Silvere</forenames></author></authors><title>Symmetries in observer design: review of some recent results and
  applications to EKF-based SLAM</title><categories>math.OC cs.RO cs.SY</categories><comments>This paper accompanies a presentation to be given at Eighth
  International Workshop on Robot Motion and Control (RoMoCo'11)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first review the theory of symmetry-preserving observers
and we mention some recent results. Then, we apply the theory to Extended
Kalman Filter-based Simultaneous Localization and Mapping (EKF SLAM). It allows
to derive a new (symmetry-preserving) Extended Kalman Filter for the non-linear
SLAM problem that possesses convergence properties. We also prove a special
choice of the gains ensures global exponential convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2255</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2255</id><created>2011-05-11</created><authors><author><keyname>Amsterdamer</keyname><forenames>Yael</forenames></author><author><keyname>Deutch</keyname><forenames>Daniel</forenames></author><author><keyname>Tannen</keyname><forenames>Val</forenames></author></authors><title>On the Limitations of Provenance for Queries With Difference</title><categories>cs.DB</categories><comments>TAPP 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The annotation of the results of database transformations was shown to be
very effective for various applications. Until recently, most works in this
context focused on positive query languages. The provenance semirings is a
particular approach that was proven effective for these languages, and it was
shown that when propagating provenance with semirings, the expected equivalence
axioms of the corresponding query languages are satisfied. There have been
several attempts to extend the framework to account for relational algebra
queries with difference. We show here that these suggestions fail to satisfy
some expected equivalence axioms (that in particular hold for queries on
&quot;standard&quot; set and bag databases). Interestingly, we show that this is not a
pitfall of these particular attempts, but rather every such attempt is bound to
fail in satisfying these axioms, for some semirings. Finally, we show
particular semirings for which an extension for supporting difference is
(im)possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2257</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2257</id><created>2011-05-11</created><authors><author><keyname>Bialonski</keyname><forenames>Stephan</forenames></author><author><keyname>Horstmann</keyname><forenames>Marie-Therese</forenames></author><author><keyname>Lehnertz</keyname><forenames>Klaus</forenames></author></authors><title>From brain to earth and climate systems: Small-world interaction
  networks or not?</title><categories>physics.data-an cs.SI physics.soc-ph</categories><journal-ref>Chaos 20, 013134 (2010)</journal-ref><doi>10.1063/1.3360561</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider recent reports on small-world topologies of interaction networks
derived from the dynamics of spatially extended systems that are investigated
in diverse scientific fields such as neurosciences, geophysics, or meteorology.
With numerical simulations that mimic typical experimental situations we have
identified an important constraint when characterizing such networks:
indications of a small-world topology can be expected solely due to the spatial
sampling of the system along with commonly used time series analysis based
approaches to network characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2264</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2264</id><created>2011-05-11</created><authors><author><keyname>Franke</keyname><forenames>Craig</forenames></author><author><keyname>Morin</keyname><forenames>Samuel</forenames></author><author><keyname>Chebotko</keyname><forenames>Artem</forenames></author><author><keyname>Abraham</keyname><forenames>John</forenames></author><author><keyname>Brazier</keyname><forenames>Pearl</forenames></author></authors><title>Distributed Semantic Web Data Management in HBase and MySQL Cluster</title><categories>cs.DB cs.PF</categories><comments>In Proc. of the 4th IEEE International Conference on Cloud Computing
  (CLOUD'11)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Various computing and data resources on the Web are being enhanced with
machine-interpretable semantic descriptions to facilitate better search,
discovery and integration. This interconnected metadata constitutes the
Semantic Web, whose volume can potentially grow the scale of the Web. Efficient
management of Semantic Web data, expressed using the W3C's Resource Description
Framework (RDF), is crucial for supporting new data-intensive,
semantics-enabled applications. In this work, we study and compare two
approaches to distributed RDF data management based on emerging cloud computing
technologies and traditional relational database clustering technologies. In
particular, we design distributed RDF data storage and querying schemes for
HBase and MySQL Cluster and conduct an empirical comparison of these approaches
on a cluster of commodity machines using datasets and queries from the Third
Provenance Challenge and Lehigh University Benchmark. Our study reveals
interesting patterns in query evaluation, shows that our algorithms are
promising, and suggests that cloud computing has a great potential for scalable
Semantic Web data management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2274</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2274</id><created>2011-05-11</created><authors><author><keyname>Ouyang</keyname><forenames>Hua</forenames></author><author><keyname>Gray</keyname><forenames>Alexander</forenames></author></authors><title>Data-Distributed Weighted Majority and Online Mirror Descent</title><categories>cs.LG cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on the question of the extent to which online
learning can benefit from distributed computing. We focus on the setting in
which $N$ agents online-learn cooperatively, where each agent only has access
to its own data. We propose a generic data-distributed online learning
meta-algorithm. We then introduce the Distributed Weighted Majority and
Distributed Online Mirror Descent algorithms, as special cases. We show, using
both theoretical analysis and experiments, that compared to a single agent:
given the same computation time, these distributed algorithms achieve smaller
generalization errors; and given the same generalization errors, they can be
$N$ times faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2279</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2279</id><created>2011-05-11</created><authors><author><keyname>Winter</keyname><forenames>Frank</forenames></author></authors><title>Accelerating QDP++ using GPUs</title><categories>hep-lat cs.DC cs.PL physics.comp-ph</categories><comments>6 pages, 3 figures</comments><report-no>Edinburgh 2011/17</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphic Processing Units (GPUs) are getting increasingly important as target
architectures in scientific High Performance Computing (HPC). NVIDIA
established CUDA as a parallel computing architecture controlling and making
use of the compute power of GPUs. CUDA provides sufficient support for C++
language elements to enable the Expression Template (ET) technique in the
device memory domain. QDP++ is a C++ vector class library suited for quantum
field theory which provides vector data types and expressions and forms the
basis of the lattice QCD software suite Chroma. In this work accelerating QDP++
expression evaluation to a GPU was successfully implemented leveraging the ET
technique and using Just-In-Time (JIT) compilation. The Portable Expression
Template Engine (PETE) and the C API for CUDA kernel arguments were used to
build the bridge between host and device memory domains. This provides the
possibility to accelerate Chroma routines to a GPU which are typically not
subject to special optimisation. As an application example a smearing routine
was accelerated to execute on a GPU. A significant speed-up compared to normal
CPU execution could be measured.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2283</identifier>
 <datestamp>2011-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2283</id><created>2011-05-11</created><authors><author><keyname>B&#xfc;hler</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>The Deterministic Sum Capacity of a Multiple Access Channel Interfering
  with a Point to Point Link</title><categories>cs.IT math.IT</categories><comments>5 pages, submitted to IEEE Information Theory Workshop (ITW), 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use the linear deterministic approximation model to study a
two user multiple access channel mutually interfering with a point to point
link, which represents a basic setup of a cellular system. We derive outer
bounds on the achievable sum rate and construct coding schemes achieving the
outer bounds. For a large parameter range, the sum capacity is identical to the
sum capacity of the interference channel obtained by silencing the weaker user
in the multiple access channel. For other interference configurations, the sum
rate can be increased using interference alignment, which exploits the channel
gain difference of the users in the multiple access channel. From these
results, lower bounds on the generalized degrees of freedom for the Gaussian
counterpart are derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2291</identifier>
 <datestamp>2011-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2291</id><created>2011-05-11</created><updated>2011-10-28</updated><authors><author><keyname>Katz</keyname><forenames>Daniel J.</forenames></author></authors><title>Proof of a Conjecture of Helleseth: Maximal Linear Recursive Sequences
  of Period $2^{2^n}-1$ Never Have Three-Valued Cross-Correlation</title><categories>math.CO cs.IT math.IT</categories><comments>5 pages, fixes typos in first version</comments><msc-class>11T24, 11T71, 94A55, 94B15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove a conjecture of Helleseth that claims that for any $n \geq 0$, a
pair of binary maximal linear sequences of period $2^{2^n}-1$ can not have a
three-valued cross-correlation function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2292</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2292</id><created>2011-05-11</created><authors><author><keyname>Ling</keyname><forenames>Yibei</forenames></author><author><keyname>Chen</keyname><forenames>ChungMin</forenames></author><author><keyname>Chen</keyname><forenames>Shigang</forenames></author></authors><title>Analysis of Power-aware Buffering Schemes in Wireless Sensor Networks</title><categories>cs.NI</categories><acm-class>F.2.m; H.4.0</acm-class><journal-ref>ACM Transactions on Sensor Network, Vol. 7, No. 3, 2010</journal-ref><doi>10.1145/1807048.1807055</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the power-aware buffering problem in battery-powered sensor
networks, focusing on the fixed-size and fixed-interval buffering schemes. The
main motivation is to address the yet poorly understood size variation-induced
effect on power-aware buffering schemes. Our theoretical analysis elucidates
the fundamental differences between the fixed-size and fixed-interval buffering
schemes in the presence of data size variation. It shows that data size
variation has detrimental effects on the power expenditure of the fixed-size
buffering in general, and reveals that the size variation induced effects can
be either mitigated by a positive skewness or promoted by a negative skewness
in size distribution. By contrast, the fixed-interval buffering scheme has an
obvious advantage of being eminently immune to the data-size variation. Hence
the fixed-interval buffering scheme is a risk-averse strategy for its
robustness in a variety of operational environments. In addition, based on the
fixed-interval buffering scheme, we establish the power consumption
relationship between child nodes and parent node in a static data collection
tree, and give an in-depth analysis of the impact of child bandwidth
distribution on parent's power consumption.
  This study is of practical significance: it sheds new light on the
relationship among power consumption of buffering schemes, power parameters of
radio module and memory bank, data arrival rate and data size variation,
thereby providing well-informed guidance in determining an optimal buffer size
(interval) to maximize the operational lifespan of sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2301</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2301</id><created>2011-05-11</created><updated>2014-07-29</updated><authors><author><keyname>D'Angelo</keyname><forenames>Gabriele</forenames></author></authors><title>Parallel and Distributed Simulation from Many Cores to the Public Cloud
  (Extended Version)</title><categories>cs.DC</categories><comments>Tutorial paper published in the Proceedings of the International
  Conference on High Performance Computing and Simulation (HPCS 2011). Istanbul
  (Turkey), IEEE, July 2011. ISBN 978-1-61284-382-7</comments><doi>10.1109/HPCSim.2011.5999802</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this tutorial paper, we will firstly review some basic simulation concepts
and then introduce the parallel and distributed simulation techniques in view
of some new challenges of today and tomorrow. More in particular, in the last
years there has been a wide diffusion of many cores architectures and we can
expect this trend to continue. On the other hand, the success of cloud
computing is strongly promoting the everything as a service paradigm. Is
parallel and distributed simulation ready for these new challenges? The current
approaches present many limitations in terms of usability and adaptivity: there
is a strong need for new evaluation metrics and for revising the currently
implemented mechanisms. In the last part of the paper, we propose a new
approach based on multi-agent systems for the simulation of complex systems. It
is possible to implement advanced techniques such as the migration of simulated
entities in order to build mechanisms that are both adaptive and very easy to
use. Adaptive mechanisms are able to significantly reduce the communication
cost in the parallel/distributed architectures, to implement load-balance
techniques and to cope with execution environments that are both variable and
dynamic. Finally, such mechanisms will be used to build simulations on top of
unreliable cloud services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2311</identifier>
 <datestamp>2014-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2311</id><created>2011-05-11</created><updated>2013-07-19</updated><authors><author><keyname>Venkataramanan</keyname><forenames>Ramji</forenames></author><author><keyname>Pradhan</keyname><forenames>S. Sandeep</forenames></author></authors><title>An Achievable Rate Region for the Broadcast Channel with Feedback</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory. Contains
  example of AWGN Broadcast Channel with noisy feedback</comments><journal-ref>IEEE Transactions on Information Theory, vol. 59, no.10, pp. 6175
  - 6191, Oct. 2013</journal-ref><doi>10.1109/TIT.2013.2268532</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A single-letter achievable rate region is proposed for the two-receiver
discrete memoryless broadcast channel with generalized feedback. The coding
strategy involves block-Markov superposition coding, using Marton's coding
scheme for the broadcast channel without feedback as the starting point. If the
message rates in the Marton scheme are too high to be decoded at the end of a
block, each receiver is left with a list of messages compatible with its
output. Resolution information is sent in the following block to enable each
receiver to resolve its list. The key observation is that the resolution
information of the first receiver is correlated with that of the second. This
correlated information is efficiently transmitted via joint source-channel
coding, using ideas similar to the Han-Costa coding scheme. Using the result,
we obtain an achievable rate region for the stochastically degraded AWGN
broadcast channel with noisy feedback from only one receiver. It is shown that
this region is strictly larger than the no-feedback capacity region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2335</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2335</id><created>2011-05-11</created><authors><author><keyname>Fern&#xe1;ndez</keyname><forenames>Alejandro</forenames></author></authors><title>Hierarchical Complexity: Measures of High Level Modularity</title><categories>cs.SE</categories><comments>5 figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Software is among the most complex endeavors of the human mind; large scale
systems can have tens of millions of lines of source code. However, seldom is
complexity measured above the lowest level of code, and sometimes source code
files or low level modules. In this paper a hierarchical approach is explored
in order to find a set of metrics that can measure higher levels of
organization. These metrics are then used on a few popular free software
packages (totaling more than 25 million lines of code) to check their
efficiency and coherency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2344</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2344</id><created>2011-05-11</created><authors><author><keyname>McFee</keyname><forenames>Brian</forenames></author><author><keyname>Barrington</keyname><forenames>Luke</forenames></author><author><keyname>Lanckriet</keyname><forenames>Gert</forenames></author></authors><title>Learning content similarity for music recommendation</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many tasks in music information retrieval, such as recommendation, and
playlist generation for online radio, fall naturally into the query-by-example
setting, wherein a user queries the system by providing a song, and the system
responds with a list of relevant or similar song recommendations. Such
applications ultimately depend on the notion of similarity between items to
produce high-quality results. Current state-of-the-art systems employ
collaborative filter methods to represent musical items, effectively comparing
items in terms of their constituent users. While collaborative filter
techniques perform well when historical data is available for each item, their
reliance on historical data impedes performance on novel or unpopular items. To
combat this problem, practitioners rely on content-based similarity, which
naturally extends to novel items, but is typically out-performed by
collaborative filter methods.
  In this article, we propose a method for optimizing contentbased similarity
by learning from a sample of collaborative filter data. The optimized
content-based similarity metric can then be applied to answer queries on novel
and unpopular items, while still maintaining high recommendation accuracy. The
proposed system yields accurate and efficient representations of audio content,
and experimental results show significant improvements in accuracy over
competing content-based recommendation techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2361</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2361</id><created>2011-05-11</created><authors><author><keyname>Alves</keyname><forenames>Marcelo Muniz S.</forenames></author></authors><title>A standard form for generator matrices with respect to the
  Niederreiter-Rosenbloom-Tsfasman metric</title><categories>cs.IT math.IT math.NT</categories><msc-class>11T71</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we present an analogue for codes in vector spaces with a
Rosenbloom-Tsfasman metric of the well-known standard form of generator
matrices for codes in spaces with the Hamming metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2375</identifier>
 <datestamp>2012-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2375</id><created>2011-05-12</created><updated>2012-11-02</updated><authors><author><keyname>Bharath</keyname><forenames>B. N.</forenames></author><author><keyname>Murthy</keyname><forenames>Chandra R.</forenames></author></authors><title>On the DMT of TDD-SIMO Systems with Channel-Dependent Reverse Channel
  Training</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in IEEE Transactions on Communications</comments><doi>10.1109/TCOMM.2012.082712.110820</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the Diversity-Multiplexing gain Trade-off (DMT) of a
training based reciprocal Single Input Multiple Output (SIMO) system, with (i)
perfect Channel State Information (CSI) at the Receiver (CSIR) and noisy CSI at
the Transmitter (CSIT), and (ii) noisy CSIR and noisy CSIT. In both the cases,
the CSIT is acquired through Reverse Channel Training (RCT), i.e., by sending a
training sequence from the receiver to the transmitter. A channel-dependent
fixed-power training scheme is proposed for acquiring CSIT, along with a
forward-link data transmit power control scheme. With perfect CSIR, the
proposed scheme is shown to achieve a diversity order that is quadratically
increasing with the number of receive antennas. This is in contrast with
conventional orthogonal RCT schemes, where the diversity order is known to
saturate as the number of receive antennas is increased, for a given channel
coherence time. Moreover, the proposed scheme can achieve a larger DMT compared
to the orthogonal training scheme. With noisy CSIR and noisy CSIT, a three-way
training scheme is proposed and its DMT performance is analyzed. It is shown
that nearly the same diversity order is achievable as in the perfect CSIR case.
The time-overhead in the training schemes is explicitly accounted for in this
work, and the results show that the proposed channel-dependent RCT and data
power control schemes offer a significant improvement in terms of the DMT,
compared to channel-agnostic orthogonal RCT schemes. The outage performance of
the proposed scheme is illustrated through Monte-Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2377</identifier>
 <datestamp>2012-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2377</id><created>2011-05-12</created><authors><author><keyname>Marchand</keyname><forenames>Katy</forenames></author><author><keyname>Mulherkar</keyname><forenames>Jaideep</forenames></author><author><keyname>Nachtergaele</keyname><forenames>Bruno</forenames></author></authors><title>Entropy rate calculations of algebraic measures</title><categories>cs.IT math.IT</categories><msc-class>94A15</msc-class><journal-ref>2012 IEEE International Symposium on Information Theory
  Proceedings, 1072-1076 (2012)</journal-ref><doi>10.1109/ISIT.2012.6283017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $K = \{0,1,...,q-1\}$. We use a special class of translation invariant
measures on $K^\mathbb{Z}$ called algebraic measures to study the entropy rate
of a hidden Markov processes. Under some irreducibility assumptions of the
Markov transition matrix we derive exact formulas for the entropy rate of a
general $q$ state hidden Markov process derived from a Markov source corrupted
by a specific noise model. We obtain upper bounds on the error when using an
approximation to the formulas and numerically compute the entropy rates of two
and three state hidden Markov models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2391</identifier>
 <datestamp>2011-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2391</id><created>2011-05-12</created><updated>2011-10-27</updated><authors><author><keyname>An</keyname><forenames>Hyung-Chan</forenames></author><author><keyname>Shmoys</keyname><forenames>David B.</forenames></author></authors><title>LP-Based Approximation Algorithms for Traveling Salesman Path Problems</title><categories>cs.DS</categories><comments>This paper has been merged into 1110.4604</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been merged into 1110.4604.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2392</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2392</id><created>2011-05-12</created><authors><author><keyname>Autexier</keyname><forenames>Serge</forenames></author><author><keyname>David</keyname><forenames>Catalin</forenames></author><author><keyname>Dietrich</keyname><forenames>Dominik</forenames></author><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author><author><keyname>Zholudev</keyname><forenames>Vyacheslav</forenames></author></authors><title>Workflows for the Management of Change in Science, Technologies,
  Engineering and Mathematics</title><categories>cs.DL</categories><comments>16 pages, Conference on Intelligent Computer Mathematics 2011, July,
  Bertinoro, Italy</comments><msc-class>68U35</msc-class><acm-class>E.2; H.3.7; H.3.6; G.4; F.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical knowledge is a central component in science, engineering, and
technology (documentation). Most of it is represented informally, and -- in
contrast to published research mathematics -- subject to continual change.
Unfortunately, machine support for change management has either been very
coarse grained and thus barely useful, or restricted to formal languages, where
automation is possible. In this paper, we report on an effort to extend change
management to collections of semi-formal documents which flexibly intermix
mathematical formulas and natural language and to integrate it into a semantic
publishing system for mathematical knowledge. We validate the long-standing
assumption that the semantic annotations in these flexiformal documents that
drive the machine-supported interaction with documents can support semantic
impact analyses at the same time. But in contrast to the fully formal setting,
where adaptations of impacted documents can be automated to some degree, the
flexiformal setting requires much more user interaction and thus a much tighter
integration into document management workflows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2397</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2397</id><created>2011-05-12</created><authors><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Kavitha</keyname><forenames>Telikepalli</forenames></author><author><keyname>Mathew</keyname><forenames>Rogers</forenames></author><author><keyname>Sen</keyname><forenames>Siddhartha</forenames></author><author><keyname>Tarjan</keyname><forenames>Robert Endre</forenames></author></authors><title>Incremental Cycle Detection, Topological Ordering, and Strong Component
  Maintenance</title><categories>cs.DS</categories><comments>31 pages</comments><acm-class>F.2.2; G.2.2; E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two on-line algorithms for maintaining a topological order of a
directed $n$-vertex acyclic graph as arcs are added, and detecting a cycle when
one is created. Our first algorithm handles $m$ arc additions in $O(m^{3/2})$
time. For sparse graphs ($m/n = O(1)$), this bound improves the best previous
bound by a logarithmic factor, and is tight to within a constant factor among
algorithms satisfying a natural {\em locality} property. Our second algorithm
handles an arbitrary sequence of arc additions in $O(n^{5/2})$ time. For
sufficiently dense graphs, this bound improves the best previous bound by a
polynomial factor. Our bound may be far from tight: we show that the algorithm
can take $\Omega(n^2 2^{\sqrt{2\lg n}})$ time by relating its performance to a
generalization of the $k$-levels problem of combinatorial geometry. A
completely different algorithm running in $\Theta(n^2 \log n)$ time was given
recently by Bender, Fineman, and Gilbert. We extend both of our algorithms to
the maintenance of strong components, without affecting the asymptotic time
bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2416</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2416</id><created>2011-05-12</created><updated>2011-05-19</updated><authors><author><keyname>Seldin</keyname><forenames>Yevgeny</forenames></author><author><keyname>Laviolette</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Shawe-Taylor</keyname><forenames>John</forenames></author><author><keyname>Peters</keyname><forenames>Jan</forenames></author><author><keyname>Auer</keyname><forenames>Peter</forenames></author></authors><title>PAC-Bayesian Analysis of Martingales and Multiarmed Bandits</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two alternative ways to apply PAC-Bayesian analysis to sequences
of dependent random variables. The first is based on a new lemma that enables
to bound expectations of convex functions of certain dependent random variables
by expectations of the same functions of independent Bernoulli random
variables. This lemma provides an alternative tool to Hoeffding-Azuma
inequality to bound concentration of martingale values. Our second approach is
based on integration of Hoeffding-Azuma inequality with PAC-Bayesian analysis.
We also introduce a way to apply PAC-Bayesian analysis in situation of limited
feedback. We combine the new tools to derive PAC-Bayesian generalization and
regret bounds for the multiarmed bandit problem. Although our regret bound is
not yet as tight as state-of-the-art regret bounds based on other
well-established techniques, our results significantly expand the range of
potential applications of PAC-Bayesian analysis and introduce a new analysis
tool to reinforcement learning and many other fields, where martingales and
limited feedback are encountered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2422</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2422</id><created>2011-05-12</created><authors><author><keyname>Wu</keyname><forenames>Xiaofu</forenames></author><author><keyname>Zeng</keyname><forenames>Weijun</forenames></author><author><keyname>Zhao</keyname><forenames>Chunming</forenames></author><author><keyname>You</keyname><forenames>Xiaohu</forenames></author></authors><title>Joint Network and LDPC Coding for Bi-directional Relaying</title><categories>cs.IT math.IT</categories><comments>3 pages, 1 figures, submitted to ICITIS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider joint network and LDPC coding for practically
implementing the denosie-and-forward protocol over bi-directional relaying. the
closed-form expressions for computing the log-likelihood ratios of the
network-coded codewords have been derived for both real and complex
multiple-access channels. It is revealed that the equivalent channel observed
at the relay is an asymmetrical channel, where the channel input is the XOR
form of the two source nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2432</identifier>
 <datestamp>2014-04-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2432</id><created>2011-05-12</created><updated>2014-04-03</updated><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Schaefer</keyname><forenames>Guido</forenames></author></authors><title>Selfishness Level of Strategic Games</title><categories>cs.GT</categories><comments>34 pages</comments><journal-ref>Journal of AI Research (JAIR) 49 (2014), pp. 207-240,
  doi:10.1613/jair.4164</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new measure of the discrepancy in strategic games between the
social welfare in a Nash equilibrium and in a social optimum, that we call
selfishness level. It is the smallest fraction of the social welfare that needs
to be offered to each player to achieve that a social optimum is realized in a
pure Nash equilibrium. The selfishness level is unrelated to the price of
stability and the price of anarchy and is invariant under positive linear
transformations of the payoff functions. Also, it naturally applies to other
solution concepts and other forms of games.
  We study the selfishness level of several well-known strategic games. This
allows us to quantify the implicit tension within a game between players'
individual interests and the impact of their decisions on the society as a
whole. Our analyses reveal that the selfishness level often provides a deeper
understanding of the characteristics of the underlying game that influence the
players' willingness to cooperate.
  In particular, the selfishness level of finite ordinal potential games is
finite, while that of weakly acyclic games can be infinite. We derive explicit
bounds on the selfishness level of fair cost sharing games and linear
congestion games, which depend on specific parameters of the underlying game
but are independent of the number of players. Further, we show that the
selfishness level of the $n$-players Prisoner's Dilemma is $c/(b(n-1)-c)$,
where $b$ and $c$ are the benefit and cost for cooperation, respectively, that
of the $n$-players public goods game is $(1-\frac{c}{n})/(c-1)$, where $c$ is
the public good multiplier, and that of the Traveler's Dilemma game is
$\frac{1}{2}(b-1)$, where $b$ is the bonus. Finally, the selfishness level of
Cournot competition (an example of an infinite ordinal potential game, Tragedy
of the Commons, and Bertrand competition is infinite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2434</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2434</id><created>2011-05-12</created><updated>2012-04-26</updated><authors><author><keyname>Apt</keyname><forenames>Krzysztof R.</forenames></author><author><keyname>Markakis</keyname><forenames>Evangelos</forenames></author></authors><title>Diffusion in Social Networks with Competing Products</title><categories>cs.SI cs.DS physics.soc-ph</categories><comments>13 pages. Appeared in Proc. 4th International Symposium on
  Algorithmic Game Theory, (SAGT 2011), Lecture Notes in Computer Science 6982,
  Springer, pp. 212-223</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new threshold model of social networks, in which the nodes
influenced by their neighbours can adopt one out of several alternatives. We
characterize the graphs for which adoption of a product by the whole network is
possible (respectively necessary) and the ones for which a unique outcome is
guaranteed. These characterizations directly yield polynomial time algorithms
that allow us to determine whether a given social network satisfies one of the
above properties.
  We also study algorithmic questions for networks without unique outcomes. We
show that the problem of computing the minimum possible spread of a product is
NP-hard to approximate with an approximation ratio better than $\Omega(n)$, in
contrast to the maximum spread, which is efficiently computable. We then move
on to questions regarding the behavior of a node with respect to adopting some
(resp. a given) product. We show that the problem of determining whether a
given node has to adopt some (resp. a given) product in all final networks is
co-NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2441</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2441</id><created>2011-05-12</created><authors><author><keyname>Mutschke</keyname><forenames>Peter</forenames></author><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author><author><keyname>Schaer</keyname><forenames>Philipp</forenames></author><author><keyname>Sure</keyname><forenames>York</forenames></author></authors><title>Science Models as Value-Added Services for Scholarly Information Systems</title><categories>cs.DL cs.IR</categories><comments>26 pages, to appear in Scientometrics</comments><acm-class>H.3.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The paper introduces scholarly Information Retrieval (IR) as a further
dimension that should be considered in the science modeling debate. The IR use
case is seen as a validation model of the adequacy of science models in
representing and predicting structure and dynamics in science. Particular
conceptualizations of scholarly activity and structures in science are used as
value-added search services to improve retrieval quality: a co-word model
depicting the cognitive structure of a field (used for query expansion), the
Bradford law of information concentration, and a model of co-authorship
networks (both used for re-ranking search results). An evaluation of the
retrieval quality when science model driven services are used turned out that
the models proposed actually provide beneficial effects to retrieval quality.
From an IR perspective, the models studied are therefore verified as expressive
conceptualizations of central phenomena in science. Thus, it could be shown
that the IR perspective can significantly contribute to a better understanding
of scholarly structures and activities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2443</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2443</id><created>2011-05-12</created><authors><author><keyname>Thamm</keyname><forenames>Mark</forenames></author><author><keyname>Mayr</keyname><forenames>Philipp</forenames></author></authors><title>Comparing webometric with web-independent rankings: a case study with
  German universities</title><categories>cs.SI cs.DL physics.soc-ph</categories><comments>3 pages, ACM Web Science 2011</comments><acm-class>H.5.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we examine if hyperlink-based (webometric) indicators can be
used to rank academic websites. Therefore we analyzed the interlinking
structure of German university websites and compared our simple hyperlink-based
ranking with official and web-independent rankings of universities. We found
that link impact could not easily be seen as a prestige factor for
universities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2447</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2447</id><created>2011-05-12</created><updated>2014-07-28</updated><authors><author><keyname>D'Angelo</keyname><forenames>Gabriele</forenames></author><author><keyname>Ferretti</keyname><forenames>Stefano</forenames></author></authors><title>LUNES: Agent-based Simulation of P2P Systems (Extended Version)</title><categories>cs.DC cs.MA cs.NI</categories><comments>Proceedings of the International Workshop on Modeling and Simulation
  of Peer-to-Peer Architectures and Systems (MOSPAS 2011). As part of the 2011
  International Conference on High Performance Computing and Simulation (HPCS
  2011)</comments><doi>10.1109/HPCSim.2011.5999879</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present LUNES, an agent-based Large Unstructured NEtwork Simulator, which
allows to simulate complex networks composed of a high number of nodes. LUNES
is modular, since it splits the three phases of network topology creation,
protocol simulation and performance evaluation. This permits to easily
integrate external software tools into the main software architecture. The
simulation of the interaction protocols among network nodes is performed via a
simulation middleware that supports both the sequential and the
parallel/distributed simulation approaches. In the latter case, a specific
mechanism for the communication overhead-reduction is used; this guarantees
high levels of performance and scalability. To demonstrate the efficiency of
LUNES, we test the simulator with gossip protocols executed on top of networks
(representing peer-to-peer overlays), generated with different topologies.
Results demonstrate the effectiveness of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2458</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2458</id><created>2011-05-12</created><updated>2014-07-28</updated><authors><author><keyname>D'Angelo</keyname><forenames>Gabriele</forenames></author><author><keyname>Ferretti</keyname><forenames>Stefano</forenames></author><author><keyname>Ghini</keyname><forenames>Vittorio</forenames></author><author><keyname>Panzieri</keyname><forenames>Fabio</forenames></author></authors><title>Mobile Computing in Digital Ecosystems: Design Issues and Challenges</title><categories>cs.NI cs.ET</categories><comments>Proceedings of the 7th International wireless Communications and
  Mobile Computing conference (IWCMC-2011), Emergency Management: Communication
  and Computing Platforms Workshop</comments><doi>10.1109/IWCMC.2011.5982863</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we argue that the set of wireless, mobile devices (e.g.,
portable telephones, tablet PCs, GPS navigators, media players) commonly used
by human users enables the construction of what we term a digital ecosystem,
i.e., an ecosystem constructed out of so-called digital organisms (see below),
that can foster the development of novel distributed services. In this context,
a human user equipped with his/her own mobile devices, can be though of as a
digital organism (DO), a subsystem characterized by a set of peculiar features
and resources it can offer to the rest of the ecosystem for use from its peer
DOs. The internal organization of the DO must address issues of management of
its own resources, including power consumption. Inside the DO and among DOs,
peer-to-peer interaction mechanisms can be conveniently deployed to favor
resource sharing and data dissemination. Throughout this paper, we show that
most of the solutions and technologies needed to construct a digital ecosystem
are already available. What is still missing is a framework (i.e., mechanisms,
protocols, services) that can support effectively the integration and
cooperation of these technologies. In addition, in the following we show that
that framework can be implemented as a middleware subsystem that enables novel
and ubiquitous forms of computation and communication. Finally, in order to
illustrate the effectiveness of our approach, we introduce some experimental
results we have obtained from preliminary implementations of (parts of) that
subsystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2459</identifier>
 <datestamp>2012-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2459</id><created>2011-05-12</created><updated>2012-12-21</updated><authors><author><keyname>Aldecoa</keyname><forenames>Rodrigo</forenames></author><author><keyname>Mar&#xed;n</keyname><forenames>Ignacio</forenames></author></authors><title>Deciphering Network Community Structure by Surprise</title><categories>q-bio.MN cs.SI physics.soc-ph</categories><comments>7 pages, 5 figures</comments><journal-ref>PLoS ONE 6(9): e24195 (2011)</journal-ref><doi>10.1371/journal.pone.0024195</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of complex networks permeates all sciences, from biology to
sociology. A fundamental, unsolved problem is how to characterize the community
structure of a network. Here, using both standard and novel benchmarks, we show
that maximization of a simple global parameter, which we call Surprise (S),
leads to a very efficient characterization of the community structure of
complex synthetic networks. Particularly, S qualitatively outperforms the most
commonly used criterion to define communities, Newman and Girvan's modularity
(Q). Applying S maximization to real networks often provides natural,
well-supported partitions, but also sometimes counterintuitive solutions that
expose the limitations of our previous knowledge. These results indicate that
it is possible to define an effective global criterion for community structure
and open new routes for the understanding of complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2461</identifier>
 <datestamp>2012-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2461</id><created>2011-05-12</created><updated>2012-03-07</updated><authors><author><keyname>Devismes</keyname><forenames>St&#xe9;phane</forenames><affiliation>VERIMAG - IMAG</affiliation></author><author><keyname>Lamani</keyname><forenames>Anissa</forenames><affiliation>MIS</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Raymond</keyname><forenames>Pascal</forenames><affiliation>VERIMAG - IMAG</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6, IUF</affiliation></author></authors><title>Optimal grid exploration by asynchronous oblivious robots</title><categories>cs.DC cs.DM cs.NI cs.RO</categories><comments>27 pages</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a team of {\em autonomous weak robots} that are endowed with
visibility sensors and motion actuators. Autonomous means that the team cannot
rely on any kind of central coordination mechanism or scheduler. By weak we
mean that the robots are devoid of (1) any (observable) IDs allowing to
differentiate them (anonymous), (2) means of communication allowing them to
communicate directly, and (3) any way to remember any previous observation nor
computation performed in any previous step (oblivious). Robots asynchronously
operate in cycles of three phases: Look, Compute, and Move. Furthermore, the
network is an anonymous unoriented grid. In such settings, the robots must
collaborate to solve a collective task, here the terminating grid exploration
(exploration for short), despite being limited with respect to input from the
environment, asymmetry, memory, etc. Exploration requires that robots explore
the grid and stop when the task is complete. We propose optimal (w.r.t. the
number of robots) solutions for the deterministic terminating exploration of a
grid shaped network by a team of $k$ asynchronous oblivious robots in the fully
asynchronous and non-atomic model, so called CORDA. In more details, we first
assume the ATOM model in which each Look-Compute-Move cycle execution is
executed atomically, ie every robot that is activated at instant t
instantaneously executes a full cycle between t and t+1. ATOM being strictly
stronger than CORDA, all impossibility results in ATOM also hold in CORDA. We
show that it is impossible to explore a grid of at least three nodes with less
than three robots in ATOM. (This first result holds for both deterministic and
probabilistic settings.) Next, we show that it is impossible to
deterministically explore a (2,2)-Grid with less than 4 robots, and a
(3,3)-Grid with less than 5 robots, respectively. Then, we propose
deterministic algorithms in CORDA to exhibit the optimal number of robots
allowing to explore of a given grid. Our results show that except in two
particular cases, 3 robots are necessary and sufficient to deterministically
explore a grid of at least three nodes. The optimal number of robots for the
two remaining cases is: 4 for the (2,2)-Grid and 5 for the (3,3)-Grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2470</identifier>
 <datestamp>2012-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2470</id><created>2011-05-12</created><updated>2012-04-18</updated><authors><author><keyname>Georgeot</keyname><forenames>Bertrand</forenames></author><author><keyname>Giraud</keyname><forenames>Olivier</forenames></author></authors><title>The game of go as a complex network</title><categories>cs.GT cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>6 pages, 9 figures, final version</comments><journal-ref>Europhysics Letters 97, 68002 (2012)</journal-ref><doi>10.1209/0295-5075/97/68002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the game of go from a complex network perspective. We construct a
directed network using a suitable definition of tactical moves including local
patterns, and study this network for different datasets of professional
tournaments and amateur games. The move distribution follows Zipf's law and the
network is scale free, with statistical peculiarities different from other real
directed networks, such as e. g. the World Wide Web. These specificities
reflect in the outcome of ranking algorithms applied to it. The fine study of
the eigenvalues and eigenvectors of matrices used by the ranking algorithms
singles out certain strategic situations. Our results should pave the way to a
better modelization of board games and other types of human strategic scheming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2491</identifier>
 <datestamp>2011-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2491</id><created>2011-05-12</created><updated>2011-06-23</updated><authors><author><keyname>Satta</keyname><forenames>Riccardo</forenames></author><author><keyname>Fumera</keyname><forenames>Giorgio</forenames></author><author><keyname>Roli</keyname><forenames>Fabio</forenames></author><author><keyname>Cristani</keyname><forenames>Marco</forenames></author><author><keyname>Murino</keyname><forenames>Vittorio</forenames></author></authors><title>A Multiple Component Matching Framework for Person Re-Identification</title><categories>cs.CV</categories><comments>Accepted paper, 16th Int. Conf. on Image Analysis and Processing
  (ICIAP 2011), Ravenna, Italy, 14/09/2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Person re-identification consists in recognizing an individual that has
already been observed over a network of cameras. It is a novel and challenging
research topic in computer vision, for which no reference framework exists yet.
Despite this, previous works share similar representations of human body based
on part decomposition and the implicit concept of multiple instances. Building
on these similarities, we propose a Multiple Component Matching (MCM) framework
for the person re-identification problem, which is inspired by Multiple
Component Learning, a framework recently proposed for object detection. We show
that previous techniques for person re-identification can be considered
particular implementations of our MCM framework. We then present a novel person
re-identification technique as a direct, simple implementation of our
framework, focused in particular on robustness to varying lighting conditions,
and show that it can attain state of the art performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2525</identifier>
 <datestamp>2013-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2525</id><created>2011-05-12</created><updated>2013-08-14</updated><authors><author><keyname>Ballerstein</keyname><forenames>Kathrin</forenames></author><author><keyname>Theis</keyname><forenames>Dirk Oliver</forenames></author></authors><title>An algorithm for random signed 3-SAT with Intervals</title><categories>math.CO cs.DM cs.DS</categories><comments>30 pages + appendix</comments><msc-class>68Q87, 68W40, 05C80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In signed k-SAT problems, one fixes a set M and a set $\mathcal S$ of subsets
of M, and is given a formula consisting of a disjunction of m clauses, each of
which is a conjunction of k literals. Each literal is of the form &quot;$x \in S$&quot;,
where $S \in \mathcal S$, and x is one of n variables.
  For Interval-SAT (iSAT), M is an ordered set and $\mathcal S$ the set of
intervals in M.
  We propose an algorithm for 3-iSAT, and analyze it on uniformly random
formulas. The algorithm follows the Unit Clause paradigm, enhanced by a (very
limited) backtracking option. Using Wormald's ODE method, we prove that, if
$m/n \le 2.3$, with high probability, our algorithm succeeds in finding an
assignment of values to the variables satisfying the formula.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2526</identifier>
 <datestamp>2011-06-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2526</id><created>2011-05-12</created><updated>2011-06-10</updated><authors><author><keyname>Blocker</keyname><forenames>Alexander W.</forenames></author><author><keyname>Airoldi</keyname><forenames>Edoardo M.</forenames></author></authors><title>Deconvolution of mixing time series on a graph</title><categories>stat.ME cs.SI</categories><comments>10 pages, 11 page supplement; updated with minor edits; accepted into
  UAI 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many applications we are interested in making inference on latent time
series from indirect measurements, which are often low-dimensional projections
resulting from mixing or aggregation. Positron emission tomography,
super-resolution, and network traffic monitoring are some examples. Inference
in such settings requires solving a sequence of ill-posed inverse problems,
y_t= A x_t, where the projection mechanism provides information on A. We
consider problems in which A specifies mixing on a graph of times series that
are bursty and sparse. We develop a multilevel state-space model for mixing
times series and an efficient approach to inference. A simple model is used to
calibrate regularization parameters that lead to efficient inference in the
multilevel state-space model. We apply this method to the problem of estimating
point-to-point traffic flows on a network from aggregate measurements. Our
solution outperforms existing methods for this problem, and our two-stage
approach suggests an efficient inference strategy for multilevel models of
dependent time series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2541</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2541</id><created>2011-05-12</created><updated>2011-06-20</updated><authors><author><keyname>Young</keyname><forenames>George Forrest</forenames></author><author><keyname>Scardovi</keyname><forenames>Luca</forenames></author><author><keyname>Leonard</keyname><forenames>Naomi Ehrich</forenames></author></authors><title>Rearranging trees for robust consensus</title><categories>math.OC cs.SY</categories><comments>Submitted to CDC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use the H2 norm associated with a communication graph to
characterize the robustness of consensus to noise. In particular, we restrict
our attention to trees and by systematic attention to the effect of local
changes in topology, we derive a partial ordering for undirected trees
according to the H2 norm. Our approach for undirected trees provides a
constructive method for deriving an ordering for directed trees. Further, our
approach suggests a decentralized manner in which trees can be rearranged in
order to improve their robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2550</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2550</id><created>2011-05-12</created><updated>2011-07-25</updated><authors><author><keyname>Di Castro</keyname><forenames>Dotan</forenames></author><author><keyname>Gentile</keyname><forenames>Claudio</forenames></author><author><keyname>Mannor</keyname><forenames>Shie</forenames></author></authors><title>A Maximal Large Deviation Inequality for Sub-Gaussian Variables</title><categories>cs.LG</categories><comments>This paper has been withdrawn by the authors due to a crucial error
  in the last sentence of the proof of Theorem 1: &quot;we can take the infimum of
  the r.h.s. over s, which yields (1).&quot; This statement is only true if a single
  value of s yields the supremum of (\epsilon_i s - \rho_i(s)) simultaneously
  for every i</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short note we prove a maximal concentration lemma for sub-Gaussian
random variables stating that for independent sub-Gaussian random variables we
have \[P&lt;(\max_{1\le i\le N}S_{i}&gt;\epsilon&gt;)
\le\exp&lt;(-\frac{1}{N^2}\sum_{i=1}^{N}\frac{\epsilon^{2}}{2\sigma_{i}^{2}}&gt;), \]
where $S_i$ is the sum of $i$ zero mean independent sub-Gaussian random
variables and $\sigma_i$ is the variance of the $i$th random variable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2554</identifier>
 <datestamp>2011-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2554</id><created>2011-05-12</created><authors><author><keyname>Auhagen</keyname><forenames>Sven</forenames></author><author><keyname>Bergstrom</keyname><forenames>Lars</forenames></author><author><keyname>Fluet</keyname><forenames>Matthew</forenames></author><author><keyname>Reppy</keyname><forenames>John</forenames></author></authors><title>Garbage Collection for Multicore NUMA Machines</title><categories>cs.PL</categories><comments>To appear in Memory Systems Performance and Correctness 2011 (MSPC11)</comments><acm-class>D.3.0; D.3.2; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern high-end machines feature multiple processor packages, each of which
contains multiple independent cores and integrated memory controllers connected
directly to dedicated physical RAM. These packages are connected via a shared
bus, creating a system with a heterogeneous memory hierarchy. Since this shared
bus has less bandwidth than the sum of the links to memory, aggregate memory
bandwidth is higher when parallel threads all access memory local to their
processor package than when they access memory attached to a remote package.
This bandwidth limitation has traditionally limited the scalability of modern
functional language implementations, which seldom scale well past 8 cores, even
on small benchmarks.
  This work presents a garbage collector integrated with our strict, parallel
functional language implementation, Manticore, and shows that it scales
effectively on both a 48-core AMD Opteron machine and a 32-core Intel Xeon
machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2576</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2576</id><created>2011-05-12</created><updated>2011-06-22</updated><authors><author><keyname>Koprowski</keyname><forenames>Adam</forenames><affiliation>MLstate, Paris, France</affiliation></author><author><keyname>Binsztok</keyname><forenames>Henri</forenames><affiliation>MLstate, Paris, France</affiliation></author></authors><title>TRX: A Formally Verified Parser Interpreter</title><categories>cs.LO cs.FL cs.PL</categories><comments>26 pages, LMCS</comments><proxy>LMCS</proxy><acm-class>D.3.4, D.2.4, F.3.1, F.4.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (June 24,
  2011) lmcs:686</journal-ref><doi>10.2168/LMCS-7(2:18)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parsing is an important problem in computer science and yet surprisingly
little attention has been devoted to its formal verification. In this paper, we
present TRX: a parser interpreter formally developed in the proof assistant
Coq, capable of producing formally correct parsers. We are using parsing
expression grammars (PEGs), a formalism essentially representing recursive
descent parsing, which we consider an attractive alternative to context-free
grammars (CFGs). From this formalization we can extract a parser for an
arbitrary PEG grammar with the warranty of total correctness, i.e., the
resulting parser is terminating and correct with respect to its grammar and the
semantics of PEGs; both properties formally proven in Coq.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2584</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2584</id><created>2011-05-12</created><authors><author><keyname>Smith</keyname><forenames>James W.</forenames></author><author><keyname>Sommerville</keyname><forenames>Ian</forenames></author></authors><title>Workload Classification &amp; Software Energy Measurement for Efficient
  Scheduling on Private Cloud Platforms</title><categories>cs.DC</categories><comments>10 pages, Submitted to ACM SOCC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At present there are a number of barriers to creating an energy efficient
workload scheduler for a Private Cloud based data center. Firstly, the
relationship between different workloads and power consumption must be
investigated. Secondly, current hardware-based solutions to providing energy
usage statistics are unsuitable in warehouse scale data centers where low cost
and scalability are desirable properties. In this paper we discuss the effect
of different workloads on server power consumption in a Private Cloud platform.
We display a noticeable difference in energy consumption when servers are given
tasks that dominate various resources (CPU, Memory, Hard Disk and Network). We
then use this insight to develop CloudMonitor, a software utility that is
capable of &gt;95% accurate power predictions from monitoring resource consumption
of workloads, after a &quot;training phase&quot; in which a dynamic power model is
developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2614</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2614</id><created>2011-05-13</created><authors><author><keyname>Brede</keyname><forenames>Markus</forenames></author></authors><title>Growth and Optimality in Network Evolution</title><categories>cond-mat.dis-nn cs.SI nlin.AO physics.bio-ph</categories><comments>To appear in Artificial Life (2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate networks whose evolution is governed by the
interaction of a random assembly process and an optimization process. In the
first process, new nodes are added one at a time and form connections to
randomly selected old nodes. In between node additions, the network is rewired
to minimize its pathlength. For timescales, at which neither the assembly nor
the optimization processes are dominant, we find a rich variety of complex
networks with power law tails in the degree distributions. These networks also
exhibit non-trivial clustering, a hierarchical organization and interesting
degree mixing patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2621</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2621</id><created>2011-05-13</created><authors><author><keyname>Reeves</keyname><forenames>Galen</forenames></author><author><keyname>Goela</keyname><forenames>Naveen</forenames></author><author><keyname>Milosavljevic</keyname><forenames>Nebojsa</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>A Compressed Sensing Wire-Tap Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multiplicative Gaussian wire-tap channel inspired by compressed sensing is
studied. Lower and upper bounds on the secrecy capacity are derived, and shown
to be relatively tight in the large system limit for a large class of
compressed sensing matrices. Surprisingly, it is shown that the secrecy
capacity of this channel is nearly equal to the capacity without any secrecy
constraint provided that the channel of the eavesdropper is strictly worse than
the channel of the intended receiver. In other words, the eavesdropper can see
almost everything and yet learn almost nothing. This behavior, which contrasts
sharply with that of many commonly studied wiretap channels, is made possible
by the fact that a small number of linear projections can make a crucial
difference in the ability to estimate sparse vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2624</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2624</id><created>2011-05-13</created><authors><author><keyname>Condo</keyname><forenames>Carlo</forenames></author><author><keyname>Masera</keyname><forenames>Guido</forenames></author></authors><title>A Flexible LDPC code decoder with a Network on Chip as underlying
  interconnect architecture</title><categories>cs.AR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  LDPC (Low Density Parity Check) codes are among the most powerful and widely
adopted modern error correcting codes. The iterative decoding algorithms
required for these codes involve high computational complexity and high
processing throughput is achieved by allocating a sufficient number of
processing elements (PEs). Supporting multiple heterogeneous LDPC codes on a
parallel decoder poses serious problems in the design of the interconnect
structure for such PEs. The aim of this work is to explore the feasibility of
NoC (Network on Chip) based decoders, where full flexibility in terms of
supported LDPC codes is obtained resorting to an NoC to connect PEs. NoC based
LDPC decoders have been previously considered unfeasible because of the cost
overhead associated to packet management and routing. On the contrary, the
designed NoC adopts a low complexity routing, which introduces a very limited
cost overhead with respect to architectures dedicated to specific classes of
codes. Moreover the paper proposes an efficient configuration technique, which
allows for fast on--the--fly switching among different codes. The decoder
architecture is scalable and VLSI synthesis results are presented for several
cases of study, including the whole set of WiMAX LDPC codes, WiFi codes and
DVB-S2 standard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2631</identifier>
 <datestamp>2011-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2631</id><created>2011-05-13</created><updated>2011-06-14</updated><authors><author><keyname>Lifshitz</keyname><forenames>Asi</forenames></author><author><keyname>Be'ery</keyname><forenames>Yair</forenames></author></authors><title>On Pseudocodewords and Decision Regions of Linear Programming Decoding
  of HDPC Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore the decision regions of Linear Programming (LP)
decoding. We compare the decision regions of an LP decoder, a Belief
Propagation (BP) decoder and the optimal Maximum Likelihood (ML) decoder. We
study the effect of minimal-weight pseudocodewords on LP decoding. We present
global optimization as a method for finding the minimal pseudoweight of a given
code as well as the number of minimal-weight generators. We present a complete
pseudoweight distribution for the [24; 12; 8] extended Golay code, and provide
justifications of why the pseudoweight distribution alone cannot be used for
obtaining a tight upper bound on the error probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2651</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2651</id><created>2011-05-13</created><authors><author><keyname>Keller</keyname><forenames>Nathan</forenames></author><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Schlank</keyname><forenames>Tomer</forenames></author></authors><title>A Note on the Entropy/Influence Conjecture</title><categories>math.CO cs.LG</categories><comments>12 pages</comments><msc-class>05D40, 60C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The entropy/influence conjecture, raised by Friedgut and Kalai in 1996, seeks
to relate two different measures of concentration of the Fourier coefficients
of a Boolean function. Roughly saying, it claims that if the Fourier spectrum
is &quot;smeared out&quot;, then the Fourier coefficients are concentrated on &quot;high&quot;
levels. In this note we generalize the conjecture to biased product measures on
the discrete cube, and prove a variant of the conjecture for functions with an
extremely low Fourier weight on the &quot;high&quot; levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2654</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2654</id><created>2011-05-13</created><authors><author><keyname>De Oliveira</keyname><forenames>Carina Teixeira</forenames><affiliation>LIG</affiliation></author><author><keyname>Theoleyre</keyname><forenames>Fabrice</forenames><affiliation>LSIIT</affiliation></author><author><keyname>Duda</keyname><forenames>Andrzej</forenames><affiliation>LIG</affiliation></author></authors><title>Broadcast Strategies with Probabilistic Delivery Guarantee in
  Multi-Channel Multi-Interface Wireless Mesh Networks</title><categories>cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-channel multi-interface Wireless Mesh Networks permit to spread the
load across orthogonal channels to improve network capacity. Although broadcast
is vital for many layer-3 protocols, proposals for taking advantage of multiple
channels mostly focus on unicast transmissions. In this paper, we propose
broadcast algorithms that fit any channel and interface assignment strategy.
They guarantee that a broadcast packet is delivered with a minimum probability
to all neighbors. Our simulations show that the proposed algorithms efficiently
limit the overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2665</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2665</id><created>2011-05-13</created><updated>2011-06-06</updated><authors><author><keyname>Alpuente</keyname><forenames>Mar&#xed;a</forenames><affiliation>Universidad Polit&#xe9;cnica de Valencia --- DSIC-ELP</affiliation></author><author><keyname>Ballis</keyname><forenames>Demis</forenames><affiliation>University of Udine --- DIMI</affiliation></author><author><keyname>Espert</keyname><forenames>Javier</forenames><affiliation>Universidad Polit&#xe9;cnica de Valencia --- DSIC-ELP</affiliation></author><author><keyname>Romero</keyname><forenames>Daniel</forenames><affiliation>Universidad Polit&#xe9;cnica de Valencia --- DSIC-ELP</affiliation></author></authors><title>Dynamic Backward Slicing of Rewriting Logic Computations</title><categories>cs.LO</categories><comments>17 pages, 1 figure, 5 extra pages for Appendix; Extended version of
  the CADE 23 paper Backward Trace Slicing for Rewriting Logic Theories</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trace slicing is a widely used technique for execution trace analysis that is
effectively used in program debugging, analysis and comprehension. In this
paper, we present a backward trace slicing technique that can be used for the
analysis of Rewriting Logic theories. Our trace slicing technique allows us to
systematically trace back rewrite sequences modulo equational axioms (such as
associativity and commutativity) by means of an algorithm that dynamically
simplifies the traces by detecting control and data dependencies, and dropping
useless data that do not influence the final result. Our methodology is
particularly suitable for analyzing complex, textually-large system
computations such as those delivered as counter-example traces by Maude
model-checkers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2686</identifier>
 <datestamp>2013-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2686</id><created>2011-05-13</created><updated>2013-04-26</updated><authors><author><keyname>Brunsch</keyname><forenames>Tobias</forenames></author><author><keyname>R&#xf6;glin</keyname><forenames>Heiko</forenames></author><author><keyname>Rutten</keyname><forenames>Cyriel</forenames></author><author><keyname>Vredeveld</keyname><forenames>Tjark</forenames></author></authors><title>Smoothed Performance Guarantees for Local Search</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study popular local search and greedy algorithms for scheduling. The
performance guarantee of these algorithms is well understood, but the
worst-case lower bounds seem somewhat contrived and it is questionable if they
arise in practical applications. To find out how robust these bounds are, we
study the algorithms in the framework of smoothed analysis, in which instances
are subject to some degree of random noise.
  While the lower bounds for all scheduling variants with restricted machines
are rather robust, we find out that the bounds are fragile for unrestricted
machines. In particular, we show that the smoothed performance guarantee of the
jump and the lex-jump algorithm are (in contrast to the worst case) independent
of the number of machines. They are Theta(phi) and Theta(log(phi)),
respectively, where 1/phi is a parameter measuring the magnitude of the
perturbation. The latter immediately implies that also the smoothed price of
anarchy is Theta(log(phi)) for routing games on parallel links. Additionally we
show that for unrestricted machines also the greedy list scheduling algorithm
has an approximation guarantee of Theta(log(phi)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2704</identifier>
 <datestamp>2014-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2704</id><created>2011-05-13</created><updated>2013-12-13</updated><authors><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Paul</keyname><forenames>Christophe</forenames></author><author><keyname>Sau</keyname><forenames>Ignasi</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author><author><keyname>Thomass&#xe9;</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>Hitting and Harvesting Pumpkins</title><categories>cs.DS</categories><comments>v2: several minor changes</comments><msc-class>05C85, 05C83</msc-class><acm-class>G.2.2</acm-class><journal-ref>SIAM Journal on Discrete Mathematics, 103/1:1363--1390, 2014</journal-ref><doi>10.1137/120883736</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The &quot;c-pumpkin&quot; is the graph with two vertices linked by c&gt;0 parallel edges.
A c-pumpkin-model in a graph G is a pair A,B of disjoint subsets of vertices of
G, each inducing a connected subgraph of G, such that there are at least c
edges in G between A and B. We focus on covering and packing c-pumpkin-models
in a given graph: On the one hand, we provide an FPT algorithm running in time
2^O(k) n^O(1) deciding, for any fixed c&gt;0, whether all c-pumpkin-models can be
covered by at most k vertices. This generalizes known single-exponential FPT
algorithms for Vertex Cover and Feedback Vertex Set, which correspond to the
cases c=1,2 respectively. On the other hand, we present a O(log
n)-approximation algorithm for both the problems of covering all
c-pumpkin-models with a smallest number of vertices, and packing a maximum
number of vertex-disjoint c-pumpkin-models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2707</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2707</id><created>2011-05-13</created><authors><author><keyname>da Costa</keyname><forenames>G. A. T. F.</forenames></author><author><keyname>Taneja</keyname><forenames>Inder Jeet</forenames></author></authors><title>Generalized Symmetric Divergence Measures and Metric Spaces</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Taneja studied two one parameter generalizations of J-divergence,
Jensen-Shannon divergence and Arithmetic-Geometric divergence. These two
generalizations in particular contain measures like: Hellinger discrimination,
symmetric chi-square divergence, and triangular discrimination. These measures
are well known in the literature of Statistics and Information theory. In this
paper our aim is to prove metric space properties for square root of these two
symmetric generalized divergence measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2725</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2725</id><created>2011-05-13</created><authors><author><keyname>Rabe</keyname><forenames>Florian</forenames></author><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author><author><keyname>Coen</keyname><forenames>Claudio Sacerdoti</forenames></author></authors><title>A Foundational View on Integration Problems</title><categories>cs.LO</categories><doi>10.1007/978-3-642-22673-1_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of reasoning and computation services across system and
language boundaries is a challenging problem of computer science. In this
paper, we use integration for the scenario where we have two systems that we
integrate by moving problems and solutions between them. While this scenario is
often approached from an engineering perspective, we take a foundational view.
Based on the generic declarative language MMT, we develop a theoretical
framework for system integration using theories and partial theory morphisms.
Because MMT permits representations of the meta-logical foundations themselves,
this includes integration across logics. We discuss safe and unsafe integration
schemes and devise a general form of safe integration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2751</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2751</id><created>2011-05-13</created><authors><author><keyname>Krebbers</keyname><forenames>Robbert</forenames></author><author><keyname>Spitters</keyname><forenames>Bas</forenames></author></authors><title>Computer certified efficient exact reals in Coq</title><categories>cs.LO</categories><comments>Proceedings of CICM11, Springer LNAI, 2011</comments><acm-class>D.2.4; F.4.1; G.1</acm-class><journal-ref>Proceedings of CICM11, vol 6824, Springer LNAI, 90-106, 2011</journal-ref><doi>10.1007/978-3-642-22673-1_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Floating point operations are fast, but require continuous effort on the part
of the user in order to ensure that the results are correct. This burden can be
shifted away from the user by providing a library of exact analysis in which
the computer handles the error estimates. We provide an implementation of the
exact real numbers in the Coq proof assistant. This improves on the earlier
Coq-implementation by O'Connor in two ways: we use dyadic rationals built from
the machine integers and we optimize computation of power series by using
approximate division. Moreover, we use type classes for clean mathematical
interfaces. This appears to be the first time that type classes are used in
heavy computation. We obtain over a 100 times speed up of the basic operations
and indications for improving the Coq system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2760</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2760</id><created>2011-05-13</created><updated>2011-06-01</updated><authors><author><keyname>Agnihotri</keyname><forenames>Samar</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author></authors><title>Amplify-and-Forward in Wireless Relay Networks</title><categories>cs.IT math.IT</categories><comments>Minor revision: fixed a typo in eqn. reference, changed the
  formatting. 30 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general class of wireless relay networks with a single source-destination
pair is considered. Intermediate nodes in the network employ an
amplify-and-forward scheme to relay their input signals. In this case the
overall input-output channel from the source via the relays to the destination
effectively behaves as an intersymbol interference channel with colored noise.
Unlike previous work we formulate the problem of the maximum achievable rate in
this setting as an optimization problem with no assumption on the network size,
topology, and received signal-to-noise ratio. Previous work considered only
scenarios wherein relays use all their power to amplify their received signals.
We demonstrate that this may not always maximize the maximal achievable rate in
amplify-and-forward relay networks. The proposed formulation allows us to not
only recover known results on the performance of the amplify-and-forward
schemes for some simple relay networks but also characterize the performance of
more complex amplify-and-forward relay networks which cannot be addressed in a
straightforward manner using existing approaches.
  Using cut-set arguments, we derive simple upper bounds on the capacity of
general wireless relay networks. Through various examples, we show that a large
class of amplify-and-forward relay networks can achieve rates within a constant
factor of these upper bounds asymptotically in network parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2769</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2769</id><created>2011-05-13</created><updated>2012-06-30</updated><authors><author><keyname>Lee</keyname><forenames>Dongryeol</forenames></author><author><keyname>Ozakin</keyname><forenames>Arkadas</forenames></author><author><keyname>Gray</keyname><forenames>Alexander G.</forenames></author></authors><title>Multibody Multipole Methods</title><categories>physics.comp-ph cs.DS</categories><comments>To appear in Journal of Computational Physics</comments><msc-class>68U01</msc-class><acm-class>J.2</acm-class><doi>10.1016/j.jcp.2012.06.027</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A three-body potential function can account for interactions among triples of
particles which are uncaptured by pairwise interaction functions such as
Coulombic or Lennard-Jones potentials. Likewise, a multibody potential of order
$n$ can account for interactions among $n$-tuples of particles uncaptured by
interaction functions of lower orders. To date, the computation of multibody
potential functions for a large number of particles has not been possible due
to its $O(N^n)$ scaling cost. In this paper we describe a fast tree-code for
efficiently approximating multibody potentials that can be factorized as
products of functions of pairwise distances. For the first time, we show how to
derive a Barnes-Hut type algorithm for handling interactions among more than
two particles. Our algorithm uses two approximation schemes: 1) a deterministic
series expansion-based method; 2) a Monte Carlo-based approximation based on
the central limit theorem. Our approach guarantees a user-specified bound on
the absolute or relative error in the computed potential with an asymptotic
probability guarantee. We provide speedup results on a three-body dispersion
potential, the Axilrod-Teller potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2770</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2770</id><created>2011-05-13</created><updated>2011-05-16</updated><authors><author><keyname>Sahidullah</keyname><forenames>Md.</forenames></author><author><keyname>Chakroborty</keyname><forenames>Sandipan</forenames></author><author><keyname>Saha</keyname><forenames>Goutam</forenames></author></authors><title>Improving Performance of Speaker Identification System Using
  Complementary Information Fusion</title><categories>cs.SD cs.MM</categories><comments>6 Pages, 3 figures</comments><journal-ref>Proceedings of 17th International Conference on Advanced Computing
  and Communications (ADCOM 2009) pp. 182-187 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature extraction plays an important role as a front-end processing block in
speaker identification (SI) process. Most of the SI systems utilize like
Mel-Frequency Cepstral Coefficients (MFCC), Perceptual Linear Prediction (PLP),
Linear Predictive Cepstral Coefficients (LPCC), as a feature for representing
speech signal. Their derivations are based on short term processing of speech
signal and they try to capture the vocal tract information ignoring the
contribution from the vocal cord. Vocal cord cues are equally important in SI
context, as the information like pitch frequency, phase in the residual signal,
etc could convey important speaker specific attributes and are complementary to
the information contained in spectral feature sets. In this paper we propose a
novel feature set extracted from the residual signal of LP modeling.
Higher-order statistical moments are used here to find the nonlinear
relationship in residual signal. To get the advantages of complementarity vocal
cord based decision score is fused with the vocal tract based score. The
experimental results on two public databases show that fused mode system
outperforms single spectral features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2782</identifier>
 <datestamp>2011-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2782</id><created>2011-05-13</created><updated>2011-10-28</updated><authors><author><keyname>Zhang</keyname><forenames>Yong</forenames></author><author><keyname>Dong</keyname><forenames>Bin</forenames></author><author><keyname>Lu</keyname><forenames>Zhaosong</forenames></author></authors><title>$\ell_0$ Minimization for Wavelet Frame Based Image Restoration</title><categories>cs.CV math.FA math.OC</categories><comments>17 pages,4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of (tight) wavelet frames has been extensively studied in the past
twenty years and they are currently widely used for image restoration and other
image processing and analysis problems. The success of wavelet frame based
models, including balanced approach and analysis based approach, is due to
their capability of sparsely approximating piecewise smooth functions like
images. Motivated by the balanced approach and analysis based approach, we
shall propose a wavelet frame based $\ell_0$ minimization model, where the
$\ell_0$ &quot;norm&quot; of the frame coefficients is penalized. We adapt the penalty
decomposition (PD) method to solve the proposed optimization problem. Numerical
results showed that the proposed model solved by the PD method can generate
images with better quality than those obtained by either analysis based
approach or balanced approach in terms of restoring sharp features as well as
maintaining smoothness of the recovered images. Some convergence analysis of
the PD method will also be provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2783</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2783</id><created>2011-05-13</created><authors><author><keyname>Sun</keyname><forenames>Yuhua</forenames></author><author><keyname>Li</keyname><forenames>Hui</forenames></author><author><keyname>Wang</keyname><forenames>Zilong</forenames></author><author><keyname>Yan</keyname><forenames>Tongjiang</forenames></author></authors><title>$p$-ary sequences with six-valued cross-correlation function: a new
  decimation of Niho type</title><categories>cs.IT cs.DM math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  For an odd prime $p$ and $n=2m$, a new decimation
$d=\frac{(p^{m}-1)^{2}}{2}+1$ of Niho type of $m$-sequences is presented. Using
generalized Niho's Theorem, we show that the cross-correlation function between
a $p$-ary $m$-sequence of period $p^{n}-1$ and its decimated sequence by the
above $d$ is at most six-valued and we can easily know that the magnitude of
the cross correlation is upper bounded by $4\sqrt{p^{n}}-1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2786</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2786</id><created>2011-05-13</created><authors><author><keyname>Sun</keyname><forenames>Yuhua</forenames></author><author><keyname>Wang</keyname><forenames>Zilong</forenames></author><author><keyname>Li</keyname><forenames>Hui</forenames></author></authors><title>On the Cross-Correlation of a Ternary $m$-sequence of Period $3^{4k}-1$
  and Its Decimated Sequence by $\frac{(3^{2k}+1)^{2}}{20}$</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $d=\frac{(3^{2k}+1)^{2}}{20}$, where $k$ is an odd integer. We show that
the magnitude of the cross-correlation values of a ternary $m$-sequence
$\{s_{t}\}$ of period $3^{4k}-1$ and its decimated sequence $\{s_{dt}\}$ is
upper bounded by $5\sqrt{3^{n}}+1$, where $n=4k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2790</identifier>
 <datestamp>2012-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2790</id><created>2011-05-13</created><updated>2012-01-10</updated><authors><author><keyname>Barra</keyname><forenames>Adriano</forenames></author><author><keyname>Bernacchia</keyname><forenames>Alberto</forenames></author><author><keyname>Santucci</keyname><forenames>Enrica</forenames></author><author><keyname>Contucci</keyname><forenames>Pierluigi</forenames></author></authors><title>On the equivalence of Hopfield Networks and Boltzmann Machines</title><categories>cond-mat.dis-nn cs.AI</categories><comments>15 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A specific type of neural network, the Restricted Boltzmann Machine (RBM), is
implemented for classification and feature detection in machine learning. RBM
is characterized by separate layers of visible and hidden units, which are able
to learn efficiently a generative model of the observed data. We study a
&quot;hybrid&quot; version of RBM's, in which hidden units are analog and visible units
are binary, and we show that thermodynamics of visible units are equivalent to
those of a Hopfield network, in which the N visible units are the neurons and
the P hidden units are the learned patterns. We apply the method of stochastic
stability to derive the thermodynamics of the model, by considering a formal
extension of this technique to the case of multiple sets of stored patterns,
which may act as a benchmark for the study of correlated sets. Our results
imply that simulating the dynamics of a Hopfield network, requiring the update
of N neurons and the storage of N(N-1)/2 synapses, can be accomplished by a
hybrid Boltzmann Machine, requiring the update of N+P neurons but the storage
of only NP synapses. In addition, the well known glass transition of the
Hopfield network has a counterpart in the Boltzmann Machine: It corresponds to
an optimum criterion for selecting the relative sizes of the hidden and visible
layers, resolving the trade-off between flexibility and generality of the
model. The low storage phase of the Hopfield model corresponds to few hidden
units and hence a overly constrained RBM, while the spin-glass phase (too many
hidden units) corresponds to unconstrained RBM prone to overfitting of the
observed data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2795</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2795</id><created>2011-05-13</created><authors><author><keyname>Dutagaci</keyname><forenames>Helin</forenames></author><author><keyname>Godil</keyname><forenames>Afzal</forenames></author><author><keyname>Sankur</keyname><forenames>Bulent</forenames></author><author><keyname>Yemez</keyname><forenames>Y&#xfc;cel</forenames></author></authors><title>View subspaces for indexing and retrieval of 3D models</title><categories>cs.CV cs.MM</categories><comments>Three-Dimensional Image Processing (3DIP) and Applications
  (Proceedings Volume) Proceedings of SPIE Volume: 7526 Editor(s): Atilla M.
  Baskurt ISBN: 9780819479198 Date: 2 February 2010</comments><acm-class>I.2.10; I.4.8; I.5.4</acm-class><doi>10.1117/12.839186</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  View-based indexing schemes for 3D object retrieval are gaining popularity
since they provide good retrieval results. These schemes are coherent with the
theory that humans recognize objects based on their 2D appearances. The
viewbased techniques also allow users to search with various queries such as
binary images, range images and even 2D sketches. The previous view-based
techniques use classical 2D shape descriptors such as Fourier invariants,
Zernike moments, Scale Invariant Feature Transform-based local features and 2D
Digital Fourier Transform coefficients. These methods describe each object
independent of others. In this work, we explore data driven subspace models,
such as Principal Component Analysis, Independent Component Analysis and
Nonnegative Matrix Factorization to describe the shape information of the
views. We treat the depth images obtained from various points of the view
sphere as 2D intensity images and train a subspace to extract the inherent
structure of the views within a database. We also show the benefit of
categorizing shapes according to their eigenvalue spread. Both the shape
categorization and data-driven feature set conjectures are tested on the PSB
database and compared with the competitor view-based 3D shape retrieval
algorithms
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2796</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2796</id><created>2011-05-13</created><authors><author><keyname>Godil</keyname><forenames>Afzal</forenames></author><author><keyname>Wagan</keyname><forenames>Asim Imdad</forenames></author></authors><title>Salient Local 3D Features for 3D Shape Retrieval</title><categories>cs.CV cs.MM</categories><comments>Three-Dimensional Imaging, Interaction, and Measurement. Edited by
  Beraldin, J. Angelo; Cheok, Geraldine S.; McCarthy, Michael B.;
  Neuschaefer-Rube, Ulrich; Baskurt, Atilla M.; McDowall, Ian E.; Dolinsky,
  Margaret. Proceedings of the SPIE, Volume 7864, pp. 78640S-78640S-8 (2011).
  Conference Location: San Francisco Airport, California, USA ISBN:
  9780819484017 Date: 10 March 2011</comments><acm-class>I.2.10; I.4.8; I.5.4</acm-class><doi>10.1117/12.872984</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper we describe a new formulation for the 3D salient local features
based on the voxel grid inspired by the Scale Invariant Feature Transform
(SIFT). We use it to identify the salient keypoints (invariant points) on a 3D
voxelized model and calculate invariant 3D local feature descriptors at these
keypoints. We then use the bag of words approach on the 3D local features to
represent the 3D models for shape retrieval. The advantages of the method are
that it can be applied to rigid as well as to articulated and deformable 3D
models. Finally, this approach is applied for 3D Shape Retrieval on the McGill
articulated shape benchmark and then the retrieval results are presented and
compared to other methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2797</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2797</id><created>2011-05-13</created><authors><author><keyname>Godil</keyname><forenames>Afzal</forenames></author><author><keyname>Ressler</keyname><forenames>Sandy</forenames></author><author><keyname>Grother</keyname><forenames>Patrick</forenames></author></authors><title>Face Recognition using 3D Facial Shape and Color Map Information:
  Comparison and Combination</title><categories>cs.CV</categories><comments>Proceedings of SPIE Vol. 5404 Biometric Technology for Human
  Identification, Anil K. Jain; Nalini K. Ratha, Editors, pp.351-361, ISBN:
  9780819453273 Date: 25 August 2004</comments><acm-class>I.2.10; I.4.8; I.5.4</acm-class><doi>10.1117/12.540754</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we investigate the use of 3D surface geometry for face
recognition and compare it to one based on color map information. The 3D
surface and color map data are from the CAESAR anthropometric database. We find
that the recognition performance is not very different between 3D surface and
color map information using a principal component analysis algorithm. We also
discuss the different techniques for the combination of the 3D surface and
color map information for multi-modal recognition by using different fusion
approaches and show that there is significant improvement in results. The
effectiveness of various techniques is compared and evaluated on a dataset with
200 subjects in two different positions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2800</identifier>
 <datestamp>2011-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2800</id><created>2011-05-13</created><authors><author><keyname>Godil</keyname><forenames>Afzal</forenames></author><author><keyname>Ressler</keyname><forenames>Sandy</forenames></author></authors><title>Retrieval and Clustering from a 3D Human Database based on Body and Head
  Shape</title><categories>cs.CV cs.CG</categories><comments>Published in Proceedings of the 2006 Digital Human Modeling for
  Design and Engineering Conference, July 2006, Lyon, FRANCE, Session: Advanced
  Size/Shape Analysis Paper Number: 2006-01-2355
  http://papers.sae.org/2006-01-2355</comments><acm-class>I.2.10; I.4.8; I.5.4</acm-class><doi>10.4271/2006-01-2355</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we describe a framework for similarity based retrieval and
clustering from a 3D human database. Our technique is based on both body and
head shape representation and the retrieval is based on similarity of both of
them. The 3D human database used in our study is the CAESAR anthropometric
database which contains approximately 5000 bodies. We have developed a
web-based interface for specifying the queries to interact with the retrieval
system. Our approach performs the similarity based retrieval in a reasonable
amount of time and is a practical approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2813</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2813</id><created>2011-05-13</created><authors><author><keyname>Gatterbauer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>Optimal Upper and Lower Bounds for Boolean Expressions by Dissociation</title><categories>cs.AI cs.DB cs.LO</categories><comments>7 pages, 2 figures; for details see the project page:
  http://LaPushDB.com/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops upper and lower bounds for the probability of Boolean
expressions by treating multiple occurrences of variables as independent and
assigning them new individual probabilities. Our technique generalizes and
extends the underlying idea of a number of recent approaches which are
varyingly called node splitting, variable renaming, variable splitting, or
dissociation for probabilistic databases. We prove that the probabilities we
assign to new variables are the best possible in some sense.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2831</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2831</id><created>2011-05-13</created><authors><author><keyname>Rowekamp</keyname><forenames>Brandon</forenames></author></authors><title>Planar Pixelations and Image Recognition</title><categories>math.DG cs.CG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Any subset of the plane can be approximated by a set of square pixels. This
transition from a shape to its pixelation is rather brutal since it destroys
geometric and topological information about the shape. Using a technique
inspired by Morse Theory, we algorithmically produce a PL approximation of the
original shape using only information from its pixelation. This approximation
converges to the original shape in a very strong sense: as the size of the
pixels goes to zero we can recover important geometric and topological
invariants of the original shape such as Betti numbers, area, perimeter and
curvature measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2849</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2849</id><created>2011-05-13</created><authors><author><keyname>Currie</keyname><forenames>James D.</forenames></author></authors><title>Pattern avoidance with involution</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the avoidance indices (morphic and antimorphic) for all unary
patterns with involution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2858</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2858</id><created>2011-05-13</created><authors><author><keyname>Feichtinger</keyname><forenames>Hans</forenames></author><author><keyname>Pesenson</keyname><forenames>Isaac</forenames></author></authors><title>A Reconstruction Method for Band-Limited Signals on the Hyperbolic Plane</title><categories>math.FA cs.IT math.IT</categories><journal-ref>Sampling Theory in Signal and Image Processing Vol. 4, No. 2, May.
  2005, pp. 107-119</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A notion of band limited functions is considered in the case of the
hyperbolic plane in its Poincare upper half-plane $\mathbb{H}$ realization. The
concept of band-limitedness is based on the existence of the Helgason-Fourier
transform on $\mathbb{H}$. An iterative algorithm is presented, which allows to
reconstruct band-limited functions from some countable sets of their values. It
is shown that for sufficiently dense metric lattices a geometric rate of
convergence can be guaranteed as long as the sampling density is high enough
compared to the band-width of the sampled function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2864</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2864</id><created>2011-05-14</created><updated>2013-05-28</updated><authors><author><keyname>Watanabe</keyname><forenames>Shun</forenames></author></authors><title>The Rate-Distortion Function for Product of Two Sources with
  Side-Information at Decoders</title><categories>cs.IT math.IT</categories><comments>14 pages, 5 figures; A part of this paper was presented at ISIT2011
  in Saint-Petersburg, Russia; v2 is the final, accepted version (to appear in
  IEEE IT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates a lossy source coding problem in which two decoders
can access their side-information respectively. The correlated sources are a
product of two component correlated sources, and we exclusively investigate the
case such that each component is degraded. We show the rate-distortion function
for that case, and give the following observations. When the components are
degraded in matched order, the rate distortion function of the product sources
is equal to the sum of the component-wise rate distortion functions. On the
otherhand, the former is strictly smaller than the latter when the component
sources are degraded in mismatched order. The converse proof for the mismatched
case is motivated by the enhancement technique used for broadcast channels. For
binary Hamming and Gaussian examples, we evaluate the rate-distortion
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2865</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2865</id><created>2011-05-14</created><authors><author><keyname>Dau</keyname><forenames>Son Hoang</forenames></author><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author><author><keyname>Chee</keyname><forenames>Yeow Meng</forenames></author></authors><title>Error Correction for Index Coding with Side Information</title><categories>cs.IT math.IT</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A problem of index coding with side information was first considered by Y.
Birk and T. Kol (IEEE INFOCOM, 1998). In the present work, a generalization of
index coding scheme, where transmitted symbols are subject to errors, is
studied. Error-correcting methods for such a scheme, and their parameters, are
investigated. In particular, the following question is discussed: given the
side information hypergraph of index coding scheme and the maximal number of
erroneous symbols $\delta$, what is the shortest length of a linear index code,
such that every receiver is able to recover the required information? This
question turns out to be a generalization of the problem of finding a
shortest-length error-correcting code with a prescribed error-correcting
capability in the classical coding theory.
  The Singleton bound and two other bounds, referred to as the $\alpha$-bound
and the $\kappa$-bound, for the optimal length of a linear error-correcting
index code (ECIC) are established. For large alphabets, a construction based on
concatenation of an optimal index code with an MDS classical code, is shown to
attain the Singleton bound. For smaller alphabets, however, this construction
may not be optimal. A random construction is also analyzed. It yields another
implicit bound on the length of an optimal linear ECIC.
  Further, the problem of error-correcting decoding by a linear ECIC is
studied. It is shown that in order to decode correctly the desired symbol, the
decoder is required to find one of the vectors, belonging to an affine space
containing the actual error vector. The syndrome decoding is shown to produce
the correct output if the weight of the error pattern is less or equal to the
error-correcting capability of the corresponding ECIC.
  Finally, the notion of static ECIC, which is suitable for use with a family
of instances of an index coding problem, is introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2868</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2868</id><created>2011-05-14</created><authors><author><keyname>Vincent</keyname><forenames>Etter</forenames></author></authors><title>Semantic Vector Machines</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We first present our work in machine translation, during which we used
aligned sentences to train a neural network to embed n-grams of different
languages into an $d$-dimensional space, such that n-grams that are the
translation of each other are close with respect to some metric. Good n-grams
to n-grams translation results were achieved, but full sentences translation is
still problematic. We realized that learning semantics of sentences and
documents was the key for solving a lot of natural language processing
problems, and thus moved to the second part of our work: sentence compression.
We introduce a flexible neural network architecture for learning embeddings of
words and sentences that extract their semantics, propose an efficient
implementation in the Torch framework and present embedding results comparable
to the ones obtained with classical neural language models, while being more
powerful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2874</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2874</id><created>2011-05-14</created><authors><author><keyname>Brandst&#xe4;dt</keyname><forenames>Andreas</forenames></author><author><keyname>Giakoumakis</keyname><forenames>Vassilis</forenames></author></authors><title>Clique Separator Decomposition of Hole- and Diamond-Free Graphs and
  Algorithmic Consequences</title><categories>cs.DM</categories><comments>14 Pages, 1 figure</comments><msc-class>Discrete Mathematics</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clique separator decomposition introduced by Tarjan and Whitesides is one of
the most important graph decompositions. A graph is an {\em atom} if it has no
clique separator. A {\em hole} is a chordless cycle with at least five
vertices, and an {\em antihole} is the complement graph of a hole. A graph is
{\em weakly chordal} if it is hole- and antihole-free. $K_4-e$ is also called
{\em diamond}. {\em Paraglider} has five vertices four of which induce a
diamond, and the fifth vertex sees exactly the two vertices of degree two in
the diamond. In this paper we show that atoms of hole- and diamond-free graphs
(of hole- and paraglider-free graphs, respectively) are either weakly chordal
or of a very specific structure. Hole- and paraglider-free graphs are perfect
graphs. The structure of their atoms leads to efficient algorithms for various
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2890</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2890</id><created>2011-05-14</created><authors><author><keyname>Conversy</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRIT</affiliation></author></authors><title>Improving Usability of Interactive Graphics Specification and
  Implementation with Picking Views and Inverse Transformations</title><categories>cs.HC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Specifying and programming graphical interactions are difficult tasks,
notably because designers have difficulties to express the dynamics of the
interaction. This paper shows how the MDPC architecture improves the usability
of the specification and the implementation of graphical interaction. The
architecture is based on the use of picking views and inverse transforms from
the graphics to the data. With three examples of graphical interaction, we show
how to express them with the architecture, how to implement them, and how this
improves programming usability. Moreover, we show that it enables implementing
graphical interaction without a scene graph. This kind of code prevents from
errors due to cache consistency management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2894</identifier>
 <datestamp>2013-12-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2894</id><created>2011-05-14</created><updated>2013-12-29</updated><authors><author><keyname>Pat</keyname><forenames>Ankit</forenames></author><author><keyname>Hota</keyname><forenames>Ashish Ranjan</forenames></author></authors><title>Ant Colony Optimization and Hypergraph Covering Problems</title><categories>cs.NE</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ant Colony Optimization (ACO) is a very popular metaheuristic for solving
computationally hard combinatorial optimization problems. Runtime analysis of
ACO with respect to various pseudo-boolean functions and different graph based
combinatorial optimization problems has been taken up in recent years. In this
paper, we investigate the runtime behavior of an MMAS*(Max-Min Ant System) ACO
algorithm on some well known hypergraph covering problems that are NP-Hard. In
particular, we have addressed the Minimum Edge Cover problem, the Minimum
Vertex Cover problem and the Maximum Weak- Independent Set problem. The
influence of pheromone values and heuristic information on the running time is
analysed. The results indicate that the heuristic information has greater
impact towards improving the expected optimization time as compared to
pheromone values. For certain instances of hypergraphs, we show that the MMAS*
algorithm gives a constant order expected optimization time when the dominance
of heuristic information is suitably increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2899</identifier>
 <datestamp>2014-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2899</id><created>2011-05-14</created><updated>2014-01-23</updated><authors><author><keyname>Hosseini</keyname><forenames>Hossein</forenames></author><author><keyname>Marvasti</keyname><forenames>Farokh</forenames></author></authors><title>Fast restoration of natural images corrupted by high-density impulse
  noise</title><categories>cs.MM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we suggest a general model for the fixed-valued impulse noise
and propose a two-stage method for high density noise suppression while
preserving the image details. In the first stage, we apply an iterative impulse
detector, exploiting the image entropy, to identify the corrupted pixels and
then employ an Adaptive Iterative Mean filter to restore them. The filter is
adaptive in terms of the number of iterations, which is different for each
noisy pixel, according to the Euclidean distance from the nearest uncorrupted
pixel. Experimental results show that the proposed filter is fast and
outperforms the best existing techniques in both objective and subjective
performance measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2902</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2902</id><created>2011-05-14</created><authors><author><keyname>Jahromi</keyname><forenames>Zahra Forootan</forenames></author><author><keyname>Rajabzadeh</keyname><forenames>Amir</forenames></author><author><keyname>Manashty</keyname><forenames>Ali Reza</forenames></author></authors><title>A Multi-Purpose Scenario-based Simulator for Smart House Environments</title><categories>cs.AI</categories><journal-ref>(IJCSIS) International Journal of Computer Science and Information
  Security, Vol. 9, No. 1, January 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Developing smart house systems has been a great challenge for researchers and
engineers in this area because of the high cost of implementation and
evaluation process of these systems, while being very time consuming. Testing a
designed smart house before actually building it is considered as an obstacle
towards an efficient smart house project. This is because of the variety of
sensors, home appliances and devices available for a real smart environment. In
this paper, we present the design and implementation of a multi-purpose smart
house simulation system for designing and simulating all aspects of a smart
house environment. This simulator provides the ability to design the house plan
and different virtual sensors and appliances in a two dimensional model of the
virtual house environment. This simulator can connect to any external smart
house remote controlling system, providing evaluation capabilities to their
system much easier than before. It also supports detailed adding of new
emerging sensors and devices to help maintain its compatibility with future
simulation needs. Scenarios can also be defined for testing various possible
combinations of device states; so different criteria and variables can be
simply evaluated without the need of experimenting on a real environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2925</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2925</id><created>2011-05-15</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Rafols</keyname><forenames>Ismael</forenames></author></authors><title>Interactive Overlays: A New Method for Generating Global Journal Maps
  from Web-of-Science Data</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in methods and techniques enable us to develop an interactive
overlay to the global map of science based on aggregated citation relations
among the 9,162 journals contained in the Science Citation Index and Social
Science Citation Index 2009 combined. The resulting mapping is provided by
VOSViewer. We first discuss the pros and cons of the various options: cited
versus citing, multidimensional scaling versus spring-embedded algorithms,
VOSViewer versus Gephi, and the various clustering algorithms and similarity
criteria. Our approach focuses on the positions of journals in the
multidimensional space spanned by the aggregated journal-journal citations. A
number of choices can be left to the user, but we provide default options
reflecting our preferences. Some examples are also provided; for example, the
potential of using this technique to assess the interdisciplinarity of
organizations and/or document sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2934</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2934</id><created>2011-05-15</created><updated>2011-08-30</updated><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author><author><keyname>van Raan</keyname><forenames>Anthony F. J.</forenames></author></authors><title>Universality of citation distributions revisited</title><categories>cs.DL physics.data-an physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radicchi, Fortunato, and Castellano [arXiv:0806.0974, PNAS 105(45), 17268]
claim that, apart from a scaling factor, all fields of science are
characterized by the same citation distribution. We present a large-scale
validation study of this universality-of-citation-distributions claim. Our
analysis shows that claiming citation distributions to be universal for all
fields of science is not warranted. Although many fields indeed seem to have
fairly similar citation distributions, there are quite some exceptions as well.
We also briefly discuss the consequences of our findings for the measurement of
scientific impact using citation-based bibliometric indicators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2942</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2942</id><created>2011-05-15</created><updated>2011-05-17</updated><authors><author><keyname>Husfeldt</keyname><forenames>Thore</forenames></author></authors><title>Invitation to Algorithmic Uses of Inclusion-Exclusion</title><categories>cs.DS cs.DM</categories><comments>Invited talk at ICALP 2011, 18 pages, 10 figures. To appear in
  Proceedings of the 38th International Colloquium on Automata, Languages and
  Programming (ICALP 2011), Z\&quot;urich, Switzerland, July 4-8, 2011, Part II,
  Springer LNCS 6756, 2011, pages 42-59</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I give an introduction to algorithmic uses of the principle of
inclusion-exclusion. The presentation is intended to be be concrete and
accessible, at the expense of generality and comprehensiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2943</identifier>
 <datestamp>2012-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2943</id><created>2011-05-15</created><authors><author><keyname>Wang</keyname><forenames>Rui</forenames></author><author><keyname>Tang</keyname><forenames>Ke</forenames></author></authors><title>Feature Selection for MAUC-Oriented Classification Systems</title><categories>cs.LG cs.AI</categories><comments>A journal length paper</comments><doi>10.1016/j.neucom.2012.01.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Feature selection is an important pre-processing step for many pattern
classification tasks. Traditionally, feature selection methods are designed to
obtain a feature subset that can lead to high classification accuracy. However,
classification accuracy has recently been shown to be an inappropriate
performance metric of classification systems in many cases. Instead, the Area
Under the receiver operating characteristic Curve (AUC) and its multi-class
extension, MAUC, have been proved to be better alternatives. Hence, the target
of classification system design is gradually shifting from seeking a system
with the maximum classification accuracy to obtaining a system with the maximum
AUC/MAUC. Previous investigations have shown that traditional feature selection
methods need to be modified to cope with this new objective. These methods most
often are restricted to binary classification problems only. In this study, a
filter feature selection method, namely MAUC Decomposition based Feature
Selection (MDFS), is proposed for multi-class classification problems. To the
best of our knowledge, MDFS is the first method specifically designed to select
features for building classification systems with maximum MAUC. Extensive
empirical results demonstrate the advantage of MDFS over several compared
feature selection methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2952</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2952</id><created>2011-05-15</created><updated>2012-01-30</updated><authors><author><keyname>Frigyik</keyname><forenames>Bela A.</forenames></author><author><keyname>Gupta</keyname><forenames>Maya R.</forenames></author></authors><title>Bounds on the Bayes Error Given Moments</title><categories>stat.ML cs.IT math.IT</categories><comments>10 pages, 2 figures, to appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to compute lower bounds for the supremum Bayes error if the
class-conditional distributions must satisfy moment constraints, where the
supremum is with respect to the unknown class-conditional distributions. Our
approach makes use of Curto and Fialkow's solutions for the truncated moment
problem. The lower bound shows that the popular Gaussian assumption is not
robust in this regard. We also construct an upper bound for the supremum Bayes
error by constraining the decision boundary to be linear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2960</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2960</id><created>2011-05-15</created><authors><author><keyname>Zidenberg</keyname><forenames>Tsahee</forenames></author><author><keyname>Keslassy</keyname><forenames>Isaac</forenames></author><author><keyname>Weiser</keyname><forenames>Uri</forenames></author></authors><title>Multi-Amdahl: Optimal Resource Sharing with Multiple Program Execution
  Segments</title><categories>cs.AR</categories><comments>Technical Report</comments><report-no>TR11-03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents Multi-Amdahl, a resource allocation analytical tool for
heterogeneous systems. Our model includes multiple program execution segments,
where each one is accelerated by a specific hardware unit. The acceleration
speedup of the specific hardware unit is a function of a limited resource, such
as the unit area, power, or energy. Using the Lagrange theorem we discover the
optimal resource distribution between all specific units. We then illustrate
this general Multi-Amdahl technique using several examples of area and power
allocation among several cores and accelerators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2965</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2965</id><created>2011-05-15</created><updated>2011-05-18</updated><authors><author><keyname>Lunga</keyname><forenames>Dalton</forenames></author><author><keyname>Kirshner</keyname><forenames>Sergey</forenames></author></authors><title>Generating Similar Graphs From Spherical Features</title><categories>cs.SI physics.soc-ph stat.AP stat.ME stat.ML</categories><comments>29 pages, 14 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel model for generating graphs similar to a given example
graph. Unlike standard approaches that compute features of graphs in Euclidean
space, our approach obtains features on a surface of a hypersphere. We then
utilize a von Mises-Fisher distribution, an exponential family distribution on
the surface of a hypersphere, to define a model over possible feature values.
While our approach bears similarity to a popular exponential random graph model
(ERGM), unlike ERGMs, it does not suffer from degeneracy, a situation when a
significant probability mass is placed on unrealistic graphs. We propose a
parameter estimation approach for our model, and a procedure for drawing
samples from the distribution. We evaluate the performance of our approach both
on the small domain of all 8-node graphs as well as larger real-world social
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2972</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2972</id><created>2011-05-15</created><authors><author><keyname>Dimitrov</keyname><forenames>Nikolay</forenames></author></authors><title>Illumination problems on translation surfaces with planar infinities</title><categories>math.MG cs.CG math.DS</categories><comments>8 pages divided into two columns each, 7 figures</comments><msc-class>51M05, 51M15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current article we discuss an illumination problem proposed by Urrutia
and Zaks. The focus is on configurations of finitely many two-sided mirrors in
the plane together with a source of light placed at an arbitrary point. In this
setting, we study the regions unilluminated by the source. In the case of
rational-$\pi$ angles between the mirrors, a planar configuration gives rise to
a surface with a translation structure and a number of planar infinities. We
show that on a surface of this type with at least two infinities, one can find
plenty of unilluminated regions isometric to unbounded planar sectors. In
addition, we establish that the non-bijectivity of a certain circle map implies
the existence of unbounded dark sectors for rational planar mirror
configurations illuminated by a light-source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2978</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2978</id><created>2011-05-15</created><authors><author><keyname>Hou</keyname><forenames>Shujie</forenames></author><author><keyname>Qiu</keyname><forenames>Robert C.</forenames></author></authors><title>Spectrum Sensing for Cognitive Radio Using Kernel-Based Learning</title><categories>cs.NI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernel method is a very powerful tool in machine learning. The trick of
kernel has been effectively and extensively applied in many areas of machine
learning, such as support vector machine (SVM) and kernel principal component
analysis (kernel PCA). Kernel trick is to define a kernel function which relies
on the inner-product of data in the feature space without knowing these feature
space data. In this paper, the kernel trick will be employed to extend the
algorithm of spectrum sensing with leading eigenvector under the framework of
PCA to a higher dimensional feature space. Namely, the leading eigenvector of
the sample covariance matrix in the feature space is used for spectrum sensing
without knowing the leading eigenvector explicitly. Spectrum sensing with
leading eigenvector under the framework of kernel PCA is proposed with the
inner-product as a measure of similarity. A modified kernel GLRT algorithm
based on matched subspace model will be the first time applied to spectrum
sensing. The experimental results on simulated sinusoidal signal show that
spectrum sensing with kernel PCA is about 4 dB better than PCA, besides, kernel
GLRT is also better than GLRT. The proposed algorithms are also tested on the
measured DTV signal. The simulation results show that kernel methods are 4 dB
better than the corresponding linear methods. The leading eigenvector of the
sample covariance matrix learned by kernel PCA is more stable than that learned
by PCA for different segments of DTV signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2988</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2988</id><created>2011-05-15</created><authors><author><keyname>James</keyname><forenames>Ryan G.</forenames></author><author><keyname>Ellison</keyname><forenames>Christopher J.</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author></authors><title>Anatomy of a Bit: Information in a Time Series Observation</title><categories>cs.IT cond-mat.stat-mech math.IT math.ST nlin.AO stat.TH</categories><comments>15 pages, 12 figures, 2 tables;
  http://cse.ucdavis.edu/~cmg/compmech/pubs/anatomy.htm</comments><doi>10.1063/1.3637494</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Appealing to several multivariate information measures---some familiar, some
new here---we analyze the information embedded in discrete-valued stochastic
time series. We dissect the uncertainty of a single observation to demonstrate
how the measures' asymptotic behavior sheds structural and semantic light on
the generating process's internal information dynamics. The measures scale with
the length of time window, which captures both intensive (rates of growth) and
subextensive components. We provide interpretations for the components,
developing explicit relationships between them. We also identify the
informational component shared between the past and the future that is not
contained in a single observation. The existence of this component directly
motivates the notion of a process's effective (internal) states and indicates
why one must build models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.2989</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.2989</id><created>2011-05-15</created><updated>2011-07-13</updated><authors><author><keyname>fard</keyname><forenames>Saeideh Parsaei</forenames></author><author><keyname>Sharafat</keyname><forenames>Ahmad R.</forenames></author></authors><title>Worst-Case Robust Distributed Power Allocation in Shared Unlicensed
  Spectrum</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers non-cooperative and fully-distributed power-allocation
for selfish transmitter-receiver pairs in shared unlicensed spectrum when
normalized-interference to each receiver is uncertain. We model each uncertain
parameter by the sum of its nominal (estimated) value and a bounded additive
error in a convex set, and show that the allocated power always converges to
its equilibrium, called robust Nash equilibrium (RNE). In the case of a bounded
and symmetric uncertainty region, we show that the power allocation problem for
each user is simplified, and can be solved in a distributed manner. We derive
the conditions for RNE's uniqueness and for convergence of the distributed
algorithm; and show that the total throughput (social utility) is less than
that at NE when RNE is unique. We also show that for multiple RNEs, the social
utility may be higher at a RNE as compared to that at the corresponding NE, and
demonstrate that this is caused by users' orthogonal utilization of bandwidth
at RNE. Simulations confirm our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3006</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3006</id><created>2011-05-16</created><authors><author><keyname>Goldenberg</keyname><forenames>Idan</forenames></author><author><keyname>Burshtein</keyname><forenames>David</forenames></author></authors><title>The approximate maximum-likelihood certificate</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new property which relies on the linear programming (LP) decoder, the
approximate maximum-likelihood certificate (AMLC), is introduced. When using
the belief propagation decoder, this property is a measure of how close the
decoded codeword is to the LP solution. Using upper bounding techniques, it is
demonstrated that the conditional frame error probability given that the AMLC
holds is, with some degree of confidence, below a threshold. In channels with
low noise, this threshold is several orders of magnitude lower than the
simulated frame error rate, and our bound holds with very high degree of
confidence. In contrast, showing this error performance by simulation would
require very long Monte Carlo runs. When the AMLC holds, our approach thus
provides the decoder with extra error detection capability, which is especially
important in applications requiring high data integrity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3023</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3023</id><created>2011-05-16</created><authors><author><keyname>Rossi</keyname><forenames>Claudio</forenames></author><author><keyname>Casetti</keyname><forenames>Claudio</forenames></author><author><keyname>Chiasserini</keyname><forenames>Carla-Fabiana</forenames></author></authors><title>An Energy Efficient Protocol for Gateway-Centric Federated Residential
  Access Networks</title><categories>cs.NI</categories><comments>8 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The proliferation of overlapping, always-on IEEE 802.11 Access Points (APs)
in urban areas can cause spectrum sharing conflicts, inefficient bandwidth
usage and power waste. Cooperation among APs could address these problems (i)
by allowing under-used devices to hand over their clients to nearby APs and
temporarily switch off, (ii) by balancing the load of clients among APs and
thus offloading congested APs. The federated houses model provides an appealing
backdrop to implement cooperation among APs. In this paper, we outline a
framework that, assuming the presence of a multipurpose gateway with AP
capabilities in every household, allows such cooperation through the monitoring
of local wireless resources and the triggering of offloading requests toward
other federated gateways. We then present simulation results in realistic
settings that provide some insight on the capabilities of our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3037</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3037</id><created>2011-05-16</created><authors><author><keyname>Pannek</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Horizon Adaptation for Nonlinear Model Predictive Controllers with
  guaranteed Degree of Suboptimality</title><categories>math.OC cs.SY</categories><comments>20 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose adaptation strategies to modify the standard constrained model
predictive controller scheme in order to guarantee a certain lower bound on the
degree of suboptimality. Within this analysis, the length of the optimization
horizon is the parameter we wish to adapt. We develop and prove several
shortening and prolongation strategies which also allow for an effective
implementation. Moreover, extensions of stability results and suboptimality
estimates to model predictive controllers with varying optimization horizon are
shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3040</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3040</id><created>2011-05-16</created><authors><author><keyname>Khlopin</keyname><forenames>Dmitry</forenames></author></authors><title>The transversality conditions for infinite-horizon optimal control
  problem with a free right endpoint and the stability of the adjoint variable
  (in Russian)</title><categories>math.OC cs.SY</categories><msc-class>49K15 (91B02)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An infinite-horizon optimal control problem with a free right endpoint is
considered. In this paper we proved that Lyapunov stability of the adjoint
variable implying the vanishing of the adjoint variable at infinity along
optimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3042</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3042</id><created>2011-05-16</created><updated>2012-06-27</updated><authors><author><keyname>Pannek</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Parallelizing a State Exchange Strategy for Noncooperative Distributed
  NMPC</title><categories>math.OC cs.SY math.DS</categories><comments>22 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a distributed non cooperative control setting in which systems
are interconnected via state constraints. Each of these systems is governed by
an agent which is responsible for exchanging information with its neighbours
and computing a feedback law using a nonlinear model predictive controller to
avoid violations of constraints. For this setting we present an algorithm which
generates a parallelizable hierarchy among the systems. Moreover, we show both
feasibility and stability of the closed loop using only abstract properties of
this algorithm. To this end, we utilize a trajectory based stability result
which we extend to the distributed setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3068</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3068</id><created>2011-05-16</created><authors><author><keyname>Simon</keyname><forenames>Francois</forenames></author></authors><title>On the Capacity of Noisy Computations</title><categories>cs.IT math.IT</categories><comments>This paper has been submitted to the Information Theory Workshop 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an analysis of the concept of capacity for noisy
computations, i.e. algorithms implemented by unreliable computing devices (e.g.
noisy Turing Machines). The capacity of a noisy computation is defined and
justified by companion coding theorems. Under some constraints on the encoding
process, capacity is the upper bound of input rates allowing reliable
computation, i.e. decodability of noisy outputs into expected outputs. A model
of noisy computation of a perfect function f thanks to an unreliable device F
is given together with a model of reliable computation based on input encoding
and output decoding. A coding lemma (extending the Feinstein's theorem to noisy
computations), a joint source-computation coding theorem and its converse are
proved. They apply if the input source, the function f, the noisy device F and
the cascade f^{-1}F induce AMS and ergodic one-sided random processes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3078</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3078</id><created>2011-05-16</created><authors><author><keyname>Lund</keyname><forenames>Ben D.</forenames></author><author><keyname>Purdy</keyname><forenames>George B.</forenames></author><author><keyname>Smith</keyname><forenames>Justin W.</forenames></author><author><keyname>T&#xf3;th</keyname><forenames>Csaba D.</forenames></author></authors><title>Collinearities in Kinetic Point Sets</title><categories>cs.CG math.CO</categories><comments>Submitted to CCCG11</comments><msc-class>68R99</msc-class><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ be a set of $n$ points in the plane, each point moving along a given
trajectory. A {\em $k$-collinearity} is a pair $(L,t)$ of a line $L$ and a time
$t$ such that $L$ contains at least $k$ points at time $t$, the points along
$L$ do not all coincide, and not all of them are collinear at all times. We
show that, if the points move with constant velocity, then the number of
3-collinearities is at most $2\binom{n}{3}$, and this bound is tight. There are
$n$ points having $\Omega(n^3/k^4 + n^2/k^2)$ distinct $k$-collinearities.
Thus, the number of $k$-collinearities among $n$ points, for constant $k$, is
$O(n^3)$, and this bound is asymptotically tight. In addition, there are $n$
points, moving in pairwise distinct directions with different speeds, such that
no three points are ever collinear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3093</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3093</id><created>2011-05-16</created><updated>2012-01-05</updated><authors><author><keyname>Reading</keyname><forenames>Nathan</forenames></author></authors><title>Generic rectangulations</title><categories>math.CO cs.DM</categories><comments>Final version to appear in Eur. J. Combinatorics. Since v2, I became
  aware of literature on generic rectangulations under the name rectangular
  drawings. There are results on asymptotic enumeration and computations
  counting generic rectangulations with n rectangles for many n. This result
  answers an open question posed in the rectangular drawings literature. See
  &quot;Note added in proof.&quot;</comments><msc-class>05A05, 05A19, 05B45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rectangulation is a tiling of a rectangle by a finite number of rectangles.
The rectangulation is called generic if no four of its rectangles share a
single corner. We initiate the enumeration of generic rectangulations up to
combinatorial equivalence by establishing an explicit bijection between generic
rectangulations and a set of permutations defined by a pattern-avoidance
condition analogous to the definition of the twisted Baxter permutations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3106</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3106</id><created>2011-05-16</created><authors><author><keyname>Rutishauser</keyname><forenames>Ueli</forenames></author><author><keyname>Douglas</keyname><forenames>Rodney J.</forenames></author><author><keyname>Slotine</keyname><forenames>Jean-Jacques</forenames></author></authors><title>Collective stability of networks of winner-take-all circuits</title><categories>q-bio.NC cond-mat.dis-nn cs.NE</categories><comments>7 Figures</comments><journal-ref>Neural computation 23(3):735-773, 2011</journal-ref><doi>10.1162/NECO_a_00091</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The neocortex has a remarkably uniform neuronal organization, suggesting that
common principles of processing are employed throughout its extent. In
particular, the patterns of connectivity observed in the superficial layers of
the visual cortex are consistent with the recurrent excitation and inhibitory
feedback required for cooperative-competitive circuits such as the soft
winner-take-all (WTA). WTA circuits offer interesting computational properties
such as selective amplification, signal restoration, and decision making. But,
these properties depend on the signal gain derived from positive feedback, and
so there is a critical trade-off between providing feedback strong enough to
support the sophisticated computations, while maintaining overall circuit
stability. We consider the question of how to reason about stability in very
large distributed networks of such circuits. We approach this problem by
approximating the regular cortical architecture as many interconnected
cooperative-competitive modules. We demonstrate that by properly understanding
the behavior of this small computational module, one can reason over the
stability and convergence of very large networks composed of these modules. We
obtain parameter ranges in which the WTA circuit operates in a high-gain
regime, is stable, and can be aggregated arbitrarily to form large stable
networks. We use nonlinear Contraction Theory to establish conditions for
stability in the fully nonlinear case, and verify these solutions using
numerical simulations. The derived bounds allow modes of operation in which the
WTA network is multi-stable and exhibits state-dependent persistent activities.
Our approach is sufficiently general to reason systematically about the
stability of any network, biological or technological, composed of networks of
small modules that express competition through shared inhibition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3107</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3107</id><created>2011-05-16</created><updated>2011-06-17</updated><authors><author><keyname>Jiang</keyname><forenames>Yun</forenames></author><author><keyname>Zheng</keyname><forenames>Changxi</forenames></author><author><keyname>Lim</keyname><forenames>Marcus</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author></authors><title>Learning to Place New Objects</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to place objects in the environment is an important skill for a
personal robot. An object should not only be placed stably, but should also be
placed in its preferred location/orientation. For instance, a plate is
preferred to be inserted vertically into the slot of a dish-rack as compared to
be placed horizontally in it. Unstructured environments such as homes have a
large variety of object types as well as of placing areas. Therefore our
algorithms should be able to handle placing new object types and new placing
areas. These reasons make placing a challenging manipulation task. In this
work, we propose a supervised learning algorithm for finding good placements
given the point-clouds of the object and the placing area. It learns to combine
the features that capture support, stability and preferred placements using a
shared sparsity structure in the parameters. Even when neither the object nor
the placing area is seen previously in the training set, our algorithm predicts
good placements. In extensive experiments, our method enables the robot to
stably place several new objects in several new placing areas with 98%
success-rate; and it placed the objects in their preferred placements in 92% of
the cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3116</identifier>
 <datestamp>2011-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3116</id><created>2011-05-16</created><authors><author><keyname>Kolpakov</keyname><forenames>Roman</forenames></author><author><keyname>Rao</keyname><forenames>Michael</forenames></author></authors><title>On the number of Dejean words over alphabets of 5, 6, 7, 8, 9 and 10
  letters</title><categories>cs.FL</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give lower bounds on the growth rate of Dejean words, i.e. minimally
repetitive words, over a k-letter alphabet, for k=5, 6, 7, 8, 9, 10. Put
together with the known upper bounds, we estimate these growth rates with the
precision of 0,005. As an consequence, we establish the exponential growth of
the number of Dejean words over a k-letter alphabet, for k=5, 6, 7, 8, 9, 10.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3144</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3144</id><created>2011-05-16</created><updated>2011-06-05</updated><authors><author><keyname>Lu</keyname><forenames>Lu</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author></authors><title>Asynchronous Physical-layer Network Coding</title><categories>cs.IT cs.NI math.IT</categories><comments>Full length version of APNC</comments><journal-ref>IEEE Transactions on Wireless Communications, 2012</journal-ref><doi>10.1109/TWC.2011.120911.111067</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key issue in physical-layer network coding (PNC) is how to deal with the
asynchrony between signals transmitted by multiple transmitters. That is,
symbols transmitted by different transmitters could arrive at the receiver with
symbol misalignment as well as relative carrier-phase offset. A second
important issue is how to integrate channel coding with PNC to achieve reliable
communication. This paper investigates these two issues and makes the following
contributions: 1) We propose and investigate a general framework for decoding
at the receiver based on belief propagation (BP). The framework can effectively
deal with symbol and phase asynchronies while incorporating channel coding at
the same time. 2) For unchannel-coded PNC, we show that for BPSK and QPSK
modulations, our BP method can significantly reduce the asynchrony penalties
compared with prior methods. 3) For unchannel-coded PNC, with half symbol
offset between the transmitters, our BP method can drastically reduce the
performance penalty due to phase asynchrony, from more than 6 dB to no more
than 1 dB. 4) For channel-coded PNC, with our BP method, both symbol and phase
asynchronies actually improve the system performance compared with the
perfectly synchronous case. Furthermore, the performance spread due to
different combinations of symbol and phase offsets between the transmitters in
channel-coded PNC is only around 1 dB. The implication of 3) is that if we
could control the symbol arrival times at the receiver, it would be
advantageous to deliberately introduce a half symbol offset in unchannel-coded
PNC. The implication of 4) is that when channel coding is used, symbol and
phase asynchronies are not major performance concerns in PNC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3162</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3162</id><created>2011-05-16</created><authors><author><keyname>Gupta</keyname><forenames>Neeraj</forenames></author><author><keyname>Shekhar</keyname><forenames>Rajiv</forenames></author><author><keyname>Kalra</keyname><forenames>Prem Kumar</forenames></author></authors><title>A Novel Method for Calculating Demand Not Served for Transmission
  Expansion Planning</title><categories>cs.OH</categories><comments>2 pages, 3 figures, letter in IEEE Transaction</comments><msc-class>93-06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Restructuring of the power market introduced demand uncertainty in
transmission expansion planning (TEP), which in turn also requires an accurate
estimation of demand not served (DNS). Unfortunately, the graph theory based
minimum-cut maximum-flow (MCMF) approach does not ensure that electrical laws
are followed. Nor can it be used for calculating DNS at individual buses. In
this letter, we propose a generalized load flow based methodology for
calculating DNS. This procedure is able to calculate simultaneously generation
not served (GNS) and wheeling loss (WL). Importantly, the procedure is able to
incorporate the effect of I2R losses, excluded in MCMF approach. Case study on
a 5-bus IEEE system shows the effectiveness of the proposed approach over
existing method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3168</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3168</id><created>2011-05-16</created><authors><author><keyname>Zhu</keyname><forenames>Hao</forenames></author><author><keyname>Giannakis</keyname><forenames>Georgios B.</forenames></author></authors><title>Lassoing Line Outages in the Smart Power Grid</title><categories>cs.SY math.OC stat.AP</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast and accurate unveiling of power line outages is of paramount importance
not only for preventing faults that may lead to blackouts, but also for routine
monitoring and control tasks of the smart grid, including state estimation and
optimal power flow. Existing approaches are either challenged by the
\emph{combinatorial complexity} issues involved, and are thus limited to
identifying single- and double-line outages; or, they invoke less pragmatic
assumptions such as \emph{conditionally independent} phasor angle measurements
available across the grid. Using only a subset of voltage phasor angle data,
the present paper develops a near real-time algorithm for identifying multiple
line outages at the affordable complexity of solving a quadratic program via
block coordinate descent iterations. The novel approach relies on reformulating
the DC linear power flow model as a \emph{sparse} overcomplete expansion, and
leveraging contemporary advances in compressive sampling and variable selection
using the least-absolute shrinkage and selection operator (Lasso). Analysis and
simulated tests on the standard IEEE 118-bus system confirm the effectiveness
of lassoing line changes in the smart power grid.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3201</identifier>
 <datestamp>2012-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3201</id><created>2011-05-16</created><updated>2011-10-03</updated><authors><author><keyname>Garcia-Saez</keyname><forenames>A.</forenames></author><author><keyname>Latorre</keyname><forenames>J. I.</forenames></author></authors><title>An exact tensor network for the 3SAT problem</title><categories>quant-ph cond-mat.stat-mech cs.CC</categories><comments>10 pages, 2 figures. New numerical examples</comments><journal-ref>Quantum Information and Computation Vol.12 No.3&amp;4, 0283-0292
  (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a tensor network that delivers an unnormalized quantum state
whose coefficients are the solutions to a given instance of 3SAT, an
NP-complete problem. The tensor network contraction that corresponds to the
norm of the state counts the number of solutions to the instance. It follows
that exact contractions of this tensor network are in the #P-complete
computational complexity class, thus believed to be a hard task. Furthermore,
we show that for a 3SAT instance with n bits, it is enough to perform a
polynomial number of contractions of the tensor network structure associated to
the computation of local observables to obtain one of the explicit solutions to
the problem, if any. Physical realization of a state described by a generic
tensor network is equivalent to finding the satisfying assignment of a 3SAT
instance and, consequently, this experimental task is expected to be hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3212</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3212</id><created>2011-05-16</created><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>Yan</keyname><forenames>Erjia</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author></authors><title>A recursive field-normalized bibliometric performance indicator: An
  application to the field of library and information science</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two commonly used ideas in the development of citation-based research
performance indicators are the idea of normalizing citation counts based on a
field classification scheme and the idea of recursive citation weighing (like
in PageRank-inspired indicators). We combine these two ideas in a single
indicator, referred to as the recursive mean normalized citation score
indicator, and we study the validity of this indicator. Our empirical analysis
shows that the proposed indicator is highly sensitive to the field
classification scheme that is used. The indicator also has a strong tendency to
reinforce biases caused by the classification scheme. Based on these
observations, we advise against the use of indicators in which the idea of
normalization based on a field classification scheme and the idea of recursive
citation weighing are combined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3228</identifier>
 <datestamp>2014-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3228</id><created>2011-05-16</created><authors><author><keyname>Biondi</keyname><forenames>Yuri</forenames></author><author><keyname>Giannoccolo</keyname><forenames>Pierpaolo</forenames></author><author><keyname>Galam</keyname><forenames>Serge</forenames></author></authors><title>The formation of share market prices under heterogeneous beliefs and
  common knowledge</title><categories>physics.soc-ph cs.SI q-fin.PR</categories><comments>22 pages, 9 figures</comments><doi>10.1016/j.physa.2012.06.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Financial economic models often assume that investors know (or agree on) the
fundamental value of the shares of the firm, easing the passage from the
individual to the collective dimension of the financial system generated by the
Share Exchange over time. Our model relaxes that heroic assumption of one
unique &quot;true value&quot; and deals with the formation of share market prices through
the dynamic formation of individual and social opinions (or beliefs) based upon
a fundamental signal of economic performance and position of the firm, the
forecast revision by heterogeneous individual investors, and their social mood
or sentiment about the ongoing state of the market pricing process. Market
clearing price formation is then featured by individual and group dynamics that
make its collective dimension irreducible to its individual level. This dynamic
holistic approach can be applied to better understand the market exuberance
generated by the Share Exchange over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3232</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3232</id><created>2011-05-16</created><authors><author><keyname>Kosta</keyname><forenames>Sokol</forenames></author><author><keyname>Aucinas</keyname><forenames>Andrius</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Mortier</keyname><forenames>Richard</forenames></author><author><keyname>Zhang</keyname><forenames>Xinwen</forenames></author></authors><title>Unleashing the Power of Mobile Cloud Computing using ThinkAir</title><categories>cs.DC cs.NI cs.OS</categories><comments>17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smartphones have exploded in popularity in recent years, becoming ever more
sophisticated and capable. As a result, developers worldwide are building
increasingly complex applications that require ever increasing amounts of
computational power and energy. In this paper we propose ThinkAir, a framework
that makes it simple for developers to migrate their smartphone applications to
the cloud. ThinkAir exploits the concept of smartphone virtualization in the
cloud and provides method level computation offloading. Advancing on previous
works, it focuses on the elasticity and scalability of the server side and
enhances the power of mobile cloud computing by parallelizing method execution
using multiple Virtual Machine (VM) images. We evaluate the system using a
range of benchmarks starting from simple micro-benchmarks to more complex
applications. First, we show that the execution time and energy consumption
decrease two orders of magnitude for the N-queens puzzle and one order of
magnitude for a face detection and a virus scan application, using cloud
offloading. We then show that if a task is parallelizable, the user can request
more than one VM to execute it, and these VMs will be provided dynamically. In
fact, by exploiting parallelization, we achieve a greater reduction on the
execution time and energy consumption for the previous applications. Finally,
we use a memory-hungry image combiner tool to demonstrate that applications can
dynamically request VMs with more computational power in order to meet their
computational requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3234</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3234</id><created>2011-05-16</created><authors><author><keyname>Berardi</keyname><forenames>Matthew</forenames></author><author><keyname>Heeringa</keyname><forenames>Brent</forenames></author><author><keyname>Malestein</keyname><forenames>Justin</forenames></author><author><keyname>Theran</keyname><forenames>Louis</forenames></author></authors><title>Rigid components in fixed-lattice and cone frameworks</title><categories>cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the fundamental algorithmic rigidity problems for generic frameworks
periodic with respect to a fixed lattice or a finite-order rotation in the
plane. For fixed-lattice frameworks we give an $O(n^2)$ algorithm for deciding
generic rigidity and an O(n^3) algorithm for computing rigid components. If the
order of rotation is part of the input, we give an O(n^4) algorithm for
deciding rigidity; in the case where the rotation's order is 3, a more
specialized algorithm solves all the fundamental algorithmic rigidity problems
in O(n^2) time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3237</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3237</id><created>2011-05-16</created><authors><author><keyname>Lorimer</keyname><forenames>William R.</forenames></author></authors><title>Double Blind Comparisons using Groups with Infeasible Inversion</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Double Blind Comparison is a new cryptographic primitive that allows a user
who is in possession of a ciphertext to determine if the corresponding
plaintext is identical to the plaintext for a different ciphertext held by a
different user, but only if both users co-operate. Neither user knows anything
about the plaintexts corresponding to either ciphertext, and neither user
learns anything about the plaintexts as a result of the comparison, other than
whether the two plaintexts are identical. Neither user can determine whether
the plaintexts are equal without the other user's co-operation. Double Blind
Comparisons have potential application in Anonymous Credentials and the
Database Aggregation Problem. This paper shows how Double Blind Comparisons can
be implemented using a Strong Associative One-Way Function (SAOWF). Proof of
security is given, making an additional assumption that the SAOWF is
implemented on a Group with Infeasible Inversion (GII), whose existence was
postulated by Hohenberger and Molnar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3239</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3239</id><created>2011-05-16</created><authors><author><keyname>Lorimer</keyname><forenames>William R.</forenames></author></authors><title>Double Blind Comparisons: A New Approach to the Database Aggregation
  Problem</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Data Aggregation Problem occurs when a large collection of data takes on
a higher security level than any of its individual component records.
Traditional approaches of breaking up the data and restricting access on a
&quot;need to know&quot; basis take away one of the great advantages of collecting the
data in the first place. This paper introduces a new cryptographic primitive,
Double Blind Comparisons, which allows two co-operating users, who each have an
encrypted secret, to determine the equality or inequality of those two secrets,
even though neither user can discover any information about what the secret is.
This paper also introduces a new problem in bilinear groups, conjectured to be
a hard problem. Assuming this conjecture, it is shown that neither user can
discover any information about whether the secrets are equal, without the other
user's co-operation. We then look at how Double Blind Comparisons can be used
to mitigate the Data Aggregation Problem. Finally, the paper concludes with
some suggested possibilities for future research and some other potential uses
for Double Blind Comparisons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3252</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3252</id><created>2011-05-16</created><authors><author><keyname>Shpilrain</keyname><forenames>Vladimir</forenames></author></authors><title>Sublinear time algorithms in the theory of groups and semigroups</title><categories>math.GR cs.CC</categories><comments>12 pages</comments><msc-class>20F10, 68Q17</msc-class><journal-ref>Illinois J. Math. 54 (2011), 187---197</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sublinear time algorithms represent a new paradigm in computing, where an
algorithm must give some sort of an answer after inspecting only a small
portion of the input. The most typical situation where sublinear time
algorithms are considered is property testing. There are several interesting
contexts where one can test properties in sublinear time. A canonical example
is graph colorability. To tell that a given graph is not k-colorable, it is
often sufficient to inspect just one vertex with incident edges: if the degree
of a vertex is greater than k, then the graph is not k-colorable. It is a
challenging and interesting task to find algebraic properties that could be
tested in sublinear time. In this paper, we address several algorithmic
problems in the theory of groups and semigroups that may admit sublinear time
solution, at least for &quot;most&quot; inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3259</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3259</id><created>2011-05-16</created><authors><author><keyname>Nielsen</keyname><forenames>Frank</forenames></author><author><keyname>Nock</keyname><forenames>Richard</forenames></author></authors><title>On R\'enyi and Tsallis entropies and divergences for exponential
  families</title><categories>cs.IT cs.LG math.IT</categories><comments>7 pages</comments><journal-ref>Journal of Physics A: Mathematical and Theoretical, Volume 45
  Number 3, 2012</journal-ref><doi>10.1088/1751-8113/45/3/032003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many common probability distributions in statistics like the Gaussian,
multinomial, Beta or Gamma distributions can be studied under the unified
framework of exponential families. In this paper, we prove that both R\'enyi
and Tsallis divergences of distributions belonging to the same exponential
family admit a generic closed form expression. Furthermore, we show that
R\'enyi and Tsallis entropies can also be calculated in closed-form for
sub-families including the Gaussian or exponential distributions, among others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3264</identifier>
 <datestamp>2013-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3264</id><created>2011-05-16</created><authors><author><keyname>Xie</keyname><forenames>Jierui</forenames></author><author><keyname>Szymanski</keyname><forenames>Boleslaw K.</forenames></author></authors><title>Community Detection Using A Neighborhood Strength Driven Label
  Propagation Algorithm</title><categories>cs.SI physics.soc-ph</categories><comments>IEEE NSW 2011</comments><journal-ref>Proc.IEEE Network Science Workshop, NSW'11, West Point, NY, 2011,
  pp. 188-195</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studies of community structure and evolution in large social networks require
a fast and accurate algorithm for community detection. As the size of analyzed
communities grows, complexity of the community detection algorithm needs to be
kept close to linear. The Label Propagation Algorithm (LPA) has the benefits of
nearly-linear running time and easy implementation, thus it forms a good basis
for efficient community detection methods. In this paper, we propose new update
rule and label propagation criterion in LPA to improve both its computational
efficiency and the quality of communities that it detects. The speed is
optimized by avoiding unnecessary updates performed by the original algorithm.
This change reduces significantly (by order of magnitude for large networks)
the number of iterations that the algorithm executes. We also evaluate our
generalization of the LPA update rule that takes into account, with varying
strength, connections to the neighborhood of a node considering a new label.
Experiments on computer generated networks and a wide range of social networks
show that our new rule improves the quality of the detected communities
compared to those found by the original LPA. The benefit of considering
positive neighborhood strength is pronounced especially on real-world networks
containing sufficiently large fraction of nodes with high clustering
coefficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3266</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3266</id><created>2011-05-16</created><authors><author><keyname>Jahn</keyname><forenames>Thomas</forenames></author><author><keyname>Pannek</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Stability of Constrained Adaptive Model Predictive Control Algorithms</title><categories>math.OC cs.SY</categories><comments>6 pages, 2 figures</comments><journal-ref>Proceedings of the 18th IFAC World Congress, 2011, 9272--9277</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, suboptimality estimates for model predictive controllers (MPC) have
been derived for the case without additional stabilizing endpoint constraints
or a Lyapunov function type endpoint weight. The proposed methods yield a
posteriori and a priori estimates of the degree of suboptimality with respect
to the infinite horizon optimal control and can be evaluated at runtime of the
MPC algorithm. Our aim is to design automatic adaptation strategies of the
optimization horizon in order to guarantee stability and a predefined degree of
suboptimality for the closed loop solution. Here, we present a stability proof
for an arbitrary adaptation scheme and state a simple shortening and
prolongation strategy which can be used for adapting the optimization horizon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3267</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3267</id><created>2011-05-16</created><authors><author><keyname>Pannek</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Worthmann</keyname><forenames>Karl</forenames></author></authors><title>Reducing the Prediction Horizon in NMPC: An Algorithm Based Approach</title><categories>math.OC cs.SY math.NA</categories><comments>6 pages, 3 figures</comments><journal-ref>Proceedings of the 18th IFAC World Congress, 2011, 7969-7974</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to guarantee stability, known results for MPC without additional
terminal costs or endpoint constraints often require rather large prediction
horizons. Still, stable behavior of closed loop solutions can often be observed
even for shorter horizons. Here, we make use of the recent observation that
stability can be guaranteed for smaller prediction horizons via Lyapunov
arguments if more than only the first control is implemented. Since such a
procedure may be harmful in terms of robustness, we derive conditions which
allow to increase the rate at which state measurements are used for feedback
while maintaining stability and desired performance specifications. Our main
contribution consists in developing two algorithms based on the deduced
conditions and a corresponding stability theorem which ensures asymptotic
stability for the MPC closed loop for significantly shorter prediction
horizons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3268</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3268</id><created>2011-05-16</created><authors><author><keyname>Findeisen</keyname><forenames>Rolf</forenames></author><author><keyname>Gr&#xfc;ne</keyname><forenames>Lars</forenames></author><author><keyname>Pannek</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>Varutti</keyname><forenames>Paolo</forenames></author></authors><title>Robustness of Prediction Based Delay Compensation for Nonlinear Systems</title><categories>math.OC cs.SY</categories><comments>6 pages, 3 figures</comments><journal-ref>Proceedings of the 18th IFAC World Congress, 2011, 203--208</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Control of systems where the information between the controller, actuator,
and sensor can be lost or delayed can be challenging with respect to stability
and performance. One way to overcome the resulting problems is the use of
prediction based compensation schemes. Instead of a single input, a sequence of
(predicted) future controls is submitted and implemented at the actuator. If
suitable, so-called prediction consistent compensation and control schemes,
such as certain predictive control approaches, are used, stability of the
closed loop in the presence of delays and packet losses can be guaranteed. In
this paper, we show that control schemes employing prediction based delay
compensation approaches do posses inherent robustness properties. Specifically,
if the nominal closed loop system without delay compensation is ISS with
respect to perturbation and measurement errors, then the closed loop system
employing prediction based delay compensation techniques is robustly stable. We
analyze the influence of the prediction horizon on the robustness gains and
illustrate the results in simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3270</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3270</id><created>2011-05-16</created><authors><author><keyname>H&#xe4;nel</keyname><forenames>Maria</forenames></author><author><keyname>Kuhn</keyname><forenames>Stefan</forenames></author><author><keyname>Henrich</keyname><forenames>Dominik</forenames></author><author><keyname>Gr&#xfc;ne</keyname><forenames>Lars</forenames></author><author><keyname>Pannek</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Optimal Camera Placement to measure Distances Conservativly Regarding
  Static and Dynamic Obstacles</title><categories>cs.CV cs.RO math.OC</categories><comments>9 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In modern production facilities industrial robots and humans are supposed to
interact sharing a common working area. In order to avoid collisions, the
distances between objects need to be measured conservatively which can be done
by a camera network. To estimate the acquired distance, unmodelled objects,
e.g., an interacting human, need to be modelled and distinguished from
premodelled objects like workbenches or robots by image processing such as the
background subtraction method.
  The quality of such an approach massively depends on the settings of the
camera network, that is the positions and orientations of the individual
cameras. Of particular interest in this context is the minimization of the
error of the distance using the objects modelled by the background subtraction
method instead of the real objects. Here, we show how this minimization can be
formulated as an abstract optimization problem. Moreover, we state various
aspects on the implementation as well as reasons for the selection of a
suitable optimization method, analyze the complexity of the proposed method and
present a basic version used for extensive experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3272</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3272</id><created>2011-05-16</created><authors><author><keyname>Pannek</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>von Lossow</keyname><forenames>Marcus</forenames></author></authors><title>Stability of Observer Based Predictive Control for Nonlinear
  Sampled-data Systems</title><categories>math.OC cs.SY math.FA</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new model predictive control (MPC) approach which is completely
based on an observer for the state system. For this, we show semiglobally
practically asymptotic stability of the closed loop for an abstract observer
and illustrate our results for a numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3287</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3287</id><created>2011-05-17</created><authors><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>IDSL, INRIA Saclay - Ile de France</affiliation></author></authors><title>Scholarly Communication</title><categories>cs.DL</categories><comments>To appear in Mehler, Romary, Gibbon (eds), Technical Communication,
  M. de Gruyter, Berlin (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The chapter tackles the role of scholarly publication in the research process
(quality, preservation) and looks at the consequences of new information
technologies in the organization of the scholarly communication ecology. It
will then show how new technologies have had an impact on the scholarly
communication process and made it depart from the traditional publishing
environment. Developments will address new editorial processes, dissemination
of new content and services, as well as the development of publication
archives. This last aspect will be covered on all levels (open access,
scientific, technical and legal aspects). A view on the possible evolutions of
the scientific publishing environment will be provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3298</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3298</id><created>2011-05-17</created><updated>2011-08-30</updated><authors><author><keyname>Williams</keyname><forenames>Jason L.</forenames></author></authors><title>Graphical model approximations of random finite set filters</title><categories>cs.SY math.OC</categories><comments>Extended version; first version submitted to Fusion 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random finite sets (RFSs) has been a fruitful area of research in recent
years, yielding new approximate filters such as the probability hypothesis
density (PHD), cardinalised PHD (CPHD), and multiple target multi-Bernoulli
(MeMBer). These new methods have largely been based on approximations that
side-step the need for measurement-to-track association. Comparably, RFS
methods that incorporate data association, such as Morelande and Challa's (M-C)
method, have received little attention. This paper provides a RFS algorithm
that incorporates data association similarly to the M-C method, but retains
computational tractability via a recently developed approximation of marginal
association weights. We describe an efficient method for resolving the track
coalescence phenomenon which is problematic for joint probabilistic data
association (JPDA) and related methods (including M-C). The method utilises a
network flow optimisation, and thus is tractable for large numbers of targets.
Finally, our derivation also shows that it is natural for the multi-target
density to incorporate both a Poisson point process (PPP) component
(representing targets that have never been detected) and a multi-Bernoulli
component (representing targets under track). We describe a method of
recycling, in which tracks with a low probability existence are transferred
from the multi-Bernoulli component to the PPP component, effectively yielding a
hybrid of M-C and PHD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3299</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3299</id><created>2011-05-17</created><updated>2011-05-21</updated><authors><author><keyname>Li</keyname><forenames>Song</forenames></author><author><keyname>Lin</keyname><forenames>Junhong</forenames></author></authors><title>Compressed Sensing with coherent tight frames via $l_q$-minimization for
  $0&lt;q\leq1$</title><categories>math.NA cs.IT math.IT</categories><msc-class>Primary 94A12, 94A15, 94A08, 68P30, Secondary 41A63, 15B52, 42C15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our aim of this article is to reconstruct a signal from undersampled data in
the situation that the signal is sparse in terms of a tight frame. We present a
condition, which is independent of the coherence of the tight frame, to
guarantee accurate recovery of signals which are sparse in the tight frame,
from undersampled data with minimal $l_1$-norm of transform coefficients. This
improves the result in [1]. Also, the $l_q$-minimization $(0&lt;q&lt;1)$ approaches
are introduced. We show that under a suitable condition, there exists a value
$q_0\in(0,1]$ such that for any $q\in(0,q_0)$, each solution of the
$l_q$-minimization is approximately well to the true signal. In particular,
when the tight frame is an identity matrix or an orthonormal basis, all results
obtained in this paper appeared in [13] and [26].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3316</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3316</id><created>2011-05-17</created><authors><author><keyname>Iribarren</keyname><forenames>Jos&#xe9; Luis</forenames></author><author><keyname>Moro</keyname><forenames>Esteban</forenames></author></authors><title>Affinity Paths and Information Diffusion in Social Networks</title><categories>physics.soc-ph cs.SI</categories><comments>11 pages, 7 figures</comments><journal-ref>Social Networks 33 (2011) 134-142</journal-ref><doi>10.1016/j.socnet.2010.11.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Widespread interest in the diffusion of information through social networks
has produced a large number of Social Dynamics models. A majority of them use
theoretical hypothesis to explain their diffusion mechanisms while the few
empirically based ones average out their measures over many messages of
different content. Our empirical research tracking the step-by-step email
propagation of an invariable viral marketing message delves into the content
impact and has discovered new and striking features. The topology and dynamics
of the propagation cascades display patterns not inherited from the email
networks carrying the message. Their disconnected, low transitivity, tree-like
cascades present positive correlation between their nodes probability to
forward the message and the average number of neighbors they target and show
increased participants' involvement as the propagation paths length grows. Such
patterns not described before, nor replicated by any of the existing models of
information diffusion, can be explained if participants make their pass-along
decisions based uniquely on local knowledge of their network neighbors affinity
with the message content. We prove the plausibility of such mechanism through a
stylized, agent-based model that replicates the \emph{Affinity Paths} observed
in real information diffusion cascades.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3324</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3324</id><created>2011-05-17</created><authors><author><keyname>Durand</keyname><forenames>Arnaud</forenames></author><author><keyname>Kontinen</keyname><forenames>Juha</forenames></author></authors><title>Hierarchies in Dependence Logic</title><categories>cs.LO</categories><comments>21 pages</comments><acm-class>F.4.1; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study fragments of dependence logic defined either by restricting the
number k of universal quantifiers or the width of dependence atoms in formulas.
We find the sublogics of existential second-order logic corresponding to these
fragments of dependence logic. We also show that these both ways of defining
fragments of dependence logic give rise to a hierarchy in expressive power with
respect to k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3326</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3326</id><created>2011-05-17</created><updated>2011-11-23</updated><authors><author><keyname>Michaeli</keyname><forenames>Tomer</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Xampling at the Rate of Innovation</title><categories>cs.IT math.IT</categories><comments>13 pages, 10 figures, journal</comments><doi>10.1109/TSP.2011.2178409</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of recovering signals from samples taken at their rate
of innovation. Our only assumption is that the sampling system is such that the
parameters defining the signal can be stably determined from the samples, a
condition that lies at the heart of every sampling theorem. Consequently, our
analysis subsumes previously studied nonlinear acquisition devices and
nonlinear signal classes. In particular, we do not restrict attention to
memoryless nonlinear distortions or to union-of-subspace models. This allows
treatment of various finite-rate-of-innovation (FRI) signals that were not
previously studied, including, for example, continuous phase modulation
transmissions. Our strategy relies on minimizing the error between the measured
samples and those corresponding to our signal estimate. This least-squares (LS)
objective is generally non-convex and might possess many local minima.
Nevertheless, we prove that under the stability hypothesis, any optimization
method designed to trap a stationary point of the LS criterion necessarily
converges to the true solution. We demonstrate our approach in the context of
recovering pulse streams in settings that were not previously treated.
Furthermore, in situations for which other algorithms are applicable, we show
that our method is often preferable in terms of noise robustness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3338</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3338</id><created>2011-05-17</created><updated>2012-03-21</updated><authors><author><keyname>Pagani</keyname><forenames>Giuliano Andrea</forenames></author><author><keyname>Aiello</keyname><forenames>Marco</forenames></author></authors><title>The Power Grid as a Complex Network: a Survey</title><categories>physics.soc-ph cs.DM cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The statistical tools of Complex Network Analysis are of great use to
understand salient properties of complex systems, may these be natural or
pertaining human engineered infrastructures. One of these that is receiving
growing attention for its societal relevance is that of electricity
distribution. In this paper, we present a survey of the most important
scientific studies investigating the properties of different Power Grids
infrastructures using Complex Network Analysis techniques and methodologies. We
categorize and explore the most relevant literature works considering general
topological properties, differences between the various graph-related
indicators and reliability aspects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3346</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3346</id><created>2011-05-17</created><authors><author><keyname>Aslanyan</keyname><forenames>Hakob</forenames></author><author><keyname>Rolim</keyname><forenames>Jose</forenames></author></authors><title>Randomly Roving Agents in Wireless Sensor Networks</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantitative characterization of randomly roving agents in wireless sensor
networks (WSN) is studied. Below the formula simplifications, regarding the
known results and publications, it is shown that the basic agent model is
probabilistically equivalent to a similar simpler model and then a formula for
frequencies is achieved in terms of combinatorial second kind Stirling numbers.
Stirling numbers are well studied and different estimates are known for them
letting to justify the roving agents quantitative characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3347</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3347</id><created>2011-05-17</created><authors><author><keyname>Herrera</keyname><forenames>Carlos</forenames></author><author><keyname>Zufiria</keyname><forenames>Pedro J.</forenames></author></authors><title>Generating Scale-free Networks with Adjustable Clustering Coefficient
  Via Random Walks</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an algorithm for generating scale-free networks with
adjustable clustering coefficient. The algorithm is based on a random walk
procedure combined with a triangle generation scheme which takes into account
genetic factors; this way, preferential attachment and clustering control are
implemented using only local information. Simulations are presented which
support the validity of the scheme, characterizing its tuning capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3351</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3351</id><created>2011-05-17</created><authors><author><keyname>Mathieu</keyname><forenames>Chouchane</forenames></author><author><keyname>S&#xe9;bastien</keyname><forenames>Paris</forenames></author><author><keyname>Fran&#xe7;ois</keyname><forenames>Le Gland</forenames></author><author><keyname>Mustapha</keyname><forenames>Ouladsine</forenames></author></authors><title>Splitting method for spatio-temporal search efforts planning</title><categories>cs.NE cs.SY math.OC</categories><comments>Submitted to Automatica. 12 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article deals with the spatio-temporal sensors deployment in order to
maximize detection probability of an intelligent and randomly moving target in
an area under surveillance. Our work is based on the rare events simulation
framework. More precisely, we derive a novel stochastic optimization algorithm
based on the generalized splitting method. This new approach offers promising
results without any state-space discretization and can handle various types of
constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3368</identifier>
 <datestamp>2012-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3368</id><created>2011-05-17</created><updated>2012-10-16</updated><authors><author><keyname>Choure</keyname><forenames>Ayush</forenames></author><author><keyname>Vishwanathan</keyname><forenames>Sundar</forenames></author></authors><title>Random Walks, Electric Networks and The Transience Class problem of
  Sandpiles</title><categories>cs.DM cond-mat.other cs.SI math-ph math.MP</categories><comments>26 pages, 9 figures. arXiv admin note: text overlap with
  arXiv:1207.0421</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Abelian Sandpile Model is a discrete diffusion process defined on graphs
(Dhar \cite{DD90}, Dhar et al. \cite{DD95}) which serves as the standard model
of \textit{self-organized criticality}. The transience class of a sandpile is
defined as the maximum number of particles that can be added without making the
system recurrent (\cite{BT05}). We develop the theory of discrete diffusions in
contrast to continuous harmonic functions on graphs and establish deep
connections between standard results in the study of random walks on graphs and
sandpiles on graphs. Using this connection and building other necessary
machinery we improve the main result of Babai and Gorodezky (SODA
2007,\cite{LB07}) of the bound on the transience class of an $n \times n$ grid,
from $O(n^{30})$ to $O(n^{7})$. Proving that the transience class is small
validates the general notion that for most natural phenomenon, the time during
which the system is transient is small. In addition, we use the machinery
developed to prove a number of auxiliary results. We exhibit an equivalence
between two other tessellations of plane, the honeycomb and triangular
lattices. We give general upper bounds on the transience class as a function of
the number of edges to the sink.
  Further, for planar sandpiles we derive an explicit algebraic expression
which provably approximates the transience class of $G$ to within $O(|E(G)|)$.
This expression is based on the spectrum of the Laplacian of the dual of the
graph $G$. We also show a lower bound of $\Omega(n^{3})$ on the transience
class on the grid improving the obvious bound of $\Omega(n^{2})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3383</identifier>
 <datestamp>2013-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3383</id><created>2011-05-17</created><updated>2013-09-24</updated><authors><author><keyname>Sachdeva</keyname><forenames>Sushant</forenames></author><author><keyname>Tulsiani</keyname><forenames>Madhur</forenames></author></authors><title>Cuts in Cartesian Products of Graphs</title><categories>cs.DM math.CO</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The k-fold Cartesian product of a graph G is defined as a graph on k-tuples
of vertices, where two tuples are connected if they form an edge in one of the
positions and are equal in the rest. Starting with G as a single edge gives G^k
as a k-dimensional hypercube. We study the distributions of edges crossed by a
cut in G^k across the copies of G in different positions. This is a
generalization of the notion of influences for cuts on the hypercube.
  We show the analogues of results of Kahn, Kalai, and Linial (KKL Theorem
[KahnKL88]) and that of Friedgut (Friedgut's Junta theorem [Friedgut98]), for
the setting of Cartesian products of arbitrary graphs. Our proofs extend the
arguments of Rossignol [Rossignol06] and of Falik and Samorodnitsky [FalikS07],
to the case of arbitrary Cartesian products. We also extend the work on
studying isoperimetric constants for these graphs [HoudreT96, ChungT98] to the
value of semidefinite relaxations for edge-expansion. We connect the optimal
values of the relaxations for computing expansion, given by various
semidefinite hierarchies, for G and G^k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3388</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3388</id><created>2011-05-17</created><authors><author><keyname>Nguyenova-Stepanikova</keyname><forenames>Alice</forenames></author><author><keyname>Duong</keyname><forenames>Tran Ngoc</forenames></author></authors><title>The block cipher NSABC (public domain)</title><categories>cs.CR</categories><comments>22 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce NSABC/w -- Nice-Structured Algebraic Block Cipher using w-bit
word arithmetic, a 4w-bit analogous of Skipjack [NSA98] with 5w-bit key. The
Skipjack's internal 4-round Feistel structure is replaced with a w-bit, 2-round
cascade of a binary operation (x,z)\mapsto(x\boxdot z)\lll(w/2) that permutes a
text word x under control of a key word z. The operation \boxdot, similarly to
the multiplication in IDEA [LM91, LMM91], bases on an algebraic group over
w-bit words, so it is also capable of decrypting by means of the inverse
element of z in the group. The cipher utilizes a secret 4w-bit tweak -- an
easily changeable parameter with unique value for each block encrypted under
the same key [LRW02] -- that is derived from the block index and an additional
4w -bit key. A software implementation for w=64 takes circa 9 clock cycles per
byte on x86-64 processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3414</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3414</id><created>2011-05-16</created><authors><author><keyname>Liu</keyname><forenames>Guohua</forenames></author><author><keyname>You</keyname><forenames>Jia-Huai</forenames></author></authors><title>Relating Weight Constraint and Aggregate Programs: Semantics and
  Representation</title><categories>cs.LO cs.PL</categories><comments>To appear in Theory and Practice of Logic Programming (TPLP), 2011.
  30 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weight constraint and aggregate programs are among the most widely used logic
programs with constraints. In this paper, we relate the semantics of these two
classes of programs, namely the stable model semantics for weight constraint
programs and the answer set semantics based on conditional satisfaction for
aggregate programs. Both classes of programs are instances of logic programs
with constraints, and in particular, the answer set semantics for aggregate
programs can be applied to weight constraint programs. We show that the two
semantics are closely related. First, we show that for a broad class of weight
constraint programs, called strongly satisfiable programs, the two semantics
coincide. When they disagree, a stable model admitted by the stable model
semantics may be circularly justified. We show that the gap between the two
semantics can be closed by transforming a weight constraint program to a
strongly satisfiable one, so that no circular models may be generated under the
current implementation of the stable model semantics. We further demonstrate
the close relationship between the two semantics by formulating a
transformation from weight constraint programs to logic programs with nested
expressions which preserves the answer set semantics. Our study on the
semantics leads to an investigation of a methodological issue, namely the
possibility of compact representation of aggregate programs by weight
constraint programs. We show that almost all standard aggregates can be encoded
by weight constraints compactly. This makes it possible to compute the answer
sets of aggregate programs using the ASP solvers for weight constraint
programs. This approach is compared experimentally with the ones where
aggregates are handled more explicitly, which show that the weight constraint
encoding of aggregates enables a competitive approach to answer set computation
for aggregate programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3416</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3416</id><created>2011-05-17</created><authors><author><keyname>Lu</keyname><forenames>Lu</forenames></author><author><keyname>Wang</keyname><forenames>Taotao</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author></authors><title>Implementation of Physical-layer Network Coding</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the first implementation of a two-way relay network based
on the principle of physical-layer network coding. To date, only a simplified
version of physical-layer network coding (PNC) method, called analog network
coding (ANC), has been successfully implemented. The advantage of ANC is that
it is simple to implement; the disadvantage, on the other hand, is that the
relay amplifies the noise along with the signal before forwarding the signal.
PNC systems in which the relay performs XOR or other denoising PNC mappings of
the received signal have the potential for significantly better performance.
However, the implementation of such PNC systems poses many challenges. For
example, the relay must be able to deal with symbol and carrier-phase
asynchronies of the simultaneous signals received from the two end nodes, and
the relay must perform channel estimation before detecting the signals. We
investigate a PNC implementation in the frequency domain, referred to as FPNC,
to tackle these challenges. FPNC is based on OFDM. In FPNC, XOR mapping is
performed on the OFDM samples in each subcarrier rather than on the samples in
the time domain. We implement FPNC on the universal soft radio peripheral
(USRP) platform. Our implementation requires only moderate modifications of the
packet preamble design of 802.11a/g OFDM PHY. With the help of the cyclic
prefix (CP) in OFDM, symbol asynchrony and the multi-path fading effects can be
dealt with in a similar fashion. Our experimental results show that
symbol-synchronous and symbol-asynchronous FPNC have essentially the same BER
performance, for both channel-coded and unchannel-coded FPNC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3422</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3422</id><created>2011-05-17</created><authors><author><keyname>Acar</keyname><forenames>Evrim</forenames></author><author><keyname>Kolda</keyname><forenames>Tamara G.</forenames></author><author><keyname>Dunlavy</keyname><forenames>Daniel M.</forenames></author></authors><title>All-at-once Optimization for Coupled Matrix and Tensor Factorizations</title><categories>math.NA cs.NA physics.data-an stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint analysis of data from multiple sources has the potential to improve our
understanding of the underlying structures in complex data sets. For instance,
in restaurant recommendation systems, recommendations can be based on rating
histories of customers. In addition to rating histories, customers' social
networks (e.g., Facebook friendships) and restaurant categories information
(e.g., Thai or Italian) can also be used to make better recommendations. The
task of fusing data, however, is challenging since data sets can be incomplete
and heterogeneous, i.e., data consist of both matrices, e.g., the person by
person social network matrix or the restaurant by category matrix, and
higher-order tensors, e.g., the &quot;ratings&quot; tensor of the form restaurant by meal
by person.
  In this paper, we are particularly interested in fusing data sets with the
goal of capturing their underlying latent structures. We formulate this problem
as a coupled matrix and tensor factorization (CMTF) problem where heterogeneous
data sets are modeled by fitting outer-product models to higher-order tensors
and matrices in a coupled manner. Unlike traditional approaches solving this
problem using alternating algorithms, we propose an all-at-once optimization
approach called CMTF-OPT (CMTF-OPTimization), which is a gradient-based
optimization approach for joint analysis of matrices and higher-order tensors.
We also extend the algorithm to handle coupled incomplete data sets. Using
numerical experiments, we demonstrate that the proposed all-at-once approach is
more accurate than the alternating least squares approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3424</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3424</id><created>2011-05-17</created><authors><author><keyname>Karrer</keyname><forenames>Brian</forenames></author><author><keyname>Newman</keyname><forenames>M. E. J.</forenames></author></authors><title>Competing epidemics on complex networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>14 pages, 5 figures</comments><journal-ref>Phys. Rev. E 84, 036106 (2011)</journal-ref><doi>10.1103/PhysRevE.84.036106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human diseases spread over networks of contacts between individuals and a
substantial body of recent research has focused on the dynamics of the
spreading process. Here we examine a model of two competing diseases spreading
over the same network at the same time, where infection with either disease
gives an individual subsequent immunity to both. Using a combination of
analytic and numerical methods, we derive the phase diagram of the system and
estimates of the expected final numbers of individuals infected with each
disease. The system shows an unusual dynamical transition between dominance of
one disease and dominance of the other as a function of their relative rates of
growth. Close to this transition the final outcomes show strong dependence on
stochastic fluctuations in the early stages of growth, dependence that
decreases with increasing network size, but does so sufficiently slowly as
still to be easily visible in systems with millions or billions of individuals.
In most regions of the phase diagram we find that one disease eventually
dominates while the other reaches only a vanishing fraction of the network, but
the system also displays a significant coexistence regime in which both
diseases reach epidemic proportions and infect an extensive fraction of the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3425</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3425</id><created>2011-05-17</created><authors><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author><author><keyname>Sudan</keyname><forenames>Madhu</forenames></author></authors><title>Delays and the Capacity of Continuous-time Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Any physical channel of communication offers two potential reasons why its
capacity (the number of bits it can transmit in a unit of time) might be
unbounded: (1) Infinitely many choices of signal strength at any given instant
of time, and (2) Infinitely many instances of time at which signals may be
sent. However channel noise cancels out the potential unboundedness of the
first aspect, leaving typical channels with only a finite capacity per instant
of time. The latter source of infinity seems less studied. A potential source
of unreliability that might restrict the capacity also from the second aspect
is delay: Signals transmitted by the sender at a given point of time may not be
received with a predictable delay at the receiving end. Here we examine this
source of uncertainty by considering a simple discrete model of delay errors.
In our model the communicating parties get to subdivide time as microscopically
finely as they wish, but still have to cope with communication delays that are
macroscopic and variable. The continuous process becomes the limit of our
process as the time subdivision becomes infinitesimal. We taxonomize this class
of communication channels based on whether the delays and noise are stochastic
or adversarial; and based on how much information each aspect has about the
other when introducing its errors. We analyze the limits of such channels and
reach somewhat surprising conclusions: The capacity of a physical channel is
finitely bounded only if at least one of the two sources of error (signal noise
or delay noise) is adversarial. In particular the capacity is finitely bounded
only if the delay is adversarial, or the noise is adversarial and acts with
knowledge of the stochastic delay. If both error sources are stochastic, or if
the noise is adversarial and independent of the stochastic delay, then the
capacity of the associated physical channel is infinite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3427</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3427</id><created>2011-05-17</created><authors><author><keyname>Quoc</keyname><forenames>Tran Dinh</forenames></author><author><keyname>Savorgnan</keyname><forenames>Carlo</forenames></author><author><keyname>Diehl</keyname><forenames>Moritz</forenames></author></authors><title>Real-Time Sequential Convex Programming for Optimal Control Applications</title><categories>math.OC cs.SY</categories><comments>10 pages, 3 figures, HPSC2009 conference paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes real-time sequential convex programming (RTSCP), a method
for solving a sequence of nonlinear optimization problems depending on an
online parameter. We provide a contraction estimate for the proposed method
and, as a byproduct, a new proof of the local convergence of sequential convex
programming. The approach is illustrated by an example where RTSCP is applied
to nonlinear model predictive control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3435</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3435</id><created>2011-05-17</created><authors><author><keyname>Abrego</keyname><forenames>Bernardo M.</forenames></author><author><keyname>Cetina</keyname><forenames>Mario</forenames></author><author><keyname>Leanos</keyname><forenames>Jesus</forenames></author><author><keyname>Salazar</keyname><forenames>Gelasio</forenames></author></authors><title>Visibility-preserving convexifications using single-vertex moves</title><categories>cs.CG cs.RO math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Devadoss asked: (1) can every polygon be convexified so that no internal
visibility (between vertices) is lost in the process? Moreover, (2) does such a
convexification exist, in which exactly one vertex is moved at a time (that is,
using {\em single-vertex moves})? We prove the redundancy of the &quot;single-vertex
moves&quot; condition: an affirmative answer to (1) implies an affirmative answer to
(2). Since Aichholzer et al. recently proved (1), this settles (2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3448</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3448</id><created>2011-05-17</created><authors><author><keyname>Vabishchevich</keyname><forenames>Petr N.</forenames></author></authors><title>Substructuring domain decomposition scheme for unsteady problems</title><categories>cs.NA</categories><msc-class>65N06, 65M06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domain decomposition methods are used for approximate solving boundary
problems for partial differential equations on parallel computing systems.
Specific features of unsteady problems are taken into account in the most
complete way in iteration-free schemes of domain decomposition.
Regionally-additive schemes are based on different classes of splitting
schemes. In this paper we highlight a class of domain decomposition schemes
which is based on the partition of the initial domain into subdomains with
common boundary nodes. Using the partition of unit we have constructed and
studied unconditionally stable schemes of domain decomposition based on
two-component splitting: the problem within subdomain and the problem at their
boundaries. As an example there is considered the Cauchy problem for
evolutionary equations of first and second order with non-negative self-adjoint
operator in a finite Hilbert space. The theoretical consideration is
supplemented with numerical solving a model problem for the two-dimensional
parabolic equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3454</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3454</id><created>2011-05-17</created><authors><author><keyname>Duchier</keyname><forenames>Denys</forenames></author><author><keyname>Durand-Lose</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Senot</keyname><forenames>Maxime</forenames></author></authors><title>Computing in the fractal cloud: modular generic solvers for SAT and
  Q-SAT variants</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Abstract geometrical computation can solve hard combinatorial problems
efficiently: we showed previously how Q-SAT can be solved in bounded space and
time using instance-specific signal machines and fractal parallelization. In
this article, we propose an approach for constructing a particular generic
machine for the same task. This machine deploies the Map/Reduce paradigm over a
fractal structure. Moreover our approach is modular: the machine is constructed
by combining modules. In this manner, we can easily create generic machines for
solving satifiability variants, such as SAT, #SAT, MAX-SAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3459</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3459</id><created>2011-05-17</created><authors><author><keyname>Sanderson</keyname><forenames>Robert</forenames></author><author><keyname>Phillips</keyname><forenames>Mark</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>Analyzing the Persistence of Referenced Web Resources with Memento</title><categories>cs.DL</categories><comments>4 pages, 5 figures. Accepted to Open Repositories 2011 Conference</comments><acm-class>H.5.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we present the results of a study into the persistence and
availability of web resources referenced from papers in scholarly repositories.
Two repositories with different characteristics, arXiv and the UNT digital
library, are studied to determine if the nature of the repository, or of its
content, has a bearing on the availability of the web resources cited by that
content. Memento makes it possible to automate discovery of archived resources
and to consider the time between the publication of the research and the
archiving of the referenced URLs. This automation allows us to process more
than 160000 URLs, the largest known such study, and the repository metadata
allows consideration of the results by discipline. The results are startling:
45% (66096) of the URLs referenced from arXiv still exist, but are not
preserved for future generations, and 28% of resources referenced by UNT papers
have been lost. Moving forwards, we provide some initial recommendations,
including that repositories should publish URL lists extracted from papers that
could be used as seeds for web archiving systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3469</identifier>
 <datestamp>2011-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3469</id><created>2011-05-15</created><authors><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author></authors><title>Book review: Katy B\&quot;orner, Atlas of Science: Visualizing What We Know.
  Cambridge, MA/ London UK: The MIT Press, 2010</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Katy B\&quot;orner has written a wonderful book about visualization that makes our
field of scientometrics accessible to much larger audiences. The book is to be
read in relation to the ongoing series of exhibitions entitled &quot;Places &amp;
Spaces: Mapping Science&quot; currently touring the world. The book also provides
the scholarly background to the exhibitions. It celebrates scientometrics as
the discipline in the background that enables us to visualize the evolution of
knowledge as the acumen of human civilization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3486</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3486</id><created>2011-05-17</created><authors><author><keyname>B&#xf6;l&#xf6;ni</keyname><forenames>Ladislau</forenames></author></authors><title>Xapagy: a cognitive architecture for narrative reasoning</title><categories>cs.AI</categories><msc-class>68T01</msc-class><acm-class>I.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the Xapagy cognitive architecture: a software system designed to
perform narrative reasoning. The architecture has been designed from scratch to
model and mimic the activities performed by humans when witnessing, reading,
recalling, narrating and talking about stories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3531</identifier>
 <datestamp>2011-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3531</id><created>2011-05-18</created><updated>2011-12-11</updated><authors><author><keyname>Scarlett</keyname><forenames>Jonathan</forenames></author><author><keyname>Evans</keyname><forenames>Jamie</forenames></author><author><keyname>Dey</keyname><forenames>Subhrakanti</forenames></author></authors><title>On the Tradeoff Between Multiuser Diversity and Training Overhead in
  Multiple Access Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a single antenna narrowband multiple access channel in which
users send training sequences to the base station and scheduling is performed
based on minimum mean square error (MMSE) channel estimates. In such a system,
there is an inherent tradeoff between training overhead and the amount of
multiuser diversity achieved. We analyze a block fading channel with
independent Rayleigh distributed channel gains, where the parameters to be
optimized are the number of users considered for transmission in each block and
the corresponding time and power spent on training by each user. We derive
closed form expressions for the optimal parameters in terms K and L, where K is
the number of users considered for transmission in each block and L is the
block length in symbols. Considering the behavior of the system as L grows
large, we optimize K with respect to an approximate expression for the
achievable rate, and obtain second order expressions for the resulting
parameters in terms of L.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3538</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3538</id><created>2011-05-18</created><authors><author><keyname>Wright</keyname><forenames>Alden H.</forenames></author></authors><title>The Exact Schema Theorem</title><categories>cs.NE</categories><comments>This paper was written in 1999 and never published except on the
  author's website. The version here is unchanged from the version of January
  28, 2000 except for formatting, the author's e-mail and website URL, and the
  addition of a comment similar to this comment</comments><acm-class>I.2.8</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  A schema is a naturally defined subset of the space of fixed-length binary
strings. The Holland Schema Theorem gives a lower bound on the expected
fraction of a population in a schema after one generation of a simple genetic
algorithm. This paper gives formulas for the exact expected fraction of a
population in a schema after one generation of the simple genetic algorithm.
Holland's schema theorem has three parts, one for selection, one for crossover,
and one for mutation. The selection part is exact, whereas the crossover and
mutation parts are approximations. This paper shows how the crossover and
mutation parts can be made exact. Holland's schema theorem follows naturally as
a corollary. There is a close relationship between schemata and the
representation of the population in the Walsh basis. This relationship is used
in the derivation of the results, and can also make computation of the schema
averages more efficient. This paper gives a version of the Vose infinite
population model where crossover and mutation are separated into two functions
rather than a single &quot;mixing&quot; function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3559</identifier>
 <datestamp>2011-07-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3559</id><created>2011-05-18</created><updated>2011-07-13</updated><authors><author><keyname>Gonzalez-Diaz</keyname><forenames>Rocio</forenames></author><author><keyname>Ion</keyname><forenames>Adrian</forenames></author><author><keyname>Iglesias-Ham</keyname><forenames>Mabel</forenames></author><author><keyname>Kropatsch</keyname><forenames>Walter G.</forenames></author></authors><title>Invariant Representative Cocycles of Cohomology Generators using
  Irregular Graph Pyramids</title><categories>cs.CV</categories><comments>Special issue on Graph-Based Representations in Computer Vision</comments><journal-ref>Computer Vision and Image Understanding, Volume 115, Issue 7, July
  2011, Pages 1011-1022</journal-ref><doi>10.1016/j.cviu.2010.12.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Structural pattern recognition describes and classifies data based on the
relationships of features and parts. Topological invariants, like the Euler
number, characterize the structure of objects of any dimension. Cohomology can
provide more refined algebraic invariants to a topological space than does
homology. It assigns `quantities' to the chains used in homology to
characterize holes of any dimension. Graph pyramids can be used to describe
subdivisions of the same object at multiple levels of detail. This paper
presents cohomology in the context of structural pattern recognition and
introduces an algorithm to efficiently compute representative cocycles (the
basic elements of cohomology) in 2D using a graph pyramid. An extension to
obtain scanning and rotation invariant cocycles is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3565</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3565</id><created>2011-05-18</created><updated>2013-05-16</updated><authors><author><keyname>Bytev</keyname><forenames>Vladimir V.</forenames><affiliation>Dubna, JINR</affiliation></author><author><keyname>Kalmykov</keyname><forenames>Mikhail Yu.</forenames><affiliation>Hamburg U., Inst. Theor. Phys. II and Dubna, JINR</affiliation></author><author><keyname>Kniehl</keyname><forenames>Bernd A.</forenames><affiliation>Hamburg U., Inst. Theor. Phys. II</affiliation></author></authors><title>HYPERDIRE: HYPERgeometric functions DIfferential REduction: MATHEMATICA
  based packages for differential reduction of generalized hypergeometric
  functions pFq, F1,F2,F3,F4</title><categories>math-ph cs.SC hep-ph hep-th math.CA math.MP</categories><comments>28 pages, accepted for publication in Computer Physics Communications</comments><report-no>DESY-13-071</report-no><journal-ref>Comput.Phys. Commun. 184 (2013) 2332-2342</journal-ref><doi>10.1016/j.cpc.2013.05.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  HYPERDIRE is a project devoted to the creation of a set of Mathematica based
programs for the differential reduction of hypergeometric functions. The
current version includes two parts: one, pfq, is relevant for manipulations of
hypergeometric functions_{p+1}F_p, and the second one, AppellF1F4, for
manipulations with Appell hypergeometric functions F_1,F_2,F_3,F_4 of two
variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3569</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3569</id><created>2011-05-18</created><authors><author><keyname>Vehkalahti</keyname><forenames>Roope</forenames></author><author><keyname>Lu</keyname><forenames>Hsiao-feng</forenames></author></authors><title>Diversity-multiplexing Gain Tradeoff: a Tool in Algebra?</title><categories>cs.IT math.IT</categories><comments>A preprint version of the paper submitted to 2011 IEEE Information
  Theory Workshop (ITW 2011), Paraty, Brazil</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the invention of space-time coding numerous algebraic methods have been
applied in code design.
  In particular algebraic number theory and central simple algebras have been
on the forefront of the research.
  In this paper we are turning the table and asking whether information theory
can be used as a tool in algebra. We will first derive some corollaries from
diversity-multiplexing gain (DMT) bounds by Zheng and Tse and later show how
these results can be used to analyze the unit group of orders of certain
division algebras. The authors do not claim that the algebraic results are new,
but we do find that this interesting relation between algebra and information
theory is quite surprising and worth pointing out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3574</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3574</id><created>2011-05-18</created><updated>2012-11-23</updated><authors><author><keyname>D'Agostino</keyname><forenames>Gregorio</forenames></author><author><keyname>Scala</keyname><forenames>Antonio</forenames></author><author><keyname>Zlati&#x107;</keyname><forenames>Vinko</forenames></author><author><keyname>Caldarelli</keyname><forenames>Guido</forenames></author></authors><title>Robustness and Assortativity for Diffusion-like Processes in Scale-free
  Networks</title><categories>physics.soc-ph cond-mat.dis-nn cond-mat.stat-mech cs.SI</categories><comments>4 pages, 4 figures</comments><journal-ref>European Physics Letters, Vol. 97, No. 6 (March 2012) 68006</journal-ref><doi>10.1209/0295-5075/97/68006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By analysing the diffusive dynamics of epidemics and of distress in complex
networks, we study the effect of the assortativity on the robustness of the
networks. We first determine by spectral analysis the thresholds above which
epidemics/failures can spread; we then calculate the slowest diffusional times.
Our results shows that disassortative networks exhibit a higher epidemiological
threshold and are therefore easier to immunize, while in assortative networks
there is a longer time for intervention before epidemic/failure spreads.
Moreover, we study by computer simulations the sandpile cascade model, a
diffusive model of distress propagation (financial contagion). We show that,
while assortative networks are more prone to the propagation of
epidemic/failures, degree-targeted immunization policies increases their
resilience to systemic risk.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3583</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3583</id><created>2011-05-18</created><updated>2011-06-27</updated><authors><author><keyname>Kazana</keyname><forenames>Wojciech</forenames><affiliation>INRIA</affiliation></author><author><keyname>Segoufin</keyname><forenames>Luc</forenames><affiliation>INRIA</affiliation></author></authors><title>First-order query evaluation on structures of bounded degree</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, F.1.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (June 29,
  2011) lmcs:903</journal-ref><doi>10.2168/LMCS-7(2:20)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the enumeration problem of first-order queries over structures of
bounded degree. It was shown that this problem is in the Constant-Delaylin
class. An enumeration problem belongs to Constant-Delaylin if for an input of
size n it can be solved by: - an O(n) precomputation phase building an index
structure, - followed by a phase enumerating the answers with no repetition and
a constant delay between two consecutive outputs. In this article we give a
different proof of this result based on Gaifman's locality theorem for
first-order logic. Moreover, the constants we obtain yield a total evaluation
time that is triply exponential in the size of the input formula, matching the
complexity of the best known evaluation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3617</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3617</id><created>2011-05-18</created><authors><author><keyname>Dutta</keyname><forenames>Abhishek</forenames></author></authors><title>Face Shape and Reflectance Acquisition using a Multispectral Light Stage</title><categories>cs.CV cs.GR</categories><comments>MSc thesis submitted for the degree of Master of Science (M.Sc.) to
  Department of Computer Science (University of York, UK) on Oct. 26, 2010</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this thesis, we discuss the design and calibration (geometric and
radiometric) of a novel shape and reflectance acquisition device called the
&quot;Multispectral Light Stage&quot;. This device can capture highly detailed facial
geometry (down to the level of skin pores detail) and Multispectral reflectance
map which can be used to estimate biophysical skin parameters such as the
distribution of pigmentation and blood beneath the surface of the skin. We
extend the analysis of the original spherical gradient photometric stereo
method to study the effects of deformed diffuse lobes on the quality of
recovered surface normals. Based on our modified radiance equations, we develop
a minimal image set method to recover high quality photometric normals using
only four, instead of six, spherical gradient images. Using the same radiance
equations, we explore a Quadratic Programming (QP) based algorithm for
correction of surface normals obtained using spherical gradient photometric
stereo. Based on the proposed minimal image sets method, we present a
performance capture sequence that significantly reduces the data capture
requirement and post-processing computational cost of existing photometric
stereo based performance geometry capture methods. Furthermore, we explore the
use of images captured in our Light Stage to generate stimuli images for a
psychology experiment exploring the neural representation of 3D shape and
texture of a human face.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3620</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3620</id><created>2011-05-18</created><updated>2011-05-20</updated><authors><author><keyname>Gonzalez-Diaz</keyname><forenames>Rocio</forenames></author><author><keyname>Jimenez</keyname><forenames>Maria Jose</forenames></author><author><keyname>Medrano</keyname><forenames>Belen</forenames></author><author><keyname>Real</keyname><forenames>Pedro</forenames></author></authors><title>Chain Homotopies for Object Topological Representations</title><categories>cs.DM</categories><journal-ref>Discrete Applied Mathematics, Volume 157, Issue 3, 2009, Pages
  490-499</journal-ref><doi>10.1016/j.dam.2008.05.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a set of tools to compute topological information of
simplicial complexes, tools that are applicable to extract topological
information from digital pictures. A simplicial complex is encoded in a
(non-unique) algebraic-topological format called AM-model. An AM-model for a
given object K is determined by a concrete chain homotopy and it provides, in
particular, integer (co)homology generators of K and representative (co)cycles
of these generators. An algorithm for computing an AM-model and the
cohomological invariant HB1 (derived from the rank of the cohomology ring) with
integer coefficients for a finite simplicial complex in any dimension is
designed here. A concept of generators which are &quot;nicely&quot; representative cycles
is also presented. Moreover, we extend the definition of AM-models to 3D binary
digital images and we design algorithms to update the AM-model information
after voxel set operations (union, intersection, difference and inverse).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3635</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3635</id><created>2011-05-18</created><authors><author><keyname>Garrido</keyname><forenames>M. C.</forenames></author><author><keyname>Lopez-de-Teruel</keyname><forenames>P. E.</forenames></author><author><keyname>Ruiz</keyname><forenames>A.</forenames></author></authors><title>Probabilistic Inference from Arbitrary Uncertainty using Mixtures of
  Factorized Generalized Gaussians</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  167-217, 1998</journal-ref><doi>10.1613/jair.533</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a general and efficient framework for probabilistic
inference and learning from arbitrary uncertain information. It exploits the
calculation properties of finite mixture models, conjugate families and
factorization. Both the joint probability density of the variables and the
likelihood function of the (objective or subjective) observation are
approximated by a special mixture model, in such a way that any desired
conditional distribution can be directly obtained without numerical
integration. We have developed an extended version of the expectation
maximization (EM) algorithm to estimate the parameters of mixture models from
uncertain training examples (indirect observations). As a consequence, any
piece of exact or uncertain information about both input and output values is
consistently handled in the inference and learning stages. This ability,
extremely useful in certain situations, is not found in most alternative
methods. The proposed framework is formally justified from standard
probabilistic principles and illustrative examples are provided in the fields
of nonparametric pattern classification, nonlinear regression and pattern
completion. Finally, experiments on a real application and comparative results
over standard databases provide empirical evidence of the utility of the method
in a wide range of applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3671</identifier>
 <datestamp>2012-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3671</id><created>2011-05-18</created><updated>2012-04-19</updated><authors><author><keyname>Kryczka</keyname><forenames>Michal</forenames></author><author><keyname>Cuevas</keyname><forenames>Ruben</forenames></author><author><keyname>Gonzalez</keyname><forenames>Roberto</forenames></author><author><keyname>Cuevas</keyname><forenames>Angel</forenames></author><author><keyname>Azcorra</keyname><forenames>Arturo</forenames></author></authors><title>TorrentGuard: stopping scam and malware distribution in the BitTorrent
  ecosystem</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we conduct a large scale measurement study in order to analyse
the fake content publishing phenomenon in the BitTorrent Ecosystem. Our results
reveal that fake content represents an important portion (35%) of those files
shared in BitTorrent and just a few tens of users are responsible for 90% of
this content. Furthermore, more than 99% of the analysed fake files are linked
to either malware or scam websites. This creates a serious threat for the
BitTorrent ecosystem. To address this issue, we present a new detection tool
named TorrentGuard for the early detection of fake content. Based on our
evaluation this tool may prevent the download of more than 35 millions of fake
files per year. This could help to reduce the number of computer infections and
scams suffered by BitTorrent users. TorrentGuard is already available and it
can be accessed through both a webpage or a Vuze plugin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3682</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3682</id><created>2011-05-18</created><authors><author><keyname>Gonzalez</keyname><forenames>Roberto</forenames></author><author><keyname>Cuevas</keyname><forenames>Ruben</forenames></author><author><keyname>Cuevas</keyname><forenames>Angel</forenames></author><author><keyname>Guerrero</keyname><forenames>Carmen</forenames></author></authors><title>Where are my followers? Understanding the Locality Effect in Twitter</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Twitter is one of the most used applications in the current Internet with
more than 200M accounts created so far. As other large-scale systems Twitter
can obtain enefit by exploiting the Locality effect existing among its users.
In this paper we perform the first comprehensive study of the Locality effect
of Twitter. For this purpose we have collected the geographical location of
around 1M Twitter users and 16M of their followers. Our results demonstrate
that language and cultural characteristics determine the level of Locality
expected for different countries. Those countries with a different language
than English such as Brazil typically show a high intra-country Locality
whereas those others where English is official or co-official language suffer
from an external Locality effect. This is, their users have a larger number of
followers in US than within their same country. This is produced by two
reasons: first, US is the dominant country in Twitter counting with around half
of the users, and second, these countries share a common language and cultural
characteristics with US.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3685</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3685</id><created>2011-05-18</created><authors><author><keyname>Godil</keyname><forenames>Afzal</forenames></author><author><keyname>Lian</keyname><forenames>Zhouhui</forenames></author><author><keyname>Dutagaci</keyname><forenames>Helin</forenames></author><author><keyname>Fang</keyname><forenames>Rui</forenames></author><author><keyname>P.</keyname><forenames>Vanamali T.</forenames></author><author><keyname>Cheung</keyname><forenames>Chun Pan</forenames></author></authors><title>Benchmarks, Performance Evaluation and Contests for 3D Shape Retrieval</title><categories>cs.CV cs.CG</categories><comments>Performance Metrics for Intelligent Systems (PerMIS'10) Workshop,
  September, 2010</comments><acm-class>I.2.10; I.4.8; I.5.4</acm-class><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Benchmarking of 3D Shape retrieval allows developers and researchers to
compare the strengths of different algorithms on a standard dataset. Here we
describe the procedures involved in developing a benchmark and issues involved.
We then discuss some of the current 3D shape retrieval benchmarks efforts of
our group and others. We also review the different performance evaluation
measures that are developed and used by researchers in the community. After
that we give an overview of the 3D shape retrieval contest (SHREC) tracks run
under the EuroGraphics Workshop on 3D Object Retrieval and give details of
tracks that we organized for SHREC 2010. Finally we demonstrate some of the
results based on the different SHREC contest tracks and the NIST shape
benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3686</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3686</id><created>2011-05-18</created><authors><author><keyname>Xu</keyname><forenames>Jiaming</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Broadcast Channels with Delayed Finite-Rate Feedback: Predict or
  Observe?</title><categories>cs.IT math.IT</categories><comments>25 pages, 4 figures, submitted to IEEE Transactions on Wireless
  Communications, May 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most multiuser precoding techniques require accurate transmitter channel
state information (CSIT) to maintain orthogonality between the users. Such
techniques have proven quite fragile in time-varying channels because the CSIT
is inherently imperfect due to estimation and feedback delay, as well
quantization noise. An alternative approach recently proposed by Maddah-Ali and
Tse (MAT) allows for significant multiplexing gain in the multi-input
single-output (MISO) broadcast channel (BC) even with transmit CSIT that is
completely stale, i.e. uncorrelated with the current channel state. With $K$
users, their scheme claims to lose only a $\log(K)$ factor relative to the full
$K$ degrees of freedom (DoF) attainable in the MISO BC with perfect CSIT for
large $K$. However, their result does not consider the cost of the feedback,
which is potentially very large in high mobility (short channel coherence
time). In this paper, we more closely examine the MAT scheme and compare its
DoF gain to single user transmission (which always achieves 1 DoF) and partial
CSIT linear precoding (which achieves up to $K$). In particular, assuming the
channel coherence time is $N$ symbol periods and the feedback delay is $N_{\rm
fd}$ we show that when $N &lt; (1+o(1)) K \log K$ (short coherence time), single
user transmission performs best, whereas for $N&gt; (1+o(1)) (N_{\rm fd}+ K / \log
K)(1-\log^{-1}K)^{-1}$ (long coherence time), zero-forcing precoding
outperforms the other two. The MAT scheme is optimal for intermediate coherence
times, which for practical parameter choices is indeed quite a large and
significant range, even accounting for the feedback cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3715</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3715</id><created>2011-05-18</created><authors><author><keyname>Alcantara</keyname><forenames>Carlos Augusto Almeida</forenames></author><author><keyname>Vieira</keyname><forenames>Anderson Luiz Nogueira</forenames></author></authors><title>Tecnologia M\'ovel: Uma Tend\^encia, Uma Realidade</title><categories>cs.CY</categories><comments>Artigo defendido no II Workshop de Redes na Universidade Est\'acio de
  S\'a, Juiz de Fora, MG, Brasil</comments><journal-ref>PEREZ, Marin, Grande Crescimento para o Com\'ercio M\'ovel,
  InformationWeek EUA -- 2009. Praestro Convergence - ebook Mobile Marketing:
  Mobile Marketing: Conceitos, Tecnologias e Cases, 2009</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Currently, mobility presents itself as a major innovation in historic
technological revolution. From the first decade of this century, nothing
compares to what happened in the field of Information Technology (IT), which is
adding to market a range of news relating to infrastructure such as mobile
computing hardware, software, computer networks, etc.. From a handheld as a
wireless device, iPad, Smartphone, you can connect to the digital world,
people, customers, business partners, etc.. Given the infinite range of
information, services and resources available in the electronic world, it is
considered that few are those, markets and people who want to be left behind.
The interest in this channel of communication becomes not only a new strategy
of marketing and communications. Mobile devices are becoming more sophisticated
and allows access to the web. Thinking in this context is that manufacturers of
electronic components face each other in a war over the disputed technology to
a competitive environment that is open to those who put on the market the
product more attractive, interactive and versatile.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3716</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3716</id><created>2011-05-18</created><authors><author><keyname>Barbera</keyname><forenames>Marco Valerio</forenames></author><author><keyname>Mei</keyname><forenames>Alessandro</forenames></author></authors><title>Personal Marks and Community Certificates: Detecting Clones in Mobile
  Wireless Networks of Smart-Phones</title><categories>cs.CR</categories><comments>12 pages, 22 figures</comments><acm-class>H.4; D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of detecting clones in wireless mobile adhoc
networks. We assume that one of the devices of the network has been cloned.
Everything, including certificates and secret keys. This can happen quite
easily, because of a virus that immediately after sending all the content of
the infected device to the adversary destroys itself, or just because the owner
has left his device unattended for a few minutes in a hostile environment. The
problem is to detect this attack. We propose a solution in networks of mobile
devices carried by individuals. These networks are composed by nodes that have
the capability of using short-range communication technology like blue-tooth or
Wi-Fi, where nodes are carried by mobile users, and where links appear and
disappear according to the social relationships between the users. Our idea is
to use social physical contacts, securely collected by wireless personal
smart-phones, as a biometric way to authenticate the legitimate owner of the
device and detect the clone attack. We introduce two mechanisms: Personal Marks
and Community Certificates. Personal Marks is a simple cryptographic protocol
that works very well when the adversary is an insider, a malicious node in the
network that is part, or not very far, from the social community of the
original device that has been cloned. Community Certificates work very well
when the adversary is an outsider, a node that has the goal of using the stolen
credentials when interacting with other nodes that are far in the social
network from the original device. When combined, these mechanisms provide an
excellent protection against this very strong attack. We prove our ideas and
solutions with extensive simulations in a real world scenario-with mobility
traces collected in a real life experiment
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3723</identifier>
 <datestamp>2011-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3723</id><created>2011-05-18</created><authors><author><keyname>Jensen</keyname><forenames>Tobias Lindstr&#xf8;m</forenames></author><author><keyname>J&#xf8;rgensen</keyname><forenames>Jakob Heide</forenames></author><author><keyname>Hansen</keyname><forenames>Per Christian</forenames></author><author><keyname>Jensen</keyname><forenames>S&#xf8;ren Holdt</forenames></author></authors><title>Implementation of an Optimal First-Order Method for Strongly Convex
  Total Variation Regularization</title><categories>math.NA cs.NA math.OC</categories><comments>23 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a practical implementation of an optimal first-order method, due
to Nesterov, for large-scale total variation regularization in tomographic
reconstruction, image deblurring, etc. The algorithm applies to $\mu$-strongly
convex objective functions with $L$-Lipschitz continuous gradient. In the
framework of Nesterov both $\mu$ and $L$ are assumed known -- an assumption
that is seldom satisfied in practice. We propose to incorporate mechanisms to
estimate locally sufficient $\mu$ and $L$ during the iterations. The mechanisms
also allow for the application to non-strongly convex functions. We discuss the
iteration complexity of several first-order methods, including the proposed
algorithm, and we use a 3D tomography problem to compare the performance of
these methods. The results show that for ill-conditioned problems solved to
high accuracy, the proposed method significantly outperforms state-of-the-art
first-order methods, as also suggested by theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3726</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3726</id><created>2011-05-18</created><authors><author><keyname>Cornelius</keyname><forenames>Sean P.</forenames></author><author><keyname>Kath</keyname><forenames>William L.</forenames></author><author><keyname>Motter</keyname><forenames>Adilson E.</forenames></author></authors><title>Controlling Complex Networks with Compensatory Perturbations</title><categories>q-bio.MN cond-mat.dis-nn cs.SI nlin.CD physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The response of complex networks to perturbations is of utmost importance in
areas as diverse as ecosystem management, emergency response, and cell
reprogramming. A fundamental property of networks is that the perturbation of
one node can affect other nodes, in a process that may cause the entire or
substantial part of the system to change behavior and possibly collapse. Recent
research in metabolic and food-web networks has demonstrated the concept that
network damage caused by external perturbations can often be mitigated or
reversed by the application of compensatory perturbations. Compensatory
perturbations are constrained to be physically admissible and amenable to
implementation on the network. However, the systematic identification of
compensatory perturbations that conform to these constraints remains an open
problem. Here, we present a method to construct compensatory perturbations that
can control the fate of general networks under such constraints. Our approach
accounts for the full nonlinear behavior of real complex networks and can bring
the system to a desirable target state even when this state is not directly
accessible. Applications to genetic networks show that compensatory
perturbations are effective even when limited to a small fraction of all nodes
in the network and that they are far more effective when limited to the
highest-degree nodes. The approach is conceptually simple and computationally
efficient, making it suitable for the rescue, control, and reprogramming of
large complex networks in various domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3748</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3748</id><created>2011-05-18</created><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Ravishankar</forenames></author><author><keyname>Pruhs</keyname><forenames>Kirk</forenames></author></authors><title>Scalably Scheduling Power-Heterogeneous Processors</title><categories>cs.DS</categories><comments>A preliminary version appeared in ICALP 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that a natural online algorithm for scheduling jobs on a
heterogeneous multiprocessor, with arbitrary power functions, is scalable for
the objective function of weighted flow plus energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3770</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3770</id><created>2011-05-18</created><authors><author><keyname>Peres</keyname><forenames>Yuval</forenames></author><author><keyname>Sotnikov</keyname><forenames>Dimitry</forenames></author><author><keyname>Sudakov</keyname><forenames>Benny</forenames></author><author><keyname>Zwick</keyname><forenames>Uri</forenames></author></authors><title>All-Pairs Shortest Paths in $O(n^2)$ time with high probability</title><categories>math.CO cs.DS math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an all-pairs shortest path algorithm whose running time on a
complete directed graph on $n$ vertices whose edge weights are chosen
independently and uniformly at random from $[0,1]$ is $O(n^2)$, in expectation
and with high probability. This resolves a long standing open problem. The
algorithm is a variant of the dynamic all-pairs shortest paths algorithm of
Demetrescu and Italiano. The analysis relies on a proof that the number of
\emph{locally shortest paths} in such randomly weighted graphs is $O(n^2)$, in
expectation and with high probability. We also present a dynamic version of the
algorithm that recomputes all shortest paths after a random edge update in
$O(\log^{2}n)$ expected time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3788</identifier>
 <datestamp>2013-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3788</id><created>2011-05-19</created><updated>2012-05-03</updated><authors><author><keyname>Tarraf</keyname><forenames>Danielle C.</forenames></author></authors><title>A Control-Oriented Notion of Finite State Approximation</title><categories>math.OC cs.SY</categories><comments>IEEE Transactions on Automatic Control, to appear</comments><journal-ref>IEEE Transactions on Automatic Control, vol.57, no.12,
  pp.3197-3202, December 2012</journal-ref><doi>10.1109/TAC.2012.2199180</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of approximating discrete-time plants with
finite-valued sensors and actu- ators by deterministic finite memory systems
for the purpose of certified-by-design controller synthesis. Building on ideas
from robust control, we propose a control-oriented notion of finite state
approximation for these systems, demonstrate its relevance to the control
synthesis problem, and discuss its key features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3790</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3790</id><created>2011-05-19</created><authors><author><keyname>Lu</keyname><forenames>Jun-Chao</forenames></author><author><keyname>Chen</keyname><forenames>Yu-Yi</forenames></author><author><keyname>Qiu</keyname><forenames>Zhen-Jie</forenames></author><author><keyname>Jan</keyname><forenames>Jinn-Ke</forenames></author></authors><title>A Secure RFID Deactivation/Activation Mechanism for Supporting Customer
  Service and Consumer Shopping</title><categories>cs.CR</categories><comments>submitting to computer communication (COMCOM) at 2010.12.28</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  RFID has been regarded as a time and money-saving solution for a wide variety
of applications, such as manufacturing, supply chain management, and inventory
control, etc. However, there are some security problems on RFID in the product
managements. The most concerned issues are the tracking and the location
privacy. Numerous scholars tried to solve these problems, but their proposals
do not include the after-sales service. In this paper, we propose a purchase
and after-sales service RFID scheme for shopping mall. The location privacy,
confidentiality, data integrity, and some security protection are hold in this
propose mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3793</identifier>
 <datestamp>2012-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3793</id><created>2011-05-19</created><updated>2012-09-29</updated><authors><author><keyname>Shany</keyname><forenames>Yaron</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author></authors><title>A lower bound on the average entropy of a function determined up to a
  diagonal linear map on F_q^n</title><categories>math.CO cs.IT math.IT</categories><comments>second version with a considerably simplified proof of the main
  theorem and additional references. 6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, it is shown that if $f\colon\efq^n\to\efq^n$ is any function
and $\bA=(A_1,..., A_n)$ is uniformly distributed over $\efq^n$, then the
average over $(k_1,...,k_n)\in \efq^n$ of the Renyi (and hence, of the Shannon)
entropy of $f(\bA)+(k_1A_1,...,k_nA_n)$ is at least about $\log_2(q^n)-n$. In
fact, it is shown that the average collision probability of
$f(\bA)+(k_1A_1,...,k_nA_n)$ is at most about $2^n/q^n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3821</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3821</id><created>2011-05-19</created><authors><author><keyname>de Blanc</keyname><forenames>Peter</forenames></author></authors><title>Ontological Crises in Artificial Agents' Value Systems</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decision-theoretic agents predict and evaluate the results of their actions
using a model, or ontology, of their environment. An agent's goal, or utility
function, may also be specified in terms of the states of, or entities within,
its ontology. If the agent may upgrade or replace its ontology, it faces a
crisis: the agent's original goal may not be well-defined with respect to its
new ontology. This crisis must be resolved before the agent can make plans
towards achieving its goals.
  We discuss in this paper which sorts of agents will undergo ontological
crises and why we may want to create such agents. We present some concrete
examples, and argue that a well-defined procedure for resolving ontological
crises is needed. We point to some possible approaches to solving this problem,
and evaluate these methods on our examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3828</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3828</id><created>2011-05-19</created><updated>2013-02-02</updated><authors><author><keyname>Martyushev</keyname><forenames>Evgeniy</forenames></author></authors><title>An Algorithmic Solution to the Five-Point Pose Problem Based on the
  Cayley Representation of Rotations</title><categories>cs.CV</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new algorithmic solution to the well-known five-point relative pose
problem. Our approach does not deal with the famous cubic constraint on an
essential matrix. Instead, we use the Cayley representation of rotations in
order to obtain a polynomial system from epipolar constraints. Solving that
system, we directly get relative rotation and translation parameters of the
cameras in terms of roots of a 10th degree polynomial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3829</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3829</id><created>2011-05-19</created><updated>2012-01-16</updated><authors><author><keyname>Alekseychuk</keyname><forenames>Alexander</forenames></author></authors><title>Hierarchical Recursive Running Median</title><categories>cs.DS cs.CV</categories><comments>9 pages, 6 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To date, the histogram-based running median filter of Perreault and H\'ebert
is considered the fastest for 8-bit images, being roughly O(1) in average case.
We present here another approximately constant time algorithm which further
improves the aforementioned one and exhibits lower associated constant, being
at the time of writing the lowest theoretical complexity algorithm for
calculation of 2D and higher dimensional median filters. The algorithm scales
naturally to higher precision (e.g. 16-bit) integer data without any
modifications. Its adaptive version offers additional speed-up for images
showing compact modes in gray-value distribution. The experimental comparison
to the previous constant-time algorithm defines the application domain of this
new development, besides theoretical interest, as high bit depth data and/or
hardware without SIMD extensions. The C/C++ implementation of the algorithm is
available under GPL for research purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3833</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3833</id><created>2011-05-19</created><authors><author><keyname>Lozinskii</keyname><forenames>Eliezer L.</forenames></author></authors><title>Typical models: minimizing false beliefs</title><categories>cs.AI</categories><acm-class>I.2.3; F.4.1</acm-class><journal-ref>Journal of Experimental &amp; Theoretical Artificial Intelligence,
  vol. 22, no.4, December 2010, 321-340</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A knowledge system S describing a part of real world does in general not
contain complete information. Reasoning with incomplete information is prone to
errors since any belief derived from S may be false in the present state of the
world. A false belief may suggest wrong decisions and lead to harmful actions.
So an important goal is to make false beliefs as unlikely as possible. This
work introduces the notions of &quot;typical atoms&quot; and &quot;typical models&quot;, and shows
that reasoning with typical models minimizes the expected number of false
beliefs over all ways of using incomplete information. Various properties of
typical models are studied, in particular, correctness and stability of beliefs
suggested by typical models, and their connection to oblivious reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3834</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3834</id><created>2011-05-19</created><authors><author><keyname>Spadaccini</keyname><forenames>Andrea</forenames></author><author><keyname>Rizzo</keyname><forenames>Vanni</forenames></author></authors><title>A Multiple-Choice Test Recognition System based on the Gamera Framework</title><categories>cs.CV</categories><comments>11 pages, 4 figures</comments><journal-ref>C. Dalitz (Ed.): &quot;Document Image Analysis with the Gamera
  Framework.&quot; Schriftenreihe des Fachbereichs Elektrotechnik und Informatik,
  Hochschule Niederrhein, vol. 8, pp.5-15, Shaker Verlag (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article describes JECT-OMR, a system that analyzes digital images
representing scans of multiple-choice tests compiled by students. The system
performs a structural analysis of the document in order to get the chosen
answer for each question, and it also contains a bar-code decoder, used for the
identification of additional information encoded in the document. JECT-OMR was
implemented using the Python programming language, and leverages the power of
the Gamera framework in order to accomplish its task. The system exhibits an
accuracy of over 99% in the recognition of marked and non-marked squares
representing answers, thus making it suitable for real world applications
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3835</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3835</id><created>2011-05-19</created><authors><author><keyname>Chatzidiamantis</keyname><forenames>Nestor D.</forenames></author><author><keyname>Michalopoulos</keyname><forenames>Diomidis S.</forenames></author><author><keyname>Kriezis</keyname><forenames>Emmanouil E.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Protocols for Relay-Assisted Free-Space Optical Systems</title><categories>cs.IT math.IT</categories><comments>25 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate transmission protocols for relay-assisted free-space optical
(FSO) systems, when multiple parallel relays are employed and there is no
direct link between the source and the destination. As alternatives to
all-active FSO relaying, where all the available relays transmit concurrently,
we propose schemes that select only a single relay to participate in the
communication between the source and the destination in each transmission slot.
This selection is based on the channel state information (CSI) obtained either
from all or from some of the FSO links. Thus, the need for synchronizing the
relays' transmissions is avoided and the slowly varying nature of the
atmospheric channel is exploited. For both relay selection and all-active
relaying, novel closed-form expressions for their outage performance are
derived, assuming the versatile Gamma-Gamma channel model. Furthermore, based
on the derived analytical results, the problem of allocating the optical power
resources to the FSO links is addressed, and optimum and suboptimum solutions
are proposed. Numerical results are provided for equal and non-equal length FSO
links, which illustrate the outage behavior of the considered relaying
protocols and demonstrate the significant performance gains offered by the
proposed power allocation schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3843</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3843</id><created>2011-05-19</created><authors><author><keyname>Hanlon</keyname><forenames>James</forenames></author><author><keyname>Hollis</keyname><forenames>Simon J.</forenames></author></authors><title>Fast Distributed Process Creation with the XMOS XS1 Architecture</title><categories>cs.DC cs.PL</categories><comments>To appear in Communicating Process Architectures (CPA) 2011, 14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The provision of mechanisms for processor allocation in current distributed
parallel programming models is very limited. This makes difficult, or even
prohibits, the expression of a large class of programs which require a run-time
assessment of their required resources. This includes programs whose structure
is irregular, composite or unbounded. Efficient allocation of processors
requires a process creation mechanism able to initiate and terminate remote
computations quickly. This paper presents the design, demonstration and
analysis of an explicit mechanism to do this, implemented on the XMOS XS1
architecture, as a foundation for a more dynamic scheme. It shows that process
creation can be made efficient so that it incurs only a fractional overhead of
the total runtime and that it can be combined naturally with recursion to
enable rapid distribution of computations over a system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3853</identifier>
 <datestamp>2013-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3853</id><created>2011-05-19</created><updated>2012-09-19</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>The taming of recurrences in computability logic through cirquent
  calculus, Part I</title><categories>cs.LO math.LO</categories><msc-class>03B47, 03B70, 68Q10, 68T27, 68T15</msc-class><acm-class>F.1.1; F.1.2; F.1.3</acm-class><journal-ref>Archive for Mathematical Logic 52 (2013), pp. 173-212</journal-ref><doi>10.1007/s00153-012-0313-8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper constructs a cirquent calculus system and proves its soundness and
completeness with respect to the semantics of computability logic (see
http://www.cis.upenn.edu/~giorgi/cl.html). The logical vocabulary of the system
consists of negation, parallel conjunction, parallel disjunction, branching
recurrence, and branching corecurrence. The article is published in two parts,
with (the present) Part I containing preliminaries and a soundness proof, and
(the forthcoming) Part II containing a completeness proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3864</identifier>
 <datestamp>2011-07-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3864</id><created>2011-05-19</created><updated>2011-07-08</updated><authors><author><keyname>Amaxilatis</keyname><forenames>Dimitrios</forenames></author><author><keyname>Chatzigiannakis</keyname><forenames>Ioannis</forenames></author><author><keyname>Koninis</keyname><forenames>Christos</forenames></author><author><keyname>Pyrgelis</keyname><forenames>Apostolos</forenames></author></authors><title>Component Based Clustering in Wireless Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering is an important research topic for wireless sensor networks
(WSNs). A large variety of approaches has been presented focusing on different
performance metrics. Even though all of them have many practical applications,
an extremely limited number of software implementations is available to the
research community. Furthermore, these very few techniques are implemented for
specific WSN systems or are integrated in complex applications. Thus it is very
difficult to comparatively study their performance and almost impossible to
reuse them in future applications under a different scope. In this work we
study a large body of well established algorithms. We identify their main
building blocks and propose a component-based architecture for developing
clustering algorithms that (a) promotes exchangeability of algorithms thus
enabling the fast prototyping of new approaches, (b) allows cross-layer
implementations to realize complex applications, (c) offers a common platform
to comparatively study the performance of different approaches, (d) is hardware
and OS independent. We implement 5 well known algorithms and discuss how to
implement 11 more. We conduct an extended simulation study to demonstrate the
faithfulness of our implementations when compared to the original
implementations. Our simulations are at very large scale thus also
demonstrating the scalability of the original algorithms beyond their original
presentations. We also conduct experiments to assess their practicality in real
WSNs. We demonstrate how the implemented clustering algorithms can be combined
with routing and group key establishment algorithms to construct WSN
applications. Our study clearly demonstrates the applicability of our approach
and the benefits it offers to both research &amp; development communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3879</identifier>
 <datestamp>2011-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3879</id><created>2011-05-19</created><authors><author><keyname>Chabanne</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Cohen</keyname><forenames>G&#xe9;rard</forenames></author><author><keyname>Flori</keyname><forenames>Jean-Pierre</forenames></author><author><keyname>Patey</keyname><forenames>Alain</forenames></author></authors><title>Non-Malleable Codes from the Wire-Tap Channel</title><categories>cs.CR cs.IT math.IT</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Dziembowski et al. introduced the notion of non-malleable codes
(NMC), inspired from the notion of non-malleability in cryptography and the
work of Gennaro et al. in 2004 on tamper proof security. Informally, when using
NMC, if an attacker modifies a codeword, decoding this modified codeword will
return either the original message or a completely unrelated value.
  The definition of NMC is related to a family of modifications authorized to
the attacker. In their paper, Dziembowski et al. propose a construction valid
for the family of all bit-wise independent functions.
  In this article, we study the link between the second version of the Wire-Tap
(WT) Channel, introduced by Ozarow and Wyner in 1984, and NMC. Using
coset-coding, we describe a new construction for NMC w.r.t. a subset of the
family of bit-wise independent functions. Our scheme is easier to build and
more efficient than the one proposed by Dziembowski et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3931</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3931</id><created>2011-05-19</created><authors><author><keyname>Zhou</keyname><forenames>Xueyuan</forenames></author><author><keyname>Belkin</keyname><forenames>Mikhail</forenames></author></authors><title>Behavior of Graph Laplacians on Manifolds with Boundary</title><categories>cs.LG math.NA stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In manifold learning, algorithms based on graph Laplacians constructed from
data have received considerable attention both in practical applications and
theoretical analysis. In particular, the convergence of graph Laplacians
obtained from sampled data to certain continuous operators has become an active
research topic recently. Most of the existing work has been done under the
assumption that the data is sampled from a manifold without boundary or that
the functions of interests are evaluated at a point away from the boundary.
However, the question of boundary behavior is of considerable practical and
theoretical interest. In this paper we provide an analysis of the behavior of
graph Laplacians at a point near or on the boundary, discuss their convergence
rates and their implications and provide some numerical results. It turns out
that while points near the boundary occupy only a small part of the total
volume of a manifold, the behavior of graph Laplacian there has different
scaling properties from its behavior elsewhere on the manifold, with global
effects on the whole manifold, an observation with potentially important
implications for the general problem of learning on manifolds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.3977</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.3977</id><created>2011-05-19</created><updated>2011-09-21</updated><authors><author><keyname>Liu</keyname><forenames>Pei</forenames></author><author><keyname>Nie</keyname><forenames>Chun</forenames></author><author><keyname>Korakis</keyname><forenames>Thanasis</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author><author><keyname>Panwar</keyname><forenames>Shivendra</forenames></author><author><keyname>Verde</keyname><forenames>Francesco</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author></authors><title>STiCMAC: A MAC Protocol for Robust Space-Time Coding in Cooperative
  Wireless LANs</title><categories>cs.NI</categories><comments>This paper is a revised version of a paper with the same name
  submitted to IEEE Transaction on Wireless Communications. STiCMAC protocol
  with RTS/CTS turned off is presented in the appendix of this draft</comments><doi>10.1109/TWC.2012.020712.101900</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Relay-assisted cooperative wireless communication has been shown to have
significant performance gains over the legacy direct transmission scheme.
Compared with single relay based cooperation schemes, utilizing multiple relays
further improves the reliability and rate of transmissions. Distributed
space-time coding (DSTC), as one of the schemes to utilize multiple relays,
requires tight coordination between relays and does not perform well in a
distributed environment with mobility. In this paper, a cooperative medium
access control (MAC) layer protocol, called \emph{STiCMAC}, is designed to
allow multiple relays to transmit at the same time in an IEEE 802.11 network.
The transmission is based on a novel DSTC scheme called \emph{randomized
distributed space-time coding} (\emph{R-DSTC}), which requires minimum
coordination. Unlike conventional cooperation schemes that pick nodes with good
links, \emph{STiCMAC} picks a \emph{transmission mode} that could most improve
the end-to-end data rate. Any station that correctly receives from the source
can act as a relay and participate in forwarding. The MAC protocol is
implemented in a fully decentralized manner and is able to opportunistically
recruit relays on the fly, thus making it \emph{robust} to channel variations
and user mobility. Simulation results show that the network capacity and delay
performance are greatly improved, especially in a mobile environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4002</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4002</id><created>2011-05-19</created><authors><author><keyname>J&#xf8;rgensen</keyname><forenames>Jakob Heide</forenames></author><author><keyname>Jensen</keyname><forenames>Tobias Lindstr&#xf8;m</forenames></author><author><keyname>Hansen</keyname><forenames>Per Christian</forenames></author><author><keyname>Jensen</keyname><forenames>S&#xf8;ren Holdt</forenames></author><author><keyname>Sidky</keyname><forenames>Emil Y.</forenames></author><author><keyname>Pan</keyname><forenames>Xiaochuan</forenames></author></authors><title>Accelerated gradient methods for total-variation-based CT image
  reconstruction</title><categories>math.NA cs.NA math.OC</categories><comments>4 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Total-variation (TV)-based Computed Tomography (CT) image reconstruction has
shown experimentally to be capable of producing accurate reconstructions from
sparse-view data. In particular TV-based reconstruction is very well suited for
images with piecewise nearly constant regions. Computationally, however,
TV-based reconstruction is much more demanding, especially for 3D imaging, and
the reconstruction from clinical data sets is far from being close to
real-time. This is undesirable from a clinical perspective, and thus there is
an incentive to accelerate the solution of the underlying optimization problem.
The TV reconstruction can in principle be found by any optimization method, but
in practice the large-scale systems arising in CT image reconstruction preclude
the use of memory-demanding methods such as Newton's method. The simple
gradient method has much lower memory requirements, but exhibits slow
convergence. In the present work we consider the use of two accelerated
gradient-based methods, GPBB and UPN, for reducing the number of gradient
method iterations needed to achieve a high-accuracy TV solution in CT image
reconstruction. The former incorporates several heuristics from the
optimization literature such as Barzilai-Borwein (BB) step size selection and
nonmonotone line search. The latter uses a cleverly chosen sequence of
auxiliary points to achieve a better convergence rate. The methods are memory
efficient and equipped with a stopping criterion to ensure that the TV
reconstruction has indeed been found. An implementation of the methods (in C
with interface to Matlab) is available for download from
http://www2.imm.dtu.dk/~pch/TVReg/. We compare the proposed methods with the
standard gradient method, applied to a 3D test problem with synthetic few-view
data. We find experimentally that for realistic parameters the proposed methods
significantly outperform the gradient method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4004</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4004</id><created>2011-05-19</created><authors><author><keyname>&#xc1;lvarez-Garc&#xed;a</keyname><forenames>Sandra</forenames></author><author><keyname>Brisaboa</keyname><forenames>Nieves R.</forenames></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>Javier D.</forenames></author><author><keyname>Mart&#xed;nez-Prieto</keyname><forenames>Miguel A.</forenames></author></authors><title>Compressed k2-Triples for Full-In-Memory RDF Engines</title><categories>cs.IR cs.DB</categories><comments>In Proc. of AMCIS'2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Current &quot;data deluge&quot; has flooded the Web of Data with very large RDF
datasets. They are hosted and queried through SPARQL endpoints which act as
nodes of a semantic net built on the principles of the Linked Data project.
Although this is a realistic philosophy for global data publishing, its query
performance is diminished when the RDF engines (behind the endpoints) manage
these huge datasets. Their indexes cannot be fully loaded in main memory, hence
these systems need to perform slow disk accesses to solve SPARQL queries. This
paper addresses this problem by a compact indexed RDF structure (called
k2-triples) applying compact k2-tree structures to the well-known
vertical-partitioning technique. It obtains an ultra-compressed representation
of large RDF graphs and allows SPARQL queries to be full-in-memory performed
without decompression. We show that k2-triples clearly outperforms
state-of-the-art compressibility and traditional vertical-partitioning query
resolution, remaining very competitive with multi-index solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4005</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4005</id><created>2011-05-19</created><authors><author><keyname>Liu</keyname><forenames>Zhen</forenames></author><author><keyname>Zhang</keyname><forenames>Qian-Ming</forenames></author><author><keyname>L&#xfc;</keyname><forenames>Linyuan</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Link prediction in complex networks: a local na\&quot;{\i}ve Bayes model</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>6 pages, 2 figures, 2 tables</comments><journal-ref>EPL 96 (2011) 48007</journal-ref><doi>10.1209/0295-5075/96/48007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common-neighbor-based method is simple yet effective to predict missing
links, which assume that two nodes are more likely to be connected if they have
more common neighbors. In such method, each common neighbor of two nodes
contributes equally to the connection likelihood. In this Letter, we argue that
different common neighbors may play different roles and thus lead to different
contributions, and propose a local na\&quot;{\i}ve Bayes model accordingly.
Extensive experiments were carried out on eight real networks. Compared with
the common-neighbor-based methods, the present method can provide more accurate
predictions. Finally, we gave a detailed case study on the US air
transportation network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4026</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4026</id><created>2011-05-20</created><authors><author><keyname>Amir</keyname><forenames>Mohamed</forenames></author><author><keyname>El-Keyi</keyname><forenames>Amr</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author></authors><title>A New Achievable DoF Region for the 3-user MxN Symmetric Interference
  Channel</title><categories>cs.IT math.IT</categories><comments>Submitted to ITW 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the 3-user multiple-input multiple-output Gaussian
interference channel with M antennas at each transmitter and N antennas at each
receiver is considered. It is assumed that the channel coefficients are
constant and known to all transmitters and receivers. A novel scheme is
presented that spans a new achievable degrees of freedom region. For some
values of M and N, the proposed scheme achieve higher number of DoF than are
currently achievable, while for other values it meets the best known
upperbound. Simulation results are presented showing the superior performance
of the proposed schemes to earlier approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4037</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4037</id><created>2011-05-20</created><authors><author><keyname>Hindawi</keyname><forenames>Ahed</forenames><affiliation>INRIA Sophia Antipolis, JAD</affiliation></author><author><keyname>Rifford</keyname><forenames>Ludovic</forenames><affiliation>JAD</affiliation></author><author><keyname>Pomet</keyname><forenames>Jean-Baptiste</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Mass transportation with LQ cost functions</title><categories>math.OC cs.SY</categories><proxy>ccsd</proxy><journal-ref>Acta Applicandae Mathematicae 113, 2 (2011) 215-229</journal-ref><doi>10.1007/s10440-010-9595-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the optimal transport problem in the Euclidean space where the cost
function is given by the value function associated with a Linear Quadratic
minimization problem. Under appropriate assumptions, we generalize Brenier's
Theorem proving existence and uniqueness of an optimal transport map. In the
controllable case, we show that the optimal transport map has to be the
gradient of a convex function up to a linear change of coordinates. We give
regularity results and also investigate the non-controllable case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4042</identifier>
 <datestamp>2012-01-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4042</id><created>2011-05-20</created><updated>2012-01-23</updated><authors><author><keyname>Gerchinovitz</keyname><forenames>S&#xe9;bastien</forenames><affiliation>DMA, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Yu</keyname><forenames>Jia Yuan</forenames></author></authors><title>Adaptive and Optimal Online Linear Regression on L1-balls</title><categories>stat.ML cs.LG math.ST stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of online linear regression on individual sequences.
The goal in this paper is for the forecaster to output sequential predictions
which are, after T time rounds, almost as good as the ones output by the best
linear predictor in a given L1-ball in R^d. We consider both the cases where
the dimension d is small and large relative to the time horizon T. We first
present regret bounds with optimal dependencies on the sizes U, X and Y of the
L1-ball, the input data and the observations. The minimax regret is shown to
exhibit a regime transition around the point d = sqrt(T) U X / (2 Y).
Furthermore, we present efficient algorithms that are adaptive, i.e., they do
not require the knowledge of U, X, and Y, but still achieve nearly optimal
regret bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4044</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4044</id><created>2011-05-20</created><authors><author><keyname>Evans</keyname><forenames>T. S.</forenames></author><author><keyname>Giometto</keyname><forenames>A.</forenames></author></authors><title>Turnover Rate of Popularity Charts in Neutral Models</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 18 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown recently that in many different cultural phenomena the
turnover rate on the most popular artefacts in a population exhibit some
regularities. A very simple expression for this turnover rate has been proposed
by Bentley et al. and its validity in two simple models for copying and
innovation is investigated in this paper. It is found that Bentley's formula is
an approximation of the real behaviour of the turnover rate in the
Wright-Fisher model, while it is not valid in the Moran model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4058</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4058</id><created>2011-05-20</created><authors><author><keyname>Beritelli</keyname><forenames>Francesco</forenames></author><author><keyname>Spadaccini</keyname><forenames>Andrea</forenames></author></authors><title>Human Identity Verification based on Heart Sounds: Recent Advances and
  Future Directions</title><categories>cs.CV stat.AP</categories><comments>18 pages, chapter to be published in the book &quot;Biometrics / Book 1&quot;,
  ISBN 978-953-307-618-8, by InTech</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Identity verification is an increasingly important process in our daily
lives, and biometric recognition is a natural solution to the authentication
problem.
  One of the most important research directions in the field of biometrics is
the characterization of novel biometric traits that can be used in conjunction
with other traits, to limit their shortcomings or to enhance their performance.
  The aim of this work is to introduce the reader to the usage of heart sounds
for biometric recognition, describing the strengths and the weaknesses of this
novel trait and analyzing in detail the methods developed so far by different
research groups and their performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4060</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4060</id><created>2011-05-20</created><authors><author><keyname>Schumann</keyname><forenames>Andrew</forenames></author><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Logical Modelling of Physarum Polycephalum</title><categories>cs.LO</categories><journal-ref>Analele Universitatii de Vest, Timisoara, Seria Matematica -
  Informatica XLVIII, 3, (2010), 175-190</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel model of unconventional computing where a structural part
of computation is presented by dynamics of plasmodium of Physarum polycephalum,
a large single cell. We sketch a new logical approach combining conventional
logic with process calculus to demonstrate how to employ formal methods in
design of unconventional computing media presented by Physarum polycephalum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4082</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4082</id><created>2011-05-20</created><authors><author><keyname>Canepa</keyname><forenames>Davide</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>D&#xe9;fago</keyname><forenames>Xavier</forenames><affiliation>JAIST</affiliation></author><author><keyname>Izumi</keyname><forenames>Taisuke</forenames><affiliation>NIT</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>INRIA Rocquencourt, LIP6</affiliation></author></authors><title>Emergent velocity agreement in robot networks</title><categories>cs.NI cs.RO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose and prove correct a new self-stabilizing velocity
agreement (flocking) algorithm for oblivious and asynchronous robot networks.
Our algorithm allows a flock of uniform robots to follow a flock head emergent
during the computation whatever its direction in plane. Robots are
asynchronous, oblivious and do not share a common coordinate system. Our
solution includes three modules architectured as follows: creation of a common
coordinate system that also allows the emergence of a flock-head, setting up
the flock pattern and moving the flock. The novelty of our approach steams in
identifying the necessary conditions on the flock pattern placement and the
velocity of the flock-head (rotation, translation or speed) that allow the
flock to both follow the exact same head and to preserve the flock pattern.
Additionally, our system is self-healing and self-stabilizing. In the event of
the head leave (the leading robot disappears or is damaged and cannot be
recognized by the other robots) the flock agrees on another head and follows
the trajectory of the new head. Also, robots are oblivious (they do not recall
the result of their previous computations) and we make no assumption on their
initial position. The step complexity of our solution is O(n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4125</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4125</id><created>2011-05-20</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Ohrimenko</keyname><forenames>Olga</forenames></author><author><keyname>Tamassia</keyname><forenames>Roberto</forenames></author></authors><title>Privacy-Preserving Group Data Access via Stateless Oblivious RAM
  Simulation</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of providing privacy-preserving access to an outsourced
honest-but-curious data repository for a group of trusted users. We show that
such privacy-preserving data access is possible using a combination of
probabilistic encryption, which directly hides data values, and stateless
oblivious RAM simulation, which hides the pattern of data accesses. We give
simulations that have only an $O(\log n)$ amortized time overhead for
simulating a RAM algorithm, $\cal A$, that has a memory of size $n$, using a
scheme that is data-oblivious with very high probability assuming the
simulation has access to a private workspace of size $O(n^\nu)$, for any given
fixed constant $\nu&gt;0$. This simulation makes use of pseudorandom hash
functions and is based on a novel hierarchy of cuckoo hash tables that all
share a common stash. We also provide results from an experimental simulation
of this scheme, showing its practicality. In addition, in a result that may be
of some theoretical interest, we also show that one can eliminate the
dependence on pseudorandom hash functions in our simulation while having the
overhead rise to be $O(\log^2 n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4127</identifier>
 <datestamp>2013-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4127</id><created>2011-05-20</created><updated>2013-05-13</updated><authors><author><keyname>Faenza</keyname><forenames>Yuri</forenames></author><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Grappe</keyname><forenames>Roland</forenames></author><author><keyname>Tiwary</keyname><forenames>Hans Raj</forenames></author></authors><title>Extended formulations, non-negative factorizations and randomized
  communication protocols</title><categories>cs.DM math.CO</categories><comments>16 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An extended formulation of a polyhedron $P$ is a linear description of a
polyhedron $Q$ together with a linear map $\pi$ such that $\pi(Q)=P$. These
objects are of fundamental importance in polyhedral combinatorics and
optimization theory, and the subject of a number of studies. Yannakakis'
factorization theorem [M. Yannakakis. Expressing combinatorial optimization
problems by linear programs. {\em J. Comput. System Sci.}, 43(3):441--466
(1991)] provides a surprising connection between extended formulations and
communication complexity, showing that the smallest size of an extended
formulation of $P$ equals the nonnegative rank of its slack matrix $S$.
Moreover, Yannakakis also shows that the nonnegative rank of $S$ is at most
$2^c$, where $c$ is the complexity of any \emph{deterministic} protocol
computing $S$. In this paper, we show that the latter result can be
strengthened when we allow protocols to be \emph{randomized}. In particular, we
prove that the base-2 logarithm of the nonnegative rank of any nonnegative
matrix equals the minimum complexity of a randomized communication protocol
computing the matrix in expectation. Using Yannakakis' factorization theorem,
this implies that the base-2 logarithm of the smallest size of an extended
formulation of a polytope $P$ equals the minimum complexity of a randomized
communication protocol computing the slack matrix of $P$ in expectation. We
show that allowing randomization in the protocol can be crucial for obtaining
small extended formulations. Specifically, we prove that for the spanning tree
and perfect matching polytopes, small variance in the protocol forces large
size in the extended formulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4130</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4130</id><created>2011-05-20</created><authors><author><keyname>Barequet</keyname><forenames>Gill</forenames></author><author><keyname>Dickerson</keyname><forenames>Matthew T.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Hodorkovsky</keyname><forenames>David</forenames></author><author><keyname>Vyatkina</keyname><forenames>Kira</forenames></author></authors><title>On 2-Site Voronoi Diagrams under Geometric Distance Functions</title><categories>cs.CG</categories><comments>8 pages, 7 figures; to appear in Proc. the 8th ISVD, Qingdao, China,
  June 28-30, 2011, published by IEEE CS</comments><journal-ref>J. Computer Science and Technology 28 (2): 267-277, 2013</journal-ref><doi>10.1007/s11390-013-1328-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit a new type of a Voronoi diagram, in which distance is measured
from a point to a pair of points. We consider a few more such distance
functions, based on geometric primitives, and analyze the structure and
complexity of the nearest- and furthest-neighbor Voronoi diagrams of a point
set with respect to these distance functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4136</identifier>
 <datestamp>2012-01-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4136</id><created>2011-05-20</created><updated>2012-01-15</updated><authors><author><keyname>Murri</keyname><forenames>Riccardo</forenames></author></authors><title>A novel parallel algorithm for Gaussian Elimination of sparse
  unsymmetric matrices</title><categories>cs.MS cs.DC cs.NA math.NA</categories><comments>14 pages; 2 PDF figures; LaTeX2e; final version submitted for the
  PPAM2011 conference proceedings</comments><msc-class>65F50, 65F05, 68W10</msc-class><acm-class>G.1.3; G.4; I.1.2; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new algorithm for Gaussian Elimination suitable for general
(unsymmetric and possibly singular) sparse matrices, of any entry type, which
has a natural parallel and distributed-memory formulation but degrades
gracefully to sequential execution.
  We present a sample MPI implementation of a program computing the rank of a
sparse integer matrix using the proposed algorithm. Some preliminary
performance measurements are presented and discussed, and the performance of
the algorithm is compared to corresponding state-of-the-art algorithms for
floating-point and integer matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4143</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4143</id><created>2011-05-20</created><updated>2013-07-24</updated><authors><author><keyname>Hsu</keyname><forenames>Yu-Pin</forenames></author><author><keyname>Abedini</keyname><forenames>Navid</forenames></author><author><keyname>Gautam</keyname><forenames>Natarajan</forenames></author><author><keyname>Sprintson</keyname><forenames>Alex</forenames></author><author><keyname>Shakkottai</keyname><forenames>Srinivas</forenames></author></authors><title>Opportunities for Network Coding: To Wait or Not to Wait</title><categories>math.OC cs.IT cs.NI math.IT</categories><comments>14 pages, journal version of arXiv:1105.4143v1, submitted to IEEE/ACM
  Transaction on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been well established that wireless network coding can significantly
improve the efficiency of multi-hop wireless networks. However, in a stochastic
environment some of the packets might not have coding pairs, which limits the
number of available coding opportunities. In this context, an important
decision is whether to delay packet transmission in hope that a coding pair
will be available in the future or transmit a packet without coding. The paper
addresses this problem by formulating a stochastic dynamic program whose
objective is to minimize the long-run average cost per unit time incurred due
to transmissions and delays. In particular, we identify optimal control actions
that would balance between costs of transmission against the costs incurred due
to the delays. Moreover, we seek to address a crucial question: what should be
observed as the state of the system? We analytically show that observing queue
lengths suffices if the system can be modeled as a Markov decision process. We
also show that a stationary threshold type policy based on queue lengths is
optimal. We further substantiate our results with simulation experiments for
more generalized settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4151</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4151</id><created>2011-05-19</created><authors><author><keyname>Thakur</keyname><forenames>Gautam S.</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Ketabdar</keyname><forenames>Hamed</forenames></author><author><keyname>Helmy</keyname><forenames>Ahmed</forenames></author></authors><title>Towards Realistic Vehicular Network Modeling Using Planet-scale Public
  Webcams</title><categories>cs.NI stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Realistic modeling of vehicular mobility has been particularly challenging
due to a lack of large libraries of measurements in the research community. In
this paper we introduce a novel method for large-scale monitoring, analysis,
and identification of spatio-temporal models for vehicular mobility using the
freely available online webcams in cities across the globe. We collect
vehicular mobility traces from 2,700 traffic webcams in 10 different cities for
several months and generate a mobility dataset of 7.5 Terabytes consisting of
125 million of images. To the best of our knowl- edge, this is the largest data
set ever used in such study. To process and analyze this data, we propose an
efficient and scalable algorithm to estimate traffic density based on
background image subtraction. Initial results show that at least 82% of
individual cameras with less than 5% deviation from four cities follow
Loglogistic distribution and also 94% cameras from Toronto follow gamma
distribution. The aggregate results from each city also demonstrate that Log-
Logistic and gamma distribution pass the KS-test with 95% confidence.
Furthermore, many of the camera traces exhibit long range dependence, with
self-similarity evident in the aggregates of traffic (per city). We believe our
novel data collection method and dataset provide a much needed contribution to
the research community for realistic modeling of vehicular networks and
mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4174</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4174</id><created>2011-05-20</created><authors><author><keyname>Couceiro</keyname><forenames>Miguel</forenames></author><author><keyname>Grabisch</keyname><forenames>Michel</forenames></author></authors><title>On the poset of computation rules for nonassociative calculus</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The symmetric maximum, denoted by v, is an extension of the usual max
operation so that 0 is the neutral element, and -x is the symmetric (or
inverse) of x, i.e., x v(-x)=0. However, such an extension does not preserve
the associativity of max. This fact asks for systematic ways of parenthesing
(or bracketing) terms of a sequence (with more than two arguments) when using
such an extended maximum. We refer to such systematic (predefined) ways of
parenthesing as computation rules. As it turns out there are infinitely many
computation rules each of which corresponding to a systematic way of bracketing
arguments of sequences. Essentially, computation rules reduce to deleting terms
of sequences based on the condition x v(-x)=0. This observation gives raise to
a quasi-order on the set of such computation rules: say that rule 1 is below
rule 2 if for all sequences of numbers, rule 1 deletes more terms in the
sequence than rule 2. In this paper we present a study of this quasi-ordering
of computation rules. In particular, we show that the induced poset of all
equivalence classes of computation rules is uncountably infinite, has
infinitely many maximal elements, has infinitely many atoms, and it embeds the
powerset of natural numbers ordered by inclusion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4175</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4175</id><created>2011-05-20</created><authors><author><keyname>Sachdeva</keyname><forenames>Sushant</forenames></author><author><keyname>Saket</keyname><forenames>Rishi</forenames></author></authors><title>Nearly Optimal NP-Hardness of Vertex Cover on k-Uniform k-Partite
  Hypergraphs</title><categories>cs.CC cs.DM math.CO</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of computing the minimum vertex cover on k-uniform
k-partite hypergraphs when the k-partition is given. On bipartite graphs (k =
2), the minimum vertex cover can be computed in polynomial time. For general k,
the problem was studied by Lov\'asz, who gave a k/2 -approximation based on the
standard LP relaxation. Subsequent work by Aharoni, Holzman and Krivelevich
showed a tight integrality gap of (k/2 - o(1)) for the LP relaxation. While
this problem was known to be NP-hard for k &gt;= 3, the first non-trivial
NP-hardness of approximation factor of k/4- \eps was shown in a recent work by
Guruswami and Saket. They also showed that assuming Khot's Unique Games
Conjecture yields a k/2 - \eps inapproximability for this problem, implying the
optimality of Lov\'asz's result.
  In this work, we show that this problem is NP-hard to approximate within k/2-
1 + 1/2k -\eps. This hardness factor is off from the optimal by an additive
constant of at most 1 for k &gt;= 4. Our reduction relies on the Multi-Layered PCP
of Dinur et al. and uses a gadget - based on biased Long Codes - adapted from
the LP integrality gap of Aharoni et al. The nature of our reduction requires
the analysis of several Long Codes with different biases, for which we prove
structural properties of the so called cross-intersecting collections of set
families - variants of which have been studied in extremal set theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4183</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4183</id><created>2011-05-20</created><authors><author><keyname>Gonzalez-Diaz</keyname><forenames>Rocio</forenames></author><author><keyname>Jimenez</keyname><forenames>Maria Jose</forenames></author><author><keyname>Medrano</keyname><forenames>Belen</forenames></author></authors><title>Cubical Cohomology Ring of 3D Photographs</title><categories>cs.CV</categories><journal-ref>Cubical cohomology ring of 3D photographs. International Journal
  of Imaging Systems and Technology. Volume 21, Issue 1, March 2011, Pages:
  76--85, Rocio Gonzalez-Diaz, Maria Jose Jimenez and Belen Medrano</journal-ref><doi>10.1002/ima.20271</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cohomology and cohomology ring of three-dimensional (3D) objects are
topological invariants that characterize holes and their relations. Cohomology
ring has been traditionally computed on simplicial complexes. Nevertheless,
cubical complexes deal directly with the voxels in 3D images, no additional
triangulation is necessary, facilitating efficient algorithms for the
computation of topological invariants in the image context. In this paper, we
present formulas to directly compute the cohomology ring of 3D cubical
complexes without making use of any additional triangulation. Starting from a
cubical complex $Q$ that represents a 3D binary-valued digital picture whose
foreground has one connected component, we compute first the cohomological
information on the boundary of the object, $\partial Q$ by an incremental
technique; then, using a face reduction algorithm, we compute it on the whole
object; finally, applying the mentioned formulas, the cohomology ring is
computed from such information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4204</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4204</id><created>2011-05-20</created><updated>2011-07-27</updated><authors><author><keyname>Chaudhury</keyname><forenames>Kunal Narayan</forenames></author><author><keyname>Sage</keyname><forenames>Daniel</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>Fast O(1) bilateral filtering using trigonometric range kernels</title><categories>cs.CV cs.CE cs.DC cs.DS</categories><comments>Accepted in IEEE Transactions on Image Processing. Also see addendum:
  https://sites.google.com/site/kunalspage/home/Addendum.pdf</comments><journal-ref>IEEE Transactions on Image Processing, vol. 20(12), pp. 3376 -
  3382, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that spatial averaging can be realized (in space or
frequency domain) using algorithms whose complexity does not depend on the size
or shape of the filter. These fast algorithms are generally referred to as
constant-time or O(1) algorithms in the image processing literature. Along with
the spatial filter, the edge-preserving bilateral filter [Tomasi1998] involves
an additional range kernel. This is used to restrict the averaging to those
neighborhood pixels whose intensity are similar or close to that of the pixel
of interest. The range kernel operates by acting on the pixel intensities. This
makes the averaging process non-linear and computationally intensive,
especially when the spatial filter is large. In this paper, we show how the
O(1) averaging algorithms can be leveraged for realizing the bilateral filter
in constant-time, by using trigonometric range kernels. This is done by
generalizing the idea in [Porikli2008] of using polynomial range kernels. The
class of trigonometric kernels turns out to be sufficiently rich, allowing for
the approximation of the standard Gaussian bilateral filter. The attractive
feature of our approach is that, for a fixed number of terms, the quality of
approximation achieved using trigonometric kernels is much superior to that
obtained in [Porikli2008] using polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4206</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4206</id><created>2011-05-20</created><authors><author><keyname>Zhang</keyname><forenames>Jun</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled B.</forenames></author></authors><title>Spatial Intercell Interference Cancellation with CSI Training and
  Feedback</title><categories>cs.IT math.IT</categories><comments>24 pages, 10 figures, submitted to IEEE Trans. Wireless Commun., May,
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate intercell interference cancellation (ICIC) with a practical
downlink training and uplink channel state information (CSI) feedback model.
The average downlink throughput for such a 2-cell network is derived. The user
location has a strong effect on the signal-to-interference ratio (SIR) and the
channel estimation error. This motivates adaptively switching between
traditional (single-cell) beamforming and ICIC at low signal-to-noise ratio
(SNR) where ICIC is preferred only with low SIR and accurate channel
estimation, and the use of ICIC with optimized training and feedback at high
SNR. For a given channel coherence time and fixed training and feedback
overheads, we develop optimal data vs. pilot power allocation for CSI training
as well as optimal feedback resource allocation to feed back CSI of different
channels. Both analog and finite-rate digital feedback are considered. With
analog feedback, the training power optimization provides a more significant
performance gain than feedback optimization; while conversely for digital
feedback, performance is more sensitive to the feedback bit allocation than the
training power optimization. We show that even with low-rate feedback and
standard training, ICIC can transform an interference-limited cellular network
into a noise-limited one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4224</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4224</id><created>2011-05-21</created><authors><author><keyname>Liu</keyname><forenames>Weiming</forenames></author><author><keyname>Li</keyname><forenames>Sanjiang</forenames></author></authors><title>On A Semi-Automatic Method for Generating Composition Tables</title><categories>cs.AI cs.LO</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Originating from Allen's Interval Algebra, composition-based reasoning has
been widely acknowledged as the most popular reasoning technique in qualitative
spatial and temporal reasoning. Given a qualitative calculus (i.e. a relation
model), the first thing we should do is to establish its composition table
(CT). In the past three decades, such work is usually done manually. This is
undesirable and error-prone, given that the calculus may contain tens or
hundreds of basic relations. Computing the correct CT has been identified by
Tony Cohn as a challenge for computer scientists in 1995. This paper addresses
this problem and introduces a semi-automatic method to compute the CT by
randomly generating triples of elements. For several important qualitative
calculi, our method can establish the correct CT in a reasonable short time.
This is illustrated by applications to the Interval Algebra, the Region
Connection Calculus RCC-8, the INDU calculus, and the Oriented Point Relation
Algebras. Our method can also be used to generate CTs for customised
qualitative calculi defined on restricted domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4246</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4246</id><created>2011-05-21</created><authors><author><keyname>Ferrero</keyname><forenames>M. Montserrat Alonso</forenames></author></authors><title>Voronoi Diagram: The Generator Recognition Problem</title><categories>cs.CG</categories><comments>Project Summary</comments><msc-class>92B99, 68U05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the analysis of systems consisting of small, regular objects, the methods
of mathematical morphology applied to images of these systems are well-suited.
One of these methods is the use of Voronoi polygons. It was found that the
Voronoi tessellation method represents a powerful tool for the analysis of thin
film morphology and provides nanostructural information to many multi-particle
assemblies. In these notes, several morphological algorithms are analyzed and
we study how to join all of them to design a graphical user interface (GUI)
that provides as input for the system the &quot;AFM image&quot; and interprets the output
of the system in terms of errors and generators coordinates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4250</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4250</id><created>2011-05-21</created><authors><author><keyname>Nutov</keyname><forenames>Zeev</forenames></author></authors><title>Approximating subset $k$-connectivity problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subset $T \subseteq V$ of terminals is $k$-connected to a root $s$ in a
directed/undirected graph $J$ if $J$ has $k$ internally-disjoint $vs$-paths for
every $v \in T$; $T$ is $k$-connected in $J$ if $T$ is $k$-connected to every
$s \in T$. We consider the {\sf Subset $k$-Connectivity Augmentation} problem:
given a graph $G=(V,E)$ with edge/node-costs, node subset $T \subseteq V$, and
a subgraph $J=(V,E_J)$ of $G$ such that $T$ is $k$-connected in $J$, find a
minimum-cost augmenting edge-set $F \subseteq E \setminus E_J$ such that $T$ is
$(k+1)$-connected in $J \cup F$. The problem admits trivial ratio $O(|T|^2)$.
We consider the case $|T|&gt;k$ and prove that for directed/undirected graphs and
edge/node-costs, a $\rho$-approximation for {\sf Rooted Subset $k$-Connectivity
Augmentation} implies the following ratios for {\sf Subset $k$-Connectivity
Augmentation}: (i) $b(\rho+k) + {(\frac{3|T|}{|T|-k})}^2
H(\frac{3|T|}{|T|-k})$; (ii) $\rho \cdot O(\frac{|T|}{|T|-k} \log k)$, where
b=1 for undirected graphs and b=2 for directed graphs, and $H(k)$ is the $k$th
harmonic number. The best known values of $\rho$ on undirected graphs are
$\min\{|T|,O(k)\}$ for edge-costs and $\min\{|T|,O(k \log |T|)\}$ for
node-costs; for directed graphs $\rho=|T|$ for both versions. Our results imply
that unless $k=|T|-o(|T|)$, {\sf Subset $k$-Connectivity Augmentation} admits
the same ratios as the best known ones for the rooted version. This improves
the ratios in \cite{N-focs,L}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4251</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4251</id><created>2011-05-21</created><authors><author><keyname>Nguyen</keyname><forenames>Hoa</forenames><affiliation>University of Utah</affiliation></author><author><keyname>Fuxman</keyname><forenames>Ariel</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Paparizos</keyname><forenames>Stelios</forenames><affiliation>Microsoft Research</affiliation></author><author><keyname>Freire</keyname><forenames>Juliana</forenames><affiliation>University of Utah</affiliation></author><author><keyname>Agrawal</keyname><forenames>Rakesh</forenames><affiliation>Microsoft Research</affiliation></author></authors><title>Synthesizing Products for Online Catalogs</title><categories>cs.DB</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 7, pp.
  409-418 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A high-quality, comprehensive product catalog is essential to the success of
Product Search engines and shopping sites such as Yahoo! Shopping, Google
Product Search or Bing Shopping. But keeping catalogs up-to-date becomes a
challenging task, calling for the need of automated techniques. In this paper,
we introduce the problem of product synthesis, a key component of catalog
creation and maintenance. Given a set of offers advertised by merchants, the
goal is to identify new products and add them to the catalog together with
their (structured) attributes. A fundamental challenge is the scale of the
problem: a Product Search engine receives data from thousands of merchants and
millions of products; the product taxonomy contains thousands of categories,
where each category comes in a different schema; and merchants use
representations for products that are different from the ones used in the
catalog of the Product Search engine.
  We propose a system that provides an end-to-end solution to the product
synthesis problem, and includes components for extraction, and addresses issues
involved in data extraction from offers, schema reconciliation, and data
fusion. We developed a novel and scalable technique for schema matching which
leverages knowledge about previously-known instance-level associations between
offers and products; and it is trained using automatically created training
sets (no manually-labeled data is needed). We present an experimental
evaluation of our system using data from Bing Shopping for more than 800K
offers, a thousand merchants, and 400 categories. The evaluation confirms that
our approach is able to automatically generate a large number of accurate
product specifications, and that our schema reconciliation component
outperforms state-of-the-art schema matching techniques in terms of precision
and recall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4252</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4252</id><created>2011-05-21</created><authors><author><keyname>Floratou</keyname><forenames>Avrilia</forenames><affiliation>University of Wisconsin-Madison</affiliation></author><author><keyname>Patel</keyname><forenames>Jignesh</forenames><affiliation>University of Wisconsin-Madison</affiliation></author><author><keyname>Shekita</keyname><forenames>Eugene</forenames><affiliation>IBM Research</affiliation></author><author><keyname>Tata</keyname><forenames>Sandeep</forenames><affiliation>IBM Research</affiliation></author></authors><title>Column-Oriented Storage Techniques for MapReduce</title><categories>cs.DB cs.DC</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><report-no>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 7, pp.
  419-429 (2011)</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Users of MapReduce often run into performance problems when they scale up
their workloads. Many of the problems they encounter can be overcome by
applying techniques learned from over three decades of research on parallel
DBMSs. However, translating these techniques to a MapReduce implementation such
as Hadoop presents unique challenges that can lead to new design choices. This
paper describes how column-oriented storage techniques can be incorporated in
Hadoop in a way that preserves its popular programming APIs.
  We show that simply using binary storage formats in Hadoop can provide a 3x
performance boost over the naive use of text files. We then introduce a
column-oriented storage format that is compatible with the replication and
scheduling constraints of Hadoop and show that it can speed up MapReduce jobs
on real workloads by an order of magnitude. We also show that dealing with
complex column types such as arrays, maps, and nested records, which are common
in MapReduce jobs, can incur significant CPU overhead. Finally, we introduce a
novel skip list column format and lazy record construction strategy that avoids
deserializing unwanted records to provide an additional 1.5x performance boost.
Experiments on a real intranet crawl are used to show that our column-oriented
storage techniques can improve the performance of the map phase in Hadoop by as
much as two orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4253</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4253</id><created>2011-05-21</created><authors><author><keyname>Lomet</keyname><forenames>David</forenames><affiliation>Microsoft Research, USA</affiliation></author><author><keyname>Tzoumas</keyname><forenames>Kostas</forenames><affiliation>Aalborg University, Denmark</affiliation></author><author><keyname>Zwilling</keyname><forenames>Michael</forenames><affiliation>Microsoft</affiliation></author></authors><title>Implementing Performance Competitive Logical Recovery</title><categories>cs.DB</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 7, pp.
  430-439 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New hardware platforms, e.g. cloud, multi-core, etc., have led to a
reconsideration of database system architecture. Our Deuteronomy project
separates transactional functionality from data management functionality,
enabling a flexible response to exploiting new platforms. This separation
requires, however, that recovery is described logically. In this paper, we
extend current recovery methods to work in this logical setting. While this is
straightforward in principle, performance is an issue. We show how ARIES style
recovery optimizations can work for logical recovery where page information is
not captured on the log. In side-by-side performance experiments using a common
log, we compare logical recovery with a state-of-the art ARIES style recovery
implementation and show that logical redo performance can be competitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4254</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4254</id><created>2011-05-21</created><authors><author><keyname>Machanavajjhala</keyname><forenames>Ashwin</forenames><affiliation>Yahoo! Research</affiliation></author><author><keyname>Korolova</keyname><forenames>Aleksandra</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Sarma</keyname><forenames>Atish Das</forenames><affiliation>Google</affiliation></author></authors><title>Personalized Social Recommendations - Accurate or Private?</title><categories>cs.DB cs.CR cs.SI</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 7, pp.
  440-450 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the recent surge of social networks like Facebook, new forms of
recommendations have become possible - personalized recommendations of ads,
content, and even new friend and product connections based on one's social
interactions. Since recommendations may use sensitive social information, it is
speculated that these recommendations are associated with privacy risks. The
main contribution of this work is in formalizing these expected trade-offs
between the accuracy and privacy of personalized social recommendations.
  In this paper, we study whether &quot;social recommendations&quot;, or recommendations
that are solely based on a user's social network, can be made without
disclosing sensitive links in the social graph. More precisely, we quantify the
loss in utility when existing recommendation algorithms are modified to satisfy
a strong notion of privacy, called differential privacy. We prove lower bounds
on the minimum loss in utility for any recommendation algorithm that is
differentially private. We adapt two privacy preserving algorithms from the
differential privacy literature to the problem of social recommendations, and
analyze their performance in comparison to the lower bounds, both analytically
and experimentally. We show that good private social recommendations are
feasible only for a small subset of the users in the social network or for a
lenient setting of privacy parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4255</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4255</id><created>2011-05-21</created><authors><author><keyname>Capannini</keyname><forenames>Gabriele</forenames><affiliation>ISTI CNR</affiliation></author><author><keyname>Nardini</keyname><forenames>Franco Maria</forenames><affiliation>ISTI-CNR</affiliation></author><author><keyname>Perego</keyname><forenames>Raffaele</forenames><affiliation>ISTI-CNR</affiliation></author><author><keyname>Silvestri</keyname><forenames>Fabrizio</forenames><affiliation>ISTI-CNR</affiliation></author></authors><title>Efficient Diversification of Web Search Results</title><categories>cs.IR</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 7, pp.
  451-459 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyze the efficiency of various search results
diversification methods. While efficacy of diversification approaches has been
deeply investigated in the past, response time and scalability issues have been
rarely addressed. A unified framework for studying performance and feasibility
of result diversification solutions is thus proposed. First we define a new
methodology for detecting when, and how, query results need to be diversified.
To this purpose, we rely on the concept of &quot;query refinement&quot; to estimate the
probability of a query to be ambiguous. Then, relying on this novel ambiguity
detection method, we deploy and compare on a standard test set, three different
diversification methods: IASelect, xQuAD, and OptSelect. While the first two
are recent state-of-the-art proposals, the latter is an original algorithm
introduced in this paper. We evaluate both the efficiency and the effectiveness
of our approach against its competitors by using the standard TREC Web
diversification track testbed. Results shown that OptSelect is able to run two
orders of magnitude faster than the two other state-of-the-art approaches and
to obtain comparable figures in diversification effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4256</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4256</id><created>2011-05-21</created><authors><author><keyname>Morales</keyname><forenames>Gianmarco De Francisci</forenames><affiliation>IMT Lucca</affiliation></author><author><keyname>Gionis</keyname><forenames>Aristides</forenames><affiliation>Yahoo! Research</affiliation></author><author><keyname>Sozio</keyname><forenames>Mauro</forenames><affiliation>MPI Saarbruecken</affiliation></author></authors><title>Social content matching in MapReduce</title><categories>cs.SI cs.DC</categories><comments>VLDB2011</comments><proxy>uroehm</proxy><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 7, pp.
  460-469 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching problems are ubiquitous. They occur in economic markets, labor
markets, internet advertising, and elsewhere. In this paper we focus on an
application of matching for social media. Our goal is to distribute content
from information suppliers to information consumers. We seek to maximize the
overall relevance of the matched content from suppliers to consumers while
regulating the overall activity, e.g., ensuring that no consumer is overwhelmed
with data and that all suppliers have chances to deliver their content.
  We propose two matching algorithms, GreedyMR and StackMR, geared for the
MapReduce paradigm. Both algorithms have provable approximation guarantees, and
in practice they produce high-quality solutions. While both algorithms scale
extremely well, we can show that StackMR requires only a poly-logarithmic
number of MapReduce steps, making it an attractive option for applications with
very large datasets. We experimentally show the trade-offs between quality and
efficiency of our solutions on two large datasets coming from real-world
social-media web sites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4261</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4261</id><created>2011-05-21</created><authors><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Zhang</keyname><forenames>Shengli</forenames></author><author><keyname>Lu</keyname><forenames>Lu</forenames></author></authors><title>Physical-Layer Network Coding: Tutorial, Survey, and Beyond</title><categories>cs.NI</categories><comments>This is a pre-finalized version of an invited paper to a special
  issue of Physical Communication on &quot;Network Coding and Its Application to
  Wireless Communications&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concept of physical-layer network coding (PNC) was proposed in 2006 for
application in wireless networks. Since then it has developed into a subfield
of network coding with wide followings. The basic idea of PNC is to exploit the
network coding operation that occurs naturally when electromagnetic (EM) waves
are superimposed on one another. This simple idea turns out to have profound
and fundamental ramifications. Subsequent works by various researchers have led
to many new results in the domains of 1) wireless communication; 2) wireless
information theory; and 3) wireless networking. The purpose of this paper is
fourfold. First, we give a brief tutorial on the basic concept of PNC. Second,
we survey and discuss recent key results in the three aforementioned areas.
Third, we examine a critical issue in PNC: synchronization. It has been a
common belief that PNC requires tight synchronization. Our recent results
suggest, however, that PNC may actually benefit from asynchrony. Fourth, we
propose that PNC is not just for wireless networks; it can also be useful in
optical networks. We provide an example showing that the throughput of a
passive optical network (PON) could potentially be raised by 100% with PNC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4272</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4272</id><created>2011-05-21</created><authors><author><keyname>Trunov</keyname><forenames>Vladimir</forenames></author><author><keyname>V'yugin</keyname><forenames>Vladimir</forenames></author></authors><title>Calibration with Changing Checking Rules and Its Application to
  Short-Term Trading</title><categories>cs.LG</categories><comments>15 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a natural learning process in which a financial trader without a
risk receives a gain in case when Stock Market is inefficient. In this process,
the trader rationally choose his gambles using a prediction made by a
randomized calibrated algorithm. Our strategy is based on Dawid's notion of
calibration with more general changing checking rules and on some modification
of Kakade and Foster's randomized algorithm for computing calibrated forecasts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4274</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4274</id><created>2011-05-21</created><updated>2012-07-25</updated><authors><author><keyname>V'yugin</keyname><forenames>Vladimir</forenames></author></authors><title>On Instability of the Ergodic Limit Theorems with Respect to Small
  Violations of Algorithmic Randomness</title><categories>cs.IT math.IT</categories><comments>32 pages. arXiv admin note: substantial text overlap with
  arXiv:0806.4572</comments><msc-class>68Q30 03D32</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An instability property of the Birkhoff's ergodic theorem and related
asymptotic laws with respect to small violations of algorithmic randomness is
studied. The Shannon--McMillan--Breiman theorem and all universal compression
schemes are also among them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4276</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4276</id><created>2011-05-21</created><authors><author><keyname>&#x160;ubelj</keyname><forenames>Lovro</forenames></author><author><keyname>Bajec</keyname><forenames>Marko</forenames></author></authors><title>Community structure of complex software systems: Analysis and
  applications</title><categories>cs.SI cs.SE physics.data-an physics.soc-ph</categories><journal-ref>Physica A 390(16), 2968-2975 (2011)</journal-ref><doi>10.1016/j.physa.2011.03.036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to notable discoveries in the fast evolving field of complex networks,
recent research in software engineering has also focused on representing
software systems with networks. Previous work has observed that these networks
follow scale-free degree distributions and reveal small-world phenomena, while
we here explore another property commonly found in different complex networks,
i.e. community structure. We adopt class dependency networks, where nodes
represent software classes and edges represent dependencies among them, and
show that these networks reveal a significant community structure,
characterized by similar properties as observed in other complex networks.
However, although intuitive and anticipated by different phenomena, identified
communities do not exactly correspond to software packages. We empirically
confirm our observations on several networks constructed from Java and various
third party libraries, and propose different applications of community
detection to software engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4278</identifier>
 <datestamp>2013-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4278</id><created>2011-05-21</created><updated>2013-03-30</updated><authors><author><keyname>Gil</keyname><forenames>Francisco Jos&#xe9; Soler</forenames></author><author><keyname>Alfonseca</keyname><forenames>Manuel</forenames></author></authors><title>Is the Multiverse Hypothesis capable of explaining the Fine Tuning of
  Nature Laws and Constants? The Case of Cellular Automata</title><categories>nlin.CG astro-ph.CO cs.NE</categories><comments>30 pages, 16 figures, 5 tables. Slightly reduced version published in
  Journal for General Philosophy of Science</comments><journal-ref>&quot;Fine tuning explained? Multiverses and cellular automata&quot;,
  F.J.Soler Gil, M.Alfonseca. Journal for General Philosophy of Science,
  Springer, March 2013</journal-ref><doi>10.1007/s10838-013-9215-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is analyzing to which extent the multiverse
hypothesis provides a real explanation of the peculiarities of the laws and
constants in our universe. First we argue in favor of the thesis that all
multiverses except Tegmark's &lt;&lt;mathematical multiverse&gt;&gt; are too small to
explain the fine tuning, so that they merely shift the problem up one level.
But the &lt;&lt;mathematical multiverse&gt;&gt; is surely too large. To prove this
assessment, we have performed a number of experiments with cellular automata of
complex behavior, which can be considered as universes in the mathematical
multiverse. The analogy between what happens in some automata (in particular
Conway's &lt;&lt;Game of Life&gt;&gt;) and the real world is very strong. But if the
results of our experiments can be extrapolated to our universe, we should
expect to inhabit -- in the context of the multiverse -- a world in which at
least some of the laws and constants of nature should show a certain time
dependence. Actually, the probability of our existence in a world such as ours
would be mathematically equal to zero. In consequence, the results presented in
this paper can be considered as an inkling that the hypothesis of the
multiverse, whatever its type, does not offer an adequate explanation for the
peculiarities of the physical laws in our world. A slightly reduced version of
this paper has been published in the Journal for General Philosophy of Science,
Springer, March 2013, DOI: 10.1007/s10838-013-9215-7.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4301</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4301</id><created>2011-05-21</created><authors><author><keyname>Gunther</keyname><forenames>Neil J.</forenames></author><author><keyname>Subramanyam</keyname><forenames>Shanti</forenames></author><author><keyname>Parvu</keyname><forenames>Stefan</forenames></author></authors><title>A Methodology for Optimizing Multithreaded System Scalability on
  Multi-cores</title><categories>cs.DC cs.PF</categories><comments>21 pages, 11 figures. To appear in &quot;Programming Multi-core and
  Many-core Computing Systems,&quot; eds. S. Pllana and F. Xhafa, Wiley Series on
  Parallel and Distributed Computing</comments><acm-class>B.8; C.4; C.5.5; D.4.8; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to quantify scalability with the Universal Scalability Law (USL)
by applying it to performance measurements of memcached, J2EE, and Weblogic on
multi-core platforms. Since commercial multicores are essentially black-boxes,
the accessible performance gains are primarily available at the application
level. We also demonstrate how our methodology can identify the most
significant performance tuning opportunities to optimize application
scalability, as well as providing an easy means for exploring other aspects of
the multi-core system design space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4318</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4318</id><created>2011-05-22</created><authors><author><keyname>Chatterhee</keyname><forenames>Diptesh</forenames></author></authors><title>Correction of Noisy Sentences using a Monolingual Corpus</title><categories>cs.DL cs.AI</categories><comments>67 pages, 2 figures, 4 tables, 2 algorithms</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Correction of Noisy Natural Language Text is an important and well studied
problem in Natural Language Processing. It has a number of applications in
domains like Statistical Machine Translation, Second Language Learning and
Natural Language Generation. In this work, we consider some statistical
techniques for Text Correction. We define the classes of errors commonly found
in text and describe algorithms to correct them. The data has been taken from a
poorly trained Machine Translation system. The algorithms use only a language
model in the target language in order to correct the sentences. We use phrase
based correction methods in both the algorithms. The phrases are replaced and
combined to give us the ?final corrected sentence. We also present the methods
to model different kinds of errors, in addition to results of the working of
the algorithms on the test set. We show that one of the approaches fail to
achieve the desired goal, whereas the other succeeds well. In the end, we
analyze the possible reasons for such a trend in performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4324</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4324</id><created>2011-05-22</created><authors><author><keyname>Leykin</keyname><forenames>Anton</forenames></author></authors><title>A search for an optimal start system for numerical homotopy continuation</title><categories>math.NA cs.MS math.AG</categories><comments>17 pages, 7 figures</comments><report-no>Mittag-Leffler-2011spring</report-no><msc-class>65Y20, 14Q99, 68N01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use our recent implementation of a certified homotopy tracking algorithm
to search for start systems that minimize the average complexity of finding all
roots of a regular system of polynomial equations. While finding optimal start
systems is a hard problem, our experiments show that it is possible to find
start systems that deliver better average complexity than the ones that are
commonly used in the existing homotopy continuation software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4337</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4337</id><created>2011-05-22</created><authors><author><keyname>Lu</keyname><forenames>Louis Yu</forenames></author></authors><title>Equivalent Effect Function and Fast Intrinsic Mode Decomposition</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Equivalent Effect Function (EEF) is defined as having the identical
integral values on the control points of the original time series data; the EEF
can be obtained from the derivative of the spline function passing through the
integral values on the control points. By choosing control points with
different criteria, the EEF can be used to find the intrinsic mode
function(IMF, fluctuation) and the residue (trend); to fit the curve of the
original data function; and to take samples on original data with equivalent
effect. As examples of application, results of trend and fluctuation on real
stock historical data are calculated on different time scales. A new approach
to extend the EEF to 2D intrinsic mode decomposition is introduced to resolve
the inter slice non continuity problem, some photo image decomposition examples
are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4340</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4340</id><created>2011-05-22</created><authors><author><keyname>Jabi</keyname><forenames>Mohammed</forenames><affiliation>INPT, Rabat, Marocco</affiliation><affiliation>INRS, Montreal, Canada</affiliation></author><author><keyname>Szczecinski</keyname><forenames>Leszek</forenames><affiliation>INRS, Montreal, Canada</affiliation></author><author><keyname>Benjillali</keyname><forenames>Mustapha</forenames><affiliation>INPT, Rabat, Marocco</affiliation></author></authors><title>Outage Probability of Diversity Combining Receivers in Arbitrarily
  Fading Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple and accurate method to evaluate the outage probability at
the output of arbitrarily fading L-branch diversity combining receiver. The
method is based on the saddlepoint approximation, which only requires the
knowledge of the moment generating functions of the signal-to-noise ratio at
the output of each diversity branch. In addition, we show that the obtained
results reduce to closed-form expressions in many particular cases of practical
interest. Numerical results illustrate a very high accuracy of the proposed
method for practical outage values and for a large mixture of fading and system
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4341</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4341</id><created>2011-05-22</created><updated>2014-01-01</updated><authors><author><keyname>Li</keyname><forenames>Quan-Lin</forenames></author><author><keyname>Wang</keyname><forenames>Meng</forenames></author><author><keyname>Lui</keyname><forenames>John C. S.</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author></authors><title>The Chaos of Propagation in a Retrial Supermarket Model</title><categories>cs.NI cs.PF math.DS math.PR</categories><comments>47 pages, 5 figures</comments><msc-class>60G, 60J, 90-08, 90B</msc-class><acm-class>C.2; C.4; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When decomposing the total orbit into $N$ sub-orbits (or simply orbits)
related to each of $N$ servers and through comparing the numbers of customers
in these orbits, we introduce a retrial supermarket model of $N$ identical
servers, where two probing-server choice numbers are respectively designed for
dynamically allocating each primary arrival and each retrial arrival into these
orbits when the chosen servers are all busy. Note that the designed purpose of
the two choice numbers can effectively improve performance measures of this
retrial supermarket model.
  This paper analyzes a simple and basic retrial supermarket model of N
identical servers, that is, Poisson arrivals, exponential service and retrial
times. To this end, we first provide a detailed probability computation to set
up an infinite-dimensional system of differential equations (or mean-field
equations) satisfied by the expected fraction vector. Then, as N goes to
infinity, we apply the operator semigroup to obtaining the mean-field limit (or
chaos of propagation) for the sequence of Markov processes which express the
state of this retrial supermarket model. Specifically, some simple and basic
conditions for the mean-field limit as well as for the Lipschitz condition are
established through the first two moments of the queue length in any orbit.
Finally, we show that the fixed point satisfies a system of nonlinear equations
which is an interesting networking generalization of the tail equations given
in the M/M/1 retrial queue, and also use the fixed point to give performance
analysis of this retrial supermarket model through numerical computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4354</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4354</id><created>2011-05-22</created><updated>2011-08-11</updated><authors><author><keyname>Das</keyname><forenames>Abhishek</forenames></author><author><keyname>Kar</keyname><forenames>Avijit</forenames></author><author><keyname>Bhattacharyya</keyname><forenames>Debasis</forenames></author></authors><title>Preprocessing for Automating Early Detection of Cervical Cancer</title><categories>cs.CV</categories><comments>15th International Conference on Information Visualisation (Track:
  8th International Conference BioMedical Visualization) at London, UK (IEEE
  Computer Society)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Uterine Cervical Cancer is one of the most common forms of cancer in women
worldwide. Most cases of cervical cancer can be prevented through screening
programs aimed at detecting precancerous lesions. During Digital Colposcopy,
colposcopic images or cervigrams are acquired in raw form. They contain
specular reflections which appear as bright spots heavily saturated with white
light and occur due to the presence of moisture on the uneven cervix surface
and. The cervix region occupies about half of the raw cervigram image. Other
parts of the image contain irrelevant information, such as equipment, frames,
text and non-cervix tissues. This irrelevant information can confuse automatic
identification of the tissues within the cervix. Therefore we focus on the
cervical borders, so that we have a geometric boundary on the relevant image
area. Our novel technique eliminates the SR, identifies the region of interest
and makes the cervigram ready for segmentation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4360</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4360</id><created>2011-05-22</created><authors><author><keyname>Kumar</keyname><forenames>Santosh</forenames></author><author><keyname>Pandey</keyname><forenames>Akhilesh</forenames></author></authors><title>Random Matrix Model for Nakagami-Hoyt Fading</title><categories>cs.IT math-ph math.IT math.MP</categories><comments>11 pages, 4 figures</comments><msc-class>94A15, 94A17, 15A18, 15A52, 60J65</msc-class><journal-ref>IEEE Transactions on Information Theory, Volume 56, Number 5,
  Pages 2360-2372, Year 2010</journal-ref><doi>10.1109/TIT.2010.2044060</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random matrix model for the Nakagami-q (Hoyt) fading in multiple-input
multiple-output (MIMO) communication channels with arbitrary number of
transmitting and receiving antennas is considered. The joint probability
density for the eigenvalues of H{\dag}H (or HH{\dag}), where H is the channel
matrix, is shown to correspond to the Laguerre crossover ensemble of random
matrices and is given in terms of a Pfaffian. Exact expression for the marginal
density of eigenvalues is obtained as a series consisting of associated
Laguerre polynomials. This is used to study the effect of fading on the Shannon
channel capacity. Exact expressions for higher order density correlation
functions are also given which can be used to study the distribution of channel
capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4372</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4372</id><created>2011-05-22</created><authors><author><keyname>Tulsiani</keyname><forenames>Madhur</forenames></author><author><keyname>Wolf</keyname><forenames>Julia</forenames></author></authors><title>Quadratic Goldreich-Levin Theorems</title><categories>cs.DS cs.DM math.CO</categories><msc-class>11B30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Decomposition theorems in classical Fourier analysis enable us to express a
bounded function in terms of few linear phases with large Fourier coefficients
plus a part that is pseudorandom with respect to linear phases. The
Goldreich-Levin algorithm can be viewed as an algorithmic analogue of such a
decomposition as it gives a way to efficiently find the linear phases
associated with large Fourier coefficients.
  In the study of &quot;quadratic Fourier analysis&quot;, higher-degree analogues of such
decompositions have been developed in which the pseudorandomness property is
stronger but the structured part correspondingly weaker. For example, it has
previously been shown that it is possible to express a bounded function as a
sum of a few quadratic phases plus a part that is small in the $U^3$ norm,
defined by Gowers for the purpose of counting arithmetic progressions of length
4. We give a polynomial time algorithm for computing such a decomposition.
  A key part of the algorithm is a local self-correction procedure for
Reed-Muller codes of order 2 (over $\F_2^n$) for a function at distance
$1/2-\epsilon$ from a codeword. Given a function $f:\F_2^n \to \{-1,1\}$ at
fractional Hamming distance $1/2-\epsilon$ from a quadratic phase (which is a
codeword of Reed-Muller code of order 2), we give an algorithm that runs in
time polynomial in $n$ and finds a codeword at distance at most $1/2-\eta$ for
$\eta = \eta(\epsilon)$. This is an algorithmic analogue of Samorodnitsky's
result, which gave a tester for the above problem. To our knowledge, it
represents the first instance of a correction procedure for any class of codes,
beyond the list-decoding radius.
  In the process, we give algorithmic versions of results from additive
combinatorics used in Samorodnitsky's proof and a refined version of the
inverse theorem for the Gowers $U^3$ norm over $\F_2^n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4378</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4378</id><created>2011-05-22</created><authors><author><keyname>Gergis</keyname><forenames>Labib Francis</forenames></author></authors><title>Performance of Hybrid Concatenated Trellis Codes CPFSK with Iterative
  Decoding over Fading Channels</title><categories>cs.IT math.IT</categories><comments>12 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Concatenation is a method of building long codes out of shorter ones, it
attempts to meet the problem of decoding complexity by breaking the required
computation into manageable segments. Concatenated Continuous Phase Frequency
Shift Keying (CPFSK) facilitates powerful error correction. CPFSK also has the
advantage of being bandwidth efficient and compatible with nonlinear
amplifiers. Bandwidth efficient concatenated coded modulation schemes were
designed for communication over Additive White Gaussian noise (AWGN), and
Rayleigh fading channels. An analytical bounds on the performance of serial
concatenated convolutional codes (SCCC), and parallel concatenated
convolutionalcodes (PCCC), were derived as a base of comparison with the third
category known as hybrid concatenated trellis codes scheme (HCTC). An upper
bound to the average maximum-likelihood bit error probability of the three
schemes were obtained. Design rules for the parallel, outer, and inner codes
that maximize the interleaver's gain were discussed. Finally, a low complexity
iterative decoding algorithm that yields a better performance is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4379</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4379</id><created>2011-05-22</created><authors><author><keyname>Gergis</keyname><forenames>Labib Francis</forenames></author></authors><title>Performance of MC-MC CDMA Systems with Nonlinear Models of HPA</title><categories>cs.IT math.IT</categories><comments>11 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new wireless communication system denoted as Multi-Code Multi-Carrier CDMA
(MC-MC CDMA), which is the combination of Multi-Code CDMA and Multi-Carrier
CDMA, is analyzed in this paper. This system can satisfy multi-rate services
using multi-code schemes and muti-carrier services used for high rate
transmission. The system is evaluated using Traveling Wave Tube Amplifier
(TWTA). This type of amplifiers continue to offer the best microwave high power
amplifiers (HPA) performance in terms of power efficiency, size and cost, but
lag behind Solid State Power Amplifiers (SSPA's) in linearity. This paper
presents a technique for improving TWTA linearity. The use of predistorter (PD)
linearization technique is described to provide TWTA performance comparable or
superior to conventional SSPA's. The characteristics of the PD scheme is
derived based on the extension of Saleh's model for HPA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4380</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4380</id><created>2011-05-22</created><authors><author><keyname>Gergis</keyname><forenames>Labib Francis</forenames></author></authors><title>Performance of MF-MSK Systems with Pre-distortion Schemes</title><categories>cs.IT math.IT</categories><comments>9 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient RF power amplifiers used in third generation systems require
linearization in order to reduce adjacent channel inter-modulation distortion,
without sacrificing efficiency. Digital baseband predistortion is a highly
cost-effective way to linearize power amplifiers (PAs). New communications
services have created a demand for highly linear high power amplifiers (HPA's).
Traveling Wave Tubes Amplifiers (TWTA) continue to offer the best microwave HPA
performance in terms of power efficiency, size and cost, but lag behind Solid
State Power Amplifiers (SSAP's) in linearity. This paper presents a technique
for improving TWTA linearity. The use of predistorter (PD) linearization
technique is described to provide TWTA performance comparable or superior to
conventional SSPA's. The characteristics of the PD scheme is derived based on
the extension of Saleh's model for HPA. The analysis results of Multi-frequency
Minimum Shift Keying (MF-MSK) in non-linear channels are presented in this
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4385</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4385</id><created>2011-05-22</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author><author><keyname>Moore</keyname><forenames>Joshua</forenames></author><author><keyname>Konig</keyname><forenames>Christian</forenames></author></authors><title>b-Bit Minwise Hashing for Large-Scale Linear SVM</title><categories>cs.LG stat.AP stat.CO stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose to (seamlessly) integrate b-bit minwise hashing
with linear SVM to substantially improve the training (and testing) efficiency
using much smaller memory, with essentially no loss of accuracy. Theoretically,
we prove that the resemblance matrix, the minwise hashing matrix, and the b-bit
minwise hashing matrix are all positive definite matrices (kernels).
Interestingly, our proof for the positive definiteness of the b-bit minwise
hashing kernel naturally suggests a simple strategy to integrate b-bit hashing
with linear SVM. Our technique is particularly useful when the data can not fit
in memory, which is an increasingly critical issue in large-scale machine
learning. Our preliminary experimental results on a publicly available webspam
dataset (350K samples and 16 million dimensions) verified the effectiveness of
our algorithm. For example, the training time was reduced to merely a few
seconds. In addition, our technique can be easily extended to many other linear
and nonlinear machine learning applications such as logistic regression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4394</identifier>
 <datestamp>2011-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4394</id><created>2011-05-22</created><updated>2011-10-20</updated><authors><author><keyname>Chamarthi</keyname><forenames>Harsh Raju</forenames><affiliation>Northeastern University</affiliation></author><author><keyname>Dillinger</keyname><forenames>Peter C.</forenames><affiliation>Northeastern University</affiliation></author><author><keyname>Kaufmann</keyname><forenames>Matt</forenames><affiliation>University of Texas at Austin</affiliation></author><author><keyname>Manolios</keyname><forenames>Panagiotis</forenames><affiliation>Northeastern University</affiliation></author></authors><title>Integrating Testing and Interactive Theorem Proving</title><categories>cs.SE cs.AI cs.LO</categories><comments>In Proceedings ACL2 2011, arXiv:1110.4473</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 70, 2011, pp. 4-19</journal-ref><doi>10.4204/EPTCS.70.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using an interactive theorem prover to reason about programs involves a
sequence of interactions where the user challenges the theorem prover with
conjectures. Invariably, many of the conjectures posed are in fact false, and
users often spend considerable effort examining the theorem prover's output
before realizing this. We present a synergistic integration of testing with
theorem proving, implemented in the ACL2 Sedan (ACL2s), for automatically
generating concrete counterexamples. Our method uses the full power of the
theorem prover and associated libraries to simplify conjectures; this
simplification can transform conjectures for which finding counterexamples is
hard into conjectures where finding counterexamples is trivial. In fact, our
approach even leads to better theorem proving, e.g. if testing shows that a
generalization step leads to a false conjecture, we force the theorem prover to
backtrack, allowing it to pursue more fruitful options that may yield a proof.
The focus of the paper is on the engineering of a synergistic integration of
testing with interactive theorem proving; this includes extending ACL2 with new
functionality that we expect to be of general interest. We also discuss our
experience in using ACL2s to teach freshman students how to reason about their
programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4395</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4395</id><created>2011-05-22</created><authors><author><keyname>Gatterbauer</keyname><forenames>Wolfgang</forenames></author><author><keyname>Meliou</keyname><forenames>Alexandra</forenames></author><author><keyname>Suciu</keyname><forenames>Dan</forenames></author></authors><title>Default-all is dangerous!</title><categories>cs.DB</categories><comments>4 pages, 6 figures, preprint of paper appearing in Proceedings of
  TaPP '11 (3rd USENIX Workshop on the Theory and Practice of Provenance); for
  details see the project page: http://db.cs.washington.edu/causality/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the default-all propagation scheme for database annotations is
dangerous. Dangerous here means that it can propagate annotations to the query
output which are semantically irrelevant to the query the user asked. This is
the result of considering all relationally equivalent queries and returning the
union of their where-provenance in an attempt to define a propagation scheme
that is insensitive to query rewriting. We propose an alternative
query-rewrite-insensitive (QRI) where-provenance called minimum propagation. It
is analogous to the minimum witness basis for why-provenance, straight-forward
to evaluate, and returns all relevant and only relevant annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4408</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4408</id><created>2011-05-23</created><authors><author><keyname>Wang</keyname><forenames>Jian</forenames></author><author><keyname>Shim</keyname><forenames>Byonghyo</forenames></author></authors><title>A Simple Proof of the Mutual Incoherence Condition for Orthogonal
  Matching Pursuit</title><categories>cs.IT math.IT</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a simple proof of the mutual incoherence condition $\mu &lt;
\frac{1}{2K-1}$ under which K-sparse signal can be accurately reconstructed
from a small number of linear measurements using the orthogonal matching
pursuit (OMP) algorithm. Our proof, based on mathematical induction, is built
on an observation that the general step of the OMP process is in essence same
as the initial step since the residual is considered as a new measurement
preserving the sparsity level of an input vector.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4421</identifier>
 <datestamp>2011-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4421</id><created>2011-05-23</created><authors><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>VERIMAG - IMAG</affiliation></author><author><keyname>Corbineau</keyname><forenames>Pierre</forenames><affiliation>VERIMAG - IMAG</affiliation></author></authors><title>On the Generation of Positivstellensatz Witnesses in Degenerate Cases</title><categories>math.LO cs.SC math.AG</categories><comments>To appear in ITP 2011</comments><proxy>ccsd</proxy><journal-ref>Interactive Theorem Proving, Nijmegen : Pays-Bas (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One can reduce the problem of proving that a polynomial is nonnegative, or
more generally of proving that a system of polynomial inequalities has no
solutions, to finding polynomials that are sums of squares of polynomials and
satisfy some linear equality (Positivstellensatz). This produces a witness for
the desired property, from which it is reasonably easy to obtain a formal proof
of the property suitable for a proof assistant such as Coq. The problem of
finding a witness reduces to a feasibility problem in semidefinite programming,
for which there exist numerical solvers. Unfortunately, this problem is in
general not strictly feasible, meaning the solution can be a convex set with
empty interior, in which case the numerical optimization method fails.
Previously published methods thus assumed strict feasibility; we propose a
workaround for this difficulty. We implemented our method and illustrate its
use with examples, including extractions of proofs to Coq.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4424</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4424</id><created>2011-05-23</created><authors><author><keyname>Rodrigues</keyname><forenames>Antonio Wendell De Oliveira</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Guyomarc'H</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Dekeyser</keyname><forenames>Jean-Luc</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author></authors><title>A Modeling Approach based on UML/MARTE for GPU Architecture</title><categories>cs.DC</categories><comments>Symposium en Architectures nouvelles de machines (SympA'14) (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, the High Performance Computing is part of the context of embedded
systems. Graphics Processing Units (GPUs) are more and more used in
acceleration of the most part of algorithms and applications. Over the past
years, not many efforts have been done to describe abstractions of applications
in relation to their target architectures. Thus, when developers need to
associate applications and GPUs, for example, they find difficulty and prefer
using API for these architectures. This paper presents a metamodel extension
for MARTE profile and a model for GPU architectures. The main goal is to
specify the task and data allocation in the memory hierarchy of these
architectures. The results show that this approach will help to generate code
for GPUs based on model transformations using Model Driven Engineering (MDE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4431</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4431</id><created>2011-05-23</created><authors><author><keyname>Chowdhury</keyname><forenames>Mostafa Zaman</forenames></author><author><keyname>Trung</keyname><forenames>Bui Minh</forenames></author><author><keyname>Jang</keyname><forenames>Yeong Min</forenames></author><author><keyname>Kim</keyname><forenames>Young-Il</forenames></author><author><keyname>Ryu</keyname><forenames>Won</forenames></author></authors><title>Service Level Agreement for the QoS Guaranteed Mobile IPTV Services over
  Mobile WiMAX Networks</title><categories>cs.MM cs.NI</categories><comments>6 pages, 5 figures</comments><journal-ref>The Journal of Korea Information and Communications Society
  (KICS), vol.36, no.4, April 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While mobile IPTV services are supported through the mobile WiMAX networks,
there must need some guaranteed bandwidth for the IPTV services especially if
IPTV and non-IPTV services are simultaneously supported by the mobile WiMAX
networks. The quality of an IPTV service definitely depends on the allocated
bandwidth for that channel. However, due to the high quality IPTV services and
to support of huge non-IPTV traffic over mobile WiMAX networks, it is not
possible to guarantee the sufficient amount of the limited mobile WiMAX
bandwidth for the mobile IPTV services every time. A Service Level Agreement
(SLA) between the mobile IPTV service provider and mobile WiMAX network
operator to reserve sufficient bandwidth for the IPTV calls can increase the
satisfaction level of the mobile IPTV users. In this paper, we propose a SLA
negotiation procedure for mobile IPTV users over mobile WiMAX networks. The
Bandwidth Broker controls the allocated bandwidth for IPTV and non-IPTV users.
The proposed dynamically reserved bandwidth for the IPTV services increases the
IPTV user's satisfaction level. The simulation results state that, our proposed
scheme is able to provide better user satisfaction level for the IPTV users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4452</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4452</id><created>2011-05-23</created><authors><author><keyname>von der Weth</keyname><forenames>Christian</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author></authors><title>GutenTag: A Multi-Term Caching Optimized Tag Query Processor for
  Key-Value Based NoSQL Storage Systems</title><categories>cs.IR cs.DB</categories><comments>22 pages, 21 figures, 11 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  NoSQL systems are more and more deployed as back-end infrastructure for
large-scale distributed online platforms like Google, Amazon or Facebook. Their
applicability results from the fact that most services of online platforms
access the stored data objects via their primary key. However, NoSQL systems do
not efficiently support services referring more than one data object, e.g. the
term-based search for data objects. To address this issue we propose our
architecture based on an inverted index on top of a NoSQL system. For queries
comprising more than one term, distributed indices yield a limited performance
in large distributed systems. We propose two extensions to cope with this
challenge. Firstly, we store index entries not only for single term but also
for a selected set of term combinations depending on their popularity derived
from a query history. Secondly, we additionally cache popular keys on gateway
nodes, which are a common concept in real-world systems, acting as interface
for services when accessing data objects in the back end. Our results show that
we can significantly reduces the bandwidth consumption for processing queries,
with an acceptable, marginal increase in the load of the gateway nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4456</identifier>
 <datestamp>2011-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4456</id><created>2011-05-23</created><updated>2011-09-30</updated><authors><author><keyname>Bostan</keyname><forenames>Alin</forenames></author><author><keyname>Chyzak</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>van Hoeij</keyname><forenames>Mark</forenames></author><author><keyname>Pech</keyname><forenames>Lucien</forenames></author></authors><title>Explicit formula for the generating series of diagonal 3D rook paths</title><categories>cs.SC cs.DM math.CO</categories><comments>To appear in &quot;S\'eminaire Lotharingien de Combinatoire&quot;</comments><msc-class>Primary 05A15, 14N10, 33F10, 68W30, Secondary 33C05, 97N80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $a_n$ denote the number of ways in which a chess rook can move from a
corner cell to the opposite corner cell of an $n \times n \times n$
three-dimensional chessboard, assuming that the piece moves closer to the goal
cell at each step. We describe the computer-driven \emph{discovery and proof}
of the fact that the generating series $G(x)= \sum_{n \geq 0} a_n x^n$ admits
the following explicit expression in terms of a Gaussian hypergeometric
function: \[ G(x) = 1 + 6 \cdot \int_0^x \frac{\,\pFq21{1/3}{2/3}{2} {\frac{27
w(2-3w)}{(1-4w)^3}}}{(1-4w)(1-64w)} \, dw.\]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4468</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4468</id><created>2011-05-23</created><authors><author><keyname>Tanrikulu</keyname><forenames>Zuhal</forenames></author><author><keyname>Ozcer</keyname><forenames>Tuna</forenames></author></authors><title>Standardization of information systems development processes and banking
  industry adaptations</title><categories>cs.SE</categories><comments>12 pages; International Journal of Software Engineering &amp;
  Applications (IJSEA), Vol.2, No.2, April 2011</comments><msc-class>68U35, 68N99, 90B90</msc-class><acm-class>D.2.8; D.2.9; K.6.1; K.6.2; K.6.3; K.6.4</acm-class><doi>10.5121/ijsea.2011.2201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the current system development processes of three major
Turkish banks in terms of compliance to internationally accepted system
development and software engineering standards to determine the common process
problems of banks. After an in-depth investigation into system development and
software engineering standards, related process-based standards were selected.
Questions were then prepared covering the whole system development process by
applying the classical Waterfall life cycle model. Each question is made up of
guidance and suggestions from the international system development standards.
To collect data, people from the information technology departments of three
major banks in Turkey were interviewed. Results have been aggregated by
examining the current process status of the three banks together. Problematic
issues were identified using the international system development standards.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4477</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4477</id><created>2011-05-23</created><authors><author><keyname>Gonzalez-Diaz</keyname><forenames>Rocio</forenames></author><author><keyname>Real</keyname><forenames>Pedro</forenames></author></authors><title>On the Cohomology of 3D Digital Images</title><categories>cs.CV</categories><comments>Special Issue: Advances in Discrete Geometry and Topology</comments><journal-ref>Discrete Applied Mathematics, Volume 147, Issues 2-3, 15 April
  2005, Pages 245-263</journal-ref><doi>10.1016/j.dam.2004.09.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for computing the cohomology ring of three--dimensional
(3D) digital binary-valued pictures. We obtain the cohomology ring of a 3D
digital binary--valued picture $I$, via a simplicial complex K(I)topologically
representing (up to isomorphisms of pictures) the picture I. The usefulness of
a simplicial description of the &quot;digital&quot; cohomology ring of 3D digital
binary-valued pictures is tested by means of a small program visualizing the
different steps of the method. Some examples concerning topological thinning,
the visualization of representative (co)cycles of (co)homology generators and
the computation of the cup product on the cohomology of simple pictures are
showed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4479</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4479</id><created>2011-05-23</created><authors><author><keyname>Dronen</keyname><forenames>Nicholas</forenames></author><author><keyname>Lv</keyname><forenames>Qin</forenames></author></authors><title>Return probability and k-step measures</title><categories>physics.soc-ph cs.SI</categories><comments>24 pages, 8 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of return probability -- explored most famously by George
P\'{o}lya on d-dimensional lattices -- has potential as a measure for the
analysis of networks. We present an efficient method for finding return
probability distributions for connected undirected graphs. We argue that return
probability has the same discriminatory power as existing k-step measures -- in
particular, beta centrality (with negative beta), the graph-theoretical power
index (GPI), and subgraph centrality. We compare the running time of our
algorithm to beta centrality and subgraph centrality and find that it is
significantly faster. When return probability is used to measure the same
phenomena as beta centrality, it runs in linear time -- O(n+m), where n and m
are the number of nodes and edges, respectively -- which takes much less time
than either the matrix inversion or the sequence of matrix multiplications
required for calculating the exact or approximate forms of beta centrality,
respectively. We call this form of return probability the P\'{o}lya power index
(PPI). Computing subgraph centrality requires an expensive eigendecomposition
of the adjacency matrix; return probability runs in half the time of the
eigendecomposition on a 2000-node network. These performance improvements are
important because computationally efficient measures are necessary in order to
analyze large networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4480</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4480</id><created>2011-05-23</created><authors><author><keyname>Gonzalez-Diaz</keyname><forenames>Rocio</forenames></author><author><keyname>Jimenez</keyname><forenames>Maria Jose</forenames></author><author><keyname>Medrano</keyname><forenames>Belen</forenames></author><author><keyname>Real</keyname><forenames>Pedro</forenames></author></authors><title>A Tool for Integer Homology Computation: Lambda-At Model</title><categories>cs.CV</categories><comments>Journal Image and Vision Computing, Volume 27 Issue 7, June, 2009</comments><doi>10.1016/j.imavis.2008.10.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we formalize the notion of lambda-AT-model (where $\lambda$ is
a non-null integer) for a given chain complex, which allows the computation of
homological information in the integer domain avoiding using the Smith Normal
Form of the boundary matrices. We present an algorithm for computing such a
model, obtaining Betti numbers, the prime numbers p involved in the invariant
factors of the torsion subgroup of homology, the amount of invariant factors
that are a power of p and a set of representative cycles of generators of
homology mod p, for each p. Moreover, we establish the minimum valid lambda for
such a construction, what cuts down the computational costs related to the
torsion subgroup. The tools described here are useful to determine topological
information of nD structured objects such as simplicial, cubical or simploidal
complexes and are applicable to extract such an information from digital
pictures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4490</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4490</id><created>2011-05-23</created><authors><author><keyname>Auer</keyname><forenames>B. O. Fagginger</forenames></author><author><keyname>Bisseling</keyname><forenames>R. H.</forenames></author></authors><title>A Geometric Approach to Matrix Ordering</title><categories>cs.DS cs.DC</categories><msc-class>05C65, 05C70, 65F05, 65F50, 65Y05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a recursive way to partition hypergraphs which creates and
exploits hypergraph geometry and is suitable for many-core parallel
architectures. Such partitionings are then used to bring sparse matrices in a
recursive Bordered Block Diagonal form (for processor-oblivious parallel LU
decomposition) or recursive Separated Block Diagonal form (for cache-oblivious
sparse matrix-vector multiplication). We show that the quality of the obtained
partitionings and orderings is competitive by comparing obtained fill-in for LU
decomposition with SuperLU (with better results for 8 of the 28 test matrices)
and comparing cut sizes for sparse matrix-vector multiplication with Mondriaan
(with better results for 4 of the 12 test matrices). The main advantage of the
new method is its speed: it is on average 21.6 times faster than Mondriaan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4502</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4502</id><created>2011-05-23</created><updated>2011-07-30</updated><authors><author><keyname>Salath&#xe9;</keyname><forenames>Marcel</forenames></author><author><keyname>Khandelwal</keyname><forenames>Shashank</forenames></author></authors><title>Assessing Vaccination Sentiments with Online Social Media: Implications
  for Infectious Disease Dynamics and Control</title><categories>cs.SI physics.soc-ph q-bio.PE</categories><comments>Accepted for publication in PLoS Computational Biology</comments><doi>10.1371/journal.pcbi.1002199</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is great interest in the dynamics of health behaviors in social
networks and how they affect collective public health outcomes, but measuring
population health behaviors over time and space requires substantial resources.
Here, we use publicly available data from 101,853 users of online social media
collected over a time period of almost six months to measure the
spatio-temporal sentiment towards a new vaccine. We validated our approach by
identifying a strong correlation between sentiments expressed online and CDC-
estimated vaccination rates by region. Analysis of the network of opinionated
users showed that information flows more often between users who share the same
sentiments - and less often between users who do not share the same sentiments
- than expected by chance alone. We also found that most communities are
dominated by either positive or negative sentiments towards the novel vaccine.
Simulations of infectious disease transmission show that if clusters of
negative vaccine sentiments lead to clusters of unprotected individuals, the
likelihood of disease outbreaks are greatly increased. Online social media
provide unprecedented access to data allowing for inexpensive and efficient
tools to identify target areas for intervention efforts and to evaluate their
effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4514</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4514</id><created>2011-05-23</created><authors><author><keyname>Dubrova</keyname><forenames>Elena</forenames></author></authors><title>Synthesis of Parallel Binary Machines</title><categories>cs.CR cs.IT math.IT</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Binary machines are a generalization of Feedback Shift Registers (FSRs) in
which both, feedback and feedforward, connections are allowed and no chain
connection between the register stages is required. In this paper, we present
an algorithm for synthesis of binary machines with the minimum number of stages
for a given degree of parallelization. Our experimental results show that for
sequences with high linear complexity such as complementary, Legendre, or truly
random, parallel binary machines are an order of magnitude smaller than
parallel FSRs generating the same sequence. The presented approach can
potentially be of advantage for any application which requires sequences with
high spectrum efficiency or high security, such as data transmission, wireless
communications, and cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4517</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4517</id><created>2011-05-23</created><authors><author><keyname>Awodele</keyname><forenames>O.</forenames></author><author><keyname>Kuyoro</keyname><forenames>S. O.</forenames></author><author><keyname>Adejumobi</keyname><forenames>A. K.</forenames></author><author><keyname>Awe</keyname><forenames>O.</forenames></author><author><keyname>Makanju</keyname><forenames>O.</forenames></author></authors><title>Citadel E-Learning: A New Dimension to Learning System</title><categories>cs.CY</categories><comments>8 Pages</comments><journal-ref>World of Computer Science and Information Technology Journal
  (WCSIT), Vol. 1, No. 3, 71- 78, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  E-learning has been an important policy for education planners for many years
in developed countries. This policy has been adopted by education in some
developing countries; it is therefore expedient to study its emergence in the
Nigerian education system. The birth of contemporary technology shows that
there is higher requirement for education even in the work force. This has been
an eye opener to importance of Education which conveniently can be achieved
through E-learning. This work presents CITADEL E-learning approach to Nigeria
institutions; its ubiquity, its implementations, its flexibility, portability,
ease of use and feature that are synonymous to the standard of education in
Nigeria and how it can be enhanced to improve learning for both educators and
learners to help them in their learning endeavour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4525</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4525</id><created>2011-05-23</created><authors><author><keyname>Znojil</keyname><forenames>Miloslav</forenames></author></authors><title>Symbolic-manipulation constructions of Hilbert-space metrics in quantum
  mechanics</title><categories>cs.SC quant-ph</categories><comments>12 pp., 2 figures, to be presented to the Computer Algebra in
  Scientific Computing conference (http://www14.in.tum.de/CASC2011/) in Kassel,
  Germany, during September 5 - 9, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of the determination of the Hilbert-space metric which renders a
given Hamiltonian $H$ self-adjoint is addressed from the point of view of
applicability of computer-assisted algebraic manipulations. An exactly solvable
example of the so called Gegenbauerian quantum-lattice oscillator is recalled
for the purpose. Both the construction of suitable metric (basically, the
solution of the Dieudonne's operator equation) and the determination of its
domain of positivity are shown facilitated by the symbolic algebraic
manipulations and by MAPLE-supported numerics and graphics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4537</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4537</id><created>2011-05-20</created><updated>2012-03-01</updated><authors><author><keyname>Braibant</keyname><forenames>Thomas</forenames><affiliation>Universit&#xe9; de Grenoble, LIG, UMR 5217</affiliation></author><author><keyname>Pous</keyname><forenames>Damien</forenames><affiliation>CNRS, LIG, UMR 5217</affiliation></author></authors><title>Deciding Kleene Algebras in Coq</title><categories>cs.LO cs.SC</categories><proxy>LMCS</proxy><acm-class>F 1.1, F 3.1, F.4.1, F.4.3, D 2.4</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 1 (March 2,
  2012) lmcs:1043</journal-ref><doi>10.2168/LMCS-8(1:16)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a reflexive tactic for deciding the equational theory of Kleene
algebras in the Coq proof assistant. This tactic relies on a careful
implementation of efficient finite automata algorithms, so that it solves
casual equations instantaneously and properly scales to larger expressions. The
decision procedure is proved correct and complete: correctness is established
w.r.t. any model by formalising Kozen's initiality theorem; a counter-example
is returned when the given equation does not hold. The correctness proof is
challenging: it involves both a precise analysis of the underlying automata
algorithms and a lot of algebraic reasoning. In particular, we have to
formalise the theory of matrices over a Kleene algebra. We build on the recent
addition of firstorder typeclasses in Coq in order to work efficiently with the
involved algebraic structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4540</identifier>
 <datestamp>2011-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4540</id><created>2011-05-23</created><updated>2011-10-18</updated><authors><author><keyname>Malloy</keyname><forenames>Matthew</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author></authors><title>On the Limits of Sequential Testing in High Dimensions</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>Asilomar 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents results pertaining to sequential methods for support
recovery of sparse signals in noise. Specifically, we show that any sequential
measurement procedure fails provided the average number of measurements per
dimension grows slower then log s / D(f0||f1) where s is the level of sparsity,
and D(f0||f1) the Kullback-Leibler divergence between the underlying
distributions. For comparison, we show any non-sequential procedure fails
provided the number of measurements grows at a rate less than log n /
D(f1||f0), where n is the total dimension of the problem. Lastly, we show that
a simple procedure termed sequential thresholding guarantees exact support
recovery provided the average number of measurements per dimension grows faster
than (log s + log log n) / D(f0||f1), a mere additive factor more than the
lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4549</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4549</id><created>2011-05-23</created><authors><author><keyname>Yousefian</keyname><forenames>Farzad</forenames></author><author><keyname>Nedi&#x107;</keyname><forenames>Angelia</forenames></author><author><keyname>Shanbhag</keyname><forenames>Uday V.</forenames></author></authors><title>On Stochastic Gradient and Subgradient Methods with Adaptive Steplength
  Sequences</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of standard stochastic approximation implementations can vary
significantly based on the choice of the steplength sequence, and in general,
little guidance is provided about good choices. Motivated by this gap, in the
first part of the paper, we present two adaptive steplength schemes for
strongly convex differentiable stochastic optimization problems, equipped with
convergence theory. The first scheme, referred to as a recursive steplength
stochastic approximation scheme, optimizes the error bounds to derive a rule
that expresses the steplength at a given iteration as a simple function of the
steplength at the previous iteration and certain problem parameters. This rule
is seen to lead to the optimal steplength sequence over a prescribed set of
choices. The second scheme, termed as a cascading steplength stochastic
approximation scheme, maintains the steplength sequence as a piecewise-constant
decreasing function with the reduction in the steplength occurring when a
suitable error threshold is met. In the second part of the paper, we allow for
nondifferentiable objective and we propose a local smoothing technique that
leads to a differentiable approximation of the function. Assuming a uniform
distribution on the local randomness, we establish a Lipschitzian property for
the gradient of the approximation and prove that the obtained Lipschitz bound
grows at a modest rate with problem size. This facilitates the development of
an adaptive steplength stochastic approximation framework, which now requires
sampling in the product space of the original measure and the artificially
introduced distribution. The resulting adaptive steplength schemes are applied
to three stochastic optimization problems. We observe that both schemes perform
well in practice and display markedly less reliance on user-defined parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4555</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4555</id><created>2011-05-23</created><authors><author><keyname>Villard</keyname><forenames>Joffrey</forenames><affiliation>Shitz</affiliation></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Secure Lossy Source-Channel Wiretapping with Side Information at the
  Receiving Terminals</title><categories>cs.IT math.IT</categories><comments>10 pages, 5 figures. To be presented at ISIT 2011</comments><doi>10.1109/ISIT.2011.6033710</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of secure lossy source-channel wiretapping with arbitrarily
correlated side informations at both receivers is investigated. This scenario
consists of an encoder (referred to as Alice) that wishes to compress a source
and send it through a noisy channel to a legitimate receiver (referred to as
Bob). In this context, Alice must simultaneously satisfy the desired
requirements on the distortion level at Bob, and the equivocation rate at the
eavesdropper (referred to as Eve). This setting can be seen as a generalization
of the conventional problems of secure source coding with side information at
the decoders, and the wiretap channel. Inner and outer bounds on the
rate-distortion-equivocation region for the case of arbitrary channels and side
informations are derived. In some special cases of interest, it is shown that
separation holds. By means of an appropriate coding, the presence of any
statistical difference among the side informations, the channel noises, and the
distortion at Bob can be fully exploited in terms of secrecy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4582</identifier>
 <datestamp>2011-05-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4582</id><created>2011-05-23</created><authors><author><keyname>Makatchev</keyname><forenames>Maxim</forenames></author><author><keyname>Simmons</keyname><forenames>Reid</forenames></author></authors><title>Perception of Personality and Naturalness through Dialogues by Native
  Speakers of American English and Arabic</title><categories>cs.CL cs.RO</categories><comments>An abridged version is accepted for publication at SIGDIAL 2011</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linguistic markers of personality traits have been studied extensively, but
few cross-cultural studies exist. In this paper, we evaluate how native
speakers of American English and Arabic perceive personality traits and
naturalness of English utterances that vary along the dimensions of verbosity,
hedging, lexical and syntactic alignment, and formality. The utterances are the
turns within dialogue fragments that are presented as text transcripts to the
workers of Amazon's Mechanical Turk. The results of the study suggest that all
four dimensions can be used as linguistic markers of all personality traits by
both language communities. A further comparative analysis shows cross-cultural
differences for some combinations of measures of personality traits and
naturalness, the dimensions of linguistic variability and dialogue acts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4585</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4585</id><created>2011-05-23</created><authors><author><keyname>Seldin</keyname><forenames>Yevgeny</forenames></author><author><keyname>Cesa-Bianchi</keyname><forenames>Nicol&#xf2;</forenames></author><author><keyname>Laviolette</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Auer</keyname><forenames>Peter</forenames></author><author><keyname>Shawe-Taylor</keyname><forenames>John</forenames></author><author><keyname>Peters</keyname><forenames>Jan</forenames></author></authors><title>PAC-Bayesian Analysis of the Exploration-Exploitation Trade-off</title><categories>cs.LG stat.ML</categories><comments>On-line Trading of Exploration and Exploitation 2 - ICML-2011
  workshop. http://explo.cs.ucl.ac.uk/workshop/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a coherent framework for integrative simultaneous analysis of the
exploration-exploitation and model order selection trade-offs. We improve over
our preceding results on the same subject (Seldin et al., 2011) by combining
PAC-Bayesian analysis with Bernstein-type inequality for martingales. Such a
combination is also of independent interest for studies of multiple
simultaneously evolving martingales.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4593</identifier>
 <datestamp>2014-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4593</id><created>2011-05-23</created><updated>2014-08-13</updated><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Vondr&#xe1;k</keyname><forenames>Jan</forenames></author><author><keyname>Zenklusen</keyname><forenames>Rico</forenames></author></authors><title>Submodular Function Maximization via the Multilinear Relaxation and
  Contention Resolution Schemes</title><categories>cs.DM cs.DS</categories><comments>Revision of previous version; extended abstract appeared at STOC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of maximizing a non-negative submodular set function
$f:2^N \rightarrow \mathbb{R}_+$ over a ground set $N$ subject to a variety of
packing type constraints including (multiple) matroid constraints, knapsack
constraints, and their intersections. In this paper we develop a general
framework that allows us to derive a number of new results, in particular when
$f$ may be a non-monotone function. Our algorithms are based on (approximately)
maximizing the multilinear extension $F$ of $f$ over a polytope $P$ that
represents the constraints, and then effectively rounding the fractional
solution. Although this approach has been used quite successfully, it has been
limited in some important ways. We overcome these limitations as follows.
  First, we give constant factor approximation algorithms to maximize $F$ over
a down-closed polytope $P$ described by an efficient separation oracle.
Previously this was known only for monotone functions. For non-monotone
functions, a constant factor was known only when the polytope was either the
intersection of a fixed number of knapsack constraints or a matroid polytope.
Second, we show that contention resolution schemes are an effective way to
round a fractional solution, even when $f$ is non-monotone. In particular,
contention resolution schemes for different polytopes can be combined to handle
the intersection of different constraints. Via LP duality we show that a
contention resolution scheme for a constraint is related to the correlation gap
of weighted rank functions of the constraint. This leads to an optimal
contention resolution scheme for the matroid polytope.
  Our results provide a broadly applicable framework for maximizing linear and
submodular functions subject to independence constraints. We give several
illustrative examples. Contention resolution schemes may find other
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4618</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4618</id><created>2011-05-23</created><authors><author><keyname>Duan</keyname><forenames>Hubert Haoyang</forenames></author></authors><title>Bounding the Fat Shattering Dimension of a Composition Function Class
  Built Using a Continuous Logic Connective</title><categories>cs.LG</categories><comments>Winter 2011 Honours research project done under the supervision of
  Dr. Vladimir Pestov at the University of Ottawa; 35 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We begin this report by describing the Probably Approximately Correct (PAC)
model for learning a concept class, consisting of subsets of a domain, and a
function class, consisting of functions from the domain to the unit interval.
Two combinatorial parameters, the Vapnik-Chervonenkis (VC) dimension and its
generalization, the Fat Shattering dimension of scale e, are explained and a
few examples of their calculations are given with proofs. We then explain
Sauer's Lemma, which involves the VC dimension and is used to prove the
equivalence of a concept class being distribution-free PAC learnable and it
having finite VC dimension.
  As the main new result of our research, we explore the construction of a new
function class, obtained by forming compositions with a continuous logic
connective, a uniformly continuous function from the unit hypercube to the unit
interval, from a collection of function classes. Vidyasagar had proved that
such a composition function class has finite Fat Shattering dimension of all
scales if the classes in the original collection do; however, no estimates of
the dimension were known. Using results by Mendelson-Vershynin and Talagrand,
we bound the Fat Shattering dimension of scale e of this new function class in
terms of the Fat Shattering dimensions of the collection's classes.
  We conclude this report by providing a few open questions and future research
topics involving the PAC learning model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4665</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4665</id><created>2011-05-23</created><authors><author><keyname>Kudekar</keyname><forenames>Shrinivas</forenames></author><author><keyname>Johnson</keyname><forenames>Jason K.</forenames></author><author><keyname>Chertkov</keyname><forenames>Misha</forenames></author></authors><title>Improved Linear Programming Decoding using Frustrated Cycles</title><categories>cs.IT math.IT</categories><comments>5 Pages, Submitted to Information Theory Workshop (ITW) 2011</comments><report-no>LA-UR 11-02962</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider transmission over a binary-input additive white Gaussian noise
channel using low-density parity-check codes. One of the most popular
techniques for decoding low-density parity-check codes is the linear
programming decoder. In general, the linear programming decoder is suboptimal.
I.e., the word error rate is higher than the optimal, maximum a posteriori
decoder.
  In this paper we present a systematic approach to enhance the linear program
decoder. More precisely, in the cases where the linear program outputs a
fractional solution, we give a simple algorithm to identify frustrated cycles
which cause the output of the linear program to be fractional. Then adding
these cycles, adaptively to the basic linear program, we show improved word
error rate performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4682</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4682</id><created>2011-05-24</created><authors><author><keyname>Pourhaghani</keyname><forenames>Asieh</forenames></author></authors><title>A note on Solving Parametric Polynomial Systems</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lazard and Rouillier in [9], by introducing the concept of discriminant
variety, have described a new and efficient algorithm for solving parametric
polynomial systems. In this paper we modify this algorithm, and we show that
with our improvements the output of our algorithm is always minimal and it does
not need to compute the radical of ideals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4683</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4683</id><created>2011-05-24</created><authors><author><keyname>Wu</keyname><forenames>Xiaofu</forenames></author><author><keyname>Zhao</keyname><forenames>Chunming</forenames></author><author><keyname>You</keyname><forenames>Xiaohu</forenames></author></authors><title>On the BCJR Algorithm for Asynchronous Physical-layer Network Coding</title><categories>cs.IT math.IT</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In practical asynchronous bi-directional relaying, symbols transmitted by two
source nodes cannot arrive at the relay with perfect symbol alignment and the
symbol-asynchronous multiple-access channel (MAC) should be seriously
considered. Recently, Lu et al. proposed a Tanner-graph representation of
symbol-asynchronous MAC with rectangular-pulse shaping and further developed
the message-passing algorithm for optimal decoding of the asynchronous
physical-layer network coding. In this paper, we present a general channel
model for the asynchronous multiple-access channel with arbitrary
pulse-shaping. Then, the Bahl, Cocke, Jelinek, and Raviv (BCJR) algorithm is
developed for optimal decoding of asynchronous MAC channel. This formulation
can be well employed to develop various low-complexity algorithms, such as
Log-MAP algorithm, Max-Log-MAP algorithm, which are favorable in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4701</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4701</id><created>2011-05-24</created><updated>2011-09-08</updated><authors><author><keyname>Poggio</keyname><forenames>Tomaso</forenames></author><author><keyname>Voinea</keyname><forenames>Stephen</forenames></author><author><keyname>Rosasco</keyname><forenames>Lorenzo</forenames></author></authors><title>Online Learning, Stability, and Stochastic Gradient Descent</title><categories>cs.LG</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In batch learning, stability together with existence and uniqueness of the
solution corresponds to well-posedness of Empirical Risk Minimization (ERM)
methods; recently, it was proved that CV_loo stability is necessary and
sufficient for generalization and consistency of ERM. In this note, we
introduce CV_on stability, which plays a similar note in online learning. We
show that stochastic gradient descent (SDG) with the usual hypotheses is CVon
stable and we then discuss the implications of CV_on stability for convergence
of SGD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4702</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4702</id><created>2011-05-24</created><authors><author><keyname>Selke</keyname><forenames>Joachim</forenames></author><author><keyname>Balke</keyname><forenames>Wolf-Tilo</forenames></author></authors><title>Exploiting Conceptual Knowledge for Querying Information Systems</title><categories>cs.IR cs.DB</categories><comments>International Conference on Philosophy's Relevance in Information
  Science (PRIS), Paderborn, Germany, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whereas today's information systems are well-equipped for efficient query
handling, their strict mathematical foundations hamper their use for everyday
tasks. In daily life, people expect information to be offered in a personalized
and focused way. But currently, personalization in digital systems still only
takes explicit knowledge into account and does not yet process conceptual
information often naturally implied by users. We discuss how to bridge the gap
between users and today's systems, building on results from cognitive
psychology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4705</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4705</id><created>2011-05-24</created><authors><author><keyname>Kaiser</keyname><forenames>Marcus</forenames></author></authors><title>A Tutorial in Connectome Analysis: Topological and Spatial Features of
  Brain Networks</title><categories>q-bio.NC cs.SI physics.soc-ph</categories><comments>Neuroimage, in press</comments><journal-ref>Neuroimage. 2011 Aug 1;57(3):892-907</journal-ref><doi>10.1016/j.neuroimage.2011.05.025</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High-throughput methods for yielding the set of connections in a neural
system, the connectome, are now being developed. This tutorial describes ways
to analyze the topological and spatial organization of the connectome at the
macroscopic level of connectivity between brain regions as well as the
microscopic level of connectivity between neurons. We will describe topological
features at three different levels: the local scale of individual nodes, the
regional scale of sets of nodes, and the global scale of the complete set of
nodes in a network. Such features can be used to characterize components of a
network and to compare different networks, e.g. the connectome of patients and
control subjects for clinical studies. At the global scale, different types of
networks can be distinguished and we will describe Erd\&quot;os-R\'enyi random,
scale-free, small-world, modular, and hierarchical archetypes of networks.
Finally, the connectome also has a spatial organization and we describe methods
for analyzing wiring lengths of neural systems. As an introduction for new
researchers in the field of connectome analysis, we discuss the benefits and
limitations of each analysis approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4712</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4712</id><created>2011-05-24</created><authors><author><keyname>Chennamma</keyname><forenames>H. R.</forenames></author><author><keyname>Rangarajan</keyname><forenames>Lalitha</forenames></author></authors><title>Image Splicing Detection Using Inherent Lens Radial Distortion</title><categories>cs.CV</categories><comments>10 pages, 23 figures, 6 tables, Published in IJCSI</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 7,
  Issue 6, November 2010, pp. 149-158, ISSN (OnlinePrint): 1694-0814</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image splicing is a common form of image forgery. Such alterations may leave
no visual clues of tampering. In recent works camera characteristics
consistency across the image has been used to establish the authenticity and
integrity of digital images. Such constant camera characteristic properties are
inherent from camera manufacturing processes and are unique. The majority of
digital cameras are equipped with spherical lens and this introduces radial
distortions on images. This aberration is often disturbed and fails to be
consistent across the image, when an image is spliced. This paper describes the
detection of splicing operation on images by estimating radial distortion from
different portions of the image using line-based calibration. For the first
time, the detection of image splicing through the verification of consistency
of lens radial distortion has been explored in this paper. The conducted
experiments demonstrate the efficacy of our proposed approach for the detection
of image splicing on both synthetic and real images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4725</identifier>
 <datestamp>2013-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4725</id><created>2011-05-24</created><authors><author><keyname>Akhavi</keyname><forenames>Ali</forenames></author><author><keyname>Klimann</keyname><forenames>Ines</forenames></author><author><keyname>Lombardy</keyname><forenames>Sylvain</forenames></author><author><keyname>Mairesse</keyname><forenames>Jean</forenames></author><author><keyname>Picantin</keyname><forenames>Matthieu</forenames></author></authors><title>On the Finiteness Problem for Automaton (Semi)groups</title><categories>cs.FL math.GR</categories><msc-class>68R99 (Primary) 20F10 (Secondary)</msc-class><acm-class>F.4.1</acm-class><doi>10.1142/S021819671250052X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses a decision problem highlighted by Grigorchuk,
Nekrashevich, and Sushchanskii, namely the finiteness problem for automaton
(semi)groups.
  For semigroups, we give an effective sufficient but not necessary condition
for finiteness and, for groups, an effective necessary but not sufficient
condition. The efficiency of the new criteria is demonstrated by testing all
Mealy automata with small stateset and alphabet. Finally, for groups, we
provide a necessary and sufficient condition that does not directly lead to a
decision procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4736</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4736</id><created>2011-05-24</created><authors><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author><author><keyname>Leydesdorff</keyname><forenames>Loet</forenames></author><author><keyname>Walch-Solimena</keyname><forenames>Christiane</forenames></author><author><keyname>Ettl</keyname><forenames>Christoph</forenames></author></authors><title>Mapping excellence in the geography of science: An approach based on
  Scopus data</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As research becomes an ever more globalized activity, there is growing
interest in national and international comparisons of standards and quality in
different countries and regions. A sign for this trend is the increasing
interest in rankings of universities according to their research performance,
both inside but also outside the scientific environment. New methods presented
in this paper, enable us to map centers of excellence around the world using
programs that are freely available. Based on Scopus data, field-specific
excellence can be identified and agglomerated in regions and cities where
recently highly-cited papers were published. Differences in performance rates
can be visualized on the map using colors and sizes of the marks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4737</identifier>
 <datestamp>2013-03-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4737</id><created>2011-05-24</created><updated>2013-03-13</updated><authors><author><keyname>Maslowski</keyname><forenames>Bohdan</forenames></author><author><keyname>Veverka</keyname><forenames>Petr</forenames></author></authors><title>Sufficient Stochastic Maximum Principle for Discounted Control Problem</title><categories>math.OC cs.SY math.PR</categories><msc-class>60H10, 93E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, the sufficient Pontryagin's maximum principle for infinite
horizon discounted stochastic control problem is established. The sufficiency
is ensured by an additional assumption of concavity of the Hamiltonian
function. Throughout the paper, it is assumed that the control domain U is a
convex set and the control may enter the diffusion term of the state equation.
The general results are applied to the controlled stochastic logistic equation
of population dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4764</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4764</id><created>2011-05-24</created><authors><author><keyname>Barhoumi</keyname><forenames>Alia</forenames></author><author><keyname>Sa&#xef;di</keyname><forenames>Abdelkader</forenames></author></authors><title>Theorical and Numerical Analysis of the Rapid Pointwise Stabilization of
  Coupled String-Beam Systems</title><categories>math.OC cs.SY math.AP</categories><comments>10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a pointwise stabilization problem for a coupled wave and plate
equations. We prove under rather general assumptions, that such systems can
stabilized so as to have arbitrarily high decay rates and are exactly
controllable. We propose a numerical approximation of the model and we study
numerically the construction of the feedbak law leading to exponential decay
with arbtrarily large rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4770</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4770</id><created>2011-05-24</created><authors><author><keyname>Guttmann-Beck</keyname><forenames>Nili</forenames></author><author><keyname>Hassin</keyname><forenames>Refael</forenames></author></authors><title>Minimum diameter and cycle-diameter orientations on planar graphs</title><categories>cs.DM cs.CC</categories><msc-class>68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G be an edge weighted undirected graph. For every pair of nodes consider
the shortest cycle containing these nodes in G. The cycle diameter of G is the
maximum length of a cycle in this set. Let H be a directed graph obtained by
directing the edges of G. The cycle diameter of H is similarly defined except
for that cycles are replaced by directed closed walks. Is there always an
orientation H of G whose cycle diameter is bounded by a constant times the
cycle diameter of G? We prove this property for planar graphs. These results
have implications on the problem of approximating an orientation with minimum
diameter
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4780</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4780</id><created>2011-05-24</created><updated>2011-10-14</updated><authors><author><keyname>Dolev</keyname><forenames>Danny</forenames></author><author><keyname>Fuegger</keyname><forenames>Matthias</forenames></author><author><keyname>Lenzen</keyname><forenames>Christoph</forenames></author><author><keyname>Schmid</keyname><forenames>Ulrich</forenames></author></authors><title>Fault-tolerant Algorithms for Tick-Generation in Asynchronous Logic:
  Robust Pulse Generation</title><categories>cs.DC cs.AR</categories><comments>52 pages, 7 figures, extended abstract published at SSS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today's hardware technology presents a new challenge in designing robust
systems. Deep submicron VLSI technology introduced transient and permanent
faults that were never considered in low-level system designs in the past.
Still, robustness of that part of the system is crucial and needs to be
guaranteed for any successful product. Distributed systems, on the other hand,
have been dealing with similar issues for decades. However, neither the basic
abstractions nor the complexity of contemporary fault-tolerant distributed
algorithms match the peculiarities of hardware implementations. This paper is
intended to be part of an attempt striving to overcome this gap between theory
and practice for the clock synchronization problem. Solving this task
sufficiently well will allow to build a very robust high-precision clocking
system for hardware designs like systems-on-chips in critical applications. As
our first building block, we describe and prove correct a novel Byzantine
fault-tolerant self-stabilizing pulse synchronization protocol, which can be
implemented using standard asynchronous digital logic. Despite the strict
limitations introduced by hardware designs, it offers optimal resilience and
smaller complexity than all existing protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4812</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4812</id><created>2011-05-24</created><authors><author><keyname>Windsor</keyname><forenames>Alistair J.</forenames></author></authors><title>Enumerating ODE Equivalent Homogeneous Networks</title><categories>math.DS cs.DM</categories><comments>11 pages, 4 figures, 3 tables</comments><msc-class>34C15, 34A34</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an simple criterion for ODE equivalence in identical edge homogeneous
coupled cell networks. This allows us to give a simple proof of Theorem 10.3 of
Aquiar and Dias &quot;Minimal Coupled Cell Networks&quot;, which characterizes minimal
identical edge homogeneous coupled cell networks. Using our criterion we give a
formula for counting homogeneous coupled cell networks up to ODE equivalence.
Our criterion is purely graph theoretic and makes no explicit use of linear
algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4868</identifier>
 <datestamp>2011-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4868</id><created>2011-05-24</created><authors><author><keyname>Mas</keyname><forenames>Massimiliano Dal</forenames></author></authors><title>Search for Hidden Knowledge in Collective Intelligence dealing
  Indeterminacy Ontology of Folksonomy with Linguistic Pragmatics and Quantum
  Logic</title><categories>cs.IR</categories><comments>17 pages, 7 figures, 2 tables; for details see:
  http://www.maxdalmas.com</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information retrieval is not only the most frequent application executed on
the Web but it is also the base of different types of applications. Considering
collective intelligence of groups of individuals as a framework for evaluating
and incorporating new experiences and information we often cannot retrieve such
knowledge being tacit. Tacit knowledge underlies many competitive capabilities
and it is hard to articulate on discrete ontology structure. It is unstructured
or unorganized, and therefore remains hidden. Developing generic solutions that
can find the hidden knowledge is extremely complex. Moreover this will be a
great challenge for the developers of semantic technologies. This work aims to
explore ways to make explicit and available the tacit knowledge hidden in the
collective intelligence of a collaborative environment within organizations.
The environment was defined by folksonomies supported by a faceted semantic
search. Vector space model which incorporates an analogy with the mathematical
apparatus of quantum theory is adopted for the representation and manipulation
of the meaning of folksonomy. Vector space retrieval has been proven efficiency
when there isn't a data behavioural because it bears ranking algorithms
involving a small number of types of elements and few operations. A solution to
find what the user has in mind when posing a query could be based on &quot;joint
meaning&quot; understood as a joint construal of the creator of the contents and the
reader of the contents. The joint meaning was proposed to deal with vagueness
on ontology of folksonomy indeterminacy, incompleteness and inconsistencies on
collective intelligence. A proof-of concept prototype was built for
collaborative environment as evolution of the actual social networks (like
Facebook, LinkedIn,..) using the information visualization on a RIA application
with Semantic Web techniques and technologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4880</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4880</id><created>2011-05-24</created><updated>2012-07-11</updated><authors><author><keyname>Bj&#xf6;rnson</keyname><forenames>Emil</forenames></author><author><keyname>Bengtsson</keyname><forenames>Mats</forenames></author><author><keyname>Ottersten</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Pareto Characterization of the Multicell MIMO Performance Region With
  Simple Receivers</title><categories>cs.IT math.IT</categories><comments>Published in IEEE Transactions on Signal Processing, 6 pages, 6
  figures</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 60, no. 8, pp.
  4464-4469, August 2012</journal-ref><doi>10.1109/TSP.2012.2199309</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the performance region of a general multicell downlink scenario with
multiantenna transmitters, hardware impairments, and low-complexity receivers
that treat interference as noise. The Pareto boundary of this region describes
all efficient resource allocations, but is generally hard to compute. We
propose a novel explicit characterization that gives Pareto optimal transmit
strategies using a set of positive parameters---fewer than in prior work. We
also propose an implicit characterization that requires even fewer parameters
and guarantees to find the Pareto boundary for every choice of parameters, but
at the expense of solving quasi-convex optimization problems. The merits of the
two characterizations are illustrated for interference channels and ideal
network multiple-input multiple-output (MIMO).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4881</identifier>
 <datestamp>2012-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4881</id><created>2011-05-24</created><updated>2012-10-10</updated><authors><author><keyname>Gross</keyname><forenames>Elizabeth</forenames></author><author><keyname>Petrovi&#x107;</keyname><forenames>Sonja</forenames></author><author><keyname>Verschelde</keyname><forenames>Jan</forenames></author></authors><title>PHCpack in Macaulay2</title><categories>math.AG cs.MS cs.SC math.AC</categories><comments>5 pages, exposition and examples improved</comments><msc-class>65H10 (Primary) 14Q99 (Secondary) 68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Macaulay2 package PHCpack.m2 provides an interface to PHCpack, a
general-purpose polynomial system solver that uses homotopy continuation. The
main method is a numerical blackbox solver which is implemented for all Laurent
systems. The package also provides a fast mixed volume computation, the ability
to filter solutions, homotopy path tracking, and a numerical irreducible
decomposition method. As the size of many problems in applied algebraic
geometry often surpasses the capabilities of symbolic software, this package
will be of interest to those working on problems involving large polynomial
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4910</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4910</id><created>2011-05-24</created><updated>2012-04-15</updated><authors><author><keyname>Ahmadi</keyname><forenames>Behzad</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author></authors><title>Robust Coding for Lossy Computing with Observation Costs</title><categories>cs.IT math.IT</categories><comments>This manuscript has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An encoder wishes to minimize the bit rate necessary to guarantee that a
decoder is able to calculate a symbol-wise function of a sequence available
only at the encoder and a sequence that can be measured only at the decoder.
This classical problem, first studied by Yamamoto, is addressed here by
including two new aspects: (i) The decoder obtains noisy measurements of its
sequence, where the quality of such measurements can be controlled via a
cost-constrained &quot;action&quot; sequence, which is taken at the decoder or at the
encoder; (ii) Measurement at the decoder may fail in a way that is
unpredictable to the encoder, thus requiring robust encoding. The considered
scenario generalizes known settings such as the Heegard-Berger-Kaspi and the
&quot;source coding with a vending machine&quot; problems. The rate-distortion-cost
function is derived in relevant special cases, along with general upper and
lower bounds. Numerical examples are also worked out to obtain further insight
into the optimal system design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4924</identifier>
 <datestamp>2011-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4924</id><created>2011-05-24</created><updated>2011-09-07</updated><authors><author><keyname>Allard</keyname><forenames>William K.</forenames></author><author><keyname>Chen</keyname><forenames>Guangliang</forenames></author><author><keyname>Maggioni</keyname><forenames>Mauro</forenames></author></authors><title>Multiscale Geometric Methods for Data Sets II: Geometric
  Multi-Resolution Analysis</title><categories>math.MG cs.DS stat.ML</categories><comments>Re-formatted using AMS style</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data sets are often modeled as point clouds in $R^D$, for $D$ large. It is
often assumed that the data has some interesting low-dimensional structure, for
example that of a $d$-dimensional manifold $M$, with $d$ much smaller than $D$.
When $M$ is simply a linear subspace, one may exploit this assumption for
encoding efficiently the data by projecting onto a dictionary of $d$ vectors in
$R^D$ (for example found by SVD), at a cost $(n+D)d$ for $n$ data points. When
$M$ is nonlinear, there are no &quot;explicit&quot; constructions of dictionaries that
achieve a similar efficiency: typically one uses either random dictionaries, or
dictionaries obtained by black-box optimization. In this paper we construct
data-dependent multi-scale dictionaries that aim at efficient encoding and
manipulating of the data. Their construction is fast, and so are the algorithms
that map data points to dictionary coefficients and vice versa. In addition,
data points are guaranteed to have a sparse representation in terms of the
dictionary. We think of dictionaries as the analogue of wavelets, but for
approximating point clouds rather than functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4927</identifier>
 <datestamp>2011-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4927</id><created>2011-05-25</created><authors><author><keyname>Halamek</keyname><forenames>Jan</forenames></author><author><keyname>Bocharova</keyname><forenames>Vera</forenames></author><author><keyname>Arugula</keyname><forenames>Mary A.</forenames></author><author><keyname>Strack</keyname><forenames>Guinevere</forenames></author><author><keyname>Privman</keyname><forenames>Vladimir</forenames></author><author><keyname>Katz</keyname><forenames>Evgeny</forenames></author></authors><title>Realization and Properties of Biochemical-Computing Biocatalytic XOR
  Gate Based on Enzyme Inhibition by a Substrate</title><categories>cond-mat.soft cs.ET physics.bio-ph q-bio.MN</categories><journal-ref>J. Phys. Chem. B 115, 9838-9845 (2011)</journal-ref><doi>10.1021/jp2041372</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a realization of the XOR logic gate in a process biocatalyzed by
an enzyme (here horseradish peroxidase: HRP), the function of which can be
inhibited by a substrate (hydrogen peroxide for HRP), when the latter is
inputted at large enough concentrations. A model is developed for describing
such systems in an approach suitable for evaluation of the analog noise
amplification properties of the gate. The obtained data are fitted for gate
quality evaluation within the developed model, and we discuss aspects of
devising XOR gates for functioning in &quot;biocomputing&quot; systems utilizing
biomolecules for information processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4931</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4931</id><created>2011-05-25</created><updated>2011-05-25</updated><authors><author><keyname>Fabila-Monroy</keyname><forenames>Ruy</forenames></author><author><keyname>Wood</keyname><forenames>David R.</forenames></author></authors><title>The chromatic number of the convex segment disjointness graph</title><categories>math.CO cs.CG</categories><comments>XIV Spanish Meeting on Computational Geometry Alcal\'a de Henares,
  Spain, June 27--30, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $P$ be a set of $n$ points in general and convex position in the plane.
Let $D_n$ be the graph whose vertex set is the set of all line segments with
endpoints in $P$, where disjoint segments are adjacent. The chromatic number of
this graph was first studied by Araujo et al. [\emph{CGTA}, 2005]. The previous
best bounds are $\frac{3n}{4}\leq\chi(D_n) &lt;n-\sqrt{\frac{n}{2}}$ (ignoring
lower order terms). In this paper we improve the lower bound to $\chi(D_n)\geq
n-\sqrt{2n}$, to conclude a near-tight bound on $\chi(D_n)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4936</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4936</id><created>2011-05-25</created><authors><author><keyname>Andrecut</keyname><forenames>M.</forenames></author></authors><title>Sparse Random Approximation and Lossy Compression</title><categories>physics.data-an cs.CR</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a method for sparse signal approximation, which is based on the
correlation of the target signal with a pseudo-random signal, and uses a
modification of the greedy matching pursuit algorithm. We show that this
approach provides an efficient encoding-decoding method, which can be used also
for lossy compression and encryption purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4953</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4953</id><created>2011-05-25</created><authors><author><keyname>Corlay</keyname><forenames>Sylvain</forenames><affiliation>LPMA</affiliation></author></authors><title>A fast nearest neighbor search algorithm based on vector quantization</title><categories>cs.DS math.PR</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we propose a new fast nearest neighbor search algorithm,
based on vector quantization. Like many other branch and bound search
algorithms [1,10], a preprocessing recursively partitions the data set into
disjointed subsets until the number of points in each part is small enough. In
doing so, a search-tree data structure is built. This preliminary recursive
data-set partition is based on the vector quantization of the empirical
distribution of the initial data-set. Unlike previously cited methods, this
kind of partitions does not a priori allow to eliminate several brother nodes
in the search tree with a single test. To overcome this difficulty, we propose
an algorithm to reduce the number of tested brother nodes to a minimal list
that we call &quot;friend Voronoi cells&quot;. The complete description of the method
requires a deeper insight into the properties of Delaunay triangulations and
Voronoi diagrams
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4958</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4958</id><created>2011-05-25</created><authors><author><keyname>Mawussi</keyname><forenames>Kwamiwi</forenames><affiliation>LURPA</affiliation></author><author><keyname>Tapie</keyname><forenames>Laurent Pierre</forenames><affiliation>LURPA</affiliation></author></authors><title>A Knowledge base model for complex forging die machining</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>Computers &amp; Industrial Engineering 61 (2011) pp. 84-97</journal-ref><doi>10.1016/j.cie.2011.02.016</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent evolutions on forging process induce more complex shape on forging
die. These evolutions, combined with High Speed Machining (HSM) process of
forging die lead to important increase in time for machining preparation. In
this context, an original approach for generating machining process based on
machining knowledge is proposed in this paper. The core of this approach is to
decompose a CAD model of complex forging die in geometric features.
Technological data and topological relations are aggregated to a geometric
feature in order to create machining features. Technological data, such as
material, surface roughness and form tolerance are defined during forging
process and dies design. These data are used to choose cutting tools and
machining strategies. Topological relations define relative positions between
the surfaces of the die CAD model. After machining features identification
cutting tools and machining strategies currently used in HSM of forging die,
are associated to them in order to generate machining sequences. A machining
process model is proposed to formalize the links between information imbedded
in the machining features and the parameters of cutting tools and machining
strategies. At last machining sequences are grouped and ordered to generate the
complete die machining process. In this paper the identification of geometrical
features is detailed. Geometrical features identification is based on machining
knowledge formalization which is translated in the generation of maps from STL
models. A map based on the contact area between cutting tools and die shape
gives basic geometrical features which are connected or not according to the
continuity maps. The proposed approach is illustrated by an application on an
industrial study case which was accomplished as part of collaboration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4965</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4965</id><created>2011-05-25</created><authors><author><keyname>Wang</keyname><forenames>Lin</forenames></author><author><keyname>Li</keyname><forenames>Xiang</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Qing</forenames></author><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Zhang</keyname><forenames>Kan</forenames></author></authors><title>Evolution of scaling emergence in large-scale spatial epidemic spreading</title><categories>physics.soc-ph cs.SI physics.data-an q-bio.PE</categories><comments>24pages, 7figures, accepted by PLoS ONE</comments><doi>10.1371/journal.pone.0021197</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Background: Zipf's law and Heaps' law are two representatives of the scaling
concepts, which play a significant role in the study of complexity science. The
coexistence of the Zipf's law and the Heaps' law motivates different
understandings on the dependence between these two scalings, which is still
hardly been clarified.
  Methodology/Principal Findings: In this article, we observe an evolution
process of the scalings: the Zipf's law and the Heaps' law are naturally shaped
to coexist at the initial time, while the crossover comes with the emergence of
their inconsistency at the larger time before reaching a stable state, where
the Heaps' law still exists with the disappearance of strict Zipf's law. Such
findings are illustrated with a scenario of large-scale spatial epidemic
spreading, and the empirical results of pandemic disease support a universal
analysis of the relation between the two laws regardless of the biological
details of disease. Employing the United States(U.S.) domestic air
transportation and demographic data to construct a metapopulation model for
simulating the pandemic spread at the U.S. country level, we uncover that the
broad heterogeneity of the infrastructure plays a key role in the evolution of
scaling emergence.
  Conclusions/Significance: The analyses of large-scale spatial epidemic
spreading help understand the temporal evolution of scalings, indicating the
coexistence of the Zipf's law and the Heaps' law depends on the collective
dynamics of epidemic processes, and the heterogeneity of epidemic spread
indicates the significance of performing targeted containment strategies at the
early time of a pandemic disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4971</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4971</id><created>2011-05-25</created><authors><author><keyname>Castillo</keyname><forenames>P. A.</forenames></author><author><keyname>Arenas</keyname><forenames>M. G.</forenames></author><author><keyname>Mora</keyname><forenames>A. M.</forenames></author><author><keyname>Laredo</keyname><forenames>J. L. J.</forenames></author><author><keyname>Romero</keyname><forenames>G.</forenames></author><author><keyname>Rivas</keyname><forenames>V. M</forenames></author><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author></authors><title>Distributed Evolutionary Computation using REST</title><categories>cs.NE</categories><comments>Paper 3 for the First International Workshop of Distributed
  Evolutionary computation in Informal Environments</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper analises distributed evolutionary computation based on the
Representational State Transfer (REST) protocol, which overlays a farming model
on evolutionary computation. An approach to evolutionary distributed
optimisation of multilayer perceptrons (MLP) using REST and language Perl has
been done. In these experiments, a master-slave based evolutionary algorithm
(EA) has been implemented, where slave processes evaluate the costly fitness
function (training a MLP to solve a classification problem). Obtained results
show that the parallel version of the developed programs obtains similar or
better results using much less time than the sequential version, obtaining a
good speedup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4978</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4978</id><created>2011-05-25</created><authors><author><keyname>Castillo</keyname><forenames>P. A.</forenames></author><author><keyname>Bernier</keyname><forenames>J. L.</forenames></author><author><keyname>Arenas</keyname><forenames>M. G.</forenames></author><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author><author><keyname>Garcia-Sanchez</keyname><forenames>P.</forenames></author></authors><title>SOAP vs REST: Comparing a master-slave GA implementation</title><categories>cs.NE</categories><comments>Paper 2 for the First International Workshop of Distributed
  Evolutionary computation in Informal Environments</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, a high-level comparison of both SOAP (Simple Object Access
Protocol) and REST (Representational State Transfer) is made. These are the two
main approaches for interfacing to the web with web services. Both approaches
are different and present some advantages and disadvantages for interfacing to
web services: SOAP is conceptually more difficult (has a steeper learning
curve) and more &quot;heavy-weight&quot; than REST, although it lacks of standards
support for security. In order to test their eficiency (in time), two
experiments have been performed using both technologies: a client-server model
implementation and a master-slave based genetic algorithm (GA). The results
obtained show clear differences in time between SOAP and REST implementations.
Although both techniques are suitable for developing parallel systems, SOAP is
heavier than REST, mainly due to the verbosity of SOAP communications (XML
increases the time taken to parse the messages).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4989</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4989</id><created>2011-05-25</created><authors><author><keyname>Ostergaard</keyname><forenames>Jan</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author></authors><title>Incremental Refinement using a Gaussian Test Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear at IEEE International Symposium on Information
  Theory (ISIT), August 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The additive rate-distortion function (ARDF) was developed in order to
universally bound the rate loss in the Wyner-Ziv problem, and has since then
been instrumental in e.g., bounding the rate loss in successive refinements,
universal quantization, and other multi-terminal source coding settings. The
ARDF is defined as the minimum mutual information over an additive test channel
followed by estimation. In the limit of high resolution, the ADRF coincides
with the true RDF for many sources and fidelity criterions. In the other
extreme, i.e., the limit of low resolutions, the behavior of the ARDF has not
previously been rigorously addressed. In this work, we consider the special
case of quadratic distortion and where the noise in the test channel is
Gaussian distributed. We first establish a link to the I-MMSE relation of Guo
et al. and use this to show that for any source the slope of the ARDF near zero
rate, converges to the slope of the Gaussian RDF near zero rate. We then
consider the multiplicative rate loss of the ARDF, and show that for bursty
sources it may be unbounded, contrary to the additive rate loss, which is upper
bounded by 1/2 bit for all sources. We finally show that unconditional
incremental refinement, i.e., where each refinement is encoded independently of
the other refinements, is ARDF optimal in the limit of low resolution,
independently of the source distribution. Our results also reveal under which
conditions linear estimation is ARDF optimal in the low rate regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4991</identifier>
 <datestamp>2012-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4991</id><created>2011-05-25</created><updated>2012-10-25</updated><authors><author><keyname>Safaka</keyname><forenames>Iris</forenames></author><author><keyname>Siavoshani</keyname><forenames>Mahdi J.</forenames></author><author><keyname>Pulleti</keyname><forenames>Uday</forenames></author><author><keyname>Atsan</keyname><forenames>Emre</forenames></author><author><keyname>Fragouli</keyname><forenames>Christina</forenames></author><author><keyname>Argyraki</keyname><forenames>Katerina</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author></authors><title>Exchanging Secrets without Using Cryptography</title><categories>cs.CR cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem where a group of n nodes, connected to the same
broadcast channel (e.g., a wireless network), want to generate a common secret
bitstream, in the presence of an adversary Eve, who tries to obtain information
on the bitstream. We assume that the nodes initially share a (small) piece of
information, but do not have access to any out-of-band channel. We ask the
question: can this problem be solved without relying on Eve's computational
limitations, i.e., without using any form of public-key cryptography?
  We propose a secret-agreement protocol, where the n nodes of the group keep
exchanging bits until they have all agreed on a bit sequence that Eve cannot
reconstruct with very high probability. In this task, the nodes are assisted by
a small number of interferers, whose role is to create channel noise in a way
that bounds the amount of information Eve can overhear. Our protocol has
polynomial-time complexity and requires no changes to the physical or MAC layer
of network devices.
  First, we formally show that, under standard theoretical assumptions, our
protocol is information-theoretically secure, achieves optimal
secret-generation rate for n = 2 nodes, and scales well to an arbitrary number
of nodes. Second, we adapt our protocol to a small wireless 14-square-meter
testbed; we experimentally show that, if Eve uses a standard wireless physical
layer and is not too close to any of the nodes, 8 nodes can achieve a
secret-generation rate of 38 Kbps. To the best of our knowledge, ours is the
first experimental demonstration of information-theoretic secret exchange on a
wireless network at a rate beyond a few tens of bits per second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4995</identifier>
 <datestamp>2012-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4995</id><created>2011-05-25</created><updated>2012-02-15</updated><authors><author><keyname>Mannor</keyname><forenames>Shie</forenames><affiliation>EE-Technion</affiliation></author><author><keyname>Perchet</keyname><forenames>Vianney</forenames><affiliation>CMLA</affiliation></author><author><keyname>Stoltz</keyname><forenames>Gilles</forenames><affiliation>DMA, GREGH, INRIA Paris - Rocquencourt</affiliation></author></authors><title>Robust approachability and regret minimization in games with partial
  monitoring</title><categories>math.ST cs.LG stat.TH</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Approachability has become a standard tool in analyzing earning algorithms in
the adversarial online learning setup. We develop a variant of approachability
for games where there is ambiguity in the obtained reward that belongs to a
set, rather than being a single vector. Using this variant we tackle the
problem of approachability in games with partial monitoring and develop simple
and efficient algorithms (i.e., with constant per-step complexity) for this
setup. We finally consider external regret and internal regret in repeated
games with partial monitoring and derive regret-minimizing strategies based on
approachability theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.4999</identifier>
 <datestamp>2013-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.4999</id><created>2011-05-25</created><updated>2013-02-15</updated><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Ho</keyname><forenames>Chin Keong</forenames></author></authors><title>MIMO Broadcasting for Simultaneous Wireless Information and Power
  Transfer</title><categories>cs.IT math.IT</categories><comments>The longer version of a paper to appear in IEEE Transactions on
  Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless power transfer (WPT) is a promising new solution to provide
convenient and perpetual energy supplies to wireless networks. In practice, WPT
is implementable by various technologies such as inductive coupling, magnetic
resonate coupling, and electromagnetic (EM) radiation, for
short-/mid-/long-range applications, respectively. In this paper, we consider
the EM or radio signal enabled WPT in particular. Since radio signals can carry
energy as well as information at the same time, a unified study on simultaneous
wireless information and power transfer (SWIPT) is pursued. Specifically, this
paper studies a multiple-input multiple-output (MIMO) wireless broadcast system
consisting of three nodes, where one receiver harvests energy and another
receiver decodes information separately from the signals sent by a common
transmitter, and all the transmitter and receivers may be equipped with
multiple antennas. Two scenarios are examined, in which the information
receiver and energy receiver are separated and see different MIMO channels from
the transmitter, or co-located and see the identical MIMO channel from the
transmitter. For the case of separated receivers, we derive the optimal
transmission strategy to achieve different tradeoffs for maximal information
rate versus energy transfer, which are characterized by the boundary of a
so-called rate-energy (R-E) region. For the case of co-located receivers, we
show an outer bound for the achievable R-E region due to the potential
limitation that practical energy harvesting receivers are not yet able to
decode information directly. Under this constraint, we investigate two
practical designs for the co-located receiver case, namely time switching and
power splitting, and characterize their achievable R-E regions in comparison to
the outer bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5032</identifier>
 <datestamp>2012-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5032</id><created>2011-05-25</created><updated>2012-07-06</updated><authors><author><keyname>Faliszewski</keyname><forenames>Piotr</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Edith</forenames></author><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author></authors><title>The Complexity of Manipulative Attacks in Nearly Single-Peaked
  Electorates</title><categories>cs.GT cs.CC cs.MA</categories><comments>35 pages, also appears as URCS-TR-2011-968</comments><acm-class>I.2.11; F.2.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many electoral bribery, control, and manipulation problems (which we will
refer to in general as &quot;manipulative actions&quot; problems) are NP-hard in the
general case. It has recently been noted that many of these problems fall into
polynomial time if the electorate is single-peaked (i.e., is polarized along
some axis/issue). However, real-world electorates are not truly single-peaked.
There are usually some mavericks, and so real-world electorates tend to merely
be nearly single-peaked. This paper studies the complexity of
manipulative-action algorithms for elections over nearly single-peaked
electorates, for various notions of nearness and various election systems. We
provide instances where even one maverick jumps the manipulative-action
complexity up to $\np$-hardness, but we also provide many instances where a
reasonable number of mavericks can be tolerated without increasing the
manipulative-action complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5053</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5053</id><created>2011-05-25</created><authors><author><keyname>Slanina</keyname><forenames>Frantisek</forenames></author><author><keyname>Konopasek</keyname><forenames>Zdenek</forenames></author></authors><title>Eigenvector localization as a tool to study small communities in online
  social networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><journal-ref>Advances in Complex Systems 13 (2010) 699-723</journal-ref><doi>10.1142/S0219525910002840</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and discuss a mathematical procedure for identification of small
&quot;communities&quot; or segments within large bipartite networks. The procedure is
based on spectral analysis of the matrix encoding network structure. The
principal tool here is localization of eigenvectors of the matrix, by means of
which the relevant network segments become visible. We exemplified our approach
by analyzing the data related to product reviewing on Amazon.com. We found
several segments, a kind of hybrid communities of densely interlinked reviewers
and products, which we were able to meaningfully interpret in terms of the type
and thematic categorization of reviewed items. The method provides a
complementary approach to other ways of community detection, typically aiming
at identification of large network modules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5055</identifier>
 <datestamp>2011-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5055</id><created>2011-05-25</created><updated>2011-09-07</updated><authors><author><keyname>Lindstr&#xf6;m</keyname><forenames>Markus</forenames></author><author><keyname>Geeraerts</keyname><forenames>Gilles</forenames></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames></author></authors><title>A faster exact multiprocessor schedulability test for sporadic tasks</title><categories>cs.OS cs.FL</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Baker and Cirinei introduced an exact but naive algorithm, based on solving a
state reachability problem in a finite automaton, to check whether sets of
sporadic hard real-time tasks are schedulable on identical multiprocessor
platforms. However, the algorithm suffered from poor performance due to the
exponential size of the automaton relative to the size of the task set. In this
paper, we successfully apply techniques developed by the formal verification
community, specifically antichain algorithms, by defining and proving the
correctness of a simulation relation on Baker and Cirinei's automaton. We show
our improved algorithm yields dramatically improved performance for the
schedulability test and opens for many further improvements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5062</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5062</id><created>2011-05-25</created><authors><author><keyname>Mazzucco</keyname><forenames>Michele</forenames></author><author><keyname>Dumas</keyname><forenames>Marlon</forenames></author></authors><title>Reserved or On-Demand Instances? A Revenue Maximization Model for Cloud
  Providers</title><categories>cs.DC cs.PF</categories><comments>8 pages, to appear in Proceedings of the 4th International Conference
  on Cloud Computing (IEEE Cloud 2011), Washington DC (USA), July 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the problem of managing a server farm in a way that attempts to
maximize the net revenue earned by a cloud provider by renting servers to
customers according to a typical Platform-as-a-Service model. The Cloud
provider offers its resources to two classes of customers: `premium' and
`basic'. Premium customers pay upfront fees to reserve servers for a specified
period of time (e.g. a year). Premium customers can submit jobs for their
reserved servers at any time and pay a fee for the server-hours they use. The
provider is liable to pay a penalty every time a `premium' job can not be
executed due to lack of resources. On the other hand, `basic' customers are
served on a best-effort basis, and pay a server-hour fee that may be higher
than the one paid by premium customers. The provider incurs energy costs when
running servers. Hence, it has an incentive to turn off idle servers. The
question of how to choose the number of servers to allocate to each pool (basic
and premium) is answered by analyzing a suitable queuing model and maximizing a
revenue function. Experimental results show that the proposed scheme adapts to
different traffic conditions, penalty levels, energy costs and usage fees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5072</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5072</id><created>2011-05-25</created><updated>2011-05-26</updated><authors><author><keyname>Chaaban</keyname><forenames>Anas</forenames></author><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author></authors><title>Sub-optimality of Treating Interference as Noise in the Cellular Uplink</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the simplicity of the scheme of treating interference as noise (TIN),
it was shown to be sum-capacity optimal in the Gaussian 2-user interference
channel in \cite{ShangKramerChen,MotahariKhandani,AnnapureddyVeeravalli}. In
this paper, an interference network consisting of a point-to-point channel
interfering with a multiple access channel (MAC) is considered, with focus on
the weak interference scenario. Naive TIN in this network is performed by using
Gaussian codes at the transmitters, joint decoding at the MAC receiver while
treating interference as noise, and single user decoding at the point-to-point
receiver while treating both interferers as noise. It is shown that this naive
TIN scheme is never optimal in this scenario. In fact, a scheme that combines
both time division multiple access and TIN outperforms the naive TIN scheme. An
upper bound on the sum-capacity of the given network is also derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5080</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5080</id><created>2011-05-25</created><authors><author><keyname>Lupu</keyname><forenames>Irina Iulia</forenames><affiliation>U.L.B.</affiliation></author><author><keyname>Goossens</keyname><forenames>Jo&#xeb;l</forenames><affiliation>U.L.B.</affiliation></author></authors><title>Scheduling of Hard Real-Time Multi-Thread Periodic Tasks</title><categories>cs.OS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the scheduling of parallel and real-time recurrent
tasks. Firstly, we propose a new parallel task model which allows recurrent
tasks to be composed of several threads, each thread requires a single
processor for execution and can be scheduled simultaneously. Secondly, we
define several kinds of real-time schedulers that can be applied to our
parallel task model. We distinguish between two scheduling classes:
hierarchical schedulers and global thread schedulers. We present and prove
correct an exact schedulability test for each class. Lastly, we also evaluate
the performance of our scheduling paradigm in comparison with Gang scheduling
by means of simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5084</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5084</id><created>2011-05-25</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author><author><keyname>Akl</keyname><forenames>Selim G.</forenames></author></authors><title>Trans-Canada Slimeways: Slime mould imitates the Canadian transport
  network</title><categories>nlin.PS cs.ET physics.soc-ph q-bio.OT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Slime mould Physarum polycephalum builds up sophisticated networks to
transport nutrients between distant part of its extended body. The slime
mould's protoplasmic network is optimised for maximum coverage of nutrients yet
minimum energy spent on transportation of the intra-cellular material. In
laboratory experiments with P. polycephalum we represent Canadian major urban
areas with rolled oats and inoculated slime mould in the Toronto area. The
plasmodium spans the urban areas with its network of protoplasmic tubes. We
uncover similarities and differences between the protoplasmic network and the
Canadian national highway network, analyse the networks in terms of proximity
graphs and evaluate slime mould's network response to contamination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5104</identifier>
 <datestamp>2013-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5104</id><created>2011-05-25</created><updated>2013-11-06</updated><authors><author><keyname>Ibrahim</keyname><forenames>Sharif</forenames></author><author><keyname>Krishnamoorthy</keyname><forenames>Bala</forenames></author><author><keyname>Vixie</keyname><forenames>Kevin R.</forenames></author></authors><title>Simplicial Flat Norm with Scale</title><categories>math.DG cs.CG math.OC</categories><comments>To appear in the Journal of Computational Geometry. Since the last
  version, the section comparing our bounds to Sullivan's has been expanded. In
  particular, we show that our bounds are uniformly better in the case of
  boundaries and less sensitive to simplicial irregularity</comments><msc-class>49Q15, 55U10, 90C05</msc-class><acm-class>I.3.5; I.4.9; G.1.6</acm-class><journal-ref>Journal of Computational Geometry, 4(1):133-159, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the multiscale simplicial flat norm (MSFN) problem, which computes
flat norm at various scales of sets defined as oriented subcomplexes of finite
simplicial complexes in arbitrary dimensions. We show that the multiscale
simplicial flat norm is NP-complete when homology is defined over integers. We
cast the multiscale simplicial flat norm as an instance of integer linear
optimization. Following recent results on related problems, the multiscale
simplicial flat norm integer program can be solved in polynomial time by
solving its linear programming relaxation, when the simplicial complex
satisfies a simple topological condition (absence of relative torsion). Our
most significant contribution is the simplicial deformation theorem, which
states that one may approximate a general current with a simplicial current
while bounding the expansion of its mass. We present explicit bounds on the
quality of this approximation, which indicate that the simplicial current gets
closer to the original current as we make the simplicial complex finer. The
multiscale simplicial flat norm opens up the possibilities of using flat norm
to denoise or extract scale information of large data sets in arbitrary
dimensions. On the other hand, it allows one to employ the large body of
algorithmic results on simplicial complexes to address more general problems
related to currents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5129</identifier>
 <datestamp>2011-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5129</id><created>2011-05-25</created><authors><author><keyname>Friedgut</keyname><forenames>Ehud</forenames></author><author><keyname>Kalai</keyname><forenames>Gil</forenames></author><author><keyname>Keller</keyname><forenames>Nathan</forenames></author><author><keyname>Nisan</keyname><forenames>Noam</forenames></author></authors><title>A Quantitative Version of the Gibbard-Satterthwaite Theorem for Three
  Alternatives</title><categories>math.CO cs.AI math.PR</categories><comments>27 pages, extended version of a FOCS'08 paper, to appear in SICOMP</comments><msc-class>05D40, 91B14, 68Q87</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gibbard-Satterthwaite theorem states that every non-dictatorial election
rule among at least three alternatives can be strategically manipulated. We
prove a quantitative version of the Gibbard-Satterthwaite theorem: a random
manipulation by a single random voter will succeed with a non-negligible
probability for any election rule among three alternatives that is far from
being a dictatorship and from having only two alternatives in its range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5131</identifier>
 <datestamp>2013-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5131</id><created>2011-05-25</created><updated>2012-12-11</updated><authors><author><keyname>Galanis</keyname><forenames>Andreas</forenames></author><author><keyname>Ge</keyname><forenames>Qi</forenames></author><author><keyname>Stefankovic</keyname><forenames>Daniel</forenames></author><author><keyname>Vigoda</keyname><forenames>Eric</forenames></author><author><keyname>Yang</keyname><forenames>Linji</forenames></author></authors><title>Improved Inapproximability Results for Counting Independent Sets in the
  Hard-Core Model</title><categories>cs.CC cs.DM math.CO</categories><comments>to appear in Random Structures and Algorithms</comments><acm-class>F.2.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computational complexity of approximately counting the number of
independent sets of a graph with maximum degree Delta. More generally, for an
input graph G=(V,E) and an activity lambda&gt;0, we are interested in the quantity
Z_G(lambda) defined as the sum over independent sets I weighted as w(I) =
lambda^|I|. In statistical physics, Z_G(lambda) is the partition function for
the hard-core model, which is an idealized model of a gas where the particles
have non-negibile size.
  Recently, an interesting phase transition was shown to occur for the
complexity of approximating the partition function. Weitz showed an FPAS for
the partition function for any graph of maximum degree Delta when Delta is
constant and lambda&lt; lambda_c(Tree_Delta):=(Delta-1)^(Delta-1)/(Delta-2)^Delta.
The quantity lambda_c(Tree_Delta) is the critical point for the so-called
uniqueness threshold on the infinite, regular tree of degree Delta. On the
other side, Sly proved that there does not exist efficient (randomized)
approximation algorithms for lambda_c(Tree_Delta) &lt; lambda &lt;
lambda_c(Tree_Delta)+epsilon(Delta), unless NP=RP, for some function
epsilon(Delta)&gt;0. We remove the upper bound in the assumptions of Sly's result
for Delta not equal to 4 and 5, that is, we show that there does not exist
efficient randomized approximation algorithms for all
lambda&gt;lambda_c(Tree_Delta) for Delta=3 and Delta&gt;= 6. Sly's inapproximability
result uses a clever reduction, combined with a second-moment analysis of
Mossel, Weitz and Wormald which prove torpid mixing of the Glauber dynamics for
sampling from the associated Gibbs distribution on almost every regular graph
of degree Delta for the same range of lambda as in Sly's result. We extend
Sly's result by improving upon the technical work of Mossel et al., via a more
detailed analysis of independent sets in random regular graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5170</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5170</id><created>2011-05-25</created><updated>2011-05-28</updated><authors><author><keyname>Goncalves</keyname><forenames>Bruno</forenames></author><author><keyname>Perra</keyname><forenames>Nicola</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>Validation of Dunbar's number in Twitter conversations</title><categories>physics.soc-ph cond-mat.other cs.HC cs.SI</categories><comments>8 pages, 6 figures</comments><journal-ref>PLoS ONE 6(8): e22656 (2011)</journal-ref><doi>10.1371/journal.pone.0022656</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern society's increasing dependency on online tools for both work and
recreation opens up unique opportunities for the study of social interactions.
A large survey of online exchanges or conversations on Twitter, collected
across six months involving 1.7 million individuals is presented here. We test
the theoretical cognitive limit on the number of stable social relationships
known as Dunbar's number. We find that users can entertain a maximum of 100-200
stable relationships in support for Dunbar's prediction. The &quot;economy of
attention&quot; is limited in the online world by cognitive and biological
constraints as predicted by Dunbar's theory. Inspired by this empirical
evidence we propose a simple dynamical mechanism, based on finite priority
queuing and time resources, that reproduces the observed social behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5174</identifier>
 <datestamp>2015-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5174</id><created>2011-05-25</created><updated>2012-12-19</updated><authors><author><keyname>Ohsawa</keyname><forenames>Tomoki</forenames></author></authors><title>Symmetry Reduction of Optimal Control Systems and Principal Connections</title><categories>math.OC cs.SY math.SG</categories><comments>23 pages, 2 figures</comments><msc-class>49J15, 53D20, 37J15, 70H05, 70H25</msc-class><journal-ref>SIAM J. Control Optim., 51(1) (2013), pp. 96-120</journal-ref><doi>10.1137/110835219</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper explores the role of symmetries and reduction in nonlinear control
and optimal control systems. The focus of the paper is to give a geometric
framework of symmetry reduction of optimal control systems as well as to show
how to obtain explicit expressions of the reduced system by exploiting the
geometry. In particular, we show how to obtain a principal connection to be
used in the reduction for various choices of symmetry groups, as opposed to
assuming such a principal connection is given or choosing a particular symmetry
group to simplify the setting. Our result synthesizes some previous works on
symmetry reduction of nonlinear control and optimal control systems. Affine and
kinematic optimal control systems are of particular interest: We explicitly
work out the details for such systems and also show a few examples of symmetry
reduction of kinematic optimal control problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5176</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5176</id><created>2011-05-25</created><updated>2011-11-01</updated><authors><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author></authors><title>The merit factor of binary arrays derived from the quadratic character</title><categories>cs.IT math.IT</categories><comments>minor corrections</comments><msc-class>94A55, 68P30</msc-class><journal-ref>Adv. Math. Commun., vol. 5, no. 4, pp. 589-607, Nov. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We calculate the asymptotic merit factor, under all cyclic rotations of rows
and columns, of two families of binary two-dimensional arrays derived from the
quadratic character. The arrays in these families have size p x q, where p and
q are not necessarily distinct odd primes, and can be considered as
two-dimensional generalisations of a Legendre sequence. The asymptotic values
of the merit factor of the two families are generally different, although the
maximum asymptotic merit factor, taken over all cyclic rotations of rows and
columns, equals 36/13 for both families. These are the first non-trivial
theoretical results for the asymptotic merit factor of families of truly
two-dimensional binary arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5177</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5177</id><created>2011-05-25</created><authors><author><keyname>Felber</keyname><forenames>David</forenames></author><author><keyname>Meyerson</keyname><forenames>Adam</forenames></author></authors><title>Scheduling under Precedence, Communication, and Energy Constraints</title><categories>cs.DS cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of scheduling a set of $n$ tasks on $m$ processors
under precedence, communication, and global system energy constraints to
minimize makespan. We extend existing scheduling models to account for energy
usage and give convex programming algorithms that yield essentially the same
results as existing algorithms that do not consider energy, while adhering to a
strict energy bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5178</identifier>
 <datestamp>2014-03-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5178</id><created>2011-05-25</created><updated>2014-03-17</updated><authors><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author></authors><title>The peak sidelobe level of random binary sequences</title><categories>math.CO cs.IT math.IT</categories><comments>minor revisions and corrections compared to the first version</comments><msc-class>05D40 (Primary) 94A55, 60F10 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $A_n=(a_0,a_1,\dots,a_{n-1})$ be drawn uniformly at random from
$\{-1,+1\}^n$ and define \[
M(A_n)=\max_{0&lt;u&lt;n}\,\Bigg|\sum_{j=0}^{n-u-1}a_ja_{j+u}\Bigg|\quad\text{for
$n&gt;1$}. \] It is proved that $M(A_n)/\sqrt{n\log n}$ converges in probability
to $\sqrt{2}$. This settles a problem first studied by Moon and Moser in the
1960s and proves in the affirmative a recent conjecture due to Alon, Litsyn,
and Shpunt. It is also shown that the expectation of $M(A_n)/\sqrt{n\log n}$
tends to $\sqrt{2}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5180</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5180</id><created>2011-05-25</created><updated>2012-07-02</updated><authors><author><keyname>Jedwab</keyname><forenames>Jonathan</forenames></author><author><keyname>Schmidt</keyname><forenames>Kai-Uwe</forenames></author></authors><title>The L_4 norm of Littlewood polynomials derived from the Jacobi symbol</title><categories>math.NT cs.IT math.IT</categories><comments>minor revisions</comments><msc-class>11B83 (Primary) 94A55 (Secondary)</msc-class><journal-ref>Pac. J. Math., vol. 257, no. 2, pp. 395-418, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Littlewood raised the question of how slowly the L_4 norm ||f||_4 of a
Littlewood polynomial f (having all coefficients in {-1,+1}) of degree n-1 can
grow with n. We consider such polynomials for odd square-free n, where \phi(n)
coefficients are determined by the Jacobi symbol, but the remaining
coefficients can be freely chosen. When n is prime, these polynomials have the
smallest known asymptotic value of the normalised L_4 norm ||f||_4/||f||_2
among all Littlewood polynomials, namely (7/6)^{1/4}. When n is not prime, our
results show that the normalised L_4 norm varies considerably according to the
free choices of the coefficients and can even grow without bound. However, by
suitably choosing these coefficients, the limit of the normalised L_4 norm can
be made as small as the best known value (7/6)^{1/4}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5196</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5196</id><created>2011-05-25</created><authors><author><keyname>Weston</keyname><forenames>Jason</forenames></author><author><keyname>Bengio</keyname><forenames>Samy</forenames></author><author><keyname>Hamel</keyname><forenames>Philippe</forenames></author></authors><title>Large-Scale Music Annotation and Retrieval: Learning to Rank in Joint
  Semantic Spaces</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Music prediction tasks range from predicting tags given a song or clip of
audio, predicting the name of the artist, or predicting related songs given a
song, clip, artist name or tag. That is, we are interested in every semantic
relationship between the different musical concepts in our database. In
realistically sized databases, the number of songs is measured in the hundreds
of thousands or more, and the number of artists in the tens of thousands or
more, providing a considerable challenge to standard machine learning
techniques. In this work, we propose a method that scales to such datasets
which attempts to capture the semantic similarities between the database items
by modeling audio, artist names, and tags in a single low-dimensional semantic
space. This choice of space is learnt by optimizing the set of prediction tasks
of interest jointly using multi-task learning. Our method both outperforms
baseline methods and, in comparison to them, is faster and consumes less
memory. We then demonstrate how our method learns an interpretable model, where
the semantic space captures well the similarities of interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5215</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5215</id><created>2011-05-26</created><authors><author><keyname>Heckel</keyname><forenames>Reinhard</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Compressive Identification of Linear Operators</title><categories>cs.IT math.IT</categories><comments>To be presented at IEEE Int. Symp. Inf. Theory 2011, St Petersburg,
  Russia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of identifying a linear deterministic operator from
an input-output measurement. For the large class of continuous (and hence
bounded) operators, under additional mild restrictions, we show that stable
identifiability is possible if the total support area of the operator's
spreading function satisfies D &lt;= 1/2. This result holds for arbitrary
(possibly fragmented) support regions of the spreading function, does not
impose limitations on the total extent of the support region, and, most
importantly, does not require the support region of the spreading function to
be known prior to identification. Furthermore, we prove that asking for
identifiability of only almost all operators, stable identifiability is
possible if D &lt;= 1. This result is surprising as it says that there is no
penalty for not knowing the support region of the spreading function prior to
identification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5225</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5225</id><created>2011-05-26</created><updated>2012-01-30</updated><authors><author><keyname>Adiga</keyname><forenames>Abhijin</forenames></author><author><keyname>Chandran</keyname><forenames>L. Sunil</forenames></author><author><keyname>Mathew</keyname><forenames>Rogers</forenames></author></authors><title>Cubicity, Degeneracy, and Crossing Number</title><categories>math.CO cs.DM</categories><comments>21 pages</comments><msc-class>05C62, 05C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A $k$-box $B=(R_1,...,R_k)$, where each $R_i$ is a closed interval on the
real line, is defined to be the Cartesian product $R_1\times R_2\times
...\times R_k$. If each $R_i$ is a unit length interval, we call $B$ a
$k$-cube. Boxicity of a graph $G$, denoted as $\boxi(G)$, is the minimum
integer $k$ such that $G$ is an intersection graph of $k$-boxes. Similarly, the
cubicity of $G$, denoted as $\cubi(G)$, is the minimum integer $k$ such that
$G$ is an intersection graph of $k$-cubes.
  It was shown in [L. Sunil Chandran, Mathew C. Francis, and Naveen Sivadasan:
Representing graphs as the intersection of axis-parallel cubes. MCDES-2008,
IISc Centenary Conference, available at CoRR, abs/cs/ 0607092, 2006.] that, for
a graph $G$ with maximum degree $\Delta$, $\cubi(G)\leq \lceil 4(\Delta +1)\log
n\rceil$. In this paper, we show that, for a $k$-degenerate graph $G$,
$\cubi(G) \leq (k+2) \lceil 2e \log n \rceil$. Since $k$ is at most $\Delta$
and can be much lower, this clearly is a stronger result. This bound is tight.
We also give an efficient deterministic algorithm that runs in $O(n^2k)$ time
to output a $8k(\lceil 2.42 \log n\rceil + 1)$ dimensional cube representation
for $G$.
  An important consequence of the above result is that if the crossing number
of a graph $G$ is $t$, then $\boxi(G)$ is $O(t^{1/4}{\lceil\log
t\rceil}^{3/4})$ . This bound is tight up to a factor of $O((\log t)^{1/4})$.
We also show that, if $G$ has $n$ vertices, then $\cubi(G)$ is $O(\log n +
t^{1/4}\log t)$.
  Using our bound for the cubicity of $k$-degenerate graphs we show that
cubicity of almost all graphs in $\mathcal{G}(n,m)$ model is $O(d_{av}\log n)$,
where $d_{av}$ denotes the average degree of the graph under consideration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5235</identifier>
 <datestamp>2012-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5235</id><created>2011-05-26</created><updated>2012-04-17</updated><authors><author><keyname>Henriques</keyname><forenames>Pedro G.</forenames></author><author><keyname>Natario</keyname><forenames>Jose</forenames></author></authors><title>The rocket problem in general relativity</title><categories>gr-qc cs.SY math.OC</categories><comments>21 pages, 3 figures; v2: several changes to improve clarity,
  including a new derivation of the rocket equation; matches final published
  version</comments><msc-class>83C10, 49N90, 49N25</msc-class><journal-ref>J. Optim. Theory Appl. 154 (2012) 500-524</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive the covariant optimality conditions for rocket trajectories in
general relativity, with and without a bound on the magnitude of the proper
acceleration. The resulting theory is then applied to solve two specific
problems: the minimum fuel consumption transfer between two galaxies in a FLRW
model, and between two stable circular orbits in the Schwarzschild spacetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5236</identifier>
 <datestamp>2011-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5236</id><created>2011-05-26</created><updated>2011-06-19</updated><authors><author><keyname>Pignolet</keyname><forenames>Yvonne Anne</forenames></author><author><keyname>Schmid</keyname><forenames>Stefan</forenames></author><author><keyname>Tredan</keyname><forenames>Gilles</forenames></author></authors><title>Misleading Stars: What Cannot Be Measured in the Internet?</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traceroute measurements are one of our main instruments to shed light onto
the structure and properties of today's complex networks such as the Internet.
This paper studies the feasibility and infeasibility of inferring the network
topology given traceroute data from a worst-case perspective, i.e., without any
probabilistic assumptions on, e.g., the nodes' degree distribution. We attend
to a scenario where some of the routers are anonymous, and propose two
fundamental axioms that model two basic assumptions on the traceroute data: (1)
each trace corresponds to a real path in the network, and (2) the routing paths
are at most a factor 1/alpha off the shortest paths, for some parameter alpha
in (0,1]. In contrast to existing literature that focuses on the cardinality of
the set of (often only minimal) inferrable topologies, we argue that a large
number of possible topologies alone is often unproblematic, as long as the
networks have a similar structure. We hence seek to characterize the set of
topologies inferred with our axioms. We introduce the notion of star graphs
whose colorings capture the differences among inferred topologies; it also
allows us to construct inferred topologies explicitly. We find that in general,
inferrable topologies can differ significantly in many important aspects, such
as the nodes' distances or the number of triangles. These negative results are
complemented by a discussion of a scenario where the trace set is best
possible, i.e., &quot;complete&quot;. It turns out that while some properties such as the
node degrees are still hard to measure, a complete trace set can help to
determine global properties such as the connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5255</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5255</id><created>2011-05-26</created><updated>2013-05-20</updated><authors><author><keyname>Kutten</keyname><forenames>Shay</forenames></author><author><keyname>Lavi</keyname><forenames>Ron</forenames></author><author><keyname>Trehan</keyname><forenames>Amitabh</forenames></author></authors><title>Composition Games for Distributed Systems: the EU Grant games</title><categories>cs.GT cs.CY cs.DC</categories><comments>Accepted at AAAI 2013: Twenty-Seventh Conference on Artificial
  Intelligence, Bellevue, Washington, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze ways by which people decompose into groups in distributed systems.
We are interested in systems in which an agent can increase its utility by
connecting to other agents, but must also pay a cost that increases with the
size of the sys- tem. The right balance is achieved by the right size group of
agents. We formulate and analyze three intuitive and realistic games and show
how simple changes in the protocol can dras- tically improve the price of
anarchy of these games. In partic- ular, we identify two important properties
for a low price of anarchy: agreement in joining the system, and the possibil-
ity of appealing a rejection from a system. We show that the latter property is
especially important if there are some pre- existing constraints regarding who
may collaborate (or com- municate) with whom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5275</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5275</id><created>2011-05-25</created><updated>2011-12-18</updated><authors><author><keyname>Pustelnik</keyname><forenames>Nelly</forenames></author><author><keyname>Pesquet</keyname><forenames>Jean-Christophe</forenames></author><author><keyname>Chaux</keyname><forenames>Caroline</forenames></author></authors><title>Relaxing Tight Frame Condition in Parallel Proximal Methods for Signal
  Restoration</title><categories>cs.OH</categories><doi>10.1109/TSP.2011.2173684</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fruitful approach for solving signal deconvolution problems consists of
resorting to a frame-based convex variational formulation. In this context,
parallel proximal algorithms and related alternating direction methods of
multipliers have become popular optimization techniques to approximate
iteratively the desired solution. Until now, in most of these methods, either
Lipschitz differentiability properties or tight frame representations were
assumed. In this paper, it is shown that it is possible to relax these
assumptions by considering a class of non necessarily tight frame
representations, thus offering the possibility of addressing a broader class of
signal restoration problems. In particular, it is possible to use non
necessarily maximally decimated filter banks with perfect reconstruction, which
are common tools in digital signal processing. The proposed approach allows us
to solve both frame analysis and frame synthesis problems for various noise
distributions. In our simulations, it is applied to the deconvolution of data
corrupted with Poisson noise or Laplacian noise by using (non-tight) discrete
dual-tree wavelet representations and filter bank structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5282</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5282</id><created>2011-05-26</created><authors><author><keyname>Escobar</keyname><forenames>Santiago</forenames></author><author><keyname>Meadows</keyname><forenames>Catherine</forenames></author><author><keyname>Meseguer</keyname><forenames>Jose</forenames></author></authors><title>State Space Reduction in the Maude-NRL Protocol Analyzer</title><categories>cs.CR cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Maude-NRL Protocol Analyzer (Maude-NPA) is a tool and inference system
for reasoning about the security of cryptographic protocols in which the
cryptosystems satisfy different equational properties. It both extends and
provides a formal framework for the original NRL Protocol Analyzer, which
supported equational reasoning in a more limited way. Maude-NPA supports a wide
variety of algebraic properties that includes many crypto-systems of interest
such as, for example, one-time pads and Diffie-Hellman. Maude-NPA, like the
original NPA, looks for attacks by searching backwards from an insecure attack
state, and assumes an unbounded number of sessions. Because of the unbounded
number of sessions and the support for different equational theories, it is
necessary to develop ways of reducing the search space and avoiding infinite
search paths. In order for the techniques to prove useful, they need not only
to speed up the search, but should not violate completeness, so that failure to
find attacks still guarantees security. In this paper we describe some state
space reduction techniques that we have implemented in Maude-NPA. We also
provide completeness proofs, and experimental evaluations of their effect on
the performance of Maude-NPA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5294</identifier>
 <datestamp>2013-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5294</id><created>2011-05-26</created><updated>2012-05-16</updated><authors><author><keyname>Roth</keyname><forenames>Camille</forenames></author><author><keyname>Kang</keyname><forenames>Soong Moon</forenames></author><author><keyname>Batty</keyname><forenames>Michael</forenames></author><author><keyname>Barthelemy</keyname><forenames>Marc</forenames></author></authors><title>A long-time limit of world subway networks</title><categories>physics.soc-ph cs.SI</categories><comments>11 pages, 13 figures, revised version, accepted for publication in
  Royal Society Interface</comments><journal-ref>Journal of the Royal Society Interface, 9:2540-2550 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the temporal evolution of the structure of the world's largest
subway networks in an exploratory manner. We show that, remarkably, all these
networks converge to {a shape which shares similar generic features} despite
their geographic and economic differences. This limiting shape is made of a
core with branches radiating from it. For most of these networks, the average
degree of a node (station) within the core has a value of order 2.5 and the
proportion of k=2 nodes in the core is larger than 60%. The number of branches
scales roughly as the square root of the number of stations, the current
proportion of branches represents about half of the total number of stations,
and the average diameter of branches is about twice the average radial
extension of the core. Spatial measures such as the number of stations at a
given distance to the barycenter display a first regime which grows as r^2
followed by another regime with different exponents, and eventually saturates.
These results -- difficult to interpret in the framework of fractal geometry --
confirm and yield a natural explanation in the geometric picture of this core
and their branches: the first regime corresponds to a uniform core, while the
second regime is controlled by the interstation spacing on branches. The
apparent convergence towards a unique network shape in the temporal limit
suggests the existence of dominant, universal mechanisms governing the
evolution of these structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5298</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5298</id><created>2011-05-26</created><authors><author><keyname>Effenberger</keyname><forenames>Felix</forenames></author><author><keyname>Spreer</keyname><forenames>Jonathan</forenames></author></authors><title>Simplicial blowups and discrete normal surfaces in simpcomp</title><categories>math.CO cs.DM math.GT</categories><comments>10 pages</comments><msc-class>52B05, 52B70, 53C42, 57Q35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  simpcomp is an extension to GAP, the well known system for computational
discrete algebra. It allows the user to work with simplicial complexes. In the
latest version, support for simplicial blowups and discrete normal surfaces was
added, both features unique to simpcomp. Furthermore, new functions for
constructing certain infinite series of triangulations have been implemented
and interfaces to other software packages have been improved to previous
versions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5306</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5306</id><created>2011-05-26</created><updated>2012-08-09</updated><authors><author><keyname>Mohapatra</keyname><forenames>Parthajit</forenames></author><author><keyname>Murthy</keyname><forenames>Chandra R.</forenames></author></authors><title>On the Generalized Degrees of Freedom of the K-user Symmetric MIMO
  Gaussian Interference Channel</title><categories>cs.IT math.IT</categories><comments>63 pages, 7 figures, part of it accepted in ISIT 2011 and IEEE
  Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The K-user symmetric multiple input multiple output (MIMO) Gaussian
interference channel (IC) where each transmitter has M antennas and each
receiver has N antennas is studied from a generalized degrees of freedom (GDOF)
perspective. An inner bound on the GDOF is derived using a combination of
techniques such as treating interference as noise, zero forcing (ZF) at the
receivers, interference alignment (IA), and extending the Han-Kobayashi (HK)
scheme to K users, as a function of the number of antennas and the log (INR) /
log (SNR) level. Three outer bounds are derived, under different assumptions of
cooperation and providing side information to receivers. The novelty in the
derivation lies in the careful selection of side information, which results in
the cancellation of the negative differential entropy terms containing signal
components, leading to a tractable outer bound. The overall outer bound is
obtained by taking the minimum of the three outer bounds. The derived bounds
are simplified for the MIMO Gaussian symmetric IC to obtain outer bounds on the
generalized degrees of freedom (GDOF). Several interesting conclusions are
drawn from the derived bounds. For example, when K &gt; N/M + 1, a combination of
the HK and IA schemes performs the best among the schemes considered. When N/M
&lt; K &lt;= N/M + 1, the HK-scheme outperforms other schemes and is shown to be GDOF
optimal. In addition, when the SNR and INR are at the same level, ZF-receiving
and the HK-scheme have the same GDOF performance. It is also shown that many of
the existing results on the GDOF of the Gaussian IC can be obtained as special
cases of the bounds, e.g., by setting K=2 or the number of antennas at each
user to 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5307</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5307</id><created>2011-05-26</created><authors><author><keyname>Gregor</keyname><forenames>Karol</forenames></author><author><keyname>LeCun</keyname><forenames>Yann</forenames></author></authors><title>Efficient Learning of Sparse Invariant Representations</title><categories>cs.CV cs.NE</categories><comments>9 pages + 6 supplement pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple and efficient algorithm for learning sparse invariant
representations from unlabeled data with fast inference. When trained on short
movies sequences, the learned features are selective to a range of orientations
and spatial frequencies, but robust to a wide range of positions, similar to
complex cells in the primary visual cortex. We give a hierarchical version of
the algorithm, and give guarantees of fast convergence under certain
conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5316</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5316</id><created>2011-05-26</created><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Thed N.</forenames></author><author><keyname>Visser</keyname><forenames>Martijn S.</forenames></author><author><keyname>van Raan</keyname><forenames>Anthony F. J.</forenames></author></authors><title>On the correlation between bibliometric indicators and peer review:
  Reply to Opthof and Leydesdorff</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opthof and Leydesdorff [arXiv:1102.2569] reanalyze data reported by Van Raan
[arXiv:physics/0511206] and conclude that there is no significant correlation
between on the one hand average citation scores measured using the CPP/FCSm
indicator and on the other hand the quality judgment of peers. We point out
that Opthof and Leydesdorff draw their conclusions based on a very limited
amount of data. We also criticize the statistical methodology used by Opthof
and Leydesdorff. Using a larger amount of data and a more appropriate
statistical methodology, we do find a significant correlation between the
CPP/FCSm indicator and peer judgment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5331</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5331</id><created>2011-05-26</created><authors><author><keyname>De Sterck</keyname><forenames>Hans</forenames></author></authors><title>A Nonlinear GMRES Optimization Algorithm for Canonical Tensor
  Decomposition</title><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm is presented for computing a canonical rank-R tensor
approximation that has minimal distance to a given tensor in the Frobenius
norm, where the canonical rank-R tensor consists of the sum of R rank-one
components. Each iteration of the method consists of three steps. In the first
step, a tentative new iterate is generated by a stand-alone one-step process,
for which we use alternating least squares (ALS). In the second step, an
accelerated iterate is generated by a nonlinear generalized minimal residual
(GMRES) approach, recombining previous iterates in an optimal way, and
essentially using the stand-alone one-step process as a preconditioner. In
particular, the nonlinear extension of GMRES is used that was proposed by
Washio and Oosterlee in [ETNA Vol. 15 (2003), pp. 165-185] for nonlinear
partial differential equation problems. In the third step, a line search is
performed for globalization. The resulting nonlinear GMRES (N-GMRES)
optimization algorithm is applied to dense and sparse tensor decomposition test
problems. The numerical tests show that ALS accelerated by N-GMRES may
significantly outperform both stand-alone ALS and a standard nonlinear
conjugate gradient optimization method, especially when highly accurate
stationary points are desired for difficult problems. The proposed N-GMRES
optimization algorithm is based on general concepts and may be applied to other
nonlinear optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5332</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5332</id><created>2011-05-26</created><updated>2016-02-12</updated><authors><author><keyname>Cvetkovski</keyname><forenames>Andrej</forenames></author><author><keyname>Crovella</keyname><forenames>Mark</forenames></author></authors><title>Multidimensional Scaling in the Poincare Disk</title><categories>stat.ML cs.SI</categories><journal-ref>Applied Mathematics &amp; Information Sciences, 10(1):125, 2016</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multidimensional scaling (MDS) is a class of projective algorithms
traditionally used in Euclidean space to produce two- or three-dimensional
visualizations of datasets of multidimensional points or point distances. More
recently however, several authors have pointed out that for certain datasets,
hyperbolic target space may provide a better fit than Euclidean space.
  In this paper we develop PD-MDS, a metric MDS algorithm designed specifically
for the Poincare disk (PD) model of the hyperbolic plane. Emphasizing the
importance of proceeding from first principles in spite of the availability of
various black box optimizers, our construction is based on an elementary
hyperbolic line search and reveals numerous particulars that need to be
carefully addressed when implementing this as well as more sophisticated
iterative optimization methods in a hyperbolic space model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5344</identifier>
 <datestamp>2012-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5344</id><created>2011-05-26</created><updated>2012-05-12</updated><authors><author><keyname>Reid</keyname><forenames>Fergal</forenames></author><author><keyname>McDaid</keyname><forenames>Aaron</forenames></author><author><keyname>Hurley</keyname><forenames>Neil</forenames></author></authors><title>Partitioning Breaks Communities</title><categories>physics.soc-ph cs.SI</categories><comments>27 pages, 11 figures. Author prepared book chapter preprint</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering a clique as a conservative definition of community structure, we
examine how graph partitioning algorithms interact with cliques. Many popular
community-finding algorithms partition the entire graph into non-overlapping
communities. We show that on a wide range of empirical networks, from different
domains, significant numbers of cliques are split across the separate
partitions produced by these algorithms. We then examine the largest connected
component of the subgraph formed by retaining only edges in cliques, and apply
partitioning strategies that explicitly minimise the number of cliques split.
We further examine several modern overlapping community finding algorithms, in
terms of the interaction between cliques and the communities they find, and in
terms of the global overlap of the sets of communities they find. We conclude
that, due to the connectedness of many networks, any community finding
algorithm that produces partitions must fail to find at least some significant
structures. Moreover, contrary to traditional intuition, in some empirical
networks, strong ties and cliques frequently do cross community boundaries;
much community structure is fundamentally overlapping and unpartitionable in
nature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5346</identifier>
 <datestamp>2012-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5346</id><created>2011-05-26</created><authors><author><keyname>Holden</keyname><forenames>Joshua</forenames></author><author><keyname>Robinson</keyname><forenames>Margaret M.</forenames></author></authors><title>Counting Fixed Points, Two-Cycles, and Collisions of the Discrete
  Exponential Function using p-adic Methods</title><categories>math.NT cs.CR</categories><comments>14 pages, no figures</comments><msc-class>Primary 11D88, Secondary 11A07, 11N37, 11Y16, 94A60</msc-class><journal-ref>Journal of the Australian Mathematical Society, 92: 163-178, 2012</journal-ref><doi>10.1017/S1446788712000262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brizolis asked for which primes p greater than 3 does there exist a pair (g,
h) such that h is a fixed point of the discrete exponential map with base g, or
equivalently h is a fixed point of the discrete logarithm with base g. Zhang
(1995) and Cobeli and Zaharescu (1999) answered with a &quot;yes&quot; for sufficiently
large primes and gave estimates for the number of such pairs when g and h are
primitive roots modulo p. In 2000, Campbell showed that the answer to Brizolis
was &quot;yes&quot; for all primes. The first author has extended this question to
questions about counting fixed points, two-cycles, and collisions of the
discrete exponential map. In this paper, we use p-adic methods, primarily
Hensel's lemma and p-adic interpolation, to count fixed points, two cycles,
collisions, and solutions to related equations modulo powers of a prime p.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5353</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5353</id><created>2011-05-26</created><authors><author><keyname>Wei</keyname><forenames>Zhaohui</forenames></author><author><keyname>Zhang</keyname><forenames>Shengyu</forenames></author></authors><title>On characterizing quantum correlated equilibria</title><categories>quant-ph cs.GT</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum game theory lays a foundation for understanding the interaction of
people using quantum computers with conflicting interests. Recently Zhang
proposed a simple yet rich model to study quantum strategic games, and
addressed some quantitative questions for general games of growing sizes
\cite{Zha10}. However, one fundamental question that the paper did not consider
is the characterization of quantum correlated equilibria (QCE). In this paper,
we answer this question by giving a sufficient and necessary condition for an
arbitrary state $\rho$ being a QCE. In addition, when the condition fails to
hold for some player $i$, we give an explicit POVM for that player to achieve a
strictly positive gain. Finally, we give some upper bounds for the maximum gain
by playing quantum strategies over classical ones, and the bounds are tight for
some games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5370</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5370</id><created>2011-05-26</created><authors><author><keyname>Guedes</keyname><forenames>Ello&#xe1; B.</forenames></author><author><keyname>de Assis</keyname><forenames>Francisco Marcos</forenames></author></authors><title>Quantum Communication Complexity of Quantum Authentication Protocols</title><categories>cs.IT math.IT quant-ph</categories><comments>7 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to perform Quantum Cryptography procedures it is often essencial to
ensure that the parties of the communication are authentic. Such task is
accomplished by quantum authentication protocols which are distributed
algorithms based on the intrinsic properties of Quantum Mechanics. The choice
of an authentication protocol must consider that quantum states are very
delicate and that the channel is subject to eavesdropping. However, even in
face of the various existing definitions of quantum authentication protocols in
the literature, little is known about them in this perspective, and this lack
of knowledge may unfavor comparisons and wise choices. In the attempt to
overcome this limitation, in the present work we aim at showing an approach to
evaluate quantum authentication protocols based on the determination of their
quantum communication complexity. Based on our investigation, no similar
methods to analyze quantum authentication protocols were found in the
literature. Pursuing this further, our approach has advantages that need to be
highlighted: it characterizes a systematic procedure to evaluate quantum
authentication protocols; its evaluation is intuitive, based only on the
protocol execution; the resulting measure is a concise notation of what
resources a quantum authentication protocol demands and how many communications
are performed; it allows comparisons between protocols; it makes possible to
analyze the communication effort when an eavesdropping occurs; and, lastly, it
is likely to be applied in almost any quantum authentication protocol. To
illustrate the proposed approach, we also bring results about its application
in ten existing quantum authentication protocols (data origin authentication
and identity authentication). Such evaluations increase the knowledge about the
existing protocols, presenting its advantages, limitations and contrasts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5379</identifier>
 <datestamp>2011-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5379</id><created>2011-05-26</created><authors><author><keyname>Bradley</keyname><forenames>Joseph K.</forenames></author><author><keyname>Kyrola</keyname><forenames>Aapo</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos</forenames></author></authors><title>Parallel Coordinate Descent for L1-Regularized Loss Minimization</title><categories>cs.LG cs.IT math.IT</categories><journal-ref>In the 28th International Conference on Machine Learning, July
  2011, Washington, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose Shotgun, a parallel coordinate descent algorithm for minimizing
L1-regularized losses. Though coordinate descent seems inherently sequential,
we prove convergence bounds for Shotgun which predict linear speedups, up to a
problem-dependent limit. We present a comprehensive empirical study of Shotgun
for Lasso and sparse logistic regression. Our theoretical predictions on the
potential for parallelism closely match behavior on real data. Shotgun
outperforms other published solvers on a range of large problems, proving to be
one of the most scalable algorithms for L1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5401</identifier>
 <datestamp>2011-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5401</id><created>2011-05-26</created><updated>2011-06-08</updated><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Common Edge-Unzippings for Tetrahedra</title><categories>cs.CG cs.DM</categories><comments>9 pages, 4 figures. Version 2 simplifies one proof</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that there are examples of distinct polyhedra, each with a
Hamiltonian path of edges, which when cut, unfolds the surfaces to a common
net. In particular, it is established for infinite classes of triples of
tetrahedra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5419</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5419</id><created>2011-05-26</created><updated>2013-09-06</updated><authors><author><keyname>Bloch</keyname><forenames>Matthieu R.</forenames></author><author><keyname>Laneman</keyname><forenames>J. Nicholas</forenames></author></authors><title>Strong Secrecy from Channel Resolvability</title><categories>cs.IT math.IT</categories><comments>23 pages, two-column, 5 figures, accepted to IEEE Transactions on
  Information Theory; corrected typos; updated references; minor change in
  title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze physical-layer security based on the premise that the coding
mechanism for secrecy over noisy channels is tied to the notion of channel
resolvability. Instead of considering capacity-based constructions, which
associate to each message a sub-code that operates just below the capacity of
the eavesdropper's channel, we consider channel-resolvability-based
constructions, which associate to each message a sub-code that operates just
above the resolvability of the eavesdropper's channel. Building upon the work
of Csiszar and Hayashi, we provide further evidence that channel resolvability
is a powerful and versatile coding mechanism for secrecy by developing results
that hold for strong secrecy metrics and arbitrary channels.
  Specifically, we show that at least for symmetric wiretap channels, random
capacity-based constructions fail to achieve the strong secrecy capacity while
channel-resolvability-based constructions achieve it. We then leverage channel
resolvability to establish the secrecy-capacity region of arbitrary broadcast
channels with confidential messages and a cost constraint for strong secrecy
metrics. Finally, we specialize our results to study the secrecy capacity of
wireless channels with perfect channel state information, mixed channels and
compound channels with receiver Channel State Information (CSI), as well as the
secret-key capacity of source models for secret-key agreement. By tying secrecy
to channel resolvability, we obtain achievable rates for strong secrecy metrics
with simple proofs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5427</identifier>
 <datestamp>2011-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5427</id><created>2011-05-26</created><updated>2011-11-30</updated><authors><author><keyname>Quoc</keyname><forenames>Tran Dinh</forenames></author><author><keyname>Savorgnan</keyname><forenames>Carlo</forenames></author><author><keyname>Diehl</keyname><forenames>Moritz</forenames></author></authors><title>Combining Lagrangian Decomposition and Excessive Gap Smoothing Technique
  for Solving Large-Scale Separable Convex Optimization Problems</title><categories>math.OC cs.SY</categories><comments>29 pages, one figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm for solving large-scale convex optimization problems with a
separable objective function is proposed. The basic idea is to combine three
techniques: Lagrangian dual decomposition, excessive gap and smoothing. The
main advantage of this algorithm is that it dynamically updates the smoothness
parameters which leads to numerically robust performance. The convergence of
the algorithm is proved under weak conditions imposed on the original problem.
The rate of convergence is $O(\frac{1}{k})$, where $k$ is the iteration
counter. In the second part of the paper, the algorithm is coupled with a dual
scheme to construct a switching variant of the dual decomposition. We discuss
implementation issues and make a theoretical comparison. Numerical examples
confirm the theoretical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5432</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5432</id><created>2011-05-26</created><updated>2011-11-17</updated><authors><author><keyname>Dang</keyname><forenames>Wenbing</forenames></author><author><keyname>Scharf</keyname><forenames>Louis L.</forenames></author></authors><title>Extensions to the Theory of Widely Linear Complex Kalman Filtering</title><categories>cs.SY cs.IT math.IT math.OC</categories><doi>10.1109/TSP.2012.2214213</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an improper complex signal x, its complementary covariance ExxT is not
zero and thus it carries useful statistical information about x. Widely linear
processing exploits Hermitian and complementary covariance to improve
performance. In this paper we extend the existing theory of widely linear
complex Kalman filters (WLCKF) and unscented WLCKFs [1]. We propose a WLCKF
which can deal with more general dynamical models of complex-valued states and
measurements than the WLCKFs in [1]. The proposed WLCKF has an equivalency with
the corresponding dual channel real KF. Our analytical and numerical results
show the performance improvement of a WLCKF over a complex Kalman filter (CKF)
that does not exploit complementary covariance. We also develop an unscented
WLCKF which uses modified complex sigma points. The modified complex sigma
points preserve complete first and second moments of complex signals, while the
sigma points in [1] only carry the mean and Hermitian covariance, but not
complementary covariance of complex signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5438</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5438</id><created>2011-05-26</created><authors><author><keyname>Geng</keyname><forenames>Yanlin</forenames></author><author><keyname>Gohari</keyname><forenames>Amin</forenames></author><author><keyname>Nair</keyname><forenames>Chandra</forenames></author><author><keyname>Yu</keyname><forenames>Yuanming</forenames></author></authors><title>The capacity region of classes of product broadcast channels</title><categories>cs.IT math.IT</categories><comments>full version of isit paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a new outer bound for the capacity region of product broadcast
channels. This outer bound matches Marton's inner bound for a variety of
classes of product broadcast channels whose capacity regions were previously
unknown. These classes include product of reversely semi-deterministic and
product of reversely more-capable channels. A significant consequence of this
new outer bound is that it establishes, via an example, that the previously
best known outer-bound is strictly suboptimal for the general broadcast
channel. Our example is comprised of a product broadcast channel with two
semi-deterministic components in reverse orientation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5440</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5440</id><created>2011-05-26</created><authors><author><keyname>Ahuactzin</keyname><forenames>J. M.</forenames></author><author><keyname>Bessiere</keyname><forenames>P.</forenames></author><author><keyname>Mazer</keyname><forenames>E.</forenames></author></authors><title>The Ariadne's Clew Algorithm</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  295-316, 1998</journal-ref><doi>10.1613/jair.468</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new approach to path planning, called the &quot;Ariadne's clew
algorithm&quot;. It is designed to find paths in high-dimensional continuous spaces
and applies to robots with many degrees of freedom in static, as well as
dynamic environments - ones where obstacles may move. The Ariadne's clew
algorithm comprises two sub-algorithms, called Search and Explore, applied in
an interleaved manner. Explore builds a representation of the accessible space
while Search looks for the target. Both are posed as optimization problems. We
describe a real implementation of the algorithm to plan paths for a six degrees
of freedom arm in a dynamic environment where another six degrees of freedom
arm is used as a moving obstacle. Experimental results show that a path is
found in about one second without any pre-processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5441</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5441</id><created>2011-05-26</created><authors><author><keyname>Backstrom</keyname><forenames>C.</forenames></author></authors><title>Computational Aspects of Reordering Plans</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  99-137, 1998</journal-ref><doi>10.1613/jair.477</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article studies the problem of modifying the action ordering of a plan
in order to optimise the plan according to various criteria. One of these
criteria is to make a plan less constrained and the other is to minimize its
parallel execution time. Three candidate definitions are proposed for the first
of these criteria, constituting a sequence of increasing optimality guarantees.
Two of these are based on deordering plans, which means that ordering relations
may only be removed, not added, while the third one uses reordering, where
arbitrary modifications to the ordering are allowed. It is shown that only the
weakest one of the three criteria is tractable to achieve, the other two being
NP-hard and even difficult to approximate. Similarly, optimising the parallel
execution time of a plan is studied both for deordering and reordering of
plans. In the general case, both of these computations are NP-hard. However, it
is shown that optimal deorderings can be computed in polynomial time for a
class of planning languages based on the notions of producers, consumers and
threats, which includes most of the commonly used planning languages. Computing
optimal reorderings can potentially lead to even faster parallel executions,
but this problem remains NP-hard and difficult to approximate even under quite
severe restrictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5442</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5442</id><created>2011-05-26</created><authors><author><keyname>Ledeniov</keyname><forenames>O.</forenames></author><author><keyname>Markovitch</keyname><forenames>S.</forenames></author></authors><title>The Divide-and-Conquer Subgoal-Ordering Algorithm for Speeding up Logic
  Inference</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  37-97, 1998</journal-ref><doi>10.1613/jair.509</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is common to view programs as a combination of logic and control: the
logic part defines what the program must do, the control part -- how to do it.
The Logic Programming paradigm was developed with the intention of separating
the logic from the control. Recently, extensive research has been conducted on
automatic generation of control for logic programs. Only a few of these works
considered the issue of automatic generation of control for improving the
efficiency of logic programs. In this paper we present a novel algorithm for
automatic finding of lowest-cost subgoal orderings. The algorithm works using
the divide-and-conquer strategy. The given set of subgoals is partitioned into
smaller sets, based on co-occurrence of free variables. The subsets are ordered
recursively and merged, yielding a provably optimal order. We experimentally
demonstrate the utility of the algorithm by testing it in several domains, and
discuss the possibilities of its cooperation with other existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5443</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5443</id><created>2011-05-26</created><authors><author><keyname>Culberson</keyname><forenames>J.</forenames></author><author><keyname>Vandegriend</keyname><forenames>B.</forenames></author></authors><title>The Gn,m Phase Transition is Not Hard for the Hamiltonian Cycle Problem</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  219-245, 1998</journal-ref><doi>10.1613/jair.512</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using an improved backtrack algorithm with sophisticated pruning techniques,
we revise previous observations correlating a high frequency of hard to solve
Hamiltonian Cycle instances with the Gn,m phase transition between
Hamiltonicity and non-Hamiltonicity. Instead all tested graphs of 100 to 1500
vertices are easily solved. When we artificially restrict the degree sequence
with a bounded maximum degree, although there is some increase in difficulty,
the frequency of hard graphs is still low. When we consider more regular graphs
based on a generalization of knight's tours, we observe frequent instances of
really hard graphs, but on these the average degree is bounded by a constant.
We design a set of graphs with a feature our algorithm is unable to detect and
so are very hard for our algorithm, but in these we can vary the average degree
from O(1) to O(n). We have so far found no class of graphs correlated with the
Gn,m phase transition which asymptotically produces a high frequency of hard
instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5444</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5444</id><created>2011-05-26</created><authors><author><keyname>Resnik</keyname><forenames>P.</forenames></author></authors><title>Semantic Similarity in a Taxonomy: An Information-Based Measure and its
  Application to Problems of Ambiguity in Natural Language</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  95-130, 1999</journal-ref><doi>10.1613/jair.514</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a measure of semantic similarity in an IS-A taxonomy
based on the notion of shared information content. Experimental evaluation
against a benchmark set of human similarity judgments demonstrates that the
measure performs better than the traditional edge-counting approach. The
article presents algorithms that take advantage of taxonomic similarity in
resolving syntactic and semantic ambiguity, along with experimental results
demonstrating their effectiveness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5446</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5446</id><created>2011-05-26</created><authors><author><keyname>Artale</keyname><forenames>A.</forenames></author><author><keyname>Franconi</keyname><forenames>E.</forenames></author></authors><title>A Temporal Description Logic for Reasoning about Actions and Plans</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  463-506, 1998</journal-ref><doi>10.1613/jair.516</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of interval-based temporal languages for uniformly representing and
reasoning about actions and plans is presented. Actions are represented by
describing what is true while the action itself is occurring, and plans are
constructed by temporally relating actions and world states. The temporal
languages are members of the family of Description Logics, which are
characterized by high expressivity combined with good computational properties.
The subsumption problem for a class of temporal Description Logics is
investigated and sound and complete decision procedures are given. The basic
language TL-F is considered first: it is the composition of a temporal logic TL
-- able to express interval temporal networks -- together with the non-temporal
logic F -- a Feature Description Logic. It is proven that subsumption in this
language is an NP-complete problem. Then it is shown how to reason with the
more expressive languages TLU-FU and TL-ALCF. The former adds disjunction both
at the temporal and non-temporal sides of the language, the latter extends the
non-temporal side with set-valued features (i.e., roles) and a propositionally
complete language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5447</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5447</id><created>2011-05-26</created><authors><author><keyname>Cook</keyname><forenames>D. J.</forenames></author><author><keyname>Varnell</keyname><forenames>R. C.</forenames></author></authors><title>Adaptive Parallel Iterative Deepening Search</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  139-165, 1998</journal-ref><doi>10.1613/jair.518</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many of the artificial intelligence techniques developed to date rely on
heuristic search through large spaces. Unfortunately, the size of these spaces
and the corresponding computational effort reduce the applicability of
otherwise novel and effective algorithms. A number of parallel and distributed
approaches to search have considerably improved the performance of the search
process. Our goal is to develop an architecture that automatically selects
parallel search strategies for optimal performance on a variety of search
problems. In this paper we describe one such architecture realized in the
Eureka system, which combines the benefits of many different approaches to
parallel heuristic search. Through empirical and theoretical analyses we
observe that features of the problem space directly affect the choice of
optimal parallel search strategy. We then employ machine learning techniques to
select the optimal parallel search strategy for a given problem space. When a
new search task is input to the system, Eureka uses features describing the
search space and the chosen architecture to automatically select the
appropriate search strategy. Eureka has been tested on a MIMD parallel
processor, a distributed network of workstations, and a single workstation
using multithreading. Results generated from fifteen puzzle problems, robot arm
motion problems, artificial search spaces, and planning problems indicate that
Eureka outperforms any of the tested strategies used exclusively for all
problem instances and is able to greatly reduce the search time for these
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5448</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5448</id><created>2011-05-26</created><authors><author><keyname>Davis</keyname><forenames>E.</forenames></author></authors><title>Order of Magnitude Comparisons of Distance</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  1-38, 1999</journal-ref><doi>10.1613/jair.520</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Order of magnitude reasoning - reasoning by rough comparisons of the sizes of
quantities - is often called 'back of the envelope calculation', with the
implication that the calculations are quick though approximate. This paper
exhibits an interesting class of constraint sets in which order of magnitude
reasoning is demonstrably fast. Specifically, we present a polynomial-time
algorithm that can solve a set of constraints of the form 'Points a and b are
much closer together than points c and d.' We prove that this algorithm can be
applied if `much closer together' is interpreted either as referring to an
infinite difference in scale or as referring to a finite difference in scale,
as long as the difference in scale is greater than the number of variables in
the constraint set. We also prove that the first-order theory over such
constraints is decidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5449</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5449</id><created>2011-05-26</created><authors><author><keyname>Di Caro</keyname><forenames>G.</forenames></author><author><keyname>Dorigo</keyname><forenames>M.</forenames></author></authors><title>AntNet: Distributed Stigmergetic Control for Communications Networks</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  317-365, 1998</journal-ref><doi>10.1613/jair.530</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces AntNet, a novel approach to the adaptive learning of
routing tables in communications networks. AntNet is a distributed, mobile
agents based Monte Carlo system that was inspired by recent work on the ant
colony metaphor for solving optimization problems. AntNet's agents concurrently
explore the network and exchange collected information. The communication among
the agents is indirect and asynchronous, mediated by the network itself. This
form of communication is typical of social insects and is called stigmergy. We
compare our algorithm with six state-of-the-art routing algorithms coming from
the telecommunications and machine learning fields. The algorithms' performance
is evaluated over a set of realistic testbeds. We run many experiments over
real and artificial IP datagram networks with increasing number of nodes and
under several paradigmatic spatial and temporal traffic distributions. Results
are very encouraging. AntNet showed superior performance under all the
experimental conditions with respect to its competitors. We analyze the main
characteristics of the algorithm and try to explain the reasons for its
superiority.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5450</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5450</id><created>2011-05-26</created><authors><author><keyname>Halpern</keyname><forenames>J. Y.</forenames></author></authors><title>A Counter Example to Theorems of Cox and Fine</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  67-85, 1999</journal-ref><doi>10.1613/jair.536</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cox's well-known theorem justifying the use of probability is shown not to
hold in finite domains. The counterexample also suggests that Cox's assumptions
are insufficient to prove the result even in infinite domains. The same
counterexample is used to disprove a result of Fine on comparative conditional
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5451</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5451</id><created>2011-05-26</created><authors><author><keyname>Fox</keyname><forenames>M.</forenames></author><author><keyname>Long</keyname><forenames>D.</forenames></author></authors><title>The Automatic Inference of State Invariants in TIM</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  367-421, 1998</journal-ref><doi>10.1613/jair.544</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As planning is applied to larger and richer domains the effort involved in
constructing domain descriptions increases and becomes a significant burden on
the human application designer. If general planners are to be applied
successfully to large and complex domains it is necessary to provide the domain
designer with some assistance in building correctly encoded domains. One way of
doing this is to provide domain-independent techniques for extracting, from a
domain description, knowledge that is implicit in that description and that can
assist domain designers in debugging domain descriptions. This knowledge can
also be exploited to improve the performance of planners: several researchers
have explored the potential of state invariants in speeding up the performance
of domain-independent planners. In this paper we describe a process by which
state invariants can be extracted from the automatically inferred type
structure of a domain. These techniques are being developed for exploitation by
STAN, a Graphplan based planner that employs state analysis techniques to
enhance its performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5452</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5452</id><created>2011-05-26</created><authors><author><keyname>Calvanese</keyname><forenames>D.</forenames></author><author><keyname>Lenzerini</keyname><forenames>M.</forenames></author><author><keyname>Nardi</keyname><forenames>D.</forenames></author></authors><title>Unifying Class-Based Representation Formalisms</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  199-240, 1999</journal-ref><doi>10.1613/jair.548</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of class is ubiquitous in computer science and is central in many
formalisms for the representation of structured knowledge used both in
knowledge representation and in databases. In this paper we study the basic
issues underlying such representation formalisms and single out both their
common characteristics and their distinguishing features. Such investigation
leads us to propose a unifying framework in which we are able to capture the
fundamental aspects of several representation languages used in different
contexts. The proposed formalism is expressed in the style of description
logics, which have been introduced in knowledge representation as a means to
provide a semantically well-founded basis for the structural aspects of
knowledge representation systems. The description logic considered in this
paper is a subset of first order logic with nice computational characteristics.
It is quite expressive and features a novel combination of constructs that has
not been studied before. The distinguishing constructs are number restrictions,
which generalize existence and functional dependencies, inverse roles, which
allow one to refer to the inverse of a relationship, and possibly cyclic
assertions, which are necessary for capturing real world domains. We are able
to show that it is precisely such combination of constructs that makes our
logic powerful enough to model the essential set of features for defining class
structures that are common to frame systems, object-oriented database
languages, and semantic data models. As a consequence of the established
correspondences, several significant extensions of each of the above formalisms
become available. The high expressiveness of the logic we propose and the need
for capturing the reasoning in different contexts forces us to distinguish
between unrestricted and finite model reasoning. A notable feature of our
proposal is that reasoning in both cases is decidable. We argue that, by virtue
of the high expressive power and of the associated reasoning capabilities on
both unrestricted and finite models, our logic provides a common core for
class-based representation formalisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5453</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5453</id><created>2011-05-26</created><authors><author><keyname>Rintanen</keyname><forenames>J.</forenames></author></authors><title>Complexity of Prioritized Default Logics</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 9, pages
  423-461, 1998</journal-ref><doi>10.1613/jair.554</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In default reasoning, usually not all possible ways of resolving conflicts
between default rules are acceptable. Criteria expressing acceptable ways of
resolving the conflicts may be hardwired in the inference mechanism, for
example specificity in inheritance reasoning can be handled this way, or they
may be given abstractly as an ordering on the default rules. In this article we
investigate formalizations of the latter approach in Reiter's default logic.
Our goal is to analyze and compare the computational properties of three such
formalizations in terms of their computational complexity: the prioritized
default logics of Baader and Hollunder, and Brewka, and a prioritized default
logic that is based on lexicographic comparison. The analysis locates the
propositional variants of these logics on the second and third levels of the
polynomial hierarchy, and identifies the boundary between tractable and
intractable inference for restricted classes of prioritized default theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5454</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5454</id><created>2011-05-26</created><authors><author><keyname>Clements</keyname><forenames>D. P.</forenames></author><author><keyname>Joslin</keyname><forenames>D. E.</forenames></author></authors><title>Squeaky Wheel Optimization</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  353-373, 1999</journal-ref><doi>10.1613/jair.561</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a general approach to optimization which we term `Squeaky Wheel'
Optimization (SWO). In SWO, a greedy algorithm is used to construct a solution
which is then analyzed to find the trouble spots, i.e., those elements, that,
if improved, are likely to improve the objective function score. The results of
the analysis are used to generate new priorities that determine the order in
which the greedy algorithm constructs the next solution. This
Construct/Analyze/Prioritize cycle continues until some limit is reached, or an
acceptable solution is found. SWO can be viewed as operating on two search
spaces: solutions and prioritizations. Successive solutions are only indirectly
related, via the re-prioritization that results from analyzing the prior
solution. Similarly, successive prioritizations are generated by constructing
and analyzing solutions. This `coupled search' has some interesting properties,
which we discuss. We report encouraging experimental results on two domains,
scheduling problems that arise in fiber-optic cable manufacturing, and graph
coloring problems. The fact that these domains are very different supports our
claim that SWO is a general technique for optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5455</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5455</id><created>2011-05-26</created><authors><author><keyname>Barber</keyname><forenames>D.</forenames></author><author><keyname>de van Laar</keyname><forenames>P.</forenames></author></authors><title>Variational Cumulant Expansions for Intractable Distributions</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  435-455, 1999</journal-ref><doi>10.1613/jair.567</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Intractable distributions present a common difficulty in inference within the
probabilistic knowledge representation framework and variational methods have
recently been popular in providing an approximate solution. In this article, we
describe a perturbational approach in the form of a cumulant expansion which,
to lowest order, recovers the standard Kullback-Leibler variational bound.
Higher-order terms describe corrections on the variational approach without
incurring much further computational cost. The relationship to other
perturbational approaches such as TAP is also elucidated. We demonstrate the
method on a particular class of undirected graphical models, Boltzmann
machines, for which our simulation results confirm improved accuracy and
enhanced stability during learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5457</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5457</id><created>2011-05-26</created><authors><author><keyname>Fox</keyname><forenames>M.</forenames></author><author><keyname>Long</keyname><forenames>D.</forenames></author></authors><title>Efficient Implementation of the Plan Graph in STAN</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  87-115, 1999</journal-ref><doi>10.1613/jair.570</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  STAN is a Graphplan-based planner, so-called because it uses a variety of
STate ANalysis techniques to enhance its performance. STAN competed in the
AIPS-98 planning competition where it compared well with the other competitors
in terms of speed, finding solutions fastest to many of the problems posed.
Although the domain analysis techniques STAN exploits are an important factor
in its overall performance, we believe that the speed at which STAN solved the
competition problems is largely due to the implementation of its plan graph.
The implementation is based on two insights: that many of the graph
construction operations can be implemented as bit-level logical operations on
bit vectors, and that the graph should not be explicitly constructed beyond the
fix point. This paper describes the implementation of STAN's plan graph and
provides experimental results which demonstrate the circumstances under which
advantages can be obtained from using this implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5458</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5458</id><created>2011-05-26</created><authors><author><keyname>Fuchs</keyname><forenames>M.</forenames></author><author><keyname>Fuchs</keyname><forenames>D.</forenames></author></authors><title>Cooperation between Top-Down and Bottom-Up Theorem Provers</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  169-198, 1999</journal-ref><doi>10.1613/jair.573</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Top-down and bottom-up theorem proving approaches each have specific
advantages and disadvantages. Bottom-up provers profit from strong redundancy
control but suffer from the lack of goal-orientation, whereas top-down provers
are goal-oriented but often have weak calculi when their proof lengths are
considered. In order to integrate both approaches, we try to achieve
cooperation between a top-down and a bottom-up prover in two different ways:
The first technique aims at supporting a bottom-up with a top-down prover. A
top-down prover generates subgoal clauses, they are then processed by a
bottom-up prover. The second technique deals with the use of bottom-up
generated lemmas in a top-down prover. We apply our concept to the areas of
model elimination and superposition. We discuss the ability of our techniques
to shorten proofs as well as to reorder the search space in an appropriate
manner. Furthermore, in order to identify subgoal clauses and lemmas which are
actually relevant for the proof task, we develop methods for a relevancy-based
filtering. Experiments with the provers SETHEO and SPASS performed in the
problem library TPTP reveal the high potential of our cooperation approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5459</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5459</id><created>2011-05-26</created><authors><author><keyname>Hogg</keyname><forenames>T.</forenames></author></authors><title>Solving Highly Constrained Search Problems with Quantum Computers</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  39-66, 1999</journal-ref><doi>10.1613/jair.574</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A previously developed quantum search algorithm for solving 1-SAT problems in
a single step is generalized to apply to a range of highly constrained k-SAT
problems. We identify a bound on the number of clauses in satisfiability
problems for which the generalized algorithm can find a solution in a constant
number of steps as the number of variables increases. This performance
contrasts with the linear growth in the number of steps required by the best
classical algorithms, and the exponential number required by classical and
quantum methods that ignore the problem structure. In some cases, the algorithm
can also guarantee that insoluble problems in fact have no solutions, unlike
previously proposed quantum search algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5460</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5460</id><created>2011-05-26</created><authors><author><keyname>Boutilier</keyname><forenames>C.</forenames></author><author><keyname>Dean</keyname><forenames>T.</forenames></author><author><keyname>Hanks</keyname><forenames>S.</forenames></author></authors><title>Decision-Theoretic Planning: Structural Assumptions and Computational
  Leverage</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  1-94, 1999</journal-ref><doi>10.1613/jair.575</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Planning under uncertainty is a central problem in the study of automated
sequential decision making, and has been addressed by researchers in many
different fields, including AI planning, decision analysis, operations
research, control theory and economics. While the assumptions and perspectives
adopted in these areas often differ in substantial ways, many planning problems
of interest to researchers in these fields can be modeled as Markov decision
processes (MDPs) and analyzed using the techniques of decision theory. This
paper presents an overview and synthesis of MDP-related methods, showing how
they provide a unifying framework for modeling many classes of planning
problems studied in AI. It also describes structural properties of MDPs that,
when exhibited by particular classes of problems, can be exploited in the
construction of optimal or approximately optimal policies or plans. Planning
problems commonly possess structure in the reward and value functions used to
describe performance criteria, in the functions used to describe state
transitions and observations, and in the relationships among features used to
describe states, actions, rewards, and observations. Specialized
representations, and algorithms employing these representations, can achieve
computational leverage by exploiting these various forms of structure. Certain
AI techniques -- in particular those based on the use of structured,
intensional representations -- can be viewed in this way. This paper surveys
several types of representations for both classical and decision-theoretic
planning problems, and planning algorithms that exploit these representations
in a number of different ways to ease the computational burden of constructing
policies or plans. It focuses primarily on abstraction, aggregation and
decomposition techniques based on AI-style representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5461</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5461</id><created>2011-05-26</created><authors><author><keyname>Lukasiewicz</keyname><forenames>T.</forenames></author></authors><title>Probabilistic Deduction with Conditional Constraints over Basic Events</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  199-241, 1999</journal-ref><doi>10.1613/jair.577</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of probabilistic deduction with conditional constraints
over basic events. We show that globally complete probabilistic deduction with
conditional constraints over basic events is NP-hard. We then concentrate on
the special case of probabilistic deduction in conditional constraint trees. We
elaborate very efficient techniques for globally complete probabilistic
deduction. In detail, for conditional constraint trees with point
probabilities, we present a local approach to globally complete probabilistic
deduction, which runs in linear time in the size of the conditional constraint
trees. For conditional constraint trees with interval probabilities, we show
that globally complete probabilistic deduction can be done in a global approach
by solving nonlinear programs. We show how these nonlinear programs can be
transformed into equivalent linear programs, which are solvable in polynomial
time in the size of the conditional constraint trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5462</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5462</id><created>2011-05-26</created><authors><author><keyname>Jaakkola</keyname><forenames>T. S.</forenames></author><author><keyname>Jordan</keyname><forenames>M. I.</forenames></author></authors><title>Variational Probabilistic Inference and the QMR-DT Network</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  291-322, 1999</journal-ref><doi>10.1613/jair.583</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a variational approximation method for efficient inference in
large-scale probabilistic models. Variational methods are deterministic
procedures that provide approximations to marginal and conditional
probabilities of interest. They provide alternatives to approximate inference
methods based on stochastic sampling or search. We describe a variational
approach to the problem of diagnostic inference in the `Quick Medical
Reference' (QMR) network. The QMR network is a large-scale probabilistic
graphical model built on statistical and expert knowledge. Exact probabilistic
inference is infeasible in this model for all but a small set of cases. We
evaluate our variational inference algorithm on a large set of diagnostic test
cases, comparing the algorithm to a state-of-the-art stochastic sampling
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5463</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5463</id><created>2011-05-26</created><authors><author><keyname>Borgida</keyname><forenames>A.</forenames></author></authors><title>Extensible Knowledge Representation: the Case of Description Reasoners</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  399-434, 1999</journal-ref><doi>10.1613/jair.584</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper offers an approach to extensible knowledge representation and
reasoning for a family of formalisms known as Description Logics. The approach
is based on the notion of adding new concept constructors, and includes a
heuristic methodology for specifying the desired extensions, as well as a
modularized software architecture that supports implementing extensions. The
architecture detailed here falls in the normalize-compared paradigm, and
supports both intentional reasoning (subsumption) involving concepts, and
extensional reasoning involving individuals after incremental updates to the
knowledge base. The resulting approach can be used to extend the reasoner with
specialized notions that are motivated by specific problems or application
areas, such as reasoning about dates, plans, etc. In addition, it provides an
opportunity to implement constructors that are not currently yet sufficiently
well understood theoretically, but are needed in practice. Also, for
constructors that are provably hard to reason with (e.g., ones whose presence
would lead to undecidability), it allows the implementation of incomplete
reasoners where the incompleteness is tailored to be acceptable for the
application at hand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5464</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5464</id><created>2011-05-26</created><authors><author><keyname>Cohen</keyname><forenames>W. W.</forenames></author><author><keyname>Schapire</keyname><forenames>R. E.</forenames></author><author><keyname>Singer</keyname><forenames>Y.</forenames></author></authors><title>Learning to Order Things</title><categories>cs.LG cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  243-270, 1999</journal-ref><doi>10.1613/jair.587</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many applications in which it is desirable to order rather than
classify instances. Here we consider the problem of learning how to order
instances given feedback in the form of preference judgments, i.e., statements
to the effect that one instance should be ranked ahead of another. We outline a
two-stage approach in which one first learns by conventional means a binary
preference function indicating whether it is advisable to rank one instance
before another. Here we consider an on-line algorithm for learning preference
functions that is based on Freund and Schapire's 'Hedge' algorithm. In the
second stage, new instances are ordered so as to maximize agreement with the
learned preference function. We show that the problem of finding the ordering
that agrees best with a learned preference function is NP-complete.
Nevertheless, we describe simple greedy algorithms that are guaranteed to find
a good approximation. Finally, we show how metasearch can be formulated as an
ordering problem, and present experimental results on learning a combination of
'search experts', each of which is a domain-specific query expansion strategy
for a web search engine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5465</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5465</id><created>2011-05-26</created><authors><author><keyname>Rintanen</keyname><forenames>J.</forenames></author></authors><title>Constructing Conditional Plans by a Theorem-Prover</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  323-352, 1999</journal-ref><doi>10.1613/jair.591</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research on conditional planning rejects the assumptions that there is no
uncertainty or incompleteness of knowledge with respect to the state and
changes of the system the plans operate on. Without these assumptions the
sequences of operations that achieve the goals depend on the initial state and
the outcomes of nondeterministic changes in the system. This setting raises the
questions of how to represent the plans and how to perform plan search. The
answers are quite different from those in the simpler classical framework. In
this paper, we approach conditional planning from a new viewpoint that is
motivated by the use of satisfiability algorithms in classical planning.
Translating conditional planning to formulae in the propositional logic is not
feasible because of inherent computational limitations. Instead, we translate
conditional planning to quantified Boolean formulae. We discuss three
formalizations of conditional planning as quantified Boolean formulae, and
present experimental results obtained with a theorem-prover.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5466</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5466</id><created>2011-05-26</created><authors><author><keyname>Ting</keyname><forenames>K. M.</forenames></author><author><keyname>Witten</keyname><forenames>I. H.</forenames></author></authors><title>Issues in Stacked Generalization</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  271-289, 1999</journal-ref><doi>10.1613/jair.594</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stacked generalization is a general method of using a high-level model to
combine lower-level models to achieve greater predictive accuracy. In this
paper we address two crucial issues which have been considered to be a `black
art' in classification tasks ever since the introduction of stacked
generalization in 1992 by Wolpert: the type of generalizer that is suitable to
derive the higher-level model, and the kind of attributes that should be used
as its input. We find that best results are obtained when the higher-level
model combines the confidence (and not just the predictions) of the lower-level
ones. We demonstrate the effectiveness of stacked generalization for combining
three different types of learning algorithms for classification tasks. We also
compare the performance of stacked generalization with majority vote and
published results of arcing and bagging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5476</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5476</id><created>2011-05-27</created><updated>2012-05-29</updated><authors><author><keyname>Cho</keyname><forenames>Sungyoon</forenames></author><author><keyname>Huang</keyname><forenames>Kaibin</forenames></author><author><keyname>Kim</keyname><forenames>Dongku</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Chae</keyname><forenames>Hyukjin</forenames></author><author><keyname>Seo</keyname><forenames>Hanbyul</forenames></author><author><keyname>Kim</keyname><forenames>Byounghoon</forenames></author></authors><title>Feedback-Topology Designs for Interference Alignment in MIMO
  Interference Channels</title><categories>cs.IT math.IT</categories><comments>28 pages; 11 figures ; submitted to IEEE Trans. on Signal Processing</comments><doi>10.1109/TSP.2012.2214214</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment (IA) is a joint-transmission technique that achieves
the capacity of the interference channel for high signal-to-noise ratios
(SNRs). Most prior work on IA is based on the impractical assumption that
perfect and global channel-state information(CSI) is available at all
transmitters. To implement IA, each receiver has to feed back CSI to all
interferers, resulting in overwhelming feedback overhead. In particular, the
sum feedback rate of each receiver scales quadratically with the number of
users even if the quantized CSI is fed back. To substantially suppress feedback
overhead, this paper focuses on designing efficient arrangements of feedback
links, called feedback topologies, under the IA constraint. For the
multiple-input-multiple-output (MIMO) K-user interference channel, we propose
the feedback topology that supports sequential CSI exchange (feedback and
feedforward) between transmitters and receivers so as to achieve IA
progressively. This feedback topology is shown to reduce the network feedback
overhead from a cubic function of K to a linear one. To reduce the delay in the
sequential CSI exchange, an alternative feedback topology is designed for
supporting two-hop feedback via a control station, which also achieves the
linear feedback scaling with K. Next, given the proposed feedback topologies,
the feedback-bit allocation algorithm is designed for allocating feedback bits
by each receiver to different feedback links so as to regulate the residual
interference caused by the finite-rate feedback. Simulation results demonstrate
that the proposed bit allocation leads to significant throughput gains
especially in strong interference environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5481</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5481</id><created>2011-05-27</created><authors><author><keyname>Zhang</keyname><forenames>Shixun</forenames></author><author><keyname>Yamagiwa</keyname><forenames>Shinichi</forenames></author><author><keyname>Okumura</keyname><forenames>Masahiko</forenames></author><author><keyname>Yunoki</keyname><forenames>Seiji</forenames></author></authors><title>Performance Acceleration of Kernel Polynomial Method Applying Graphics
  Processing Units</title><categories>physics.comp-ph cond-mat.other cs.PF</categories><comments>IPDPS/APDCM11, pp. 564-571, Anchorage USA, May 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Kernel Polynomial Method (KPM) is one of the fast diagonalization methods
used for simulations of quantum systems in research fields of condensed matter
physics and chemistry. The algorithm has a difficulty to be parallelized on a
cluster computer or a supercomputer due to the fine-gain recursive
calculations. This paper proposes an implementation of the KPM on the recent
graphics processing units (GPU) where the recursive calculations are able to be
parallelized in the massively parallel environment. This paper also illustrates
performance evaluations regarding the cases when the actual simulation
parameters are applied, the one for increased intensive calculations and the
one for increased amount of memory usage. Finally, it concludes that the
performance on GPU promises very high performance compared to the one on CPU
and reduces the overall simulation time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5487</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5487</id><created>2011-05-27</created><updated>2011-06-06</updated><authors><author><keyname>Bollig</keyname><forenames>Benedikt</forenames></author><author><keyname>Kuske</keyname><forenames>Dietrich</forenames></author></authors><title>An optimal construction of Hanf sentences</title><categories>cs.LO math.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first elementary construction of equivalent formulas in Hanf
normal form. The triply exponential upper bound is complemented by a matching
lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5488</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5488</id><created>2011-05-27</created><authors><author><keyname>Kurant</keyname><forenames>Maciej</forenames></author><author><keyname>Gjoka</keyname><forenames>Minas</forenames></author><author><keyname>Wang</keyname><forenames>Yan</forenames></author><author><keyname>Almquist</keyname><forenames>Zack W.</forenames></author><author><keyname>Butts</keyname><forenames>Carter T.</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author></authors><title>Coarse-Grained Topology Estimation via Graph Sampling</title><categories>cs.SI physics.data-an physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many online networks are measured and studied via sampling techniques, which
typically collect a relatively small fraction of nodes and their associated
edges. Past work in this area has primarily focused on obtaining a
representative sample of nodes and on efficient estimation of local graph
properties (such as node degree distribution or any node attribute) based on
that sample. However, less is known about estimating the global topology of the
underlying graph.
  In this paper, we show how to efficiently estimate the coarse-grained
topology of a graph from a probability sample of nodes. In particular, we
consider that nodes are partitioned into categories (e.g., countries or
work/study places in OSNs), which naturally defines a weighted category graph.
We are interested in estimating (i) the size of categories and (ii) the
probability that nodes from two different categories are connected. For each of
the above, we develop a family of estimators for design-based inference under
uniform or non-uniform sampling, employing either of two measurement
strategies: induced subgraph sampling, which relies only on information about
the sampled nodes; and star sampling, which also exploits category information
about the neighbors of sampled nodes. We prove consistency of these estimators
and evaluate their efficiency via simulation on fully known graphs. We also
apply our methodology to a sample of Facebook users to obtain a number of
category graphs, such as the college friendship graph and the country
friendship graph; we share and visualize the resulting data at
www.geosocialmap.com.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5504</identifier>
 <datestamp>2014-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5504</id><created>2011-05-27</created><updated>2012-01-23</updated><authors><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author><author><keyname>Tran</keyname><forenames>Ngoc Mai</forenames></author></authors><title>Combinatorial Types of Tropical Eigenvectors</title><categories>math.CO cs.DM</categories><comments>9 pages, 1 figure, exposition improved</comments><report-no>Mittag-Leffler-2011spring</report-no><doi>10.1112/blms/bds058</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The map which takes a square matrix to its tropical eigenvalue-eigenvector
pair is piecewise linear. We determine the cones of linearity of this map. They
are simplicial but they do not form a fan. Motivated by statistical ranking, we
also study the restriction of that cone decomposition to the subspace of
skew-symmetric matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5509</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5509</id><created>2011-05-27</created><authors><author><keyname>Vejdemo-Johansson</keyname><forenames>Mikael</forenames></author><author><keyname>Sk&#xf6;ldberg</keyname><forenames>Emil</forenames></author><author><keyname>Dusek</keyname><forenames>Jason</forenames></author></authors><title>A parallel Buchberger algorithm for multigraded ideals</title><categories>math.AC cs.DC cs.SC</categories><comments>8 pages, 6 figures</comments><report-no>Mittag-Leffler-2011spring</report-no><msc-class>13-04 13P10</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We demonstrate a method to parallelize the computation of a Gr\&quot;obner basis
for a homogenous ideal in a multigraded polynomial ring. Our method uses
anti-chains in the lattice $\mathbb N^k$ to separate mutually independent
S-polynomials for reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5515</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5515</id><created>2011-05-27</created><authors><author><keyname>Shuaib</keyname><forenames>Khaled</forenames></author><author><keyname>Sallabi</keyname><forenames>Farag</forenames></author><author><keyname>Zhang</keyname><forenames>Liren</forenames></author></authors><title>Smoothing and Modeling of Video Transmission Rates over a QoS Network
  with Limited Bandwidth Connections</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmission of video over a limited bandwidth network is challenging due to
the natural variability of video, and link characteristics. Video smoothing
techniques can be used to facilitate more effective transmission and to
preserve better quality. In this paper we develop a semi-optimal video
smoothing approach to manage the transmission of MPEG-4 and H.264 video while
mapping it to be more suitable for a QoS based network. The proposed technique
utilizes a smoothing buffer with pre-defined thresholds to smooth the
transmission rates while assuming minimal information about the video to be
transmitted. The results obtained showed a significant improvements in
transmission rate variability while guaranteeing no buffer overflows or
underflows. In addition, a queuing model is developed for the used smoothing
algorithm for H.264 video streams with optimized encoding and packetization,
utilizing the available H.264 macroblock ordering option.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5516</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5516</id><created>2011-05-27</created><updated>2011-08-18</updated><authors><author><keyname>Suchanek</keyname><forenames>Fabian</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Abiteboul</keyname><forenames>Serge</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Senellart</keyname><forenames>Pierre</forenames></author></authors><title>Ontology Alignment at the Instance and Schema Level</title><categories>cs.AI</categories><comments>Technical Report at INRIA RT-0408</comments><proxy>ccsd</proxy><report-no>RT-0408</report-no><journal-ref>N&amp;deg; RT-0408 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present PARIS, an approach for the automatic alignment of ontologies.
PARIS aligns not only instances, but also relations and classes. Alignments at
the instance-level cross-fertilize with alignments at the schema-level.
Thereby, our system provides a truly holistic solution to the problem of
ontology alignment. The heart of the approach is probabilistic. This allows
PARIS to run without any parameter tuning. We demonstrate the efficiency of the
algorithm and its precision through extensive experiments. In particular, we
obtain a precision of around 90% in experiments with two of the world's largest
ontologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5518</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5518</id><created>2011-05-27</created><authors><author><keyname>Rantala</keyname><forenames>Pekka</forenames></author><author><keyname>Virtanen</keyname><forenames>Seppo</forenames></author><author><keyname>Isoaho</keyname><forenames>Jouni</forenames></author></authors><title>Hybrid Trust Model for Internet Routing</title><categories>cs.NI</categories><comments>in Special Issue on Networks and Communication in International
  Journal of Computer Networks &amp; Communications (IJCNC), Vol 3, No 3, May 2011</comments><doi>10.5121/ijcnc.2011.3301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The current Internet is based on a fundamental assumption of reliability and
good intent among actors in the network. Unfortunately, unreliable and
malicious behaviour is becoming a major obstacle for Internet communication. In
order to improve the trustworthiness and reliability of the network
infrastructure, we propose a novel trust model to be incorporated into BGP
routing. In our approach, trust model is defined by combining voting and
recommendation to direct trust estimation for neighbour routers located in
different autonomous systems. We illustrate the impact of our approach with
cases that demonstrate the indication of distrusted paths beyond the nearest
neighbours and the detection of a distrusted neighbour advertising a trusted
path. We simulated the impact of weighting voted and direct trust in a
rectangular grid of 15*15 nodes (autonomous systems) with a randomly connected
topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5521</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5521</id><created>2011-05-27</created><authors><author><keyname>Janakiraman</keyname><forenames>T. N.</forenames></author><author><keyname>Thilak</keyname><forenames>A. Senthil</forenames></author></authors><title>Design and Analysis of SD_DWCA - A Mobility based clustering of
  Homogeneous MANETs</title><categories>cs.DM math.CO</categories><doi>10.5121/ijcnc.2011.3307</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the design and analysis of the distributed weighted
clustering algorithm SD_DWCA proposed for homogeneous mobile ad hoc networks.
It is a connectivity, mobility and energy based clustering algorithm which is
suitable for scalable ad hoc networks. The algorithm uses a new graph parameter
called strong degree defined based on the quality of neighbours of a node. The
parameters are so chosen to ensure high connectivity, cluster stability and
energy efficient communication among nodes of high dynamic nature. This paper
also includes the experimental results of the algorithm implemented using the
network simulator NS2. The experimental results show that the algorithm is
suitable for high speed networks and generate stable clusters with less
maintenance overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5540</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5540</id><created>2011-05-27</created><authors><author><keyname>Lehre</keyname><forenames>Per Kristian</forenames></author><author><keyname>Witt</keyname><forenames>Carsten</forenames></author></authors><title>Finite First Hitting Time versus Stochastic Convergence in Particle
  Swarm Optimisation</title><categories>cs.NE</categories><comments>An extended version of a paper that will appear in the Proceedings of
  the 9th Metaheuristics International Conference (MIC 2011), Udine, Italy,
  July 25th-28th, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We reconsider stochastic convergence analyses of particle swarm optimisation,
and point out that previously obtained parameter conditions are not always
sufficient to guarantee mean square convergence to a local optimum. We show
that stagnation can in fact occur for non-trivial configurations in non-optimal
parts of the search space, even for simple functions like SPHERE. The
convergence properties of the basic PSO may in these situations be detrimental
to the goal of optimisation, to discover a sufficiently good solution within
reasonable time. To characterise optimisation ability of algorithms, we suggest
the expected first hitting time (FHT), i.e., the time until a search point in
the vicinity of the optimum is visited. It is shown that a basic PSO may have
infinite expected FHT, while an algorithm introduced here, the Noisy PSO, has
finite expected FHT on some functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5542</identifier>
 <datestamp>2012-12-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5542</id><created>2011-05-27</created><updated>2012-08-06</updated><authors><author><keyname>Molkaraie</keyname><forenames>Mehdi</forenames></author><author><keyname>Loeliger</keyname><forenames>Hans-Andrea</forenames></author></authors><title>Monte Carlo Algorithms for the Partition Function and Information Rates
  of Two-Dimensional Channels</title><categories>cs.IT math.IT stat.AP stat.CO</categories><journal-ref>IEEE Trans. on Information Theory, Volume 59, Jan. 2013, pp.
  495-503</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes Monte Carlo algorithms for the computation of the
information rate of two-dimensional source/channel models. The focus of the
paper is on binary-input channels with constraints on the allowed input
configurations. The problem of numerically computing the information rate, and
even the noiseless capacity, of such channels has so far remained largely
unsolved. Both problems can be reduced to computing a Monte Carlo estimate of a
partition function. The proposed algorithms use tree-based Gibbs sampling and
multilayer (multitemperature) importance sampling. The viability of the
proposed algorithms is demonstrated by simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5545</identifier>
 <datestamp>2012-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5545</id><created>2011-05-27</created><updated>2012-05-03</updated><authors><author><keyname>Castellano</keyname><forenames>Claudio</forenames></author><author><keyname>Pastor-Satorras</keyname><forenames>Romualdo</forenames></author></authors><title>Competing activation mechanisms in epidemics on networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>32 pages, 10 figures</comments><journal-ref>Nature Scientific Reports 2, 371 (2012)</journal-ref><doi>10.1038/srep00371</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In contrast to previous common wisdom that epidemic activity in heterogeneous
networks is dominated by the hubs with the largest number of connections,
recent research has pointed out the role that the innermost, dense core of the
network plays in sustaining epidemic processes. Here we show that the mechanism
responsible of spreading depends on the nature of the process. Epidemics with a
transient state are boosted by the innermost core. Contrarily, epidemics
allowing a steady state present a dual scenario, where either the hub
independently sustains activity and propagates it to the rest of the system,
or, alternatively, the innermost network core collectively turns into the
active state, maintaining it globally. In uncorrelated networks the former
mechanism dominates if the degree distribution decays with an exponent larger
than 5/2, and the latter otherwise. Topological correlations, rife in real
networks, may perturb this picture, mixing the role of both mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5553</identifier>
 <datestamp>2011-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5553</id><created>2011-05-27</created><updated>2011-06-21</updated><authors><author><keyname>Feng</keyname><forenames>Shu</forenames></author><author><keyname>Mao</keyname><forenames>Wang</forenames></author><author><keyname>Xiajie</keyname><forenames>Shi</forenames></author><author><keyname>Junhao</keyname><forenames>Liu</forenames></author><author><keyname>Weixin</keyname><forenames>Sheng</forenames></author><author><keyname>Renhong</keyname><forenames>Xie</forenames></author></authors><title>A Frequency-domain Compensation Scheme for IQ-Imbalance in OFDM
  Receivers</title><categories>cs.NI cs.MM</categories><comments>17 pages, 6 figures</comments><acm-class>C.2.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  A pilot pattern across two OFDM symbols with special structure is devised for
channel estimation in OFDM systems with IQ imbalance at receiver. Based on this
pilot pattern, a high-efficiency time-domain (TD) least square (LS) channel
estimator is proposed to significantly suppress channel noise by a factor
N/(L+1) in comparison with the frequency-domain LS one in [1] where N and L+1
are the total number of subcarriers and the length of cyclic prefix,
respectively. Following this, a low-complexity frequency-domain (FD) Gaussian
elimination (GE) equalizer is proposed to eliminate IQ distortion by using only
2N complex multiplications per OFDM symbol. From simulation, the proposed
scheme TD-LS/FD-GE using only two pilot OFDM symbols achieves the same bit
error rate (BER) performance under ideal channel knowledge and no IQ imbalances
at low and medium signal-to-noise ratio (SNR) regions whereas these
compensation schemes including FD-LS/Post-FFT LS, FD-LS/Pre-FFT Corr, and
SPP/Pre-FFT Corr in [1] require about twenty OFDM training symbols to reach the
same performance where A/B denotes compensation scheme with A being channel
estimator and B being equalizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5557</identifier>
 <datestamp>2012-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5557</id><created>2011-05-27</created><updated>2012-04-17</updated><authors><author><keyname>Campello</keyname><forenames>Antonio</forenames></author><author><keyname>Jorge</keyname><forenames>Grasiele C.</forenames></author><author><keyname>Costa</keyname><forenames>Sueli I. R.</forenames></author></authors><title>Decoding q-ary lattices in the Lee metric</title><categories>cs.IT math.CO math.IT</categories><comments>5 pages, 4 figures. Presented at the 2012 Information Theory Workshop
  (ITW)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  q-ary lattices can be obtained from q-ary codes using the so-called
Construction A. We investigate these lattices in the Lee metric and show how
their decoding process can be related to the associated codes. For prime q we
derive a Lee sphere decoding algorithm for q-ary lattices, present a brief
discussion on its complexity and some comparisons with the classic sphere
decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5563</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5563</id><created>2011-05-27</created><authors><author><keyname>Sarma</keyname><forenames>Abhijit</forenames></author><author><keyname>Joshi</keyname><forenames>Shantanu</forenames></author><author><keyname>Nandi</keyname><forenames>Sukumar</forenames></author></authors><title>Context Awarw Mobile Initiated Handoff for Performance Improvement in
  IEEE 802.11 Networks</title><categories>cs.NI</categories><comments>19 pages, 14 figures</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.3, No.3, May 2011 pp 48-66</journal-ref><doi>10.5121/ijcnc.2011.3304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IEEE 802.11 is a widely used wireless LAN standard which offers a good
bandwidth at low cost In an ESS, multiple APs can co-exist with overlapping
coverage area. A mobile node connects to the AP from which it receives the best
signal. Changes in traffic to and from different MNs occur over time. Load
imbalance may develop on different APs. Throughput and delay of the different
flows passing through the APs, where the load has increased beyond certain
limit, may degrade. Different MNs associated to the overloaded APs will
experience performance degradation. Overall performance of the ESS will also
drop. In this paper we propose a scheme where MNs experiencing degraded
performance will initiate action and with assistance from the associate AP
perform handoff to less loaded AP within its range to improve performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5575</identifier>
 <datestamp>2012-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5575</id><created>2011-05-27</created><authors><author><keyname>Tahat</keyname><forenames>Amani</forenames></author><author><keyname>Salah</keyname><forenames>Wa'el</forenames></author></authors><title>Comprehensive online Atomic Database Management System (DBMS) with
  Highly Qualified Computing Capabilities</title><categories>physics.atom-ph astro-ph.CO astro-ph.IM cs.DB</categories><comments>20 pages,4 figures, 5 tables, 2 appendixes; International Journal of
  Database Management Systems (IJDMS), Vol.3, No.2, May 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The intensive need of atomic data is expanding continuously in a wide variety
of applications (e.g. fusion energy and astrophysics, laser-produced, plasma
researches, and plasma processing).This paper will introduce our ongoing
research work to build a comprehensive, complete, up-to-date, user friendly and
online atomic Database Management System (DBMS) namely called AIMS by using
SQLite (http://www.sqlite.org/about.html)(8). Programming language tools and
techniques will not be covered here. The system allows the generation of
various atomic data based on professional online atomic calculators. The
ongoing work is a step forward to bring detailed atomic model accessible to a
wide community of laboratory and astrophysical plasma diagnostics. AIMS is a
professional worldwide tool for supporting several educational purposes and can
be considered as a complementary database of IAEA atomic databases. Moreover,
it will be an exceptional strategy of incorporating the output data of several
atomic codes to external spectral models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5592</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5592</id><created>2011-05-27</created><authors><author><keyname>Song</keyname><forenames>Le</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Low</keyname><forenames>Yucheng</forenames></author><author><keyname>Guestrin</keyname><forenames>Carlos</forenames></author></authors><title>Kernel Belief Propagation</title><categories>cs.LG</categories><journal-ref>In the Fourteenth International Conference on Artificial
  Intelligence and Statistics April 11-13, 2011 Ft. Lauderdale, FL, USA</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a nonparametric generalization of belief propagation, Kernel
Belief Propagation (KBP), for pairwise Markov random fields. Messages are
represented as functions in a reproducing kernel Hilbert space (RKHS), and
message updates are simple linear operations in the RKHS. KBP makes none of the
assumptions commonly required in classical BP algorithms: the variables need
not arise from a finite domain or a Gaussian distribution, nor must their
relations take any particular parametric form. Rather, the relations between
variables are represented implicitly, and are learned nonparametrically from
training data. KBP has the advantage that it may be used on any domain where
kernels are defined (Rd, strings, groups), even where explicit parametric
models are not known, or closed form expressions for the BP updates do not
exist. The computational cost of message updates in KBP is polynomial in the
training data size. We also propose a constant time approximate message update
procedure by representing messages using a small number of basis functions. In
experiments, we apply KBP to image denoising, depth prediction from still
images, and protein configuration prediction: KBP is faster than competing
classical and nonparametric approaches (by orders of magnitude, in some cases),
while providing significantly more accurate results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5593</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5593</id><created>2011-05-27</created><authors><author><keyname>Goyal</keyname><forenames>Ruchita</forenames></author><author><keyname>Divyanshu</keyname></author><author><keyname>Mishra</keyname><forenames>Manoj</forenames></author></authors><title>Quality of Service Provisioning in Manet Using a Cross-Layer Approach
  for Routing</title><categories>cs.NI</categories><comments>12 pages, 12 figures</comments><acm-class>C.2.2</acm-class><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC) Vol.3, No.3, May 2011, 81-92</journal-ref><doi>10.5121/ijcnc.2011.3306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deployment of multimedia applications warrants provisioning of Quality of
Service (QoS) in MANET. However, limited battery power, other resource
constraints and mobility of nodes make QoS provisioning difficult to achieve in
MANET. This difficulty can be overcome by using a cross-layer approach for
routing. In [1] Patil et al., proposed a cross-layer routing protocol named
Cost Based Power Aware Cross Layer - AODV (CPACL-AODV) which overcomes the
limitation of battery power of nodes. Though many similar energy efficient and
cross-layer routing protocols have been proposed for MANET, none of them
handles QoS. A novel MANET routing protocol, Type of Service, Power and
Bandwidth Aware AODV (TSPBA-AODV), which overcomes resource constraints and
simultaneously provides QoS guarantees using a cross-layer approach, is
proposed in this paper. In addition the effect of variation in nodes' mobility
on performance of TSPBA-AODV is compared with that of CPACL-AODV [1] for two
different types of network traffic. As shown by the results of simulations
performed, TSPBA-AODV performs better than CPACL-AODV for MANET in which nodes
move with small speeds (speeds up to 40 Km/hr approx.). In addition the effect
of variation in data sending rate of nodes on performance of the protocols is
also studied. As shown by the results of simulations performed, TSPBA-AODV
performs better than CPACL-AODV for all variations in data sending rate of
nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5594</identifier>
 <datestamp>2014-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5594</id><created>2011-05-27</created><updated>2011-08-18</updated><authors><author><keyname>Nelson</keyname><forenames>Kenric P.</forenames></author><author><keyname>Scannell</keyname><forenames>Brian J.</forenames></author><author><keyname>Landau</keyname><forenames>Herbert</forenames></author></authors><title>A risk profile for information fusion algorithms</title><categories>cs.IT cond-mat.stat-mech math.IT</categories><comments>15 pages, 4 figures</comments><journal-ref>Entropy, vol. 13, no. 8, pp. 1518-1532, 2011</journal-ref><doi>10.3390/e13081518</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  E.T. Jaynes, originator of the maximum entropy interpretation of statistical
mechanics, emphasized that there is an inevitable trade-off between the
conflicting requirements of robustness and accuracy for any inferencing
algorithm. This is because robustness requires discarding of information in
order to reduce the sensitivity to outliers. The principal of nonlinear
statistical coupling, which is an interpretation of the Tsallis entropy
generalization, can be used to quantify this trade-off. The coupled-surprisal,
-ln_k (p)=-(p^k-1)/k, is a generalization of Shannon surprisal or the
logarithmic scoring rule, given a forecast p of a true event by an inferencing
algorithm. The coupling parameter k=1-q, where q is the Tsallis entropy index,
is the degree of nonlinear coupling between statistical states. Positive
(negative) values of nonlinear coupling decrease (increase) the surprisal
information metric and thereby biases the risk in favor of decisive (robust)
algorithms relative to the Shannon surprisal (k=0). We show that translating
the average coupled-surprisal to an effective probability is equivalent to
using the generalized mean of the true event probabilities as a scoring rule.
The metric is used to assess the robustness, accuracy, and decisiveness of a
fusion algorithm. We use a two-parameter fusion algorithm to combine input
probabilities from N sources. The generalized mean parameter 'alpha' varies the
degree of smoothing and raising to a power N^beta with beta between 0 and 1
provides a model of correlation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5623</identifier>
 <datestamp>2011-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5623</id><created>2011-05-27</created><authors><author><keyname>Agrawal</keyname><forenames>Sudhir</forenames></author><author><keyname>Jain</keyname><forenames>Sanjeev</forenames></author><author><keyname>Sharma</keyname><forenames>Sanjeev</forenames></author></authors><title>A Survey of Routing Attacks and Security Measures in Mobile Ad-Hoc
  Networks</title><categories>cs.NI</categories><comments>7 pages journal of computing vol3 issue 1 january2011</comments><journal-ref>Journal of Computing, Volume 3, Issue 1, January 2011, 41-48</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile ad hoc networks (MANETs) are a set of mobile nodes which are
self-configuring and connected by wireless links automatically as per the
defined routing protocol. The absence of a central management agency or a fixed
infrastructure is a key feature of MANETs. These nodes communicate with each
other by interchange of packets, which for those nodes not in wireless range
goes hop by hop. Due to lack of a defined central authority, securitizing the
routing process becomes a challenging task thereby leaving MANETs vulnerable to
attacks, which results in deterioration in the performance characteristics as
well as raises a serious question mark about the reliability of such networks.
In this paper we have attempted to present an overview of the routing
protocols, the known routing attacks and the proposed countermeasures to these
attacks in various works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5639</identifier>
 <datestamp>2012-07-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5639</id><created>2011-05-27</created><updated>2012-07-09</updated><authors><author><keyname>Tchamkerten</keyname><forenames>Aslan</forenames></author><author><keyname>Chandar</keyname><forenames>Venkat</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Asynchronous Communication: Capacity Bounds and Suboptimality of
  Training</title><categories>cs.IT math.IT</categories><comments>27 pages, 8 figures, submitted to the IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several aspects of the problem of asynchronous point-to-point communication
without feedback are developed when the source is highly intermittent. In the
system model of interest, the codeword is transmitted at a random time within a
prescribed window whose length corresponds to the level of asynchronism between
the transmitter and the receiver. The decoder operates sequentially and
communication rate is defined as the ratio between the message size and the
elapsed time between when transmission commences and when the decoder makes a
decision.
  For such systems, general upper and lower bounds on capacity as a function of
the level of asynchronism are established, and are shown to coincide in some
nontrivial cases. From these bounds, several properties of this asynchronous
capacity are derived. In addition, the performance of training-based schemes is
investigated. It is shown that such schemes, which implement synchronization
and information transmission on separate degrees of freedom in the encoding,
cannot achieve the asynchronous capacity in general, and that the penalty is
particularly significant in the high-rate regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5640</identifier>
 <datestamp>2012-06-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5640</id><created>2011-05-27</created><updated>2012-06-20</updated><authors><author><keyname>Mari</keyname><forenames>Federico</forenames></author><author><keyname>Melatti</keyname><forenames>Igor</forenames></author><author><keyname>Salvo</keyname><forenames>Ivano</forenames></author><author><keyname>Tronci</keyname><forenames>Enrico</forenames></author></authors><title>Quantized Feedback Control Software Synthesis from System Level Formal
  Specifications for Buck DC/DC Converters</title><categories>cs.SY math.OC</categories><comments>arXiv admin note: text overlap with arXiv:1107.5638</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many Embedded Systems are indeed Software Based Control Systems (SBCSs), that
is control systems whose controller consists of control software running on a
microcontroller device. This motivates investigation on Formal Model Based
Design approaches for automatic synthesis of SBCS control software. In previous
works we presented an algorithm, along with a tool QKS implementing it, that
from a formal model (as a Discrete Time Linear Hybrid System, DTLHS) of the
controlled system (plant), implementation specifications (that is, number of
bits in the Analog-to-Digital, AD, conversion) and System Level Formal
Specifications (that is, safety and liveness requirements for the closed loop
system) returns correct-by-construction control software that has a Worst Case
Execution Time (WCET) linear in the number of AD bits and meets the given
specifications. In this technical report we present full experimental results
on using it to synthesize control software for two versions of buck DC-DC
converters (single-input and multi-input), a widely used mixed-mode analog
circuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5641</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5641</id><created>2011-05-27</created><authors><author><keyname>Jaganathan</keyname><forenames>Suresh</forenames></author><author><keyname>Eranti</keyname><forenames>Jeevan</forenames></author></authors><title>High Quality of Service on Video Streaming in P2P Networks using FST-MDC</title><categories>cs.DC cs.MM</categories><comments>11 pages, 8 figures, journal</comments><journal-ref>International Journal of Multimedia &amp; Its Applications (IJMA),
  Vol:3, No:2, May 2011, 33-43</journal-ref><doi>10.5121/ijma.2011.3203</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Video streaming applications have newly attracted a large number of
participants in a distribution network. Traditional client-server based video
streaming solutions sustain precious bandwidth provision rate on the server.
Recently, several P2P streaming systems have been organized to provide
on-demand and live video streaming services on the wireless network at reduced
server cost. Peer-to-Peer (P2P) computing is a new pattern to construct
disseminated network applications. Typical error control techniques are not
very well matched and on the other hand error prone channels has increased
greatly for video transmission e.g., over wireless networks and IP. These two
facts united together provided the essential motivation for the development of
a new set of techniques (error concealment) capable of dealing with
transmission errors in video systems. In this paper, we propose an flexible
multiple description coding method named as Flexible Spatial-Temporal (FST)
which improves error resilience in the sense of frame loss possibilities over
independent paths. It introduces combination of both spatial and temporal
concealment technique at the receiver and to conceal the lost frames more
effectively. Experimental results show that, proposed approach attains
reasonable quality of video performance over P2P wireless network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5651</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5651</id><created>2011-05-27</created><updated>2012-06-21</updated><authors><author><keyname>Banerjee</keyname><forenames>Siddhartha</forenames></author><author><keyname>Gupta</keyname><forenames>Piyush</forenames></author><author><keyname>Shakkottai</keyname><forenames>Sanjay</forenames></author></authors><title>Towards a Queueing-Based Framework for In-Network Function Computation</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We seek to develop network algorithms for function computation in sensor
networks. Specifically, we want dynamic joint aggregation, routing, and
scheduling algorithms that have analytically provable performance benefits due
to in-network computation as compared to simple data forwarding. To this end,
we define a class of functions, the Fully-Multiplexible functions, which
includes several functions such as parity, MAX, and k th -order statistics. For
such functions we exactly characterize the maximum achievable refresh rate of
the network in terms of an underlying graph primitive, the min-mincut. In
acyclic wireline networks, we show that the maximum refresh rate is achievable
by a simple algorithm that is dynamic, distributed, and only dependent on local
information. In the case of wireless networks, we provide a MaxWeight-like
algorithm with dynamic flow splitting, which is shown to be throughput-optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5652</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5652</id><created>2011-05-27</created><authors><author><keyname>Ekstein</keyname><forenames>Jan</forenames></author><author><keyname>Holub</keyname><forenames>P&#x159;emysl</forenames></author><author><keyname>Lidick&#xfd;</keyname><forenames>Bernard</forenames></author></authors><title>Packing Chromatic Number of Distance Graphs</title><categories>cs.DM math.CO</categories><comments>13 pages, 3 figures</comments><msc-class>05C12, 05C15</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The packing chromatic number $\chi_{\rho}(G)$ of a graph $G$ is the smallest
integer $k$ such that vertices of $G$ can be partitioned into disjoint classes
$X_1, ..., X_k$ where vertices in $X_i$ have pairwise distance greater than
$i$. We study the packing chromatic number of infinite distance graphs $G(Z,
D)$, i.e. graphs with the set $Z$ of integers as vertex set and in which two
distinct vertices $i, j \in Z$ are adjacent if and only if $|i - j| \in D$. In
this paper we focus on distance graphs with $D = \{1, t\}$. We improve some
results of Togni who initiated the study. It is shown that $\chi_{\rho}(G(Z,
D)) \leq 35$ for sufficiently large odd $t$ and $\chi_{\rho}(G(Z, D)) \leq 56$
for sufficiently large even $t$. We also give a lower bound 12 for $t \geq 9$
and tighten several gaps for $\chi_{\rho}(G(Z, D))$ with small $t$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5667</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5667</id><created>2011-05-27</created><authors><author><keyname>Davies</keyname><forenames>Jessica</forenames></author><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Complexity of and Algorithms for Borda Manipulation</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that it is NP-hard for a coalition of two manipulators to compute
how to manipulate the Borda voting rule. This resolves one of the last open
problems in the computational complexity of manipulating common voting rules.
Because of this NP-hardness, we treat computing a manipulation as an
approximation problem where we try to minimize the number of manipulators.
Based on ideas from bin packing and multiprocessor scheduling, we propose two
new approximation methods to compute manipulations of the Borda rule.
Experiments show that these methods significantly outperform the previous best
known %existing approximation method. We are able to find optimal manipulations
in almost all the randomly generated elections tested. Our results suggest
that, whilst computing a manipulation of the Borda rule by a coalition is
NP-hard, computational complexity may provide only a weak barrier against
manipulation in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5675</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5675</id><created>2011-05-27</created><authors><author><keyname>Xie</keyname><forenames>Jierui</forenames></author><author><keyname>Beigi</keyname><forenames>Mandis S.</forenames></author></authors><title>Scale-Invariant Local Descriptor for Event Recognition in 1D Sensor
  Signals</title><categories>cs.MM cs.CV</categories><journal-ref>IEEE International Conference on Multimedia &amp;
  Expo(ICME),Page(s):1226 - 1229, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a shape-based, time-scale invariant feature
descriptor for 1-D sensor signals. The time-scale invariance of the feature
allows us to use feature from one training event to describe events of the same
semantic class which may take place over varying time scales such as walking
slow and walking fast. Therefore it requires less training set. The descriptor
takes advantage of the invariant location detection in the scale space theory
and employs a high level shape encoding scheme to capture invariant local
features of events. Based on this descriptor, a scale-invariant classifier with
&quot;R&quot; metric (SIC-R) is designed to recognize multi-scale events of human
activities. The R metric combines the number of matches of keypoint in scale
space with the Dynamic Time Warping score. SICR is tested on various types of
1-D sensors data from passive infrared, accelerometer and seismic sensors with
more than 90% classification accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5676</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5676</id><created>2011-05-27</created><updated>2011-06-10</updated><authors><author><keyname>Fanous</keyname><forenames>Anthony</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author></authors><title>Transmission Control of Two-User Slotted ALOHA Over Gilbert-Elliott
  Channel: Stability and Delay Analysis</title><categories>cs.IT math.IT</categories><comments>7 pages, 3 figures, to appear in part in IEEE International Symposium
  on Information Theory (ISIT) 2011. This version has all the proofs omitted in
  the conference version due to space limitations. Version 2 fixed a minor typo
  in equation (36), all the results are correct and unchanged</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of calculating the stability region
and average delay of two user slotted ALOHA over a Gilbert-Elliott channel,
where users have channel state information and adapt their transmission
probabilities according to the channel state. Each channel has two states,
namely, the 'good' and 'bad' states. In the 'bad' state, the channel is assumed
to be in deep fade and the transmission fails with probability one, while in
the 'good' state, there is some positive success probability. We calculate the
Stability region with and without Multipacket Reception capability as well as
the average delay without MPR. Our results show that the stability region of
the controlled S-ALOHA is always a superset of the stability region of
uncontrolled S-ALOHA. Moreover, if the channel tends to be in the 'bad' state
for long proportion of time, then the stability region is a convex Polyhedron
strictly containing the TDMA stability region and the optimal transmission
strategy is to transmit with probability one whenever the nodes have packets
and it is shown that this strategy is delay optimal. On the other hand, if the
channel tends to be in the 'good' state more often, then the stability region
is bounded by a convex curve and is strict subset of the TDMA stability region.
We also show that enhancing the physical layer by allowing MPR capability can
significantly enhance the performance while simplifying the MAC Layer design by
the lack of the need of scheduling under some conditions. Furthermore, it is
shown that transmission control not only allows handling higher stable arrival
rates but also leads to lower delay for the same arrival rate compared with
ordinary S-ALOHA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5678</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5678</id><created>2011-05-27</created><authors><author><keyname>Sadlo</keyname><forenames>Filip</forenames></author><author><keyname>Weiskopf</keyname><forenames>Daniel</forenames></author></authors><title>Time-Dependent 2-D Vector Field Topology: An Approach Inspired by
  Lagrangian Coherent Structures</title><categories>cs.GR math.AP math.DS nlin.CD physics.data-an physics.flu-dyn</categories><acm-class>I.3.8; J.2</acm-class><journal-ref>Computer Graphics Forum, Volume 29, Issue 1, pages 88-100, March
  2010</journal-ref><doi>10.1111/j.1467-8659.2009.01546.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an approach to a time-dependent variant of the concept of
vector field topology for 2-D vector fields. Vector field topology is defined
for steady vector fields and aims at discriminating the domain of a vector
field into regions of qualitatively different behaviour. The presented approach
represents a generalization for saddle-type critical points and their
separatrices to unsteady vector fields based on generalized streak lines, with
the classical vector field topology as its special case for steady vector
fields. The concept is closely related to that of Lagrangian coherent
structures obtained as ridges in the finite-time Lyapunov exponent field. The
proposed approach is evaluated on both 2-D time-dependent synthetic and vector
fields from computational fluid dynamics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5681</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5681</id><created>2011-05-27</created><authors><author><keyname>Bose</keyname><forenames>Mausumi</forenames></author><author><keyname>Mukerjee</keyname><forenames>Rahul</forenames></author></authors><title>Improving Anonymity in Shared Key Primitives Based on Perfect Hash
  Families</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new scheme for sharing symmetric key operations among a set of
participants according to a (t,n) threshold access structure. We focus on
anonymity properties of this scheme and show that this scheme provides improved
values of anonymity measures than the existing ones. In particular, the scheme
can provide optimal and equitable participant anonymity when it is based on
balanced perfect hash families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5684</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5684</id><created>2011-05-28</created><authors><author><keyname>He</keyname><forenames>Fei</forenames></author><author><keyname>Xiang</keyname><forenames>Fan</forenames></author><author><keyname>Xue</keyname><forenames>Yibo</forenames></author><author><keyname>Li</keyname><forenames>Jun</forenames></author></authors><title>Towards High-Performance Network Application Identification With
  Aggregate-Flow Cache</title><categories>cs.NI</categories><journal-ref>International Journal of Computer Networks &amp; Communications, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classifying network traffic according to their application-layer protocols is
an important task in modern networks for traffic management and network
security. Existing payload-based or statistical methods of application
identification cannot meet the demand of both high performance and accurate
identification at the same time. We propose an application identification
framework that classifies traffic at aggregate-flow level leveraging
aggregate-flow cache. A detailed traffic classifier designed based on this
framework is illustrated to improve the throughput of payload-based
identification methods. We further optimize the classifier by proposing an
efficient design of aggregate-flow cache. The cache design employs a
frequency-based, recency-aware replacement algorithm based on the analysis of
temporal locality of aggregate-flow cache. Experiments on real-world traces
show that our traffic classifier with aggregate-flow cache can reduce up to 95%
workload of backend identification engine. The proposed cache replacement
algorithm outperforms well-known replacement algorithms, and achieves 90% of
the optimal performance using only 15% of memory. The throughput of a
payload-based identification system, L7-filter [1], is increased by up to 5.1
times by using our traffic classifier design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5718</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5718</id><created>2011-05-28</created><authors><author><keyname>Prehnal</keyname><forenames>Vojtech</forenames></author></authors><title>Relational Schema Protocol (RSP)</title><categories>cs.DS</categories><comments>IETF Internet-Draft</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document specifies the Relational Schema Protocol (RSP). RSP enables
loosely coupled applications to share and exchange relational data. It defines
fixed message format for an arbitrary relational schema so that the changes in
the data schema do not affect the message format. This prevents the interacting
applications from having to be reimplemented during the data schema evolvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5721</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5721</id><created>2011-05-28</created><authors><author><keyname>Rathmanner</keyname><forenames>Samuel</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>A Philosophical Treatise of Universal Induction</title><categories>cs.LG cs.IT math.IT</categories><comments>72 pages, 2 figures, 1 table, LaTeX</comments><journal-ref>Entropy, 13:6 (2011) pages 1076-1136</journal-ref><doi>10.3390/e13061076</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding inductive reasoning is a problem that has engaged mankind for
thousands of years. This problem is relevant to a wide range of fields and is
integral to the philosophy of science. It has been tackled by many great minds
ranging from philosophers to scientists to mathematicians, and more recently
computer scientists. In this article we argue the case for Solomonoff
Induction, a formal inductive framework which combines algorithmic information
theory with the Bayesian framework. Although it achieves excellent theoretical
results and is based on solid philosophical foundations, the requisite
technical knowledge necessary for understanding this framework has caused it to
remain largely unknown and unappreciated in the wider scientific community. The
main contribution of this article is to convey Solomonoff induction and its
related concepts in a generally accessible form with the aim of bridging this
current technical gap. In the process we examine the major historical
contributions that have led to the formulation of Solomonoff Induction as well
as criticisms of Solomonoff and induction in general. In particular we examine
how Solomonoff induction addresses many issues that have plagued other
inductive systems, such as the black ravens paradox and the confirmation
problem, and compare this approach with other recent approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5736</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5736</id><created>2011-05-28</created><authors><author><keyname>Heidarzadeh</keyname><forenames>Anoosheh</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>Network Codes with Overlapping Chunks over Line Networks: A Case for
  Linear-Time Codes</title><categories>cs.IT math.IT</categories><comments>73 pages, 28 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the problem of designing network codes that are both
communicationally and computationally efficient over packet line networks with
worst-case schedules is considered. In this context, random linear network
codes (dense codes) are asymptotically capacity-achieving, but require highly
complex coding operations. To reduce the coding complexity, Maymounkov et al.
proposed chunked codes (CC). Chunked codes operate by splitting the message
into non-overlapping chunks and send a randomly chosen chunk at each
transmission time by a dense code. The complexity, that is linear in the chunk
size, is thus reduced compared to dense codes. In this paper, the existing
analysis of CC is revised, and tighter bounds on the performance of CC are
derived. As a result, we prove that (i) CC with sufficiently large chunks are
asymptotically capacity-achieving, but with a slower speed of convergence
compared to dense codes; and (ii) CC with relatively smaller chunks approach
the capacity with an arbitrarily small but non-zero constant gap. To improve
the speed of convergence of CC, while maintaining their advantage in reducing
the computational complexity, we propose and analyze a new CC scheme with
overlapping chunks, referred to as overlapped chunked codes (OCC). We prove
that for smaller chunks, which are advantageous due to lower computational
complexity, OCC with larger overlaps provide a better tradeoff between the
speed of convergence and the message or packet error rate. This implies that
for smaller chunks, and with the same computational complexity, OCC outperform
CC in terms of the speed of approaching the capacity for sufficiently small
target error rate. In fact, we design linear-time OCC with very small chunks
(constant in the message size) that are both computationally and
communicationally efficient, and that outperform linear-time CC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5755</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5755</id><created>2011-05-29</created><authors><author><keyname>Asnani</keyname><forenames>Himanshu</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>On Real Time Coding with Limited Lookahead</title><categories>cs.IT math.IT</categories><comments>27 pages, 6 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A real time coding system with lookahead consists of a memoryless source, a
memoryless channel, an encoder, which encodes the source symbols sequentially
with knowledge of future source symbols upto a fixed finite lookahead, d, with
or without feedback of the past channel output symbols and a decoder, which
sequentially constructs the source symbols using the channel output. The
objective is to minimize the expected per-symbol distortion. For a fixed finite
lookahead d&gt;=1 we invoke the theory of controlled markov chains to obtain an
average cost optimality equation (ACOE), the solution of which, denoted by
D(d), is the minimum expected per-symbol distortion. With increasing d, D(d)
bridges the gap between causal encoding, d=0, where symbol by symbol
encoding-decoding is optimal and the infinite lookahead case, d=\infty, where
Shannon Theoretic arguments show that separation is optimal. We extend the
analysis to a system with finite state decoders, with or without noise-free
feedback. For a Bernoulli source and binary symmetric channel, under hamming
loss, we compute the optimal distortion for various source and channel
parameters, and thus obtain computable bounds on D(d). We also identify regions
of source and channel parameters where symbol by symbol encoding-decoding is
suboptimal. Finally, we demonstrate the wide applicability of our approach by
applying it in additional coding scenarios, such as the case where the
sequential decoder can take cost constrained actions affecting the quality or
availability of side information about the source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5762</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5762</id><created>2011-05-29</created><authors><author><keyname>Yu</keyname><forenames>Yaming</forenames></author></authors><title>On Log-concavity of the Generalized Marcum Q Function</title><categories>math.ST cs.IT math.CA math.IT stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that, if nu &gt;= 1/2 then the generalized Marcum Q function Q_nu(a,
b) is log-concave in 0&lt;=b &lt;infty. This proves a conjecture of Sun, Baricz and
Zhou (2010). We also point out relevant results in the statistics literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5766</identifier>
 <datestamp>2011-11-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5766</id><created>2011-05-29</created><updated>2011-11-05</updated><authors><author><keyname>Barilari</keyname><forenames>Davide</forenames><affiliation>SISSA/ISAS</affiliation></author><author><keyname>Boscain</keyname><forenames>Ugo</forenames><affiliation>CMAP</affiliation></author><author><keyname>Gauthier</keyname><forenames>Jean-Paul</forenames><affiliation>LSIS</affiliation></author></authors><title>On 2-step, corank 2 nilpotent sub-Riemannian metrics</title><categories>math.OC cs.SY</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the nilpotent 2-step, corank 2 sub-Riemannian metrics
that are nilpotent approximations of general sub-Riemannian metrics. We exhibit
optimal syntheses for these problems. It turns out that in general the cut time
is not equal to the first conjugate time but has a simple explicit expression.
As a byproduct of this study we get some smoothness properties of the spherical
Hausdorff measure in the case of a generic 6 dimensional, 2-step corank 2
sub-Riemannian metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5782</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5782</id><created>2011-05-29</created><authors><author><keyname>Inoue</keyname><forenames>Takao</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>Grassmannian Predictive Coding for Limited Feedback in Multiple Antenna
  Wireless Systems</title><categories>cs.IT math.IT</categories><comments>20 pages, 11 figures, submitted to IEEE Trans. on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Limited feedback is a paradigm for the feedback of channel state information
in wireless systems. In multiple antenna wireless systems, limited feedback
usually entails quantizing a source that lives on the Grassmann manifold. Most
work on limited feedback beamforming considered single-shot quantization. In
wireless systems, however, the channel is temporally correlated, which can be
used to reduce feedback requirements. Unfortunately, conventional predictive
quantization does not incorporate the non-Euclidean structure of the Grassmann
manifold. In this paper, we propose a Grassmannian predictive coding algorithm
where the differential geometric structure of the Grassmann manifold is used to
formulate a predictive vector quantization encoder and decoder. We analyze the
quantization error and derive bounds on the distortion attained by the proposed
algorithm. We apply the algorithm to a multiuser multiple-input multiple-output
wireless system and show that it improves the achievable sum rate as the
temporal correlation of the channel increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5789</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5789</id><created>2011-05-29</created><authors><author><keyname>Pivovarov</keyname><forenames>Grigory</forenames></author><author><keyname>Trunov</keyname><forenames>Sergei</forenames></author></authors><title>Clustering and Classification in Text Collections Using Graph Modularity</title><categories>cs.IR cs.DL</categories><comments>11 pages, submitted to JMLR</comments><msc-class>68U99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new fast algorithm for clustering and classification of large collections
of text documents is introduced. The new algorithm employs the bipartite graph
that realizes the word-document matrix of the collection. Namely, the
modularity of the bipartite graph is used as the optimization functional.
Experiments performed with the new algorithm on a number of text collections
had shown a competitive quality of the clustering (classification), and a
record-breaking speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5802</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5802</id><created>2011-05-29</created><updated>2011-11-02</updated><authors><author><keyname>Taneja</keyname><forenames>Inder Jeet</forenames></author></authors><title>Sequences of Inequalities among Differences of Gini Means and Divergence
  Measures</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1938, Gini studied a mean having two parameters. Later, many authors
studied properties of this mean. In particular, it contains the famous means as
harmonic, geometric, arithmetic, etc. Here we considered a sequence of
inequalities arising due to particular values of each parameter of Gini's mean.
This sequence generates many nonnegative differences. Not all of them are
convex. We have studied here convexity of these differences and again
established new sequences of inequalities of these differences. Considering in
terms of probability distributions these differences, we have made connections
with some of well known divergence measures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5803</identifier>
 <datestamp>2011-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5803</id><created>2011-05-29</created><updated>2011-07-02</updated><authors><author><keyname>Benaloh</keyname><forenames>Josh</forenames></author><author><keyname>Jones</keyname><forenames>Douglas</forenames></author><author><keyname>Lazarus</keyname><forenames>Eric</forenames></author><author><keyname>Lindeman</keyname><forenames>Mark</forenames></author><author><keyname>Stark</keyname><forenames>Philip B.</forenames></author></authors><title>SOBA: Secrecy-preserving Observable Ballot-level Audit</title><categories>stat.AP cs.CR cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  SOBA is an approach to election verification that provides observers with
justifiably high confidence that the reported results of an election are
consistent with an audit trail (&quot;ballots&quot;), which can be paper or electronic.
SOBA combines three ideas: (1) publishing cast vote records (CVRs) separately
for each contest, so that anyone can verify that each reported contest outcome
is correct, if the CVRs reflect voters' intentions with sufficient accuracy;
(2) shrouding a mapping between ballots and the CVRs for those ballots to
prevent the loss of privacy that could occur otherwise; (3) assessing the
accuracy with which the CVRs reflect voters' intentions for a collection of
contests while simultaneously assessing the integrity of the shrouded mapping
between ballots and CVRs by comparing randomly selected ballots to the CVRs
that purport to represent them. Step (1) is related to work by the Humboldt
County Election Transparency Project, but publishing CVRs separately for
individual contests rather than images of entire ballots preserves privacy.
Step (2) requires a cryptographic commitment from elections officials.
Observers participate in step (3), which relies on the &quot;super-simple
simultaneous single-ballot risk-limiting audit.&quot; Step (3) is designed to reveal
relatively few ballots if the shrouded mapping is proper and the CVRs
accurately reflect voter intent. But if the reported outcomes of the contests
differ from the outcomes that a full hand count would show, step (3) is
guaranteed to have a large chance of requiring all the ballots to be counted by
hand, thereby limiting the risk that an incorrect outcome will become official
and final.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5806</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5806</id><created>2011-05-29</created><authors><author><keyname>Viderman</keyname><forenames>Michael</forenames></author></authors><title>A Combination of Testability and Decodability by Tensor Products</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ben-Sasson and Sudan (RSA 2006) showed that repeated tensor products of
linear codes with a very large distance are locally testable. Due to the
requirement of a very large distance the associated tensor products could be
applied only over sufficiently large fields. Then Meir (SICOMP 2009) used this
result (as a black box) to present a combinatorial construction of locally
testable codes that match best known parameters. As a consequence, this
construction was obtained over sufficiently large fields.
  In this paper we improve the result of Ben-Sasson and Sudan and show that for
\emph{any} linear codes the associated tensor products are locally testable.
Consequently, the construction of Meir can be taken over any field, including
the binary field.
  Moreover, a combination of our result with the result of Spielman (IEEE IT,
1996) implies a construction of linear codes (over any field) that combine the
following properties: have constant rate and constant relative distance; have
blocklength $n$ and testable with $n^{\epsilon}$ queries, for any constant
$\epsilon &gt; 0$; linear time encodable and linear-time decodable from a constant
fraction of errors.
  Furthermore, a combination of our result with the result of Guruswami et al.
(STOC 2009) implies a similar corollary regarding the list-decodable codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5817</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5817</id><created>2011-05-29</created><authors><author><keyname>Bouzid</keyname><forenames>Zohir</forenames><affiliation>LIP6</affiliation></author><author><keyname>Lamani</keyname><forenames>Anissa</forenames><affiliation>MIS</affiliation></author></authors><title>Robot Networks with Homonyms: The Case of Patterns Formation</title><categories>cs.DC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of formation of a series of geometric
patterns [4] by a network of oblivious mobile robots that communicate only
through vision. So far, the problem has been studied in models where robots are
either assumed to have distinct identifiers or to be completely anonymous. To
generalize these results and to better understand how anonymity affects the
computational power of robots, we study the problem in a new model, introduced
recently in [5], in which n robots may share up to 1 &lt;= h &lt;= n different
identifiers. We present necessary and sufficient conditions, relating
symmetricity and homonymy, that makes the problem solvable. We also show that
in the case where h = n, making the identifiers of robots invisible does not
limit their computational power. This contradicts a result of [4]. To present
our algorithms, we use a function that computes the Weber point for many
regular and symmetric configurations. This function is interesting in its own
right, since the problem of finding Weber points has been solved up to now for
only few other patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5831</identifier>
 <datestamp>2011-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5831</id><created>2011-05-29</created><updated>2011-10-20</updated><authors><author><keyname>Szyprowski</keyname><forenames>Marek</forenames></author><author><keyname>Kerntopf</keyname><forenames>Pawel</forenames></author></authors><title>Reducing Quantum Cost in Reversible Toffoli Circuits</title><categories>quant-ph cs.ET</categories><journal-ref>Proceedings of Reed-Muller 2011 Workshop, May 25-26, 2011, pp.
  127-136</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, reversible circuit synthesis has been intensively studied. One of
the problems that has not been solved for a long time was exact minimization of
gate count (GC) in 4-bit circuits. Finally, last year a tool of practical usage
for finding optimal gate count Toffoli networks for any 4-variable function was
developed. However, not much work has been done yet on exact minimization of
quantum cost (QC) in 4-bit circuits. This paper presents an application of the
above mentioned tool to reducing QC of 4-bit reversible circuits. It is shown
that for benchmarks and for designs taken from recent publications it is
possible to obtain savings in QC of up to 74% comparing with previously known
circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5832</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5832</id><created>2011-05-29</created><authors><author><keyname>Vo&#xdf;</keyname><forenames>Jakob</forenames></author></authors><title>Revealing digital documents. Concealed structures in data</title><categories>cs.DL</categories><comments>8 pages, accepted for TPDL 2011 Doctoral Consortium</comments><journal-ref>Bulletin of IEEE Technical Committee on Digital Libraries, Volume
  8, Issue 3, May 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short paper gives an introduction to a research project to analyze how
digital documents are structured and described. Using a phenomenological
approach, this research will reveal common patterns that are used in data,
independent from the particular technology in which the data is available. The
ability to identify these patterns, on different levels of description, is
important for several applications in digital libraries. A better understanding
of data structuring will not only help to better capture singular
characteristics of data by metadata, but will also recover intended structures
of digital objects, beyond long term preservation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5839</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5839</id><created>2011-05-29</created><authors><author><keyname>Leung</keyname><forenames>Ian X. Y.</forenames></author><author><keyname>Chan</keyname><forenames>Shu-Yan</forenames></author><author><keyname>Hui</keyname><forenames>Pan</forenames></author><author><keyname>Lio'</keyname><forenames>Pietro</forenames></author></authors><title>Intra-City Urban Network and Traffic Flow Analysis from GPS Mobility
  Trace</title><categories>physics.soc-ph cs.SI</categories><comments>23 pages, 6 figures, 2 tables, 1 algorithm</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse two large-scale intra-city urban networks and traffic flows
therein measured by GPS traces of taxis in San Francisco and Shanghai. Our
results coincide with previous findings that, based purely on topological
means, it is often insufficient to characterise traffic flow. Traditional
shortest-path betweenness analysis, where shortest paths are calculated from
each pairs of nodes, carries an unrealistic implicit assumption that each node
or junction in the urban network generates and attracts an equal amount of
traffic. We also argue that weighting edges based only on euclidean distance is
inadequate, as primary roads are commonly favoured over secondary roads due to
the perceived and actual travel time required. We show that betweenness traffic
analysis can be improved by a simple extended framework which incorporates both
the notions of node weights and fastest-path betweenness. We demonstrate that
the framework is superior to traditional methods based solely on simple
topological perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5849</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5849</id><created>2011-05-29</created><updated>2011-09-29</updated><authors><author><keyname>Reid</keyname><forenames>Fergal</forenames></author><author><keyname>Hurley</keyname><forenames>Neil</forenames></author></authors><title>Diffusion in Networks With Overlapping Community Structure</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 21 Figures. R2, updated with extra figures, clearer
  explanation</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study diffusion in networks with community structure. We
first replicate and extend work on networks with non-overlapping community
structure. We then study diffusion on network models that have overlapping
community structure. We study contagions in the standard SIR model, and complex
contagions thought to be better models of some social diffusion processes.
Finally, we investigate diffusion on empirical networks with known overlapping
community structure, by analysing the structure of such networks, and by
simulating contagion on them. We find that simple and complex contagions can
spread fast in networks with overlapping community structure. We also find that
short paths exist through overlapping community structure on empirical
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5853</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5853</id><created>2011-05-29</created><authors><author><keyname>Fletcher</keyname><forenames>Alyson K.</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Orthogonal Matching Pursuit: A Brownian Motion Analysis</title><categories>cs.IT math.IT</categories><comments>11 pages, 2 figures</comments><doi>10.1109/TSP.2011.2176936</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well-known analysis of Tropp and Gilbert shows that orthogonal matching
pursuit (OMP) can recover a k-sparse n-dimensional real vector from 4 k log(n)
noise-free linear measurements obtained through a random Gaussian measurement
matrix with a probability that approaches one as n approaches infinity. This
work strengthens this result by showing that a lower number of measurements, 2
k log(n - k), is in fact sufficient for asymptotic recovery. More generally,
when the sparsity level satisfies kmin &lt;= k &lt;= kmax but is unknown, 2 kmax
log(n - kmin) measurements is sufficient. Furthermore, this number of
measurements is also sufficient for detection of the sparsity pattern (support)
of the vector with measurement errors provided the signal-to-noise ratio (SNR)
scales to infinity. The scaling 2 k log(n - k) exactly matches the number of
measurements required by the more complex lasso method for signal recovery with
a similar SNR scaling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5861</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5861</id><created>2011-05-30</created><authors><author><keyname>Inaltekin</keyname><forenames>Hazer</forenames></author><author><keyname>Hanly</keyname><forenames>Stephen V.</forenames></author></authors><title>Optimality of binary power-control in a single cell via majorization</title><categories>cs.IT math.IT</categories><comments>24 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the optimum single cell power-control maximizing the
aggregate (uplink) communication rate of the cell when there are peak power
constraints at mobile users, and a low-complexity data decoder (without
successive decoding) at the base station. It is shown, via the theory of
majorization, that the optimum power allocation is binary, which means links
are either &quot;on&quot; or &quot;off&quot;. By exploiting further structure of the optimum binary
power allocation, a simple polynomial-time algorithm for finding the optimum
transmission power allocation is proposed, together with a reduced complexity
near-optimal heuristic algorithm. Sufficient conditions under which
channel-state aware time-division-multiple-access (TDMA) maximizes the
aggregate communication rate are established. Finally, a numerical study is
performed to compare and contrast the performance achieved by the optimum
binary power-control policy with other sub-optimum policies and the throughput
capacity achievable via successive decoding. It is observed that two dominant
modes of communication arise, wideband or TDMA, and that successive decoding
achieves better sum-rates only under near-perfect interference cancellation
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5875</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5875</id><created>2011-05-30</created><authors><author><keyname>Buldakova</keyname><forenames>Yulia V.</forenames></author></authors><title>Publicity of the intimate text (the blog studying and publication)</title><categories>cs.OH</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the important problems of a modern society - communications. At all
readiness of this question both humanitarian, and engineering science, process
of transfer and information reception remains in the centre of attention of
researchers. The dialogue phenomenon in a network becomes the significant
factor of such attention. The fact of the publication of blogs and increasing
popularity of bloggers is connected, in our opinion, with an increasing
openness of a blog sphere (each record can be commented any user), and
accordingly, the Internet as a whole.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5881</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5881</id><created>2011-05-30</created><updated>2011-06-05</updated><authors><author><keyname>Chen</keyname><forenames>Mingyu</forenames></author><author><keyname>Bader</keyname><forenames>David A.</forenames></author></authors><title>On the random access performance of Cell Broadband Engine with graph
  analysis application</title><categories>cs.CE cs.PF</categories><comments>8 pages, 10 figures</comments><acm-class>D.1.3; C.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Cell Broad Engine (BE) Processor has unique memory access architecture
besides its powerful computing engines. Many computing-intensive applications
have been ported to Cell/BE successfully. But memory-intensive applications are
rarely investigated except for several micro benchmarks. Since Cell/BE has
powerful software visible DMA engine, this paper studies on whether Cell/BE is
suit for applica- tions with large amount of random memory accesses. Two
benchmarks, GUPS and SSCA#2, are used. The latter is a rather complex one that
in representative of real world graph analysis applications. We find both
benchmarks have good performance on Cell/BE based IBM QS20/22. Com- pared with
2 conventional multi-processor systems with the same core/thread number, GUPS
is about 40-80% fast and SSCA#2 about 17-30% fast. The dynamic load balanc- ing
and software pipeline for optimizing SSCA#2 are intro- duced. Based on the
experiment, the potential of Cell/BE for random access is analyzed in detail as
well as its limita- tions of memory controller, atomic engine and TLB manage-
ment.Our research shows although more programming effort are needed, Cell/BE
has the potencial for irregular memory access applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5887</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5887</id><created>2011-05-30</created><authors><author><keyname>Orieux</keyname><forenames>F.</forenames></author><author><keyname>F&#xe9;ron</keyname><forenames>O.</forenames></author><author><keyname>Giovannelli</keyname><forenames>J. -F.</forenames></author></authors><title>Efficient sampling of high-dimensional Gaussian fields: the
  non-stationary / non-sparse case</title><categories>stat.CO cs.LG stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is devoted to the problem of sampling Gaussian fields in high
dimension. Solutions exist for two specific structures of inverse covariance :
sparse and circulant. The proposed approach is valid in a more general case and
especially as it emerges in inverse problems. It relies on a
perturbation-optimization principle: adequate stochastic perturbation of a
criterion and optimization of the perturbed criterion. It is shown that the
criterion minimizer is a sample of the target density. The motivation in
inverse problems is related to general (non-convolutive) linear observation
models and their resolution in a Bayesian framework implemented through
sampling algorithms when existing samplers are not feasible. It finds a direct
application in myopic and/or unsupervised inversion as well as in some
non-Gaussian inversion. An illustration focused on hyperparameter estimation
for super-resolution problems assesses the effectiveness of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5894</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5894</id><created>2011-05-30</created><authors><author><keyname>Rubtsov</keyname><forenames>A.</forenames></author><author><keyname>Vyalyi</keyname><forenames>M.</forenames></author></authors><title>Regular realizability problems and models of a generalized
  nondeterminism</title><categories>cs.FL cs.DM</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Models of a generalized nondeterminism are defined by limitations on nonde-
terministic behavior of a computing device. A regular realizability problem is
a problem of verifying existence of a special sort word in a regular language.
These notions are closely connected. In this paper we consider regular
realizability problems for languages consist- ing of all prefixes of an
infinite word. These problems are related to the automata on infinite words and
to the decidability of monadic second-order theories. The main contribution is
a new decidability condition for regular realizability problems and for
monadic-second order theories. We also show that decidability of a regular
realizability problem is equivalent to decidability of some prefix
realizability problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5895</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5895</id><created>2011-05-30</created><updated>2011-12-15</updated><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author></authors><title>Percolation and Connectivity on the Signal to Interference Ratio Graph</title><categories>cs.IT math.IT</categories><comments>To appear in the Proceedings of the IEEE Conference on Computer
  Communications (INFOCOM 2012), to be held in Orlando Florida Mar. 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wireless communication network is considered where any two nodes are
connected if the signal-to-interference ratio (SIR) between them is greater
than a threshold. Assuming that the nodes of the wireless network are
distributed as a Poisson point process (PPP), percolation (unbounded connected
cluster) on the resulting SIR graph is studied as a function of the density of
the PPP. For both the path-loss as well as path-loss plus fading model of
signal propagation, it is shown that for a small enough threshold, there exists
a closed interval of densities for which percolation happens with non-zero
probability. Conversely, for the path-loss model of signal propagation, it is
shown that for a large enough threshold, there exists a closed interval of
densities for which the probability of percolation is zero. Restricting all
nodes to lie in an unit square, connectivity properties of the SIR graph are
also studied. Assigning separate frequency bands or time-slots proportional to
the logarithm of the number of nodes to different nodes for
transmission/reception is sufficient to guarantee connectivity in the SIR
graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5900</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5900</id><created>2011-05-30</created><updated>2011-05-31</updated><authors><author><keyname>Dom&#xed;nguez</keyname><forenames>Juli&#xe1;n</forenames></author><author><keyname>Alba</keyname><forenames>Enrique</forenames></author></authors><title>Ethane: A Heterogeneous Parallel Search Algorithm for Heterogeneous
  Platforms</title><categories>cs.NE cs.DC</categories><comments>Paper 6 for the First International Workshop of Distributed
  Evolutionary computation in Informal Environments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present Ethane, a parallel search algorithm specifically
designed for its execution on heterogeneous hardware environments. With Ethane
we propose an algorithm inspired in the structure of the chemical compound of
the same name, implementing a heterogeneous island model based in the structure
of its chemical bonds. We also propose a schema for describing a family of
parallel heterogeneous metaheuristics inspired by the structure of hydrocarbons
in Nature, HydroCM (HydroCarbon inspired Metaheuristics), establishing a resem-
blance between atoms and computers, and between chemical bonds and
communication links. Our goal is to gracefully match computers of different
power to algorithms of different behavior (GA and SA in this study), all them
collaborating to solve the same problem. The analysis will show that Ethane,
though simple, can solve search problems in a faster and more robust way than
well-known panmitic and distributed algorithms very popular in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5903</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5903</id><created>2011-05-30</created><updated>2011-07-25</updated><authors><author><keyname>Yano</keyname><forenames>Akiyuki</forenames></author><author><keyname>Wadayama</keyname><forenames>Tadashi</forenames></author></authors><title>Probabilistic Analysis of the Network Reliability Problem on a Random
  Graph Ensemble</title><categories>cs.IT cs.DM math.IT</categories><comments>9 pages, 2 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the field of computer science, the network reliability problem for
evaluating the network failure probability has been extensively investigated.
For a given undirected graph $G$, the network failure probability is the
probability that edge failures (i.e., edge erasures) make $G$ unconnected. Edge
failures are assumed to occur independently with the same probability. The main
contributions of the present paper are the upper and lower bounds on the
expected network failure probability. We herein assume a simple random graph
ensemble that is closely related to the Erd\H{o}s-R\'{e}nyi random graph
ensemble. These upper and lower bounds exhibit the typical behavior of the
network failure probability. The proof is based on the fact that the cut-set
space of $G$ is a linear space over $\Bbb F_2$ spanned by the incident matrix
of $G$. The present study shows a close relationship between the ensemble
analysis of the network failure probability and the ensemble analysis of the
error detection probability of LDGM codes with column weight 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5912</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5912</id><created>2011-05-30</created><authors><author><keyname>Salah</keyname><forenames>Almila Akdag</forenames></author><author><keyname>Gao</keyname><forenames>Cheng</forenames></author><author><keyname>Suchecki</keyname><forenames>Krzysztof</forenames></author><author><keyname>Scharnhorst</keyname><forenames>Andrea</forenames></author></authors><title>Need to categorize: A comparative look at the categories of the
  Universal Decimal Classification system (UDC) and Wikipedia</title><categories>cs.DL cs.IR physics.soc-ph</categories><comments>Paper for High Throughput Humanities - a satellite meeting at the
  European Conference on Complex Systems 2010; Sept. 15, 2010 Lisbon University
  Institute ISCTE, Lisbon, Portugal</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This study analyzes the differences between the category structure of the
Universal Decimal Classification (UDC) system (which is one of the widely used
library classification systems in Europe) and Wikipedia. In particular, we
compare the emerging structure of category-links to the structure of classes in
the UDC. With this comparison we would like to scrutinize the question of how
do knowledge maps of the same domain differ when they are created socially
(i.e. Wikipedia) as opposed to when they are created formally (UDC) using
classificatio theory. As a case study, we focus on the category of &quot;Arts&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5915</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5915</id><created>2011-05-30</created><updated>2014-02-08</updated><authors><author><keyname>Wu</keyname><forenames>Bang Ye</forenames></author></authors><title>Algorithms for the minimum non-separating path and the balanced
  connected bipartition problems on grid graphs (With erratum)</title><categories>cs.DS</categories><comments>With erratum</comments><journal-ref>Journal of Combinatorial Optimization, 26 (2013): 592--607</journal-ref><doi>10.1007/s10878-012-9481-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For given a pair of nodes in a graph, the minimum non-separating path problem
looks for a minimum weight path between the two nodes such that the remaining
graph after removing the path is still connected. The balanced connected
bipartition (BCP$_2$) problem looks for a way to bipartition a graph into two
connected subgraphs with their weights as equal as possible. In this paper we
present an algorithm in time $O(N\log N)$ for finding a minimum weight
non-separating path between two given nodes in a grid graph of $N$ nodes with
positive weight. This result leads to a 5/4-approximation algorithm for the
BCP$_2$ problem on grid graphs, which is the currently best ratio achieved in
polynomial time. We also developed an exact algorithm for the BCP$_2$ problem
on grid graphs. Based on the exact algorithm and a rounding technique, we show
an approximation scheme, which is a fully polynomial time approximation scheme
for fixed number of rows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5924</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5924</id><created>2011-05-30</created><authors><author><keyname>Suksmono</keyname><forenames>Andriyan Bayu</forenames></author></authors><title>Reconstruction of Fractional Brownian Motion Signals From Its Sparse
  Samples Based on Compressive Sampling</title><categories>cs.NA math.PR physics.data-an stat.CO</categories><comments>6 double-column pages, 5 figures, submitted to ICEEI-2011</comments><msc-class>62M10</msc-class><acm-class>G.3; B.2.4; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new fBm (fractional Brownian motion)
interpolation/reconstruction method from partially known samples based on CS
(Compressive Sampling). Since 1/f property implies power law decay of the fBm
spectrum, the fBm signals should be sparse in frequency domain. This property
motivates the adoption of CS in the development of the reconstruction method.
Hurst parameter H that occurs in the power law determines the sparsity level,
therefore the CS reconstruction quality of an fBm signal for a given number of
known subsamples will depend on H. However, the proposed method does not
require the information of H to reconstruct the fBm signal from its partial
samples. The method employs DFT (Discrete Fourier Transform) as the sparsity
basis and a random matrix derived from known samples positions as the
projection basis. Simulated fBm signals with various values of H are used to
show the relationship between the Hurst parameter and the reconstruction
quality. Additionally, US-DJIA (Dow Jones Industrial Average) stock index
monthly values time-series are also used to show the applicability of the
proposed method to reconstruct a real-world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5933</identifier>
 <datestamp>2012-08-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5933</id><created>2011-05-30</created><updated>2012-08-27</updated><authors><author><keyname>Larsen</keyname><forenames>Kasper Green</forenames></author></authors><title>The Cell Probe Complexity of Dynamic Range Counting</title><categories>cs.DS cs.CC</categories><comments>This is an updated version of the paper which has been submitted to
  Journal of the ACM by invitation. The new version contains a new section
  which introduces an artificial problem for which it is significantly easier
  to apply the new lower bound technique</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop a new technique for proving lower bounds on the
update time and query time of dynamic data structures in the cell probe model.
With this technique, we prove the highest lower bound to date for any explicit
problem, namely a lower bound of $t_q=\Omega((\lg n/\lg(wt_u))^2)$. Here $n$ is
the number of update operations, $w$ the cell size, $t_q$ the query time and
$t_u$ the update time. In the most natural setting of cell size $w=\Theta(\lg
n)$, this gives a lower bound of $t_q=\Omega((\lg n/\lg \lg n)^2)$ for any
polylogarithmic update time. This bound is almost a quadratic improvement over
the highest previous lower bound of $\Omega(\lg n)$, due to P\v{a}tra\c{s}cu
and Demaine [SICOMP'06].
  We prove the lower bound for the fundamental problem of weighted orthogonal
range counting. In this problem, we are to support insertions of
two-dimensional points, each assigned a $\Theta(\lg n)$-bit integer weight. A
query to this problem is specified by a point $q=(x,y)$, and the goal is to
report the sum of the weights assigned to the points dominated by $q$, where a
point $(x',y')$ is dominated by $q$ if $x' \leq x$ and $y' \leq y$. In addition
to being the highest cell probe lower bound to date, the lower bound is also
tight for data structures with update time $t_u = \Omega(\lg^{2+\eps}n)$, where
$\eps&gt;0$ is an arbitrarily small constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5939</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5939</id><created>2011-05-30</created><authors><author><keyname>Jang</keyname><forenames>Hyungjun</forenames></author></authors><title>Airborne TDMA for High Throughput and Fast Weather Conditions
  Notification</title><categories>cs.CE</categories><journal-ref>IJCNC 3, 3, 2011, 206-220</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As air traffic grows significantly, aircraft accidents increase. Many
aviation accidents could be prevented if the precise aircraft positions and
weather conditions on the aircraft's route were known. Existing studies propose
determining the precise aircraft positions via a VHF channel with an air-to-air
radio relay system that is based on mobile ad-hoc networks. However, due to the
long propagation delay, the existing TDMA MAC schemes underutilize the
networks. The existing TDMA MAC sends data and receives ACK in one time slot,
which requires two guard times in one time slot. Since aeronautical
communications spans a significant distance, the guard time occupies a
significantly large portion of the slot. To solve this problem, we propose a
piggybacking mechanism ACK. Our proposed MAC has one guard time in one time
slot, which enables the transmission of more data. Using this additional data,
we can send weather conditions that pertain to the aircraft's current position.
Our analysis shows that this proposed MAC performs better than the existing
MAC, since it offers better throughput and network utilization. In addition,
our weather condition notification model achieves a much lower transmission
delay than a HF (high frequency) voice communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5941</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5941</id><created>2011-05-30</created><authors><author><keyname>Mohn</keyname><forenames>Chris E.</forenames></author><author><keyname>St&#xf8;len</keyname><forenames>Svein</forenames></author><author><keyname>Kob</keyname><forenames>Walter</forenames></author></authors><title>Predicting the Structure of Alloys using Genetic Algorithms</title><categories>cond-mat.mtrl-sci cs.NE physics.comp-ph</categories><comments>presented on ComPlasTech XVIII Computer Methods in Materials
  Technology, January 16-19 2011, Zakopane</comments><journal-ref>Materials and Manufacturing Processes Vol. 26, Issue: 3, 348-353
  (2011)</journal-ref><doi>10.1080/10426914.2011.552021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss a novel genetic algorithm that can be used to find global minima
on the potential energy surface of disordered ceramics and alloys using a
real-space symmetry adapted crossover. Due to a high number of symmetrically
equivalent solutions of many alloys a conventional genetic algorithms using
reasonable population sizes are unable to locate the global minima for even the
smallest systems. We demonstrate the superior performance of the use of
symmetry adapted crossover by the comparison of that of a conventional GA for
finding global minima of two binary Ising-type alloys that either order or
phase separate at low temperature. Comparison of different representations and
crossover operations show that the use of real-space crossover outperforms
crossover operators working on binary representations by several orders of
magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5951</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5951</id><created>2011-05-30</created><authors><author><keyname>Shahzad</keyname><forenames>Muhammad Tayyab</forenames></author><author><keyname>Rizwan</keyname><forenames>Muhammad</forenames></author></authors><title>Performance of Short-Commit in Extreme Database Environment</title><categories>cs.DB</categories><comments>19 pages. International Journal of Database Management Systems, ISSN
  : 0975-5705 (Online); International Journal of Database Management Systems
  (IJDMS)2011, 0975-5985 (Print)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Atomic commit protocols are used where data integrity is more important than
data availability. Two-Phase commit (2PC) is a standard commit protocol for
commercial database management systems. To reduce certain drawbacks in 2PC
protocol people have suggested different variance of this protocol.
Short-Commit protocol is developed with an objective to achieve low cost
transaction commitment cost with non-blocking capability. In this paper we have
briefly explained short-commit protocol executing pattern. Experimental
analysis and results are presented to support the claim that short-commit can
work efficiently in extreme database environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5975</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5975</id><created>2011-05-30</created><authors><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames><affiliation>Shitz</affiliation></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Multiple Access Channel with States Known Noncausally at One Encoder and
  Only Strictly Causally at the Other Encoder</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in the 2011 IEEE International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two-user state-dependent multiaccess channel in which the
states of the channel are known non-causally to one of the encoders and only
strictly causally to the other encoder. Both encoders transmit a common message
and, in addition, the encoder that knows the states non-causally transmits an
individual message. We study the capacity region of this communication model.
In the discrete memoryless case, we establish inner and outer bounds on the
capacity region. Although the encoder that sends both messages knows the states
fully, we show that the strictly causal knowledge of these states at the other
encoder can be beneficial for this encoder, and in general enlarges the
capacity region. Furthermore, we find an explicit characterization of the
capacity in the case in which the two encoders transmit only the common
message. In the Gaussian case, we characterize the capacity region for the
model with individual message as well. Our converse proof in this case shows
that, for this model, strictly causal knowledge of the state at one of the
encoders does not increase capacity if the other is informed non-causally, a
result which sheds more light on the utility of conveying a compressed version
of the state to the decoder in recent results by Lapidoth and Steinberg on a
multiacess model with only strictly causal state at both encoders and
independent messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5979</identifier>
 <datestamp>2011-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5979</id><created>2011-05-30</created><updated>2011-11-21</updated><authors><author><keyname>Eisenschmidt</keyname><forenames>Elke</forenames></author><author><keyname>Haus</keyname><forenames>Utz-Uwe</forenames></author></authors><title>A Polynomial Time Approximation Algorithm for the Two-Commodity
  Splittable Flow Problem</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a generalization of the unsplittable maximum two-commodity flow
problem on undirected graphs where each commodity $i\in{1,2}$ can be split into
a bounded number $k_i$ of equally-sized chunks that can be routed on different
paths. We show that in contrast to the single-commodity case this problem is
NP-hard, and hard to approximate to within a factor of $\alpha&gt;1/2$. We present
a polynomial time 1/2-approximation algorithm for the case of uniform chunk
size over both commodities and show that for even $k_i$ and a mild cut
condition it can be modified to yield an exact method. The uniform case can be
used to derive a 1/4-approximation for the maximum concurrent
$(k_1,k_2)$-splittable flow without chunk size restrictions for fixed demand
ratios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5981</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5981</id><created>2011-05-30</created><updated>2011-05-31</updated><authors><author><keyname>Khina</keyname><forenames>Anatoly</forenames></author><author><keyname>Hitron</keyname><forenames>Ayal</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author></authors><title>Modulation for MIMO Networks with Several Users</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent work, a capacity-achieving scheme for the common-message two-user
MIMO broadcast channel, based on single-stream coding and decoding, was
described. This was obtained via a novel joint unitary triangularization which
is applied to the corresponding channel matrices. In this work, the
triangularization is generalized, to any (finite) number of matrices, allowing
multi-user applications. To that end, multiple channel uses are jointly
treated, in a manner reminiscent of space-time coding. As opposed to the
two-user case, in the general case there does not always exist a perfect
(capacity-achieving) solution. However, a nearly optimal scheme (with vanishing
loss in the limit of large blocks) always exists. Common-message broadcasting
is but one example of communication networks with MIMO links which can be
solved using an approach coined &quot;Network Modulation&quot;; the extension beyond two
links carries over to these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5983</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5983</id><created>2011-05-30</created><updated>2012-02-09</updated><authors><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Meir</keyname><forenames>Reshef</forenames></author><author><keyname>Tennenholtz</keyname><forenames>Moshe</forenames></author></authors><title>Stability Scores: Measuring Coalitional Stability</title><categories>cs.GT</categories><comments>Full version, including proofs, of a paper published in the
  proceedings of AAMAS 2012</comments><acm-class>I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a measure for the level of stability against coalitional
deviations, called \emph{stability scores}, which generalizes widely used
notions of stability in non-cooperative games. We use the proposed measure to
compare various Nash equilibria in congestion games, and to quantify the effect
of game parameters on coalitional stability. For our main results, we apply
stability scores to analyze and compare the Generalized Second Price (GSP) and
Vickrey-Clarke-Groves (VCG) ad auctions. We show that while a central result of
the ad auctions literature is that the GSP and VCG auctions implement the same
outcome in one of the equilibria of GSP, the GSP outcome is far more stable.
Finally, a modified version of VCG is introduced, which is group
strategy-proof, and thereby achieves the highest possible stability score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.5986</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.5986</id><created>2011-05-30</created><authors><author><keyname>Bakhshi</keyname><forenames>Rena</forenames></author><author><keyname>Gavidia</keyname><forenames>Daniela</forenames></author><author><keyname>Fokkink</keyname><forenames>Wan</forenames></author><author><keyname>van Steen</keyname><forenames>Maarten</forenames></author></authors><title>A Modeling Framework for Gossip-based Information Spread</title><categories>cs.DC cs.DM cs.IT cs.PF math.IT</categories><comments>25 pages, including appendix</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an analytical framework for gossip protocols based on the pairwise
information exchange between interacting nodes. This framework allows for
studying the impact of protocol parameters on the performance of the protocol.
Previously, gossip-based information dissemination protocols have been analyzed
under the assumption of perfect, lossless communication channels. We extend our
framework for the analysis of networks with lossy channels. We show how the
presence of message loss, coupled with specific topology configurations,impacts
the expected behavior of the protocol. We validate the obtained models against
simulations for two protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6001</identifier>
 <datestamp>2012-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6001</id><created>2011-05-30</created><updated>2012-10-02</updated><authors><author><keyname>Badia</keyname><forenames>Antonio</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>A Call to Arms: Revisiting Database Design</title><categories>cs.DB</categories><comments>Removed spurious column break. Nothing else was changed</comments><journal-ref>Antonio Badia and Daniel Lemire. A call to arms: revisiting
  database design. SIGMOD Record 40 (3), pages 61-69, 2011</journal-ref><doi>10.1145/2070736.2070750</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Good database design is crucial to obtain a sound, consistent database, and -
in turn - good database design methodologies are the best way to achieve the
right design. These methodologies are taught to most Computer Science
undergraduates, as part of any Introduction to Database class. They can be
considered part of the &quot;canon&quot;, and indeed, the overall approach to database
design has been unchanged for years. Moreover, none of the major database
research assessments identify database design as a strategic research
direction.
  Should we conclude that database design is a solved problem?
  Our thesis is that database design remains a critical unsolved problem.
Hence, it should be the subject of more research. Our starting point is the
observation that traditional database design is not used in practice - and if
it were used it would result in designs that are not well adapted to current
environments. In short, database design has failed to keep up with the times.
In this paper, we put forth arguments to support our viewpoint, analyze the
root causes of this situation and suggest some avenues of research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6009</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6009</id><created>2011-05-30</created><authors><author><keyname>Riegler</keyname><forenames>Erwin</forenames></author><author><keyname>Morgenshtern</keyname><forenames>Veniamin I.</forenames></author><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Lin</keyname><forenames>Shaowei</forenames></author><author><keyname>Sturmfels</keyname><forenames>Bernd</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Noncoherent SIMO Pre-Log via Resolution of Singularities</title><categories>cs.IT math.AG math.IT</categories><comments>IEEE International Symposium on Information Theory 2011 (ISIT 2011),
  Saint Petersburg, Russia, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a lower bound on the noncoherent capacity pre-log of a
temporally correlated Rayleigh block-fading single-input multiple-output (SIMO)
channel. Our result holds for arbitrary rank Q of the channel correlation
matrix, arbitrary block-length L &gt; Q, and arbitrary number of receive antennas
R, and includes the result in Morgenshtern et al. (2010) as a special case. It
is well known that the capacity pre-log for this channel in the single-input
single-output (SISO) case is given by 1-Q/L, where Q/L is the penalty incurred
by channel uncertainty. Our result reveals that this penalty can be reduced to
1/L by adding only one receive antenna, provided that L \geq 2Q - 1 and the
channel correlation matrix satisfies mild technical conditions. The main
technical tool used to prove our result is Hironaka's celebrated theorem on
resolution of singularities in algebraic geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6010</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6010</id><created>2011-05-30</created><updated>2011-06-06</updated><authors><author><keyname>Bouhadiba</keyname><forenames>Tayeb</forenames><affiliation>INRIA Grenoble Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Sabah</keyname><forenames>Quentin</forenames><affiliation>INRIA Grenoble Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Delaval</keyname><forenames>Gwena&#xeb;l</forenames><affiliation>INRIA Grenoble Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author><author><keyname>Rutten</keyname><forenames>&#xc9;ric</forenames><affiliation>INRIA Grenoble Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author></authors><title>Synchronous Control of Reconfiguration in Fractal Component-based
  Systems -- a Case Study</title><categories>cs.SE cs.SY</categories><proxy>ccsd</proxy><report-no>RR-7631, RR-7631</report-no><journal-ref>N&amp;deg; RR-7631 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of component-based embedded systems, the management of dynamic
reconfiguration in adaptive systems is an increasingly important feature. The
Fractal component-based framework, and its industrial instantiation MIND,
provide for support for control operations in the lifecycle of components.
Nevertheless, the use of complex and integrated architectures make the
management of this reconfiguration operations difficult to handle by
programmers. To address this issue, we propose to use Synchronous languages,
which are a complete approach to the design of reactive systems, based on
behavior models in the form of transition systems. Furthermore, the design of
closed-loop reactive managers of reconfigurations can benefit from formal tools
like Discrete Controller Synthesis. In this paper we describe an approach to
concretely integrate synchronous reconfiguration managers in Fractal
component-based systems. We describe how to model the state space of the
control problem, and how to specify the control objectives. We describe the
implementation of the resulting manager with the Fractal/Cecilia programming
environment, taking advantage of the Comete distributed middleware. We
illustrate and validate it with the case study of the Comanche HTTP server on a
multi-core execution platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6014</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6014</id><created>2011-05-30</created><authors><author><keyname>Sun</keyname><forenames>Yafei</forenames></author></authors><title>Neural Networks for Emotion Classification</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is argued that for the computer to be able to interact with humans, it
needs to have the communication skills of humans. One of these skills is the
ability to understand the emotional state of the person. This thesis describes
a neural network-based approach for emotion classification. We learn a
classifier that can recognize six basic emotions with an average accuracy of
77% over the Cohn-Kanade database. The novelty of this work is that instead of
empirically selecting the parameters of the neural network, i.e. the learning
rate, activation function parameter, momentum number, the number of nodes in
one layer, etc. we developed a strategy that can automatically select
comparatively better combination of these parameters. We also introduce another
way to perform back propagation. Instead of using the partial differential of
the error function, we use optimal algorithm; namely Powell's direction set to
minimize the error function. We were also interested in construction an
authentic emotion databases. This is a very important task because nowadays
there is no such database available. Finally, we perform several experiments
and show that our neural network approach can be successfully used for emotion
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6020</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6020</id><created>2011-05-27</created><authors><author><keyname>De Leo</keyname><forenames>Gianluca</forenames></author><author><keyname>Goodman</keyname><forenames>Koren S.</forenames></author><author><keyname>Radici</keyname><forenames>Elena</forenames></author><author><keyname>Secrhist</keyname><forenames>Scott R.</forenames></author><author><keyname>Mastaglio</keyname><forenames>Thomas W.</forenames></author></authors><title>Level of Presence in Team-Building Activities: Gaming Component in
  Virtual Environments</title><categories>cs.HC</categories><comments>10 pages, 1 figure, 5 tables; The International Journal of Multimedia
  &amp; Its Applications (IJMA) Vol.3, No.2, May 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Historically the training of teams has been implemented using a face-to-face
approach. In the past decade, on-line multiuser virtual environments have
offered a solution for training teams whose members are geographically
dispersed. In order to develop on effective team training activity, a high
sense of presence among the participant needs to be reached. Previous research
studies reported being able to reach a high level of presence even when using
inexpensive technology such as laptop and headset. This study evaluates the
level of presence of ten subjects who have to perform a team-building activity
in a multi-user virtual environment using a laptop computer and a headset. The
authors are interested in determining which user characterizes, such as gender,
age and knowledge of computers, have a strong correlation with the level of
sense of presence. The results of this study showed that female participants
were more likely to engage in the activity and perceived fewer negative
effects. Participants who reported less negative effects such as feeling tired,
dizzy, or experiencing eye strain during the team-building activity reached a
higher level of sense of presence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6024</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6024</id><created>2011-05-30</created><authors><author><keyname>Karumbu</keyname><forenames>Premkumar</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Optimum Sleep-Wake Scheduling of Sensors for Quickest Event Detection in
  Small Extent Wireless Sensor Networks</title><categories>cs.NI</categories><comments>Submitted to IEEE/ACM Transactions on Networking, Feb. 01, 2011. This
  is an expanded version of a paper that was presented in IEEE INFOCOM 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of quickest event detection with sleep-wake
scheduling in small extent wireless sensor networks in which, at each time
slot, each sensor node in the awake state observes a sample and communicates
the information to the fusion centre. The sensor nodes in the sleep state do
not sample or communicate any information to the fusion centre (FC), thereby
conserving energy. At each time slot, the FC, after having received the samples
from the sensor nodes in the wake state, makes a decision to stop (and thus
declare that the event has occurred) or to continue observing. If it decides to
continue, the FC also makes the decision of choosing the number of sensor nodes
to be in the wake state in the next time slot. We consider three alternative
approaches to the problem of choosing the number of sensor nodes to be in the
wake state in time slot k+1, based on the information available at time slot k,
namely, 1. optimal control of M_{k+1}, the number of sensor nodes to be in the
awake state in time slot k+1, 2. optimal control of q_{k+1}, the probability of
a sensor node to be in the awake state in time slot k+1, and 3. optimal
probability q that a sensor node is in the awake state in any time slot. In
each case, we formulate the problem as a sequential decision process. We show
that a sufficient statistic for the decision at time k is the a posteriori
probability of change Pi_k. Also, we show that the optimal stopping rule is a
threshold rule on Pi_k. The optimal policy for M_{k+1} can keep very few
sensors wake during the prechange phase and then quickly increase the number of
sensors in the wake state when a change is &quot;suspected&quot;. Among the three
sleep-wake algorithms described, we observe that the total cost is minimum for
the optimum control of M_{k+1} and is maximum for the optimum control on q.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6033</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6033</id><created>2011-05-30</created><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>A New Outer-Bound via Interference Localization and the Degrees of
  Freedom Regions of MIMO Interference Networks with no CSIT</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Information Theory, May 2011. A material in
  this paper will be presented in part at the IEEE Intern. Symp. Information
  Theory (ISIT), Aug. 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The two-user multi-input, multi-output (MIMO) interference and cognitive
radio channels are studied under the assumption of no channel state information
at the transmitter (CSIT) from the degrees of freedom (DoF) region perspective.
With $M_i$ and $N_i$ denoting the number of antennas at transmitter $i$ and
receiver $i$ respectively, the DoF regions of the MIMO interference channel
were recently characterized by Huang et al., Zhu and Guo, and by the authors of
this paper for all values of numbers of antennas except when $\min(M_1,N_1) &gt;
N_2 &gt; M_2$ (or $\min(M_2,N_2) &gt; N_1 &gt; M_1$). This latter case was solved more
recently by Zhu and Guo who provided a tight outer-bound. Here, a simpler and
more widely applicable proof of that outer-bound is given based on the idea of
interference localization. Using it, the DoF region is also established for the
class of MIMO cognitive radio channels when $\min(M_1+M_2,N_1) &gt; N_2 &gt; M_2$
(with the second transmitter cognitive) -- the only class for which the inner
and outer bounds previously obtained by the authors were not tight -- thereby
completing the DoF region characterization of the general 2-user MIMO cognitive
radio channel as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6040</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6040</id><created>2011-05-30</created><authors><author><keyname>Elnashar</keyname><forenames>Alaa Ismail</forenames></author></authors><title>Parallel Performance of MPI Sorting Algorithms on Dual-Core Processor
  Windows-Based Systems</title><categories>cs.DC</categories><doi>10.5121/ijdps.2011.2301</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Message Passing Interface (MPI) is widely used to implement parallel
programs. Although Windowsbased architectures provide the facilities of
parallel execution and multi-threading, little attention has been focused on
using MPI on these platforms. In this paper we use the dual core Window-based
platform to study the effect of parallel processes number and also the number
of cores on the performance of three MPI parallel implementations for some
sorting algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6041</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6041</id><created>2011-05-30</created><authors><author><keyname>Panagiotakopoulos</keyname><forenames>Constantinos</forenames></author><author><keyname>Tsampouka</keyname><forenames>Petroula</forenames></author></authors><title>The Perceptron with Dynamic Margin</title><categories>cs.LG</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical perceptron rule provides a varying upper bound on the maximum
margin, namely the length of the current weight vector divided by the total
number of updates up to that time. Requiring that the perceptron updates its
internal state whenever the normalized margin of a pattern is found not to
exceed a certain fraction of this dynamic upper bound we construct a new
approximate maximum margin classifier called the perceptron with dynamic margin
(PDM). We demonstrate that PDM converges in a finite number of steps and derive
an upper bound on them. We also compare experimentally PDM with other
perceptron-like algorithms and support vector machines on hard margin tasks
involving linear kernels which are equivalent to 2-norm soft margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6060</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6060</id><created>2011-05-30</created><authors><author><keyname>Yu</keyname><forenames>Feiyang</forenames></author><author><keyname>Oerlemans</keyname><forenames>Ard</forenames></author><author><keyname>Bakker</keyname><forenames>Erwin M.</forenames></author></authors><title>Alignment of Microtubule Imagery</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work discusses preliminary work aimed at simulating and visualizing the
growth process of a tiny structure inside the cell---the microtubule.
Difficulty of recording the process lies in the fact that the tissue
preparation method for electronic microscopes is highly destructive to live
cells. Here in this paper, our approach is to take pictures of microtubules at
different time slots and then appropriately combine these images into a
coherent video. Experimental results are given on real data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6061</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6061</id><created>2011-05-30</created><updated>2011-07-18</updated><authors><author><keyname>Karumbu</keyname><forenames>Premkumar</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author><author><keyname>Kuri</keyname><forenames>Joy</forenames></author></authors><title>Distributed Detection/Isolation Procedures for Quickest Event Detection
  in Large Extent Wireless Sensor Networks</title><categories>stat.AP cs.IT cs.NI math.IT</categories><comments>Submitted to IEEE Transactions on Signal Processing, Mar. 10, 2011.
  Revised on Jul. 17, 2011. A part of this work was presented in Forty-Seventh
  Annual Allerton Conference on Communication, Control, and Computing,
  Monticello, IL, USA, Sep. - Oct. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a problem of distributed detection of a stationary point event in a
large extent wireless sensor network ($\wsn$), where the event influences the
observations of the sensors only in the vicinity of where it occurs. An event
occurs at an unknown time and at a random location in the coverage region (or
region of interest ($\ROI$)) of the $\wsn$. We consider a general sensing model
in which the effect of the event at a sensor node depends on the distance
between the event and the sensor node; in particular, in the Boolean sensing
model, all sensors in a disk of a given radius around the event are equally
affected. Following the prior work reported in
\cite{nikiforov95change_isolation},
\cite{nikiforov03lower-bound-for-det-isolation},
\cite{tartakovsky08multi-decision}, {\em the problem is formulated as that of
detecting the event and locating it to a subregion of the $\ROI$ as early as
possible under the constraints that the average run length to false alarm
($\tfa$) is bounded below by $\gamma$, and the probability of false isolation
($\pfi$) is bounded above by $\alpha$}, where $\gamma$ and $\alpha$ are target
performance requirements. In this setting, we propose distributed procedures
for event detection and isolation (namely $\mx$, $\all$, and $\hall$), based on
the local fusion of $\CUSUM$s at the sensors. For these procedures, we obtain
bounds on the maximum mean detection/isolation delay ($\add$), and on $\tfa$
and $\pfi$, and thus provide an upper bound on $\add$ as
$\min\{\gamma,1/\alpha\} \to \infty$. For the Boolean sensing model, we show
that an asymptotic upper bound on the maximum mean detection/isolation delay of
our distributed procedure scales with $\gamma$ and $\alpha$ in the same way as
the asymptotically optimal centralised procedure
\cite{nikiforov03lower-bound-for-det-isolation}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6063</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6063</id><created>2011-05-30</created><authors><author><keyname>Ablinger</keyname><forenames>Jakob</forenames></author><author><keyname>Bl&#xfc;mlein</keyname><forenames>Johannes</forenames></author><author><keyname>Schneider</keyname><forenames>Carsten</forenames></author></authors><title>Harmonic Sums and Polylogarithms Generated by Cyclotomic Polynomials</title><categories>math-ph cs.SC hep-ph hep-th math.AG math.MP</categories><comments>55 pages, 1 figure, 1 style file</comments><report-no>DESY 11--033, DO--TH 11--12, SFB/CPP-11-24, LPN 11/24</report-no><doi>10.1063/1.3629472</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computation of Feynman integrals in massive higher order perturbative
calculations in renormalizable Quantum Field Theories requires extensions of
multiply nested harmonic sums, which can be generated as real representations
by Mellin transforms of Poincar\'e--iterated integrals including denominators
of higher cyclotomic polynomials. We derive the cyclotomic harmonic
polylogarithms and harmonic sums and study their algebraic and structural
relations. The analytic continuation of cyclotomic harmonic sums to complex
values of $N$ is performed using analytic representations. We also consider
special values of the cyclotomic harmonic polylogarithms at argument $x=1$,
resp., for the cyclotomic harmonic sums at $N \rightarrow \infty$, which are
related to colored multiple zeta values, deriving various of their relations,
based on the stuffle and shuffle algebras and three multiple argument
relations. We also consider infinite generalized nested harmonic sums at roots
of unity which are related to the infinite cyclotomic harmonic sums. Basis
representations are derived for weight {\sf w = 1,2} sums up to cyclotomy {\sf
l = 20}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6065</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6065</id><created>2011-05-30</created><authors><author><keyname>Karumbu</keyname><forenames>Premkumar</forenames></author><author><keyname>M.</keyname><forenames>Venkata K. Prasanthi</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Delay Optimal Event Detection on Ad Hoc Wireless Sensor Networks</title><categories>cs.NI</categories><comments>To appear in ACM Transactions on Sensor Networks. A part of this work
  was presented in IEEE SECON 2006, and Allerton 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a small extent sensor network for event detection, in which nodes
take samples periodically and then contend over a {\em random access network}
to transmit their measurement packets to the fusion center. We consider two
procedures at the fusion center to process the measurements. The Bayesian
setting is assumed; i.e., the fusion center has a prior distribution on the
change time. In the first procedure, the decision algorithm at the fusion
center is \emph{network-oblivious} and makes a decision only when a complete
vector of measurements taken at a sampling instant is available. In the second
procedure, the decision algorithm at the fusion center is \emph{network-aware}
and processes measurements as they arrive, but in a time causal order. In this
case, the decision statistic depends on the network delays as well, whereas in
the network-oblivious case, the decision statistic does not depend on the
network delays. This yields a Bayesian change detection problem with a tradeoff
between the random network delay and the decision delay; a higher sampling rate
reduces the decision delay but increases the random access delay. Under
periodic sampling, in the network--oblivious case, the structure of the optimal
stopping rule is the same as that without the network, and the optimal change
detection delay decouples into the network delay and the optimal decision delay
without the network. In the network--aware case, the optimal stopping problem
is analysed as a partially observable Markov decision process, in which the
states of the queues and delays in the network need to be maintained. A
sufficient statistic for decision is found to be the network-state and the
posterior probability of change having occurred given the measurements received
and the state of the network. The optimal regimes are studied using simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6073</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6073</id><created>2011-05-30</created><authors><author><keyname>Bodirsky</keyname><forenames>Manuel</forenames></author><author><keyname>Pinsker</keyname><forenames>Michael</forenames></author></authors><title>Reducts of Ramsey structures</title><categories>math.LO cs.CC</categories><comments>29 pages</comments><msc-class>03C40, 08A35, 05C55, 03D15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One way of studying a relational structure is to investigate functions which
are related to that structure and which leave certain aspects of the structure
invariant. Examples are the automorphism group, the self-embedding monoid, the
endomorphism monoid, or the polymorphism clone of a structure. Such functions
can be particularly well understood when the relational structure is countably
infinite and has a first-order definition in another relational structure which
has a finite language, is totally ordered and homogeneous, and has the Ramsey
property. This is because in this situation, Ramsey theory provides the
combinatorial tool for analyzing these functions -- in a certain sense, it
allows to represent such functions by functions on finite sets.
  This is a survey of results in model theory and theoretical computer science
obtained recently by the authors in this context. In model theory, we approach
the problem of classifying the reducts of countably infinite ordered
homogeneous Ramsey structures in a finite language, and certain decidability
questions connected with such reducts. In theoretical computer science, we use
the same combinatorial methods in order to classify the computational
complexity for various classes of infinite-domain constraint satisfaction
problems. While the first set of applications is obviously of an infinitary
character, the second set concerns genuinely finitary problems -- their
unifying feature is that the same tools from Ramsey theory are used in their
solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6084</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6084</id><created>2011-05-30</created><updated>2012-02-11</updated><authors><author><keyname>Kosba</keyname><forenames>Ahmed E.</forenames></author><author><keyname>Saeed</keyname><forenames>Ahmed</forenames></author><author><keyname>Youssef</keyname><forenames>Moustafa</forenames></author></authors><title>RASID: A Robust WLAN Device-free Passive Motion Detection System</title><categories>cs.NI cs.CV</categories><comments>V1: 14 pages, 11 figures. V2: 16 Pages, 15 figures. The
  non-parametric model of the system is compared with a parametric model of the
  system operation. Added 2-sample KS-Test for evaluating the profile update
  mechanism. Latency in detection decisions was allowed, and parameters
  configurations tuned accordingly. Same Conclusions. The effect of network
  activity on system profiles is analyzed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WLAN Device-free passive DfP indoor localization is an emerging technology
enabling the localization of entities that do not carry any devices nor
participate actively in the localization process using the already installed
wireless infrastructure. This technology is useful for a variety of
applications such as intrusion detection, smart homes and border protection. We
present the design, implementation and evaluation of RASID, a DfP system for
human motion detection. RASID combines different modules for statistical
anomaly detection while adapting to changes in the environment to provide
accurate, robust, and low-overhead detection of human activities using standard
WiFi hardware. Evaluation of the system in two different testbeds shows that it
can achieve an accurate detection capability in both environments with an
F-measure of at least 0.93. In addition, the high accuracy and low overhead
performance are robust to changes in the environment as compared to the current
state of the art DfP detection systems. We also relay the lessons learned
during building our system and discuss future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6115</identifier>
 <datestamp>2013-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6115</id><created>2011-05-30</created><updated>2013-04-17</updated><authors><author><keyname>N&#xf3;brega</keyname><forenames>Roberto W.</forenames></author><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Uch&#xf4;a-Filho</keyname><forenames>Bartolomeu F.</forenames></author></authors><title>On the Capacity of Multiplicative Finite-Field Matrix Channels</title><categories>cs.IT math.IT</categories><comments>11 pages, 4 figures, to appear in the IEEE Transactions on
  Information Theory</comments><doi>10.1109/TIT.2013.2253542</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the multiplicative finite-field matrix channel, a
discrete memoryless channel whose input and output are matrices (over a finite
field) related by a multiplicative transfer matrix. The model considered here
assumes that all transfer matrices with the same rank are equiprobable, so that
the channel is completely characterized by the rank distribution of the
transfer matrix. This model is seen to be more flexible than previously
proposed ones in describing random linear network coding systems subject to
link erasures, while still being sufficiently simple to allow tractability. The
model is also conservative in the sense that its capacity provides a lower
bound on the capacity of any channel with the same rank distribution. A main
contribution is to express the channel capacity as the solution of a convex
optimization problem which can be easily solved by numerical computation. For
the special case of constant-rank input, a closed-form expression for the
capacity is obtained. The behavior of the channel for asymptotically large
field size or packet length is studied, and it is shown that constant-rank
input suffices in this case. Finally, it is proved that the well-known approach
of treating inputs and outputs as subspaces is information-lossless even in
this more general model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6118</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6118</id><created>2011-05-30</created><authors><author><keyname>Tahat</keyname><forenames>Amani</forenames></author><author><keyname>Ling</keyname><forenames>Maurice HT</forenames></author></authors><title>Mapping Relational Operations onto Hypergraph Model</title><categories>cs.DB cs.PL</categories><comments>21 pages</comments><journal-ref>The Python Papers 6(1): 4,2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relational model is the most commonly used data model for storing large
datasets, perhaps due to the simplicity of the tabular format which had
revolutionized database management systems. However, many real world objects
are recursive and associative in nature which makes storage in the relational
model difficult. The hypergraph model is a generalization of a graph model,
where each hypernode can be made up of other nodes or graphs and each hyperedge
can be made up of one or more edges. It may address the recursive and
associative limitations of relational model. However, the hypergraph model is
non-tabular; thus, loses the simplicity of the relational model. In this study,
we consider the means to convert a relational model into a hypergraph model in
two layers. At the bottom layer, each relational tuple can be considered as a
star graph centered where the primary key node is surrounded by non-primary key
attributes. At the top layer, each tuple is a hypernode, and a relation is a
set of hypernodes. We presented a reference implementation of relational
operators (project, rename, select, inner join, natural join, left join, right
join, outer join and Cartesian join) on a hypergraph model. Using a simple
example, we demonstrate that a relation and relational operators can be
implemented on this hypergraph model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6120</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6120</id><created>2011-05-30</created><authors><author><keyname>Hesham</keyname><forenames>Laila</forenames></author><author><keyname>Sultan</keyname><forenames>Ahmed</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author></authors><title>Distributed Spectrum Sensing with Sequential Ordered Transmissions to a
  Cognitive Fusion Center</title><categories>cs.IT math.IT</categories><comments>14 pages, 9 figures</comments><doi>10.1109/TSP.2012.2187644</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cooperative spectrum sensing is a robust strategy that enhances the detection
probability of primary licensed users. However, a large number of detectors
reporting to a fusion center for a final decision causes significant delay and
also presumes the availability of unreasonable communication resources at the
disposal of a network searching for spectral opportunities. In this work, we
employ the idea of sequential detection to obtain a quick, yet reliable,
decision regarding primary activity. Local detectors take measurements, and
only a few of them transmit the log likelihood ratios (LLR) to a fusion center
in descending order of LLR magnitude. The fusion center runs a sequential test
with a maximum imposed on the number of sensors that can report their LLR
measurements. We calculate the detection thresholds using two methods. The
first achieves the same probability of error as the optimal block detector. In
the second, an objective function is constructed and decision thresholds are
obtained via backward induction to optimize this function. The objective
function is related directly to the primary and secondary throughputs with
inbuilt privilege for primary operation. Simulation results demonstrate the
enhanced performance of the approaches proposed in this paper. We also
investigate the case of fading channels between the local sensors and the
fusion center, and the situation in which the sensing cost is negligible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6124</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6124</id><created>2011-05-30</created><authors><author><keyname>Barber</keyname><forenames>F.</forenames></author></authors><title>Reasoning on Interval and Point-based Disjunctive Metric Constraints in
  Temporal Contexts</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  35-86, 2000</journal-ref><doi>10.1613/jair.693</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a temporal model for reasoning on disjunctive metric constraints
on intervals and time points in temporal contexts. This temporal model is
composed of a labeled temporal algebra and its reasoning algorithms. The
labeled temporal algebra defines labeled disjunctive metric point-based
constraints, where each disjunct in each input disjunctive constraint is
univocally associated to a label. Reasoning algorithms manage labeled
constraints, associated label lists, and sets of mutually inconsistent
disjuncts. These algorithms guarantee consistency and obtain a minimal network.
Additionally, constraints can be organized in a hierarchy of alternative
temporal contexts. Therefore, we can reason on context-dependent disjunctive
metric constraints on intervals and points. Moreover, the model is able to
represent non-binary constraints, such that logical dependencies on disjuncts
in constraints can be handled. The computational cost of reasoning algorithms
is exponential in accordance with the underlying problem complexity, although
some improvements are proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6128</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6128</id><created>2011-05-30</created><authors><author><keyname>Chaouni</keyname><forenames>Samia Benabdellah</forenames></author><author><keyname>Fredj</keyname><forenames>Mounia</forenames></author><author><keyname>Mouline</keyname><forenames>Salma</forenames></author></authors><title>MDA based-approach for UML Models Complete Comparison</title><categories>cs.SE</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 2, March 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If a modeling task is distributed, it will frequently be necessary to
integrate models developed by different team members. Problems occur in the
models integration step and particularly, in the comparison phase of the
integration. This issue had been discussed in several domains and various
models. However, previous approaches have not correctly handled the semantic
comparison. In the current paper, we provide a MDA-based approach for models
comparison which aims at comparing UML models. We develop an hybrid approach
which takes into account syntactic, semantic and structural comparison aspects.
For this purpose, we use the domain ontology as well as other resources such as
dictionaries. We propose a decision support system which permits the user to
validate (or not) correspondences extracted in the comparison phase. For
implementation, we propose an extension of the generic correspondence metamodel
AMW in order to transform UML models to the correspondence model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6138</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6138</id><created>2011-05-30</created><authors><author><keyname>Bailey</keyname><forenames>J.</forenames></author><author><keyname>Iwen</keyname><forenames>M. A.</forenames></author><author><keyname>Spencer</keyname><forenames>C. V.</forenames></author></authors><title>On the Design of Deterministic Matrices for Fast Recovery of Fourier
  Compressible Functions</title><categories>math.NA cs.DS cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general class of compressed sensing matrices which are then
demonstrated to have associated sublinear-time sparse approximation algorithms.
We then develop methods for constructing specialized matrices from this class
which are sparse when multiplied with a discrete Fourier transform matrix.
Ultimately, these considerations improve previous sampling requirements for
deterministic sparse Fourier transform methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6145</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6145</id><created>2011-05-30</created><updated>2013-06-18</updated><authors><author><keyname>Rinaldo</keyname><forenames>Alessandro</forenames></author><author><keyname>Petrovi&#x107;</keyname><forenames>Sonja</forenames></author><author><keyname>Fienberg</keyname><forenames>Stephen E.</forenames></author></authors><title>Maximum lilkelihood estimation in the $\beta$-model</title><categories>stat.OT cs.DM math.ST stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/12-AOS1078 the Annals of
  Statistics (http://www.imstat.org/aos/) by the Institute of Mathematical
  Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AOS-AOS1078</report-no><journal-ref>Annals of Statistics 2013, Vol. 41, No. 3, 1085-1110</journal-ref><doi>10.1214/12-AOS1078</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study maximum likelihood estimation for the statistical model for
undirected random graphs, known as the $\beta$-model, in which the degree
sequences are minimal sufficient statistics. We derive necessary and sufficient
conditions, based on the polytope of degree sequences, for the existence of the
maximum likelihood estimator (MLE) of the model parameters. We characterize in
a combinatorial fashion sample points leading to a nonexistent MLE, and
nonestimability of the probability parameters under a nonexistent MLE. We
formulate conditions that guarantee that the MLE exists with probability
tending to one as the number of nodes increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6148</identifier>
 <datestamp>2013-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6148</id><created>2011-05-30</created><updated>2013-03-04</updated><authors><author><keyname>El-Dosuky</keyname><forenames>M. A.</forenames></author><author><keyname>Hamza</keyname><forenames>T. T.</forenames></author><author><keyname>Rashad</keyname><forenames>M. Z.</forenames></author><author><keyname>Naguib</keyname><forenames>A. H.</forenames></author></authors><title>Overcoming Misleads In Logic Programs by Redefining Negation</title><categories>cs.AI</categories><comments>8 pages, 1 figure</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Negation as failure and incomplete information in logic programs have been
studied by many researchers In order to explains HOW a negated conclusion was
reached, we introduce and proof a different way for negating facts to
overcoming misleads in logic programs. Negating facts can be achieved by asking
the user for constants that do not appear elsewhere in the knowledge base.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6150</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6150</id><created>2011-05-30</created><authors><author><keyname>Viswanatha</keyname><forenames>Kumar</forenames></author><author><keyname>Akyol</keyname><forenames>Emrah</forenames></author><author><keyname>Rose</keyname><forenames>Kenneth</forenames></author></authors><title>A Strictly Improved Achievable Region for Multiple Descriptions Using
  Combinatorial Message Sharing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We recently proposed a new coding scheme for the L-channel multiple
descriptions (MD) problem for general sources and distortion measures involving
`Combinatorial Message Sharing' (CMS) [7] leading to a new achievable
rate-distortion region. Our objective in this paper is to establish that this
coding scheme strictly subsumes the most popular region for this problem due to
Venkataramani, Kramer and Goyal (VKG) [3]. In particular, we show that for a
binary symmetric source under Hamming distortion measure, the CMS scheme
provides a strictly larger region for all L&gt;2. The principle of the CMS coding
scheme is to include a common message in every subset of the descriptions,
unlike the VKG scheme which sends a single common message in all the
descriptions. In essence, we show that allowing for a common codeword in every
subset of descriptions provides better freedom in coordinating the messages
which can be exploited constructively to achieve points outside the VKG region.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6151</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6151</id><created>2011-05-30</created><authors><author><keyname>Farach-Colton</keyname><forenames>Martin</forenames></author><author><keyname>Anta</keyname><forenames>Antonio Fernandez</forenames></author><author><keyname>Milani</keyname><forenames>Alessia</forenames></author><author><keyname>Mosteiro</keyname><forenames>Miguel A.</forenames></author><author><keyname>Zaks</keyname><forenames>Shmuel</forenames></author></authors><title>Opportunistic Information Dissemination in Mobile Ad-hoc Networks:
  adaptiveness vs. obliviousness and randomization vs. determinism</title><categories>cs.DS cs.DC cs.NI</categories><msc-class>68Q25</msc-class><acm-class>F.2.0; C.2.2; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the problem of information dissemination in Mobile Ad-hoc
Networks (MANET) is studied. The problem is to disseminate a piece of
information, initially held by a distinguished source node, to all nodes in a
set defined by some predicate. We use a model of MANETs that is well suited for
dynamic networks and opportunistic communication. In this model nodes are
placed in a plane, in which they can move with bounded speed, and communication
between nodes occurs over a collision-prone single channel. In this setup
informed and uninformed nodes can be disconnected for some time (bounded by a
parameter alpha), but eventually some uninformed node must become neighbor of
an informed node and remain so for some time (bounded by a parameter beta). In
addition, nodes can start at different times, and they can crash and recover.
Under the above framework, we show negative and positive results for different
types of randomized protocols, and we put those results in perspective with
respect to previous deterministic results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6160</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6160</id><created>2011-05-31</created><authors><author><keyname>Choochaisri</keyname><forenames>Supasate</forenames></author><author><keyname>Niennattrakul</keyname><forenames>Vit</forenames></author><author><keyname>Jenjaturong</keyname><forenames>Saran</forenames></author><author><keyname>Intanagonwiwat</keyname><forenames>Chalermek</forenames></author><author><keyname>Ratanamahatana</keyname><forenames>Chotirat Ann</forenames></author></authors><title>SENVM: Server Environment Monitoring and Controlling System for a Small
  Data Center Using Wireless Sensor Network</title><categories>cs.NI</categories><comments>6 pages</comments><acm-class>C.2.4; J.7</acm-class><journal-ref>The 2010 International Computer Science and Engineering Conference
  (ICSEC), Chiang Mai, Thailand</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, efficient energy utilization becomes an essential
requirement for data centers, especially in data centers of world-leading
companies, where &quot;Green Data Center&quot; defines a new term for an
environment-concerned data center. Solutions to change existing a data center
to the green one may vary. In the big company, high-cost approaches including
re-planning server rooms, changing air-conditioners, buying low-powered
servers, and equipping sophisticating environmental control equipments are
possible, but not for small to medium enterprises (SMEs) and academic sectors
which have limited budget. In this paper, we propose a novel system, SENVM,
used to monitor and control air temperature in a server room to be in
appropriate condition, not too cold, where very unnecessary cooling leads to
unnecessary extra electricity expenses, and also inefficient in energy
utilization. With implementing on an emerging technology, Wireless Sensor
Network (WSN), Green Data Center is feasible to every small data center with no
wiring installation, easy deployment, and low maintenance fee. In addition, the
prototype of the system has been tested, and the first phase of the project is
deployed in a real-world data center.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6162</identifier>
 <datestamp>2011-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6162</id><created>2011-05-31</created><updated>2011-06-26</updated><authors><author><keyname>Van Aken</keyname><forenames>Jerry R.</forenames></author></authors><title>A statistical learning algorithm for word segmentation</title><categories>cs.CL</categories><comments>30 pages, 5 figures</comments><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In natural speech, the speaker does not pause between words, yet a human
listener somehow perceives this continuous stream of phonemes as a series of
distinct words. The detection of boundaries between spoken words is an instance
of a general capability of the human neocortex to remember and to recognize
recurring sequences. This paper describes a computer algorithm that is designed
to solve the problem of locating word boundaries in blocks of English text from
which the spaces have been removed. This problem avoids the complexities of
speech processing but requires similar capabilities for detecting recurring
sequences. The algorithm relies entirely on statistical relationships between
letters in the input stream to infer the locations of word boundaries. A
Viterbi trellis is used to simultaneously evaluate a set of hypothetical
segmentations of a block of adjacent words. This technique improves accuracy
but incurs a small latency between the arrival of letters in the input stream
and the sending of words to the output stream. The source code for a C++
version of this algorithm is presented in an appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6163</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6163</id><created>2011-05-31</created><authors><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Manoj M.</forenames></author></authors><title>Assisted Common Information: Further Results</title><categories>cs.IT cs.CR math.IT</categories><comments>8 pages, 3 figures, 1 appendix; to be presented at the IEEE
  International Symposium on Information Theory, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We presented assisted common information as a generalization of
G\'acs-K\&quot;orner (GK) common information at ISIT 2010. The motivation for our
formulation was to improve upperbounds on the efficiency of protocols for
secure two-party sampling (which is a form of secure multi-party computation).
Our upperbound was based on a monotonicity property of a rate-region (called
the assisted residual information region) associated with the assisted common
information formulation. In this note we present further results. We explore
the connection of assisted common information with the Gray-Wyner system. We
show that the assisted residual information region and the Gray-Wyner region
are connected by a simple relationship: the assisted residual information
region is the increasing hull of the Gray-Wyner region under an affine map.
Several known relationships between GK common information and Gray-Wyner system
fall out as consequences of this. Quantities which arise in other source coding
contexts acquire new interpretations. In previous work we showed that assisted
common information can be used to derive upperbounds on the rate at which a
pair of parties can {\em securely sample} correlated random variables, given
correlated random variables from another distribution. Here we present an
example where the bound derived using assisted common information is much
better than previously known bounds, and in fact is tight. This example
considers correlated random variables defined in terms of standard variants of
oblivious transfer, and is interesting on its own as it answers a natural
question about these cryptographic primitives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6164</identifier>
 <datestamp>2013-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6164</id><created>2011-05-31</created><updated>2013-04-10</updated><authors><author><keyname>Tal</keyname><forenames>Ido</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author></authors><title>How to Construct Polar Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for efficiently constructing polar codes is presented and analyzed.
Although polar codes are explicitly defined, straightforward construction is
intractable since the resulting polar bit-channels have an output alphabet that
grows exponentially with he code length. Thus the core problem that needs to be
solved is that of faithfully approximating a bit-channel with an intractably
large alphabet by another channel having a manageable alphabet size. We devise
two approximation methods which &quot;sandwich&quot; the original bit-channel between a
degraded and an upgraded version thereof. Both approximations can be
efficiently computed, and turn out to be extremely close in practice. We also
provide theoretical analysis of our construction algorithms, proving that for
any fixed $\epsilon &gt; 0$ and all sufficiently large code lengths $n$, polar
codes whose rate is within $\epsilon$ of channel capacity can be constructed in
time and space that are both linear in $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6170</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6170</id><created>2011-05-31</created><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author></authors><title>How Many Transmit Antennas to Use in a MIMO Interference Channel</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of finding the optimal number of data streams to transmit in a
multi-user MIMO scenario, where both the transmitters and receivers are
equipped with multiple antennas is considered. Without channel state
information at any transmitter, with a zero-forcing receiver each user is shown
to transmit a single data stream to maximize its own outage capacity in the
presence of sufficient number of users. Transmitting a single data stream is
also shown to be optimal in terms of maximizing the sum of the outage
capacities in the presence of sufficient number of users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6176</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6176</id><created>2011-05-31</created><authors><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author></authors><title>Energy-Delay Considerations in Coded Packet Flows</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures. Accepted, IEEE ISIT 2011, Saint Petersburg,
  Russia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a line of terminals which is connected by packet erasure channels
and where random linear network coding is carried out at each node prior to
transmission. In particular, we address an online approach in which each
terminal has local information to be conveyed to the base station at the end of
the line and provide a queueing theoretic analysis of this scenario. First, a
genie-aided scenario is considered and the average delay and average
transmission energy depending on the link erasure probabilities and the Poisson
arrival rates at each node are analyzed. We then assume that all nodes cannot
send and receive at the same time. The transmitting nodes in the network send
coded data packets before stopping to wait for the receiving nodes to
acknowledge the number of degrees of freedom, if any, that are required to
decode correctly the information. We analyze this problem for an infinite queue
size at the terminals and show that there is an optimal number of coded data
packets at each node, in terms of average completion time or transmission
energy, to be sent before stopping to listen.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6190</identifier>
 <datestamp>2014-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6190</id><created>2011-05-31</created><authors><author><keyname>Stamenkovi&#x107;</keyname><forenames>Aleksandar</forenames></author><author><keyname>&#x106;iri&#x107;</keyname><forenames>Miroslav</forenames></author></authors><title>Construction of fuzzy automata from fuzzy regular expressions</title><categories>cs.FL</categories><comments>26 pages, submitted to a journal</comments><msc-class>68Q45, 68Q70, 68T37, 03E72</msc-class><acm-class>F.1.1; I.2.3</acm-class><journal-ref>Fuzzy Sets and Systems 199 (2012) 1-27</journal-ref><doi>10.1016/j.fss.2012.01.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Li and Pedrycz [Y. M. Li, W. Pedrycz, Fuzzy finite automata and fuzzy regular
expressions with membership values in lattice ordered monoids, Fuzzy Sets and
Systems 156 (2005) 68--92] have proved fundamental results that provide
different equivalent ways to represent fuzzy languages with membership values
in a lattice-ordered monoid, and generalize the well-known results of the
classical theory of formal languages. In particular, they have shown that a
fuzzy language over an integral lattice-ordered monoid can be represented by a
fuzzy regular expression if and only if it can be recognized by a fuzzy finite
automaton. However, they did not give any effective method for constructing an
equivalent fuzzy finite automaton from a given fuzzy regular expression. In
this paper we provide such an effective method. Transforming scalars appearing
in a fuzzy regular expression {\alpha} into letters of the new extended
alphabet, we convert the fuzzy regular expression {\alpha} to an ordinary
regular expression {\alpha}_{R}. Then, starting from an arbitrary
nondeterministic finite automaton A that recognizes the language ||{\alpha}_R||
represented by the regular expression {\alpha}_R, we construct fuzzy finite
automata A_{\alpha} and A_{\alpha}^r with the same or even less number of
states than the automaton A, which recognize the fuzzy language ||{\alpha}||
represented by the fuzzy regular expression {\alpha}. The starting
nondeterministic finite automaton A can be obtained from {\alpha}_R using any
of the well-known constructions for converting regular expressions to
nondeterministic finite automata, such as Glushkov-McNaughton-Yamada's position
automaton, Brzozowski's derivative automaton, Antimirov's partial derivative
automaton, or Ilie-Yu's follow automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6199</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6199</id><created>2011-05-31</created><authors><author><keyname>Kim</keyname><forenames>Heejin</forenames></author><author><keyname>Lee</keyname><forenames>Sang-Rim</forenames></author><author><keyname>Lee</keyname><forenames>Kyoung-Jae</forenames></author><author><keyname>Lee</keyname><forenames>Inkyu</forenames></author></authors><title>Transmission Schemes based on Sum Rate Analysis in Distributed Antenna
  Systems</title><categories>cs.IT math.IT</categories><comments>25 pages, 8 figures, submitted to IEEE Transactions on Wireless
  Communications, May 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study single cell multi-user downlink distributed antenna
systems (DAS) where antenna ports are geographically separated in a cell.
First, we derive an expression of the ergodic sum rate for the DAS in the
presence of pathloss. Then, we propose a transmission selection scheme based on
the derived expressions which does not require channel state information at the
transmitter. Utilizing the knowledge of distance information from a user to
each distributed antenna (DA) port, we consider the optimization of pairings of
DA ports and users to maximize the system performance. Based on the ergodic sum
rate expressions, the proposed scheme chooses the best mode maximizing the
ergodic sum rate among mode candidates. In our proposed scheme, the number of
mode candidates are greatly reduced compared to that of ideal mode selection.
In addition, we analyze the signal to noise ratio cross-over point for
different modes using the sum rate expressions. Through Monte Carlo
simulations, we show the accuracy of our derivations for the ergodic sum rate.
Moreover, simulation results with the pathloss modeling confirm that the
proposed scheme produces the average sum rate identical to the ideal mode
selection with significantly reduced candidates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6205</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6205</id><created>2011-05-31</created><authors><author><keyname>Merelo</keyname><forenames>Juan-J.</forenames></author><author><keyname>Garc&#xed;a-Arenas</keyname><forenames>Maribel</forenames></author><author><keyname>Mora</keyname><forenames>Antonio M.</forenames></author><author><keyname>Castillo</keyname><forenames>Pedro</forenames></author><author><keyname>Romero</keyname><forenames>Gustavo</forenames></author><author><keyname>Laredo</keyname><forenames>JLJ</forenames></author></authors><title>Cloud-based Evolutionary Algorithms: An algorithmic study</title><categories>cs.NE cs.DC cs.NI</categories><comments>Paper 4 for the First International Workshop of Distributed
  Evolutionary computation in Informal Environments</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  After a proof of concept using Dropbox(tm), a free storage and
synchronization service, showed that an evolutionary algorithm using several
dissimilar computers connected via WiFi or Ethernet had a good scaling behavior
in terms of evaluations per second, it remains to be proved whether that effect
also translates to the algorithmic performance of the algorithm. In this paper
we will check several different, and difficult, problems, and see what effects
the automatic load-balancing and asynchrony have on the speed of resolution of
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6210</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6210</id><created>2011-05-31</created><authors><author><keyname>Deransart</keyname><forenames>Pierre</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Generic Traces and Constraints, GenTra4CP revisited</title><categories>cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The generic trace format GenTra4CP has been defined in 2004 with the goal of
becoming a standard trace format for the observation of constraint solvers over
finite domains. It has not been used since. This paper defines the concept of
generic trace formally, based on simple transformations of traces. It then
analyzes, and occasionally corrects, shortcomings of the proposed initial
format and shows the interest that a generic tracer may bring to develop
portable applications or to standardization efforts, in particular in the field
of constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6213</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6213</id><created>2011-05-31</created><authors><author><keyname>Bouramoul</keyname><forenames>Abdelkrim</forenames></author><author><keyname>Kholladi</keyname><forenames>Mohamed-Khireddine</forenames></author><author><keyname>Doan</keyname><forenames>Bich-Lien</forenames></author></authors><title>Using Context to Improve the Evaluation of Information Retrieval Systems</title><categories>cs.IR</categories><comments>18 pages</comments><journal-ref>International Journal of Database Management Systems ( IJDMS ),
  Vol.3, No.2, May 2011</journal-ref><doi>10.5121/ijdms.2011.3202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The crucial role of the evaluation in the development of the information
retrieval tools is useful evidence to improve the performance of these tools
and the quality of results that they return. However, the classic evaluation
approaches have limitations and shortcomings especially regarding to the user
consideration, the measure of the adequacy between the query and the returned
documents and the consideration of characteristics, specifications and
behaviors of the search tool. Therefore, we believe that the exploitation of
contextual elements could be a very good way to evaluate the search tools. So,
this paper presents a new approach that takes into account the context during
the evaluation process at three complementary levels. The experiments gives at
the end of this article has shown the applicability of the proposed approach to
real research tools. The tests were performed with the most popular searching
engine (i.e. Google, Bing and Yahoo) selected in particular for their high
selectivity. The obtained results revealed that the ability of these engines to
rejecting dead links, redundant results and parasites pages depends strongly to
how queries are formulated, and to the political of sites offering this
information to present their content. The relevance evaluation of results
provided by these engines, using the user's judgments, then using an automatic
manner to take into account the query context has also shown a general decline
in the perceived relevance according to the number of the considered results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6224</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6224</id><created>2011-05-31</created><authors><author><keyname>Frolov</keyname><forenames>Alexey</forenames></author><author><keyname>Zyablov</keyname><forenames>Victor</forenames></author></authors><title>Upper and Lower Bounds on the Minimum Distance of Expander Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, IEEE International Symposium on Information Theory
  2011 (ISIT 2011), Saint Petersburg, Russia, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimum distance of expander codes over GF(q) is studied. A new upper
bound on the minimum distance of expander codes is derived. The bound is shown
to lie under the Varshamov-Gilbert (VG) bound while q &gt;= 32. Lower bounds on
the minimum distance of some families of expander codes are obtained. A lower
bound on the minimum distance of low-density parity-check (LDPC) codes with a
Reed--Solomon constituent code over GF(q) is obtained. The bound is shown to be
very close to the VG bound and to lie above the upper bound for expander codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6237</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6237</id><created>2011-05-31</created><authors><author><keyname>Liu</keyname><forenames>Tang</forenames></author><author><keyname>Peng</keyname><forenames>Jian</forenames></author><author><keyname>Yang</keyname><forenames>Jin</forenames></author><author><keyname>Wang</keyname><forenames>Chunli</forenames></author></authors><title>Energy efficient prediction clustering algorithm for multilevel
  heterogeneous wireless sensor networks</title><categories>cs.NI</categories><comments>17pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In designing wireless sensor networks, it is important to reduce energy
dissipation and prolong network lifetime. In this paper, a new model with
energy and monitored objects heterogeneity is proposed for heterogeneous
wireless sensor networks. We put forward an energy-efficient prediction
clustering algorithm, which is adaptive to the heterogeneous model. This
algorithm enables the nodes to select the cluster head according to factors
such as energy and communication cost, thus the nodes with higher residual
energy have higher probability to become a cluster head than those with lower
residual energy, so that the network energy can be dissipated uniformly. In
order to reduce energy consumption when broadcasting in clustering phase and
prolong network lifetime, an energy consumption prediction model is established
for regular data acquisition nodes. Simulation results show that compared with
current clustering algorithms, this algorithm can achieve longer sensor network
lifetime, higher energy efficiency and superior network monitoring quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6245</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6245</id><created>2011-05-31</created><authors><author><keyname>Airoldi</keyname><forenames>Edoardo M.</forenames></author><author><keyname>Choi</keyname><forenames>David S.</forenames></author><author><keyname>Wolfe</keyname><forenames>Patrick J.</forenames></author></authors><title>Confidence sets for network structure</title><categories>stat.ME cs.SI physics.soc-ph</categories><comments>17 pages, 3 figures, 3 tables</comments><journal-ref>Statistical Analysis and Data Mining, vol. 4, pp. 461-469, 2011</journal-ref><doi>10.1002/sam.10136</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Latent variable models are frequently used to identify structure in
dichotomous network data, in part because they give rise to a Bernoulli product
likelihood that is both well understood and consistent with the notion of
exchangeable random graphs. In this article we propose conservative confidence
sets that hold with respect to these underlying Bernoulli parameters as a
function of any given partition of network nodes, enabling us to assess
estimates of 'residual' network structure, that is, structure that cannot be
explained by known covariates and thus cannot be easily verified by manual
inspection. We demonstrate the proposed methodology by analyzing student
friendship networks from the National Longitudinal Survey of Adolescent Health
that include race, gender, and school year as covariates. We employ a
stochastic expectation-maximization algorithm to fit a logistic regression
model that includes these explanatory variables as well as a latent stochastic
blockmodel component and additional node-specific effects. Although
maximum-likelihood estimates do not appear consistent in this context, we are
able to evaluate confidence sets as a function of different blockmodel
partitions, which enables us to qualitatively assess the significance of
estimated residual network structure relative to a baseline, which models
covariates but lacks block structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6257</identifier>
 <datestamp>2014-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6257</id><created>2011-05-31</created><updated>2014-01-30</updated><authors><author><keyname>&#x10c;adek</keyname><forenames>Martin</forenames></author><author><keyname>Kr&#x10d;&#xe1;l</keyname><forenames>Marek</forenames></author><author><keyname>Matou&#x161;ek</keyname><forenames>Ji&#x159;&#xed;</forenames></author><author><keyname>Sergeraert</keyname><forenames>Francis</forenames></author><author><keyname>Vok&#x159;&#xed;nek</keyname><forenames>Luk&#xe1;&#x161;</forenames></author><author><keyname>Wagner</keyname><forenames>Uli</forenames></author></authors><title>Computing all maps into a sphere</title><categories>cs.CG math.AT</categories><comments>42 pages; a revised and substantially updated version (referring to
  follow-up papers and results)</comments><msc-class>68U05, 68W99, 55S45, 55S37</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given topological spaces X and Y, a fundamental problem of algebraic topology
is understanding the structure of all continuous maps X -&gt; Y . We consider a
computational version, where X, Y are given as finite simplicial complexes, and
the goal is to compute [X,Y], i.e., all homotopy classes of such maps. We solve
this problem in the stable range, where for some d &gt;= 2, we have dim X &lt;= 2d -
2 and Y is (d - 1)-connected; in particular, Y can be the d-dimensional sphere
S^d. The algorithm combines classical tools and ideas from homotopy theory
(obstruction theory, Postnikov systems, and simplicial sets) with algorithmic
tools from effective algebraic topology (locally effective simplicial sets and
objects with effective homology). In contrast, [X,Y] is known to be
uncomputable for general X,Y, since for X = S^1 it includes a well known
undecidable problem: testing triviality of the fundamental group of Y. In
follow-up papers, the algorithm is shown to run in polynomial time for d fixed,
and extended to other problems, such as the extension problem, where we are
given a subspace A of X and a map A -&gt; Y and ask whether it extends to a map X
-&gt; Y, or computing the Z_2-index---everything in the stable range. Outside the
stable range, the extension problem is undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6265</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6265</id><created>2011-05-31</created><authors><author><keyname>Buda</keyname><forenames>Andrzej</forenames></author></authors><title>Hierarchical structure in phonographic market</title><categories>q-fin.GN cs.SI physics.soc-ph stat.AP</categories><comments>10 pages, 3 figures, 2 tables, 2 pictures, presented at FENS 2010 in
  Warsaw, chapter of book &quot;Life-time Of Correlation And Its Application (volume
  1)&quot;</comments><journal-ref>A. Buda, A. Jarynowski, Life-time Of Correlation And Its
  Application (volume 1), Wydawnictwo Niezalezne, Wroclaw 2010, ISBN
  978-83915272-9-0</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I find a topological arrangement of assets traded in a phonographic market
which has associated a meaningful economic taxonomy. I continue using the
Minimal Spanning Tree and the Life-time Of Correlations between assets, but now
outside the stock markets. This is the first attempt to use these methods on
phonographic market where we have artists instead of stocks. The value of an
artist is defined by record sales. The graph is obtained starting from the
matrix of correlations coefficient computed between the world's most popular 30
artists by considering the synchronous time evolution of the difference of the
logarithm of weekly record sales. This method provides the hierarchical
structure of phonographic market and information on which music genre is
meaningful according to customers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6277</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6277</id><created>2011-05-31</created><authors><author><keyname>Wong</keyname><forenames>Hoi Sim</forenames></author><author><keyname>Chin</keyname><forenames>Tat-Jun</forenames></author><author><keyname>Yu</keyname><forenames>Jin</forenames></author><author><keyname>Suter</keyname><forenames>David</forenames></author></authors><title>Incremental Top-k List Comparison Approach to Robust Multi-Structure
  Model Fitting</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random hypothesis sampling lies at the core of many popular robust fitting
techniques such as RANSAC. In this paper, we propose a novel hypothesis
sampling scheme based on incremental computation of distances between partial
rankings (top-$k$ lists) derived from residual sorting information. Our method
simultaneously (1) guides the sampling such that hypotheses corresponding to
all true structures can be quickly retrieved and (2) filters the hypotheses
such that only a small but very promising subset remain. This permits the usage
of simple agglomerative clustering on the surviving hypotheses for accurate
model selection. The outcome is a highly efficient multi-structure robust
estimation technique. Experiments on synthetic and real data show the superior
performance of our approach over previous methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6288</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6288</id><created>2011-05-31</created><authors><author><keyname>Heidarzadeh</keyname><forenames>Anoosheh</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>Analysis of Overlapped Chunked Codes with Small Chunks over Line
  Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures; accepted for presentation at ISIT'11</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To lower the complexity of network codes over packet line networks with
arbitrary schedules, chunked codes (CC) and overlapped chunked codes (OCC) were
proposed in earlier works. These codes have been previously analyzed for
relatively large chunks. In this paper, we prove that for smaller chunks, CC
and OCC asymptotically approach the capacity with an arbitrarily small but
non-zero constant gap. We also show that unlike the case for large chunks, the
larger is the overlap size, the better would be the tradeoff between the speed
of convergence and the message or packet error rate. This implies that OCC are
superior to CC for shorter chunks. Simulations consistent with the theoretical
results are also presented, suggesting great potential for the application of
OCC for multimedia transmission over packet networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6305</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6305</id><created>2011-05-31</created><authors><author><keyname>Vejdemo-Johansson</keyname><forenames>Mikael</forenames></author></authors><title>Interleaved computation for persistent homology</title><categories>cs.CG math.AT</categories><comments>5 pages, draft version</comments><report-no>Mittag-Leffler-2011spring</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We describe an approach to bounded-memory computation of persistent homology
and betti barcodes, in which a computational state is maintained with updates
introducing new edges to the underlying neighbourhood graph and percolating the
resulting changes into the simplex stream feeding the persistence algorithm.
  We further discuss the memory consumption and resulting speed and complexity
behaviours of the resulting algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6307</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6307</id><created>2011-05-31</created><authors><author><keyname>Catanese</keyname><forenames>Salvatore A.</forenames></author><author><keyname>De Meo</keyname><forenames>Pasquale</forenames></author><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Fiumara</keyname><forenames>Giacomo</forenames></author><author><keyname>Provetti</keyname><forenames>Alessandro</forenames></author></authors><title>Crawling Facebook for Social Network Analysis Purposes</title><categories>cs.SI cs.CY physics.soc-ph</categories><comments>WIMS '11: International Conference on Web Intelligence, Mining and
  Semantics ACM New York, NY, USA \c{opyright}2011 ISBN: 978-1-4503-0148-0</comments><msc-class>91D30</msc-class><acm-class>H.2.8; E.1; G.2.2</acm-class><journal-ref>Proceedings of the International Conference on Web Intelligence,
  Mining and Semantics, 2011</journal-ref><doi>10.1145/1988688.1988749</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe our work in the collection and analysis of massive data
describing the connections between participants to online social networks.
Alternative approaches to social network data collection are defined and
evaluated in practice, against the popular Facebook Web site. Thanks to our
ad-hoc, privacy-compliant crawlers, two large samples, comprising millions of
connections, have been collected; the data is anonymous and organized as an
undirected graph. We describe a set of tools that we developed to analyze
specific properties of such social-network graphs, i.e., among others, degree
distribution, centrality measures, scaling laws and distribution of friendship.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6314</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6314</id><created>2011-05-31</created><authors><author><keyname>Michel</keyname><forenames>L.</forenames></author><author><keyname>Van Hentenryck</keyname><forenames>P.</forenames></author></authors><title>Activity-Based Search for Black-Box Contraint-Programming Solvers</title><categories>cs.AI cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust search procedures are a central component in the design of black-box
constraint-programming solvers. This paper proposes activity-based search, the
idea of using the activity of variables during propagation to guide the search.
Activity-based search was compared experimentally to impact-based search and
the WDEG heuristics. Experimental results on a variety of benchmarks show that
activity-based search is more robust than other heuristics and may produce
significant improvements in performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6317</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6317</id><created>2011-05-31</created><updated>2011-08-22</updated><authors><author><keyname>Ben-Amram</keyname><forenames>Amir M.</forenames><affiliation>Tel-Aviv Academic College</affiliation></author></authors><title>Monotonicity Constraints for Termination in the Integer Domain</title><categories>cs.LO</categories><comments>43 pages</comments><proxy>LMCS</proxy><acm-class>D.2.4, F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 3 (August 24,
  2011) lmcs:1002</journal-ref><doi>10.2168/LMCS-7(3:4)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Size-Change Termination (SCT) is a method of proving program termination
based on the impossibility of infinite descent. To this end we use a program
abstraction in which transitions are described by Monotonicity Constraints over
(abstract) variables. When only constraints of the form x&gt;y' and x\geq y' are
allowed, we have size-change graphs. In the last decade, both theory and
practice have evolved significantly in this restricted framework. The crucial
underlying assumption of most of the past work is that the domain of the
variables is well-founded. In a recent paper I showed how to extend and adapt
some theory from the domain of size-change graphs to general monotonicity
constraints, thus complementing previous work, but remaining in the realm of
well-founded domains. However, monotonicity constraints are, interestingly,
capable of proving termination also in the integer domain, which is not
well-founded. The purpose of this paper is to explore the application of
monotonicity constraints in this domain. We lay the necessary theoretical
foundation, and present precise decision procedures for termination; finally,
we provide a procedure to construct explicit global ranking functions from
monotonicity constraints in singly-exponential time, and of optimal worst-case
size and dimension (ordinal).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6320</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6320</id><created>2011-05-31</created><authors><author><keyname>Kohli</keyname><forenames>Mohit</forenames></author></authors><title>Transformation from Identity Stone Age to Digital Identity</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Technological conversion, political interests and Business drivers has
triggered a means, to establish individual characterization and
personalization. People started raising concerns on multiple identities managed
across various zones and hence various solutions were designed. Technological
advancement has brought various issues and concerns around Identity assurance,
privacy and policy enabled common Authentication framework. A compressive
framework is needed to established common identity model to address national
needs like standards, regulation and laws, minimum risk, interoperability and
to provide user with a consistent context or user experience.
  This document focuses on Transformation path of identity stone age to
Identity as in state. It defines a digital identity zone model (DIZM) to
showcase the Global Identity defined across the ecosystem. Also, provide
insight of emerging Technology trend to enable Identity assurance, privacy and
policy enabled common Authentication framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6326</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6326</id><created>2011-05-31</created><authors><author><keyname>Wang</keyname><forenames>I-Hsiang</forenames></author><author><keyname>Kamath</keyname><forenames>Sudeep U.</forenames></author><author><keyname>Tse</keyname><forenames>David N. C.</forenames></author></authors><title>Two Unicast Information Flows over Linear Deterministic Networks</title><categories>cs.IT math.IT</categories><comments>Extended version of the conference paper to be presented at ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the two unicast flow problem over layered linear deterministic
networks with arbitrary number of nodes. When the minimum cut value between
each source-destination pair is constrained to be 1, it is obvious that the
triangular rate region {(R_1,R_2):R_1,R_2&gt; 0, R_1+R_2&lt; 1} can be achieved, and
that one cannot achieve beyond the square rate region {(R_1,R_2):R_1,R_2&gt; 0,
R_1&lt; 1,R_2&lt; 1}. Analogous to the work by Wang and Shroff for wired networks, we
provide the necessary and sufficient conditions for the capacity region to be
the triangular region and the necessary and sufficient conditions for it to be
the square region. Moreover, we completely characterize the capacity region and
conclude that there are exactly three more possible capacity regions of this
class of networks, in contrast to the result in wired networks where only the
triangular and square rate regions are possible. Our achievability scheme is
based on linear coding over an extension field with at most four nodes
performing special linear coding operations, namely interference neutralization
and zero forcing, while all other nodes perform random linear coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6331</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6331</id><created>2011-05-31</created><authors><author><keyname>Galbraith</keyname><forenames>Steven</forenames></author><author><keyname>Stolbunov</keyname><forenames>Anton</forenames></author></authors><title>Improved Algorithm for the Isogeny Problem for Ordinary Elliptic Curves</title><categories>math.NT cs.DS</categories><comments>23 pages, 3 figures</comments><msc-class>11Y16, 11G20, 14G50, 68W20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A low storage algorithm for constructing isogenies between ordinary elliptic
curves was proposed by Galbraith, Hess and Smart (GHS). We give an improvement
of this algorithm by modifying the pseudorandom walk so that lower-degree
isogenies are used more frequently. This is motivated by the fact that high
degree isogenies are slower to compute than low degree ones. We analyse the
running time of the parallel collision search algorithm when the partitioning
is uneven. We also give experimental results. We conclude that our algorithm is
around 14 times faster than the GHS algorithm when constructing horizontal
isogenies between random isogenous elliptic curves over a 160-bit prime field.
  The results apply to generic adding walks and the more general group action
inverse problem; a speed-up is obtained whenever the cost of computing edges in
the graph varies significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6357</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6357</id><created>2011-05-31</created><authors><author><keyname>Al-Khouri</keyname><forenames>Ali M.</forenames></author></authors><title>PKI in Government Identity Management Systems</title><categories>cs.CY</categories><comments>28 pages, 9 figures, 3 tables</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.3, May 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this article is to provide an overview of the PKI project
initiated part of the UAE national ID card program. It primarily shows the
operational model of the PKI implementation that is indented to integrate the
federal government identity management infrastructure with e-government
initiatives owners in the country. It also explicates the agreed structure of
the major components in relation to key stakeholders; represented by federal
and local e-government authorities, financial institutions, and other
organizations in both public and private sectors. The content of this article
is believed to clarify some of the misconceptions about PKI implementation in
national ID schemes, and explain how the project is envisaged to encourage the
diffusion of e-government services in the United Arab Emirates. The study
concludes that governments in the Middle East region have the trust in PKI
technology to support their e-government services and expanding outreach and
population trust, if of course accompanied by comprehensive digital laws and
policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6358</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6358</id><created>2011-05-31</created><authors><author><keyname>Al-Khouri</keyname><forenames>Ali M.</forenames></author></authors><title>An Innovative Approach for E-Government Transformation</title><categories>cs.CY</categories><comments>22 Pages, 15 figures, 5 tables</comments><journal-ref>International Journal of Managing Value and Supply Chains (IJMVSC)
  Vol. 2, No. 1, March 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the immeasurable investment in e-government initiatives throughout
the world, such initiatives have yet to succeed in fully meeting expectations
and desired outcomes. A key objective of this research article is to support
the government of the UAE in realizing its vision of e-government
transformation. It presents an innovative framework to support e-government
implementation, which was developed from a practitioner's perspective and based
on learnings from numerous e-government practices around the globe. The
framework presents an approach to guide governments worldwide, and UAE in
particular, to develop a top down strategy and leverage technology in order
realize its long term goal of e-government transformation. The study also
outlines the potential role of modern national identity schemes in enabling the
transformation of traditional identities into digital identities. The work
presented in this study is envisaged to help bridge the gap between policy
makers and implementers, by providing greater clarity and reducing misalignment
on key elements of e-government transformation. In the hands of leaders that
have a strong will to invest in e-government transformation, the work presented
in this study is envisaged to become a powerful tool to communicate and
coordinate initiatives, and provide a clear visualization of an integrated
approach to e-government transformation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6361</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6361</id><created>2011-05-31</created><authors><author><keyname>Al-Khouri</keyname><forenames>Ali M.</forenames></author></authors><title>Re-thinking Enrolment in Identity Card Schemes</title><categories>cs.OH</categories><comments>14 pages, 11 figures, 1 table</comments><journal-ref>International Journal of Engineering Science and Technology
  (IJEST), Vol. 3 No. 2 Feb 2011, pp.912-925</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many countries around the world have initiated national ID card programs in
the last decade. These programs are considered of strategic value to
governments due to its contribution in enhancing existing identity management
systems. Considering the total cost of such programs which goes up to billions
of dollars, the success in attaining their objectives is a crucial element in
the agendas of political systems in countries worldwide. Our experience in the
field shows that many of such projects have been challenged to deliver their
primary objectives of population enrolment, and therefore resulted in failing
to meet deadlines and keeping up with budgetary constraints. The purpose of
this paper is to explain the finding of a case study action research aimed to
introduce a new approach to how population are enrolled in national ID
programs. This is achieved through presenting a case study of a business
process reengineering initiative undertaken in the UAE national ID program. The
scope of this research is limited to the enrolment process within the program.
This article also intends to explore the possibilities of significant results
with the new proposed enrolment approach with the application of BPR. An
overview of the ROI study has been developed to illustrate such efficiencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6368</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6368</id><created>2011-05-31</created><updated>2011-11-20</updated><authors><author><keyname>Kamilov</keyname><forenames>Ulugbek</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K.</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author></authors><title>Message-Passing Estimation from Quantized Samples</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>12 pages, 8 figures</comments><journal-ref>IEEE Trans. on Signal Processing, vol. 60, no. 12, pp. 6270-6281,
  December 2012</journal-ref><doi>10.1109/TSP.2012.2217334</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Estimation of a vector from quantized linear measurements is a common problem
for which simple linear techniques are suboptimal -- sometimes greatly so. This
paper develops generalized approximate message passing (GAMP) algorithms for
minimum mean-squared error estimation of a random vector from quantized linear
measurements, notably allowing the linear expansion to be overcomplete or
undercomplete and the scalar quantization to be regular or non-regular. GAMP is
a recently-developed class of algorithms that uses Gaussian approximations in
belief propagation and allows arbitrary separable input and output channels.
Scalar quantization of measurements is incorporated into the output channel
formalism, leading to the first tractable and effective method for
high-dimensional estimation problems involving non-regular scalar quantization.
Non-regular quantization is empirically demonstrated to greatly improve
rate-distortion performance in some problems with oversampling or with
undersampling combined with a sparsity-inducing prior. Under the assumption of
a Gaussian measurement matrix with i.i.d. entries, the asymptotic error
performance of GAMP can be accurately predicted and tracked through the state
evolution formalism. We additionally use state evolution to design MSE-optimal
scalar quantizers for GAMP signal reconstruction and empirically demonstrate
the superior error performance of the resulting quantizers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1105.6374</identifier>
 <datestamp>2011-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1105.6374</id><created>2011-05-31</created><authors><author><keyname>Yedla</keyname><forenames>Arvind</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna</forenames></author></authors><title>Universality for the Noisy Slepian-Wolf Problem Via Spatial Coupling</title><categories>cs.IT math.IT</categories><comments>5 pages, 8 figures, to appear in ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a noisy Slepian-Wolf problem where two correlated sources are
separately encoded and transmitted over two independent binary memoryless
symmetric channels. Each channel capacity is assumed to be characterized by a
single parameter which is not known at the transmitter. The receiver has
knowledge of both the source correlation and the channel parameters. We call a
system universal if it retains near-capacity performance without channel
knowledge at the transmitter. Kudekar et al. recently showed that terminated
low-density parity-check (LDPC) convolutional codes (a.k.a. spatially-coupled
LDPC ensembles) can have belief-propagation thresholds that approach their
maximum a-posteriori thresholds. This was proven for binary erasure channels
and shown empirically for binary memoryless symmetric channels. They also
conjectured that the principle of spatial coupling is very general and the
phenomenon of threshold saturation applies to a very broad class of graphical
models. In this work, we derive an area theorem for the joint decoder and
empirically show that threshold saturation occurs for this problem. As a
result, we demonstrate near-universal performance for this problem using the
proposed spatially-coupled coding system. A similar result is also discussed
briefly for the 2-user multiple-access channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0016</identifier>
 <datestamp>2012-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0016</id><created>2011-05-31</created><updated>2012-03-20</updated><authors><author><keyname>Roberts</keyname><forenames>Andrew</forenames></author><author><keyname>Tayebi</keyname><forenames>Abdelhamid</forenames></author></authors><title>A New Position Control Strategy for VTOL UAVs using IMU and GPS
  measurements</title><categories>math.OC cs.SY</categories><comments>Submitted to Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new position control strategy for VTOL-UAVs using IMU and GPS
measurements. Since there is no sensor that measures the attitude, our approach
does not rely on the knowledge (or reconstruction) of the system orientation as
usually done in the existing literature. Instead, IMU and GPS measurements are
directly incorporated in the control law. An important feature of the proposed
strategy, is that the accelerometer is used to measure the apparent
acceleration of the vehicle, as opposed to only measuring the gravity vector,
which would otherwise lead to unexpected performance when the vehicle is
accelerating (i.e. not in a hover configuration). Simulation results are
provided to demonstrate the performance of the proposed position control
strategy in the presence of noise and disturbances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0027</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0027</id><created>2011-05-31</created><authors><author><keyname>Thakur</keyname><forenames>Mohit</forenames></author><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>On the geometry of wireless network multicast in 2-D</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a geometric solution to the problem of optimal relay positioning
to maximize the multicast rate for low-SNR networks. The networks we consider,
consist of a single source, multiple receivers and the only intermediate and
locatable node as the relay. We construct network the hypergraph of the system
nodes from the underlying information theoretic model of low-SNR regime that
operates using superposition coding and FDMA in conjunction (which we call the
&quot;achievable hypergraph model&quot;). We make the following contributions. 1) We show
that the problem of optimal relay positioning maximizing the multicast rate can
be completely decoupled from the flow optimization by noticing and exploiting
geometric properties of multicast flow. 2) All the flow maximizing the
multicast rate is sent over at most two paths, in succession. The relay
position is dependent only on one path (out of the two), irrespective of the
number of receiver nodes in the system. Subsequently, we propose simple and
efficient geometric algorithms to compute the optimal relay position. 3)
Finally, we show that in our model at the optimal relay position, the
difference between the maximized multicast rate and the cut-set bound is
minimum. We solve the problem for all (Ps,Pr) pairs of source and relay
transmit powers and the path loss exponent \alpha greater than 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0032</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0032</id><created>2011-05-31</created><authors><author><keyname>Courtade</keyname><forenames>Thomas</forenames></author><author><keyname>Wesel</keyname><forenames>Richard</forenames></author></authors><title>Multiterminal Source Coding with an Entropy-Based Distortion Measure</title><categories>cs.IT math.IT</categories><comments>6 pages, to appear at IEEE International Symposium on Information
  Theory 2011 (ISIT 2011), Saint-Petersburg, Russia</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a class of multiterminal source coding problems,
each subject to distortion constraints computed using a specific,
entropy-based, distortion measure. We provide the achievable rate distortion
region for two cases and, in so doing, we demonstrate a relationship between
the lossy multiterminal source coding problems with our specific distortion
measure and (1) the canonical Slepian-Wolf lossless distributed source coding
network, and (2) the Ahlswede-K\&quot;{o}rner-Wyner source coding with side
information problem in which only one of the sources is recovered losslessly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0041</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0041</id><created>2011-05-31</created><updated>2011-08-02</updated><authors><author><keyname>Steen</keyname><forenames>Matthew</forenames><affiliation>Department of Radiology, Wake Forest School of Medicine, Winston-Salem, North Carolina, USA</affiliation></author><author><keyname>Hayasaka</keyname><forenames>Satoru</forenames><affiliation>Department of Biostatistical Sciences, Wake Forest School of Medicine, Winston-Salem, North Carolina, USA</affiliation></author><author><keyname>Joyce</keyname><forenames>Karen</forenames><affiliation>School of Biomedical Engineering and Sciences, Wake Forest School of Medicine, Winston-Salem, North Carolina, USA</affiliation></author><author><keyname>Laurienti</keyname><forenames>Paul</forenames><affiliation>Department of Radiology, Wake Forest School of Medicine, Winston-Salem, North Carolina, USA</affiliation></author></authors><title>Assessing the consistency of community structure in complex networks</title><categories>cs.SI nlin.AO physics.soc-ph</categories><journal-ref>Physical Review E 84, 016111 (2011)</journal-ref><doi>10.1103/PhysRevE.84.016111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, community structure has emerged as a key component of
complex network analysis. As more data has been collected, researchers have
begun investigating changing community structure across multiple networks.
Several methods exist to analyze changing communities, but most of these are
limited to evolution of a single network over time. In addition, most of the
existing methods are more concerned with change at the community level than at
the level of the individual node. In this paper, we introduce scaled
inclusivity, which is a method to quantify the change in community structure
across networks. Scaled inclusivity evaluates the consistency of the
classiffication of every node in a network independently. In addition, the
method can be applied cross-sectionally as well as longitudinally. In this
paper, we calculate the scaled inclusivity for a set of simulated networks of
United States cities and a set of real networks consisting of teams that play
in the top division of American college football. We found that scaled
inclusivity yields reasonable results for the consistency of individual nodes
in both sets of networks. We propose that scaled inclusivity may provide a
useful way to quantify the change in a network's community structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0057</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0057</id><created>2011-05-31</created><authors><author><keyname>Wang</keyname><forenames>Jiadong</forenames></author><author><keyname>Dolecek</keyname><forenames>Lara</forenames></author><author><keyname>Zhang</keyname><forenames>Zhengya</forenames></author><author><keyname>Wesel</keyname><forenames>Richard</forenames></author></authors><title>Absorbing Set Spectrum Approach for Practical Code Design</title><categories>cs.IT math.IT</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on controlling the absorbing set spectrum for a class of
regular LDPC codes known as separable, circulant-based (SCB) codes. For a
specified circulant matrix, SCB codes all share a common mother matrix,
examples of which are array-based LDPC codes and many common quasi-cyclic
codes. SCB codes retain the standard properties of quasi-cyclic LDPC codes such
as girth, code structure, and compatibility with efficient decoder
implementations. In this paper, we define a cycle consistency matrix (CCM) for
each absorbing set of interest in an SCB LDPC code. For an absorbing set to be
present in an SCB LDPC code, the associated CCM must not be full columnrank.
Our approach selects rows and columns from the SCB mother matrix to
systematically eliminate dominant absorbing sets by forcing the associated CCMs
to be full column-rank. We use the CCM approach to select rows from the SCB
mother matrix to design SCB codes of column weight 5 that avoid all low-weight
absorbing sets (4, 8), (5, 9), and (6, 8). Simulation results demonstrate that
the newly designed code has a steeper error-floor slope and provides at least
one order of magnitude of improvement in the low error rate region as compared
to an elementary array-based code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0061</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0061</id><created>2011-05-31</created><authors><author><keyname>Zhang</keyname><forenames>Zhenliang</forenames></author><author><keyname>Pezeshki</keyname><forenames>Ali</forenames></author><author><keyname>Moran</keyname><forenames>William</forenames></author><author><keyname>Howard</keyname><forenames>Stephen D.</forenames></author><author><keyname>Chong</keyname><forenames>Edwin K. P.</forenames></author></authors><title>Error Probability Bounds for Binary Relay Trees with Crummy Sensors</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the detection error probability associated with balanced binary
relay trees, in which sensor nodes fail with some probability. We consider N
identical and independent crummy sensors, represented by leaf nodes of the
tree. The root of the tree represents the fusion center, which makes the final
decision between two hypotheses. Every other node is a relay node, which fuses
at most two binary messages into one binary message and forwards the new
message to its parent node. We derive tight upper and lower bounds for the
total error probability at the fusion center as functions of N and characterize
how fast the total error probability converges to 0 with respect to N. We show
that the convergence of the total error probability is sub-linear, with the
same decay exponent as that in a balanced binary relay tree without sensor
failures. We also show that the total error probability converges to 0, even if
the individual sensors have total error probabilities that converge to 1/2 and
the failure probabilities that converge to 1, provided that the convergence
rates are sufficiently slow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0070</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0070</id><created>2011-05-31</created><authors><author><keyname>Iyengar</keyname><forenames>Aravind R.</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Wolf</keyname><forenames>Jack K.</forenames></author></authors><title>Modeling and Information Rates for Synchronization Error Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, to be presented at ISIT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new channel model for channels with synchronization errors.
Using this model, we give simple, non-trivial and, in some cases, tight lower
bounds on the capacity for certain synchronization error channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0075</identifier>
 <datestamp>2012-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0075</id><created>2011-05-31</created><updated>2012-11-30</updated><authors><author><keyname>Iyengar</keyname><forenames>Aravind R.</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Urbanke</keyname><forenames>Rudiger L.</forenames></author><author><keyname>Wolf</keyname><forenames>Jack K.</forenames></author></authors><title>Windowed Decoding of Spatially Coupled Codes</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in the IEEE Transactions on Information
  Theory, November 2012. Summary presented at ISIT 2011
  &lt;http://arxiv.org/abs/1106.0075v1&gt;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatially coupled codes have been of interest recently owing to their
superior performance over memoryless binary-input channels. The performance is
good both asymptotically, since the belief propagation thresholds approach
capacity, as well as for finite lengths, since degree-2 variables that result
in high error floors can be completely avoided. However, to realize the
promised good performance, one needs large blocklengths. This in turn implies a
large latency and decoding complexity. For the memoryless binary erasure
channel, we consider the decoding of spatially coupled codes through a windowed
decoder that aims to retain many of the attractive features of belief
propagation, while trying to reduce complexity further. We characterize the
performance of this scheme by defining thresholds on channel erasure rates that
guarantee a target erasure rate. We give analytical lower bounds on these
thresholds and show that the performance approaches that of belief propagation
exponentially fast in the window size. We give numerical results including the
thresholds computed using density evolution and the erasure rate curves for
finite-length spatially coupled codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0086</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0086</id><created>2011-06-01</created><authors><author><keyname>Mimura</keyname><forenames>Kazushi</forenames></author></authors><title>Generating Functional Analysis of Iterative Algorithms for Compressed
  Sensing</title><categories>cs.IT cond-mat.dis-nn math.IT</categories><comments>5 pages, 1 figure, to appear in Proc. of ISIT2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been shown that approximate message passing algorithm is effective in
reconstruction problems for compressed sensing. To evaluate dynamics of such an
algorithm, the state evolution (SE) has been proposed. If an algorithm can
cancel the correlation between the present messages and their past values, SE
can accurately tract its dynamics via a simple one-dimensional map. In this
paper, we focus on dynamics of algorithms which cannot cancel the correlation
and evaluate it by the generating functional analysis (GFA), which allows us to
study the dynamics by an exact way in the large system limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0107</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0107</id><created>2011-06-01</created><authors><author><keyname>Jomy</keyname><forenames>John</forenames></author><author><keyname>Pramod</keyname><forenames>K. V.</forenames></author><author><keyname>Kannan</keyname><forenames>Balakrishnan</forenames></author></authors><title>Handwritten Character Recognition of South Indian Scripts: A Review</title><categories>cs.CV cs.CL</categories><comments>Paper presented on the &quot;National Conference on Indian Language
  Computing&quot;, Kochi, February 19-20, 2011. 6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Handwritten character recognition is always a frontier area of research in
the field of pattern recognition and image processing and there is a large
demand for OCR on hand written documents. Even though, sufficient studies have
performed in foreign scripts like Chinese, Japanese and Arabic characters, only
a very few work can be traced for handwritten character recognition of Indian
scripts especially for the South Indian scripts. This paper provides an
overview of offline handwritten character recognition in South Indian Scripts,
namely Malayalam, Tamil, Kannada and Telungu.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0108</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0108</id><created>2011-06-01</created><updated>2014-11-01</updated><authors><author><keyname>Su</keyname><forenames>Shenghui</forenames></author><author><keyname>Lv</keyname><forenames>Shuwang</forenames></author><author><keyname>Fan</keyname><forenames>Xiubin</forenames></author></authors><title>Asymptotic Granularity Reduction and Its Application</title><categories>cs.CC</categories><comments>13 pages</comments><journal-ref>Theoretical Computer Science, vol. 412, issue 39, Sep. 2011, pp.
  5374-5386</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that the inverse function of y = x with the derivative y' =
1 is x = y, the inverse function of y = c with the derivative y' = 0 is
inexistent, and so on. Hence, on the assumption that the noninvertibility of
the univariate increasing function y = f(x) with x &gt; 0 is in direct proportion
to the growth rate reflected by its derivative, the authors put forward a
method of comparing difficulties in inverting two functions on a continuous or
discrete interval called asymptotic granularity reduction (AGR) which
integrates asymptotic analysis with logarithmic granularities, and is an
extension and a complement to polynomial time (Turing) reduction (PTR). Prove
by AGR that inverting y = x ^ x (mod p) is computationally harder than
inverting y = g ^ x (mod p), and inverting y = g ^ (x ^ n) (mod p) is
computationally equivalent to inverting y = g ^ x (mod p), which are compatible
with the results from PTR. Besides, apply AGR to the comparison of inverting y
= x ^ n (mod p) with y = g ^ x (mod p), y = g ^ (g1 ^ x) (mod p) with y = g ^ x
(mod p), and y = x ^ n + x + 1 (mod p) with y = x ^ n (mod p) in difficulty,
and observe that the results are consistent with existing facts, which further
illustrates that AGR is suitable for comparison of inversion problems in
difficulty. Last, prove by AGR that inverting y = (x ^ n)(g ^ x) (mod p) is
computationally equivalent to inverting y = g ^ x (mod p) when PTR can not be
utilized expediently. AGR with the assumption partitions the complexities of
problems more detailedly, and finds out some new evidence for the security of
cryptosystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0113</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0113</id><created>2011-06-01</created><authors><author><keyname>Izumi</keyname><forenames>Taisuke</forenames></author><author><keyname>Bouzid</keyname><forenames>Zohir</forenames></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Wada</keyname><forenames>Koichi</forenames></author></authors><title>The BG-simulation for Byzantine Mobile Robots</title><categories>cs.DC cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the task solvability of mobile robot systems subject
to Byzantine faults. We first consider the gathering problem, which requires
all robots to meet in finite time at a non-predefined location. It is known
that the solvability of Byzantine gathering strongly depends on a number of
system attributes, such as synchrony, the number of Byzantine robots,
scheduling strategy, obliviousness, orientation of local coordinate systems and
so on. However, the complete characterization of the attributes making
Byzantine gathering solvable still remains open.
  In this paper, we show strong impossibility results of Byzantine gathering.
Namely, we prove that Byzantine gathering is impossible even if we assume one
Byzantine fault, an atomic execution system, the n-bounded centralized
scheduler, non-oblivious robots, instantaneous movements and a common
orientation of local coordinate systems (where n denote the number of correct
robots). Those hypotheses are much weaker than used in previous work, inducing
a much stronger impossibility result.
  At the core of our impossibility result is a reduction from the distributed
consensus problem in asynchronous shared-memory systems. In more details, we
newly construct a generic reduction scheme based on the distributed
BG-simulation. Interestingly, because of its versatility, we can easily extend
our impossibility result for general pattern formation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0114</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0114</id><created>2011-06-01</created><authors><author><keyname>Carbone</keyname><forenames>Vincenzo</forenames></author></authors><title>Fractional counting of authorship to quantify scientific research output</title><categories>physics.soc-ph cs.DL stat.AP</categories><comments>Submitted to Europhysics Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of counting co-authorhip in order to quantify the
impact and relevance of scientific research output through normalized
\textit{h-index} and \textit{g-index}. We use the papers whose authors belong
to a subset of full professors of the Italian Settore Scientifico Disciplinare
(SSD) FIS01 - Experimental Physics. In this SSD two populations, characterized
by the number of co-authors of each paper, are roughly present. The total
number of citations for each individuals, as well as their h-index and g-index,
strongly depends on the average number of co-authors. We show that, in order to
remove the dependence of the various indices on the two populations, the best
way to define a fractional counting of autorship is to divide the number of
citations received by each paper by the square root of the number of
co-authors. This allows us to obtain some information which can be used for a
better understanding of the scientific knowledge made through the process of
writing and publishing papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0117</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0117</id><created>2011-06-01</created><authors><author><keyname>Razaghi</keyname><forenames>Peyman</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>A Nonlinear Approach to Interference Alignment</title><categories>cs.IT math.IT</categories><comments>To be presented at ISIT 2011</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Cadambe and Jafar (CJ) alignment strategy for the K-user scalar
frequency-selective fading Gaussian channel, with encoding over blocks of 2n+1
random channel coefficients (subcarriers) is considered. The linear
zero-forcing (LZF) strategy is compared with a novel approach based on lattice
alignment and lattice decoding (LD). Despite both LZF and LD achieve the same
degrees of freedom, it is shown that LD can achieve very significant
improvements in terms of error rates at practical SNRs with respect to the
conventional LZF proposed in the literature. We also show that these gains are
realized provided that channel gains are controlled to be near constant, for
example, by means of power control and opportunistic carrier and user selection
strategies. In presence of relatively-small variations in the normalized
channel coefficient amplitudes, CJ alignment strategy yields very disappointing
results at finite SNRs, and the gain of LD over ZLF significantly reduces. In
light of these results, the practical applicability of CJ alignment scheme
remains questionable, in particular for Rayleigh fading channels, where channel
inversion power control yields to unbounded average transmit power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0118</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0118</id><created>2011-06-01</created><updated>2011-06-02</updated><authors><author><keyname>Merelo</keyname><forenames>Juan-J.</forenames><affiliation>editors</affiliation></author><author><keyname>Garc&#xed;a-Arenas</keyname><forenames>Maribel</forenames><affiliation>editors</affiliation></author><author><keyname>Laredo</keyname><forenames>Juan-Luis J.</forenames><affiliation>editors</affiliation></author><author><keyname>de la Vega</keyname><forenames>Francisco Fern&#xe1;ndez</forenames><affiliation>editors</affiliation></author></authors><title>1st International Workshop on Distributed Evolutionary Computation in
  Informal Environments</title><categories>cs.NE cs.DC cs.ET cs.NI</categories><comments>Five papers, workshop took place together with CEC 2011 in New
  Orleans (LA, USA). http://geneura.ugr.es/~iwdecie</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Online conference proceedings for the IWDECIE workshop, taking place in New
Orleans on June 5th, 2011. The workshop focuses on non-conventional
implementations of bioinspired algorithms and its conceptual implications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0120</identifier>
 <datestamp>2014-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0120</id><created>2011-06-01</created><updated>2014-05-16</updated><authors><author><keyname>Coja-Oghlan</keyname><forenames>Amin</forenames></author><author><keyname>Frieze</keyname><forenames>Alan</forenames></author></authors><title>Analyzing Walksat on random formulas</title><categories>math.CO cs.DM</categories><msc-class>68R01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let F be a uniformly distributed random k-SAT formula with n variables and m
clauses. We prove that the Walksat algorithm from Papadimitriou (FOCS
1991)/Schoning (FOCS 1999) finds a satisfying assignment of F in polynomial
time w.h.p. if m/n&lt;\rho 2^k/k for a certain constant \rho&gt;0. This is an
improvement by a factor of $\Theta(k)$ over the best previous analysis of
Walksat from Coja-Oghlan, Feige, Frieze, Krivelevich, Vilenchik (SODA 2009).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0141</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0141</id><created>2011-06-01</created><updated>2012-11-22</updated><authors><author><keyname>Wild</keyname><forenames>Marcel</forenames></author></authors><title>Counting or producing all fixed cardinality transversals</title><categories>cs.DM math.CO</categories><comments>This improves upon the previous version, and is to appear (with
  identical content) in Algorithmica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorith to count, or alternatively generate, all k-element transversals
of a set system is presented and compared with three known methods. For special
cases it works in output-linear time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0151</identifier>
 <datestamp>2012-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0151</id><created>2011-06-01</created><updated>2012-09-23</updated><authors><author><keyname>Zaghloul</keyname><forenames>Mofreh R.</forenames></author><author><keyname>Ali</keyname><forenames>Ahmed N.</forenames></author></authors><title>Algorithm 916: computing the Faddeyeva and Voigt functions</title><categories>cs.NA math-ph math.MP</categories><comments>27 pages, 5 tables, 9 figurs</comments><journal-ref>ACM Transactions on Mathematical Software, Vol 38, No. 2, Article
  15(2011),22 pages</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a MATLAB function for the numerical evaluation of the Faddeyeva
function w(z). The function is based on a newly developed accurate algorithm.
In addition to its higher accuracy, the software provides a flexible accuracy
vs efficiency trade-off through a controlling parameter that may be used to
reduce accuracy and computational time and vice versa. Verification of the
flexibility, reliability and superior accuracy of the algorithm is provided
through comparison with standard algorithms available in other libraries and
software packages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0159</identifier>
 <datestamp>2013-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0159</id><created>2011-06-01</created><updated>2013-04-01</updated><authors><author><keyname>Szydlarski</keyname><forenames>Mikolaj</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Esterie</keyname><forenames>Pierre</forenames><affiliation>LRI</affiliation></author><author><keyname>Falcou</keyname><forenames>Joel</forenames><affiliation>LRI</affiliation></author><author><keyname>Grigori</keyname><forenames>Laura</forenames><affiliation>INRIA Saclay - Ile de France</affiliation></author><author><keyname>Stompor</keyname><forenames>R.</forenames><affiliation>APC</affiliation></author></authors><title>Parallel Spherical Harmonic Transforms on heterogeneous architectures
  (GPUs/multi-core CPUs)</title><categories>cs.DC astro-ph.CO physics.ao-ph physics.comp-ph physics.geo-ph</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spherical Harmonic Transforms (SHT) are at the heart of many scientific and
practical applications ranging from climate modelling to cosmological
observations. In many of these areas new, cutting-edge science goals have been
recently proposed requiring simulations and analyses of experimental or
observational data at very high resolutions and of unprecedented volumes. Both
these aspects pose formidable challenge for the currently existing
implementations of the transforms.
  This paper describes parallel algorithms for computing SHT with two variants
of intra-node parallelism appropriate for novel supercomputer architectures,
multi-core processors and Graphic Processing Units (GPU). It also discusses
their performance, alone and embedded within a top-level, MPI-based
parallelisation layer ported from the S2HAT library, in terms of their
accuracy, overall efficiency and scalability. We show that our inverse SHT run
on GeForce 400 Series GPUs equipped with latest CUDA architecture (&quot;Fermi&quot;)
outperforms the state of the art implementation for a multi-core processor
executed on a current Intel Core i7-2600K. Furthermore, we show that an
MPI/CUDA version of the inverse transform run on a cluster of 128 Nvidia Tesla
S1070 is as much as 3 times faster than the hybrid MPI/OpenMP version executed
on the same number of quad-core processors Intel Nahalem for problem sizes
motivated by our target applications. Performance of the direct transforms is
however found to be at the best comparable in these cases. We discuss in detail
the algorithmic solutions devised for major steps involved in the transforms
calculation, emphasising those with a major impact on their overall
performance, and elucidates the sources of the dichotomy between the direct and
the inverse operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0171</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0171</id><created>2011-05-31</created><authors><author><keyname>de Paiva</keyname><forenames>Gilberto</forenames></author></authors><title>Proposal of Pattern Recognition as a necessary and sufficient Principle
  to Cognitive Science</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the prevalence of the Computational Theory of Mind and the
Connectionist Model, the establishing of the key principles of the Cognitive
Science are still controversy and inconclusive. This paper proposes the concept
of Pattern Recognition as Necessary and Sufficient Principle for a general
cognitive science modeling, in a very ambitious scientific proposal. A formal
physical definition of the pattern recognition concept is also proposed to
solve many key conceptual gaps on the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0178</identifier>
 <datestamp>2012-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0178</id><created>2011-06-01</created><updated>2012-08-23</updated><authors><author><keyname>Yuan</keyname><forenames>Xiaojun</forenames></author><author><keyname>Ping</keyname><forenames>Li</forenames></author><author><keyname>Xu</keyname><forenames>Chongbin</forenames></author><author><keyname>Kavcic</keyname><forenames>Aleksandar</forenames></author></authors><title>Achievable Rates of MIMO Systems with Linear Precoding and Iterative
  LMMSE Detection</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish area theorems for iterative detection over coded linear systems
(including multiple-input multipleoutput (MIMO) channels,
inter-symbol-interference (ISI) channels, and orthogonal frequency-division
multiplexing (OFDM) systems). We propose a linear precoding technique that
asymptotically ensures the Gaussianness of the messages passed in iterative
detection, as the transmission block length tends to infinity. We show that the
proposed linear precoding scheme with iterative linear minimum mean-square
error (LMMSE) detection is potentially information lossless, under various
assumptions on the availability of channel state information at the transmitter
(CSIT). Numerical results are provided to verify our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0190</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0190</id><created>2011-06-01</created><authors><author><keyname>Eiben</keyname><forenames>A. E.</forenames></author><author><keyname>Ferreira</keyname><forenames>N.</forenames></author><author><keyname>Schut</keyname><forenames>M.</forenames></author><author><keyname>Kernbach</keyname><forenames>S.</forenames></author></authors><title>Evolution of Things</title><categories>cs.NE</categories><comments>Paper 5 for the First International Workshop of Distributed
  Evolutionary computation in Informal Environments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolution is one of the major omnipresent powers in the universe that has
been studied for about two centuries. Recent scientific and technical
developments make it possible to make the transition from passively
understanding to actively mastering evolution. As of today, the only area where
human experimenters can design and manipulate evolutionary processes in full is
that of Evolutionary Computing, where evolutionary processes are carried out in
a digital space, inside computers, in simulation. We argue that in the near
future it will be possible to move evolutionary computing outside such
imaginary spaces and make it physically embodied. In other words, we envision
the &quot;Evolution of Things&quot;, rather than just the evolution of code, leading to a
new field of Embodied Artificial Evolution (EAE). The main objective of the
present paper is to offer an umbrella term and vision in order to aid the
development of this high potential research area. To this end, we introduce the
notion of EAE, discuss a few examples and applications, and elaborate on the
expected benefits as well as the grand challenges this developing field will
have to address.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0216</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0216</id><created>2011-06-01</created><updated>2012-07-11</updated><authors><author><keyname>Gamkrelidze</keyname><forenames>Alexander</forenames></author></authors><title>Algorithms for Low-Dimensional Topology</title><categories>cs.CG</categories><comments>17 pages, 21 figures. arXiv admin note: text overlap with
  arXiv:math/9810026, arXiv:math/0501040 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we re-introduce the so called &quot;Arkaden-Faden-Lage&quot; (AFL for
short) representation of knots in 3 dimensional space introduced by Kurt
Reidemeister and show how it can be used to develop efficient algorithms to
compute some important topological knot structures. In particular, we introduce
an efficient algorithm to calculate holonomic representation of knots
introduced by V. Vassiliev and give the main ideas how to use the AFL
representations of knots to compute the Kontsevich Integral.
  The methods introduced here are to our knowledge novel and can open new
perspectives in the development of fast algorithms in low dimensional topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0217</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0217</id><created>2011-06-01</created><authors><author><keyname>Schaer</keyname><forenames>Philipp</forenames></author></authors><title>Using Lotkaian Informetrics for Ranking in Digital Libraries</title><categories>cs.IR cs.DL</categories><comments>4 pages; Proceedings of the ASIS&amp;T European Workshop 2011 (AEW 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is to propose the use of models, theories and laws
in bibliometrics and scientometrics to enhance information retrieval processes,
especially ranking. A common pattern in many man-made data sets is Lotka's Law
which follows the well-known power-law distributions. These informetric
distributions can be used to give an alternative order to large and scattered
result sets and can be applied as a new ranking mechanism. The
polyrepresentation of information in Digital Library systems is used to enhance
the retrieval quality, to overcome the drawbacks of the typical term-based
ranking approaches and to enable users to explore retrieved document sets from
a different perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0218</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0218</id><created>2011-06-01</created><authors><author><keyname>Birnbaum</keyname><forenames>E.</forenames></author><author><keyname>Lozinskii</keyname><forenames>E. L.</forenames></author></authors><title>The Good Old Davis-Putnam Procedure Helps Counting Models</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 10, pages
  457-477, 1999</journal-ref><doi>10.1613/jair.601</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As was shown recently, many important AI problems require counting the number
of models of propositional formulas. The problem of counting models of such
formulas is, according to present knowledge, computationally intractable in a
worst case. Based on the Davis-Putnam procedure, we present an algorithm, CDP,
that computes the exact number of models of a propositional CNF or DNF formula
F. Let m and n be the number of clauses and variables of F, respectively, and
let p denote the probability that a literal l of F occurs in a clause C of F,
then the average running time of CDP is shown to be O(nm^d), where
d=-1/log(1-p). The practical performance of CDP has been estimated in a series
of experiments on a wide variety of CNF formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0219</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0219</id><created>2011-06-01</created><authors><author><keyname>Brodley</keyname><forenames>C. E.</forenames></author><author><keyname>Friedl</keyname><forenames>M. A.</forenames></author></authors><title>Identifying Mislabeled Training Data</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  131-167, 1999</journal-ref><doi>10.1613/jair.606</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new approach to identifying and eliminating mislabeled
training instances for supervised learning. The goal of this approach is to
improve classification accuracies produced by learning algorithms by improving
the quality of the training data. Our approach uses a set of learning
algorithms to create classifiers that serve as noise filters for the training
data. We evaluate single algorithm, majority vote and consensus filters on five
datasets that are prone to labeling errors. Our experiments illustrate that
filtering significantly improves classification accuracy for noise levels up to
30 percent. An analytical and empirical evaluation of the precision of our
approach shows that consensus filters are conservative at throwing away good
data at the expense of retaining bad data and that majority filters are better
at detecting bad data at the expense of throwing away good data. This suggests
that for situations in which there is a paucity of data, consensus filters are
preferable, whereas majority vote filters are preferable for situations with an
abundance of data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0220</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0220</id><created>2011-06-01</created><authors><author><keyname>Argamon-Engelson</keyname><forenames>S.</forenames></author><author><keyname>Dagan</keyname><forenames>I.</forenames></author></authors><title>Committee-Based Sample Selection for Probabilistic Classifiers</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  335-360, 1999</journal-ref><doi>10.1613/jair.612</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many real-world learning tasks, it is expensive to acquire a sufficient
number of labeled examples for training. This paper investigates methods for
reducing annotation cost by `sample selection'. In this approach, during
training the learning program examines many unlabeled examples and selects for
labeling only those that are most informative at each stage. This avoids
redundantly labeling examples that contribute little new information. Our work
follows on previous research on Query By Committee, extending the
committee-based paradigm to the context of probabilistic classification. We
describe a family of empirical methods for committee-based sample selection in
probabilistic classification models, which evaluate the informativeness of an
example by measuring the degree of disagreement between several model variants.
These variants (the committee) are drawn randomly from a probability
distribution conditioned by the training set labeled so far. The method was
applied to the real-world natural language processing task of stochastic
part-of-speech tagging. We find that all variants of the method achieve a
significant reduction in annotation cost, although their computational
efficiency differs. In particular, the simplest variant, a two member committee
with no parameters to tune, gives excellent results. We also show that sample
selection yields a significant reduction in the size of the model used by the
tagger.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0221</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0221</id><created>2011-06-01</created><authors><author><keyname>Grefenstette</keyname><forenames>J. J.</forenames></author><author><keyname>Moriarty</keyname><forenames>D. E.</forenames></author><author><keyname>Schultz</keyname><forenames>A. C.</forenames></author></authors><title>Evolutionary Algorithms for Reinforcement Learning</title><categories>cs.LG cs.AI cs.NE</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  241-276, 1999</journal-ref><doi>10.1613/jair.613</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are two distinct approaches to solving reinforcement learning problems,
namely, searching in value function space and searching in policy space.
Temporal difference methods and evolutionary algorithms are well-known examples
of these approaches. Kaelbling, Littman and Moore recently provided an
informative survey of temporal difference methods. This article focuses on the
application of evolutionary algorithms to the reinforcement learning problem,
emphasizing alternative policy representations, credit assignment methods, and
problem-specific genetic operators. Strengths and weaknesses of the
evolutionary approach to reinforcement learning are presented, along with a
survey of representative applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0222</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0222</id><created>2011-06-01</created><authors><author><keyname>Burgard</keyname><forenames>W.</forenames></author><author><keyname>Fox</keyname><forenames>D.</forenames></author><author><keyname>Thrun</keyname><forenames>S.</forenames></author></authors><title>Markov Localization for Mobile Robots in Dynamic Environments</title><categories>cs.AI cs.RO</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  391-427, 1999</journal-ref><doi>10.1613/jair.616</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Localization, that is the estimation of a robot's location from sensor data,
is a fundamental problem in mobile robotics. This papers presents a version of
Markov localization which provides accurate position estimates and which is
tailored towards dynamic environments. The key idea of Markov localization is
to maintain a probability density over the space of all locations of a robot in
its environment. Our approach represents this space metrically, using a
fine-grained grid to approximate densities. It is able to globally localize the
robot from scratch and to recover from localization failures. It is robust to
approximate models of the environment (such as occupancy grid maps) and noisy
sensors (such as ultrasound sensors). Our approach also includes a filtering
technique which allows a mobile robot to reliably estimate its position even in
densely populated environments in which crowds of people block the robot's
sensors for extended periods of time. The method described here has been
implemented and tested in several real-world applications of mobile robots,
including the deployments of two mobile robots as interactive museum
tour-guides.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0223</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0223</id><created>2011-06-01</created><authors><author><keyname>Akkermans</keyname><forenames>H.</forenames></author><author><keyname>Ygge</keyname><forenames>F.</forenames></author></authors><title>Decentralized Markets versus Central Control: A Comparative Study</title><categories>cs.MA cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  301-333, 1999</journal-ref><doi>10.1613/jair.627</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-Agent Systems (MAS) promise to offer solutions to problems where
established, older paradigms fall short. In order to validate such claims that
are repeatedly made in software agent publications, empirical in-depth studies
of advantages and weaknesses of multi-agent solutions versus conventional ones
in practical applications are needed. Climate control in large buildings is one
application area where multi-agent systems, and market-oriented programming in
particular, have been reported to be very successful, although central control
solutions are still the standard practice. We have therefore constructed and
implemented a variety of market designs for this problem, as well as different
standard control engineering solutions. This article gives a detailed analysis
and comparison, so as to learn about differences between standard versus agent
approaches, and yielding new insights about benefits and limitations of
computational markets. An important outcome is that &quot;local information plus
market communication produces global control&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0224</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0224</id><created>2011-06-01</created><authors><author><keyname>Rosati</keyname><forenames>R.</forenames></author></authors><title>Reasoning about Minimal Belief and Negation as Failure</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  277-300, 1999</journal-ref><doi>10.1613/jair.637</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of reasoning in the propositional fragment of
MBNF, the logic of minimal belief and negation as failure introduced by
Lifschitz, which can be considered as a unifying framework for several
nonmonotonic formalisms, including default logic, autoepistemic logic,
circumscription, epistemic queries, and logic programming. We characterize the
complexity and provide algorithms for reasoning in propositional MBNF. In
particular, we show that entailment in propositional MBNF lies at the third
level of the polynomial hierarchy, hence it is harder than reasoning in all the
above mentioned propositional formalisms for nonmonotonic reasoning. We also
prove the exact correspondence between negation as failure in MBNF and negative
introspection in Moore's autoepistemic logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0225</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0225</id><created>2011-06-01</created><authors><author><keyname>Bar-Yehuda</keyname><forenames>R.</forenames></author><author><keyname>Becker</keyname><forenames>A.</forenames></author><author><keyname>Geiger</keyname><forenames>D.</forenames></author></authors><title>Randomized Algorithms for the Loop Cutset Problem</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  219-234, 2000</journal-ref><doi>10.1613/jair.638</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to find a minimum weight loop cutset in a Bayesian network with
high probability. Finding such a loop cutset is the first step in the method of
conditioning for inference. Our randomized algorithm for finding a loop cutset
outputs a minimum loop cutset after O(c 6^k kn) steps with probability at least
1 - (1 - 1/(6^k))^c6^k, where c &gt; 1 is a constant specified by the user, k is
the minimal size of a minimum weight loop cutset, and n is the number of
vertices. We also show empirically that a variant of this algorithm often finds
a loop cutset that is closer to the minimum weight loop cutset than the ones
found by the best deterministic algorithms known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0229</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0229</id><created>2011-06-01</created><authors><author><keyname>Jensen</keyname><forenames>R. M.</forenames></author><author><keyname>Veloso</keyname><forenames>M. M.</forenames></author></authors><title>OBDD-based Universal Planning for Synchronized Agents in
  Non-Deterministic Domains</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 13, pages
  189-226, 2000</journal-ref><doi>10.1613/jair.649</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently model checking representation and search techniques were shown to be
efficiently applicable to planning, in particular to non-deterministic
planning. Such planning approaches use Ordered Binary Decision Diagrams (OBDDs)
to encode a planning domain as a non-deterministic finite automaton and then
apply fast algorithms from model checking to search for a solution. OBDDs can
effectively scale and can provide universal plans for complex planning domains.
We are particularly interested in addressing the complexities arising in
non-deterministic, multi-agent domains. In this article, we present UMOP, a new
universal OBDD-based planning framework for non-deterministic, multi-agent
domains. We introduce a new planning domain description language, NADL, to
specify non-deterministic, multi-agent domains. The language contributes the
explicit definition of controllable agents and uncontrollable environment
agents. We describe the syntax and semantics of NADL and show how to build an
efficient OBDD-based representation of an NADL description. The UMOP planning
system uses NADL and different OBDD-based universal planning algorithms. It
includes the previously developed strong and strong cyclic planning algorithms.
In addition, we introduce our new optimistic planning algorithm that relaxes
optimality guarantees and generates plausible universal plans in some domains
where no strong nor strong cyclic solution exists. We present empirical results
applying UMOP to domains ranging from deterministic and single-agent with no
environment actions to non-deterministic and multi-agent with complex
environment actions. UMOP is shown to be a rich and efficient planning system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0230</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0230</id><created>2011-06-01</created><authors><author><keyname>Kambhampati</keyname><forenames>S.</forenames></author></authors><title>Planning Graph as a (Dynamic) CSP: Exploiting EBL, DDB and other CSP
  Search Techniques in Graphplan</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  1-34, 2000</journal-ref><doi>10.1613/jair.655</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews the connections between Graphplan's planning-graph and the
dynamic constraint satisfaction problem and motivates the need for adapting CSP
search techniques to the Graphplan algorithm. It then describes how explanation
based learning, dependency directed backtracking, dynamic variable ordering,
forward checking, sticky values and random-restart search strategies can be
adapted to Graphplan. Empirical results are provided to demonstrate that these
augmentations improve Graphplan's performance significantly (up to 1000x
speedups) on several benchmark problems. Special attention is paid to the
explanation-based learning and dependency directed backtracking techniques as
they are empirically found to be most useful in improving the performance of
Graphplan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0233</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0233</id><created>2011-06-01</created><authors><author><keyname>Cadoli</keyname><forenames>M.</forenames></author><author><keyname>Donini</keyname><forenames>F. M.</forenames></author><author><keyname>Liberatore</keyname><forenames>P.</forenames></author><author><keyname>Schaerf</keyname><forenames>M.</forenames></author></authors><title>Space Efficiency of Propositional Knowledge Representation Formalisms</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 13, pages
  1-31, 2000</journal-ref><doi>10.1613/jair.664</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the space efficiency of a Propositional Knowledge
Representation (PKR) formalism. Intuitively, the space efficiency of a
formalism F in representing a certain piece of knowledge A, is the size of the
shortest formula of F that represents A. In this paper we assume that knowledge
is either a set of propositional interpretations (models) or a set of
propositional formulae (theorems). We provide a formal way of talking about the
relative ability of PKR formalisms to compactly represent a set of models or a
set of theorems. We introduce two new compactness measures, the corresponding
classes, and show that the relative space efficiency of a PKR formalism in
representing models/theorems is directly related to such classes. In
particular, we consider formalisms for nonmonotonic reasoning, such as
circumscription and default logic, as well as belief revision operators and the
stable model semantics for logic programs with negation. One interesting result
is that formalisms with the same time complexity do not necessarily belong to
the same space efficiency class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0234</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0234</id><created>2011-06-01</created><authors><author><keyname>Hauskrecht</keyname><forenames>M.</forenames></author></authors><title>Value-Function Approximations for Partially Observable Markov Decision
  Processes</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 13, pages
  33-94, 2000</journal-ref><doi>10.1613/jair.678</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partially observable Markov decision processes (POMDPs) provide an elegant
mathematical framework for modeling complex decision and planning problems in
stochastic domains in which states of the system are observable only
indirectly, via a set of imperfect or noisy observations. The modeling
advantage of POMDPs, however, comes at a price -- exact methods for solving
them are computationally very expensive and thus applicable in practice only to
very simple problems. We focus on efficient approximation (heuristic) methods
that attempt to alleviate the computational problem and trade off accuracy for
speed. We have two objectives here. First, we survey various approximation
methods, analyze their properties and relations and provide some new insights
into their differences. Second, we present a number of new approximation
methods and novel refinements of existing techniques. The theoretical results
are supported by experiments on a problem from the agent navigation domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0235</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0235</id><created>2011-06-01</created><authors><author><keyname>Kaminka</keyname><forenames>G. A.</forenames></author><author><keyname>Tambe</keyname><forenames>M.</forenames></author></authors><title>Robust Agent Teams via Socially-Attentive Monitoring</title><categories>cs.MA cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  105-147, 2000</journal-ref><doi>10.1613/jair.682</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agents in dynamic multi-agent environments must monitor their peers to
execute individual and group plans. A key open question is how much monitoring
of other agents' states is required to be effective: The Monitoring Selectivity
Problem. We investigate this question in the context of detecting failures in
teams of cooperating agents, via Socially-Attentive Monitoring, which focuses
on monitoring for failures in the social relationships between the agents. We
empirically and analytically explore a family of socially-attentive teamwork
monitoring algorithms in two dynamic, complex, multi-agent domains, under
varying conditions of task distribution and uncertainty. We show that a
centralized scheme using a complex algorithm trades correctness for
completeness and requires monitoring all teammates. In contrast, a simple
distributed teamwork monitoring algorithm results in correct and complete
detection of teamwork failures, despite relying on limited, uncertain
knowledge, and monitoring only key agents in a team. In addition, we report on
the design of a socially-attentive monitoring system and demonstrate its
generality in monitoring several coordination relationships, diagnosing
detected failures, and both on-line and off-line applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0237</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0237</id><created>2011-06-01</created><authors><author><keyname>Neal</keyname><forenames>R. M.</forenames></author></authors><title>On Deducing Conditional Independence from d-Separation in Causal Graphs
  with Feedback (Research Note)</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  87-91, 2000</journal-ref><doi>10.1613/jair.689</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pearl and Dechter (1996) claimed that the d-separation criterion for
conditional independence in acyclic causal networks also applies to networks of
discrete variables that have feedback cycles, provided that the variables of
the system are uniquely determined by the random disturbances. I show by
example that this is not true in general. Some condition stronger than
uniqueness is needed, such as the existence of a causal dynamics guaranteed to
lead to the unique solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0238</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0238</id><created>2011-06-01</created><authors><author><keyname>Borgida</keyname><forenames>A.</forenames></author><author><keyname>Kusters</keyname><forenames>R.</forenames></author></authors><title>What's in an Attribute? Consequences for the Least Common Subsumer</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  167-203, 2001</journal-ref><doi>10.1613/jair.702</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functional relationships between objects, called `attributes', are of
considerable importance in knowledge representation languages, including
Description Logics (DLs). A study of the literature indicates that papers have
made, often implicitly, different assumptions about the nature of attributes:
whether they are always required to have a value, or whether they can be
partial functions. The work presented here is the first explicit study of this
difference for subclasses of the CLASSIC DL, involving the same-as concept
constructor. It is shown that although determining subsumption between concept
descriptions has the same complexity (though requiring different algorithms),
the story is different in the case of determining the least common subsumer
(lcs). For attributes interpreted as partial functions, the lcs exists and can
be computed relatively easily; even in this case our results correct and extend
three previous papers about the lcs of DLs. In the case where attributes must
have a value, the lcs may not exist, and even if it exists it may be of
exponential size. Interestingly, it is possible to decide in polynomial time if
the lcs exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0239</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0239</id><created>2011-06-01</created><authors><author><keyname>Tobies</keyname><forenames>S.</forenames></author></authors><title>The Complexity of Reasoning with Cardinality Restrictions and Nominals
  in Expressive Description Logics</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  199-217, 2000</journal-ref><doi>10.1613/jair.705</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of the combination of the Description Logics ALCQ and
ALCQI with a terminological formalism based on cardinality restrictions on
concepts. These combinations can naturally be embedded into C^2, the two
variable fragment of predicate logic with counting quantifiers, which yields
decidability in NExpTime. We show that this approach leads to an optimal
solution for ALCQI, as ALCQI with cardinality restrictions has the same
complexity as C^2 (NExpTime-complete). In contrast, we show that for ALCQ, the
problem can be solved in ExpTime. This result is obtained by a reduction of
reasoning with cardinality restrictions to reasoning with the (in general
weaker) terminological formalism of general axioms for ALCQ extended with
nominals. Using the same reduction, we show that, for the extension of ALCQI
with nominals, reasoning with general axioms is a NExpTime-complete problem.
Finally, we sharpen this result and show that pure concept satisfiability for
ALCQI with nominals is NExpTime-complete. Without nominals, this problem is
known to be PSpace-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0240</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0240</id><created>2011-06-01</created><authors><author><keyname>Gent</keyname><forenames>I. P.</forenames></author><author><keyname>Singer</keyname><forenames>J.</forenames></author><author><keyname>Smaill</keyname><forenames>A.</forenames></author></authors><title>Backbone Fragility and the Local Search Cost Peak</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  235-270, 2000</journal-ref><doi>10.1613/jair.711</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The local search algorithm WSat is one of the most successful algorithms for
solving the satisfiability (SAT) problem. It is notably effective at solving
hard Random 3-SAT instances near the so-called `satisfiability threshold', but
still shows a peak in search cost near the threshold and large variations in
cost over different instances. We make a number of significant contributions to
the analysis of WSat on high-cost random instances, using the
recently-introduced concept of the backbone of a SAT instance. The backbone is
the set of literals which are entailed by an instance. We find that the number
of solutions predicts the cost well for small-backbone instances but is much
less relevant for the large-backbone instances which appear near the threshold
and dominate in the overconstrained region. We show a very strong correlation
between search cost and the Hamming distance to the nearest solution early in
WSat's search. This pattern leads us to introduce a measure of the backbone
fragility of an instance, which indicates how persistent the backbone is as
clauses are removed. We propose that high-cost random instances for local
search are those with very large backbones which are also backbone-fragile. We
suggest that the decay in cost beyond the satisfiability threshold is due to
increasing backbone robustness (the opposite of backbone fragility). Our
hypothesis makes three correct predictions. First, that the backbone robustness
of an instance is negatively correlated with the local search cost when other
factors are controlled for. Second, that backbone-minimal instances (which are
3-SAT instances altered so as to be more backbone-fragile) are unusually hard
for WSat. Third, that the clauses most often unsatisfied during search are
those whose deletion has the most effect on the backbone. In understanding the
pathologies of local search methods, we hope to contribute to the development
of new and better techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0241</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0241</id><created>2011-06-01</created><authors><author><keyname>Walker</keyname><forenames>M. A.</forenames></author></authors><title>An Application of Reinforcement Learning to Dialogue Strategy Selection
  in a Spoken Dialogue System for Email</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  387-416, 2000</journal-ref><doi>10.1613/jair.713</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes a novel method by which a spoken dialogue system can
learn to choose an optimal dialogue strategy from its experience interacting
with human users. The method is based on a combination of reinforcement
learning and performance modeling of spoken dialogue systems. The reinforcement
learning component applies Q-learning (Watkins, 1989), while the performance
modeling component applies the PARADISE evaluation framework (Walker et al.,
1997) to learn the performance function (reward) used in reinforcement
learning. We illustrate the method with a spoken dialogue system named ELVIS
(EmaiL Voice Interactive System), that supports access to email over the phone.
We conduct a set of experiments for training an optimal dialogue strategy on a
corpus of 219 dialogues in which human users interact with ELVIS over the
phone. We then test that strategy on a corpus of 18 dialogues. We show that
ELVIS can learn to optimize its strategy selection for agent initiative, for
reading messages, and for summarizing email folders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0242</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0242</id><created>2011-06-01</created><authors><author><keyname>Goldsmith</keyname><forenames>J.</forenames></author><author><keyname>Lusena</keyname><forenames>C.</forenames></author><author><keyname>Mundhenk</keyname><forenames>M.</forenames></author></authors><title>Nonapproximability Results for Partially Observable Markov Decision
  Processes</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  83-103, 2001</journal-ref><doi>10.1613/jair.714</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for several variations of partially observable Markov decision
processes, polynomial-time algorithms for finding control policies are unlikely
to or simply don't have guarantees of finding policies within a constant factor
or a constant summand of optimal. Here &quot;unlikely&quot; means &quot;unless some complexity
classes collapse,&quot; where the collapses considered are P=NP, P=PSPACE, or P=EXP.
Until or unless these collapses are shown to hold, any control-policy designer
must choose between such performance guarantees and efficient computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0243</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0243</id><created>2011-06-01</created><authors><author><keyname>Hoffmann</keyname><forenames>J.</forenames></author><author><keyname>Koehler</keyname><forenames>J.</forenames></author></authors><title>On Reasonable and Forced Goal Orderings and their Use in an
  Agenda-Driven Planning Algorithm</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  338-386, 2000</journal-ref><doi>10.1613/jair.715</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper addresses the problem of computing goal orderings, which is one of
the longstanding issues in AI planning. It makes two new contributions. First,
it formally defines and discusses two different goal orderings, which are
called the reasonable and the forced ordering. Both orderings are defined for
simple STRIPS operators as well as for more complex ADL operators supporting
negation and conditional effects. The complexity of these orderings is
investigated and their practical relevance is discussed. Secondly, two
different methods to compute reasonable goal orderings are developed. One of
them is based on planning graphs, while the other investigates the set of
actions directly. Finally, it is shown how the ordering relations, which have
been derived for a given set of goals G, can be used to compute a so-called
goal agenda that divides G into an ordered set of subgoals. Any planner can
then, in principle, use the goal agenda to plan for increasing sets of
subgoals. This can lead to an exponential complexity reduction, as the solution
to a complex planning problem is found by solving easier subproblems. Since
only a polynomial overhead is caused by the goal agenda computation, a
potential exists to dramatically speed up planning algorithms as we demonstrate
in the empirical evaluation, where we use this method in the IPP planner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0244</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0244</id><created>2011-06-01</created><authors><author><keyname>Gordon</keyname><forenames>D. F.</forenames></author></authors><title>Asimovian Adaptive Agents</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 13, pages
  95-153, 2000</journal-ref><doi>10.1613/jair.720</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this research is to develop agents that are adaptive and
predictable and timely. At first blush, these three requirements seem
contradictory. For example, adaptation risks introducing undesirable side
effects, thereby making agents' behavior less predictable. Furthermore,
although formal verification can assist in ensuring behavioral predictability,
it is known to be time-consuming. Our solution to the challenge of satisfying
all three requirements is the following. Agents have finite-state automaton
plans, which are adapted online via evolutionary learning (perturbation)
operators. To ensure that critical behavioral constraints are always satisfied,
agents' plans are first formally verified. They are then reverified after every
adaptation. If reverification concludes that constraints are violated, the
plans are repaired. The main objective of this paper is to improve the
efficiency of reverification after learning, so that agents have a sufficiently
rapid response time. We present two solutions: positive results that certain
learning operators are a priori guaranteed to preserve useful classes of
behavioral assurance constraints (which implies that no reverification is
needed for these operators), and efficient incremental reverification
algorithms for those learning operators that have negative a priori results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0245</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0245</id><created>2011-06-01</created><authors><author><keyname>Baxter</keyname><forenames>J.</forenames></author></authors><title>A Model of Inductive Bias Learning</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  149-198, 2000</journal-ref><doi>10.1613/jair.731</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major problem in machine learning is that of inductive bias: how to choose
a learner's hypothesis space so that it is large enough to contain a solution
to the problem being learnt, yet small enough to ensure reliable generalization
from reasonably-sized training sets. Typically such bias is supplied by hand
through the skill and insights of experts. In this paper a model for
automatically learning bias is investigated. The central assumption of the
model is that the learner is embedded within an environment of related learning
tasks. Within such an environment the learner can sample from multiple tasks,
and hence it can search for a hypothesis space that contains good solutions to
many of the problems in the environment. Under certain restrictions on the set
of all hypothesis spaces available to the learner, we show that a hypothesis
space that performs well on a sufficiently large number of training tasks will
also perform well when learning novel tasks in the same environment. Explicit
bounds are also derived demonstrating that learning multiple tasks within an
environment of related tasks can potentially give much better generalization
than learning a single task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0246</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0246</id><created>2011-06-01</created><authors><author><keyname>Bhattacharyya</keyname><forenames>C.</forenames></author><author><keyname>Keerthi</keyname><forenames>S. S.</forenames></author></authors><title>Mean Field Methods for a Special Class of Belief Networks</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  91-114, 2001</journal-ref><doi>10.1613/jair.734</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The chief aim of this paper is to propose mean-field approximations for a
broad class of Belief networks, of which sigmoid and noisy-or networks can be
seen as special cases. The approximations are based on a powerful mean-field
theory suggested by Plefka. We show that Saul, Jaakkola and Jordan' s approach
is the first order approximation in Plefka's approach, via a variational
derivation. The application of Plefka's theory to belief networks is not
computationally tractable. To tackle this problem we propose new approximations
based on Taylor series. Small scale experiments show that the proposed schemes
are attractive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0247</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0247</id><created>2011-06-01</created><authors><author><keyname>Nebel</keyname><forenames>B.</forenames></author></authors><title>On the Compilability and Expressive Power of Propositional Planning
  Formalisms</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 12, pages
  271-315, 2000</journal-ref><doi>10.1613/jair.735</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent approaches of extending the GRAPHPLAN algorithm to handle more
expressive planning formalisms raise the question of what the formal meaning of
&quot;expressive power&quot; is. We formalize the intuition that expressive power is a
measure of how concisely planning domains and plans can be expressed in a
particular formalism by introducing the notion of &quot;compilation schemes&quot; between
planning formalisms. Using this notion, we analyze the expressiveness of a
large family of propositional planning formalisms, ranging from basic STRIPS to
a formalism with conditional effects, partial state specifications, and
propositional formulae in the preconditions. One of the results is that
conditional effects cannot be compiled away if plan size should grow only
linearly but can be compiled away if we allow for polynomial growth of the
resulting plans. This result confirms that the recently proposed extensions to
the GRAPHPLAN algorithm concerning conditional effects are optimal with respect
to the &quot;compilability&quot; framework. Another result is that general propositional
formulae cannot be compiled into conditional effects if the plan size should be
preserved linearly. This implies that allowing general propositional formulae
in preconditions and effect conditions adds another level of difficulty in
generating a plan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0248</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0248</id><created>2011-06-01</created><authors><author><keyname>Basu</keyname><forenames>C.</forenames></author><author><keyname>Cohen</keyname><forenames>W. W.</forenames></author><author><keyname>Hirsh</keyname><forenames>H.</forenames></author><author><keyname>Nevill-Manning</keyname><forenames>C.</forenames></author></authors><title>Technical Paper Recommendation: A Study in Combining Multiple
  Information Sources</title><categories>cs.IR</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  231-252, 2001</journal-ref><doi>10.1613/jair.739</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growing need to manage and exploit the proliferation of online data
sources is opening up new opportunities for bringing people closer to the
resources they need. For instance, consider a recommendation service through
which researchers can receive daily pointers to journal papers in their fields
of interest. We survey some of the known approaches to the problem of technical
paper recommendation and ask how they can be extended to deal with multiple
information sources. More specifically, we focus on a variant of this problem -
recommending conference paper submissions to reviewing committee members -
which offers us a testbed to try different approaches. Using WHIRL - an
information integration system - we are able to implement different
recommendation algorithms derived from information retrieval principles. We
also use a novel autonomous procedure for gathering reviewer interest
information from the Web. We evaluate our approach and compare it to other
methods using preference data provided by members of the AAAI-98 conference
reviewing committee along with data about the actual submissions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0249</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0249</id><created>2011-06-01</created><authors><author><keyname>Boutilier</keyname><forenames>C.</forenames></author><author><keyname>Brafman</keyname><forenames>R. I.</forenames></author></authors><title>Partial-Order Planning with Concurrent Interacting Actions</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  105-136, 2001</journal-ref><doi>10.1613/jair.740</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to generate plans for agents with multiple actuators, agent teams,
or distributed controllers, we must be able to represent and plan using
concurrent actions with interacting effects. This has historically been
considered a challenging task requiring a temporal planner with the ability to
reason explicitly about time. We show that with simple modifications, the
STRIPS action representation language can be used to represent interacting
actions. Moreover, algorithms for partial-order planning require only small
modifications in order to be applied in such multiagent domains. We demonstrate
this fact by developing a sound and complete partial-order planner for planning
with concurrent interacting actions, POMP, that extends existing partial-order
planners in a straightforward way. These results open the way to the use of
partial-order planners for the centralized control of cooperative multiagent
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0250</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0250</id><created>2011-06-01</created><authors><author><keyname>Ambite</keyname><forenames>J. L.</forenames></author><author><keyname>Knoblock</keyname><forenames>C. A.</forenames></author></authors><title>Planning by Rewriting</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  207-261, 2001</journal-ref><doi>10.1613/jair.754</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Domain-independent planning is a hard combinatorial problem. Taking into
account plan quality makes the task even more difficult. This article
introduces Planning by Rewriting (PbR), a new paradigm for efficient
high-quality domain-independent planning. PbR exploits declarative
plan-rewriting rules and efficient local search techniques to transform an
easy-to-generate, but possibly suboptimal, initial plan into a high-quality
plan. In addition to addressing the issues of planning efficiency and plan
quality, this framework offers a new anytime planning algorithm. We have
implemented this planner and applied it to several existing domains. The
experimental results show that the PbR approach provides significant savings in
planning effort while generating high-quality plans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0251</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0251</id><created>2011-06-01</created><authors><author><keyname>Zhang</keyname><forenames>N. L.</forenames></author><author><keyname>Zhang</keyname><forenames>W.</forenames></author></authors><title>Speeding Up the Convergence of Value Iteration in Partially Observable
  Markov Decision Processes</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  29-51, 2001</journal-ref><doi>10.1613/jair.761</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partially observable Markov decision processes (POMDPs) have recently become
popular among many AI researchers because they serve as a natural model for
planning under uncertainty. Value iteration is a well-known algorithm for
finding optimal policies for POMDPs. It typically takes a large number of
iterations to converge. This paper proposes a method for accelerating the
convergence of value iteration. The method has been evaluated on an array of
benchmark problems and was found to be very effective: It enabled value
iteration to converge after only a few iterations on all the test problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0252</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0252</id><created>2011-06-01</created><authors><author><keyname>Cimatti</keyname><forenames>A.</forenames></author><author><keyname>Roveri</keyname><forenames>M.</forenames></author></authors><title>Conformant Planning via Symbolic Model Checking</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 13, pages
  305-338, 2000</journal-ref><doi>10.1613/jair.774</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the problem of planning in nondeterministic domains, by presenting
a new approach to conformant planning. Conformant planning is the problem of
finding a sequence of actions that is guaranteed to achieve the goal despite
the nondeterminism of the domain. Our approach is based on the representation
of the planning domain as a finite state automaton. We use Symbolic Model
Checking techniques, in particular Binary Decision Diagrams, to compactly
represent and efficiently search the automaton. In this paper we make the
following contributions. First, we present a general planning algorithm for
conformant planning, which applies to fully nondeterministic domains, with
uncertainty in the initial condition and in action effects. The algorithm is
based on a breadth-first, backward search, and returns conformant plans of
minimal length, if a solution to the planning problem exists, otherwise it
terminates concluding that the problem admits no conformant solution. Second,
we provide a symbolic representation of the search space based on Binary
Decision Diagrams (BDDs), which is the basis for search techniques derived from
symbolic model checking. The symbolic representation makes it possible to
analyze potentially large sets of states and transitions in a single
computation step, thus providing for an efficient implementation. Third, we
present CMBP (Conformant Model Based Planner), an efficient implementation of
the data structures and algorithm described above, directly based on BDD
manipulations, which allows for a compact representation of the search layers
and an efficient implementation of the search steps. Finally, we present an
experimental comparison of our approach with the state-of-the-art conformant
planners CGP, QBFPLAN and GPT. Our analysis includes all the planning problems
from the distribution packages of these systems, plus other problems defined to
stress a number of specific factors. Our approach appears to be the most
effective: CMBP is strictly more expressive than QBFPLAN and CGP and, in all
the problems where a comparison is possible, CMBP outperforms its competitors,
sometimes by orders of magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0253</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0253</id><created>2011-06-01</created><authors><author><keyname>Cheng</keyname><forenames>J.</forenames></author><author><keyname>Druzdzel</keyname><forenames>M. J.</forenames></author></authors><title>AIS-BN: An Adaptive Importance Sampling Algorithm for Evidential
  Reasoning in Large Bayesian Networks</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 13, pages
  155-188, 2000</journal-ref><doi>10.1613/jair.764</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic sampling algorithms, while an attractive alternative to exact
algorithms in very large Bayesian network models, have been observed to perform
poorly in evidential reasoning with extremely unlikely evidence. To address
this problem, we propose an adaptive importance sampling algorithm, AIS-BN,
that shows promising convergence rates even under extreme conditions and seems
to outperform the existing sampling algorithms consistently. Three sources of
this performance improvement are (1) two heuristics for initialization of the
importance function that are based on the theoretical properties of importance
sampling in finite-dimensional integrals and the structural advantages of
Bayesian networks, (2) a smooth learning method for the importance function,
and (3) a dynamic weighting function for combining samples from different
stages of the algorithm. We tested the performance of the AIS-BN algorithm
along with two state of the art general purpose sampling algorithms, likelihood
weighting (Fung and Chang, 1989; Shachter and Peot, 1989) and self-importance
sampling (Shachter and Peot, 1989). We used in our tests three large real
Bayesian network models available to the scientific community: the CPCS network
(Pradhan et al., 1994), the PathFinder network (Heckerman, Horvitz, and
Nathwani, 1990), and the ANDES network (Conati, Gertner, VanLehn, and Druzdzel,
1997), with evidence as unlikely as 10^-41. While the AIS-BN algorithm always
performed better than the other two algorithms, in the majority of the test
cases it achieved orders of magnitude improvement in precision of the results.
Improvement in speed given a desired precision is even more dramatic, although
we are unable to report numerical results here, as the other algorithms almost
never achieved the precision reached even by the first few iterations of the
AIS-BN algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0254</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0254</id><created>2011-06-01</created><authors><author><keyname>Chen</keyname><forenames>X.</forenames></author><author><keyname>van Beek</keyname><forenames>P.</forenames></author></authors><title>Conflict-Directed Backjumping Revisited</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  53-81, 2001</journal-ref><doi>10.1613/jair.788</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, many improvements to backtracking algorithms for solving
constraint satisfaction problems have been proposed. The techniques for
improving backtracking algorithms can be conveniently classified as look-ahead
schemes and look-back schemes. Unfortunately, look-ahead and look-back schemes
are not entirely orthogonal as it has been observed empirically that the
enhancement of look-ahead techniques is sometimes counterproductive to the
effects of look-back techniques. In this paper, we focus on the relationship
between the two most important look-ahead techniques---using a variable
ordering heuristic and maintaining a level of local consistency during the
backtracking search---and the look-back technique of conflict-directed
backjumping (CBJ). We show that there exists a &quot;perfect&quot; dynamic variable
ordering such that CBJ becomes redundant. We also show theoretically that as
the level of local consistency that is maintained in the backtracking search is
increased, the less that backjumping will be an improvement. Our theoretical
results partially explain why a backtracking algorithm doing more in the
look-ahead phase cannot benefit more from the backjumping look-back scheme.
Finally, we show empirically that adding CBJ to a backtracking algorithm that
maintains generalized arc consistency (GAC), an algorithm that we refer to as
GAC-CBJ, can still provide orders of magnitude speedups. Our empirical results
contrast with Bessiere and Regin's conclusion (1996) that CBJ is useless to an
algorithm that maintains arc consistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0256</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0256</id><created>2011-06-01</created><authors><author><keyname>Siskind</keyname><forenames>J. M.</forenames></author></authors><title>Grounding the Lexical Semantics of Verbs in Visual Perception using
  Force Dynamics and Event Logic</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  31-90, 2001</journal-ref><doi>10.1613/jair.790</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an implemented system for recognizing the occurrence of
events described by simple spatial-motion verbs in short image sequences. The
semantics of these verbs is specified with event-logic expressions that
describe changes in the state of force-dynamic relations between the
participants of the event. An efficient finite representation is introduced for
the infinite sets of intervals that occur when describing liquid and
semi-liquid events. Additionally, an efficient procedure using this
representation is presented for inferring occurrences of compound events,
described with event-logic expressions, from occurrences of primitive events.
Using force dynamics and event logic to specify the lexical semantics of events
allows the system to be more robust than prior systems based on motion profile.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0257</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0257</id><created>2011-06-01</created><authors><author><keyname>Maclin</keyname><forenames>R.</forenames></author><author><keyname>Opitz</keyname><forenames>D.</forenames></author></authors><title>Popular Ensemble Methods: An Empirical Study</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  169-198, 1999</journal-ref><doi>10.1613/jair.614</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An ensemble consists of a set of individually trained classifiers (such as
neural networks or decision trees) whose predictions are combined when
classifying novel instances. Previous research has shown that an ensemble is
often more accurate than any of the single classifiers in the ensemble. Bagging
(Breiman, 1996c) and Boosting (Freund and Shapire, 1996; Shapire, 1990) are two
relatively new but popular methods for producing ensembles. In this paper we
evaluate these methods on 23 data sets using both neural networks and decision
trees as our classification algorithm. Our results clearly indicate a number of
conclusions. First, while Bagging is almost always more accurate than a single
classifier, it is sometimes much less accurate than Boosting. On the other
hand, Boosting can create ensembles that are less accurate than a single
classifier -- especially when using neural networks. Analysis indicates that
the performance of the Boosting methods is dependent on the characteristics of
the data set being examined. In fact, further results show that Boosting
ensembles may overfit noisy data sets, thus decreasing its performance.
Finally, consistent with previous studies, our work suggests that most of the
gain in an ensemble's performance comes in the first few classifiers combined;
however, relatively large gains can be seen up to 25 classifiers when Boosting
decision trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0263</identifier>
 <datestamp>2014-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0263</id><created>2011-06-01</created><updated>2011-10-01</updated><authors><author><keyname>Alabau-Boussouira</keyname><forenames>F.</forenames></author><author><keyname>Cannarsa</keyname><forenames>P.</forenames></author><author><keyname>Guglielmi</keyname><forenames>R.</forenames></author></authors><title>Indirect stabilization of weakly coupled systems with hybrid boundary
  conditions</title><categories>math.OC cs.SY math.AP</categories><msc-class>93D15, 35L53, 47D06, 46B70</msc-class><journal-ref>Mathematical Control and Related Fields 1, no. 4, 413-436 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate stability properties of indirectly damped systems of evolution
equations in Hilbert spaces, under new compatibility assumptions. We prove
polynomial decay for the energy of solutions and optimize our results by
interpolation techniques, obtaining a full range of power-like decay rates. In
particular, we give explicit estimates with respect to the initial data. We
discuss several applications to hyperbolic systems with {\em hybrid} boundary
conditions, including the coupling of two wave equations subject to Dirichlet
and Robin type boundary conditions, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0264</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0264</id><created>2011-06-01</created><authors><author><keyname>Naguib</keyname><forenames>Ahmed A.</forenames></author><author><keyname>Elsayed</keyname><forenames>Khaled</forenames></author><author><keyname>Nafie</keyname><forenames>Mohammed</forenames></author></authors><title>Achievable Degrees of Freedom of the K-user Interference Channel with
  Partial Cooperation</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we consider the K-user interference channel with partial
cooperation, where a strict subset of the K users cooperate. For the K-user
interference channel with cooperating subsets of length M, the outer bound of
the total degrees of freedom is KM/(M+1). In this paper, we propose a signal
space-based interference alignment scheme that proves the achievability of
these degrees of freedom for the case K=M+2. The proposed scheme consists of a
design for the transmit precoding matrices and a processing algorithm which we
call the Successive Interference Alignment (SIA) algorithm. The decoder of each
message uses the SIA algorithm to process the signals received by the M
cooperating receivers in order to get the maximum available degrees of freedom.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0281</identifier>
 <datestamp>2011-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0281</id><created>2011-06-01</created><updated>2011-09-09</updated><authors><author><keyname>Peres</keyname><forenames>Lucas R.</forenames></author><author><keyname>Fontanari</keyname><forenames>Jos&#xe9; F.</forenames></author></authors><title>The media effect in Axelrod's model explained</title><categories>physics.soc-ph cs.SI</categories><journal-ref>EPL, 96 (2011) 38004</journal-ref><doi>10.1209/0295-5075/96/38004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the problem of introducing an external global field -- the mass
media -- in Axelrod's model of social dynamics, where in addition to their
nearest neighbors, the agents can interact with a virtual neighbor whose
cultural features are fixed from the outset. The finding that this apparently
homogenizing field actually increases the cultural diversity has been
considered a puzzle since the phenomenon was first reported more than a decade
ago. Here we offer a simple explanation for it, which is based on the
pedestrian observation that Axelrod's model exhibits more cultural diversity,
i.e., more distinct cultural domains, when the agents are allowed to interact
solely with the media field than when they can interact with their neighbors as
well. In this perspective, it is the local homogenizing interactions that work
towards making the absorbing configurations less fragmented as compared with
the extreme situation in which the agents interact with the media only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0284</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0284</id><created>2011-06-01</created><authors><author><keyname>Khor</keyname><forenames>E. F.</forenames></author><author><keyname>Lee</keyname><forenames>T. H.</forenames></author><author><keyname>Sathikannan</keyname><forenames>R.</forenames></author><author><keyname>Tan</keyname><forenames>K. C.</forenames></author></authors><title>An Evolutionary Algorithm with Advanced Goal and Priority Specification
  for Multi-objective Optimization</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 18, pages
  183-215, 2003</journal-ref><doi>10.1613/jair.842</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an evolutionary algorithm with a new goal-sequence
domination scheme for better decision support in multi-objective optimization.
The approach allows the inclusion of advanced hard/soft priority and constraint
information on each objective component, and is capable of incorporating
multiple specifications with overlapping or non-overlapping objective functions
via logical 'OR' and 'AND' connectives to drive the search towards multiple
regions of trade-off. In addition, we propose a dynamic sharing scheme that is
simple and adaptively estimated according to the on-line population
distribution without needing any a priori parameter setting. Each feature in
the proposed algorithm is examined to show its respective contribution, and the
performance of the algorithm is compared with other evolutionary optimization
methods. It is shown that the proposed algorithm has performed well in the
diversity of evolutionary search and uniform distribution of non-dominated
individuals along the final trade-offs, without significant computational
effort. The algorithm is also applied to the design optimization of a practical
servo control system for hard disk drives with a single voice-coil-motor
actuator. Results of the evolutionary designed servo control system show a
superior closed-loop performance compared to classical PID or RPT approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0285</identifier>
 <datestamp>2011-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0285</id><created>2011-06-01</created><authors><author><keyname>Refanidis</keyname><forenames>I.</forenames></author><author><keyname>Vlahavas</keyname><forenames>I.</forenames></author></authors><title>The GRT Planning System: Backward Heuristic Construction in Forward
  State-Space Planning</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  115-161, 2001</journal-ref><doi>10.1613/jair.893</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents GRT, a domain-independent heuristic planning system for
STRIPS worlds. GRT solves problems in two phases. In the pre-processing phase,
it estimates the distance between each fact and the goals of the problem, in a
backward direction. Then, in the search phase, these estimates are used in
order to further estimate the distance between each intermediate state and the
goals, guiding so the search process in a forward direction and on a best-first
basis. The paper presents the benefits from the adoption of opposite directions
between the preprocessing and the search phases, discusses some difficulties
that arise in the pre-processing phase and introduces techniques to cope with
them. Moreover, it presents several methods of improving the efficiency of the
heuristic, by enriching the representation and by reducing the size of the
problem. Finally, a method of overcoming local optimal states, based on domain
axioms, is proposed. According to it, difficult problems are decomposed into
easier sub-problems that have to be solved sequentially. The performance
results from various domains, including those of the recent planning
competitions, show that GRT is among the fastest planners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0286</identifier>
 <datestamp>2013-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0286</id><created>2011-06-01</created><updated>2013-04-17</updated><authors><author><keyname>Papadopoulos</keyname><forenames>Fragkiskos</forenames></author><author><keyname>Kitsak</keyname><forenames>Maksim</forenames></author><author><keyname>Serrano</keyname><forenames>M. Angeles</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author><author><keyname>Krioukov</keyname><forenames>Dmitri</forenames></author></authors><title>Popularity versus Similarity in Growing Networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.NI cs.SI</categories><journal-ref>Nature, v.489, p.537, 2012</journal-ref><doi>10.1038/nature11459</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Popularity is attractive -- this is the formula underlying preferential
attachment, a popular explanation for the emergence of scaling in growing
networks. If new connections are made preferentially to more popular nodes,
then the resulting distribution of the number of connections that nodes have
follows power laws observed in many real networks. Preferential attachment has
been directly validated for some real networks, including the Internet.
Preferential attachment can also be a consequence of different underlying
processes based on node fitness, ranking, optimization, random walks, or
duplication. Here we show that popularity is just one dimension of
attractiveness. Another dimension is similarity. We develop a framework where
new connections, instead of preferring popular nodes, optimize certain
trade-offs between popularity and similarity. The framework admits a geometric
interpretation, in which popularity preference emerges from local optimization.
As opposed to preferential attachment, the optimization framework accurately
describes large-scale evolution of technological (Internet), social (web of
trust), and biological (E.coli metabolic) networks, predicting the probability
of new links in them with a remarkable precision. The developed framework can
thus be used for predicting new links in evolving networks, and provides a
different perspective on preferential attachment as an emergent phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0288</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0288</id><created>2011-06-01</created><authors><author><keyname>Jo</keyname><forenames>Hang-Hyun</forenames></author><author><keyname>Pan</keyname><forenames>Raj Kumar</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author></authors><title>Emergence of Bursts and Communities in Evolving Weighted Networks</title><categories>physics.soc-ph cs.SI</categories><comments>9 pages, 6 figures</comments><journal-ref>PLoS ONE 6(8): e22687 (2011)</journal-ref><doi>10.1371/journal.pone.0022687</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding the patterns of human dynamics and social interaction, and the
way they lead to the formation of an organized and functional society are
important issues especially for techno-social development. Addressing these
issues of social networks has recently become possible through large scale data
analysis of e.g. mobile phone call records, which has revealed the existence of
modular or community structure with many links between nodes of the same
community and relatively few links between nodes of different communities. The
weights of links, e.g. the number of calls between two users, and the network
topology are found correlated such that intra-community links are stronger
compared to the weak inter-community links. This is known as Granovetter's &quot;The
strength of weak ties&quot; hypothesis. In addition to this inhomogeneous community
structure, the temporal patterns of human dynamics turn out to be inhomogeneous
or bursty, characterized by the heavy tailed distribution of inter-event time
between two consecutive events. In this paper, we study how the community
structure and the bursty dynamics emerge together in an evolving weighted
network model. The principal mechanisms behind these patterns are social
interaction by cyclic closure, i.e. links to friends of friends and the focal
closure, i.e. links to individuals sharing similar attributes or interests, and
human dynamics by task handling process. These three mechanisms have been
implemented as a network model with local attachment, global attachment, and
priority-based queuing processes. By comprehensive numerical simulations we
show that the interplay of these mechanisms leads to the emergence of heavy
tailed inter-event time distribution and the evolution of Granovetter-type
community structure. Moreover, the numerical results are found to be in
qualitative agreement with empirical results from mobile phone call dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0296</identifier>
 <datestamp>2012-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0296</id><created>2011-06-02</created><updated>2011-11-07</updated><authors><author><keyname>Clemson</keyname><forenames>T.</forenames></author><author><keyname>Evans</keyname><forenames>T. S.</forenames></author></authors><title>The Emergence of Leadership in Social Networks</title><categories>physics.soc-ph cs.SI q-fin.GN</categories><comments>22 pages (as in Physica A but with a few extra references to
  supplementary material) plus 11 pages of supplementary material not in
  Physica A version</comments><report-no>Imperial/TP/11/TSE/3</report-no><journal-ref>Physica A 391 (2012) 1434-1444</journal-ref><doi>10.1016/j.physa.2011.11.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a networked version of the minority game in which agents can choose
to follow the choices made by a neighbouring agent in a social network. We show
that for a wide variety of networks a leadership structure always emerges, with
most agents following the choice made by a few agents. We find a suitable
parameterisation which highlights the universal aspects of the behaviour and
which also indicates where results depend on the type of social network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0297</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0297</id><created>2011-06-01</created><authors><author><keyname>Courtat</keyname><forenames>Thomas</forenames></author><author><keyname>Gloaguen</keyname><forenames>Catherine</forenames></author><author><keyname>Douady</keyname><forenames>St&#xe9;phane</forenames></author></authors><title>Hypergraphs and City Street Networks</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The map of a city's streets constitutes a particular case of spatial complex
network. However a city is not limited to its topology: it is above all a
geometrical object whose particularity is to organize into short and long axes
called streets. In this article we present and discuss two algorithms aiming at
recovering the notion of street from a graph representation of a city. Then we
show that the length of the so-called streets scales logarithmically. This
phenomenon leads to assume that a city is shaped into a logic of extension and
division of space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0304</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0304</id><created>2011-06-01</created><authors><author><keyname>Pardillo</keyname><forenames>Jes&#xfa;s</forenames></author><author><keyname>Maz&#xf3;n</keyname><forenames>Jose-Norberto</forenames></author></authors><title>Using Ontologies for the Design of Data Warehouses</title><categories>cs.DB</categories><comments>15 pages, 2 figures</comments><msc-class>68P15</msc-class><acm-class>H.2.7</acm-class><journal-ref>International Journal of Database Management Systems (IJDMS),
  Vol.3, No.2, May 2011</journal-ref><doi>10.5121/ijdms.2011.3205</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Obtaining an implementation of a data warehouse is a complex task that forces
designers to acquire wide knowledge of the domain, thus requiring a high level
of expertise and becoming it a prone-to-fail task. Based on our experience, we
have detected a set of situations we have faced up with in real-world projects
in which we believe that the use of ontologies will improve several aspects of
the design of data warehouses. The aim of this article is to describe several
shortcomings of current data warehouse design approaches and discuss the
benefit of using ontologies to overcome them. This work is a starting point for
discussing the convenience of using ontologies in data warehouse design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0305</identifier>
 <datestamp>2012-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0305</id><created>2011-06-01</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Slime mould computes planar shapes</title><categories>cs.ET nlin.PS</categories><journal-ref>International Journal of Bio-Inspired Computation 2012 - Vol. 4,
  No.3 pp. 149 - 154</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing a polygon defining a set of planar points is a classical problem of
modern computational geometry. In laboratory experiments we demonstrate that a
concave hull, a connected alpha-shape without holes, of a finite planar set is
approximated by slime mould Physarum polycephalum. We represent planar points
with sources of long-distance attractants and short-distance repellents and
inoculate a piece of plasmodium outside the data set. The plasmodium moves
towards the data and envelops it by pronounced protoplasmic tubes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0342</identifier>
 <datestamp>2011-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0342</id><created>2011-06-01</created><updated>2011-12-11</updated><authors><author><keyname>Pola</keyname><forenames>Giordano</forenames></author><author><keyname>Di Benedetto</keyname><forenames>Maria D.</forenames></author><author><keyname>De Santis</keyname><forenames>Elena</forenames></author></authors><title>Arenas of Finite State Machines</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite state machines are widely used as a sound mathematical formalism that
appropriately describes large scale, distributed and complex systems. Multiple
interactions of finite state machines in complex systems are well captured by
the notion of non-flat systems. Non--flat systems are &quot;finite state machines&quot;
where each &quot;state&quot; can be either a basic state or an aggregate of finite state
machines. By expanding a non-flat system, a flat system is obtained which is an
ordinary finite state machine. In this paper we introduce a novel class of
non--flat systems called Arena of Finite State Machines (AFSM). AFSMs are
collections of finite state machines that interact concurrently through a
communication network. We propose a notion of compositional bisimulation that
allows checking bisimulation equivalence of AFSMs by directly exploiting their
communication networks and hence, without the need of expanding the AFSMs to
finite state machines. Compositional bisimulation allows a computational
complexity reduction when checking bisimulation equivalence of AFSMs, as
formally quantified in the paper. An application of the proposed framework to
the regulation of gene expression in the bacterium Escherichia coli is also
presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0346</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0346</id><created>2011-06-01</created><authors><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author><author><keyname>Surachawala</keyname><forenames>Tawan</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Entropy-based Classification of 'Retweeting' Activity on Twitter</title><categories>cs.SI cs.CY</categories><comments>snakdd-11(submitted)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Twitter is used for a variety of reasons, including information
dissemination, marketing, political organizing and to spread propaganda,
spamming, promotion, conversations, and so on. Characterizing these activities
and categorizing associated user generated content is a challenging task. We
present a information-theoretic approach to classification of user activity on
Twitter. We focus on tweets that contain embedded URLs and study their
collective `retweeting' dynamics. We identify two features, time-interval and
user entropy, which we use to classify retweeting activity. We achieve good
separation of different activities using just these two features and are able
to categorize content based on the collective user response it generates.
  We have identified five distinct categories of retweeting activity on
Twitter: automatic/robotic activity, newsworthy information dissemination,
advertising and promotion, campaigns, and parasitic advertisement. In the
course of our investigations, we have shown how Twitter can be exploited for
promotional and spam-like activities. The content-independent, entropy-based
activity classification method is computationally efficient, scalable and
robust to sampling and missing data. It has many applications, including
automatic spam-detection, trend identification, trust management,
user-modeling, social search and content classification on online social media.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0349</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0349</id><created>2011-06-01</created><authors><author><keyname>Morrison</keyname><forenames>David R.</forenames></author><author><keyname>Martonosi</keyname><forenames>Susan E.</forenames></author></authors><title>Characteristics of Optimal Solutions to the Sensor Location Problem</title><categories>math.OC cs.DM</categories><comments>Submitted for peer review on October 3, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In [Bianco, L., Giuseppe C., and P. Reverberi. 2001. &quot;A network based model
for traffic sensor location with implications on O/D matrix estimates&quot;.
Transportation Science 35(1):50-60.], the authors present the Sensor Location
Problem: that of locating the minimum number of traffic sensors at
intersections of a road network such that the traffic flow on the entire
network can be determined. They offer a necessary and sufficient condition on
the set of monitored nodes in order for the flow everywhere to be determined.
In this paper, we present a counterexample that demonstrates that the condition
is not actually sufficient (though it is still necessary). We present a
stronger necessary condition for flow calculability, and show that it is a
sufficient condition in a large class of graphs in which a particular subgraph
is a tree. Many typical road networks are included in this category, and we
show how our condition can be used to inform traffic sensor placement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0357</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0357</id><created>2011-06-01</created><authors><author><keyname>Tarifi</keyname><forenames>Mohamad</forenames></author><author><keyname>Sitharam</keyname><forenames>Meera</forenames></author><author><keyname>Ho</keyname><forenames>Jeffery</forenames></author></authors><title>Learning Hierarchical Sparse Representations using Iterative Dictionary
  Learning and Dimension Reduction</title><categories>cs.LG cs.AI cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces an elemental building block which combines Dictionary
Learning and Dimension Reduction (DRDL). We show how this foundational element
can be used to iteratively construct a Hierarchical Sparse Representation (HSR)
of a sensory stream. We compare our approach to existing models showing the
generality of our simple prescription. We then perform preliminary experiments
using this framework, illustrating with the example of an object recognition
task using standard datasets. This work introduces the very first steps towards
an integrated framework for designing and analyzing various computational tasks
from learning to attention to action. The ultimate goal is building a
mathematically rigorous, integrated theory of intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0359</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0359</id><created>2011-06-01</created><authors><author><keyname>Pan</keyname><forenames>Wei</forenames></author><author><keyname>Aharony</keyname><forenames>Nadav</forenames></author><author><keyname>Pentland</keyname><forenames>Alex</forenames></author></authors><title>Composite Social Network for Predicting Mobile Apps Installation</title><categories>cs.SI cs.HC physics.soc-ph</categories><journal-ref>Proceeding of AAAI 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have carefully instrumented a large portion of the population living in a
university graduate dormitory by giving participants Android smart phones
running our sensing software. In this paper, we propose the novel problem of
predicting mobile application (known as &quot;apps&quot;) installation using social
networks and explain its challenge. Modern smart phones, like the ones used in
our study, are able to collect different social networks using built-in
sensors. (e.g. Bluetooth proximity network, call log network, etc) While this
information is accessible to app market makers such as the iPhone AppStore, it
has not yet been studied how app market makers can use these information for
marketing research and strategy development. We develop a simple computational
model to better predict app installation by using a composite network computed
from the different networks sensed by phones. Our model also captures
individual variance and exogenous factors in app adoption. We show the
importance of considering all these factors in predicting app installations,
and we observe the surprising result that app installation is indeed
predictable. We also show that our model achieves the best results compared
with generic approaches: our results are four times better than random guess,
and predict almost 45% of all apps users install with almost 45% precision (F1
score= 0.43).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0365</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0365</id><created>2011-06-02</created><updated>2011-06-02</updated><authors><author><keyname>Ba</keyname><forenames>Khanh Do</forenames></author><author><keyname>Indyk</keyname><forenames>Piotr</forenames></author><author><keyname>Price</keyname><forenames>Eric</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author></authors><title>Lower Bounds for Sparse Recovery</title><categories>cs.DS cs.IT math.IT</categories><comments>11 pages. Appeared at SODA 2010</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We consider the following k-sparse recovery problem: design an m x n matrix
A, such that for any signal x, given Ax we can efficiently recover x'
satisfying
  ||x-x'||_1 &lt;= C min_{k-sparse} x&quot;} ||x-x&quot;||_1.
  It is known that there exist matrices A with this property that have only O(k
log (n/k)) rows.
  In this paper we show that this bound is tight. Our bound holds even for the
more general /randomized/ version of the problem, where A is a random variable
and the recovery algorithm is required to work for any fixed x with constant
probability (over A).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0371</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0371</id><created>2011-06-02</created><authors><author><keyname>Aly</keyname><forenames>Ashraf A.</forenames></author><author><keyname>Deris</keyname><forenames>Safaai Bin</forenames></author><author><keyname>Zaki</keyname><forenames>Nazar</forenames></author></authors><title>A Novel Image Segmentation Enhancement Technique based on Active Contour
  and Topological Alignments</title><categories>cs.CV</categories><comments>7 pages</comments><journal-ref>Advanced Computing: An International Journal ( ACIJ ), Vol.2,
  No.3, May 2011</journal-ref><doi>10.5121/acij.2011.2301</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Topological alignments and snakes are used in image processing, particularly
in locating object boundaries. Both of them have their own advantages and
limitations. To improve the overall image boundary detection system, we focused
on developing a novel algorithm for image processing. The algorithm we propose
to develop will based on the active contour method in conjunction with
topological alignments method to enhance the image detection approach. The
algorithm presents novel technique to incorporate the advantages of both
Topological Alignments and snakes. Where the initial segmentation by
Topological Alignments is firstly transformed into the input of the snake model
and begins its evolvement to the interested object boundary. The results show
that the algorithm can deal with low contrast images and shape cells,
demonstrate the segmentation accuracy under weak image boundaries, which
responsible for lacking accuracy in image detecting techniques. We have
achieved better segmentation and boundary detecting for the image, also the
ability of the system to improve the low contrast and deal with over and under
segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0380</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0380</id><created>2011-06-02</created><authors><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Steinberg</keyname><forenames>Yossef</forenames></author></authors><title>A Note on Multiple-Access Channels with Strictly-Causal State
  Information</title><categories>cs.IT math.IT</categories><comments>To appear in the proceedings of Wireless Advanced, London June 20-22,
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new inner bound on the capacity region of a memoryless
multiple-access channel that is governed by a memoryless state that is known
strictly causally to the encoders. The new inner bound contains the previous
bounds, and we provide an example demonstrating that the inclusion can be
strict.
  A variation on this example is then applied to the case where the channel is
governed by two independent state sequences, where each transmitter knows one
of the states strictly causally. The example proves that, as conjectured by Li
et al., an inner bound that they derived for this scenario can indeed by
strictly better than previous bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0390</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0390</id><created>2011-06-02</created><authors><author><keyname>Drozdz</keyname><forenames>Stanislaw</forenames></author><author><keyname>Kwapien</keyname><forenames>Jaroslaw</forenames></author><author><keyname>Ioannides</keyname><forenames>Andreas A.</forenames></author></authors><title>Asymmetric random matrices: What do we need them for?</title><categories>physics.data-an cs.CE q-fin.ST</categories><journal-ref>Acta Phys. Pol. B 42, 987-999 (2011)</journal-ref><doi>10.5506/APhysPolB.42.987</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex systems are typically represented by large ensembles of observations.
Correlation matrices provide an efficient formal framework to extract
information from such multivariate ensembles and identify in a quantifiable way
patterns of activity that are reproducible with statistically significant
frequency compared to a reference chance probability, usually provided by
random matrices as fundamental reference. The character of the problem and
especially the symmetries involved must guide the choice of random matrices to
be used for the definition of a baseline reference. For standard correlation
matrices this is the Wishart ensemble of symmetric random matrices. The real
world complexity however often shows asymmetric information flows and therefore
more general correlation matrices are required to adequately capture the
asymmetry. Here we first summarize the relevant theoretical concepts. We then
present some examples of human brain activity where asymmetric time-lagged
correlations are evident and hence highlight the need for further theoretical
developments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0399</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0399</id><created>2011-06-02</created><authors><author><keyname>Bastenhof</keyname><forenames>Arno</forenames></author></authors><title>Focalization and phase models for classical extensions of
  non-associative Lambek calculus</title><categories>cs.LO</categories><comments>To be submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lambek's non-associative syntactic calculus (NL) excels in its resource
consciousness: the usual structural rules for weakening, contraction, exchange
and even associativity are all dropped. Recently, there have been proposals for
conservative extensions dispensing with NL's intuitionistic bias towards
sequents with single conclusions: De Groote and Lamarche's classical
non-associative Lambek calculus (CNL) and the Lambek-Grishin calculus (LG) of
Moortgat and associates. We demonstrate Andreoli's focalization property for
said proposals: a normalization result for Cut-free sequent derivations
identifying to a large extent those differing only by trivial rule
permutations. In doing so, we proceed from a `uniform' sequent presentation,
deriving CNL from LG through the addition of structural rules. The
normalization proof proceeds by the construction of syntactic phase models
wherein every `truth' has a focused proof, similar to work of Okada and of
Herbelin and Lee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0411</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0411</id><created>2011-06-02</created><authors><author><keyname>Huertas-Rosero</keyname><forenames>Alvaro Francisco</forenames></author><author><keyname>van Rijsbergen</keyname><forenames>C. J.</forenames></author></authors><title>Quantum-Like Uncertain Conditionals for Text Analysis</title><categories>cs.CL quant-ph</categories><comments>11 pages, 2 figures. To be published in the proceedings of Quantum
  Interaction 2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Simple representations of documents based on the occurrences of terms are
ubiquitous in areas like Information Retrieval, and also frequent in Natural
Language Processing. In this work we propose a logical-probabilistic approach
to the analysis of natural language text based in the concept of Uncertain
Conditional, on top of a formulation of lexical measurements inspired in the
theoretical concept of ideal quantum measurements. The proposed concept can be
used for generating topic-specific representations of text, aiming to match in
a simple way the perception of a user with a pre-established idea of what the
usage of terms in the text should be. A simple example is developed with two
versions of a text in two languages, showing how regularities in the use of
terms are detected and easily represented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0419</identifier>
 <datestamp>2011-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0419</id><created>2011-06-02</created><updated>2011-11-18</updated><authors><author><keyname>Biswas</keyname><forenames>Soumyajyoti</forenames></author></authors><title>Mean field solutions of kinetic exchange opinion models</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>9 pages, 7 eps figs</comments><journal-ref>Phys. Rev. E 84, 056106 (2011)</journal-ref><doi>10.1103/PhysRevE.84.056106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here the exact solution of an infinite range, discrete, opinion
formation model. The model shows an active-absorbing phase transition, similar
to that numerically found in its recently proposed continuous version
(Lallouache et al., Phys. Rev E 82, 056112 (2010)). Apart from the two-agent
interactions here we also report the effect of having three agent interactions.
The phase diagram has a continuous transition line (two agent interaction
dominated) and a discontinuous transition line (three agent interaction
dominated) separated by a tricritical point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0423</identifier>
 <datestamp>2011-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0423</id><created>2011-06-02</created><updated>2011-10-12</updated><authors><author><keyname>Bonifaci</keyname><forenames>Vincenzo</forenames></author><author><keyname>Mehlhorn</keyname><forenames>Kurt</forenames></author><author><keyname>Varma</keyname><forenames>Girish</forenames></author></authors><title>Physarum Can Compute Shortest Paths</title><categories>cs.DS cs.CE cs.ET cs.SY math.DS math.OC physics.bio-ph</categories><comments>Accepted in SODA 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Physarum Polycephalum is a slime mold that is apparently able to solve
shortest path problems.
  A mathematical model has been proposed by biologists to describe the feedback
mechanism used by the slime mold to adapt its tubular channels while foraging
two food sources s0 and s1. We prove that, under this model, the mass of the
mold will eventually converge to the shortest s0 - s1 path of the network that
the mold lies on, independently of the structure of the network or of the
initial mass distribution.
  This matches the experimental observations by the biologists and can be seen
as an example of a &quot;natural algorithm&quot;, that is, an algorithm developed by
evolution over millions of years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0436</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0436</id><created>2011-06-02</created><authors><author><keyname>Guruswami</keyname><forenames>Venkatesan</forenames></author></authors><title>Linear-algebraic list decoding of folded Reed-Solomon codes</title><categories>cs.IT cs.DS math.IT</categories><comments>16 pages. Extended abstract in Proc. of IEEE Conference on
  Computational Complexity (CCC), 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Folded Reed-Solomon codes are an explicit family of codes that achieve the
optimal trade-off between rate and error-correction capability: specifically,
for any $\eps &gt; 0$, the author and Rudra (2006,08) presented an $n^{O(1/\eps)}$
time algorithm to list decode appropriate folded RS codes of rate $R$ from a
fraction $1-R-\eps$ of errors. The algorithm is based on multivariate
polynomial interpolation and root-finding over extension fields. It was noted
by Vadhan that interpolating a linear polynomial suffices if one settles for a
smaller decoding radius (but still enough for a statement of the above form).
Here we give a simple linear-algebra based analysis of this variant that
eliminates the need for the computationally expensive root-finding step over
extension fields (and indeed any mention of extension fields). The entire list
decoding algorithm is linear-algebraic, solving one linear system for the
interpolation step, and another linear system to find a small subspace of
candidate solutions. Except for the step of pruning this subspace, the
algorithm can be implemented to run in {\em quadratic} time. The theoretical
drawback of folded RS codes are that both the decoding complexity and proven
worst-case list-size bound are $n^{\Omega(1/\eps)}$. By combining the above
idea with a pseudorandom subset of all polynomials as messages, we get a Monte
Carlo construction achieving a list size bound of $O(1/\eps^2)$ which is quite
close to the existential $O(1/\eps)$ bound (however, the decoding complexity
remains $n^{\Omega(1/\eps)}$). Our work highlights that constructing an
explicit {\em subspace-evasive} subset that has small intersection with
low-dimensional subspaces could lead to explicit codes with better
list-decoding guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0438</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0438</id><created>2011-06-02</created><updated>2011-09-08</updated><authors><author><keyname>Kondratiuk</keyname><forenames>Pawe&#x142;</forenames></author><author><keyname>Siudem</keyname><forenames>Grzegorz</forenames></author><author><keyname>Ho&#x142;yst</keyname><forenames>Janusz A.</forenames></author></authors><title>Analytical approach to model of scientific revolutions</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 13 figures, REVTEX format</comments><doi>10.1103/PhysRevE.85.066126</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The model of scientific paradigms spreading throughout the community of
agents with memory is analyzed using the master equation. The case of two
competing ideas is considered for various networks of interactions, including
agents placed at Erd\H{o}s-R\'{e}nyi graphs or complete graphs. The pace of
adopting a new idea by a community is analyzed, along with the distribution of
periods after which a new idea replaces the old one. The approach is extended
for the chain topology onto the more general case when more than two ideas
compete. Our analytical results are in agreement with numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0439</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0439</id><created>2011-06-02</created><authors><author><keyname>Kondratiuk</keyname><forenames>Pawe&#x142;</forenames></author><author><keyname>Ho&#x142;yst</keyname><forenames>Janusz A.</forenames></author></authors><title>Model of communities isolation at hierarchical modular networks</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The model of community isolation was extended to the case when individuals
are randomly placed at nodes of hierarchical modular networks. It was shown
that the average number of blocked nodes (individuals) increases in time as a
power function, with the exponent depending on network parameters. The
distribution of time when the first isolated cluster appears is unimodal,
non-gaussian. The developed analytical approach is in a good agreement with the
simulation data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0443</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0443</id><created>2011-06-02</created><authors><author><keyname>Wu</keyname><forenames>Wenji</forenames></author><author><keyname>DeMar</keyname><forenames>Phil</forenames></author><author><keyname>Crawford</keyname><forenames>Matt</forenames></author></authors><title>Why Does Flow Director Cause Packet Reordering?</title><categories>cs.NI</categories><journal-ref>IEEE Commun.Lett.15:253-255,2011</journal-ref><doi>10.1109/LCOMM.2011.122010.102022</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Intel Ethernet Flow Director is an advanced network interface card (NIC)
technology. It provides the benefits of parallel receive processing in
multiprocessing environments and can automatically steer incoming network data
to the same core on which its application process resides. However, our
analysis and experiments show that Flow Director cannot guarantee in-order
packet delivery in multiprocessing environments. Packet reordering causes
various negative impacts. E.g., TCP performs poorly with severe packet
reordering. In this paper, we use a simplified model to analyze why Flow
Director can cause packet reordering. Our experiments verify our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0445</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0445</id><created>2011-06-02</created><authors><author><keyname>Wu</keyname><forenames>Wenji</forenames></author><author><keyname>Crawford</keyname><forenames>Matt</forenames></author><author><keyname>DeMar</keyname><forenames>Phil</forenames></author></authors><title>A Transport-Friendly NIC for Multicore/Multiprocessor Systems</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Receive side scaling (RSS) is a network interface card (NIC) technology. It
provides the benefits of parallel receive processing in multiprocessing
environments. However, existing RSS-enabled NICs lack a critical data steering
mechanism that would automatically steer incoming network data to the same core
on which its application process resides. This absence causes inefficient cache
usage if an application is not running on the core on which RSS has scheduled
the received traffic to be processed. In Linux systems, it cannot even ensure
that packets in a TCP flow are processed by a single core, even if the
interrupts for the flow are pinned to a specific core. This results in degraded
performance. In this paper, we develop such a data steering mechanism in the
NIC for multicore or multiprocessor systems. This data steering mechanism is
mainly targeted at TCP, but it can be extended to other transport layer
protocols. We term a NIC with such a data steering mechanism &quot;A Transport
Friendly NIC&quot; (A-TFN). Experimental results have proven the effectiveness of
A-TFN in accelerating TCP/IP performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0447</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0447</id><created>2011-06-02</created><authors><author><keyname>Acar</keyname><forenames>Umut A.</forenames></author><author><keyname>Blelloch</keyname><forenames>Guy E.</forenames></author><author><keyname>Harper</keyname><forenames>Robert</forenames></author></authors><title>Selective Memoization</title><categories>cs.PL</categories><comments>Total of 31 pages. This is the full version of a conference paper
  with the same title that appears in ACM Conference on Principles of
  Programming Languages (POPL) in 2003</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents language techniques for applying memoization selectively.
The techniques provide programmer control over equality, space usage, and
identification of precise dependences so that memoization can be applied
according to the needs of an application. Two key properties of the approach
are that it accepts and efficient implementation and yields programs whose
performance can be analyzed using standard analysis techniques. We describe our
approach in the context of a functional language called MFL and an
implementation as a Standard ML library. The MFL language employs a modal type
system to enable the programmer to express programs that reveal their true data
dependences when executed. We prove that the MFL language is sound by showing
that that MFL programs yield the same result as they would with respect to a
standard, non-memoizing semantics. The SML implementation cannot support the
modal type system of MFL statically but instead employs run-time checks to
ensure correct usage of primitives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0461</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0461</id><created>2011-06-02</created><authors><author><keyname>Devroye</keyname><forenames>Luc</forenames></author><author><keyname>King</keyname><forenames>James</forenames></author></authors><title>Random hyperplane search trees in high dimensions</title><categories>cs.CG cs.DS math.PR</categories><comments>19 pages, 4 figures</comments><msc-class>68Q87</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set S of n \geq d points in general position in R^d, a random
hyperplane split is obtained by sampling d points uniformly at random without
replacement from S and splitting based on their affine hull. A random
hyperplane search tree is a binary space partition tree obtained by recursive
application of random hyperplane splits. We investigate the structural
distributions of such random trees with a particular focus on the growth with
d. A blessing of dimensionality arises--as d increases, random hyperplane
splits more closely resemble perfectly balanced splits; in turn, random
hyperplane search trees more closely resemble perfectly balanced binary search
trees.
  We prove that, for any fixed dimension d, a random hyperplane search tree
storing n points has height at most (1 + O(1/sqrt(d))) log_2 n and average
element depth at most (1 + O(1/d)) log_2 n with high probability as n
\rightarrow \infty. Further, we show that these bounds are asymptotically
optimal with respect to d.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0468</identifier>
 <datestamp>2012-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0468</id><created>2011-06-01</created><updated>2012-05-22</updated><authors><author><keyname>Mari</keyname><forenames>Federico</forenames></author><author><keyname>Melatti</keyname><forenames>Igor</forenames></author><author><keyname>Salvo</keyname><forenames>Ivano</forenames></author><author><keyname>Tronci</keyname><forenames>Enrico</forenames></author></authors><title>From Boolean Functional Equations to Control Software</title><categories>cs.SY cs.LO cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many software as well digital hardware automatic synthesis methods define the
set of implementations meeting the given system specifications with a boolean
relation K. In such a context a fundamental step in the software (hardware)
synthesis process is finding effective solutions to the functional equation
defined by K. This entails finding a (set of) boolean function(s) F (typically
represented using OBDDs, Ordered Binary Decision Diagrams) such that: 1) for
all x for which K is satisfiable, K(x, F(x)) = 1 holds; 2) the implementation
of F is efficient with respect to given implementation parameters such as code
size or execution time. While this problem has been widely studied in digital
hardware synthesis, little has been done in a software synthesis context.
Unfortunately the approaches developed for hardware synthesis cannot be
directly used in a software context. This motivates investigation of effective
methods to solve the above problem when F has to be implemented with software.
In this paper we present an algorithm that, from an OBDD representation for K,
generates a C code implementation for F that has the same size as the OBDD for
F and a WCET (Worst Case Execution Time) at most O(nr), being n = |x| the
number of arguments of functions in F and r the number of functions in F.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0478</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0478</id><created>2011-06-02</created><authors><author><keyname>Acar</keyname><forenames>Umut A.</forenames></author><author><keyname>Blume</keyname><forenames>Matthias</forenames></author><author><keyname>Donham</keyname><forenames>Jacob</forenames></author></authors><title>A Consistent Semantics of Self-Adjusting Computation</title><categories>cs.PL</categories><comments>91 pages including the full Twelf proof in the appendix. This paper
  is a full version of the conference paper (published in European Symposium on
  Programming, ESOP, 2007)</comments><report-no>CMU-CS-2007-18</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a semantics of self-adjusting computation and proves that
the semantics are correct and consistent. The semantics integrate change
propagation with the classic idea of memoization to enable reuse of
computations under mutation to memory. During evaluation, reuse of a
computation via memoization triggers a change propagation that adjusts the
reused computation to reflect the mutated memory. Since the semantics integrate
memoization and change-propagation, it involves both non-determinism (due to
memoization) and mutation (due to change propagation). Our consistency theorem
states that the non-determinism is not harmful: any two evaluations of the same
program starting at the same state yield the same result. Our correctness
theorem states that mutation is not harmful: self-adjusting programs are
consistent with purely functional programming. We formalize the semantics and
their meta-theory in the LF logical framework and machine check our proofs
using Twelf.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0483</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0483</id><created>2011-06-02</created><authors><author><keyname>Pitkow</keyname><forenames>Xaq</forenames></author><author><keyname>Ahmadian</keyname><forenames>Yashar</forenames></author><author><keyname>Miller</keyname><forenames>Ken D.</forenames></author></authors><title>Learning unbelievable marginal probabilities</title><categories>cs.AI cs.LG</categories><comments>10 pages, 3 figures, submitted to NIPS*2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Loopy belief propagation performs approximate inference on graphical models
with loops. One might hope to compensate for the approximation by adjusting
model parameters. Learning algorithms for this purpose have been explored
previously, and the claim has been made that every set of locally consistent
marginals can arise from belief propagation run on a graphical model. On the
contrary, here we show that many probability distributions have marginals that
cannot be reached by belief propagation using any set of model parameters or
any learning algorithm. We call such marginals `unbelievable.' This problem
occurs whenever the Hessian of the Bethe free energy is not positive-definite
at the target marginals. All learning algorithms for belief propagation
necessarily fail in these cases, producing beliefs or sets of beliefs that may
even be worse than the pre-learning approximation. We then show that averaging
inaccurate beliefs, each obtained from belief propagation using model
parameters perturbed about some learned mean values, can achieve the
unbelievable marginals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0485</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0485</id><created>2011-06-02</created><authors><author><keyname>Kalai</keyname><forenames>Gil</forenames></author></authors><title>How Quantum Computers Fail: Quantum Codes, Correlations in Physical
  Systems, and Noise Accumulation</title><categories>quant-ph cs.CC</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The feasibility of computationally superior quantum computers is one of the
most exciting and clear-cut scientific questions of our time. The question
touches on fundamental issues regarding probability, physics, and
computability, as well as on exciting problems in experimental physics,
engineering, computer science, and mathematics. We propose three related
directions towards a negative answer. The first is a conjecture about physical
realizations of quantum codes, the second has to do with correlations in
stochastic physical systems, and the third proposes a model for quantum
evolutions when noise accumulates. The paper is dedicated to the memory of
Itamar Pitowsky.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0488</identifier>
 <datestamp>2011-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0488</id><created>2011-06-02</created><authors><author><keyname>Haija</keyname><forenames>Ahmad Abu Al</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>A Half-Duplex Cooperative Scheme with Partial Decode-Forward Relaying</title><categories>cs.IT math.IT</categories><comments>2011 IEEE International Symposium on Information Theory (ISIT 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a new cooperative communication scheme consisting
of two users in half-duplex mode communicating with one destination over a
discrete memoryless channel. The users encode messages in independent blocks
and divide the transmission of each block into 3 time slots with variable
durations. Cooperation is performed by partial decodeforward relaying over
these 3 time slots. During the first two time slots, each user alternatively
transmits and decodes, while during the last time slot, both users cooperate to
send information to the destination. An achievable rate region for this scheme
is derived using superposition encoding and joint maximum likelihood (ML)
decoding across the 3 time slots. An example of the Gaussian channel is treated
in detail and its achievable rate region is given explicitly. Results show that
the proposed half-duplex scheme achieves significantly larger rate region than
the classical multiple access channel and approaches the performance of a
full-duplex cooperative scheme as the inter-user channel quality increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0489</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0489</id><created>2011-06-02</created><updated>2011-06-16</updated><authors><author><keyname>Avci</keyname><forenames>S. N.</forenames></author><author><keyname>Hu</keyname><forenames>X.</forenames></author><author><keyname>Ayanoglu</keyname><forenames>E.</forenames></author></authors><title>Recovery from Link Failures in Networks with Arbitrary Topology via
  Diversity Coding</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link failures in wide area networks are common. To recover from such
failures, a number of methods such as SONET rings, protection cycles, and
source rerouting have been investigated. Two important considerations in such
approaches are the recovery time and the needed spare capacity to complete the
recovery. Usually, these techniques attempt to achieve a recovery time less
than 50 ms. In this paper we introduce an approach that provides link failure
recovery in a hitless manner, or without any appreciable delay. This is
achieved by means of a method called diversity coding. We present an algorithm
for the design of an overlay network to achieve recovery from single link
failures in arbitrary networks via diversity coding. This algorithm is designed
to minimize spare capacity for recovery. We compare the recovery time and spare
capacity performance of this algorithm against conventional techniques in terms
of recovery time, spare capacity, and a joint metric called Quality of Recovery
(QoR). QoR incorporates both the spare capacity percentages and worst case
recovery times. Based on these results, we conclude that the proposed technique
provides much shorter recovery times while achieving similar extra capacity, or
better QoR performance overall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0518</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0518</id><created>2011-06-02</created><updated>2011-06-13</updated><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author><author><keyname>Klivans</keyname><forenames>Adam</forenames></author><author><keyname>Kothari</keyname><forenames>Pravesh</forenames></author><author><keyname>Lee</keyname><forenames>Homin K.</forenames></author></authors><title>Submodular Functions Are Noise Stable</title><categories>cs.LG cs.CC cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that all non-negative submodular functions have high {\em
noise-stability}. As a consequence, we obtain a polynomial-time learning
algorithm for this class with respect to any product distribution on
$\{-1,1\}^n$ (for any constant accuracy parameter $\epsilon$). Our algorithm
also succeeds in the agnostic setting. Previous work on learning submodular
functions required either query access or strong assumptions about the types of
submodular functions to be learned (and did not hold in the agnostic setting).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0519</identifier>
 <datestamp>2014-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0519</id><created>2011-06-02</created><updated>2014-10-26</updated><authors><author><keyname>Cai</keyname><forenames>Yang</forenames></author><author><keyname>Daskalakis</keyname><forenames>Constantinos</forenames></author></authors><title>Extreme-Value Theorems for Optimal Multidimensional Pricing</title><categories>cs.GT cs.DS</categories><comments>58 pages, 2 figure, Appeared in FOCS 2011 and accepted to Games and
  Economics Behavior</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a near-optimal, computationally efficient algorithm for the
unit-demand pricing problem, where a seller wants to price n items to optimize
revenue against a unit-demand buyer whose values for the items are
independently drawn from known distributions. For any chosen accuracy eps&gt;0 and
item values bounded in [0,1], our algorithm achieves revenue that is optimal up
to an additive error of at most eps, in polynomial time. For values sampled
from Monotone Hazard Rate (MHR) distributions, we achieve a (1-eps)-fraction of
the optimal revenue in polynomial time, while for values sampled from regular
distributions the same revenue guarantees are achieved in quasi-polynomial
time.
  Our algorithm for bounded distributions applies probabilistic techniques to
understand the statistical properties of revenue distributions, obtaining a
reduction in the search space of the algorithm via dynamic programming.
Adapting this approach to MHR and regular distributions requires the proof of
novel extreme value theorems for such distributions.
  As a byproduct, our techniques establish structural properties of
approximately-optimal and near-optimal solutions. We show that, for values
independently distributed according to MHR distributions, pricing all items at
the same price achieves a constant fraction of the optimal revenue. Moreover,
for all eps &gt;0, g(1/eps) distinct prices suffice to obtain a (1-eps)-fraction
of the optimal revenue, where g(1/eps) is quadratic in 1/eps and independent of
n. Similarly, for all eps&gt;0 and n&gt;0, at most g(1/(eps log n)) distinct prices
suffice if the values are independently distributed according to regular
distributions, where g() is a polynomial function. Finally, when the values are
i.i.d. from some MHR distribution, we show that, if n is a sufficiently large
function of 1/eps, a single price suffices to achieve a (1-eps)-fraction of the
optimal revenue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0541</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0541</id><created>2011-06-02</created><authors><author><keyname>Seong-Ho</keyname><affiliation>Paul</affiliation></author><author><keyname>Hur</keyname></author><author><keyname>Rao</keyname><forenames>Bhaskar D.</forenames></author></authors><title>Sum rate analysis of a reduced feedback OFDMA system employing joint
  scheduling and diversity</title><categories>cs.IT math.IT</categories><comments>In revision for IEEE Trans. Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider joint scheduling and diversity to enhance the benefits of
multiuser diversity in an \OFDMA{} system. The \OFDMA{} spectrum is assumed to
consist of $\Nrb$ resource blocks and the reduced feedback scheme consists of
each user feeding back channel quality information (\CQI) for only the
best-$\NFb$ resource blocks. Assuming largest normalized \CQI{} scheduling and
a general value for $\NFb$, we develop a unified framework to analyze the sum
rate of the system for both the quantized and non-quantized \CQI{} feedback
schemes. Based on this framework, we provide closed-form expressions for the
sum rate for three different multi-antenna transmitter schemes; Transmit
antenna selection (\TAS), orthogonal space time block codes (\OSTBC) and cyclic
delay diversity (\CDD). Furthermore, we approximate the sum rate expression and
determine the feedback ratio $(\frac{\NFb}{\Nrb})$ required to achieve a sum
rate comparable to the sum rate obtained by a full feedback scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0547</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0547</id><created>2011-06-02</created><authors><author><keyname>Humi</keyname><forenames>Mayer</forenames></author></authors><title>A Modified EMD Algorithm and its Applications</title><categories>math.NA cs.NA physics.data-an</categories><comments>To be presented at &quot;The 2011 International Conference on Scientific
  Computing (CSC'11)&quot; Las-Vegas Nevada July 17-21, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical EMD algorithm has been used extensively in the literature to
decompose signals that contain nonlinear waves. However when a signal contain
two or more frequencies that are close to one another the decomposition might
fail. In this paper we propose a new formulation of this algorithm which is
based on the zero crossings of the signal and show that it performs well even
when the classical algorithm fail. We address also the filtering properties and
convergence rate of the new algorithm versus the classical EMD algorithm. These
properties are compared then to those of the principal component algorithm
(PCA). Finally we apply this algorithm to the detection of gravity waves in the
atmosphere.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0560</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0560</id><created>2011-06-03</created><authors><author><keyname>Bagrow</keyname><forenames>James P.</forenames></author><author><keyname>Wang</keyname><forenames>Dashun</forenames></author><author><keyname>Barab&#xe1;si</keyname><forenames>Albert-L&#xe1;szl&#xf3;</forenames></author></authors><title>Collective response of human populations to large-scale emergencies</title><categories>physics.soc-ph cs.SI physics.data-an</categories><journal-ref>PLoS ONE 6(3): e17680, 2011</journal-ref><doi>10.1371/journal.pone.0017680</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite recent advances in uncovering the quantitative features of stationary
human activity patterns, many applications, from pandemic prediction to
emergency response, require an understanding of how these patterns change when
the population encounters unfamiliar conditions. To explore societal response
to external perturbations we identified real-time changes in communication and
mobility patterns in the vicinity of eight emergencies, such as bomb attacks
and earthquakes, comparing these with eight non-emergencies, like concerts and
sporting events. We find that communication spikes accompanying emergencies are
both spatially and temporally localized, but information about emergencies
spreads globally, resulting in communication avalanches that engage in a
significant manner the social network of eyewitnesses. These results offer a
quantitative view of behavioral changes in human activity under extreme
conditions, with potential long-term impact on emergency detection and
response.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0566</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0566</id><created>2011-06-03</created><authors><author><keyname>Chen</keyname><forenames>Tianshi</forenames></author><author><keyname>Chen</keyname><forenames>Yunji</forenames></author><author><keyname>Tang</keyname><forenames>Ke</forenames></author><author><keyname>Chen</keyname><forenames>Guoliang</forenames></author><author><keyname>Yao</keyname><forenames>Xin</forenames></author></authors><title>The Impact of Mutation Rate on the Computation Time of Evolutionary
  Dynamic Optimization</title><categories>cs.AI cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mutation has traditionally been regarded as an important operator in
evolutionary algorithms. In particular, there have been many experimental
studies which showed the effectiveness of adapting mutation rates for various
static optimization problems. Given the perceived effectiveness of adaptive and
self-adaptive mutation for static optimization problems, there have been
speculations that adaptive and self-adaptive mutation can benefit dynamic
optimization problems even more since adaptation and self-adaptation are
capable of following a dynamic environment. However, few theoretical results
are available in analyzing rigorously evolutionary algorithms for dynamic
optimization problems. It is unclear when adaptive and self-adaptive mutation
rates are likely to be useful for evolutionary algorithms in solving dynamic
optimization problems. This paper provides the first rigorous analysis of
adaptive mutation and its impact on the computation times of evolutionary
algorithms in solving certain dynamic optimization problems. More specifically,
for both individual-based and population-based EAs, we have shown that any
time-variable mutation rate scheme will not significantly outperform a fixed
mutation rate on some dynamic optimization problem instances. The proofs also
offer some insights into conditions under which any time-variable mutation
scheme is unlikely to be useful and into the relationships between the problem
characteristics and algorithmic features (e.g., different mutation schemes).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0572</identifier>
 <datestamp>2011-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0572</id><created>2011-06-03</created><updated>2011-06-22</updated><authors><author><keyname>Bebel</keyname><forenames>Joseph</forenames></author><author><keyname>Yuen</keyname><forenames>Henry</forenames></author></authors><title>BQP_p = PP for integer p &gt; 2</title><categories>quant-ph cs.CC</categories><comments>This paper has been withdrawn by the authors due to the fact that
  strong error reduction for BQP_p problems is significantly more subtle than
  demonstrated, which compromises the main result</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There's something really strange about quantum mechanics. It's not just that
cats can be dead and alive at the same time, and that entanglement seems to
violate the principle of locality; quantum mechanics seems to be what Aaronson
calls &quot;an island in theoryspace&quot;, because even slight perturbations to the
theory of quantum mechanics seem to generate absurdities. In [Aar 04] and [Aar
05], he explores these perturbations and the corresponding absurdities in the
context of computation. In particular, he shows that a quantum theory where the
measurement probabilities are computed using p-norm instead of the standard
2-norm has the effect of blowing up the class BQP (the class of problems that
can be efficiently solved on a quantum computer) to at least PP (the class of
problems that can be solved in probabilistic polynomial time). He showed that
PP \subseteq BQP_p \subseteq PSPACE for all constants p != 2, and that BQP_p =
PP for even integers p &gt; 2. Here, we show that this equality holds for all
integers p &gt; 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0596</identifier>
 <datestamp>2011-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0596</id><created>2011-06-03</created><authors><author><keyname>Piccardi</keyname><forenames>Carlo</forenames></author></authors><title>Finding and testing network communities by lumped Markov chains</title><categories>physics.soc-ph cs.SI</categories><journal-ref>PLoS ONE 6(11): e27028, 2011</journal-ref><doi>10.1371/journal.pone.0027028</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Identifying communities (or clusters), namely groups of nodes with
comparatively strong internal connectivity, is a fundamental task for deeply
understanding the structure and function of a network. Yet, there is a lack of
formal criteria for defining communities and for testing their significance. We
propose a sharp definition which is based on a significance threshold. By means
of a lumped Markov chain model of a random walker, a quality measure called
&quot;persistence probability&quot; is associated to a cluster. Then the cluster is
defined as an &quot;$\alpha$-community&quot; if such a probability is not smaller than
$\alpha$. Consistently, a partition composed of $\alpha$-communities is an
&quot;$\alpha$-partition&quot;. These definitions turn out to be very effective for
finding and testing communities. If a set of candidate partitions is available,
setting the desired $\alpha$-level allows one to immediately select the
$\alpha$-partition with the finest decomposition. Simultaneously, the
persistence probabilities quantify the significance of each single community.
Given its ability in individually assessing the quality of each cluster, this
approach can also disclose single well-defined communities even in networks
which overall do not possess a definite clusterized structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0599</identifier>
 <datestamp>2014-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0599</id><created>2011-06-03</created><updated>2011-06-17</updated><authors><author><keyname>Fan</keyname><forenames>Chao</forenames></author><author><keyname>Guo</keyname><forenames>Jin-Li</forenames></author></authors><title>Research on the visitor flow pattern of Expo 2010</title><categories>physics.soc-ph cs.SI stat.AP</categories><comments>12 pages</comments><journal-ref>Chin. Phys. B 2012 21(7) 070209</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Expo 2010 Shanghai China was a successful, splendid and unforgettable event,
remaining us with valuable experiences. The visitor flow pattern of Expo is
investigated in this paper. The Hurst exponent, mean value and standard
deviation of visitor volume prove that the visitor flow is fractal with
long-term stability and correlation as well as obvious fluctuation in short
period. Then the time series of visitor volume is converted to complex network
by visibility algorithm. It can be inferred from the topological properties of
the visibility graph that the network is scale-free, small-world and
hierarchically constructed, conforming that the time series are fractal and
close relationship exit between the visitor volume on different days.
Furthermore, it is inevitable to show some extreme visitor volume in the
original visitor flow, and these extreme points may appear in group to a great
extent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0622</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0622</id><created>2011-06-03</created><updated>2011-09-16</updated><authors><author><keyname>Vierling</keyname><forenames>Morten</forenames></author></authors><title>Control-constrained parabolic optimal control problems on evolving
  surfaces - theory and variational discretization</title><categories>math.OC cs.SY math.AP math.NA</categories><report-no>HBAM 2011-10</report-no><msc-class>58J35, 49J20, 49Q99, 35D30, 35R01</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider control-constrained linear-quadratic optimal control problems on
evolving surfaces. In order to formulate well-posed problems, we prove
existence and uniqueness of weak solutions for the state equation, in the sense
of vector-valued distributions. We then carry out and prove convergence of the
variational discretization of a distributed optimal control problem. In the
process, we investigate the convergence of a fully discrete approximation of
the state equation, and obtain optimal orders of convergence under weak
regularity assumptions. We conclude with a numerical example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0664</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0664</id><created>2011-06-03</created><authors><author><keyname>Cristani</keyname><forenames>M.</forenames></author></authors><title>The Complexity of Reasoning about Spatial Congruence</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 11, pages
  361-390, 1999</journal-ref><doi>10.1613/jair.641</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the recent literature of Artificial Intelligence, an intensive research
effort has been spent, for various algebras of qualitative relations used in
the representation of temporal and spatial knowledge, on the problem of
classifying the computational complexity of reasoning problems for subsets of
algebras. The main purpose of these researches is to describe a restricted set
of maximal tractable subalgebras, ideally in an exhaustive fashion with respect
to the hosting algebras. In this paper we introduce a novel algebra for
reasoning about Spatial Congruence, show that the satisfiability problem in the
spatial algebra MC-4 is NP-complete, and present a complete classification of
tractability in the algebra, based on the individuation of three maximal
tractable subclasses, one containing the basic relations. The three algebras
are formed by 14, 10 and 9 relations out of 16 which form the full algebra.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0665</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0665</id><created>2011-06-03</created><authors><author><keyname>Bartlett</keyname><forenames>P. L.</forenames></author><author><keyname>Baxter</keyname><forenames>J.</forenames></author></authors><title>Infinite-Horizon Policy-Gradient Estimation</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  319-350, 2001</journal-ref><doi>10.1613/jair.806</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gradient-based approaches to direct policy search in reinforcement learning
have received much recent attention as a means to solve problems of partial
observability and to avoid some of the problems associated with policy
degradation in value-function methods. In this paper we introduce GPOMDP, a
simulation-based algorithm for generating a biased estimate of the gradient of
the average reward in Partially Observable Markov Decision Processes POMDPs
controlled by parameterized stochastic policies. A similar algorithm was
proposed by (Kimura et al. 1995). The algorithm's chief advantages are that it
requires storage of only twice the number of policy parameters, uses one free
beta (which has a natural interpretation in terms of bias-variance trade-off),
and requires no knowledge of the underlying state. We prove convergence of
GPOMDP, and show how the correct choice of the parameter beta is related to the
mixing time of the controlled POMDP. We briefly describe extensions of GPOMDP
to controlled Markov chains, continuous state, observation and control spaces,
multiple-agents, higher-order derivatives, and a version for training
stochastic policies with internal states. In a companion paper (Baxter et al.,
this volume) we show how the gradient estimates generated by GPOMDP can be used
in both a traditional stochastic gradient algorithm and a conjugate-gradient
procedure to find local optima of the average reward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0666</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0666</id><created>2011-06-03</created><authors><author><keyname>Bartlett</keyname><forenames>P. L.</forenames></author><author><keyname>Baxter</keyname><forenames>J.</forenames></author><author><keyname>Weaver</keyname><forenames>L.</forenames></author></authors><title>Experiments with Infinite-Horizon, Policy-Gradient Estimation</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  351-381, 2001</journal-ref><doi>10.1613/jair.807</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present algorithms that perform gradient ascent of the
average reward in a partially observable Markov decision process (POMDP). These
algorithms are based on GPOMDP, an algorithm introduced in a companion paper
(Baxter and Bartlett, this volume), which computes biased estimates of the
performance gradient in POMDPs. The algorithm's chief advantages are that it
uses only one free parameter beta, which has a natural interpretation in terms
of bias-variance trade-off, it requires no knowledge of the underlying state,
and it can be applied to infinite state, control and observation spaces. We
show how the gradient estimates produced by GPOMDP can be used to perform
gradient ascent, both with a traditional stochastic-gradient algorithm, and
with an algorithm based on conjugate-gradients that utilizes gradient
information to bracket maxima in line searches. Experimental results are
presented illustrating both the theoretical results of (Baxter and Bartlett,
this volume) on a toy problem, and practical aspects of the algorithms on a
number of more realistic problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0667</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0667</id><created>2011-06-03</created><authors><author><keyname>Straccia</keyname><forenames>U.</forenames></author></authors><title>Reasoning within Fuzzy Description Logics</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  137-166, 2001</journal-ref><doi>10.1613/jair.813</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Description Logics (DLs) are suitable, well-known, logics for managing
structured knowledge. They allow reasoning about individuals and well defined
concepts, i.e., set of individuals with common properties. The experience in
using DLs in applications has shown that in many cases we would like to extend
their capabilities. In particular, their use in the context of Multimedia
Information Retrieval (MIR) leads to the convincement that such DLs should
allow the treatment of the inherent imprecision in multimedia object content
representation and retrieval. In this paper we will present a fuzzy extension
of ALC, combining Zadeh's fuzzy logic with a classical DL. In particular,
concepts becomes fuzzy and, thus, reasoning about imprecise concepts is
supported. We will define its syntax, its semantics, describe its properties
and present a constraint propagation calculus for reasoning in it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0668</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0668</id><created>2011-06-03</created><authors><author><keyname>Elomaa</keyname><forenames>T.</forenames></author><author><keyname>Kaariainen</keyname><forenames>M.</forenames></author></authors><title>An Analysis of Reduced Error Pruning</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  163-187, 2001</journal-ref><doi>10.1613/jair.816</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Top-down induction of decision trees has been observed to suffer from the
inadequate functioning of the pruning phase. In particular, it is known that
the size of the resulting tree grows linearly with the sample size, even though
the accuracy of the tree does not improve. Reduced Error Pruning is an
algorithm that has been used as a representative technique in attempts to
explain the problems of decision tree learning. In this paper we present
analyses of Reduced Error Pruning in three different settings. First we study
the basic algorithmic properties of the method, properties that hold
independent of the input decision tree and pruning examples. Then we examine a
situation that intuitively should lead to the subtree under consideration to be
replaced by a leaf node, one in which the class label and attribute values of
the pruning examples are independent of each other. This analysis is conducted
under two different assumptions. The general analysis shows that the pruning
probability of a node fitting pure noise is bounded by a function that
decreases exponentially as the size of the tree grows. In a specific analysis
we assume that the examples are distributed uniformly to the tree. This
assumption lets us approximate the number of subtrees that are pruned because
they do not receive any pruning examples. This paper clarifies the different
variants of the Reduced Error Pruning algorithm, brings new insight to its
algorithmic properties, analyses the algorithm with less imposed assumptions
than before, and includes the previously overlooked empty subtrees to the
analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0669</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0669</id><created>2011-06-03</created><authors><author><keyname>Ginsberg</keyname><forenames>M. L.</forenames></author></authors><title>GIB: Imperfect Information in a Computationally Challenging Game</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  303-358, 2001</journal-ref><doi>10.1613/jair.820</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the problems arising in the construction of a program
to play the game of contract bridge. These problems include both the difficulty
of solving the game's perfect information variant, and techniques needed to
address the fact that bridge is not, in fact, a perfect information game. GIB,
the program being described, involves five separate technical advances:
partition search, the practical application of Monte Carlo techniques to
realistic problems, a focus on achievable sets to solve problems inherent in
the Monte Carlo approach, an extension of alpha-beta pruning from total orders
to arbitrary distributive lattices, and the use of squeaky wheel optimization
to find approximately optimal solutions to cardplay problems. GIB is currently
believed to be of approximately expert caliber, and is currently the strongest
computer bridge program in the world.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0671</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0671</id><created>2011-06-03</created><authors><author><keyname>Bessiere</keyname><forenames>C.</forenames></author><author><keyname>Debruyne</keyname><forenames>R.</forenames></author></authors><title>Domain Filtering Consistencies</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  205-230, 2001</journal-ref><doi>10.1613/jair.834</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Enforcing local consistencies is one of the main features of constraint
reasoning. Which level of local consistency should be used when searching for
solutions in a constraint network is a basic question. Arc consistency and
partial forms of arc consistency have been widely studied, and have been known
for sometime through the forward checking or the MAC search algorithms. Until
recently, stronger forms of local consistency remained limited to those that
change the structure of the constraint graph, and thus, could not be used in
practice, especially on large networks. This paper focuses on the local
consistencies that are stronger than arc consistency, without changing the
structure of the network, i.e., only removing inconsistent values from the
domains. In the last five years, several such local consistencies have been
proposed by us or by others. We make an overview of all of them, and highlight
some relations between them. We compare them both theoretically and
experimentally, considering their pruning efficiency and the time required to
enforce them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0672</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0672</id><created>2011-06-03</created><authors><author><keyname>Bui</keyname><forenames>H. H.</forenames></author><author><keyname>Venkatesh</keyname><forenames>S.</forenames></author><author><keyname>West</keyname><forenames>G.</forenames></author></authors><title>Policy Recognition in the Abstract Hidden Markov Model</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 17, pages
  451-499, 2002</journal-ref><doi>10.1613/jair.839</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a method for recognising an agent's behaviour in
dynamic, noisy, uncertain domains, and across multiple levels of abstraction.
We term this problem on-line plan recognition under uncertainty and view it
generally as probabilistic inference on the stochastic process representing the
execution of the agent's plan. Our contributions in this paper are twofold. In
terms of probabilistic inference, we introduce the Abstract Hidden Markov Model
(AHMM), a novel type of stochastic processes, provide its dynamic Bayesian
network (DBN) structure and analyse the properties of this network. We then
describe an application of the Rao-Blackwellised Particle Filter to the AHMM
which allows us to construct an efficient, hybrid inference method for this
model. In terms of plan recognition, we propose a novel plan recognition
framework based on the AHMM as the plan execution model. The Rao-Blackwellised
hybrid inference for AHMM can take advantage of the independence properties
inherent in a model of plan execution, leading to an algorithm for online
probabilistic plan recognition that scales well with the number of levels in
the plan hierarchy. This illustrates that while stochastic models for plan
execution can be complex, they exhibit special structures which, if exploited,
can lead to efficient plan recognition algorithms. We demonstrate the
usefulness of the AHMM framework via a behaviour recognition system in a
complex spatial environment using distributed video surveillance data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0673</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0673</id><created>2011-06-03</created><authors><author><keyname>Martinez-Barco</keyname><forenames>P.</forenames></author><author><keyname>Palomar</keyname><forenames>M.</forenames></author></authors><title>Computational Approach to Anaphora Resolution in Spanish Dialogues</title><categories>cs.CL</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  263-287, 2001</journal-ref><doi>10.1613/jair.848</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an algorithm for identifying noun-phrase antecedents of
pronouns and adjectival anaphors in Spanish dialogues. We believe that anaphora
resolution requires numerous sources of information in order to find the
correct antecedent of the anaphor. These sources can be of different kinds,
e.g., linguistic information, discourse/dialogue structure information, or
topic information. For this reason, our algorithm uses various different kinds
of information (hybrid information). The algorithm is based on linguistic
constraints and preferences and uses an anaphoric accessibility space within
which the algorithm finds the noun phrase. We present some experiments related
to this algorithm and this space using a corpus of 204 dialogues. The algorithm
is implemented in Prolog. According to this study, 95.9% of antecedents were
located in the proposed space, a precision of 81.3% was obtained for pronominal
anaphora resolution, and 81.5% for adjectival anaphora.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0675</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0675</id><created>2011-06-03</created><authors><author><keyname>Hoffmann</keyname><forenames>J.</forenames></author><author><keyname>Nebel</keyname><forenames>B.</forenames></author></authors><title>The FF Planning System: Fast Plan Generation Through Heuristic Search</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 14, pages
  253-302, 2001</journal-ref><doi>10.1613/jair.855</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe and evaluate the algorithmic techniques that are used in the FF
planning system. Like the HSP system, FF relies on forward state space search,
using a heuristic that estimates goal distances by ignoring delete lists.
Unlike HSP's heuristic, our method does not assume facts to be independent. We
introduce a novel search strategy that combines hill-climbing with systematic
search, and we show how other powerful heuristic information can be extracted
and used to prune the search space. FF was the most successful automatic
planner at the recent AIPS-2000 planning competition. We review the results of
the competition, give data for other benchmark domains, and investigate the
reasons for the runtime performance of FF compared to HSP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0676</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0676</id><created>2011-06-03</created><authors><author><keyname>Kearns</keyname><forenames>M.</forenames></author><author><keyname>Litman</keyname><forenames>D.</forenames></author><author><keyname>Singh</keyname><forenames>S.</forenames></author><author><keyname>Walker</keyname><forenames>M.</forenames></author></authors><title>Optimizing Dialogue Management with Reinforcement Learning: Experiments
  with the NJFun System</title><categories>cs.LG cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 16, pages
  105-133, 2002</journal-ref><doi>10.1613/jair.859</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Designing the dialogue policy of a spoken dialogue system involves many
nontrivial choices. This paper presents a reinforcement learning approach for
automatically optimizing a dialogue policy, which addresses the technical
challenges in applying reinforcement learning to a working dialogue system with
human users. We report on the design, construction and empirical evaluation of
NJFun, an experimental spoken dialogue system that provides users with access
to information about fun things to do in New Jersey. Our results show that by
optimizing its performance via reinforcement learning, NJFun measurably
improves system performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0678</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0678</id><created>2011-06-03</created><authors><author><keyname>Kearns</keyname><forenames>M.</forenames></author><author><keyname>Littman</keyname><forenames>M. L.</forenames></author><author><keyname>Singh</keyname><forenames>S.</forenames></author><author><keyname>Stone</keyname><forenames>P.</forenames></author></authors><title>ATTac-2000: An Adaptive Autonomous Bidding Agent</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  189-206, 2001</journal-ref><doi>10.1613/jair.865</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The First Trading Agent Competition (TAC) was held from June 22nd to July
8th, 2000. TAC was designed to create a benchmark problem in the complex domain
of e-marketplaces and to motivate researchers to apply unique approaches to a
common task. This article describes ATTac-2000, the first-place finisher in
TAC. ATTac-2000 uses a principled bidding strategy that includes several
elements of adaptivity. In addition to the success at the competition, isolated
empirical results are presented indicating the robustness and effectiveness of
ATTac-2000's adaptive strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0679</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0679</id><created>2011-06-03</created><authors><author><keyname>Nebel</keyname><forenames>B.</forenames></author><author><keyname>Renz</keyname><forenames>J.</forenames></author></authors><title>Efficient Methods for Qualitative Spatial Reasoning</title><categories>cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 15, pages
  289-318, 2001</journal-ref><doi>10.1613/jair.872</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theoretical properties of qualitative spatial reasoning in the RCC8
framework have been analyzed extensively. However, no empirical investigation
has been made yet. Our experiments show that the adaption of the algorithms
used for qualitative temporal reasoning can solve large RCC8 instances, even if
they are in the phase transition region -- provided that one uses the maximal
tractable subsets of RCC8 that have been identified by us. In particular, we
demonstrate that the orthogonal combination of heuristic methods is successful
in solving almost all apparently hard instances in the phase transition region
up to a certain size in reasonable time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0680</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0680</id><created>2011-06-03</created><authors><author><keyname>Kaelbling</keyname><forenames>L. P.</forenames></author><author><keyname>Shatkay</keyname><forenames>H.</forenames></author></authors><title>Learning Geometrically-Constrained Hidden Markov Models for Robot
  Navigation: Bridging the Topological-Geometrical Gap</title><categories>cs.AI cs.RO</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 16, pages
  167-207, 2002</journal-ref><doi>10.1613/jair.874</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hidden Markov models (HMMs) and partially observable Markov decision
processes (POMDPs) provide useful tools for modeling dynamical systems. They
are particularly useful for representing the topology of environments such as
road networks and office buildings, which are typical for robot navigation and
planning. The work presented here describes a formal framework for
incorporating readily available odometric information and geometrical
constraints into both the models and the algorithm that learns them. By taking
advantage of such information, learning HMMs/POMDPs can be made to generate
better solutions and require fewer iterations, while being robust in the face
of data reduction. Experimental results, obtained from both simulated and real
robot data, demonstrate the effectiveness of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0681</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0681</id><created>2011-06-03</created><authors><author><keyname>Boutilier</keyname><forenames>C.</forenames></author><author><keyname>Price</keyname><forenames>B.</forenames></author></authors><title>Accelerating Reinforcement Learning through Implicit Imitation</title><categories>cs.LG cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 19, pages
  569-629, 2003</journal-ref><doi>10.1613/jair.898</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Imitation can be viewed as a means of enhancing learning in multiagent
environments. It augments an agent's ability to learn useful behaviors by
making intelligent use of the knowledge implicit in behaviors demonstrated by
cooperative teachers or other more experienced agents. We propose and study a
formal model of implicit imitation that can accelerate reinforcement learning
dramatically in certain cases. Roughly, by observing a mentor, a
reinforcement-learning agent can extract information about its own capabilities
in, and the relative value of, unvisited parts of the state space. We study two
specific instantiations of this model, one in which the learning agent and the
mentor have identical abilities, and one designed to deal with agents and
mentors with different action sets. We illustrate the benefits of implicit
imitation by integrating it with prioritized sweeping, and demonstrating
improved performance and convergence through observation of single and multiple
mentors. Though we make some stringent assumptions regarding observability and
possible interactions, we briefly comment on extensions of the model that relax
these restricitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0683</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0683</id><created>2011-06-03</created><updated>2011-10-01</updated><authors><author><keyname>Groff</keyname><forenames>Matt</forenames></author></authors><title>Towards P = NP via k-SAT: A k-SAT Algorithm Using Linear Algebra on
  Finite Fields</title><categories>cs.DS cs.CC</categories><comments>28 pages, 25 figures, 1 picture</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of P vs. NP is very serious, and solutions to the problem can
help save lives. This article is an attempt at solving the problem using a
computer algorithm. It is presented in a fashion that will hopefully allow for
easy understanding for many people and scientists from many diverse fields.
  In technical terms, a novel method for solving k-SAT is explained. This
method is primarily based on linear algebra and finite fields. Evidence is
given that this method may require rougly O(n^3) time and space for
deterministic models. More specifically the algorithm runs in time O(P
V(n+V)^2) with mistaking satisfiable Boolean expressions as unsatisfiable with
an approximate probablity 1 / \Theta(V(n+V)^2)^P, where n is the number of
clauses and V is the number of variables. It's concluded that significant
evidence exists that P=NP.
  There is a forum devoted to this paper at http://482527.ForumRomanum.com. All
are invited to correspond here and help with the analysis of the algorithm.
Source code for the associated algorithm can be found at
https://sourceforge.net/p/la3sat.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0706</identifier>
 <datestamp>2011-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0706</id><created>2011-06-03</created><updated>2011-08-29</updated><authors><author><keyname>Pavlovic</keyname><forenames>Dusko</forenames></author><author><keyname>Meadows</keyname><forenames>Catherine</forenames></author></authors><title>Actor-network procedures: Modeling multi-factor authentication, device
  pairing, social interactions</title><categories>cs.CR cs.CY cs.LO cs.SI</categories><comments>32 pages, 12 figures, 3 tables; journal submission; extended
  references, added discussion</comments><acm-class>D.4.6; D.4.4; K.6.5; K.4.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As computation spreads from computers to networks of computers, and migrates
into cyberspace, it ceases to be globally programmable, but it remains
programmable indirectly: network computations cannot be controlled, but they
can be steered by local constraints on network nodes. The tasks of
&quot;programming&quot; global behaviors through local constraints belong to the area of
security. The &quot;program particles&quot; that assure that a system of local
interactions leads towards some desired global goals are called security
protocols. As computation spreads beyond cyberspace, into physical and social
spaces, new security tasks and problems arise. As networks are extended by
physical sensors and controllers, including the humans, and interlaced with
social networks, the engineering concepts and techniques of computer security
blend with the social processes of security. These new connectors for
computational and social software require a new &quot;discipline of programming&quot; of
global behaviors through local constraints. Since the new discipline seems to
be emerging from a combination of established models of security protocols with
older methods of procedural programming, we use the name procedures for these
new connectors, that generalize protocols. In the present paper we propose
actor-networks as a formal model of computation in heterogenous networks of
computers, humans and their devices; and we introduce Procedure Derivation
Logic (PDL) as a framework for reasoning about security in actor-networks. On
the way, we survey the guiding ideas of Protocol Derivation Logic (also PDL)
that evolved through our work in security in last 10 years. Both formalisms are
geared towards graphic reasoning and tool support. We illustrate their workings
by analysing a popular form of two-factor authentication, and a multi-channel
device pairing procedure, devised for this occasion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0707</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0707</id><created>2011-06-03</created><authors><author><keyname>He</keyname><forenames>H.</forenames></author><author><keyname>Hu</keyname><forenames>D.</forenames></author><author><keyname>Xu</keyname><forenames>X.</forenames></author></authors><title>Efficient Reinforcement Learning Using Recursive Least-Squares Methods</title><categories>cs.LG cs.AI</categories><proxy>jair.org</proxy><journal-ref>Journal Of Artificial Intelligence Research, Volume 16, pages
  259-292, 2002</journal-ref><doi>10.1613/jair.946</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recursive least-squares (RLS) algorithm is one of the most well-known
algorithms used in adaptive filtering, system identification and adaptive
control. Its popularity is mainly due to its fast convergence speed, which is
considered to be optimal in practice. In this paper, RLS methods are used to
solve reinforcement learning problems, where two new reinforcement learning
algorithms using linear value function approximators are proposed and analyzed.
The two algorithms are called RLS-TD(lambda) and Fast-AHC (Fast Adaptive
Heuristic Critic), respectively. RLS-TD(lambda) can be viewed as the extension
of RLS-TD(0) from lambda=0 to general lambda within interval [0,1], so it is a
multi-step temporal-difference (TD) learning algorithm using RLS methods. The
convergence with probability one and the limit of convergence of RLS-TD(lambda)
are proved for ergodic Markov chains. Compared to the existing LS-TD(lambda)
algorithm, RLS-TD(lambda) has advantages in computation and is more suitable
for online learning. The effectiveness of RLS-TD(lambda) is analyzed and
verified by learning prediction experiments of Markov chains with a wide range
of parameter settings. The Fast-AHC algorithm is derived by applying the
proposed RLS-TD(lambda) algorithm in the critic network of the adaptive
heuristic critic method. Unlike conventional AHC algorithm, Fast-AHC makes use
of RLS methods to improve the learning-prediction efficiency in the critic.
Learning control experiments of the cart-pole balancing and the acrobot
swing-up problems are conducted to compare the data efficiency of Fast-AHC with
conventional AHC. From the experimental results, it is shown that the data
efficiency of learning control can also be improved by using RLS methods in the
learning-prediction process of the critic. The performance of Fast-AHC is also
compared with that of the AHC method using LS-TD(lambda). Furthermore, it is
demonstrated in the experiments that different initial values of the variance
matrix in RLS-TD(lambda) are required to get better performance not only in
learning prediction but also in learning control. The experimental results are
analyzed based on the existing theoretical work on the transient phase of
forgetting factor RLS methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0708</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0708</id><created>2011-06-03</created><authors><author><keyname>Bourque</keyname><forenames>Fran&#xe7;ois-Alex</forenames></author><author><keyname>Nguyen</keyname><forenames>Bao U.</forenames></author></authors><title>Optimal Sensor Configurations for Rectangular Target Dectection</title><categories>math.OC cs.MA cs.RO cs.SY</categories><comments>6 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal search strategies where targets are observed at several different
angles are found. Targets are assumed to exhibit rectangular symmetry and have
a uniformly-distributed orientation. By rectangular symmetry, it is meant that
one side of a target is the mirror image of its opposite side. Finding an
optimal solution is generally a hard problem. Fortunately, symmetry principles
allow analytical and intuitive solutions to be found. One such optimal search
strategy consists of choosing n angles evenly separated on the half-circle and
leads to a lower bound of the probability of not detecting targets. As no prior
knowledge of the target orientation is required, such search strategies are
also robust, a desirable feature in search and detection missions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0718</identifier>
 <datestamp>2012-01-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0718</id><created>2011-06-03</created><updated>2012-01-05</updated><authors><author><keyname>Kumar</keyname><forenames>Arun</forenames></author><author><keyname>R&#xe9;</keyname><forenames>Christopher</forenames></author></authors><title>Probabilistic Management of OCR Data using an RDBMS</title><categories>cs.DB cs.DL cs.IR</categories><comments>41 pages including the appendix. Shorter version (without appendix)
  to appear as a full research paper in VLDB 2012</comments><report-no>vol5no4/p322_arunkumar_vldb2012</report-no><journal-ref>Proceedings of the VLDB Endowment (PVLDB), Vol. 5, No. 4, pp.
  322-333 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The digitization of scanned forms and documents is changing the data sources
that enterprises manage. To integrate these new data sources with enterprise
data, the current state-of-the-art approach is to convert the images to ASCII
text using optical character recognition (OCR) software and then to store the
resulting ASCII text in a relational database. The OCR problem is challenging,
and so the output of OCR often contains errors. In turn, queries on the output
of OCR may fail to retrieve relevant answers. State-of-the-art OCR programs,
e.g., the OCR powering Google Books, use a probabilistic model that captures
many alternatives during the OCR process. Only when the results of OCR are
stored in the database, do these approaches discard the uncertainty. In this
work, we propose to retain the probabilistic models produced by OCR process in
a relational database management system. A key technical challenge is that the
probabilistic data produced by OCR software is very large (a single book blows
up to 2GB from 400kB as ASCII). As a result, a baseline solution that
integrates these models with an RDBMS is over 1000x slower versus standard text
processing for single table select-project queries. However, many applications
may have quality-performance needs that are in between these two extremes of
ASCII and the complete model output by the OCR software. Thus, we propose a
novel approximation scheme called Staccato that allows a user to trade recall
for query performance. Additionally, we provide a formal analysis of our
scheme's properties, and describe how we integrate our scheme with
standard-RDBMS text indexing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0730</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0730</id><created>2011-06-03</created><authors><author><keyname>McDonald</keyname><forenames>Daniel J.</forenames></author><author><keyname>Shalizi</keyname><forenames>Cosma Rohilla</forenames></author><author><keyname>Schervish</keyname><forenames>Mark</forenames></author></authors><title>Risk bounds for time series without strong mixing</title><categories>stat.ML cs.LG</categories><comments>10 pages, 1 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to control the generalization error of time series models wherein
past values of the outcome are used to predict future values. The results are
based on a generalization of standard IID concentration inequalities to
dependent data. We show how these concentration inequalities behave under
different versions of dependence to provide some intuition for our methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0733</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0733</id><created>2011-06-03</created><authors><author><keyname>Li</keyname><forenames>Liangbin</forenames></author><author><keyname>Jafarkhani</keyname><forenames>Hamid</forenames></author></authors><title>Short-term Performance Limits of MIMO Systems with Side Information at
  the Transmitter</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental performance limits of space-time block code (STBC) designs
when perfect channel information is available at the transmitter (CSIT) are
studied in this report. With CSIT, the transmitter can perform various
techniques such as rate adaption, power allocation, or beamforming. Previously,
the exploration of these fundamental results assumed long-term constraints, for
example, channel codes can have infinite decoding delay, and power or rate is
normalized over infinite channel-uses. With long-term constraints, the
transmitter can operate at the rate lower than the instantaneous mutual
information and error-free transmission can be supported. In this report, we
focus on the performance limits of short-term behavior for STBC systems. We
assume that the system has block power constraint, block rate constraint, and
finite decoding delay. With these constraints, although the transmitter can
perform rate adaption, power control, or beamforming, we show that
decoding-error is unavoidable. In the high SNR regime, the diversity gain is
upperbounded by the product of the number of transmit antennas, receive
antennas, and independent fading block channels that messages spread over. In
other words, fading cannot be completely combatted with short-term constraints.
The proof is based on a sphere-packing argument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0735</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0735</id><created>2011-06-03</created><authors><author><keyname>Xue</keyname><forenames>Dongyue</forenames></author><author><keyname>Ekici</keyname><forenames>Eylem</forenames></author></authors><title>Cross-Layer Scheduling for Cooperative Multi-Hop Cognitive Radio
  Networks</title><categories>cs.NI</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper aims to design cross-layer optimal scheduling algorithms for
cooperative multi-hop Cognitive Radio Networks (CRNs), where secondary users
(SUs) assist primary user (PU)'s multi-hop transmissions and in return gain
authorization to access a share of the spectrum. We build two models for two
different types of PUs, corresponding to elastic and inelastic service classes.
For CRNs with elastic service, the PU maximizes its throughput while assigning
a time-share of the channel to SUs proportional to SUs' assistance. For the
inelastic case, the PU is guaranteed a minimum utility. The proposed algorithm
for elastic PU model can achieve arbitrarily close to the optimal PU
throughput, while the proposed algorithm for inelastic PU model can achieve
arbitrarily close to the optimal SU utility. Both algorithms provide
deterministic upper-bounds for PU queue backlogs. In addition, we show a
tradeoff between throughput/utility and PU's average end-to-end delay
upper-bounds for both algorithms. Furthermore, the algorithms work in both
backlogged as well as arbitrary arrival rate systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0736</identifier>
 <datestamp>2011-06-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0736</id><created>2011-06-03</created><authors><author><keyname>Yang</keyname><forenames>Lei</forenames></author><author><keyname>Sagduyu</keyname><forenames>Yalin E.</forenames></author><author><keyname>Zhang</keyname><forenames>Junshan</forenames></author><author><keyname>Li</keyname><forenames>Jason H.</forenames></author></authors><title>Distributed Stochastic Power Control in Ad-hoc Networks: A Nonconvex
  Case</title><categories>cs.DC</categories><comments>Contains 12 pages, 10 figures, and 2 tables; work submitted to IEEE
  Transactions on Mobile Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Utility-based power allocation in wireless ad-hoc networks is inherently
nonconvex because of the global coupling induced by the co-channel
interference. To tackle this challenge, we first show that the globally optimal
point lies on the boundary of the feasible region, which is utilized as a basis
to transform the utility maximization problem into an equivalent max-min
problem with more structure. By using extended duality theory, penalty
multipliers are introduced for penalizing the constraint violations, and the
minimum weighted utility maximization problem is then decomposed into
subproblems for individual users to devise a distributed stochastic power
control algorithm, where each user stochastically adjusts its target utility to
improve the total utility by simulated annealing. The proposed distributed
power control algorithm can guarantee global optimality at the cost of slow
convergence due to simulated annealing involved in the global optimization. The
geometric cooling scheme and suitable penalty parameters are used to improve
the convergence rate. Next, by integrating the stochastic power control
approach with the back-pressure algorithm, we develop a joint scheduling and
power allocation policy to stabilize the queueing systems. Finally, we
generalize the above distributed power control algorithms to multicast
communications, and show their global optimality for multicast traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0760</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0760</id><created>2011-06-03</created><authors><author><keyname>Winters</keyname><forenames>R. Michael</forenames><affiliation>College of Wooster</affiliation></author><author><keyname>Blaikie</keyname><forenames>Andrew</forenames><affiliation>College of Wooster</affiliation></author><author><keyname>O'Neil</keyname><forenames>Deva</forenames><affiliation>Bridgewater College</affiliation></author></authors><title>Simulating the Electroweak Phase Transition: Sonification of Bubble
  Nucleation</title><categories>cs.SD astro-ph.CO cs.MM</categories><comments>13 pages, 5 figures. To appear in Proc. ICAD 2011</comments><acm-class>H.5.2; H.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As an applicaton of sonification, a simulation of the early universe was
developed to portray a phase transition that occurred shortly after the Big
Bang. The Standard Model of particle physics postulates that a hypothetical
particle, the Higgs boson, is responsible for the breaking of the symmetry
between the electromagnetic force and the weak force. This phase transition may
have been responsible for triggering Baryogenesis, the generation of an
abundance of matter over anti-matter. This hypothesis is known as Electroweak
Baryogenesis. In this simulation, aspects of bubble nucleation in Standard
Model Electroweak Baryogenesis were examined and modeled using Mathematica, and
sonified using SuperCollider3. The resulting simulation, which has been used
for pedagogical purposes by one of the authors, suggests interesting
possibilities for the integration of science and aesthetics as well as auditory
perception. The sonification component in particular also had the unexpected
benefit of being useful in debugging the Mathematica code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0776</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0776</id><created>2011-06-03</created><authors><author><keyname>Nieves</keyname><forenames>Juan Carlos</forenames></author><author><keyname>Osorio</keyname><forenames>Mauricio</forenames></author><author><keyname>Cort&#xe9;s</keyname><forenames>Ulises</forenames></author></authors><title>Semantics for Possibilistic Disjunctive Programs</title><categories>cs.AI cs.LO cs.PL</categories><comments>37 pages, 5 figures. To appear in Theory and Practice of Logic
  Programming (TPLP)</comments><msc-class>68T37 Reasoning under uncertainty</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, a possibilistic disjunctive logic programming approach for
modeling uncertain, incomplete and inconsistent information is defined. This
approach introduces the use of possibilistic disjunctive clauses which are able
to capture incomplete information and incomplete states of a knowledge base at
the same time.
  By considering a possibilistic logic program as a possibilistic logic theory,
a construction of a possibilistic logic programming semantic based on answer
sets and the proof theory of possibilistic logic is defined. It shows that this
possibilistic semantics for disjunctive logic programs can be characterized by
a fixed-point operator. It is also shown that the suggested possibilistic
semantics can be computed by a resolution algorithm and the consideration of
optimal refutations from a possibilistic logic theory.
  In order to manage inconsistent possibilistic logic programs, a preference
criterion between inconsistent possibilistic models is defined; in addition,
the approach of cuts for restoring consistency of an inconsistent possibilistic
knowledge base is adopted. The approach is illustrated in a medical scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0778</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0778</id><created>2011-06-03</created><updated>2011-09-30</updated><authors><author><keyname>Friedmann</keyname><forenames>Oliver</forenames><affiliation>University of Munich</affiliation></author></authors><title>An Exponential Lower Bound for the Latest Deterministic Strategy
  Iteration Algorithms</title><categories>cs.GT</categories><proxy>LMCS</proxy><acm-class>F.2.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 3 (October 3,
  2011) lmcs:1026</journal-ref><doi>10.2168/LMCS-7(3:23)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new exponential lower bound for the two most popular
deterministic variants of the strategy improvement algorithms for solving
parity, mean payoff, discounted payoff and simple stochastic games. The first
variant improves every node in each step maximizing the current valuation
locally, whereas the second variant computes the globally optimal improvement
in each step. We outline families of games on which both variants require
exponentially many strategy iterations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0785</identifier>
 <datestamp>2013-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0785</id><created>2011-06-03</created><authors><author><keyname>Chen</keyname><forenames>Feng</forenames></author><author><keyname>Xu</keyname><forenames>Aiguo</forenames></author><author><keyname>Zhang</keyname><forenames>Guangcai</forenames></author><author><keyname>Li</keyname><forenames>Yingjun</forenames></author></authors><title>Prandtl number effects in MRT Lattice Boltzmann models for shocked and
  unshocked compressible fluids</title><categories>cond-mat.soft cs.NA nlin.CG physics.comp-ph</categories><comments>17 pages, 8 figures</comments><journal-ref>Theoretical and Applied Mechanics Letters 1, 052004 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For compressible fluids under shock wave reaction, we have proposed two
Multiple-Relaxation-Time (MRT) Lattice Boltzmann (LB) models [F. Chen, et al,
EPL \textbf{90} (2010) 54003; Phys. Lett. A \textbf{375} (2011) 2129.]. In this
paper, we construct a new MRT Lattice Boltzmann model which is not only for the
shocked compressible fluids, but also for the unshocked compressible fluids. To
make the model work for unshocked compressible fluids, a key step is to modify
the collision operators of energy flux so that the viscous coefficient in
momentum equation is consistent with that in energy equation even in the
unshocked system. The unnecessity of the modification for systems under strong
shock is analyzed. The model is validated by some well-known benchmark tests,
including (i) thermal Couette flow, (ii) Riemann problem, (iii)
Richtmyer-Meshkov instability. The first system is unshocked and the latter two
are shocked. In all the three systems, the Prandtl numbers effects are checked.
Satisfying agreements are obtained between new model results and analytical
ones or other numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0787</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0787</id><created>2011-06-04</created><authors><author><keyname>Li</keyname><forenames>Quan-Lin</forenames></author></authors><title>Super-Exponential Solution in Markovian Supermarket Models: Framework
  and Challenge</title><categories>cs.NI cs.PF math.CA math.PR</categories><comments>Randomized load balancing, supermarket model, matrix-analytic method,
  super-exponential solution, density-dependent jump Markov process, Batch
  Markovian Arrival Process (BMAP), phase-type (PH) distribution, fixed point</comments><msc-class>60J, 60-08, 90-08, 94A</msc-class><acm-class>C.2; C.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Marcel F. Neuts opened a key door in numerical computation of stochastic
models by means of phase-type (PH) distributions and Markovian arrival
processes (MAPs). To celebrate his 75th birthday, this paper reports a more
general framework of Markovian supermarket models, including a system of
differential equations for the fraction measure and a system of nonlinear
equations for the fixed point. To understand this framework heuristically, this
paper gives a detailed analysis for three important supermarket examples: M/G/1
type, GI/M/1 type and multiple choices, explains how to derive the system of
differential equations by means of density-dependent jump Markov processes, and
shows that the fixed point may be simply super-exponential through solving the
system of nonlinear equations. Note that supermarket models are a class of
complicated queueing systems and their analysis can not apply popular queueing
theory, it is necessary in the study of supermarket models to summarize such a
more general framework which enables us to focus on important research issues.
On this line, this paper develops matrix-analytical methods of Markovian
supermarket models. We hope this will be able to open a new avenue in
performance evaluation of supermarket models by means of matrix-analytical
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0793</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0793</id><created>2011-06-04</created><updated>2012-06-05</updated><authors><author><keyname>Vijay</keyname><forenames>Sujith</forenames></author></authors><title>Monochromatic Progressions in Random Colorings</title><categories>math.CO cs.DM</categories><comments>5 pages</comments><msc-class>11B25, 05D10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let N^{+}(k)= 2^{k/2} k^{3/2} f(k) and N^{-}(k)= 2^{k/2} k^{1/2} g(k) where
1=o(f(k)) and g(k)=o(1). We show that the probability of a random 2-coloring of
{1,2,...,N^{+}(k)} containing a monochromatic k-term arithmetic progression
approaches 1, and the probability of a random 2-coloring of {1,2,...,N^{-}(k)}
containing a monochromatic k-term arithmetic progression approaches 0, for
large k. This improves an upper bound due to Brown, who had established an
analogous result for N^{+}(k)= 2^k log k f(k).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0800</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0800</id><created>2011-06-04</created><updated>2011-10-14</updated><authors><author><keyname>Hennig</keyname><forenames>Philipp</forenames></author></authors><title>Optimal Reinforcement Learning for Gaussian Systems</title><categories>stat.ML cs.LG</categories><comments>final pre-conference version of this NIPS 2011 paper. Once again,
  please note some nontrivial changes to exposition and interpretation of the
  results, in particular in Equation (9) and Eqs. 11-14. The algorithm and
  results have remained the same, but their theoretical interpretation has
  changed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exploration-exploitation trade-off is among the central challenges of
reinforcement learning. The optimal Bayesian solution is intractable in
general. This paper studies to what extent analytic statements about optimal
learning are possible if all beliefs are Gaussian processes. A first order
approximation of learning of both loss and dynamics, for nonlinear,
time-varying systems in continuous time and space, subject to a relatively weak
restriction on the dynamics, is described by an infinite-dimensional partial
differential equation. An approximate finite-dimensional projection gives an
impression for how this result may be helpful.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0814</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0814</id><created>2011-06-04</created><authors><author><keyname>D'Agostino</keyname><forenames>Giovanna</forenames><affiliation>Universit&#xe0; degli Studi di Udine</affiliation></author><author><keyname>La Torre</keyname><forenames>Salvatore</forenames><affiliation>Universit&#xe0; degli Studi di Salerno</affiliation></author></authors><title>Proceedings of Second International Symposium on Games, Automata, Logics
  and Formal Verification</title><categories>cs.LO</categories><proxy>EPTCS</proxy><acm-class>F.4.1;F.4.3;F.1.1;D.2.4</acm-class><journal-ref>EPTCS 54, 2011</journal-ref><doi>10.4204/EPTCS.54</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the Proceedings of the Second International Symposium on
Games, Automata, Languages, and Formal Verification (GandALF 2011). The
conference was held in Minori (Amalfi Coast, Italy), from the 15th to the 17th
of June 2011. The aim of the GandALF Symposium is to provide a forum for
researchers from different areas and with different background, that share a
common interest in game theory, mathematical logic, automata theory, and their
applications to the specification, design, and verification of complex systems.
This proceedings contain the abstracts of three invited talks and nineteen
regular papers that have been selected through a rigorous reviewing process
according to originality, quality, and relevance to the topics of the
symposium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0823</identifier>
 <datestamp>2013-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0823</id><created>2011-06-04</created><updated>2012-07-19</updated><authors><author><keyname>Kupervasser</keyname><forenames>Oleg</forenames></author></authors><title>Recovering Epipolar Geometry from Images of Smooth Surfaces</title><categories>cs.CV cs.AI</categories><comments>accepted to &quot;Pattern Recognition and Image Analysis&quot; for publishing
  in 2013, 33 pages, 19 figures</comments><msc-class>68T45</msc-class><acm-class>E.5; E.4; E.2; H.1.1; F.1.1; F.1.3</acm-class><journal-ref>Pattern Recognition and Image Analysis, April 2013, Volume 23,
  Issue 2, pp 236-257</journal-ref><doi>10.1134/S1054661813020107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present four methods for recovering the epipolar geometry from images of
smooth surfaces. In the existing methods for recovering epipolar geometry
corresponding feature points are used that cannot be found in such images. The
first method is based on finding corresponding characteristic points created by
illumination (ICPM - illumination characteristic points' method (PM)). The
second method is based on correspondent tangency points created by tangents
from epipoles to outline of smooth bodies (OTPM - outline tangent PM). These
two methods are exact and give correct results for real images, because
positions of the corresponding illumination characteristic points and
corresponding outline are known with small errors. But the second method is
limited either to special type of scenes or to restricted camera motion. We
also consider two more methods which are termed CCPM (curve characteristic PM)
and CTPM (curve tangent PM), for searching epipolar geometry for images of
smooth bodies based on a set of level curves with constant illumination
intensity. The CCPM method is based on searching correspondent points on
isophoto curves with the help of correlation of curvatures between these lines.
The CTPM method is based on property of the tangential to isophoto curve
epipolar line to map into the tangential to correspondent isophoto curves
epipolar line. The standard method (SM) based on knowledge of pairs of the
almost exact correspondent points. The methods have been implemented and tested
by SM on pairs of real images. Unfortunately, the last two methods give us only
a finite subset of solutions including &quot;good&quot; solution. Exception is &quot;epipoles
in infinity&quot;. The main reason is inaccuracy of assumption of constant
brightness for smooth bodies. But outline and illumination characteristic
points are not influenced by this inaccuracy. So, the first pair of methods
gives exact results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0831</identifier>
 <datestamp>2013-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0831</id><created>2011-06-04</created><updated>2013-01-12</updated><authors><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Zhong</keyname><forenames>Xiaofeng</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-Hui</forenames></author><author><keyname>Zhou</keyname><forenames>Shidong</forenames></author><author><keyname>Wang</keyname><forenames>Jing</forenames></author><author><keyname>Chi</keyname><forenames>Chong-Yung</forenames></author></authors><title>Optimal Real-time Spectrum Sharing between Cooperative Relay and Ad-hoc
  Networks</title><categories>cs.IT math.IT</categories><comments>One typo in the caption of Figure 5 is corrected</comments><journal-ref>IEEE Transactions on Singal Processing, vol. 60, no. 4, pp.
  1971-1985, Apr. 2012</journal-ref><doi>10.1109/TSP.2011.2179651</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimization based spectrum sharing strategies have been widely studied.
However, these strategies usually require a great amount of real-time
computation and significant signaling delay, and thus are hard to be fulfilled
in practical scenarios. This paper investigates optimal real-time spectrum
sharing between a cooperative relay network (CRN) and a nearby ad-hoc network.
Specifically, we optimize the spectrum access and resource allocation
strategies of the CRN so that the average traffic collision time between the
two networks can be minimized while maintaining a required throughput for the
CRN. The development is first for a frame-level setting, and then is extended
to an ergodic setting. For the latter setting, we propose an appealing optimal
real-time spectrum sharing strategy via Lagrangian dual optimization. The
proposed method only involves a small amount of real-time computation and
negligible control delay, and thus is suitable for practical implementations.
Simulation results are presented to demonstrate the efficiency of the proposed
strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0833</identifier>
 <datestamp>2011-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0833</id><created>2011-06-04</created><authors><author><keyname>Gnedin</keyname><forenames>Alexander</forenames></author></authors><title>Dominance in the Monty Hall Problem</title><categories>math.HO cs.GT</categories><comments>http://www.springerlink.com/content/8402812734520774/fulltext.pdf</comments><journal-ref>The Mathematical Intelligencer (26 October 2011), pp. 1-8</journal-ref><doi>10.1007/s00283-011-9253-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Elementary decision-theoretic analysis of the Monty Hall dilemma shows that
the problem has dominance. This makes possible to discard nonswitching
strategies, without making any assumptions on the prior distribution of factors
out of control of the decision maker. A path to the Bayesian and the minimax
decision-making environments is then straightforward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0840</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0840</id><created>2011-06-04</created><updated>2011-06-23</updated><authors><author><keyname>Kwon</keyname><forenames>Taesoo</forenames></author><author><keyname>Cioffi</keyname><forenames>John. M.</forenames></author></authors><title>Random Deployment of Data Collectors for Serving Randomly-Located
  Sensors</title><categories>cs.NI</categories><comments>22 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, wireless communication industries have begun to extend their
services to machine-type communication devices as well as to user equipments.
Such machine-type communication devices as meters and sensors need intermittent
uplink resources to report measured or sensed data to their serving data
collector. It is however hard to dedicate limited uplink resources to each of
them. Thus, efficient service of a tremendous number of devices with low
activities may consider simple random access as a solution. The data collectors
receiving the measured data from many sensors simultaneously can successfully
decode only signals with signal-to-interference-plus-noise-ratio (SINR) above a
certain value. The main design issues for this environment become how many data
collectors are needed, how much power sensor nodes transmit with, and how
wireless channels affect the performance. This paper provides answers to those
questions through a stochastic analysis based on a spatial point process and on
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0843</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0843</id><created>2011-06-04</created><authors><author><keyname>Hadei</keyname><forenames>Sayed A.</forenames><affiliation>Student Member IEEE</affiliation></author><author><keyname>Azmi</keyname><forenames>Paeiz</forenames><affiliation>Senior Member, IEEE</affiliation></author></authors><title>A Novel Adaptive Channel Equalization Method Using Variable Step-Size
  Partial Rank Algorithm</title><categories>cs.IT cs.SD math.IT</categories><comments>6th Advance International Conference on Telecommunications (AICT2010)
  Barcelona, Spanish</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently a framework has been introduced within which a large number of
classical and modern adaptive filter algorithms can be viewed as special cases.
Variable Step-Size (VSS) normalized least mean square (VSSNLMS) and VSS Affine
Projection Algorithms (VSSAPA) are two particular examples of the adaptive
algorithms that can be covered by this generic adaptive filter. In this paper,
we introduce a new VSS Partial Rank (VSSPR) adaptive algorithm based on the
generic VSS adaptive filter and use it for channel equalization. The proposed
algorithm performs very well in attenuating noise and inter-symbol interference
(ISI) in comparison with the standard NLMS and the recently introduced AP
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0844</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0844</id><created>2011-06-04</created><authors><author><keyname>Hadei</keyname><forenames>Sayed A.</forenames><affiliation>Student Member, IEEE</affiliation></author><author><keyname>Sonbolestan</keyname><forenames>N.</forenames></author></authors><title>A Fast Affine Projection Algorithm Based on Matching Pursuit in Adaptive
  Noise Cancellation for Speech Enhancement</title><categories>cs.SD</categories><comments>2010 International Conference on Intelligent Systems, Modelling and
  Simulation, Liverpool, UK</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many application of noise cancellation, the changes in signal
characteristics could be quite fast. This requires the utilization of adaptive
algorithms, which converge rapidly. Least Mean Squares (LMS) adaptive filters
have been used in a wide range of signal processing application. The Recursive
Least Squares (RLS) algorithm has established itself as the &quot;ultimate&quot; adaptive
filtering algorithm in the sense that it is the adaptive filter exhibiting the
best convergence behavior. Unfortunately, practical implementations of the
algorithm are often associated with high computational complexity and/or poor
numerical properties. Recently adaptive filtering was presented that was based
on Matching Pursuits, have a nice tradeoff between complexity and the
convergence speed. This paper describes a new approach for noise cancellation
in speech enhancement using the new adaptive filtering algorithm named fast
affine projection algorithm (FAPA). The simulation results demonstrate the good
performance of the FAPA in attenuating the noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0846</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0846</id><created>2011-06-04</created><authors><author><keyname>Hadei</keyname><forenames>Sayed. A.</forenames><affiliation>Student Member IEEE</affiliation></author><author><keyname>lotfizad</keyname><forenames>M.</forenames></author></authors><title>A Family of Adaptive Filter Algorithms in Noise Cancellation for Speech
  Enhancement</title><categories>cs.SD</categories><comments>International Journal of Computer and Electrical Engineering, Vol. 2,
  No. 2, pp. 307-315, Apr. 2010. Singapore</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many application of noise cancellation, the changes in signal
characteristics could be quite fast. This requires the utilization of adaptive
algorithms, which converge rapidly. Least Mean Squares (LMS) and Normalized
Least Mean Squares (NLMS) adaptive filters have been used in a wide range of
signal processing application because of its simplicity in computation and
implementation. The Recursive Least Squares (RLS) algorithm has established
itself as the &quot;ultimate&quot; adaptive filtering algorithm in the sense that it is
the adaptive filter exhibiting the best convergence behavior. Unfortunately,
practical implementations of the algorithm are often associated with high
computational complexity and/or poor numerical properties. Recently adaptive
filtering was presented, have a nice tradeoff between complexity and the
convergence speed. This paper describes a new approach for noise cancellation
in speech enhancement using the two new adaptive filtering algorithms named
fast affine projection algorithm and fast Euclidean direction search algorithms
for attenuating noise in speech signals. The simulation results demonstrate the
good performance of the two new algorithms in attenuating the noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0851</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0851</id><created>2011-06-04</created><authors><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author><author><keyname>Xia</keyname><forenames>Yong</forenames></author></authors><title>A Dual Approach for Solving Nonlinear Infinite-Norm Minimization
  Problems with Applications in Separable Cases</title><categories>cs.CC</categories><comments>10 pages</comments><journal-ref>Numer. Math. J. Chinese Univ. (English Ser.), Issue 3, Vol. 16,
  pp. 265-270, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we focus on nonlinear infinite-norm minimization problems that
have many applications, especially in computer science and operations research.
We set a reliable Lagrangian dual aproach for solving this kind of problems in
general, and based on this method, we propose an algorithm for the mixed linear
and nonlinear infinite-norm minimization cases with numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0853</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0853</id><created>2011-06-04</created><authors><author><keyname>Gharibi</keyname><forenames>Wajeb</forenames></author></authors><title>Studying and Classification of the Most Significant Malicious Software</title><categories>cs.CR</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the cost of information processing and Internet accessibility falls, most
organizations are becoming increasingly vulnerable to potential cyber threats
which its rate has been dramatically increasing every year in recent times. In
this paper, we study, discuss and classify the most significant malicious
software: viruses, Trojans, worms, adware and pornware which have made step
forward in the science of Virology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0855</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0855</id><created>2011-06-04</created><updated>2011-07-24</updated><authors><author><keyname>Ackerman</keyname><forenames>Eyal</forenames></author><author><keyname>Gelander</keyname><forenames>Tsachik</forenames></author><author><keyname>Pinchasi</keyname><forenames>Rom</forenames></author></authors><title>Ice-Creams and Wedge Graphs</title><categories>cs.CG</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  What is the minimum angle $\alpha &gt;0$ such that given any set of
$\alpha$-directional antennas (that is, antennas each of which can communicate
along a wedge of angle $\alpha$), one can always assign a direction to each
antenna such that the resulting communication graph is connected? Here two
antennas are connected by an edge if and only if each lies in the wedge
assigned to the other. This problem was recently presented by Carmi, Katz,
Lotker, and Ros\'en \cite{CKLR10} who also found the minimum such $\alpha$
namely $\alpha=\frac{\pi}{3}$. In this paper we give a simple proof of this
result. Moreover, we obtain a much stronger and optimal result (see Theorem
\ref{theorem:main}) saying in particular that one can chose the directions of
the antennas so that the communication graph has diameter $\le 4$.
  Our main tool is a surprisingly basic geometric lemma that is of independent
interest. We show that for every compact convex set $S$ in the plane and every
$0 &lt; \alpha &lt; \pi$, there exist a point $O$ and two supporting lines to $S$
passing through $O$ and touching $S$ at two \emph{single points} $X$ and $Y$,
respectively, such that $|OX|=|OY|$ and the angle between the two lines is
$\alpha$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0868</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0868</id><created>2011-06-04</created><authors><author><keyname>Tahat</keyname><forenames>Amani</forenames></author><author><keyname>Tahat</keyname><forenames>Mofleh</forenames></author></authors><title>Python GUI Scripting Interface for Running Atomic Physics Applications</title><categories>cs.HC</categories><comments>7 pages, 2 figures</comments><journal-ref>The Python Papers Source Codes 3: 2, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We create a Python GUI scripting interface working under Windows in addition
to (UNIX/Linux). The GUI has been built around the Python open-source
programming language. We use the Python's GUI library that so called Python
Mega Widgets (PMW) and based on Tkinter Python module
(http://www.freenetpages.co.uk/hp/alan.gauld/tutgui.htm). The new GUI was
motivated primarily by the desire of more updated operations, more flexibility
incorporating future and current improvements in producing atomic data.
Furthermore it will be useful for a variety of applications of atomic physics,
plasma physics and astrophysics and will help in calculating various atomic
properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0869</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0869</id><created>2011-06-04</created><authors><author><keyname>Varma</keyname><forenames>Vineeth S</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Elayoubi</keyname><forenames>Salah Eddine</forenames></author></authors><title>Impact of Mobility on MIMO Green Wireless Systems</title><categories>cs.IT math.IT</categories><comments>Accepted for EUSIPCO conference. 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the impact of mobility on the power consumption of
wireless networks. With increasing mobility, we show that the network should
dedicate a non negligible fraction of the useful rate to estimate the different
degrees of freedom. In order to keep the rate constant, we quantify the
increase of power required for several cases of interest. In the case of a
point to point MIMO link, we calculate the minimum transmit power required for
a target rate and outage probability as a function of the coherence time and
the number of antennas. Interestingly, the results show that there is an
optimal number of antennas to be used for a given coherence time and power
consumption. This provides a lower bound limit on the minimum power required
for maintaining a green network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0870</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0870</id><created>2011-06-04</created><authors><author><keyname>Dai</keyname><forenames>Xiongping</forenames></author></authors><title>The finite-step realizability of the joint spectral radius of a pair of
  $d\times d$ matrices one of which being rank-one</title><categories>math.OC cs.SY math.DS</categories><comments>14 pages, 61 bibliography references</comments><msc-class>Primary 15B52, Secondary 15A60, 93D20, 65F15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the finite-step realizability of the joint/generalized spectral
radius of a pair of real $d\times d$ matrices, one of which has rank 1. Then we
prove that there always exists a finite-length word for which there holds the
spectral finiteness property for the set of matrices under consideration. This
implies that stability is algorithmically decidable in our case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0872</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0872</id><created>2011-06-05</created><authors><author><keyname>Kanovsky</keyname><forenames>Igor</forenames></author><author><keyname>Yaary</keyname><forenames>Omer</forenames></author></authors><title>Model of Opinion Spreading in Social Networks</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposed a new model, which capture the main difference between
information and opinion spreading. In information spreading additional exposure
to certain information has a small effect. Contrary, when an actor is exposed
to 2 opinioned actors the probability to adopt the opinion is significant
higher than in the case of contact with one such actor (called by J. Kleinberg
&quot;the 0-1-2 effect&quot;). In each time step if an actor does not have an opinion, we
randomly choose 2 his network neighbors. If one of them has an opinion, the
actor adopts opinion with some low probability, if two - with a higher
probability. Opinion spreading was simulated on different real world social
networks and similar random scale-free networks. The results show that small
world structure has a crucial impact on tipping point time. The &quot;0-1-2&quot; effect
causes a significant difference between ability of the actors to start opinion
spreading. Actor is an influencer according to his topological position in the
network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0874</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0874</id><created>2011-06-05</created><authors><author><keyname>Shutters</keyname><forenames>Brad</forenames></author><author><keyname>Fern&#xe1;ndez-Baca</keyname><forenames>David</forenames></author></authors><title>A Simple Characterization of the Minimal Obstruction Sets for
  Three-State Perfect Phylogenies</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lam, Gusfield, and Sridhar (2009) showed that a set of three-state characters
has a perfect phylogeny if and only if every subset of three characters has a
perfect phylogeny. They also gave a complete characterization of the sets of
three three-state characters that do not have a perfect phylogeny. However, it
is not clear from their characterization how to find a subset of three
characters that does not have a perfect phylogeny without testing all triples
of characters. In this note, we build upon their result by giving a simple
characterization of when a set of three-state characters does not have a
perfect phylogeny that can be inferred from testing all pairs of characters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0880</identifier>
 <datestamp>2012-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0880</id><created>2011-06-05</created><updated>2012-02-07</updated><authors><author><keyname>Shokri</keyname><forenames>Hossein</forenames></author><author><keyname>Mozaffari</keyname><forenames>Mohammad</forenames></author><author><keyname>Gavili</keyname><forenames>Adnan</forenames></author><author><keyname>Nasiri-Kenari</keyname><forenames>Masoumeh</forenames></author></authors><title>Performance Analysis of Sequential Method for HandOver in Cognitive
  Radio Networks</title><categories>cs.PF</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to a crucial problem in Lemma
3. This equation must be changed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0895</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0895</id><created>2011-06-05</created><authors><author><keyname>Naiss</keyname><forenames>Iddo</forenames></author><author><keyname>Permuter</keyname><forenames>Haim</forenames></author></authors><title>Computable Bounds for Rate Distortion with Feed-Forward for Stationary
  and Ergodic Sources</title><categories>cs.IT math.IT</categories><comments>41 pages, 13 figures, 19 references</comments><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the rate distortion problem of discrete-time,
ergodic, and stationary sources with feed forward at the receiver. We derive a
sequence of achievable and computable rates that converge to the feed-forward
rate distortion. We show that, for ergodic and stationary sources, the rate
{align} R_n(D)=\frac{1}{n}\min I(\hat{X}^n\rightarrow X^n){align} is achievable
for any $n$, where the minimization is taken over the transition conditioning
probability $p(\hat{x}^n|x^n)$ such that $\ex{}{d(X^n,\hat{X}^n)}\leq D$. The
limit of $R_n(D)$ exists and is the feed-forward rate distortion. We follow
Gallager's proof where there is no feed-forward and, with appropriate
modification, obtain our result. We provide an algorithm for calculating
$R_n(D)$ using the alternating minimization procedure, and present several
numerical examples. We also present a dual form for the optimization of
$R_n(D)$, and transform it into a geometric programming problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0917</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0917</id><created>2011-06-05</created><authors><author><keyname>Reardon</keyname><forenames>Joel</forenames></author><author><keyname>Marforio</keyname><forenames>Claudio</forenames></author><author><keyname>Capkun</keyname><forenames>Srdjan</forenames></author><author><keyname>Basin</keyname><forenames>David</forenames></author></authors><title>Secure Deletion on Log-structured File Systems</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of secure data deletion on log-structured file
systems. We focus on the YAFFS file system, widely used on Android smartphones.
We show that these systems provide no temporal guarantees on data deletion and
that deleted data still persists for nearly 44 hours with average phone use and
indefinitely if the phone is not used after the deletion. Furthermore, we show
that file overwriting and encryption, methods commonly used for secure deletion
on block-structured file systems, do not ensure data deletion in log-structured
file systems.
  We propose three mechanisms for secure deletion on log-structured file
systems. Purging is a user-level mechanism that guarantees secure deletion at
the cost of negligible device wear. Ballooning is a user-level mechanism that
runs continuously and gives probabilistic improvements to secure deletion. Zero
overwriting is a kernel-level mechanism that guarantees immediate secure
deletion without device wear. We implement these mechanisms on Nexus One
smartphones and show that they succeed in secure deletion and neither
prohibitively reduce the longevity of the flash memory nor noticeably reduce
the device's battery lifetime. These techniques provide mobile phone users more
confidence that data they delete from their phones are indeed deleted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0932</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0932</id><created>2011-06-05</created><authors><author><keyname>Hogan</keyname><forenames>Emilie</forenames></author><author><keyname>Zeilberger</keyname><forenames>Doron</forenames></author></authors><title>A New Algorithm for Proving Global Asymptotic Stability of Rational
  Difference Equations</title><categories>math.DS cs.SC</categories><comments>18 pages, 7 figures, to be submitted to Journal of Difference
  Equations and Applications</comments><msc-class>39A30, 68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Global asymptotic stability of rational difference equations is an area of
research that has been well studied. In contrast to the many current methods
for proving global asymptotic stability, we propose an algorithmic approach.
The algorithm we summarize here employs the idea of contractions. Given a
particular rational difference equation, defined by a function $Q$ which maps
the $k+1$ dimensional real numbers to itself, we attempt to find an integer,
$K$, for which $Q^K$ shrinks distances to the difference equation's equilibrium
point. We state some general results that our algorithm has been able to prove,
and also mention the implementation of our algorithm using Maple.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0934</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0934</id><created>2011-06-05</created><authors><author><keyname>Sznajd-Weron</keyname><forenames>K.</forenames></author><author><keyname>Tabiszewski</keyname><forenames>M.</forenames></author><author><keyname>Timpanaro</keyname><forenames>A. M.</forenames></author></authors><title>Phase transition in the Sznajd model with independence</title><categories>physics.soc-ph cs.SI</categories><doi>10.1209/0295-5075/96/48002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model of opinion dynamics which describes two major types of
social influence -- conformity and independence. Conformity in our model is
described by the so called outflow dynamics (known as Sznajd model). According
to sociologists' suggestions, we introduce also a second type of social
influence, known in social psychology as independence. Various social
experiments have shown that the level of conformity depends on the society. We
introduce this level as a parameter of the model and show that there is a
continuous phase transition between conformity and independence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0940</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0940</id><created>2011-06-05</created><authors><author><keyname>Herodotou</keyname><forenames>Herodotos</forenames></author></authors><title>Hadoop Performance Models</title><categories>cs.DC</categories><comments>16 pages, 0 figures, Duke University Technical Report</comments><report-no>CS-2011-05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hadoop MapReduce is now a popular choice for performing large-scale data
analytics. This technical report describes a detailed set of mathematical
performance models for describing the execution of a MapReduce job on Hadoop.
The models describe dataflow and cost information at the fine granularity of
phases within the map and reduce tasks of a job execution. The models can be
used to estimate the performance of MapReduce jobs as well as to find the
optimal configuration settings to use when running the jobs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0941</identifier>
 <datestamp>2013-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0941</id><created>2011-06-05</created><updated>2013-12-08</updated><authors><author><keyname>Firooz</keyname><forenames>Mohammad H.</forenames></author><author><keyname>Roy</keyname><forenames>Sumit</forenames></author></authors><title>Link Delay Estimation via Expander Graphs</title><categories>cs.NI cs.IT math.IT</categories><journal-ref>IEEE Transactions on Communications, 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the purposes of network tomography is to infer the status of
parameters (e.g., delay) for the links inside a network through end-to-end
probing between (external) boundary nodes along predetermined routes. In this
work, we apply concepts from compressed sensing and expander graphs to the
delay estimation problem. We first show that a relative majority of network
topologies are not expanders for existing expansion criteria. Motivated by this
challenge, we then relax such criteria, enabling us to acquire simulation
evidence that link delays can be estimated for 30% more networks. That is, our
relaxation expands the list of identifiable networks with bounded estimation
error by 30%. We conduct a simulation performance analysis of delay estimation
and congestion detection on the basis of l1 minimization, demonstrating that
accurate estimation is feasible for an increasing proportion of networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0954</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0954</id><created>2011-06-05</created><updated>2011-12-05</updated><authors><author><keyname>Yang</keyname><forenames>Feng</forenames></author><author><keyname>Lu</keyname><forenames>Yue M.</forenames></author><author><keyname>Sbaiz</keyname><forenames>Luciano</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Bits from Photons: Oversampled Image Acquisition Using Binary Poisson
  Statistics</title><categories>cs.IT cs.MM math.IT</categories><report-no>EPFL Technical Report -166345</report-no><doi>10.1109/TIP.2011.2179306</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a new image sensor that is reminiscent of traditional photographic
film. Each pixel in the sensor has a binary response, giving only a one-bit
quantized measurement of the local light intensity. To analyze its performance,
we formulate the oversampled binary sensing scheme as a parameter estimation
problem based on quantized Poisson statistics. We show that, with a
single-photon quantization threshold and large oversampling factors, the
Cram\'er-Rao lower bound (CRLB) of the estimation variance approaches that of
an ideal unquantized sensor, that is, as if there were no quantization in the
sensor measurements. Furthermore, the CRLB is shown to be asymptotically
achievable by the maximum likelihood estimator (MLE). By showing that the
log-likelihood function of our problem is concave, we guarantee the global
optimality of iterative algorithms in finding the MLE. Numerical results on
both synthetic data and images taken by a prototype sensor verify our
theoretical analysis and demonstrate the effectiveness of our image
reconstruction algorithm. They also suggest the potential application of the
oversampled binary sensing scheme in high dynamic range photography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0958</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0958</id><created>2011-06-06</created><authors><author><keyname>Suk</keyname><forenames>Andrew</forenames></author></authors><title>$k$-quasi planar graphs</title><categories>math.CO cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A topological graph is \emph{$k$-quasi-planar} if it does not contain $k$
pairwise crossing edges. A topological graph is \emph{simple} if every pair of
its edges intersect at most once (either at a vertex or at their intersection).
In 1996, Pach, Shahrokhi, and Szegedy \cite{pach} showed that every $n$-vertex
simple $k$-quasi-planar graph contains at most $O(n(\log n)^{2k-4})$ edges.
This upper bound was recently improved (for large $k$) by Fox and Pach
\cite{fox} to $n(\log n)^{O(\log k)}$. In this note, we show that all such
graphs contain at most $(n\log^2n)2^{\alpha^{c_k}(n)}$ edges, where $\alpha(n)$
denotes the inverse Ackermann function and $c_k$ is a constant that depends
only on $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0961</identifier>
 <datestamp>2012-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0961</id><created>2011-06-06</created><updated>2012-06-15</updated><authors><author><keyname>Alaei</keyname><forenames>Saeed</forenames></author></authors><title>Bayesian Combinatorial Auctions: Expanding Single Buyer Mechanisms to
  Many Buyers</title><categories>cs.GT</categories><comments>A preliminary version was published in the proceedings of FOCS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For Bayesian combinatorial auctions, we present a general framework for
approximately reducing the mechanism design problem for multiple buyers to
single buyer sub-problems. Our framework can be applied to any setting which
roughly satisfies the following assumptions: (i) buyers' types must be
distributed independently (not necessarily identically), (ii) objective
function must be linearly separable over the buyers, and (iii) except for the
supply constraints, there should be no other inter-buyer constraints. Our
framework is general in the sense that it makes no explicit assumption about
buyers' valuations, type distributions, and single buyer constraints (e.g.,
budget, incentive compatibility, etc).
  We present two generic multi buyer mechanisms which use single buyer
mechanisms as black boxes; if an $\alpha$-approximate single buyer mechanism
can be constructed for each buyer, and if no buyer requires more than
$\frac{1}{k}$ of all units of each item, then our generic multi buyer
mechanisms are $\gamma_k\alpha$-approximation of the optimal multi buyer
mechanism, where $\gamma_k$ is a constant which is at least
$1-\frac{1}{\sqrt{k+3}}$. Observe that $\gamma_k$ is at least 1/2 (for $k=1$)
and approaches 1 as $k \to \infty$. As a byproduct of our construction, we
present a generalization of prophet inequalities. Furthermore, as applications
of our framework, we present multi buyer mechanisms with improved approximation
factor for several settings from the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0962</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0962</id><created>2011-06-06</created><authors><author><keyname>Chattopadhyay</keyname><forenames>K.</forenames></author><author><keyname>Basu</keyname><forenames>J.</forenames></author><author><keyname>Konar</keyname><forenames>A.</forenames></author></authors><title>An efficient circle detection scheme in digital images using ant system
  algorithm</title><categories>cs.CV</categories><comments>4 pages, 3 figures, Published in Proceedings of the IEEE Sponsored
  Conference on Computational Intelligence, Control And Computer Vision In
  Robotics &amp; Automation, 2008</comments><journal-ref>Proceedings of the 2008 IEEE Sponsored Conference on Computational
  Intelligence, Control And Computer Vision In Robotics &amp; Automation, Rourkela,
  India, 2008, pages 145-148</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detection of geometric features in digital images is an important exercise in
image analysis and computer vision. The Hough Transform techniques for
detection of circles require a huge memory space for data processing hence
requiring a lot of time in computing the locations of the data space, writing
to and searching through the memory space. In this paper we propose a novel and
efficient scheme for detecting circles in edge-detected grayscale digital
images. We use Ant-system algorithm for this purpose which has not yet found
much application in this field. The main feature of this scheme is that it can
detect both intersecting as well as non-intersecting circles with a time
efficiency that makes it useful in real time applications. We build up an ant
system of new type which finds out closed loops in the image and then tests
them for circles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0967</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0967</id><created>2011-06-06</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author><author><keyname>Shrivastava</keyname><forenames>Anshumali</forenames></author><author><keyname>Moore</keyname><forenames>Joshua</forenames></author><author><keyname>Konig</keyname><forenames>Arnd Christian</forenames></author></authors><title>Hashing Algorithms for Large-Scale Learning</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we first demonstrate that b-bit minwise hashing, whose
estimators are positive definite kernels, can be naturally integrated with
learning algorithms such as SVM and logistic regression. We adopt a simple
scheme to transform the nonlinear (resemblance) kernel into linear (inner
product) kernel; and hence large-scale problems can be solved extremely
efficiently. Our method provides a simple effective solution to large-scale
learning in massive and extremely high-dimensional datasets, especially when
data do not fit in memory.
  We then compare b-bit minwise hashing with the Vowpal Wabbit (VW) algorithm
(which is related the Count-Min (CM) sketch). Interestingly, VW has the same
variances as random projections. Our theoretical and empirical comparisons
illustrate that usually $b$-bit minwise hashing is significantly more accurate
(at the same storage) than VW (and random projections) in binary data.
Furthermore, $b$-bit minwise hashing can be combined with VW to achieve further
improvements in terms of training speed, especially when $b$ is large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0969</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0969</id><created>2011-06-06</created><authors><author><keyname>Ukil</keyname><forenames>Arijit</forenames></author><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author><author><keyname>Bera</keyname><forenames>Debasish</forenames></author></authors><title>Long-Term Proportional Fair QoS Profile Follower Sub-carrier Allocation
  Algorithm in Dynamic OFDMA Systems</title><categories>cs.NI cs.IT math.IT</categories><comments>5 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, Long-Term Proportional Fair (LTPF) resource allocation
algorithm in dynamic OFDMA system is presented, which provides long-term QoS
guarantee (mainly throughput requirement satisfaction) to individual user and
follows every user's QoS profile at long-term by incremental optimization of
proportional fairness and overall system rate maximization. The LTPF algorithm
dynamically allocates the OFDMA sub-carriers to the users in such a way that in
long-term the individual QoS requirement is achieved as well as fairness among
the users is maintained even in a heterogeneous traffic condition. Here more
than maintaining individual user's instantaneous QoS; emphasis is given to
follow mean QoS profile of all the users in long-term to retain the objectives
of both proportional fairness and multi-user raw rate maximization. Compared to
the algorithms, which provide proportional fair optimization and raw-rate
maximization independently, this algorithm attempts to provide both kinds of
optimizations simultaneously and reach an optimum point when computed in
long-term by exploiting the time diversity gain of mobile wireless environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0987</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0987</id><created>2011-06-06</created><authors><author><keyname>Zhang</keyname><forenames>Junping</forenames></author><author><keyname>Xie</keyname><forenames>Ziyu</forenames></author><author><keyname>Li</keyname><forenames>Stan Z.</forenames></author></authors><title>Nearest Prime Simplicial Complex for Object Recognition</title><categories>cs.LG cs.AI cs.CG cs.CV</categories><comments>16pages, 6 figures</comments><msc-class>22A05, 22A30, 57M50, 57N65, 57R19</msc-class><acm-class>I.4.8; I.5; I.5.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The structure representation of data distribution plays an important role in
understanding the underlying mechanism of generating data. In this paper, we
propose nearest prime simplicial complex approaches (NSC) by utilizing
persistent homology to capture such structures. Assuming that each class is
represented with a prime simplicial complex, we classify unlabeled samples
based on the nearest projection distances from the samples to the simplicial
complexes. We also extend the extrapolation ability of these complexes with a
projection constraint term. Experiments in simulated and practical datasets
indicate that compared with several published algorithms, the proposed NSC
approaches achieve promising performance without losing the structure
representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.0989</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.0989</id><created>2011-06-06</created><authors><author><keyname>Zaiter</keyname><forenames>Abdel Kader</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>A study of the singularity locus in the joint space of planar parallel
  manipulators: special focus on cusps and nodes</title><categories>cs.RO</categories><comments>4th International Congress Design and Modeling of Mechanical Systems,
  Sousse : Tunisia (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cusps and nodes on plane sections of the singularity locus in the joint space
of parallel manipulators play an important role in nonsingular assembly-mode
changing motions. This paper analyses in detail such points, both in the joint
space and in the workspace. It is shown that a cusp (resp. a node) defines a
point of tangency (resp. a crossing point) in the workspace between the
singular curves and the curves associated with the so-called characteristics
surfaces. The study is conducted on a planar 3-RPR manipulator for illustrative
purposes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.1017</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.1017</id><created>2011-06-06</created><updated>2012-08-09</updated><authors><author><keyname>Bustin</keyname><forenames>Ronit</forenames></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames></author></authors><title>MMSE of &quot;Bad&quot; Codes</title><categories>cs.IT math.IT</categories><comments>8 pages, 2 figures, submitted to the IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine codes, over the additive Gaussian noise channel, designed for
reliable communication at some specific signal-to-noise ratio (SNR) and
constrained by the permitted minimum mean-square error (MMSE) at lower SNRs.
The maximum possible rate is below point-to-point capacity, and hence these are
non-optimal codes (alternatively referred to as &quot;bad&quot; codes). We show that the
maximum possible rate is the one attained by superposition codebooks. Moreover,
the MMSE and mutual information behavior as a function of SNR, for any code
attaining the maximum rate under the MMSE constraint, is known for all SNR. We
also provide a lower bound on the MMSE for finite length codes, as a function
of the error probability of the code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.1049</identifier>
 <datestamp>2012-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.1049</id><created>2011-06-06</created><updated>2012-12-01</updated><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Yeo</keyname><forenames>Anders</forenames></author></authors><title>Hypercontractive Inequality for Pseudo-Boolean Functions of Bounded
  Fourier Width</title><categories>cs.DM cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A function $f:\ \{-1,1\}^n\rightarrow \mathbb{R}$ is called pseudo-Boolean.
It is well-known that each pseudo-Boolean function $f$ can be written as
$f(x)=\sum_{I\in {\cal F}}\hat{f}(I)\chi_I(x),$ where ${\cal F}\subseteq \{I:\
I\subseteq [n]\}$, $[n]=\{1,2,...,n\}$, and $\chi_I(x)=\prod_{i\in I}x_i$ and
$\hat{f}(I)$ are non-zero reals. The degree of $f$ is $\max \{|I|:\ I\in {\cal
F}\}$ and the width of $f$ is the minimum integer $\rho$ such that every $i\in
[n]$ appears in at most $\rho$ sets in $\cal F$. For $i\in [n]$, let
$\mathbf{x}_i$ be a random variable taking values 1 or -1 uniformly and
independently from all other variables $\mathbf{x}_j$, $j\neq i.$ Let
$\mathbf{x}=(\mathbf{x}_1,...,\mathbf{x}_n)$. The $p$-norm of $f$ is
$||f||_p=(\mathbb E[|f(\mathbf{x})|^p])^{1/p}$ for any $p\ge 1$. It is
well-known that $||f||_q\ge ||f||_p$ whenever $q&gt; p\ge 1$. However, the higher
norm can be bounded by the lower norm times a coefficient not directly
depending on $f$: if $f$ is of degree $d$ and $q&gt; p&gt;1$ then $ ||f||_q\le
(\frac{q-1}{p-1})^{d/2}||f||_p.$ This inequality is called the Hypercontractive
Inequality. We show that one can replace $d$ by $\rho$ in the Hypercontractive
Inequality for each $q&gt; p\ge 2$ as follows: $ ||f||_q\le
((2r)!\rho^{r-1})^{1/(2r)}||f||_p,$ where $r=\lceil q/2\rceil$. For the case
$q=4$ and $p=2$, which is important in many applications, we prove a stronger
inequality: $ ||f||_4\le (2\rho+1)^{1/4}||f||_2.$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.1105</identifier>
 <datestamp>2012-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.1105</id><created>2011-06-06</created><updated>2012-03-14</updated><authors><author><keyname>Alicea</keyname><forenames>Bradly</forenames></author></authors><title>Naturally Supervised Learning in Manipulable Technologies</title><categories>cs.HC q-bio.NC</categories><comments>27 pages, 12 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relationship between physiological systems and modern electromechanical
technologies is fast becoming intimate with high degrees of complex
interaction. It can be argued that muscular function, limb movements, and touch
perception serve supervisory functions for movement control in motion and
touch-based (e.g. manipulable) devices/interfaces and human-machine interfaces
in general. To get at this hypothesis requires the use of novel techniques and
analyses which demonstrate the multifaceted and regulatory role of adaptive
physiological processes in these interactions. Neuromechanics is an approach
that unifies the role of physiological function, motor performance, and
environmental effects in determining human performance. A neuromechanical
perspective will be used to explain the effect of environmental fluctuations on
supervisory mechanisms, which leads to adaptive physiological responses. Three
experiments are presented using two different types of virtual environment that
allowed for selective switching between two sets of environmental forces. This
switching was done in various ways to maximize the variety of results.
Electromyography (EMG) and kinematic information contributed to the development
of human performance-related measures. Both descriptive and specialized
analyses were conducted: peak amplitude analysis, loop trace analysis, and the
analysis of unmatched muscle power. Results presented here provide a window
into performance under a range of conditions. These analyses also demonstrated
myriad consequences for force-related fluctuations on dynamic physiological
regulation. The findings presented here could be applied to the dynamic control
of touch-based and movement-sensitive human-machine systems. In particular, the
design of systems such as human-robotic systems, touch screen devices, and
rehabilitative technologies could benefit from this research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.1113</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.1113</id><created>2011-06-06</created><authors><author><keyname>Chinea</keyname><forenames>Alejandro</forenames></author><author><keyname>Korutcheva</keyname><forenames>Elka</forenames></author></authors><title>Complexity Analysis of Vario-eta through Structure</title><categories>cs.LG cs.DM</categories><comments>13 pages, 2 figures, 14th International Workshop, IWCIA 2011, Madrid,
  Spain, May 2011; Advances in Image Analysis and Applications, Research
  Publishing Services 2011 ISBN 978-981-08-7923-5</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph-based representations of images have recently acquired an important
role for classification purposes within the context of machine learning
approaches. The underlying idea is to consider that relevant information of an
image is implicitly encoded into the relationships between more basic entities
that compose by themselves the whole image. The classification problem is then
reformulated in terms of an optimization problem usually solved by a
gradient-based search procedure. Vario-eta through structure is an approximate
second order stochastic optimization technique that achieves a good trade-off
between speed of convergence and the computational effort required. However,
the robustness of this technique for large scale problems has not been yet
assessed. In this paper we firstly provide a theoretical justification of the
assumptions made by this optimization procedure. Secondly, a complexity
analysis of the algorithm is performed to prove its suitability for large scale
learning problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.1150</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.1150</id><created>2011-06-06</created><authors><author><keyname>Hemaspaandra</keyname><forenames>Lane A.</forenames></author><author><keyname>Murray</keyname><forenames>Kyle</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoqing</forenames></author></authors><title>Barbosa, Uniform Polynomial Time Bounds, and Promises</title><categories>cs.CC</categories><report-no>URCS TR-2011-969</report-no><msc-class>68Q15 (Primary), 68Q05 (Secondary)</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note is a commentary on, and critique of, Andre Luiz Barbosa's paper
entitled &quot;P != NP Proof.&quot; Despite its provocative title, what the paper is
seeking to do is not to prove P \neq NP in the standard sense in which that
notation is used in the literature. Rather, Barbosa is (and is aware that he
is) arguing that a different meaning should be associated with the notation P
\neq NP, and he claims to prove the truth of the statement P \neq NP in his
quite different sense of that statement. However, we note that (1) the paper
fails even on its own terms, as due to a uniformity problem, the paper's proof
does not establish, even in its unusual sense of the notation, that P \neq NP;
and (2) what the paper means by the claim P \neq NP in fact implies that P \neq
NP holds even under the standard meaning that that notation has in the
literature (and so it is exceedingly unlikely that Barbosa's proof can be fixed
any time soon).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.1151</identifier>
 <datestamp>2011-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.1151</id><created>2011-06-06</created><authors><author><keyname>Rudelson</keyname><forenames>Mark</forenames></author><author><keyname>Zhou</keyname><forenames>Shuheng</forenames></author></authors><title>Reconstruction from anisotropic random measurements</title><categories>math.ST cs.IT math.FA math.IT stat.TH</categories><comments>30 Pages</comments><report-no>Technical Report 522, University of Michigan, Department of
  Statistics</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random matrices are widely used in sparse recovery problems, and the relevant
properties of matrices with i.i.d. entries are well understood. The current
paper discusses the recently introduced Restricted Eigenvalue (RE) condition,
which is among the most general assumptions on the matrix, guaranteeing
recovery. We prove a reduction principle showing that the RE condition can be
guaranteed by checking the restricted isometry on a certain family of
low-dimensional subspaces. This principle allows us to establish the RE
condition for several broad classes of random matrices with dependent entries,
including random matrices with subgaussian rows and non-trivial covariance
structure, as well as matrices with independent rows, and uniformly bounded
entries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1106.1157</identifier>
 <datestamp>2012-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1106.1157</id><created>2011-06-06</created><updated>2012-08-17</updated><authors><author><keyname>Mohamed</keyname><forenames>Shakir</forenames></author><author><keyname>Heller</keyname><forenames>Katherine</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Bayesian and L1 Approaches to Sparse Unsupervised Learning</title><categories>cs.LG cs.AI stat.ML</categories><comments>In Proceedings of the 29th International Conference on Machine
  Learning (ICML), Edinburgh, Scotland, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of L1 regularisation for sparse learning has generated immense
research interest, with successful application in such diverse areas as signal
acquisition, image coding, genomics and collaborative filtering. While existing
work highlights the many advantages of L1 methods, in this paper we find that
L1 regularisation often dramatically underperforms in terms of predictive
performance when compared with other methods for inferring sparsity. We focus
on unsupervised latent variable models, and develop L1 minimising factor
models, Bayesian variants of &quot;L1&quot;, and Bayesian models with a stronger L0-like
sparsity induced through spike-and-slab distributions. These spike-and-slab
Bayesian factor models encourage sparsity while accounting for uncertainty in a
principled manner and avoiding unnecessary shrinkage of non-zero values. We
demonstrate on a number of data sets that in practice spike-and-slab Bayesian
methods outperform L1 minimisation, even on a computational budget. We thus
highlight the need to re-assess the wide use of L1 methods in sparsity-reliant
applications, particularly when we care about generalising to previously unseen
data, and provide an alternative that, over many varying conditions, provides
improved generalisation performance.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="21000" completeListSize="102538">1122234|22001</resumptionToken>
</ListRecords>
</OAI-PMH>
