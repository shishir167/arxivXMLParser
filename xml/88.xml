<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T03:59:12Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|87001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04377</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04377</id><created>2015-11-13</created><updated>2016-01-07</updated><authors><author><keyname>Harley</keyname><forenames>Adam W.</forenames></author><author><keyname>Derpanis</keyname><forenames>Konstantinos G.</forenames></author><author><keyname>Kokkinos</keyname><forenames>Iasonas</forenames></author></authors><title>Learning Dense Convolutional Embeddings for Semantic Segmentation</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new deep convolutional neural network (DCNN)
architecture that learns pixel embeddings, such that pairwise distances between
the embeddings can be used to infer whether or not the pixels lie on the same
region. That is, for any two pixels on the same object, the embeddings are
trained to be similar; for any pair that straddles an object boundary, the
embeddings are trained to be dissimilar. Experimental results show that when
this embedding network is used in conjunction with a DCNN trained on semantic
segmentation, there is a systematic improvement in per-pixel classification
accuracy. Our contributions are integrated in the popular Caffe deep learning
framework, and consist in straightforward modifications to convolution
routines. As such, they can be exploited for any task involving convolution
layers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04383</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04383</id><created>2015-11-13</created><updated>2016-02-21</updated><authors><author><keyname>Li</keyname><forenames>Bopeng</forenames></author><author><keyname>Chaudhuri</keyname><forenames>Sougata</forenames></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames></author></authors><title>Handling Class Imbalance in Link Prediction using Learning to Rank
  Techniques</title><categories>stat.ML cs.LG cs.SI</categories><comments>The paper has been withdrawn due to a baseline implementation error
  in experiments</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the link prediction problem in a partially observed network,
where the objective is to make predictions in the unobserved portion of the
network. Many existing methods reduce link prediction to binary classification
problem. However, the dominance of absent links in real world networks makes
misclassification error a poor performance metric. Instead, researchers have
argued for using ranking performance measures, like AUC, AP and NDCG, for
evaluation. Our main contribution is to recast the link prediction problem as a
learning to rank problem and use effective learning to rank techniques directly
during training. This is in contrast to existing work that uses ranking
measures only during evaluation. Our approach is able to deal with the class
imbalance problem by using effective, scalable learning to rank techniques
during training. Furthermore, our approach allows us to combine network
topology and node features. As a demonstration of our general approach, we
develop a link prediction method by optimizing the cross-entropy surrogate,
originally used in the popular ListNet ranking algorithm. We conduct extensive
experiments on publicly available co-authorship, citation and metabolic
networks to demonstrate the merits of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04384</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04384</id><created>2015-11-13</created><authors><author><keyname>Rematas</keyname><forenames>Konstantinos</forenames></author><author><keyname>Ritschel</keyname><forenames>Tobias</forenames></author><author><keyname>Fritz</keyname><forenames>Mario</forenames></author><author><keyname>Gavves</keyname><forenames>Efstratios</forenames></author><author><keyname>Tuytelaars</keyname><forenames>Tinne</forenames></author></authors><title>Deep Reflectance Maps</title><categories>cs.CV</categories><comments>project page: http://homes.esat.kuleuven.be/~krematas/DRM/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Undoing the image formation process and therefore decomposing appearance into
its intrinsic properties is a challenging task due to the under-constraint
nature of this inverse problem. While significant progress has been made on
inferring shape, materials and illumination from images only, progress in an
unconstrained setting is still limited. We propose a convolutional neural
architecture to estimate reflectance maps of specular materials in natural
lighting conditions. We achieve this in an end-to-end learning formulation that
directly predicts a reflectance map from the image itself. We show how to
improve estimates by facilitating additional supervision in an indirect scheme
that first predicts surface orientation and afterwards predicts the reflectance
map by a learning-based sparse data interpolation.
  In order to analyze performance on this difficult task, we propose a new
challenge of Specular MAterials on SHapes with complex IllumiNation (SMASHINg)
using both synthetic and real images. Furthermore, we show the application of
our method to a range of image-based editing tasks on real images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04385</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04385</id><created>2015-11-13</created><authors><author><keyname>Grosshans</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Lawson</keyname><forenames>Thomas</forenames></author><author><keyname>Morain</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Smith</keyname><forenames>Benjamin</forenames></author></authors><title>Factoring Safe Semiprimes with a Single Quantum Query</title><categories>quant-ph cs.CC</categories><msc-class>68Q12</msc-class><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shor's factoring algorithm (SFA), by its ability to efficiently factor large
numbers, has the potential to undermine contemporary encryption. At its heart
is a process called order finding, which quantum mechanics lets us perform
efficiently. SFA thus consists of a quantum order finding algorithm (QOFA),
bookended by classical routines which, given the order, return the factors.
But, with probability up to $1/2$, these classical routines fail, and QOFA must
be rerun. We modify these routines using elementary results in number theory,
improving the likelihood that they return the factors.
  We present a new quantum factoring algorithm based on QOFA which is better
than SFA at factoring safe semiprimes, an important class of numbers used in
RSA encryption (and reputed to be the hardest to factor). With just one call to
QOFA, our algorithm almost always factors safe semiprimes. As well as a
speed-up, improving efficiency gives our algorithm other, practical advantages:
unlike SFA, it does not need a randomly picked input, making it simpler to
construct in the lab; and in the (unlikely) case of failure, the same circuit
can be rerun, without modification.
  We consider generalising this result to other cases, although we do not find
a simple extension, and conclude that SFA is still the best algorithm for
general numbers (non safe semiprimes, in other words). Even so, we present some
simple number theoretic tricks for improving SFA in this case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04386</identifier>
 <datestamp>2015-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04386</id><created>2015-11-13</created><authors><author><keyname>Britt</keyname><forenames>Keith A.</forenames></author><author><keyname>Humble</keyname><forenames>Travis S.</forenames></author></authors><title>High-Performance Computing with Quantum Processing Units</title><categories>cs.ET quant-ph</categories><comments>8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prospects of quantum computing have driven efforts to realize fully
functional quantum processing units (QPUs). Recent success in developing
proof-of-principle QPUs has prompted the question of how to integrate these
emerging processors into modern high-performance computing (HPC) systems. We
examine how QPUs can be integrated into current and future HPC system
architectures by accounting for functional and physical design requirements. We
identify two integration pathways that are differentiated by infrastructure
constraints on the QPU and the use cases expected for the HPC system. This
includes a tight integration that assumes infrastructure bottlenecks can be
overcome as well as a loose integration that assumes they cannot. We find that
the performance of both approaches is likely to depend on the quantum
interconnect that serves to entangle multiple QPUs. We also identify several
challenges in assessing QPU performance for HPC, and we consider new metrics
that capture the interplay between system architecture and the quantum
parallelism underlying computational performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04387</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04387</id><created>2015-11-13</created><authors><author><keyname>Asta</keyname><forenames>Shahriar</forenames></author><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author><author><keyname>Kheiri</keyname><forenames>Ahmed</forenames></author><author><keyname>&#xd6;zcan</keyname><forenames>Ender</forenames></author><author><keyname>Parkes</keyname><forenames>Andrew J.</forenames></author></authors><title>Combining Monte-Carlo and Hyper-heuristic methods for the Multi-mode
  Resource-constrained Multi-project Scheduling Problem</title><categories>cs.DS cs.AI cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-mode resource and precedence-constrained project scheduling is a
well-known challenging real-world optimisation problem. An important variant of
the problem requires scheduling of activities for multiple projects considering
availability of local and global resources while respecting a range of
constraints. This problem has been addressed by a competition, and associated
set of benchmark instances, as a part of the MISTA 2013 conference. A critical
aspect of the benchmarks is that the primary objective is to minimise the sum
of the project completion times, with the usual makespan minimisation as a
secondary objective. We observe that this leads to an expected different
overall structure of good solutions and discuss the effects this has on the
algorithm design. This paper presents the resulting competition winning
approach; it is a carefully designed hybrid of Monte-Carlo tree search, novel
neighbourhood moves, memetic algorithms, and hyper-heuristic methods. The
implementation is also engineered to increase the speed with which iterations
are performed, and to exploit the computing power of multicore machines. The
resulting information-sharing multi-component algorithm significantly
outperformed the other approaches during the competition, producing the best
solution for 17 out of the 20 test instances and performing the best in around
90% of all the trials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04389</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04389</id><created>2015-11-13</created><authors><author><keyname>Ferragut</keyname><forenames>Erik M.</forenames></author><author><keyname>Brady</keyname><forenames>Andrew C.</forenames></author><author><keyname>Brady</keyname><forenames>Ethan J.</forenames></author><author><keyname>Ferragut</keyname><forenames>Jacob M.</forenames></author><author><keyname>Ferragut</keyname><forenames>Nathan M.</forenames></author><author><keyname>Wildgruber</keyname><forenames>Max C.</forenames></author></authors><title>HackAttack: Game-Theoretic Analysis of Realistic Cyber Conflicts</title><categories>cs.CR cs.GT</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game theory is appropriate for studying cyber conflict because it allows for
an intelligent and goal-driven adversary. Applications of game theory have led
to a number of results regarding optimal attack and defense strategies.
However, the overwhelming majority of applications explore overly simplistic
games, often ones in which each participant's actions are visible to every
other participant. These simplifications strip away the fundamental properties
of real cyber conflicts: probabilistic alerting, hidden actions, unknown
opponent capabilities.
  In this paper, we demonstrate that it is possible to analyze a more realistic
game, one in which different resources have different weaknesses, players have
different exploits, and moves occur in secrecy, but they can be detected.
Certainly, more advanced and complex games are possible, but the game presented
here is more realistic than any other game we know of in the scientific
literature. While optimal strategies can be found for simpler games using
calculus, case-by-case analysis, or, for stochastic games, Q-learning, our more
complex game is more naturally analyzed using the same methods used to study
other complex games, such as checkers and chess. We define a simple evaluation
function and ploy multi-step searches to create strategies. We show that such
scenarios can be analyzed, and find that in cases of extreme uncertainty, it is
often better to ignore one's opponent's possible moves. Furthermore, we show
that a simple evaluation function in a complex game can lead to interesting and
nuanced strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04397</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04397</id><created>2015-11-13</created><updated>2016-01-07</updated><authors><author><keyname>Hosseini-Asl</keyname><forenames>Ehsan</forenames></author><author><keyname>Guha</keyname><forenames>Angshuman</forenames></author></authors><title>Similarity-based Text Recognition by Deeply Supervised Siamese Network</title><categories>cs.CV cs.LG</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a new text recognition model based on measuring the
visual similarity of text and predicting the content of unlabeled texts. First
a Siamese convolutional network is trained with deep supervision on a labeled
training dataset. This network projects texts into a similarity manifold. The
Deeply Supervised Siamese network learns visual similarity of texts. Then a
K-nearest neighbor classifier is used to predict unlabeled text based on
similarity distance to labeled texts. The performance of the model is evaluated
on three datasets of machine-print and hand-written text combined. We
demonstrate that the model reduces the cost of human estimation by $50\%-85\%$.
The error of the system is less than $0.5\%$. The proposed model outperform
conventional Siamese network by finding visually-similar barely-readable and
readable text, e.g. machine-printed, handwritten, due to deep supervision. The
results also demonstrate that the predicted labels are sometimes better than
human labels e.g. spelling correction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04401</identifier>
 <datestamp>2016-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04401</id><created>2015-11-13</created><updated>2016-01-12</updated><authors><author><keyname>Raue</keyname><forenames>Federico</forenames></author><author><keyname>Breuel</keyname><forenames>Thomas M.</forenames></author><author><keyname>Dengel</keyname><forenames>Andreas</forenames></author><author><keyname>Liwicki</keyname><forenames>Marcus</forenames></author></authors><title>Symbol Grounding Association in Multimodal Sequences with Missing
  Elements</title><categories>cs.CV cs.CL cs.LG cs.NE</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we extend a symbolic association framework to being able to
handle missing elements in multimodal sequences. The general scope of the work
is the symbolic associations of object-word mappings as it happens in language
development on infants. This scenario has been long interested by Artificial
Intelligence, Psychology and Neuroscience. In this work, we extend a recent
approach for multimodal sequences (visual and audio) to also cope with missing
elements in one or both modalities. Our approach uses two parallel Long
Short-Term Memory (LSTM) networks with a learning rule based on EM-algorithm.
It aligns both LSTM outputs via Dynamic Time Warping (DTW). We propose to
include an extra step for the combination with max and mean operations for
handling missing elements in the sequences. The intuition behind is that the
combination acts as a condition selector for choosing the best representation
from both LSTMs. We evaluated the proposed extension in three different
scenarios: audio sequences with missing elements, visual sequences with missing
elements, and sequences with missing elements in both modalities. The
performance of our extension reaches better results than the original model and
similar results to a unique LSTM trained in one modality, i.e., where the
learning problem is less difficult.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04404</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04404</id><created>2015-11-13</created><authors><author><keyname>Tuzel</keyname><forenames>Oncel</forenames></author><author><keyname>Tambe</keyname><forenames>Salil</forenames></author><author><keyname>Marks</keyname><forenames>Tim K.</forenames></author></authors><title>Robust Face Alignment Using a Mixture of Invariant Experts</title><categories>cs.CV</categories><comments>10 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Face alignment, which is the task of finding the locations of a set of facial
landmark points in an image of a face, is an important problem that is useful
in widespread application areas. Face alignment is particularly challenging
when there are large variations in pose (in-plane and out-of-plane rotations)
and facial expression. To address this issue, we propose a cascade in which
each stage consists of a mixture of regression experts. Each expert learns a
customized regression model that is specialized to a different subset of the
joint space of pose and expressions. The system is invariant to a predefined
class of transformations (e.g., affine), because the input is transformed to
match each expert's prototype shape before the regression is applied. We also
present a method to include deformation constraints within the discriminative
alignment framework, which makes our algorithm more robust. Results show that
our algorithm significantly outperforms previous methods on publicly available
face alignment datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04411</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04411</id><created>2015-11-13</created><authors><author><keyname>Raza</keyname><forenames>Arif</forenames></author><author><keyname>Capretz</keyname><forenames>Luiz Fernando</forenames></author><author><keyname>ul-Mustafa</keyname><forenames>Zaka</forenames></author></authors><title>Personality Profiles of Software Engineers and Their Software Quality
  Preferences</title><categories>cs.SE</categories><journal-ref>International Journal of Information Systems and Social Changes
  (IJISSC), 5(3):74-84, 2014</journal-ref><doi>10.4018/ijissc.2014070106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Studies related to human aspects in software engineering (SE) have been
performed from different perspectives. These perspectives include the study of
human factors in different phases of software life cycle, effect of team
performance in software development, how can a personality trait suit a
particular task, and about some other miscellaneous issues. This research work
aims to establish personality profiles of Pakistani software engineers using
the Myers-Briggs Type Indicator (MBTI) instrument. In this survey, we have
collected personality profiles of 110 software engineers. Moreover, their
preferences of software quality attributes have also been collected. Analysis
of the study shows that the most prominent personality type is a combination of
introversion, sensing, thinking and judging. Investigative results indicate
that most of the software engineers consider usability and functionality as the
most important software quality attributes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04412</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04412</id><created>2015-11-13</created><authors><author><keyname>Melibari</keyname><forenames>Mazen</forenames></author><author><keyname>Poupart</keyname><forenames>Pascal</forenames></author><author><keyname>Doshi</keyname><forenames>Prashant</forenames></author></authors><title>Dynamic Sum Product Networks for Tractable Inference on Sequence Data</title><categories>cs.LG cs.AI stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sum-Product Networks (SPN) have recently emerged as a new class of tractable
probabilistic graphical models. Unlike Bayesian networks and Markov networks
where inference may be exponential in the size of the network, inference in
SPNs is in time linear in the size of the network. Since SPNs represent
distributions over a fixed set of variables only, we propose dynamic sum
product networks (DSPNs) as a generalization of SPNs for sequence data of
varying length. A DSPN consists of a template network that is repeated as many
times as needed to model data sequences of any length. We present a local
search technique to learn the structure of the template network. In contrast to
dynamic Bayesian networks for which inference is generally exponential in the
number of variables per time slice, DSPNs inherit the linear inference
complexity of SPNs. We demonstrate the advantages of DSPNs over DBNs and other
models on several datasets of sequence data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04417</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04417</id><created>2015-11-13</created><authors><author><keyname>Alrasheedi</keyname><forenames>Muasaad</forenames></author><author><keyname>Capretz</keyname><forenames>Luiz Fernando</forenames></author><author><keyname>Raza</keyname><forenames>Arif</forenames></author></authors><title>A Systematic Literature Review of the Critical Factors for Success of
  Mobile Learning in Higher Education (University Students' Perspective)</title><categories>cs.CY</categories><journal-ref>Journal of Educational Computing Research, 52(2):257-276, 2015</journal-ref><doi>10.1177/0735633115571928</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The phenomenon of the use of a mobile learning (m-Learning) platform in
educational institutions is slowly gaining momentum. While this can be taken as
an encouraging sign, the perplexing part is that the fervor with which mobile
phones have been welcomed into every aspect of our lives does not seem to be
evident in the educational sector. In order to understand the reason, it is
important to understand user expectations of the system. This paper documents a
systematic review of various research studies seeking to find the success
factors for effective m-Learning. A total of 30 studies were included in the
research, which combined would give a true picture of user perceptions of the
factors they consider important for effective m-Learning implementation. Our
systematic review collates results from 30 studies conducted in 17 countries,
where 13 critical success factors (CSFs) were found to strongly impact
m-Learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04422</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04422</id><created>2015-11-13</created><authors><author><keyname>Aleem</keyname><forenames>Saiqa</forenames></author><author><keyname>Capretz</keyname><forenames>Luiz Fernando</forenames></author><author><keyname>Ahmed</keyname><forenames>Faheem</forenames></author></authors><title>Empirical Investigation of Key Business Factors for Digital Game
  Performance</title><categories>cs.CY</categories><comments>in Entertainment Computing, 2014</comments><doi>10.1016/j.entcom.2015.09.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game development is an interdisciplinary concept that embraces software
engineering, business, management, and artistic disciplines. This research
facilitates a better understanding of the business dimension of digital games.
The main objective of this research is to investigate empirically the effect of
business factors on the performance of digital games in the market and to
answer the research questions asked in this study. Game development
organizations are facing high pressure and competition in the digital game
industry. Business has become a crucial dimension, especially for game
development organizations. The main contribution of this paper is to
investigate empirically the influence of key business factors on the business
performance of games. This is the first study in the domain of game development
that demonstrates the interrelationship between key business factors and game
performance in the market. The results of the study provide evidence that game
development organizations must deal with multiple business key factors to
remain competitive and handle the high pressure in the digital game industry.
Furthermore, the results of the study support the theoretical assertion that
key business factors play an important role in game business performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04424</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04424</id><created>2015-11-13</created><authors><author><keyname>Capretz</keyname><forenames>Luiz Fernando</forenames></author><author><keyname>Varona</keyname><forenames>Daniel</forenames></author><author><keyname>Raza</keyname><forenames>Arif</forenames></author></authors><title>Influence of Personality Types in Software Tasks Choices</title><categories>cs.CY cs.SE</categories><journal-ref>Computers in Human Behavior, 52:373-378, 2015</journal-ref><doi>10.1016/j.chb.2015.05.050</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  According to psychology, not everybody can excel at all kinds of tasks. Thus,
chances of a successful outcome of software development increase if people with
particular personality types are assigned to their preferred tasks in the
project. Likewise, software development depends significantly on how software
practitioners perform their tasks. This empirical study surveys 100 Cuban
software developers, who also teach or study at the University of Informatics
Sciences in Havana, Cuba. This work aims to find possible patterns that link
personality types to role preferences in a software life cycle. Among the
various roles, system analyst, software designer, and programmer are found to
be the most preferred among the participants. In contrast, software tester and
software maintainer happen to be the least popular roles among software
engineers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04428</identifier>
 <datestamp>2016-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04428</id><created>2015-11-13</created><updated>2016-01-14</updated><authors><author><keyname>Arablouei</keyname><forenames>Reza</forenames></author><author><keyname>Do&#x11f;an&#xe7;ay</keyname><forenames>Kutluy&#x131;l</forenames></author><author><keyname>Werner</keyname><forenames>Stefan</forenames></author><author><keyname>Huang</keyname><forenames>Yih-Fang</forenames></author></authors><title>On the Asymptotic Bias of the Diffusion-Based Distributed Pareto
  Optimization</title><categories>cs.DC cs.GT cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the asymptotic bias analysis of the distributed Pareto
optimization algorithm developed based on the diffusion strategies. We propose
an alternative way to analyze the bias of this algorithm at small step-sizes
and show that the bias descends to zero with a linear dependence on the largest
step-size parameter when this parameter is sufficiently small. In addition, we
provide an expression for the asymptotic bias when a condition assumed jointly
on the combination matrices and the step-sizes does not strictly hold. This is
a likely scenario in practice, which has not been considered in the original
paper that introduced the algorithm. Our methodology provides new insights into
the inner workings of the diffusion Pareto optimization algorithm while being
considerably simpler than the small-step-size asymptotic bias analysis
presented in the original work. This is because we take advantage of the
special eigenstructure of the composite combination matrix used in the
algorithm without calling for any eigenspace decomposition or matrix inversion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04433</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04433</id><created>2015-11-13</created><authors><author><keyname>Barnes</keyname><forenames>Richard</forenames></author><author><keyname>Lehman</keyname><forenames>Clarence</forenames></author><author><keyname>Mulla</keyname><forenames>David</forenames></author></authors><title>An Efficient Assignment of Drainage Direction Over Flat Surfaces in
  Raster Digital Elevation Models</title><categories>cs.DS</categories><comments>13 pages, 4 figures, 8 subalgorithms</comments><journal-ref>Computers &amp; Geosciences. Vol 62, Jan 2014, pp 12--135</journal-ref><doi>10.1016/j.cageo.2013.01.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In processing raster digital elevation models (DEMs) it is often necessary to
assign drainage directions over flats---that is, over regions with no local
elevation gradient. This paper presents an approach to drainage direction
assignment which is not restricted by a flat's shape, number of outlets, or
surrounding topography. Flow is modeled by superimposing a gradient away from
higher terrain with a gradient towards lower terrain resulting in a drainage
field exhibiting flow convergence, an improvement over methods which produce
regions of parallel flow. This approach builds on previous work by Garbrecht
and Martz (1997), but presents several important improvements. The improved
algorithm guarantees that flats are only resolved if they have outlets. The
algorithm does not require iterative application; a single pass is sufficient
to resolve all flats. The algorithm presents a clear strategy for identifying
flats and their boundaries. The algorithm is not susceptible to loss of
floating-point precision. Furthermore, the algorithm is efficient, operating in
O( N ) time whereas the older algorithm operates in O( N^(3/2) ) time. In
testing, the improved algorithm ran 6.5 times faster than the old for a 100 x
100 cell flat and 69 times faster for a 700 x 700 cell flat. In tests on actual
DEMs, the improved algorithm finished its processing 38--110 times sooner while
running on a single processor than a parallel implementation of the old
algorithm did while running on 16 processors. The improved algorithm is an
optimal, accurate, easy-to-implement drop-in replacement for the original.
Pseudocode is provided in the paper and working source code is provided in the
Supplemental Materials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04435</identifier>
 <datestamp>2015-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04435</id><created>2015-11-11</created><authors><author><keyname>Best</keyname><forenames>R. E.</forenames></author><author><keyname>Kuznetsov</keyname><forenames>N. V.</forenames></author><author><keyname>Leonov</keyname><forenames>G. A.</forenames></author><author><keyname>Yuldashev</keyname><forenames>M. V.</forenames></author><author><keyname>Yuldashev</keyname><forenames>R. V.</forenames></author></authors><title>A Survey on Dynamic Analysis of the Costas Loop</title><categories>cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This survey is devoted to the dynamic analysis of the Costas loop. In
particular the acquisition process is analyzed in great detail. Acquision is
most conventiently described by a number of frequency and time parameters such
as lock-in range, lock-in time, pull-in range, pull-in time, and hold-in range.
While for the classical PLL equations for all these parameters have been
derived (many of them are approximations, some even crude approximations), this
has not yet been carried out for the Costas loop. It is the aim of this
analysis to close this gap. The paper starts with an overview on mathematical
and physical models (exact and simplified) of the different variants of the
Costas loop, cf. Section~1. In Sections 2--5 equations for the above mentioned
key parameters are derived. Finally, the hold-in range of the Costas loop for
the case where a lead-lag filter is used for the loop filter is analyzed, cf.
Appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04437</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04437</id><created>2015-11-09</created><authors><author><keyname>Kondratev</keyname><forenames>Aleksei</forenames></author><author><keyname>Mazalov</keyname><forenames>Vladimir</forenames></author></authors><title>The Ranking Problem of Alternatives as a Cooperative Game</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the ranking problem of candidates for a certain position
based on ballot papers filled by voters. We suggest a ranking procedure of
alternatives using cooperative game theory methods. For this, it is necessary
to construct a characteristic function via the filled ballot paper profile of
voters. The Shapley value serves as the ranking method. The winner is the
candidate having the maximum Shapley value. And finally, we explore the
properties of the designed ranking procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04440</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04440</id><created>2015-11-13</created><authors><author><keyname>Legchekova</keyname><forenames>Elena</forenames></author><author><keyname>Titov</keyname><forenames>Oleg</forenames></author></authors><title>Mathematical model stabilization control of a robot due to the delay of
  the control signal</title><categories>cs.SY</categories><comments>4 pages, in Russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the question of building a system of commands remotely controlled
robot that can perform motion stabilization in the presence of a constant delay
of the control signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04458</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04458</id><created>2015-11-13</created><authors><author><keyname>Xu</keyname><forenames>Xun</forenames></author><author><keyname>Hospedales</keyname><forenames>Timothy</forenames></author><author><keyname>Gong</keyname><forenames>Shaogang</forenames></author></authors><title>Zero-Shot Action Recognition by Word-Vector Embedding</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of categories for action recognition is growing rapidly and it has
become increasingly hard to label sufficient training data for learning
conventional models for all categories. Instead of collecting ever more data
and labelling them exhaustively for all categories, an attractive alternative
approach is &quot;zeroshot learning&quot; (ZSL). To that end, in this study we construct
a mapping between visual features and a semantic descriptor of each action
category, allowing new categories to be recognised in the absence of any visual
training data. Existing ZSL studies focus primarily on still images, and
attribute-based semantic representations. In this work, we explore word-vectors
as the shared semantic space to embed videos and category labels for ZSL action
recognition. This is a more challenging problem than existing ZSL of still
images and/or attributes, because the mapping between the semantic space and
video space-time features of actions is more complex and harder to learn for
the purpose of generalising over any cross-category domain shift. To solve this
generalisation problem in ZSL action recognition, we investigate a series of
synergistic improvements to the standard ZSL pipeline. First, we enhance
significantly the semantic space mapping by proposing manifold-regularised
regression and data augmentation strategies. Second, we evaluate two existing
post processing strategies (transductive self-training and hubness correction),
and show that they are complementary. We evaluate extensively our model on a
wide range of human action datasets including HMDB51, UCF101, OlympicSports,
CCV and TRECVID MED 13. The results demonstrate that our approach achieves the
state-of-the-art zero-shot action recognition performance with a simple and
efficient pipeline, and without supervised annotation of attributes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04463</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04463</id><created>2015-11-13</created><authors><author><keyname>Barnes</keyname><forenames>Richard</forenames></author><author><keyname>Lehman</keyname><forenames>Clarence</forenames></author><author><keyname>Mulla</keyname><forenames>David</forenames></author></authors><title>Priority-Flood: An Optimal Depression-Filling and Watershed-Labeling
  Algorithm for Digital Elevation Models</title><categories>cs.DS</categories><comments>17 pages, 4 figures, 5 algorithms</comments><journal-ref>Computers &amp; Geosciences. Vol 62, Jan 2014, pp 117--127</journal-ref><doi>10.1016/j.cageo.2013.04.024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Depressions (or pits) are low areas within a digital elevation model that are
surrounded by higher terrain, with no outlet to lower areas. Filling them so
they are level, as fluid would fill them if the terrain were impermeable, is
often necessary in preprocessing DEMs. The depression-filling algorithm
presented here---called Priority-Flood---unifies and improves on the work of a
number of previous authors who have published similar algorithms. The algorithm
operates by flooding DEMs inwards from their edges using a priority queue to
determine the next cell to be flooded. The resultant DEM has no depressions or
digital dams: every cell is guaranteed to drain. The algorithm is optimal for
both integer and floating-point data, working in O(n) and O(n lg n) time,
respectively. It is shown that by using a plain queue to fill depressions once
they have been found, an O(m lg m) time-complexity can be achieved, where m
does not exceed the number of cells n. This is the lowest time complexity of
any known floating-point depression-filling algorithm. In testing, this
improved variation of the algorithm performed up to 37% faster than the
original. Additionally, a parallel version of an older, but widely-used
depression-filling algorithm required six parallel processors to achieve a
run-time on par with what the newer algorithm's improved variation took on a
single processor. The Priority-Flood Algorithm is simple to understand and
implement: the included pseudocode is only 20 lines and the included C++
reference implementation is under a hundred lines. The algorithm can work on
irregular meshes as well as 4-, 6-, 8-, and n-connected grids. It can also be
adapted to label watersheds and determine flow directions through either
incremental elevation changes or depression carving. In the case of incremental
elevation changes, the algorithm includes safety checks not present in prior
works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04466</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04466</id><created>2015-11-13</created><authors><author><keyname>Lee</keyname><forenames>Jasper C. H.</forenames></author><author><keyname>Valiant</keyname><forenames>Paul</forenames></author></authors><title>Beyond Convex Optimization: Star-Convex Functions</title><categories>cs.DS</categories><comments>24 pages (including appendices), submitted to STOC '16</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a polynomial time algorithm for optimizing the class of
star-convex functions, under no restrictions except boundedness on a region
about the origin, and Lebesgue measurability. The algorithm's performance is
polynomial in the requested number of digits of accuracy, exponentially faster
than the previous best known algorithm of Nesterov and Polyak that further
requires Lipschitz second differentiability of the function. Star-convex
functions constitute a rich class of functions generalizing convex functions,
including, for example: for any convex (or star-convex) functions $f, g$, with
global minima $f(0)=g(0)=0$, their power mean
$h(x)=(\frac{f(x)^p+g(x)^p}{2})^{1/p}$ is star-convex, for any real $p$,
defining powers via limits as appropriate. Star-convex functions arise as loss
functions in non-convex machine learning contexts, including, for data points
$X_i$, parameter vector $\theta$, and exponent $p\in (0,1)$, the loss function
$h_{\theta,X}(\hat{\theta})=(\sum_i |(\hat{\theta}-\theta)\cdot X_i|^p)^{1/p}$.
Further, for ANY function $g&gt;0$ on the surface of the unit sphere, the
star-convex function $h(x)=||x||_2\cdot g\left(\frac{x}{||x||_2}\right)$
extends the arbitrary behavior of $g$ to the whole space.
  Our algorithm introduces a new method to find cutting planes, via sampling
the objective function on Gaussian regions across an exponentially large range
of widths. Our algorithm looks for structure at all scales, since, unlike
convex functions, star-convex functions do not necessarily display simpler
behavior on smaller length scales. We emphasize that the class of star-convex
functions we consider is as unrestricted as possible, assuming Lebesgue
measurability only so that sampling of objective function values is
well-defined.
  We view our results as a step forward in understanding the scope of
optimization techniques beyond the garden of convex optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04467</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04467</id><created>2015-11-13</created><authors><author><keyname>Esposito</keyname><forenames>Umberto</forenames></author><author><keyname>Vasilaki</keyname><forenames>Eleni</forenames></author></authors><title>Detection of multiple and overlapping bidirectional communities within
  large, directed and weighted networks of neurons</title><categories>cs.SI cs.DS physics.soc-ph q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the recent explosion of publicly available biological data, the analysis
of networks has gained significant interest. In particular, recent promising
results in Neuroscience show that the way neurons and areas of the brain are
connected to each other plays a fundamental role in cognitive functions and
behaviour. Revealing pattern and structures within such an intricate volume of
connections is a hard problem that has its roots in Graph and Network Theory.
Since many real world situations can be modelled through networks, structures
detection algorithms find application in almost every field of Science. These
are NP-complete problems; therefore the generally used approach is through
heuristic algorithms. Here, we formulate the problem of finding structures in
networks of neurons in terms of a community detection problem. We introduce a
definition of community and we construct a statistics-based heuristic algorithm
for directed and weighted networks aiming at identifying overlapping
bidirectional communities in large networks. We carry out a systematic analysis
of the algorithm's performance, showing excellent results over a wide range of
parameters (successful detection percentages almost $100\%$ all the time).
Also, we show results on the computational time needed and we suggest future
directions on how to improve computational performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04472</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04472</id><created>2015-11-13</created><authors><author><keyname>Yu</keyname><forenames>Rui</forenames></author><author><keyname>Russell</keyname><forenames>Chris</forenames></author><author><keyname>Agapito</keyname><forenames>Lourdes</forenames></author></authors><title>Solving Jigsaw Puzzles with Linear Programming</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel Linear Program (LP) based formula- tion for solving jigsaw
puzzles. We formulate jigsaw solving as a set of successive global convex
relaxations of the stan- dard NP-hard formulation, that can describe both
jigsaws with pieces of unknown position and puzzles of unknown po- sition and
orientation. The main contribution and strength of our approach comes from the
LP assembly strategy. In contrast to existing greedy methods, our LP solver
exploits all the pairwise matches simultaneously, and computes the position of
each piece/component globally. The main ad- vantages of our LP approach
include: (i) a reduced sensi- tivity to local minima compared to greedy
approaches, since our successive approximations are global and convex and (ii)
an increased robustness to the presence of mismatches in the pairwise matches
due to the use of a weighted L1 penalty. To demonstrate the effectiveness of
our approach, we test our algorithm on public jigsaw datasets and show that it
outperforms state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04478</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04478</id><created>2015-11-13</created><authors><author><keyname>Fasi</keyname><forenames>Massimiliano</forenames></author><author><keyname>Langou</keyname><forenames>Julien</forenames></author><author><keyname>Robert</keyname><forenames>Yves</forenames></author><author><keyname>Ucar</keyname><forenames>Bora</forenames></author></authors><title>A Backward/Forward Recovery Approach for the Preconditioned Conjugate
  Gradient Method</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several recent papers have introduced a periodic verification mechanism to
detect silent errors in iterative solvers. Chen [PPoPP'13, pp. 167--176] has
shown how to combine such a verification mechanism (a stability test checking
the orthogonality of two vectors and recomputing the residual) with
checkpointing: the idea is to verify every $d$ iterations, and to checkpoint
every $c \times d$ iterations. When a silent error is detected by the
verification mechanism, one can rollback to and re-execute from the last
checkpoint. In this paper, we also propose to combine checkpointing and
verification, but we use algorithm-based fault tolerance (ABFT) rather than
stability tests. ABFT can be used for error detection, but also for error
detection and correction, allowing a forward recovery (and no rollback nor
re-execution) when a single error is detected. We introduce an abstract
performance model to compute the performance of all schemes, and we instantiate
it using the preconditioned conjugate gradient algorithm. Finally, we validate
our new approach through a set of simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04479</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04479</id><created>2015-11-13</created><authors><author><keyname>F&#xfc;rer</keyname><forenames>Martin</forenames></author></authors><title>Multi-Clique-Width</title><categories>cs.DM cs.DS</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-clique-width is obtained by a simple modification in the definition of
clique-width. It has the advantage of providing a natural extension of
tree-width. Unlike clique-width, it does not explode exponentially compared to
tree-width. Efficient algorithms based on multi-clique-width are still possible
for interesting tasks like computing the independent set polynomial or testing
$c$-colorability. In particular, $c$-colorability can be tested in time linear
in $n$ and singly exponential in $c$ and the width $k$ of a given
multi-$k$-expression. For these tasks, the running time as a function of the
multi-clique-width is the same as the running time of the fastest known
algorithm as a function of the clique-width. This results in an exponential
speed-up for some graphs, if the corresponding graph generating expressions are
given. The reason is that the multi-clique-width is never bigger, but is
exponentially smaller than the clique-width for many graphs. This gap shows up
when the tree-width is basically equal to the multi-clique width as well as
when the tree-width is not bounded by any function of the clique-width.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04484</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04484</id><created>2015-11-13</created><authors><author><keyname>Neftci</keyname><forenames>Emre O.</forenames></author><author><keyname>Pedroni</keyname><forenames>Bruno U.</forenames></author><author><keyname>Joshi</keyname><forenames>Siddharth</forenames></author><author><keyname>Al-Shedivat</keyname><forenames>Maruan</forenames></author><author><keyname>Cauwenberghs</keyname><forenames>Gert</forenames></author></authors><title>Unsupervised Learning in Synaptic Sampling Machines</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies have shown that synaptic unreliability is a robust and
sufficient mechanism for inducing the stochasticity observed in cortex. Here,
we introduce the Synaptic Sampling Machine (SSM), a stochastic neural network
model that uses synaptic unreliability as a means to stochasticity for
sampling. Synaptic unreliability plays the dual role of an efficient mechanism
for sampling in neuromorphic hardware, and a regularizer during learning akin
to DropConnect. Similar to the original formulation of Boltzmann machines, the
SSM can be viewed as a stochastic counterpart of Hopfield networks, but where
stochasticity is induced by a random mask over the connections. The SSM is
trained to learn generative models with a synaptic plasticity rule implementing
an event-driven form of contrastive divergence. We demonstrate this by learning
a model of MNIST hand-written digit dataset, and by testing it in recognition
and inference tasks. We find that SSMs outperform restricted Boltzmann machines
(4.4% error rate vs. 5%), they are more robust to overfitting, and tend to
learn sparser representations. SSMs are remarkably robust to weight pruning:
removal of more than 80% of the weakest connections followed by cursory
re-learning causes only a negligible performance loss on the MNIST task (4.8%
error rate). These results show that SSMs offer substantial improvements in
terms of performance, power and complexity over existing methods for
unsupervised learning in spiking neural networks, and are thus promising models
for machine learning in neuromorphic execution platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04491</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04491</id><created>2015-11-13</created><authors><author><keyname>Kim</keyname><forenames>Jiwon</forenames></author><author><keyname>Lee</keyname><forenames>Jung Kwon</forenames></author><author><keyname>Lee</keyname><forenames>Kyoung Mu</forenames></author></authors><title>Deeply-Recursive Convolutional Network for Image Super-Resolution</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an image super-resolution method (SR) using a deeply-recursive
convolutional network (DRCN). Our network has a very deep recursive layer (up
to 16 recursions). Increasing recursion depth can improve performance without
introducing new parameters for additional convolutions. Albeit advantages,
learning a DRCN is very hard with a standard gradient descent method due to
exploding/vanishing gradients. To ease the difficulty of training, we propose
two extensions: recursive-supervision and skip-connection. Our method
outperforms previous methods by a large margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04493</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04493</id><created>2015-11-13</created><authors><author><keyname>Zhang</keyname><forenames>Huijing</forenames></author><author><keyname>Choffnes</keyname><forenames>David</forenames></author></authors><title>Client-Side Web Proxy Detection from Unprivileged Mobile Devices</title><categories>cs.NI cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile devices that connect to the Internet via cellular networks are rapidly
becoming the primary medium for accessing Web content. Cellular service
providers (CSPs) commonly deploy Web proxies and other middleboxes for
security, performance optimization and traffic engineering reasons. However,
the prevalence and policies of these Web proxies are generally opaque to users
and difficult to measure without privileged access to devices and servers. In
this paper, we present a methodology to detect the presence of Web proxies
without requiring access to low-level packet traces on a device, nor access to
servers being contacted. We demonstrate the viability of this technique using
controlled experiments, and present the results of running our approach on
several production networks and popular Web sites. Next, we characterize the
behaviors of these Web proxies, including caching, redirecting, and content
rewriting. Our analysis can identify how Web proxies impact network
performance, and inform policies for future deployments. Last, we release an
Android app called Proxy Detector on the Google Play Store, allowing average
users with unprivileged (non-rooted) devices to understand Web proxy
deployments and contribute to our IRB-approved study. We report on results of
using this app on 11 popular carriers from the US, Canada, Austria, and China.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04494</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04494</id><created>2015-11-13</created><authors><author><keyname>Bereg</keyname><forenames>Sergey</forenames></author><author><keyname>Levy</keyname><forenames>Avi</forenames></author><author><keyname>Sudborough</keyname><forenames>I. Hal</forenames></author></authors><title>Constructing Permutation Arrays from Groups</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let M(n,d) be the maximum size of a permutation array on n symbols with
pairwise Hamming distance at least d. We use various combinatorial, algebraic,
and computational methods to improve lower bounds for M(n,d). Some lower bounds
are based on a new computational approach called a coset method. We also use
algebraic techniques, involving computing the Hamming distances of affine
semilinear groups and projective semilinear groups, and unions of cosets of
AGL(1,q) and PGL(2,q) with Frobenius maps to obtain infinitely many new,
improved lower bounds for M(n,d). We give new randomized algorithms for
computing cosets. For example, we show that M(13,4) is at least 60,635,520,
where 41,712,480 was previously the best lower bound. Furthermore, this
permutation array consists of a union of 638 cosets of a group of 95,040
permutations, so it can be recorded and verified quickly. An up-to-date table
of lower bounds for M(n,d) is also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04508</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04508</id><created>2015-11-13</created><authors><author><keyname>Papernot</keyname><forenames>Nicolas</forenames></author><author><keyname>McDaniel</keyname><forenames>Patrick</forenames></author><author><keyname>Wu</keyname><forenames>Xi</forenames></author><author><keyname>Jha</keyname><forenames>Somesh</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>Distillation as a Defense to Adversarial Perturbations against Deep
  Neural Networks</title><categories>cs.CR cs.LG cs.NE stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning algorithms have been shown to perform extremely well on many
classical machine learning problems. However, recent studies have shown that
deep learning is vulnerable to adversarial samples: inputs crafted to force a
deep neural network (DNN) to provide adversary-selected outputs. Such attacks
can seriously undermine the security of the system supported by the DNN,
sometimes with devastating consequences. For example, autonomous vehicles can
be crashed, illicit or illegal content can bypass content filters, or biometric
authentication systems can be manipulated to allow improper access. In this
work, we introduce a defensive mechanism called defensive distillation to
reduce the effectiveness of adversarial samples on DNNs. We analytically
investigate the generalizability and robustness properties granted by the use
of defensive distillation when training DNNs. We also empirically study the
effectiveness of our defense mechanisms on two DNNs placed in adversarial
settings. The study shows that defensive distillation can reduce effectiveness
of sample creation from 95% to less than 0.5% on a studied DNN. Such dramatic
gains can be explained by the fact that distillation leads gradients used in
adversarial sample creation to be reduced by a factor of 10^30. We also find
that distillation increases the average minimum number of features that need to
be modified to create adversarial samples by about 800% on one of the DNNs we
tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04510</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04510</id><created>2015-11-14</created><authors><author><keyname>Liang</keyname><forenames>Xiaodan</forenames></author><author><keyname>Shen</keyname><forenames>Xiaohui</forenames></author><author><keyname>Xiang</keyname><forenames>Donglai</forenames></author><author><keyname>Feng</keyname><forenames>Jiashi</forenames></author><author><keyname>Lin</keyname><forenames>Liang</forenames></author><author><keyname>Yan</keyname><forenames>Shuicheng</forenames></author></authors><title>Semantic Object Parsing with Local-Global Long Short-Term Memory</title><categories>cs.CV</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semantic object parsing is a fundamental task for understanding objects in
detail in computer vision community, where incorporating multi-level contextual
information is critical for achieving such fine-grained pixel-level
recognition. Prior methods often leverage the contextual information through
post-processing predicted confidence maps. In this work, we propose a novel
deep Local-Global Long Short-Term Memory (LG-LSTM) architecture to seamlessly
incorporate short-distance and long-distance spatial dependencies into the
feature learning over all pixel positions. In each LG-LSTM layer, local
guidance from neighboring positions and global guidance from the whole image
are imposed on each position to better exploit complex local and global
contextual information. Individual LSTMs for distinct spatial dimensions are
also utilized to intrinsically capture various spatial layouts of semantic
parts in the images, yielding distinct hidden and memory cells of each position
for each dimension. In our parsing approach, several LG-LSTM layers are stacked
and appended to the intermediate convolutional layers to directly enhance
visual features, allowing network parameters to be learned in an end-to-end
way. The long chains of sequential computation by stacked LG-LSTM layers also
enable each pixel to sense a much larger region for inference benefiting from
the memorization of previous dependencies in all positions along all
dimensions. Comprehensive evaluations on three public datasets well demonstrate
the significant superiority of our LG-LSTM over other state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04511</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04511</id><created>2015-11-14</created><authors><author><keyname>Zhang</keyname><forenames>Ziming</forenames></author><author><keyname>Liu</keyname><forenames>Yun</forenames></author><author><keyname>Bolukbasi</keyname><forenames>Tolga</forenames></author><author><keyname>Cheng</keyname><forenames>Ming-Ming</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>BING++: A Fast High Quality Object Proposal Generator at 100fps</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are motivated by the need for an object proposal generation algorithm that
achieves a good balance between proposal localization quality, object recall
and computational efficiency. We propose a novel object proposal algorithm {\em
BING++} which inherits the good computational efficiency of BING
\cite{BingObj2014} but significantly improves its proposal localization
quality. Central to our success is based on the observation that good bounding
boxes are those that tightly cover objects. Edge features, which can be
computed efficiently, play a critical role in this context. We propose a new
algorithm that recursively improves BING's proposals by exploiting the fact
that edges in images are typically associated with object boundaries. BING++
improves proposals recursively by incorporating nearest edge points (to
proposal boundary pixels) to obtain a tighter bounding box. This operation has
linear computational complexity in number of pixels and can be done efficiently
using distance transform. Superpixel merging techniques are then employed as
post-processing to further improve the proposal quality. Empirically on the
VOC2007 dataset, using $10^3$ proposals and IoU threshold 0.5, our method
achieves 95.3\% object detection recall (DR), 79.2\% mean average best overlap
(MABO), and 68.7\% mean average precision (mAP) on object detection over 20
object classes within an average time of {\bf 0.009} seconds per image.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04512</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04512</id><created>2015-11-14</created><authors><author><keyname>Zhang</keyname><forenames>Ziming</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>Classifying Unseen Instances by Learning Class-Independent Similarity
  Functions</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Zero-shot recognition (ZSR) deals with the problem of predicting class labels
for target domain instances based on source domain side information (\eg
attributes) of unseen classes. We formulate ZSR as a binary prediction problem.
Our resulting classifier is class-agnostic. It takes an arbitrary pair of
source and target domain instances as input and predicts whether or not they
come from the same class, \ie whether there is a match. We model the posterior
probability of a match since it is a sufficient statistic and propose a latent
probabilistic model in this context. We develop a joint discriminative learning
framework based on dictionary learning to jointly learn the parameters of our
model for both domains, which ultimately leads to our class-agnostic
classifier. Many of the existing embedding methods can be viewed as special
cases of our probabilistic model. On ZSR our method shows 4.90\% improvement
over the state-of-the-art in accuracy averaged across four benchmark datasets.
We also adapt ZSR method for zero-shot retrieval and show 22.45\% improvement
accordingly in mean average precision (mAP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04514</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04514</id><created>2015-11-14</created><authors><author><keyname>Yang</keyname><forenames>Zhuoran</forenames></author><author><keyname>Wang</keyname><forenames>Zhaoran</forenames></author><author><keyname>Liu</keyname><forenames>Han</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Sparse Nonlinear Regression: Parameter Estimation and Asymptotic
  Inference</title><categories>stat.ML cs.IT cs.LG math.IT math.OC</categories><comments>32 pages, 2 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study parameter estimation and asymptotic inference for sparse nonlinear
regression. More specifically, we assume the data are given by $y = f( x^\top
\beta^* ) + \epsilon$, where $f$ is nonlinear. To recover $\beta^*$, we propose
an $\ell_1$-regularized least-squares estimator. Unlike classical linear
regression, the corresponding optimization problem is nonconvex because of the
nonlinearity of $f$. In spite of the nonconvexity, we prove that under mild
conditions, every stationary point of the objective enjoys an optimal
statistical rate of convergence. In addition, we provide an efficient algorithm
that provably converges to a stationary point. We also access the uncertainty
of the obtained estimator. Specifically, based on any stationary point of the
objective, we construct valid hypothesis tests and confidence intervals for the
low dimensional components of the high-dimensional parameter $\beta^*$.
Detailed numerical results are provided to back up our theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04515</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04515</id><created>2015-11-14</created><authors><author><keyname>Zhuang</keyname><forenames>Hao</forenames></author><author><keyname>Yu</keyname><forenames>Wenjian</forenames></author><author><keyname>Kang</keyname><forenames>Ilgweon</forenames></author><author><keyname>Wang</keyname><forenames>Xinan</forenames></author><author><keyname>Cheng</keyname><forenames>Chung-Kuan</forenames></author></authors><title>An Algorithmic Framework for Efficient Large-Scale Circuit Simulation
  Using Exponential Integrators</title><categories>cs.CE cs.NA math.NA</categories><comments>6 pages; ACM/IEEE DAC 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient algorithmic framework for time domain circuit
simulation using exponential integrator. This work addresses several critical
issues exposed by previous matrix exponential based circuit simulation
research, and makes it capable of simulating stiff nonlinear circuit system at
a large scale. In this framework, the system's nonlinearity is treated with
exponential Rosenbrock-Euler formulation. The matrix exponential and vector
product is computed using invert Krylov subspace method. Our proposed method
has several distinguished advantages over conventional formulations (e.g., the
well-known backward Euler with Newton-Raphson method). The matrix factorization
is performed only for the conductance/resistance matrix G, without being
performed for the combinations of the capacitance/inductance matrix C and
matrix G, which are used in traditional implicit formulations. Furthermore, due
to the explicit nature of our formulation, we do not need to repeat LU
decompositions when adjusting the length of time steps for error controls. Our
algorithm is better suited to solving tightly coupled post-layout circuits in
the pursuit for full-chip simulation. Our experimental results validate the
advantages of our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04517</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04517</id><created>2015-11-14</created><updated>2015-11-18</updated><authors><author><keyname>Liang</keyname><forenames>Xiaodan</forenames></author><author><keyname>Wei</keyname><forenames>Yunchao</forenames></author><author><keyname>Shen</keyname><forenames>Xiaohui</forenames></author><author><keyname>Jie</keyname><forenames>Zequn</forenames></author><author><keyname>Feng</keyname><forenames>Jiashi</forenames></author><author><keyname>Lin</keyname><forenames>Liang</forenames></author><author><keyname>Yan</keyname><forenames>Shuicheng</forenames></author></authors><title>Reversible Recursive Instance-level Object Segmentation</title><categories>cs.CV</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we propose a novel Reversible Recursive Instance-level Object
Segmentation (R2-IOS) framework to address the challenging instance-level
object segmentation task. R2-IOS consists of a reversible proposal refinement
sub-network that predicts bounding box offsets for refining the object proposal
locations, and an instance-level segmentation sub-network that generates the
foreground mask of the dominant object instance in each proposal. By being
recursive, R2-IOS iteratively optimizes the two sub-networks during joint
training, in which the refined object proposals and improved segmentation
predictions are alternately fed into each other to progressively increase the
network capabilities. By being reversible, the proposal refinement sub-network
adaptively determines an optimal number of refinement iterations required for
each proposal during both training and testing. Furthermore, to handle multiple
overlapped instances within a proposal, an instance-aware denoising autoencoder
is introduced into the segmentation sub-network to distinguish the dominant
object from other distracting instances. Extensive experiments on the
challenging PASCAL VOC 2012 benchmark well demonstrate the superiority of
R2-IOS over other state-of-the-art methods. In particular, the $\text{AP}^r$
over $20$ classes at $0.5$ IoU achieves $66.7\%$, which significantly
outperforms the results of $58.7\%$ by PFN~\cite{PFN} and $46.3\%$
by~\cite{liu2015multi}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04519</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04519</id><created>2015-11-14</created><authors><author><keyname>Zhuang</keyname><forenames>Hao</forenames></author><author><keyname>Weng</keyname><forenames>Shih-Hung</forenames></author><author><keyname>Lin</keyname><forenames>Jeng-Hau</forenames></author><author><keyname>Cheng</keyname><forenames>Chung-Kuan</forenames></author></authors><title>MATEX: A Distributed Framework for Transient Simulation of Power
  Distribution Networks</title><categories>cs.CE cs.DC cs.NA</categories><comments>ACM/IEEE DAC 2014. arXiv admin note: substantial text overlap with
  arXiv:1505.06699</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We proposed MATEX, a distributed framework for transient simulation of power
distribution networks (PDNs). MATEX utilizes matrix exponential kernel with
Krylov subspace approximations to solve differential equations of linear
circuit. First, the whole simulation task is divided into subtasks based on
decompositions of current sources, in order to reduce the computational
overheads. Then these subtasks are distributed to different computing nodes and
processed in parallel. Within each node, after the matrix factorization at the
beginning of simulation, the adaptive time stepping solver is performed without
extra matrix re-factorizations. MATEX overcomes the stiff-ness hinder of
previous matrix exponential-based circuit simulator by rational Krylov subspace
method, which leads to larger step sizes with smaller dimensions of Krylov
subspace bases and highly accelerates the whole computation. MATEX outperforms
both traditional fixed and adaptive time stepping methods, e.g., achieving
around 13X over the trapezoidal framework with fixed time step for the IBM
power grid benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04524</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04524</id><created>2015-11-14</created><authors><author><keyname>Zhang</keyname><forenames>Ziming</forenames></author><author><keyname>Chen</keyname><forenames>Yuting</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>Supervised Hashing with Deep Neural Networks</title><categories>cs.CV cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose training very deep neural networks (DNNs) for
supervised learning of hash codes. Existing methods in this context train
relatively &quot;shallow&quot; networks limited by the issues arising in back propagation
(\eg vanishing gradients) as well as computational efficiency. We propose a
novel and efficient training algorithm inspired by alternating direction method
of multipliers (ADMM) that overcomes some of these limitations. Our method
decomposes the training process into independent layer-wise local updates
through auxiliary variables. Empirically we observe that our training algorithm
always converges and its computational complexity is linearly proportional to
the number of edges in the networks. Empirically we manage to train DNNs with
64 hidden layers and 1024 nodes per layer for supervised hashing in about 3
hours using a single GPU. Our proposed very deep supervised hashing (VDSH)
method significantly outperforms the state-of-the-art on several benchmark
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04534</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04534</id><created>2015-11-14</created><authors><author><keyname>Wang</keyname><forenames>Zhenhua</forenames></author><author><keyname>Wang</keyname><forenames>Xingxing</forenames></author><author><keyname>Wang</keyname><forenames>Gang</forenames></author></authors><title>Learning Fine-grained Features via a CNN Tree for Large-scale
  Classification</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We propose a novel approach to enhance the discriminability of Convolutional
Neural Networks (CNN). The key idea is to build a tree structure that could
progressively learn fine-grained features to distinguish a subset of classes,
by learning features only among these classes. Such features are expected to be
more discriminative, compared to features learned for all the classes. We
develop a new algorithm to effectively learn the tree structure among a large
number of classes. Experiments on large-scale image classification tasks
demonstrate that our method could boost the performance of a given basic CNN
model. Our method is quite general, hence it can potentially be used in
combination with many other deep learning models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04536</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04536</id><created>2015-11-14</created><authors><author><keyname>V</keyname><forenames>Sarasvathi</forenames></author><author><keyname>Saha</keyname><forenames>Snehanshu</forenames></author><author><keyname>Iyengar</keyname><forenames>N. Ch. S. N.</forenames></author><author><keyname>Koti</keyname><forenames>Mahalaxmi</forenames></author></authors><title>Coefficient of Restitution based Cross Layer Interference Aware Routing
  Protocol in Wireless Mesh Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Multi-Radio Multi-Channel (MRMC) Wireless Mesh Networks (WMN), Partially
Overlapped Channels (POC) has been used to increase the parallel transmission.
But adjacent channel interference is very severe in MRMC environment; it
decreases the network throughput very badly. In this paper, we propose a
Coefficient of Restitution based Cross layer Interference aware Routing
protocol (CoRCiaR) to improve TCP performance in Wireless Mesh Networks. This
approach comprises of two-steps: Initially, the interference detection
algorithm is developed at MAC layer by enhancing the RTS/CTS method. Based on
the channel interference, congestion is identified by Round Trip Time (RTT)
measurements, and subsequently the route discovery module selects the
alternative path to send the data packet. The packets are transmitted to the
congestion free path seamlessly by the source. The performance of the proposed
CoRCiaR protocol is measured by Coefficient of Restitution (COR) parameter. The
impact of the rerouting is experienced on the network throughput performance.
The simulation results show that the proposed cross layer interference aware
dynamic routing enhances the TCP performance on WMN.
  Keywords: Coefficient of Restitution, Wireless Mesh Networks, Partially
Overlapped Channels, Round Trip Time, Multi-Radio, Multi-Channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04541</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04541</id><created>2015-11-14</created><updated>2016-01-07</updated><authors><author><keyname>Arachchilage</keyname><forenames>Nalin Asanka Gamagedara</forenames></author><author><keyname>Martin</keyname><forenames>Andrew</forenames></author></authors><title>A Trust Domains Taxonomy for Securely Sharing Information: A Preliminary
  Investigation</title><categories>cs.CR</categories><comments>16, Eighth International Symposium on Human Aspects of Information
  Security &amp; Assurance (HAISA 2014)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information sharing has become a vital part in our day-to-day life due to the
pervasiveness of Internet technology. In any given collaboration, information
needs to flow from one participant to another. While participants may be
interested in sharing information with one another, it is often necessary for
them to establish the impact of sharing certain kinds of information. This is
because certain information could have detrimental effects when it ends up in
wrong hands. For this reason, any would-be participant in a given collaboration
may need to establish the guarantees that the collaboration provides, in terms
of protecting sensitive information, before joining the collaboration as well
as evaluating the impact of sharing a given piece of information with a given
set of entities. In order to address this issue, earlier work introduced a
trust domains taxonomy that aims at managing trust-related issues in
information sharing. This paper attempts to empirically investigate the
proposed taxonomy through a possible scenario (e.g. the ConfiChair system). The
study results determined that Role, Policy, Action, Control, Evidence and Asset
elements should be incorporated into the taxonomy for securely sharing
information among others. Additionally, the study results showed that the
ConfiChair, a novel cloud-based conference management system, offers strong
privacy and confidentiality guarantees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04557</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04557</id><created>2015-11-14</created><authors><author><keyname>Arend</keyname><forenames>Lionel</forenames></author><author><keyname>Krause</keyname><forenames>Jens</forenames></author><author><keyname>Marso</keyname><forenames>Michel</forenames></author><author><keyname>Sperber</keyname><forenames>Ray</forenames></author></authors><title>Four-dimensional signalling schemes - Application to satellite
  communications</title><categories>cs.IT math.IT</categories><comments>14 pages, 9 figures</comments><msc-class>94A14</msc-class><acm-class>J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In satellite communications both polarizations of an electromagnetic wave are
used to transmit two separate signals. These two independent signals can be
merged to form one dual-polarization, four-dimensional signal.
  The present article pursues this idea and proposes different signal
constellations to be used for four-dimensional signalling in satellite links.
Analytical methods and simulations predict an increased power efficiency of
these constellations with respect to currently used transmission methods. The
cost of this advantage is evaluated considering the limited applicability in
non-linear channels.
  Four-dimensional signalling also implies simultaneous reception on both
polarizations. Such a combined reception allows the precision of timing and
carrier recovery loops to be doubled. This claim is derived analytically and
illustrated by simulating an example case.
  An experimental transmitter/receiver pair was implemented and used to
demonstrate a satellite transmission using a four-dimensional, bi-orthogonal
signal in the dual-polarization channel. The experimental verification confirms
the presented simulation results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04561</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04561</id><created>2015-11-14</created><updated>2016-02-19</updated><authors><author><keyname>Dettmers</keyname><forenames>Tim</forenames></author></authors><title>8-Bit Approximations for Parallelism in Deep Learning</title><categories>cs.NE cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The creation of practical deep learning data-products often requires
parallelization across processors and computers to make deep learning feasible
on large data sets, but bottlenecks in communication bandwidth make it
difficult to attain good speedups through parallelism. Here we develop and test
8-bit approximation algorithms which make better use of the available bandwidth
by compressing 32-bit gradients and nonlinear activations to 8-bit
approximations. We show that these approximations do not decrease predictive
performance on MNIST, CIFAR10, and ImageNet for both model and data parallelism
and provide a data transfer speedup of 2x relative to 32-bit parallelism. We
build a predictive model for speedups based on our experimental data, verify
its validity on known speedup data, and show that we can obtain a speedup of
50x and more on a system of 96 GPUs compared to a speedup of 23x for 32-bit. We
compare our data types with other methods and show that 8-bit approximations
achieve state-of-the-art speedups for model parallelism. Thus 8-bit
approximation is an efficient method to parallelize convolutional networks on
very large systems of GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04581</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04581</id><created>2015-11-14</created><updated>2016-02-15</updated><authors><author><keyname>Bounliphone</keyname><forenames>Wacha</forenames></author><author><keyname>Belilovsky</keyname><forenames>Eugene</forenames></author><author><keyname>Blaschko</keyname><forenames>Matthew B.</forenames></author><author><keyname>Antonoglou</keyname><forenames>Ioannis</forenames></author><author><keyname>Gretton</keyname><forenames>Arthur</forenames></author></authors><title>A Test of Relative Similarity For Model Selection in Generative Models</title><categories>stat.ML cs.LG</categories><comments>International Conference on Learning Representations 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic generative models provide a powerful framework for representing
data that avoids the expense of manual annotation typically needed by
discriminative approaches. Model selection in this generative setting can be
challenging, however, particularly when likelihoods are not easily accessible.
To address this issue, we introduce a statistical test of relative similarity,
which is used to determine which of two models generates samples that are
significantly closer to a real-world reference dataset of interest. We use as
our test statistic the difference in maximum mean discrepancies (MMDs) between
the reference dataset and each model dataset, and derive a powerful,
low-variance test based on the joint asymptotic distribution of the MMDs
between each reference-model pair. In experiments on deep generative models,
including the variational auto-encoder and generative moment matching network,
the tests provide a meaningful ranking of model performance as a function of
parameter and training settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04582</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04582</id><created>2015-11-14</created><authors><author><keyname>Brajovic</keyname><forenames>Milo&#x161;</forenames></author><author><keyname>Orovic</keyname><forenames>Irena</forenames></author><author><keyname>Dakovic</keyname><forenames>Milos</forenames></author><author><keyname>Stankovic</keyname><forenames>Srdjan</forenames></author></authors><title>Compressive Sensing of Sparse Signals in the Hermite Transform Basis:
  Analysis and Algorithm for Signal Reconstruction</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An analysis of the influence of missing samples in signals exhibiting
sparsity in the Hermite transform domain is provided. Based on the statistical
properties derived for the Hermite coefficients of randomly undersampled
signal, the probability of success in detection of signal components support is
determined. Based on the probabilistic analysis, a threshold for the detection
of signal components is provided. It is a crucial step in the definition of a
simple non-iterative algorithm for compressive sensing signal reconstruction.
The derived theoretical concepts are proved on several examples using different
statistical tests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04583</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04583</id><created>2015-11-14</created><updated>2015-11-24</updated><authors><author><keyname>Liu</keyname><forenames>Yanhong A.</forenames></author><author><keyname>Brandvein</keyname><forenames>Jon</forenames></author><author><keyname>Stoller</keyname><forenames>Scott D.</forenames></author><author><keyname>Lin</keyname><forenames>Bo</forenames></author></authors><title>Demand-Driven Incremental Object Queries</title><categories>cs.PL cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object queries are significantly easier to write, understand, and maintain
than efficient low-level programs. However, a query may involve any number and
combination of objects and sets, which can be arbitrarily nested and aliased.
The objects and sets involved, starting from the given demand---the given
parameter values of interest---can change arbitrarily. How to generate
efficient implementations automatically, and furthermore to provide complexity
guarantees?
  This paper describes such an automatic method. The method allows the queries
to be written completely declaratively. It transforms demand into relations,
based on the same basic idea for transforming objects and sets into relations
in a prior work. Most importantly, it defines and incrementally maintains
invariants for not only the query results, but also all auxiliary values about
the objects and sets involved, starting from the demand. Implementation and
experiments with problems from a variety of application areas, including
distributed algorithms, confirm the analyzed complexities, trade-offs, and
significant improvements over prior works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04585</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04585</id><created>2015-11-14</created><authors><author><keyname>Orovic</keyname><forenames>Irena</forenames></author><author><keyname>Draganic</keyname><forenames>Andjela</forenames></author><author><keyname>Lekic</keyname><forenames>Nedjeljko</forenames></author><author><keyname>Stankovic</keyname><forenames>Srdjan</forenames></author></authors><title>A System for Compressive Sensing Signal Reconstruction</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An architecture for hardware realization of a system for sparse signal
reconstruction is presented. The system is grounded on the threshold based
single iteration algorithm. The threshold is used for creating a partial random
Fourier matrix. Then, applying the least square based optimization, the
accurate signal reconstruction is achieved. Instead of using the original
partial random Fourier transform matrix, the problem is efficiently solved and
implemented in hardware by employing only the triangular R matrix from the QR
decomposition method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04586</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04586</id><created>2015-11-14</created><authors><author><keyname>Ling</keyname><forenames>Wang</forenames></author><author><keyname>Trancoso</keyname><forenames>Isabel</forenames></author><author><keyname>Dyer</keyname><forenames>Chris</forenames></author><author><keyname>Black</keyname><forenames>Alan W</forenames></author></authors><title>Character-based Neural Machine Translation</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a neural machine translation model that views the input and
output sentences as sequences of characters rather than words. Since word-level
information provides a crucial source of bias, our input model composes
representations of character sequences into representations of words (as
determined by whitespace boundaries), and then these are translated using a
joint attention/translation model. In the target language, the translation is
modeled as a sequence of word vectors, but each word is generated one character
at a time, conditional on the previous character generations in each word. As
the representation and generation of words is performed at the character level,
our model is capable of interpreting and generating unseen word forms. A
secondary benefit of this approach is that it alleviates much of the challenges
associated with preprocessing/tokenization of the source and target languages.
We show that our model can achieve translation results that are on par with
conventional word-based models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04587</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04587</id><created>2015-11-14</created><authors><author><keyname>Kim</keyname><forenames>Jiwon</forenames></author><author><keyname>Lee</keyname><forenames>Jung Kwon</forenames></author><author><keyname>Lee</keyname><forenames>Kyoung Mu</forenames></author></authors><title>Accurate Image Super-Resolution Using Very Deep Convolutional Networks</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a highly accurate single-image super-resolution (SR) method. Our
method uses a very deep convolutional network inspired by VGG-net used for
ImageNet classification \cite{simonyan2015very}. We find increasing our network
depth shows a significant improvement in accuracy. Our final model uses 20
weight layers. By cascading small filters many times in a deep network
structure, contextual information over large image regions is exploited in an
efficient way. With very deep networks, however, convergence speed becomes a
critical issue during training. We propose a simple yet effective training
procedure. We learn residuals only and use extremely high learning rates
($10^4$ times higher than SRCNN \cite{dong2015image}) enabled by adjustable
gradient clipping. Our proposed method performs better than existing methods in
accuracy and visual improvements in our results are easily noticeable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04590</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04590</id><created>2015-11-14</created><updated>2016-01-06</updated><authors><author><keyname>Yao</keyname><forenames>Li</forenames></author><author><keyname>Ballas</keyname><forenames>Nicolas</forenames></author><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author><author><keyname>Smith</keyname><forenames>John R.</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Empirical performance upper bounds for image and video captioning</title><categories>cs.CV cs.CL stat.ML</categories><comments>ICLR 2016 submission, updated on 6th Jan 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of associating images and videos with a natural language description
has attracted a great amount of attention recently. Rapid progress has been
made in terms of both developing novel algorithms and releasing new datasets.
Indeed, the state-of-the-art results on some of the standard datasets have been
pushed into the regime where it has become more and more difficult to make
significant improvements. Instead of proposing new models, this work
investigates the possibility of empirically establishing performance upper
bounds on various visual captioning datasets without extra data labelling
effort or human evaluation. In particular, it is assumed that visual captioning
is decomposed into two steps: from visual inputs to visual concepts, and from
visual concepts to natural language descriptions. One would be able to obtain
an upper bound when assuming the first step is perfect and only requiring
training a conditional language model for the second step. We demonstrate the
construction of such bounds on MS-COCO, YouTube2Text and LSMDC (a combination
of M-VAD and MPII-MD). Surprisingly, despite of the imperfect process we used
for visual concept extraction in the first step and the simplicity of the
language model for the second step, we show that current state-of-the-art
models fall short when being compared with the learned upper bounds.
Furthermore, with such a bound, we quantify several important factors
concerning image and video captioning: the number of visual concepts captured
by different models, the trade-off between the amount of visual elements
captured and their accuracy, and the intrinsic difficulty and blessing of
different datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04594</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04594</id><created>2015-11-14</created><authors><author><keyname>Gruss</keyname><forenames>Daniel</forenames></author><author><keyname>Maurice</keyname><forenames>Cl&#xe9;mentine</forenames></author><author><keyname>Wagner</keyname><forenames>Klaus</forenames></author></authors><title>Flush+Flush: A Stealthier Last-Level Cache Attack</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research on cache attacks has shown that CPU caches leak significant
information. Recent attacks either use the Flush+Reload technique on read-only
shared memory or the Prime+Probe technique without shared memory, to derive
encryption keys or eavesdrop on user input. Efficient countermeasures against
these powerful attacks that do not cause a loss of performance are a challenge.
In this paper, we use hardware performance counters as a means to detect
access-based cache attacks. Indeed, existing attacks cause numerous cache
references and cache misses and can subsequently be detected. We propose a new
criteria that uses these events for ad-hoc detection.
  These findings motivate the development of a novel attack technique: the
Flush+Flush attack. The Flush+Flush attack only relies on the execution time of
the flush instruction, that depends on whether the data is cached or not. Like
Flush+Reload, it monitors when a process loads read-only shared memory into the
CPU cache. However, Flush+Flush does not have a reload step, thus causing no
cache misses compared to typical Flush+Reload and Prime+Probe attacks. We show
that the significantly lower impact on the hardware performance counters
therefore evades detection mechanisms. The Flush+Flush attack has a performance
close to state-of-the-art side channels in existing cache attack scenarios,
while reducing cache misses significantly below the border of detectability.
Our Flush+Flush covert channel achieves a transmission rate of 496KB/s which is
6.7 times faster than any previously published cache covert channel. To the
best of our knowledge, this is the first work discussing the stealthiness of
cache attacks both from the attacker and the defender perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04599</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04599</id><created>2015-11-14</created><authors><author><keyname>Moosavi-Dezfooli</keyname><forenames>Seyed-Mohsen</forenames></author><author><keyname>Fawzi</keyname><forenames>Alhussein</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>DeepFool: a simple and accurate method to fool deep neural networks</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art deep neural networks have achieved impressive results on
many image classification tasks. However, these same architectures have been
shown to be unstable to small, well sought, perturbations of the images.
Despite the importance of this phenomenon, no effective methods have been
proposed to accurately compute the robustness of state-of-the-art deep
classifiers to such perturbations on large-scale datasets. In this paper, we
fill this gap and propose the DeepFool framework to efficiently compute
perturbations that fools deep network and thus reliably quantify the robustness
of arbitrary classifiers. Extensive experimental results show that our approach
outperforms recent methods in the task of computing adversarial perturbations
and making classifiers more robust. To encourage reproducible research, the
code of DeepFool will be available online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04601</identifier>
 <datestamp>2016-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04601</id><created>2015-11-14</created><updated>2016-01-14</updated><authors><author><keyname>Liu</keyname><forenames>Weiyang</forenames></author><author><keyname>Yu</keyname><forenames>Zhiding</forenames></author><author><keyname>Yang</keyname><forenames>Yingzhen</forenames></author><author><keyname>Yang</keyname><forenames>Meng</forenames></author><author><keyname>Huang</keyname><forenames>Thomas S.</forenames></author></authors><title>Jointly Learning Non-negative Projection and Dictionary with
  Discriminative Graph Constraints for Classification</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dictionary learning (DL) for sparse coding has shown impressive performance
in classification tasks. But how to select a feature that can best work with
the learned dictionary remains an open question. Current prevailing DL methods
usually adopt existing well-performing features, ignoring the inner
relationship between dictionaries and features. To address the problem, we
propose a joint non-negative projection and dictionary learning (JNPDL) method.
Non-negative projection learning and dictionary learning are complementary to
each other, since the former leads to the intrinsic discriminative parts-based
features for objects while the latter searches a suitable representation in the
projected feature space. Specifically, discrimination of projection and
dictionary is achieved by imposing to both projection and coding coefficients a
graph constraint that maximizes the intra-class compactness and inter-class
separability. Experimental results on both image classification and image set
classification show the excellent performance of JNPDL by being comparable or
outperforming many state-of-the-art approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04623</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04623</id><created>2015-11-14</created><updated>2015-11-19</updated><authors><author><keyname>Kawakami</keyname><forenames>Kazuya</forenames></author><author><keyname>Dyer</keyname><forenames>Chris</forenames></author></authors><title>Learning to Represent Words in Context with Multilingual Supervision</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a neural network architecture based on bidirectional LSTMs to
compute representations of words in the sentential contexts. These
context-sensitive word representations are suitable for, e.g., distinguishing
different word senses and other context-modulated variations in meaning. To
learn the parameters of our model, we use cross-lingual supervision,
hypothesizing that a good representation of a word in context will be one that
is sufficient for selecting the correct translation into a second language. We
evaluate the quality of our representations as features in three downstream
tasks: prediction of semantic supersenses (which assign nouns and verbs into a
few dozen semantic classes), low resource machine translation, and a lexical
substitution task, and obtain state-of-the-art results on all of these.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04628</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04628</id><created>2015-11-14</created><authors><author><keyname>Zhao</keyname><forenames>Ye</forenames></author><author><keyname>Fernandez</keyname><forenames>Benito R.</forenames></author><author><keyname>Sentis</keyname><forenames>Luis</forenames></author></authors><title>A Framework for Planning and Controlling Non-Periodic Bipedal Locomotion</title><categories>cs.RO cs.SY</categories><comments>33 pages, 18 figures, journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study presents a theoretical framework for planning and controlling
agile bipedal locomotion based on robustly tracking a set of non-periodic apex
states. Based on the prismatic inverted pendulum model, we formulate a hybrid
phase-space planning and control framework which includes the following key
components: (1) a step transition solver that enables dynamically tracking
non-periodic apex or keyframe states over various types of terrains, (2) a
robust hybrid automaton to effectively formulate planning and control
algorithms, (3) a phase-space metric to measure distance to the planned
locomotion manifolds, and (4) a hybrid control method based on the previous
distance metric to produce robust dynamic locomotion under external
disturbances. Compared to other locomotion frameworks, we have a larger focus
on non-periodic gait generation and robustness metrics to deal with
disturbances. Such focus enables the proposed control framework to robustly
track non-periodic apex states over various challenging terrains and under
external disturbances as illustrated through several simulations. Additionally,
it allows a bipedal robot to perform non-periodic bouncing maneuvers over
disjointed terrains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04629</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04629</id><created>2015-11-14</created><authors><author><keyname>Erseghe</keyname><forenames>Tomaso</forenames></author></authors><title>Coding in the Finite-Blocklength Regime: Bounds based on Laplace
  Integrals and their Asymptotic Approximations</title><categories>cs.IT math.IT</categories><comments>24 pages, 6 figures. Submitted to IEEE Trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we provide new compact integral expressions and associated
simple asymptotic approximations for converse and achievability bounds in the
finite blocklength regime. The chosen converse and random coding union bounds
were taken from the recent work of Polyanskyi-Poor-Verdu, and are investigated
under parallel AWGN channels, the AWGN channels, the BI-AWGN channel, and the
BSC. The technique we use, which is a generalization of some recent results
available from the literature, is to map the probabilities of interest into a
Laplace integral, and then solve (or approximate) the integral by use of a
steepest descent technique. The proposed results are particularly useful for
short packet lengths, where the normal approximation may provide unreliable
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04631</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04631</id><created>2015-11-14</created><authors><author><keyname>Sealfon</keyname><forenames>Adam</forenames></author></authors><title>Shortest Paths and Distances with Differential Privacy</title><categories>cs.CR cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a model for differentially private analysis of weighted graphs
in which the graph topology $(V,E)$ is assumed to be public and the private
information consists only of the edge weights $w:E\to\mathbb{R}^+$. This can
express hiding congestion patterns in a known system of roads. Differential
privacy requires that the output of an algorithm provides little advantage,
measured by privacy parameters $\epsilon$ and $\delta$, for distinguishing
between neighboring inputs, which are thought of as inputs that differ on the
contribution of one individual. In our model, two weight functions $w,w'$ are
considered to be neighboring if they have $\ell_1$ distance at most one. We
study the problems of privately releasing a short path between a pair of
vertices and of privately releasing approximate distances between all pairs of
vertices. We are concerned with the approximation error, the difference between
the distance or length of the released path and the actual distance or length
of the shortest path.
  For privately releasing a short path between a pair of vertices, we prove a
lower bound of $\Omega(|V|)$ on the additive approximation error for fixed
$\epsilon,\delta$. We provide a differentially private algorithm that nearly
matches this error bound and releases paths between all pairs of vertices. The
approximation error of our algorithm can be bounded by the number of edges on
the shortest path, so we achieve better accuracy than the worst-case bound for
pairs of vertices that are connected by a low-weight path with $o(|V|)$
vertices.
  For releasing all-pairs distances, we show that for bounded-weight graphs
with edge weights in $[0,M]$ we can release all distances with approximation
error $\tilde{O}(\sqrt{|V|M})$ for fixed $\epsilon,\delta &gt; 0$. For trees we
show that we can release all-pairs distances with approximation error
$O(\log^{2.5}|V|)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04634</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04634</id><created>2015-11-14</created><updated>2016-02-27</updated><authors><author><keyname>Agarwal</keyname><forenames>Saurav</forenames></author><author><keyname>Tamjidi</keyname><forenames>Amirhossein</forenames></author><author><keyname>Chakravorty</keyname><forenames>Suman</forenames></author></authors><title>Motion Planning for Global Localization in Non-Gaussian Belief Spaces</title><categories>cs.RO cs.SY</categories><comments>extends previous submission with updated figures, analysis and
  justifications. arXiv admin note: text overlap with arXiv:1506.01780</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for motion planning under uncertainty to deal
with situations where ambiguous data associations result in a multimodal
hypothesis on the robot state. In the global localization problem, sometimes
referred to as the &quot;lost or kidnapped robot problem&quot;, given little to no a
priori pose information, the localization algorithm should recover the correct
pose of a mobile robot with respect to a global reference frame. We present a
Receding Horizon approach, to plan actions that sequentially disambiguate a
multimodal belief to achieve tight localization on the correct pose in finite
time, i.e., converge to a unimodal belief. Experimental results are presented
using a physical ground robot operating in an artificial maze-like environment.
We demonstrate two runs wherein the robot is given no a priori information
about its initial pose and the planner is tasked to localize the robot.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04636</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04636</id><created>2015-11-14</created><updated>2016-01-16</updated><authors><author><keyname>He</keyname><forenames>Ji</forenames></author><author><keyname>Chen</keyname><forenames>Jianshu</forenames></author><author><keyname>He</keyname><forenames>Xiaodong</forenames></author><author><keyname>Gao</keyname><forenames>Jianfeng</forenames></author><author><keyname>Li</keyname><forenames>Lihong</forenames></author><author><keyname>Deng</keyname><forenames>Li</forenames></author><author><keyname>Ostendorf</keyname><forenames>Mari</forenames></author></authors><title>Deep Reinforcement Learning with an Action Space Defined by Natural
  Language</title><categories>cs.AI cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose the deep reinforcement relevance network (DRRN), a
novel deep architecture, to design a model for handling an action space
characterized using natural language with applications to text-based games. For
a particular class of games, a user must choose among a number of actions
described by text, with the goal of maximizing long-term reward. In these
games, the best action is typically what fits the current situation best
(modeled as a state in the DRRN), also described by text. Because of the
exponential complexity of natural language with respect to sentence length,
there is typically an unbounded set of unique actions. Even with a constrained
vocabulary, the action space is very large and sparse, posing challenges for
learning. To address this challenge, the DRRN extracts separate high-level
embedding vectors from the texts that describe states and actions,
respectively, using a general interaction function, such as inner product,
bilinear, and DNN interaction, between these embedding vectors to approximate
the Q-function. We evaluate the DRRN on two popular text games, showing
superior performance over other deep Q-learning architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04646</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04646</id><created>2015-11-14</created><authors><author><keyname>Shen</keyname><forenames>Yikang</forenames></author><author><keyname>Rong</keyname><forenames>Wenge</forenames></author><author><keyname>Jiang</keyname><forenames>Nan</forenames></author><author><keyname>Peng</keyname><forenames>Baolin</forenames></author><author><keyname>Tang</keyname><forenames>Jie</forenames></author><author><keyname>Xiong</keyname><forenames>Zhang</forenames></author></authors><title>Word Embedding based Correlation Model for Question/Answer Matching</title><categories>cs.CL cs.AI</categories><comments>8 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the development of community based question answering (Q\&amp;A) services, a
large scale of Q\&amp;A archives have been accumulated and are an important
information and knowledge resource on the web. Question and answer matching has
been attached much importance to for its ability to reuse knowledge stored in
these systems: it can be useful in enhancing user experience with recurrent
questions. In this paper, we try to improve the matching accuracy by overcoming
the lexical gap between question and answer pairs. A Word Embedding based
Correlation (WEC) model is proposed by integrating advantages of both the
translation model and word embedding, given a random pair of words, WEC can
score their co-occurrence probability in Q\&amp;A pairs and it can also leverage
the continuity and smoothness of continuous space word representation to deal
with new pairs of words that are rare in the training parallel text. An
experimental study on Yahoo! Answers dataset and Baidu Zhidao dataset shows
this new method's promising potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04651</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04651</id><created>2015-11-14</created><authors><author><keyname>Han</keyname><forenames>Rui</forenames></author></authors><title>Investigations into Elasticity in Cloud Computing</title><categories>cs.DC</categories><comments>211 pages, 27 tables, 75 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pay-as-you-go model supported by existing cloud infrastructure providers
is appealing to most application service providers to deliver their
applications in the cloud. Within this context, elasticity of applications has
become one of the most important features in cloud computing. This elasticity
enables real-time acquisition/release of compute resources to meet application
performance demands. In this thesis we investigate the problem of delivering
cost-effective elasticity services for cloud applications.
  Traditionally, the application level elasticity addresses the question of how
to scale applications up and down to meet their performance requirements, but
does not adequately address issues relating to minimising the costs of using
the service. With this current limitation in mind, we propose a scaling
approach that makes use of cost-aware criteria to detect the bottlenecks within
multi-tier cloud applications, and scale these applications only at bottleneck
tiers to reduce the costs incurred by consuming cloud infrastructure resources.
Our approach is generic for a wide class of multi-tier applications, and we
demonstrate its effectiveness by studying the behaviour of an example
electronic commerce site application.
  Furthermore, we consider the characteristics of the algorithm for
implementing the business logic of cloud applications, and investigate the
elasticity at the algorithm level: when dealing with large-scale data under
resource and time constraints, the algorithm's output should be elastic with
respect to the resource consumed. We propose a novel framework to guide the
development of elastic algorithms that adapt to the available budget while
guaranteeing the quality of output result, e.g. prediction accuracy for
classification tasks, improves monotonically with the used budget.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04657</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04657</id><created>2015-11-14</created><updated>2016-01-01</updated><authors><author><keyname>Saldi</keyname><forenames>Naci</forenames></author><author><keyname>Y&#xfc;ksel</keyname><forenames>Serdar</forenames></author><author><keyname>Linder</keyname><forenames>Tam&#xe1;s</forenames></author></authors><title>Finite Model Approximations and Asymptotic Optimality of Quantized
  Policies in Decentralized Stochastic Control</title><categories>math.OC cs.SY</categories><comments>13 pages, double column</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider finite model approximations of a large class of
static and dynamic team problems where these models are constructed through
uniform quantization of the observation and action spaces of the agents. The
strategies obtained from these finite models are shown to approximate the
optimal cost with arbitrary precision under mild technical assumptions. In
particular, quantized team policies are asymptotically optimal. This result is
then applied to Witsenhausen's celebrated counterexample and the Gaussian relay
channel problem. For the Witsenhausen's counterexample, our approximation
approach provides, to our knowledge, the first rigorously established result
that one can construct an $\varepsilon$-optimal strategy for any $\varepsilon &gt;
0$ through a solution of a simpler problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04659</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04659</id><created>2015-11-14</created><authors><author><keyname>Panchal</keyname><forenames>Shailesh</forenames></author><author><keyname>Thakker</keyname><forenames>Rajesh</forenames></author></authors><title>Implementation and comparative quantitative assessment of different
  multispectral image pansharpening approches</title><categories>cs.CV</categories><comments>14 pages</comments><doi>10.5121/sipij.2015.6503</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In remote sensing, images acquired by various earth observation satellites
tend to have either a high spatial and low spectral resolution or vice versa.
Pansharpening is a technique which aims to improve spatial resolution of
multispectral image. The challenges involve in the pansharpening are not only
to improve the spatial resolution but also to preserve spectral quality of the
multispectral image. In this paper, various pansharpening algorithms are
discussed and classified based on approaches they have adopted. Using MATLAB
image processing toolbox, several state-of-art pan-sharpening algorithms are
implemented. Quality of pansharpened images are assessed visually and
quantitatively. Correlation coefficient (CC), Root mean square error (RMSE),
Relative average spectral error (RASE) and Universal quality index (Q) indices
are used to easure spectral quality while to spatial-CC (SCC) quantitative
parameter is used for spatial quality measurement. Finally, the paper is
concluded with useful remarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04661</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04661</id><created>2015-11-15</created><authors><author><keyname>Wang</keyname><forenames>Hao</forenames></author><author><keyname>Bommireddipalli</keyname><forenames>Vijay R.</forenames></author><author><keyname>Hanafy</keyname><forenames>Ayman</forenames></author><author><keyname>Bahgat</keyname><forenames>Mohamed</forenames></author><author><keyname>Noeman</keyname><forenames>Sara</forenames></author><author><keyname>Emam</keyname><forenames>Ossama S.</forenames></author></authors><title>A System for Extracting Sentiment from Large-Scale Arabic Social Data</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social media data in Arabic language is becoming more and more abundant. It
is a consensus that valuable information lies in social media data. Mining this
data and making the process easier are gaining momentum in the industries. This
paper describes an enterprise system we developed for extracting sentiment from
large volumes of social data in Arabic dialects. First, we give an overview of
the Big Data system for information extraction from multilingual social data
from a variety of sources. Then, we focus on the Arabic sentiment analysis
capability that was built on top of the system including normalizing written
Arabic dialects, building sentiment lexicons, sentiment classification, and
performance evaluation. Lastly, we demonstrate the value of enriching sentiment
results with user profiles in understanding sentiments of a specific user
group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04664</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04664</id><created>2015-11-15</created><authors><author><keyname>Alsheikh</keyname><forenames>Mohammad Abu</forenames></author><author><keyname>Selim</keyname><forenames>Ahmed</forenames></author><author><keyname>Niyato</keyname><forenames>Dusit</forenames></author><author><keyname>Doyle</keyname><forenames>Linda</forenames></author><author><keyname>Lin</keyname><forenames>Shaowei</forenames></author><author><keyname>Tan</keyname><forenames>Hwee-Pink</forenames></author></authors><title>Deep Activity Recognition Models with Triaxial Accelerometers</title><categories>cs.LG cs.HC cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the widespread installation of accelerometers in almost all mobile
phones and wearable devices, activity recognition using accelerometers is still
immature due to the poor recognition accuracy of existing recognition methods
and the scarcity of labeled training data. We consider the problem of human
activity recognition using triaxial accelerometers and deep learning paradigms.
This paper shows that deep activity recognition models (a) provide better
recognition accuracy of human activities, (b) avoid the expensive design of
handcrafted features in existing systems, and (c) utilize the massive unlabeled
acceleration samples for unsupervised feature extraction. Moreover, a hybrid
approach of deep learning and hidden Markov models (DL-HMM) is presented for
sequential activity recognition. This hybrid approach integrates the
hierarchical representations of deep activity recognition models with the
stochastic modeling of temporal sequences in the hidden Markov models. We show
substantial recognition improvement on real world datasets over
state-of-the-art methods of human activity recognition using triaxial
accelerometers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04668</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04668</id><created>2015-11-15</created><updated>2015-11-26</updated><authors><author><keyname>Kim</keyname><forenames>Dong Ki</forenames></author><author><keyname>Chen</keyname><forenames>Tsuhan</forenames></author></authors><title>Deep Neural Network for Real-Time Autonomous Indoor Navigation</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autonomous indoor navigation of Micro Aerial Vehicles (MAVs) possesses many
challenges. One main reason is that GPS has limited precision in indoor
environments. The additional fact that MAVs are not able to carry heavy weight
or power consuming sensors, such as range finders, makes indoor autonomous
navigation a challenging task. In this paper, we propose a practical system in
which a quadcopter autonomously navigates indoors and finds a specific target,
i.e., a book bag, by using a single camera. A deep learning model,
Convolutional Neural Network (ConvNet), is used to learn a controller strategy
that mimics an expert pilot's choice of action. We show our system's
performance through real-time experiments in diverse indoor locations. To
understand more about our trained network, we use several visualization
techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04670</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04670</id><created>2015-11-15</created><authors><author><keyname>Zhu</keyname><forenames>Linchao</forenames></author><author><keyname>Xu</keyname><forenames>Zhongwen</forenames></author><author><keyname>Yang</keyname><forenames>Yi</forenames></author><author><keyname>Hauptmann</keyname><forenames>Alexander G.</forenames></author></authors><title>Uncovering Temporal Context for Video Question and Answering</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we introduce Video Question Answering in temporal domain to
infer the past, describe the present and predict the future. We present an
encoder-decoder approach using Recurrent Neural Networks to learn temporal
structures of videos and introduce a dual-channel ranking loss to answer
multiple-choice questions. We explore approaches for finer understanding of
video content using question form of &quot;fill-in-the-blank&quot;, and managed to
collect 109,895 video clips with duration over 1,000 hours from TACoS, MPII-MD,
MEDTest 14 datasets, while the corresponding 390,744 questions are generated
from annotations. Extensive experiments demonstrate that our approach
significantly outperforms the compared baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04674</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04674</id><created>2015-11-15</created><authors><author><keyname>Abdallah</keyname><forenames>Sherief</forenames></author></authors><title>Using Text Mining To Analyze Real Estate Classifieds</title><categories>cs.IR</categories><comments>18 pages, 3 figures, and 9 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many brokers have adapted their operation to exploit the potential of the
web. Despite the importance of the real estate classifieds, there has been
little work in analyzing such data. In this paper we propose a two-stage
regression model that exploits the textual data in real estate classifieds. We
show how our model can be used to predict the price of a real estate
classified. We also show how our model can be used to highlight keywords that
affect the price positively or negatively. To assess our contributions, we
analyze four real world data sets, which we gathered from three different
property websites. The analysis shows that our model (which exploits textual
features) achieves significantly lower root mean squared error across the
different data sets and against variety of regression models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04685</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04685</id><created>2015-11-15</created><authors><author><keyname>Gilboa</keyname><forenames>Guy</forenames></author></authors><title>Semi-Inner-Products for Convex Functionals and Their Use in Image
  Decomposition</title><categories>math.NA cs.CV math.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semi-inner-products in the sense of Lumer are extended to convex functionals.
This yields a Hilbert-space like structure to convex functionals in Banach
spaces. In particular, a general expression for semi-inner-products with
respect to one homogeneous functionals is given. Thus one can use the new
operator for the analysis of total variation and higher order functionals like
total-generalized-variation (TGV). Having a semi-inner-product, an angle
between functions can be defined in a straightforward manner. It is shown that
in the one homogeneous case the Bregman distance can be expressed in terms of
this newly defined angle. In addition, properties of the semi-inner-product of
nonlinear eigenfunctions induced by the functional are derived. We use this
construction to state a sufficient condition for a perfect decomposition of two
signals and suggest numerical measures which indicate when those conditions are
approximately met.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04687</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04687</id><created>2015-11-15</created><authors><author><keyname>Horesh</keyname><forenames>Dikla</forenames></author><author><keyname>Gilboa</keyname><forenames>Guy</forenames></author></authors><title>Separation Surfaces in the Spectral TV Domain for Texture Decomposition</title><categories>cs.CV math.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a novel notion of separation surfaces for image
decomposition. A surface is embedded in the spectral total-variation (TV) three
dimensional domain and encodes a spatially-varying separation scale. The method
allows good separation of textures with gradually varying pattern-size,
pattern-contrast or illumination. The recently proposed total variation
spectral framework is used to decompose the image into a continuum of textural
scales. A desired texture, within a scale range, is found by fitting a surface
to the local maximal responses in the spectral domain. A band above and below
the surface, referred to as the \textit{Texture Stratum}, defines for each
pixel the adaptive scale-range of the texture. Based on the decomposition an
application is proposed which can attenuate or enhance textures in the image in
a very natural and visually convincing manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04690</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04690</id><created>2015-11-15</created><authors><author><keyname>Liu</keyname><forenames>Weiyang</forenames></author><author><keyname>Yu</keyname><forenames>Zhiding</forenames></author><author><keyname>Yang</keyname><forenames>Meng</forenames></author></authors><title>Robust Elastic Net Regression</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a robust elastic net (REN) model for high-dimensional sparse
regression and give its performance guarantees (both the statistical error
bound and the optimization bound). A simple idea of trimming the inner product
is applied to the elastic net model. Specifically, we robustify the covariance
matrix by trimming the inner product based on the intuition that the trimmed
inner product can not be significant affected by a bounded number of
arbitrarily corrupted points (outliers). The REN model can also derive two
interesting special cases: robust Lasso and robust soft thresholding.
Comprehensive experimental results show that the robustness of the proposed
model consistently outperforms the original elastic net and matches the
performance guarantees nicely.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04691</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04691</id><created>2015-11-15</created><authors><author><keyname>Wang</keyname><forenames>Chao</forenames></author><author><keyname>Mou</keyname><forenames>Xuanqin</forenames></author><author><keyname>Zhang</keyname><forenames>Lei</forenames></author></authors><title>Optimization of the Block-level Bit Allocation in Perceptual Video
  Coding based on MINMAX</title><categories>cs.MM</categories><comments>11 pages, 17 figures</comments><acm-class>I.4.2; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In video coding, it is expected that the encoder could adaptively select the
encoding parameters (e.g., quantization parameter) to optimize the bit
allocation to different sources under the given constraint. However, in hybrid
video coding, the dependency between sources brings high complexity for the bit
allocation optimization, especially in the block-level, and existing
optimization methods mostly focus on frame-level bit allocation. In this paper,
we propose a macroblock (MB) level bit allocation method based on the minimum
maximum (MINMAX) criterion, which has acceptable encoding complexity for
offline applications. An iterative-based algorithm, namely maximum distortion
descend (MDD), is developed to reduce quality fluctuation among MBs within a
frame, where the Structure SIMilarity (SSIM) index is used to measure the
perceptual distortion of MBs. Our extensive experimental results on benchmark
video sequences show that the proposed method can greatly enhance the encoding
performance in terms of both bits saving and perceptual quality improvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04695</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04695</id><created>2015-11-15</created><authors><author><keyname>Yang</keyname><forenames>Linxiao</forenames></author><author><keyname>Fang</keyname><forenames>Jun</forenames></author><author><keyname>Li</keyname><forenames>Hongbin</forenames></author><author><keyname>Zeng</keyname><forenames>Bing</forenames></author></authors><title>An Iterative Reweighted Method for Tucker Decomposition of Incomplete
  Multiway Tensors</title><categories>cs.NA cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of low-rank decomposition of incomplete multiway
tensors. Since many real-world data lie on an intrinsically low dimensional
subspace, tensor low-rank decomposition with missing entries has applications
in many data analysis problems such as recommender systems and image
inpainting. In this paper, we focus on Tucker decomposition which represents an
Nth-order tensor in terms of N factor matrices and a core tensor via
multilinear operations. To exploit the underlying multilinear low-rank
structure in high-dimensional datasets, we propose a group-based log-sum
penalty functional to place structural sparsity over the core tensor, which
leads to a compact representation with smallest core tensor. The method for
Tucker decomposition is developed by iteratively minimizing a surrogate
function that majorizes the original objective function, which results in an
iterative reweighted process. In addition, to reduce the computational
complexity, an over-relaxed monotone fast iterative shrinkage-thresholding
technique is adapted and embedded in the iterative reweighted process. The
proposed method is able to determine the model complexity (i.e. multilinear
rank) in an automatic way. Simulation results show that the proposed algorithm
offers competitive performance compared with other existing algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04698</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04698</id><created>2015-11-15</created><authors><author><keyname>AL-Naday</keyname><forenames>Mays F.</forenames></author><author><keyname>Thomos</keyname><forenames>Nikolaos</forenames></author><author><keyname>Reed</keyname><forenames>Martin J.</forenames></author></authors><title>Information-centric Multilayer Network: ICN/WDM</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information-centric networking (ICN) facilitates content identification in
networks and offers parametric representation of content semantics. This work,
proposes an ICN/WDM network architecture that uses these features to offer
superior network utilization, in terms of performance and power consumption.
The architecture introduces an ICN publish/subscribe communication approach to
the wavelength layer; whereby, content is aggregated according to its
popularity rank into wavelength-size groups that can be published and
&quot;subscribed to&quot; by multiple nodes. Consequently, routing and wavelength
assignment (RWA) algorithms benefit from anycast to identify multiple sources
of aggregate content and allow optimization of the source selection of
light-paths. A power-aware algorithm, Maximum Degree of connectivity (MaxDeg),
has been developed with the objective of exploiting this flexibility to address
the trade-off between power consumption and network performance. The algorithm
is also applicable to IP architectures, albeit with less flexibility.
Evaluation results indicate the superiority of the proposed ICN architecture,
even when utilizing conventional routing methods, compared to its IP
counterpart. The results further highlight the performance improvement achieved
by the proposed algorithm, compared to conventional RWA methods such as
Shortest-path First Fit (SFF).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04700</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04700</id><created>2015-11-15</created><authors><author><keyname>Zhang</keyname><forenames>Xiaojing</forenames></author><author><keyname>Kamgarpour</keyname><forenames>Maryam</forenames></author><author><keyname>Georghiou</keyname><forenames>Angelos</forenames></author><author><keyname>Lygeros</keyname><forenames>John</forenames></author></authors><title>Robust Optimal Control with Adjustable Uncertainty Sets</title><categories>math.OC cs.SY</categories><comments>Pre-print submitted to Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust control design for constrained uncertain systems is a well-studied
topic. Given a known uncertainty set, the objective is to find a control policy
that minimizes a given cost and satisfies the system's constraints for all
possible uncertainty realizations. In this paper, we extend the classical
robust control setup by treating the uncertainty sets as additional decision
variables. We develop a unified framework for studying such problems, which we
refer to as constrained robust optimal control problems with adjustable
uncertainty sets. In particular, given a metric for adjusting the uncertainty
sets, we address the question of determining the optimal size and shape of the
uncertainty sets, while simultaneously ensuring the existence of a control
policy that will keep the system within its constraints for all possible
disturbance realizations inside the adjusted uncertainty set. Since our problem
subsumes the classical constrained robust optimal control design, it is
computationally intractable in general. We demonstrate in this paper that by
restricting the families of admissible uncertainty sets and control policies,
the problem can be formulated as a tractable convex optimization problem. We
show that our framework captures several families of (convex) uncertainty sets
of practical interest, and illustrate our approach on a demand response problem
of providing control reserves for a power system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04707</identifier>
 <datestamp>2016-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04707</id><created>2015-11-15</created><updated>2016-02-17</updated><authors><author><keyname>Dorfer</keyname><forenames>Matthias</forenames></author><author><keyname>Kelz</keyname><forenames>Rainer</forenames></author><author><keyname>Widmer</keyname><forenames>Gerhard</forenames></author></authors><title>Deep Linear Discriminant Analysis</title><categories>cs.LG</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Deep Linear Discriminant Analysis (DeepLDA) which learns
linearly separable latent representations in an end-to-end fashion. Classic LDA
extracts features which preserve class separability and is used for
dimensionality reduction for many classification problems. The central idea of
this paper is to put LDA on top of a deep neural network. This can be seen as a
non-linear extension of classic LDA. Instead of maximizing the likelihood of
target labels for individual samples, we propose an objective function that
pushes the network to produce feature distributions which: (a) have low
variance within the same class and (b) high variance between different classes.
Our objective is derived from the general LDA eigenvalue problem and still
allows to train with stochastic gradient descent and back-propagation. For
evaluation we test our approach on three different benchmark datasets (MNIST,
CIFAR-10 and STL-10). DeepLDA produces competitive results on MNIST and
CIFAR-10 and outperforms a network trained with categorical cross entropy (same
architecture) on a supervised setting of STL-10.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04717</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04717</id><created>2015-11-15</created><authors><author><keyname>Soualah-Alila</keyname><forenames>Fayrouz</forenames><affiliation>L3I</affiliation></author><author><keyname>Faucher</keyname><forenames>Cyril</forenames><affiliation>L3I</affiliation></author><author><keyname>Bertrand</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>L3I</affiliation></author><author><keyname>Coustaty</keyname><forenames>Micka&#xeb;l</forenames><affiliation>L3I</affiliation></author><author><keyname>Doucet</keyname><forenames>Antoine</forenames><affiliation>L3I</affiliation></author></authors><title>Applying Semantic Web Technologies for Improving the Visibility of
  Tourism Data</title><categories>cs.IR</categories><comments>ESAIR: Exploiting Semantic Annotations in Information Retrieval, Oct
  2015, Melbourne, Austria. 2015</comments><proxy>ccsd</proxy><doi>10.1145/2810133.2810137</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tourism industry is an extremely information-intensive, complex and dynamic
activity. It can benefit from semantic Web technologies, due to the significant
heterogeneity of information sources and the high volume of on-line data. The
management of semantically diverse annotated tourism data is facilitated by
ontologies that provide methods and standards, which allow flexibility and more
intelligent access to on-line data. This paper provides a description of some
of the early results of the Tourinflux project which aims to apply semantic Web
technologies to support tourist actors in effectively finding and publishing
information on the Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04731</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04731</id><created>2015-11-15</created><updated>2016-01-28</updated><authors><author><keyname>Chang</keyname><forenames>Yi-Jun</forenames></author></authors><title>Hardness of RNA Folding Problem with Four Symbols</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An RNA sequence is a string composed of four types of nucleotides, $A, C, G$,
and $U$. Given an RNA sequence, the goal of the RNA folding problem is to find
a maximum cardinality set of crossing-free pairs of the form $\{A,U\}$ or
$\{C,G\}$. The problem is central in bioinformatics and has received much
attention over the years. However, the current best algorithm for the problem
still takes $\mathcal{O}\left(\frac{n^3}{\log^2 (n)}\right)$ time, which is
only a slight improvement over the classic $\mathcal{O}(n^3)$ dynamic
programming algorithm. Whether the RNA folding problem can be solved in
$\mathcal{O}(n^{3-\epsilon})$ time remains an open problem. Recently, Abboud,
Backurs, and Williams (FOCS'15) made the first progress by showing a
conditional lower bound for a generalized version of the RNA folding problem
based on a conjectured hardness of the $k$-clique problem. A drawback of their
work is that they require the RNA sequence to have at least 36 types of
letters, making their result biologically irrelevant. In this paper, we show
that by constructing the gadgets using a lemma of Bringmann and K\&quot;{u}nnemann
(FOCS'15) and surrounding them with some carefully designed sequences, the
framework of Abboud et al. can be improved upon to work for the case where the
alphabet size is 4, yielding a conditional lower bound for the RNA folding
problem.
  We also investigate the Dyck edit distance problem. We demonstrate a
reduction from RNA folding problem to Dyck edit distance problem of alphabet
size 10, establishing a connection between the two fundamental string problems.
This leads to a much simpler proof of the conditional lower bound for Dyck edit
distance problem given by Abboud et al. and lowers the required alphabet size
for the lower bound to work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04741</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04741</id><created>2015-11-15</created><authors><author><keyname>Rubinstein</keyname><forenames>Aviad</forenames></author></authors><title>On the Computational Complexity of Optimal Simple Mechanisms</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a monopolist seller facing a single buyer with additive
valuations over n heterogeneous, independent items. It is known that in this
important setting optimal mechanisms may require randomization [HR12], use
menus of infinite size [DDT15], and may be computationally intractable [DDT14].
This has sparked recent interest in finding simple mechanisms that obtain
reasonable approximations to the optimal revenue [HN12, LY13, BILW14]. In this
work we attempt to find the optimal simple mechanism.
  There are many ways to define simple mechanisms. Here we restrict our search
to partition mechanisms, where the seller partitions the items into disjoint
bundles and posts a price for each bundle; the buyer is allowed to buy any
number of bundles.
  We give a PTAS for the problem of finding a revenue-maximizing partition
mechanism, and prove that the problem is strongly NP-hard. En route, we prove
structural properties of near-optimal partition mechanisms which may be of
independent interest: for example, there always exists a near-optimal partition
mechanism that uses only a constant number of non-trivial bundles (i.e. bundles
with more than one item).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04747</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04747</id><created>2015-11-15</created><updated>2016-02-14</updated><authors><author><keyname>Ghosh</keyname><forenames>Sayan</forenames></author><author><keyname>Laksana</keyname><forenames>Eugene</forenames></author><author><keyname>Morency</keyname><forenames>Louis-Philippe</forenames></author><author><keyname>Scherer</keyname><forenames>Stefan</forenames></author></authors><title>Learning Representations of Affect from Speech</title><categories>cs.CL cs.LG</categories><comments>This is a submission for the ICLR (International Conference on
  Learning Representations) Workshop 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been a lot of prior work on representation learning for speech
recognition applications, but not much emphasis has been given to an
investigation of effective representations of affect from speech, where the
paralinguistic elements of speech are separated out from the verbal content. In
this paper, we explore denoising autoencoders for learning paralinguistic
attributes i.e. categorical and dimensional affective traits from speech. We
show that the representations learnt by the bottleneck layer of the autoencoder
are highly discriminative of activation intensity and at separating out
negative valence (sadness and anger) from positive valence (happiness). We
experiment with different input speech features (such as FFT and log-mel
spectrograms with temporal context windows), and different autoencoder
architectures (such as stacked and deep autoencoders). We also learn utterance
specific representations by a combination of denoising autoencoders and BLSTM
based recurrent autoencoders. Emotion classification is performed with the
learnt temporal/dynamic representations to evaluate the quality of the
representations. Experiments on a well-established real-life speech dataset
(IEMOCAP) show that the learnt representations are comparable to state of the
art feature extractors (such as voice quality features and MFCCs) and are
competitive with state-of-the-art approaches at emotion and dimensional affect
recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04750</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04750</id><created>2015-11-15</created><updated>2016-02-19</updated><authors><author><keyname>Bikakis</keyname><forenames>Nikos</forenames></author><author><keyname>Papastefanatos</keyname><forenames>George</forenames></author><author><keyname>Skourla</keyname><forenames>Melina</forenames></author><author><keyname>Sellis</keyname><forenames>Timos</forenames></author></authors><title>A Hierarchical Aggregation Framework for Efficient Multilevel Visual
  Exploration and Analysis</title><categories>cs.HC cs.DB cs.DS</categories><comments>Semantic Web Journal 2016 (to appear)</comments><msc-class>97R50, 68P05, 68P15</msc-class><acm-class>E.1; H.2.8; H.5.2; H.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data exploration and visualization systems are of great importance in the Big
Data era, in which the volume and heterogeneity of available information make
it difficult for humans to manually explore and analyse data. Most traditional
systems operate in an offline way, limited to accessing preprocessed (static)
sets of data. They also restrict themselves to dealing with small dataset
sizes, which can be easily handled with conventional techniques. However, the
Big Data era has realized the availability of a great amount and variety of big
datasets that are dynamic in nature; most of them offer API or query endpoints
for online access, or the data is received in a stream fashion. Therefore,
modern systems must address the challenge of on-the-fly scalable visualizations
over large dynamic sets of data, offering efficient exploration techniques, as
well as mechanisms for information abstraction and summarization. In this work,
we present a generic model for personalized multilevel exploration and analysis
over large dynamic sets of numeric and temporal data. Our model is built on top
of a lightweight tree-based structure which can be efficiently constructed
on-the-fly for a given set of data. This tree structure aggregates input
objects into a hierarchical multiscale model. Considering different exploration
scenarios over large datasets, the proposed model enables efficient multilevel
exploration, offering incremental construction and prefetching via user
interaction, and dynamic adaptation of the hierarchies based on user
preferences. A thorough theoretical analysis is presented, illustrating the
efficiency of the proposed model. The proposed model is realized in a web-based
prototype tool, called SynopsViz that offers multilevel visual exploration and
analysis over Linked Data datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04754</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04754</id><created>2015-11-15</created><authors><author><keyname>Banagar</keyname><forenames>Morteza</forenames></author><author><keyname>Maham</keyname><forenames>Behrouz</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Pantisano</keyname><forenames>Francesco</forenames></author></authors><title>Power Distribution of Device-to-Device Communications in Underlaid
  Cellular Networks</title><categories>cs.NI cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Device-to-device (D2D) communications have recently emerged as a novel
transmission paradigm in wireless cellular networks. D2D transmissions take
place concurrently with the usual cellular connections, and thus, controlling
the interference brought to the macro-cellular user equipment (UE) is of vital
importance. In this paper, we consider the uplink transmission of a tier of D2D
users that operates as an underlay for the traditional cellular network. Using
network model based on stochastic geometry, we derive the equilibrium
cumulative distribution function (CDF) of the D2D transmit power. Considering
interference-limited and relatively lossy environment cases, closed form
equations are derived for the power CDF. Finally, a tight closed-form
upper-bound for the derived power distribution is proposed, and the analytical
results are validated via simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04762</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04762</id><created>2015-11-15</created><authors><author><keyname>Alsarhan</keyname><forenames>Hamza</forenames></author><author><keyname>Chia</keyname><forenames>Davin</forenames></author><author><keyname>Christman</keyname><forenames>Ananya</forenames></author><author><keyname>Fu</keyname><forenames>Shannia</forenames></author><author><keyname>Jin</keyname><forenames>Yanfeng</forenames></author></authors><title>Bin Packing with Multiple Colors</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Colored Bin Packing problem a set of items with varying weights and
colors must be packed into bins of uniform weight limit such that no two items
of the same color may be packed adjacently within a bin. We solve this problem
for the case where there are two or more colors when the items have zero weight
and when the items have unit weight. Our algorithms are optimal and run in
linear time. Since our algorithms apply for two or more colors, they
demonstrate that the problem does not get harder as the number of colors
increases. We also provide closed-form expressions for the optimal number of
bins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04763</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04763</id><created>2015-11-15</created><updated>2015-11-17</updated><authors><author><keyname>Reddy</keyname><forenames>M Pavan Kumar</forenames></author><author><keyname>Kala</keyname><forenames>Srikant Manas</forenames></author><author><keyname>Tamma</keyname><forenames>Bheemarjuna Reddy</forenames></author></authors><title>Evaluation of Channel Assignment Performance Prediction Techniques in
  Random Wireless Mesh Networks</title><categories>cs.NI</categories><comments>Accepted in 2015 International Conference on Computing and Network
  Communications (CoCoNet'15) (IEEE)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance of wireless mesh networks (WMNs) in terms of network capacity,
end-to-end latency, and network resilience depends upon the prevalent levels of
interference. Thus, interference alleviation is a fundamental design concern in
multi-radio multi-channel (MRMC) WMNs, and is achieved through a judicious
channel assignment (CA) to the radios in a WMN. In our earlier works we have
tried to address the problem of estimating the intensity of interference in a
wireless network and predicting the performance of CA schemes based on the
measure of the interference estimate. We have proposed reliable CA performance
prediction approaches which have proven effective in grid WMNs. In this work,
we further assess the reliability of these CA performance prediction techniques
in a large MRMC WMN which comprises of randomly placed mesh routers. We perform
exhaustive simulations on an ns-3 802.11n environment. We obtain conclusive
results to demonstrate the efficacy of proposed schemes in random WMNs as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04773</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04773</id><created>2015-11-15</created><updated>2016-02-29</updated><authors><author><keyname>Wang</keyname><forenames>Weiran</forenames></author><author><keyname>Livescu</keyname><forenames>Karen</forenames></author></authors><title>Large-Scale Approximate Kernel Canonical Correlation Analysis</title><categories>cs.LG</categories><comments>Published as a conference paper at International Conference on
  Learning Representations (ICLR) 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kernel canonical correlation analysis (KCCA) is a nonlinear multi-view
representation learning technique with broad applicability in statistics and
machine learning. Although there is a closed-form solution for the KCCA
objective, it involves solving an $N\times N$ eigenvalue system where $N$ is
the training set size, making its computational requirements in both memory and
time prohibitive for large-scale problems. Various approximation techniques
have been developed for KCCA. A commonly used approach is to first transform
the original inputs to an $M$-dimensional random feature space so that inner
products in the feature space approximate kernel evaluations, and then apply
linear CCA to the transformed inputs. In many applications, however, the
dimensionality $M$ of the random feature space may need to be very large in
order to obtain a sufficiently good approximation; it then becomes challenging
to perform the linear CCA step on the resulting very high-dimensional data
matrices. We show how to use a stochastic optimization algorithm, recently
proposed for linear CCA and its neural-network extension, to further alleviate
the computation requirements of approximate KCCA. This approach allows us to
run approximate KCCA on a speech dataset with $1.4$ million training samples
and a random feature space of dimensionality $M=100000$ on a typical
workstation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04775</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04775</id><created>2015-11-15</created><authors><author><keyname>Stark</keyname><forenames>Cyril</forenames></author></authors><title>Expressive recommender systems through normalized nonnegative models</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce normalized nonnegative models (NNM) for explorative data
analysis. NNMs are partial convexifications of models from probability theory.
We demonstrate their value at the example of item recommendation. We show that
NNM-based recommender systems satisfy three criteria that all recommender
systems should ideally satisfy: high predictive power, computational
tractability, and expressive representations of users and items. Expressive
user and item representations are important in practice to succinctly summarize
the pool of customers and the pool of items. In NNMs, user representations are
expressive because each user's preference can be regarded as normalized mixture
of preferences of stereotypical users. The interpretability of item and user
representations allow us to arrange properties of items (e.g., genres of movies
or topics of documents) or users (e.g., personality traits) hierarchically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04776</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04776</id><created>2015-11-15</created><updated>2016-01-08</updated><authors><author><keyname>Goessling</keyname><forenames>Marc</forenames></author><author><keyname>Amit</keyname><forenames>Yali</forenames></author></authors><title>Sparse Autoregressive Networks</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider high-dimensional distribution estimation through autoregressive
networks. By combining the concepts of sparsity, mixtures and parameter sharing
we obtain a simple model which is fast to train and which achieves
state-of-the-art or better results on several standard benchmark datasets.
Specifically, we use an L1-penalty to regularize the conditional distributions
and introduce a procedure for automatic parameter sharing between mixture
components. Moreover, we propose a simple distributed representation which
permits exact likelihood evaluations since the latent variables are interleaved
with the observable variables and can be easily integrated out. Our model
achieves excellent generalization performance and scales well to extremely high
dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04777</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04777</id><created>2015-11-15</created><updated>2015-11-29</updated><authors><author><keyname>Sun</keyname><forenames>Ju</forenames></author><author><keyname>Qu</keyname><forenames>Qing</forenames></author><author><keyname>Wright</keyname><forenames>John</forenames></author></authors><title>Complete Dictionary Recovery over the Sphere II: Recovery by Riemannian
  Trust-region Method</title><categories>cs.IT cs.CV math.IT math.OC stat.ML</categories><comments>The second of two papers based on the report arXiv:1504.06785.
  Submitted to IEEE Transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recovering a complete (i.e., square and
invertible) matrix $\mathbf A_0$, from $\mathbf Y \in \mathbb{R}^{n \times p}$
with $\mathbf Y = \mathbf A_0 \mathbf X_0$, provided $\mathbf X_0$ is
sufficiently sparse. This recovery problem is central to the theoretical
understanding of dictionary learning, which seeks a sparse representation for a
collection of input signals, and finds numerous applications in modern signal
processing and machine learning. We give the first efficient algorithm that
provably recovers $\mathbf A_0$ when $\mathbf X_0$ has $O(n)$ nonzeros per
column, under suitable probability model for $\mathbf X_0$.
  Our algorithmic pipeline centers around solving a certain nonconvex
optimization problem with a spherical constraint, and hence is naturally
phrased in the language of manifold optimization. In a companion paper
(arXiv:1511.03607), we have showed that with high probability our nonconvex
formulation has no &quot;spurious&quot; local minimizers and any saddle point present is
second-order. In this paper, we take advantage of the particular geometric
structure and design a Riemannian trust region algorithm over the sphere that
provably converges to a local minimizer with an arbitrary initialization. Such
minimizers give excellent approximations to rows of $\mathbf X_0$. The rows are
recovered by linear programming rounding and deflation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04780</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04780</id><created>2015-11-15</created><authors><author><keyname>Weichwald</keyname><forenames>Sebastian</forenames></author><author><keyname>Meyer</keyname><forenames>Timm</forenames></author><author><keyname>&#xd6;zdenizci</keyname><forenames>Ozan</forenames></author><author><keyname>Sch&#xf6;lkopf</keyname><forenames>Bernhard</forenames></author><author><keyname>Ball</keyname><forenames>Tonio</forenames></author><author><keyname>Grosse-Wentrup</keyname><forenames>Moritz</forenames></author></authors><title>Causal interpretation rules for encoding and decoding models in
  neuroimaging</title><categories>stat.ML cs.LG q-bio.NC stat.AP</categories><comments>accepted manuscript</comments><journal-ref>NeuroImage, 110:48-59, 2015</journal-ref><doi>10.1016/j.neuroimage.2015.01.036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Causal terminology is often introduced in the interpretation of encoding and
decoding models trained on neuroimaging data. In this article, we investigate
which causal statements are warranted and which ones are not supported by
empirical evidence. We argue that the distinction between encoding and decoding
models is not sufficient for this purpose: relevant features in encoding and
decoding models carry a different meaning in stimulus- and in response-based
experimental paradigms. We show that only encoding models in the stimulus-based
setting support unambiguous causal interpretations. By combining encoding and
decoding models trained on the same data, however, we obtain insights into
causal relations beyond those that are implied by each individual model type.
We illustrate the empirical relevance of our theoretical findings on EEG data
recorded during a visuo-motor learning task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04785</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04785</id><created>2015-11-15</created><authors><author><keyname>Webb</keyname><forenames>Jonathan</forenames></author><author><keyname>Docemmilli</keyname><forenames>Fernando</forenames></author><author><keyname>Bonin</keyname><forenames>Mikhail</forenames></author></authors><title>Graph Theory Applications in Network Security</title><categories>cs.CR cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph theory has become a very critical component in many applications in the
computing field including networking and security. Unfortunately, it is also
amongst the most complex topics to understand and apply.
  In this paper, we review some of the key applications of graph theory in
network security. We first cover some algorithmic aspects, then present network
coding and its relation to routing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04792</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04792</id><created>2015-11-15</created><updated>2015-11-23</updated><authors><author><keyname>Leong</keyname><forenames>Alex S.</forenames></author><author><keyname>Dey</keyname><forenames>Subhrakanti</forenames></author><author><keyname>Quevedo</keyname><forenames>Daniel E.</forenames></author></authors><title>Sensor Scheduling in Variance Based Event Triggered Estimation with
  Packet Drops</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a remote state estimation problem with multiple sensors
observing a dynamical process, where sensors transmit local state estimates
over an independent and identically distributed (i.i.d.) packet dropping
channel to a remote estimator. At every discrete time instant, the remote
estimator decides whether each sensor should transmit or not, with each sensor
transmission incurring a fixed energy cost. The channel is shared such that
collisions will occur if more than one sensor transmits at a time. Performance
is quantified via an optimization problem that minimizes a convex combination
of the expected estimation error covariance at the remote estimator and
expected energy usage across the sensors. For transmission schedules dependent
only on the estimation error covariance at the remote estimator, this work
establishes structural results on the optimal scheduling which show that 1) for
unstable systems, if the error covariance is large then a sensor will always be
scheduled to transmit, and 2) there is a threshold-type behaviour in switching
from one sensor transmitting to another. Specializing to the single sensor
case, these structural results demonstrate that a threshold policy (i.e.
transmit if the error covariance exceeds a certain threshold and don't transmit
otherwise) is optimal. We also consider the situation where sensors transmit
measurements instead of state estimates, and establish structural results
including the optimality of threshold policies for the single sensor, scalar
case. These results provide a theoretical justification for the use of such
threshold policies in variance based event triggered estimation. Numerical
studies confirm the qualitative behaviour predicted by our structural results.
An extension of the structural results to Markovian packet drops is also
outlined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04794</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04794</id><created>2015-11-15</created><authors><author><keyname>Koohian</keyname><forenames>Abbas</forenames></author><author><keyname>Mehrpouyan</keyname><forenames>Hani</forenames></author><author><keyname>Nasir</keyname><forenames>Ali A.</forenames></author><author><keyname>Durrani</keyname><forenames>Salman</forenames></author><author><keyname>Azarbad</keyname><forenames>Mohammad</forenames></author><author><keyname>Blostein</keyname><forenames>Steven D.</forenames></author></authors><title>Blind Channel Estimation in Full Duplex Systems: Identifiability
  Analysis, Bounds, and Estimators</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Signal Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider blind channel estimation in a single-input single-output
full-duplex communication system, where both the self-interference and the
communication channels need to be accurately estimated. In this context, blind
estimators are attractive as they improve bandwidth efficiency but they suffer
from the phase ambiguity problem. In this paper, we first formally define and
analyse this ambiguity and then develop a general framework for testing and
designing modulation sets for blind estimation of channel parameters. We
mathematically show that simply shifting the mean of the $M$-PSK modulation
resolves the ambiguity problem. We also show how this can be extended to more
general modulation sets. Finally, we propose an expectation maximization (EM)
iterative estimator and a closed form minimum mean square error (MMSE)
estimator for use with the shifted modulation set. Since the non-data aided
Cram\'er-Rao lower bound (CRLB) or the Bayesian CRLB (BCRLB) are intractable,
we derive the data-aided CRLB and the data-aided BCRLB to assess the
performance of these estimators. Simulations show that both estimators reach
the performance of their corresponding bounds. The EM estimator has
considerably lower computational complexity compared to the MMSE estimator for
a large number of observations. The MMSE estimator performs well for number of
observations as low as $N=6$, which is desirable for delay constrained systems.
The simulation results also show the robustness of proposed estimators to
increasing power of self-interference signal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04798</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04798</id><created>2015-11-15</created><authors><author><keyname>Xu</keyname><forenames>Baohan</forenames></author><author><keyname>Fu</keyname><forenames>Yanwei</forenames></author><author><keyname>Jiang</keyname><forenames>Yu-Gang</forenames></author><author><keyname>Li</keyname><forenames>Boyang</forenames></author><author><keyname>Sigal</keyname><forenames>Leonid</forenames></author></authors><title>Heterogeneous Knowledge Transfer in Video Emotion Recognition,
  Attribution and Summarization</title><categories>cs.CV cs.AI cs.MM</categories><comments>13 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Emotional content is a key element in user-generated videos. However, it is
difficult to understand emotions conveyed in such videos due to the complex and
unstructured nature of user-generated content and the sparsity of video frames
that express emotion. In this paper, for the first time, we study the problem
of transferring knowledge from heterogeneous external sources, including image
and textual data, to facilitate three related tasks in video emotion
understanding: emotion recognition, emotion attribution and emotion-oriented
summarization. Specifically, our framework (1) learns a video encoding from an
auxiliary emotional image dataset in order to improve supervised video emotion
recognition, and (2) transfers knowledge from an auxiliary textual corpus for
zero-shot \pl{recognition} of emotion classes unseen during training. The
proposed technique for knowledge transfer facilitates novel applications of
emotion attribution and emotion-oriented summarization. A comprehensive set of
experiments on multiple datasets demonstrate the effectiveness of our
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04805</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04805</id><created>2015-11-15</created><authors><author><keyname>Liu</keyname><forenames>Tong</forenames></author><author><keyname>Homan</keyname><forenames>Christopher M.</forenames></author><author><keyname>Alm</keyname><forenames>Cecilia Ovesdotter</forenames></author><author><keyname>White</keyname><forenames>Ann Marie</forenames></author><author><keyname>Lytle-Flint</keyname><forenames>Megan C.</forenames></author><author><keyname>Kautz</keyname><forenames>Henry A.</forenames></author></authors><title>Job-related discourse on social media</title><categories>cs.SI</categories><comments>9 pages, 7 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Working adults spend nearly one third of their daily time at their jobs. In
this paper, we study job-related social media discourse from a community of
users. We use both crowdsourcing and local expertise to train a classifier to
detect job-related messages on Twitter. Additionally, we analyze the linguistic
differences in a job-related corpus of tweets between individual users vs.
commercial accounts. The volumes of job-related tweets from individual users
indicate that people use Twitter with distinct monthly, daily, and hourly
patterns. We further show that the moods associated with jobs, positive and
negative, have unique diurnal rhythms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04808</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04808</id><created>2015-11-15</created><authors><author><keyname>Liu</keyname><forenames>Mengyi</forenames></author><author><keyname>Wang</keyname><forenames>Ruiping</forenames></author><author><keyname>Shan</keyname><forenames>Shiguang</forenames></author><author><keyname>Chen</keyname><forenames>Xilin</forenames></author></authors><title>Learning Mid-level Words on Riemannian Manifold for Action Recognition</title><categories>cs.CV</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human action recognition remains a challenging task due to the various
sources of video data and large intra-class variations. It thus becomes one of
the key issues in recent research to explore effective and robust
representation to handle such challenges. In this paper, we propose a novel
representation approach by constructing mid-level words in videos and encoding
them on Riemannian manifold. Specifically, we first conduct a global alignment
on the densely extracted low-level features to build a bank of corresponding
feature groups, each of which can be statistically modeled as a mid-level word
lying on some specific Riemannian manifold. Based on these mid-level words, we
construct intrinsic Riemannian codebooks by employing K-Karcher-means
clustering and Riemannian Gaussian Mixture Model, and consequently extend the
Riemannian manifold version of three well studied encoding methods in Euclidean
space, i.e. Bag of Visual Words (BoVW), Vector of Locally Aggregated
Descriptors (VLAD), and Fisher Vector (FV), to obtain the final action video
representations. Our method is evaluated in two tasks on four popular realistic
datasets: action recognition on YouTube, UCF50, HMDB51 databases, and action
similarity labeling on ASLAN database. In all cases, the reported results
achieve very competitive performance with those most recent state-of-the-art
works.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04810</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04810</id><created>2015-11-15</created><authors><author><keyname>Zhou</keyname><forenames>Fang</forenames></author><author><keyname>Li</keyname><forenames>Xiaopeng</forenames></author><author><keyname>Ma</keyname><forenames>Jiaqi</forenames></author></authors><title>Parsimonious shooting heuristic for trajectory control of connected
  automated traffic part I: Theoretical analysis with generalized time
  geography</title><categories>math.OC cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a problem of controlling trajectories of a platoon of
vehicles on a highway segment with connected and automated vehicles. This
problem is complex because each vehicle trajectory is an infinite-dimensional
object and neighboring trajectories have complex interactions (e.g.,
car-following behavior). A parsimonious shooting heuristic algorithm is
proposed to construct vehicle trajectories on a signalized highway segment that
comply with boundary conditions for vehicle arrivals, vehicle mechanical
limits, traffic lights and vehicle following safety. This algorithm breaks each
vehicle trajectory into a few sections and each is analytically solvable. This
decomposes the original hard trajectory control problem to a simple
constructive heuristic. Then we slightly adapt this shooting heuristic
algorithm to efficiently solve a leading vehicle problem on an uninterrupted
freeway. To study theoretical properties of the proposed algorithms, the time
geography theory is generalized by considering finite accelerations. With this
generalized theory, it is found that under mild conditions, these algorithms
can always obtain a feasible solution to the original complex trajectory
control problem. Further, we discover that the shooting heuristic solution is a
generalization of the solution to the classic kinematic wave theory by
incorporating finite accelerations. We identify the theoretical bounds to the
difference between the shooting heuristic solution and the kinematic wave
solution. Numerical experiments are conducted to verify the theoretical results
and to draw additional insights into the potential of trajectory control in
improving traffic performance. Building upon this foundation, an optimization
framework will be presented in a following paper as Part II of this study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04813</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04813</id><created>2015-11-15</created><updated>2015-11-18</updated><authors><author><keyname>Lu</keyname><forenames>Jing</forenames></author><author><keyname>Hoi</keyname><forenames>Steven C. H.</forenames></author><author><keyname>Sahoo</keyname><forenames>Doyen</forenames></author><author><keyname>Zhao</keyname><forenames>Peilin</forenames></author></authors><title>Budget Online Multiple Kernel Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online learning with multiple kernels has gained increasing interests in
recent years and found many applications. For classification tasks, Online
Multiple Kernel Classification (OMKC), which learns a kernel based classifier
by seeking the optimal linear combination of a pool of single kernel
classifiers in an online fashion, achieves superior accuracy and enjoys great
flexibility compared with traditional single-kernel classifiers. Despite being
studied extensively, existing OMKC algorithms suffer from high computational
cost due to their unbounded numbers of support vectors. To overcome this
drawback, we present a novel framework of Budget Online Multiple Kernel
Learning (BOMKL) and propose a new Sparse Passive Aggressive learning to
perform effective budget online learning. Specifically, we adopt a simple yet
effective Bernoulli sampling to decide if an incoming instance should be added
to the current set of support vectors. By limiting the number of support
vectors, our method can significantly accelerate OMKC while maintaining
satisfactory accuracy that is comparable to that of the existing OMKC
algorithms. We theoretically prove that our new method achieves an optimal
regret bound in expectation, and empirically found that the proposed algorithm
outperforms various OMKC algorithms and can easily scale up to large-scale
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04814</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04814</id><created>2015-11-15</created><authors><author><keyname>Erpek</keyname><forenames>Tugba</forenames></author><author><keyname>Abdelhadi</keyname><forenames>Ahmed</forenames></author><author><keyname>Clancy</keyname><forenames>T. Charles</forenames></author></authors><title>Application-Aware Resource Block and Power Allocation for LTE</title><categories>cs.NI</categories><comments>5 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we implement an application-aware scheduler that
differentiates users running real-time applications and delay-tolerant
applications while allocating resources. This approach ensures that the
priority is given to real-time applications over delay-tolerant applications.
In our system model, we include realistic channel effects of Long Term
Evolution (LTE) system. Our application-aware scheduler runs in two stages, the
first stage is resource block allocation and the second stage is power
allocation. In the optimal solution of resource block allocation problem, each
user is inherently guaranteed a minimum Quality of Experience (QoE) while
ensuring priority given to users with real-time applications. In the power
allocation problem, a new power allocation method is proposed which utilizes
the optimal solution of the application-aware resource block scheduling
problem. As a proof of concept, we run a simulation comparison between a
conventional proportional fairness scheduler and the application-aware
scheduler. The simulation results show better QoE with the application-aware
scheduler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04834</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04834</id><created>2015-11-16</created><updated>2016-03-01</updated><authors><author><keyname>Neelakantan</keyname><forenames>Arvind</forenames></author><author><keyname>Le</keyname><forenames>Quoc V.</forenames></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author></authors><title>Neural Programmer: Inducing Latent Programs with Gradient Descent</title><categories>cs.LG cs.CL stat.ML</categories><comments>Accepted as a conference paper at ICLR 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks have achieved impressive supervised classification
performance in many tasks including image recognition, speech recognition, and
sequence to sequence learning. However, this success has not been translated to
applications like question answering that may involve complex arithmetic and
logic reasoning. A major limitation of these models is in their inability to
learn even simple arithmetic and logic operations. For example, it has been
shown that neural networks fail to learn to add two binary numbers reliably. In
this work, we propose Neural Programmer, an end-to-end differentiable neural
network augmented with a small set of basic arithmetic and logic operations.
Neural Programmer can call these augmented operations over several steps,
thereby inducing compositional programs that are more complex than the built-in
operations. The model learns from a weak supervision signal which is the result
of execution of the correct program, hence it does not require expensive
annotation of the correct program itself. The decisions of what operations to
call, and what data segments to apply to are inferred by Neural Programmer.
Such decisions, during training, are done in a differentiable fashion so that
the entire network can be trained jointly by gradient descent. We find that
training the model is difficult, but it can be greatly improved by adding
random noise to the gradient. On a fairly complex synthetic table-comprehension
dataset, traditional recurrent networks and attentional models perform poorly
while Neural Programmer typically obtains nearly perfect accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04836</identifier>
 <datestamp>2016-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04836</id><created>2015-11-16</created><updated>2016-01-20</updated><authors><author><keyname>Lee</keyname><forenames>Byunghan</forenames></author><author><keyname>Moon</keyname><forenames>Taesup</forenames></author><author><keyname>Yoon</keyname><forenames>Sungroh</forenames></author><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author></authors><title>DUDE-Seq: Fast, flexible, and robust denoising of nucleotide sequences</title><categories>q-bio.GN cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the correction of errors from nucleotide sequences produced by
next-generation sequencing. The error rate in reads has been increasing with
the shift of focus of mainstream sequencers from accuracy to throughput.
Denoising in high-throughput sequencing is thus becoming a crucial component
for boosting the reliability of downstream analyses. Our methodology, named
DUDE-Seq, is derived from a general setting of reconstructing finite-valued
source data corrupted by a discrete memoryless channel and provides an
effective means for correcting substitution and homopolymer indel errors, the
two major types of sequencing errors in most high-throughput sequencing
platforms. Our experimental studies with real and simulated data sets suggest
that the proposed DUDE-Seq not only outperforms existing alternatives in terms
of error-correction capabilities, and time efficiency, but also boosts the
reliability of downstream analyses. Further, the flexibility of DUDE-Seq
enables us to robustly apply it to different sequencing platforms and analysis
pipelines by a simple update of the noise model. [availability:
http://data.snu.ac.kr/pub/dude-seq]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04838</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04838</id><created>2015-11-16</created><authors><author><keyname>Ar&#x131;kan</keyname><forenames>Erdal</forenames></author></authors><title>On the Origin of Polar Coding</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Journal on Selected Areas in Communications,
  Special Issue on Recent Advances on Capacity-Approaching Codes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Polar coding was conceived originally as a technique for boosting the cutoff
rate of sequential decoding, along the lines of earlier schemes of Pinsker and
Massey. The key idea in boosting the cutoff rate is to take a vector channel
(either given or artificially built), split it into multiple correlated
subchannels, and employ a separate sequential decoder on each subchannel. Polar
coding was originally designed to be a low-complexity recursive channel
combining and splitting operation of this type, to be used as the inner code in
a concatenated scheme with outer convolutional coding and sequential decoding.
However, the polar inner code turned out to be so effective that no outer code
was actually needed to achieve the original aim of boosting the cutoff rate to
channel capacity. This paper explains the cutoff rate considerations that
motivated the development of polar coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04839</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04839</id><created>2015-11-16</created><updated>2016-02-07</updated><authors><author><keyname>Michaeli</keyname><forenames>Tomer</forenames></author><author><keyname>Wang</keyname><forenames>Weiran</forenames></author><author><keyname>Livescu</keyname><forenames>Karen</forenames></author></authors><title>Nonparametric Canonical Correlation Analysis</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Canonical correlation analysis (CCA) is a classical representation learning
technique for finding correlated variables in multi-view data. Several
nonlinear extensions of the original linear CCA have been proposed, including
kernel and deep neural network methods. These approaches seek maximally
correlated projections among families of functions, which the user specifies
(by choosing a kernel or neural network structure), and are computationally
demanding. Interestingly, the theory of nonlinear CCA, without functional
restrictions, had been studied in the population setting by Lancaster already
in the 1950s, but these results have not inspired practical algorithms. We
revisit Lancaster's theory to devise a practical algorithm for nonparametric
CCA (NCCA). Specifically, we show that the solution can be expressed in terms
of the singular value decomposition of a certain operator associated with the
joint density of the views. Thus, by estimating the population density from
data, NCCA reduces to solving an eigenvalue system, superficially like kernel
CCA but, importantly, without requiring the inversion of any kernel matrix. We
also derive a partially linear CCA (PLCCA) variant in which one of the views
undergoes a linear projection while the other is nonparametric. Using a kernel
density estimate based on a small number of nearest neighbors, our NCCA and
PLCCA algorithms are memory-efficient, often run much faster, and perform
better than kernel CCA and comparable to deep CCA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04841</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04841</id><created>2015-11-16</created><updated>2016-01-09</updated><authors><author><keyname>Xie</keyname><forenames>Hongxiang</forenames></author><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Zhang</keyname><forenames>Shun</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author></authors><title>A Simple DFT-aided Spatial Basis Expansion Model and Channel Estimation
  Strategy for TDD/FDD Massive MIMO Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new transmission strategy for the multiuser massive
multiple-input multiple-output (MIMO) systems, including uplink/downlink
channel estimation and user scheduling for data transmission. A discrete
Fourier transform (DFT) aided spatial basis expansion model (SBEM) is first
introduced to represent the uplink/downlink channels with much few parameter
dimensions by exploiting angle reciprocity and the physical characteristics of
the uniform linear array (ULA). With SBEM, both uplink and downlink channel
estimation of multiuser can be carried out with very few amount of training
resources, which significantly reduces the training overhead and feedback cost.
Meanwhile, the pilot contamination problem in the uplink raining is immediately
relieved by exploiting the spatial information of users. To enhance the
spectral efficiency and to fully utilize the spatial resources, we also design
a greedy user scheduling scheme during the data transmission period. Compared
to existing low-rank models, the newly proposed SBEM offers an alternative for
channel acquisition without need of channel statistics for both TDD and FDD
systems based on the angle reciprocity. Moreover, the proposed method can be
efficiently deployed by the fast Fourier transform (FFT). Various numerical
results are provided to corroborate the proposed studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04846</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04846</id><created>2015-11-16</created><authors><author><keyname>Tsai</keyname><forenames>Yi-Fan</forenames></author><author><keyname>Coughlin</keyname><forenames>Devin</forenames></author><author><keyname>Chang</keyname><forenames>Bor-Yuh Evan</forenames></author><author><keyname>Rival</keyname><forenames>Xavier</forenames></author></authors><title>Synthesizing Short-Circuiting Validation of Data Structure Invariants</title><categories>cs.PL</categories><acm-class>D.2.4; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents incremental verification-validation, a novel approach for
checking rich data structure invariants expressed as separation logic
assertions. Incremental verification-validation combines static verification of
separation properties with efficient, short-circuiting dynamic validation of
arbitrarily rich data constraints. A data structure invariant checker is an
inductive predicate in separation logic with an executable interpretation; a
short-circuiting checker is an invariant checker that stops checking whenever
it detects at run time that an assertion for some sub-structure has been fully
proven statically. At a high level, our approach does two things: it statically
proves the separation properties of data structure invariants using a static
shape analysis in a standard way but then leverages this proof in a novel
manner to synthesize short-circuiting dynamic validation of the data
properties. As a consequence, we enable dynamic validation to make up for
imprecision in sound static analysis while simultaneously leveraging the static
verification to make the remaining dynamic validation efficient. We show
empirically that short-circuiting can yield asymptotic improvements in dynamic
validation, with low overhead over no validation, even in cases where static
verification is incomplete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04854</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04854</id><created>2015-11-16</created><authors><author><keyname>Shi</keyname><forenames>Chuan</forenames></author><author><keyname>Li</keyname><forenames>Yitong</forenames></author><author><keyname>Zhang</keyname><forenames>Jiawei</forenames></author><author><keyname>Sun</keyname><forenames>Yizhou</forenames></author><author><keyname>Yu</keyname><forenames>Philip S.</forenames></author></authors><title>A Survey of Heterogeneous Information Network Analysis</title><categories>cs.SI physics.soc-ph</categories><comments>45 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most real systems consist of a large number of interacting, multi-typed
components, while most contemporary researches model them as homogeneous
networks, without distinguishing different types of objects and links in the
networks. Recently, more and more researchers begin to consider these
interconnected, multi-typed data as heterogeneous information networks, and
develop structural analysis approaches by leveraging the rich semantic meaning
of structural types of objects and links in the networks. Compared to widely
studied homogeneous network, the heterogeneous information network contains
richer structure and semantic information, which provides plenty of
opportunities as well as a lot of challenges for data mining. In this paper, we
provide a survey of heterogeneous information network analysis. We will
introduce basic concepts of heterogeneous information network analysis, examine
its developments on different data mining tasks, discuss some advanced topics,
and point out some future research directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04855</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04855</id><created>2015-11-16</created><authors><author><keyname>Pibre</keyname><forenames>Lionel</forenames><affiliation>ICAR</affiliation></author><author><keyname>J&#xe9;r&#xf4;me</keyname><forenames>Pasquet</forenames><affiliation>ICAR</affiliation></author><author><keyname>Ienco</keyname><forenames>Dino</forenames><affiliation>UMR TETIS</affiliation></author><author><keyname>Chaumont</keyname><forenames>Marc</forenames><affiliation>ICAR</affiliation></author></authors><title>Deep Learning for steganalysis is better than a Rich Model with an
  Ensemble Classifier, and is natively robust to the cover source-mismatch</title><categories>cs.MM cs.CV cs.LG cs.NE</categories><comments>IS&amp;T. Media Watermarking, Security, and Forensics, Part of IS&amp;T
  International Symposium on Electronic Imaging, EI'2016, Feb 2015, San
  Fransisco, United States</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Since the BOSS competition, in 2010, most steganalysis approaches use a
learning methodology involving two steps: feature extraction, such as the Rich
Models (RM), for the image representation, and use of the Ensemble Classifier
(EC) for the learning step. In 2015, Qian et al. have shown that the use of a
deep learning approach that jointly learns and computes the features, is very
promising for the steganalysis. In this paper, we follow-up the study of Qian
et al., and show that, due to intrinsic joint minimization, the results
obtained from a Convolutional Neural Network (CNN) or a Fully Connected Neural
Network (FNN), if well parameterized, surpass the conventional use of a RM with
an EC. First, numerous experiments were conducted in order to find the best &quot;
shape &quot; of the CNN. Second, experiments were carried out in the clairvoyant
scenario in order to compare the CNN and FNN to an RM with an EC. The results
show more than 16% reduction in the classification error with our CNN or FNN.
Third, experiments were also performed in a cover-source mismatch setting. The
results show that the CNN and FNN are naturally robust to the mismatch problem.
In Addition to the experiments, we provide discussions on the internal
mechanisms of a CNN, and weave links with some previously stated ideas, in
order to understand the impressive results we obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04861</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04861</id><created>2015-11-16</created><authors><author><keyname>Lee</keyname><forenames>Woo-Hyun</forenames></author><author><keyname>Jun</keyname><forenames>Hee-Gook</forenames></author><author><keyname>Kim</keyname><forenames>Hyoung-Joo</forenames></author></authors><title>Hadoop Mapreduce Performance Enhancement Using In-node Combiners</title><categories>cs.DC</categories><comments>International Journal of Computer Science &amp; Information Technology,
  2015</comments><doi>10.5121/ijcsit.2015.7501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While advanced analysis of large dataset is in high demand, data sizes have
surpassed capabilities of conventional software and hardware. Hadoop framework
distributes large datasets over multiple commodity servers and performs
parallel computations. We discuss the I/O bottlenecks of Hadoop framework and
propose methods for enhancing I/O performance. A proven approach is to cache
data to maximize memory-locality of all map tasks. We introduce an approach to
optimize I/O, the in-node combining design which extends the traditional
combiner to a node level. The in-node combiner reduces the total number of
intermediate results and curtail network traffic between mappers and reducers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04867</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04867</id><created>2015-11-16</created><updated>2015-11-23</updated><authors><author><keyname>Rajpal</keyname><forenames>Avni</forenames></author><author><keyname>Shah</keyname><forenames>Nirmesh J.</forenames></author><author><keyname>Zaki</keyname><forenames>Mohammadi</forenames></author><author><keyname>Patil</keyname><forenames>Hemant A.</forenames></author></authors><title>Quality assessment of voice converted speech using articulatory features</title><categories>cs.SD</categories><comments>The paper is withdrawn from the arxiv. Author doesnot want
  circulation of unpublished unverified results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel application based on acoustic-to-articulatory inversion
towards quality assessment of voice converted speech. The ability of humans to
speak effortlessly requires coordinated movements of various articulators,
muscles, etc. This effortless movement contributes towards naturalness,
intelligibility and speakers identity which is partially present in voice
converted speech. Hence, during voice conversion, the information related to
speech production is lost. In this paper, this loss is quantified for male
voice, by showing increase in RMSE error for voice converted speech followed by
showing decrease in mutual information. Similar results are obtained in case of
female voice. This observation is extended by showing that articulatory
features can be used as an objective measure. The effectiveness of proposed
measure over MCD is illustrated by comparing their correlation with Mean
Opinion Score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04868</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04868</id><created>2015-11-16</created><updated>2015-11-19</updated><authors><author><keyname>Jaitly</keyname><forenames>Navdeep</forenames></author><author><keyname>Le</keyname><forenames>Quoc V.</forenames></author><author><keyname>Vinyals</keyname><forenames>Oriol</forenames></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author><author><keyname>Bengio</keyname><forenames>Samy</forenames></author></authors><title>An Online Sequence-to-Sequence Model Using Partial Conditioning</title><categories>cs.LG cs.CL cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence-to-sequence models have achieved impressive results on various
tasks. However, they are unsuitable for tasks that require incremental
predictions to be made as more data arrives. This is because they generate an
output sequence conditioned on an entire input sequence. In this paper, we
present a new model that can make incremental predictions as more input
arrives, without redoing the entire computation. Unlike sequence-to-sequence
models, our method computes the next-step distribution conditioned on the
partial input sequence observed and the partial sequence generated. It
accomplishes this goal using an encoder recurrent neural network (RNN) that
computes features at the same frame rate as the input, and a transducer RNN
that operates over blocks of input steps. The transducer RNN extends the
sequence produced so far using a local sequence-to-sequence model. During
training, our method uses alignment information to generate supervised targets
for each block. Approximate alignment is easily available for tasks such as
speech recognition, action recognition in videos, etc. During inference
(decoding), beam search is used to find the most likely output sequence for an
input sequence. This decoding is performed online - at the end of each block,
the best candidates from the previous block are extended through the local
sequence-to-sequence model. On TIMIT, our online method achieves 19.8% phone
error rate (PER). For comparison with published sequence-to-sequence methods,
we used a bidirectional encoder and achieved 18.7% PER compared to 17.6% from
the best reported sequence-to-sequence model. Importantly, unlike
sequence-to-sequence our model is minimally impacted by the length of the
input. On artificially created longer utterances, it achieves 20.9% with a
unidirectional model, compared to 20% from the best bidirectional
sequence-to-sequence models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04870</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04870</id><created>2015-11-16</created><authors><author><keyname>Beer</keyname><forenames>Gernot</forenames></author><author><keyname>Marussig</keyname><forenames>Benjamin</forenames></author><author><keyname>Zechner</keyname><forenames>J&#xfc;rgen</forenames></author><author><keyname>D&#xfc;nser</keyname><forenames>Christian</forenames></author><author><keyname>Fries</keyname><forenames>Thomas-Peter</forenames></author></authors><title>Isogeometric Boundary Element Analysis with elasto-plastic inclusions.
  Part 1: Plane problems</title><categories>cs.NA math.NA physics.geo-ph</categories><comments>21 pages, 16 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work a novel approach is presented for the isogeometric Boundary
Element analysis of domains that contain inclusions with different elastic
properties than the ones used for computing the fundamental solutions. In
addition the inclusion may exhibit inelastic material behavior. In this paper
only plane stress/strain problems are considered.
  In our approach the geometry of the inclusion is described using NURBS basis
functions. The advantage over currently used methods is that no discretization
into cells is required in order to evaluate the arising volume integrals. The
other difference to current approaches is that Kernels of lower singularity are
used in the domain term. The implementation is verified on simple finite and
infinite domain examples with various boundary conditions. Finally a practical
application in geomechanics is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04874</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04874</id><created>2015-11-16</created><updated>2016-01-16</updated><authors><author><keyname>Tomamichel</keyname><forenames>Marco</forenames></author><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author></authors><title>Operational Interpretation of Renyi Information Measures via Composite
  Hypothesis Testing Against Product and Markov Distributions</title><categories>cs.IT math.IT quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit the problem of asymmetric binary hypothesis testing against a
composite alternative hypothesis. We introduce a general framework to treat
such problems when the alternative hypothesis adheres to certain axioms. In
this case we find the threshold rate, the optimal error and strong converse
exponents (at large deviations from the threshold) and the second order
asymptotics (at small deviations from the threshold). We apply our results to
find operational interpretations of various Renyi information measures. In case
the alternative hypothesis is comprised of bipartite product distributions, we
find that the optimal error and strong converse exponents are determined by
variations of Renyi mutual information. In case the alternative hypothesis
consists of tripartite distributions satisfying the Markov property, we find
that the optimal exponents are determined by variations of Renyi conditional
mutual information. In either case the relevant notion of Renyi mutual
information depends on the precise choice of the alternative hypothesis. As
such, our work also strengthens the view that different definitions of Renyi
mutual information, conditional entropy and conditional mutual information are
adequate depending on the context in which the measures are used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04891</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04891</id><created>2015-11-16</created><updated>2016-01-07</updated><authors><author><keyname>Elhoseiny</keyname><forenames>Mohamed</forenames></author><author><keyname>Cohen</keyname><forenames>Scott</forenames></author><author><keyname>Chang</keyname><forenames>Walter</forenames></author><author><keyname>Price</keyname><forenames>Brian</forenames></author><author><keyname>Elgammal</keyname><forenames>Ahmed</forenames></author></authors><title>Sherlock: Modeling Structured Knowledge in Images</title><categories>cs.CV cs.CL cs.LG</categories><comments>Jan 7 Update</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How to build a machine learning method that can continuously gain structured
visual knowledge by learning structured facts? Our goal in this paper is to
address this question by proposing a problem setting, where training data comes
as structured facts in images with different types including (1) objects(e.g.,
&lt; boy &gt;), (2) attributes (e.g., &lt; boy,tall &gt;), (3) actions (e.g., &lt; boy,
playing &gt;), (4) interactions (e.g., &lt; boy, riding, a horse &gt;). Each structured
fact has a semantic language view (e.g., &lt; boy, playing &gt;) and a visual view
(an image with this fact). A human is able to efficiently gain visual knowledge
by learning facts in a never ending process, and as we believe in a structured
way (e.g., understanding &quot;playing&quot; is the action part of &lt; boy, playing &gt;, and
hence can generalize to recognize &lt; girl, playing &gt; if just learn &lt; girl &gt;
additionally). Inspired by human visual perception, we propose a model that is
(1) able to learn a representation, we name as wild-card, which covers
different types of structured facts, (2) could flexibly get fed with structured
fact language-visual view pairs in a never ending way to gain more structured
knowledge, (3) could generalize to unseen facts, and (4) allows retrieval of
both the fact language view given the visual view (i.e., image) and vice versa.
We also propose a novel method to generate hundreds of thousands of structured
fact pairs from image caption data, which are necessary to train our model and
can be useful for other applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04892</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04892</id><created>2015-11-16</created><authors><author><keyname>Engwer</keyname><forenames>Christian</forenames></author><author><keyname>Vorwerk</keyname><forenames>Johannes</forenames></author><author><keyname>Ludewig</keyname><forenames>Jakob</forenames></author><author><keyname>Wolters</keyname><forenames>Carsten H.</forenames></author></authors><title>A discontinuous Galerkin Method for the EEG Forward Problem</title><categories>cs.CE math.NA q-bio.NC</categories><msc-class>35J25, 35J75, 35Q90, 65N12, 65N30, 68U20, 92C50</msc-class><acm-class>G.1.8; G.1.10; I.6.0; J.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to perform accurate electroencephalography (EEG) source
reconstruction, i.e., to localize the sources underlying a measured EEG, the
electric potential distribution at the electrodes generated by a dipolar
current source in the brain has to be simulated, the so-called EEG forward
problem. Therefore, it is necessary to apply numerical methods that are able to
take the individual geometry and conductivity distribution of the subject's
head into account. The finite element method (FEM) has shown high numerical
accuracy with the possibility to model complex geometries and conductive
features, e.g., white matter conductivity anisotropy. In this article we
introduce and analyze the application of a Discontinuous Galerkin (DG) method,
a finite element method that includes features of the finite volume framework,
to the EEG forward problem. The DG-FEM approach allows to fulfill the
conservation property of electric charge also in the discrete case, making it
attractive for a variety of applications. Furthermore, as we show, it can
alleviate modeling inaccuracies that might occur in head geometries when using
classical FE methods, e.g., so-called &quot;skull leakage effects&quot; for skull
compartments with a thickness in the range of the mesh resolution. Therefore,
we derive a DG formulation of the FEM subtraction approach for the EEG forward
problem and present first numerical results which highlight the advantageous
features and the potential of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04893</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04893</id><created>2015-11-16</created><authors><author><keyname>Chistikov</keyname><forenames>Dmitry</forenames></author><author><keyname>Haase</keyname><forenames>Christoph</forenames></author><author><keyname>Halfon</keyname><forenames>Simon</forenames></author></authors><title>Context-Free Commutative Grammars with Integer Counters and Resets</title><categories>cs.FL</categories><comments>31 pages</comments><acm-class>F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computational complexity of reachability, coverability and
inclusion for extensions of context-free commutative grammars with integer
counters and reset operations on them. Those grammars can alternatively be
viewed as an extension of communication-free Petri nets. Our main results are
that reachability and coverability are inter-reducible and both NP-complete. In
particular, this class of commutative grammars enjoys semi-linear reachability
sets. We also show that the inclusion problem is, in general, coNEXP-complete
and already $\Pi_2^\text{P}$-complete for grammars with only one non-terminal
symbol. Showing the lower bound for the latter result requires us to develop a
novel $\Pi_2^\text{P}$-complete variant of the classic subset sum problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04897</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04897</id><created>2015-11-16</created><authors><author><keyname>Lipp</keyname><forenames>Moritz</forenames></author><author><keyname>Gruss</keyname><forenames>Daniel</forenames></author><author><keyname>Spreitzer</keyname><forenames>Raphael</forenames></author><author><keyname>Mangard</keyname><forenames>Stefan</forenames></author></authors><title>ARMageddon: Last-Level Cache Attacks on Mobile Devices</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last 10 years cache attacks on Intel CPUs have gained increasing
attention among the scientific community. More specifically, powerful
techniques to exploit the cache side channel have been developed. However, so
far only a few investigations have been performed on modern smartphones and
mobile devices in general. In this work, we describe Evict+Reload, the first
access-based cross-core cache attack on modern ARM Cortex-A architectures as
used in most of today's mobile devices. Our attack approach overcomes several
limitations of existing cache attacks on ARM-based devices, for instance, the
requirement of a rooted device or specific permissions. Thereby, we broaden the
scope of cache attacks in two dimensions. First, we show that all existing
attacks on the x86 architecture can also be applied to mobile devices. Second,
despite the general belief these attacks can also be launched on non-rooted
devices and, thus, on millions of off-the-shelf devices.
  Similarly to the well-known Flush+Reload attack for the x86 architecture,
Evict+Reload allows to launch generic cache attacks on mobile devices. Based on
cache template attacks we identify information leaking through the last-level
cache that can be exploited, for instance, to infer tap and swipe events,
inter-keystroke timings as well as the length of words entered on the
touchscreen, and even cryptographic primitives implemented in Java.
Furthermore, we demonstrate the applicability of Prime+Probe attacks on ARM
Cortex-A CPUs. The performed example attacks demonstrate the immense potential
of our proposed attack techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04898</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04898</id><created>2015-11-16</created><authors><author><keyname>Thirion</keyname><forenames>Bertrand</forenames><affiliation>PARIETAL</affiliation></author><author><keyname>Hoyos-Idrobo</keyname><forenames>Andr&#xe9;s</forenames><affiliation>NEUROSPIN, PARIETAL</affiliation></author><author><keyname>Kahn</keyname><forenames>Jonas</forenames><affiliation>LPP</affiliation></author><author><keyname>Varoquaux</keyname><forenames>Gael</forenames><affiliation>NEUROSPIN, PARIETAL</affiliation></author></authors><title>Fast clustering for scalable statistical analysis on structured images</title><categories>stat.ML cs.CV</categories><comments>ICML Workshop on Statistics, Machine Learning and Neuroscience
  (Stamlins 2015), Jul 2015, Lille, France</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of brain images as markers for diseases or behavioral differences is
challenged by the small effects size and the ensuing lack of power, an issue
that has incited researchers to rely more systematically on large cohorts.
Coupled with resolution increases, this leads to very large datasets. A
striking example in the case of brain imaging is that of the Human Connectome
Project: 20 Terabytes of data and growing. The resulting data deluge poses
severe challenges regarding the tractability of some processing steps
(discriminant analysis, multivariate models) due to the memory demands posed by
these data. In this work, we revisit dimension reduction approaches, such as
random projections, with the aim of replacing costly function evaluations by
cheaper ones while decreasing the memory requirements. Specifically, we
investigate the use of alternate schemes, based on fast clustering, that are
well suited for signals exhibiting a strong spatial structure, such as
anatomical and functional brain images. Our contribution is twofold: i) we
propose a linear-time clustering scheme that bypasses the percolation issues
inherent in these algorithms and thus provides compressions nearly as good as
traditional quadratic-complexity variance-minimizing clustering schemes, ii) we
show that cluster-based compression can have the virtuous effect of removing
high-frequency noise, actually improving subsequent estimations steps. As a
consequence, the proposed approach yields very accurate models on several
large-scale problems yet with impressive gains in computational efficiency,
making it possible to analyze large datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04901</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04901</id><created>2015-11-16</created><authors><author><keyname>Huang</keyname><forenames>Zhiao</forenames></author><author><keyname>Zhou</keyname><forenames>Erjin</forenames></author><author><keyname>Cao</keyname><forenames>Zhimin</forenames></author></authors><title>Coarse-to-fine Face Alignment with Multi-Scale Local Patch Regression</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Facial landmark localization plays an important role in face recognition and
analysis applications. In this paper, we give a brief introduction to a
coarse-to-fine pipeline with neural networks and sequential regression. First,
a global convolutional network is applied to the holistic facial image to give
an initial landmark prediction. A pyramid of multi-scale local image patches is
then cropped to feed to a new network for each landmark to refine the
prediction. As the refinement network outputs a more accurate position
estimation than the input, such procedure could be repeated several times until
the estimation converges. We evaluate our system on the 300-W dataset [11] and
it outperforms the recent state-of-the-arts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04902</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04902</id><created>2015-11-16</created><authors><author><keyname>Schoenenberger</keyname><forenames>Yann</forenames></author><author><keyname>Paratte</keyname><forenames>Johan</forenames></author><author><keyname>Vandergheynst</keyname><forenames>Pierre</forenames></author></authors><title>Graph-based denoising for time-varying point clouds</title><categories>cs.CV cs.GR</categories><comments>4 pages, 3 figures, 3DTV-Con 2015</comments><acm-class>I.5.4</acm-class><journal-ref>3DTV-Conference: The True Vision - Capture, Transmission and
  Display of 3D Video (3DTV-CON) (2015) 1-4</journal-ref><doi>10.1109/3DTV.2015.7169366</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Noisy 3D point clouds arise in many applications. They may be due to errors
when constructing a 3D model from images or simply to imprecise depth sensors.
Point clouds can be given geometrical structure using graphs created from the
similarity information between points. This paper introduces a technique that
uses this graph structure and convex optimization methods to denoise 3D point
clouds. A short discussion presents how those methods naturally generalize to
time-varying inputs such as 3D point cloud time series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04906</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04906</id><created>2015-11-16</created><updated>2016-01-04</updated><authors><author><keyname>Zaratiegui</keyname><forenames>Jaime</forenames></author><author><keyname>Montoro</keyname><forenames>Ana</forenames></author><author><keyname>Castanedo</keyname><forenames>Federico</forenames></author></authors><title>Performing Highly Accurate Predictions Through Convolutional Networks
  for Actual Telecommunication Challenges</title><categories>cs.LG cs.CV</categories><comments>11 pages, 6 figures, under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigated how the application of deep learning, specifically the use of
convolutional networks trained with GPUs, can help to build better predictive
models in telecommunication business environments, and fill this gap. In
particular, we focus on the non-trivial problem of predicting customer churn in
telecommunication operators. Our model, called WiseNet, consists of a
convolutional network and a novel encoding method that transforms customer
activity data and Call Detail Records (CDRs) into images. Experimental
evaluation with several machine learning classifiers supports the ability of
WiseNet for learning features when using structured input data. For this type
of telecommunication business problems, we found that WiseNet outperforms
machine learning models with hand-crafted features, and does not require the
labor-intensive step of feature engineering. Furthermore, the same model has
been applied without retraining to a different market, achieving consistent
results. This confirms the generalization property of WiseNet and the ability
to extract useful representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04919</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04919</id><created>2015-11-16</created><updated>2015-12-20</updated><authors><author><keyname>Moskovich</keyname><forenames>Daniel</forenames></author><author><keyname>Carmi</keyname><forenames>Avishy Y.</forenames></author></authors><title>Tales told by coloured tangles</title><categories>cs.IT math.GT math.IT quant-ph</categories><comments>29 pages, 28 figures. Revised to be more self-contained</comments><msc-class>94A15, 81P68, 57M99</msc-class><acm-class>H.1.1; F.0</acm-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Tangle machines are a topologically inspired diagrammatic formalism to
describe information flow in networks. This paper begins with an expository
account of tangle machines motivated by the problem of describing `covariance
intersection' fusion of Gaussian estimators in networks. It then gives two
examples in which tangle machines tell stories of adiabatic quantum
computations, and discusses learning tangle machines from data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04925</identifier>
 <datestamp>2016-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04925</id><created>2015-11-16</created><authors><author><keyname>Kadavankandy</keyname><forenames>Arun</forenames><affiliation>MAESTRO</affiliation></author><author><keyname>Avrachenkov</keyname><forenames>Konstantin</forenames><affiliation>MAESTRO</affiliation></author><author><keyname>Prokhorenkova</keyname><forenames>Luidmilla Ostroumova</forenames></author><author><keyname>Raigorodskii</keyname><forenames>Andrei</forenames></author></authors><title>PageRank in undirected random graphs</title><categories>cs.SI cs.DM math.PR math.SP physics.soc-ph</categories><comments>WAW 2015, Nov 2015, Eindhoven, Netherlands. 2015</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PageRank has numerous applications in information retrieval, reputation
systems, machine learning, and graph partitioning .In this paper, we study
PageRank in undirected random graphs with expansion property. The Chung-Lu
random graph represents an example of such graphs. We show that in the limit,
as the size of the graph goes to infinity, PageRank can be represented by a
mixture of the restart distribution and the vertex degree distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04926</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04926</id><created>2015-11-16</created><authors><author><keyname>Giachino</keyname><forenames>Elena</forenames><affiliation>DISI, FOCUS</affiliation></author><author><keyname>Laneve</keyname><forenames>Cosimo</forenames><affiliation>DISI, FOCUS</affiliation></author><author><keyname>Lienhardt</keyname><forenames>Michael</forenames><affiliation>FOCUS, DISI</affiliation></author></authors><title>A framework for deadlock detection in core ABS</title><categories>cs.PL</categories><comments>Software and Systems Modeling, Springer Verlag, 2015</comments><proxy>ccsd</proxy><doi>10.1007/s10270-014-0444-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework for statically detecting deadlocks in a concurrent
object-oriented language with asynchronous method calls and cooperative
scheduling of method activations. Since this language features recursion and
dynamic resource creation, deadlock detection is extremely complex and
state-of-the-art solutions either give imprecise answers or do not scale. In
order to augment precision and scalability we propose a modular framework that
allows several techniques to be combined. The basic component of the framework
is a front-end inference algorithm that extracts abstract behavioural
descriptions of methods, called contracts, which retain resource dependency
information. This component is integrated with a number of possible different
back-ends that analyse contracts and derive deadlock information. As a
proof-of-concept, we discuss two such back-ends: (i) an evaluator that computes
a fixpoint semantics and (ii) an evaluator using abstract model checking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04930</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04930</id><created>2015-11-16</created><authors><author><keyname>Pratas</keyname><forenames>Nuno K.</forenames></author><author><keyname>Stefanovic</keyname><forenames>Cedomir</forenames></author><author><keyname>Madueno</keyname><forenames>German Corrales</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author></authors><title>Random Access for Machine-Type Communication based on Bloom Filtering</title><categories>cs.IT cs.NI math.IT</categories><comments>submitted to IEEE Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach for random access suited for Machine-Type
Communication (MTC) that is inspired by the Bloom filter technique. Each
accessing device sends a signature during the contention process. A signature
is constructed using Bloom filtering method and contains information on the
device identity, as well as the connection establishment cause. The system
model used to instantiate our approach is based on LTE-A access protocol. We
show that the proposed access method uses the resources, i.e., link time,
significantly more efficiently and achieves comparable or lower latency of
connection establishment in case of synchronous arrivals, compared to the LTE-A
access protocol optimized for MTC traffic according to 3GPP. A dividend of the
proposed method is that allows the base station (BS) to acquire the device
identity and the connection establishment cause already in the initial phase of
the connection establishment, thereby enabling their differentiated treatment
by the BS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04934</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04934</id><created>2015-11-16</created><authors><author><keyname>Suryani</keyname><forenames>Esti</forenames></author><author><keyname>Wiharto</keyname><forenames>Wiharto</forenames></author><author><keyname>Polvonov</keyname><forenames>Nizomjon</forenames></author></authors><title>Identification and Counting White Blood Cells and Red Blood Cells using
  Image Processing Case Study of Leukemia</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Leukemia is diagnosed with complete blood counts which is by calculating all
blood cells and compare the number of white blood cells (White Blood Cells /
WBC) and red blood cells (Red Blood Cells / RBC). Information obtained from a
complete blood count, has become a cornerstone in the hematology laboratory for
diagnostic purposes and monitoring of hematological disorders. However, the
traditional procedure for counting blood cells manually requires effort and a
long time, therefore this method is one of the most expensive routine tests in
laboratory hematology clinic. Solution for such kind of time consuming task and
necessity of data tracability can be found in image processing techniques based
on blood cell morphology . This study aims to identify Acute Lymphocytic
Leukemia (ALL) and Acute Myeloid Leukemia type M3 (AML M3) using Fuzzy Rule
Based System based on morphology of white blood cells. Characteristic
parameters witch extractedare WBC Area, Nucleus and Granule Ratio of white
blood cells. Image processing algorithms such as thresholding, Canny edge
detection and color identification filters are used.Then for identification of
ALL, AML M3 and Healthy cells used Fuzzy Rule Based System with Sugeno method.
In the testing process used 104 images out of which 29 ALL - Positive, 50 AML
M3 - Positive and 25 Healthy cells. Test results showed 83.65 % accuracy .
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04944</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04944</id><created>2015-11-16</created><authors><author><keyname>Kwon</keyname><forenames>Sunyoung</forenames></author><author><keyname>Kim</keyname><forenames>Gyuwan</forenames></author><author><keyname>Lee</keyname><forenames>Byunghan</forenames></author><author><keyname>Yoon</keyname><forenames>Sungroh</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>NASCUP: Nucleic Acid Sequence Classification by Universal Probability</title><categories>q-bio.GN cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the need for fast and accurate classification of unlabeled
nucleotide sequences on a large scale, we propose a new classification method
that captures the probabilistic structure of a sequence family as a compact
context-tree model and uses it efficiently to test proximity and membership of
a query sequence. The proposed nucleic acid sequence classification by
universal probability (NASCUP) method crucially utilizes the notion of
universal probability from information theory in model-building and
classification processes, delivering BLAST-like accuracy in orders-of-magnitude
reduced runtime for large-scale databases. A comprehensive experimental study
involving seven public databases for functional non-coding RNA classification
and microbial taxonomy classification demonstrates the advantages of NASCUP
over widely-used alternatives in efficiency, accuracy, and scalability across
all datasets considered. [availability: http://data.snu.ac.kr/nascup]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04946</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04946</id><created>2015-11-16</created><authors><author><keyname>Doslu</keyname><forenames>Metin</forenames></author><author><keyname>Bingol</keyname><forenames>Haluk O.</forenames></author></authors><title>Context Sensitive Article Ranking with Citation Context Analysis</title><categories>cs.DL cs.IR cs.SI physics.soc-ph</categories><acm-class>H.3.3; H.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is hard to detect important articles in a specific context. Information
retrieval techniques based on full text search can be inaccurate to identify
main topics and they are not able to provide an indication about the importance
of the article. Generating a citation network is a good way to find most
popular articles but this approach is not context aware.
  The text around a citation mark is generally a good summary of the referred
article. So citation context analysis presents an opportunity to use the wisdom
of crowd for detecting important articles in a context sensitive way. In this
work, we analyze citation contexts to rank articles properly for a given topic.
The model proposed uses citation contexts in order to create a directed and
weighted citation network based on the target topic. We create a directed and
weighted edge between two articles if citation context contains terms related
with the target topic. Then we apply common ranking algorithms in order to find
important articles in this newly created network. We showed that this method
successfully detects a good subset of most prominent articles in a given topic.
The biggest contribution of this approach is that we are able to identify
important articles for a given search term even though these articles do not
contain this search term. This technique can be used in other linked documents
including web pages, legal documents, and patents.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04952</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04952</id><created>2015-11-16</created><updated>2015-11-17</updated><authors><author><keyname>Adler</keyname><forenames>Isolde</forenames></author><author><keyname>Kolliopoulos</keyname><forenames>Stavros G.</forenames></author><author><keyname>Thilikos</keyname><forenames>Dimitrios M.</forenames></author></authors><title>Planar Disjoint-Paths Completion</title><categories>cs.DS math.CO</categories><msc-class>05C10</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  introduce {\sc Planar Disjoint Paths Completion}, a completion counterpart of
the Disjoint Paths problem, and study its parameterized complexity. The problem
can be stated as follows: given a, not necessarily connected, plane graph $G,$
$k$ pairs of terminals, and a face $F$ of $G,$ find a minimum-size set of
edges, if one exists, to be added inside $F$ so that the embedding remains
planar and the pairs become connected by $k$ disjoint paths in the augmented
network. Our results are twofold: first, we give an upper bound on the number
of necessary additional edges when a solution exists. This bound is a function
of $k$, independent of the size of $G.$ Second, we show that the problem is
fixed-parameter tractable, in particular, it can be solved in time $f(k)\cdot
n^{2}.$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04960</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04960</id><created>2015-11-16</created><authors><author><keyname>Najafi</keyname><forenames>Mohammad</forenames></author><author><keyname>Namin</keyname><forenames>Sarah Taghavi</forenames></author><author><keyname>Salzmann</keyname><forenames>Mathieu</forenames></author><author><keyname>Petersson</keyname><forenames>Lars</forenames></author></authors><title>Sample and Filter: Nonparametric Scene Parsing via Efficient Filtering</title><categories>cs.CV</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scene parsing has attracted a lot of attention in computer vision. While
parametric models have proven effective for this task, they cannot easily
incorporate new training data. By contrast, nonparametric approaches, which
bypass any learning phase and directly transfer the labels from the training
data to the query images, can readily exploit new labeled samples as they
become available. Unfortunately, because of the computational cost of their
label transfer procedures, state-of-the-art nonparametric methods typically
filter out most training images to only keep a few relevant ones to label the
query. As such, these methods throw away many images that still contain
valuable information and generally obtain an unbalanced set of labeled samples.
In this paper, we introduce a nonparametric approach to scene parsing that
follows a sample-and-filter strategy. More specifically, we propose to sample
labeled superpixels according to an image similarity score, which allows us to
obtain a balanced set of samples. We then formulate label transfer as an
efficient filtering procedure, which lets us exploit more labeled samples than
existing techniques. Our experiments evidence the benefits of our approach over
state-of-the-art nonparametric methods on two benchmark datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04970</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04970</id><created>2015-11-16</created><authors><author><keyname>Gon&#xe7;alves</keyname><forenames>Bruno</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>David</forenames></author></authors><title>Learning Spanish dialects through Twitter</title><categories>stat.ML cs.CL cs.CY physics.soc-ph stat.AP</categories><comments>14 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We map the large-scale variation of the Spanish language by employing a
corpus based on geographically tagged Twitter messages. Lexical dialects are
extracted from an analysis of variants of tens of concepts. The resulting maps
show linguistic variations on an unprecedented scale across the globe. We
discuss the properties of the main dialects within a machine learning approach
and find that varieties spoken in urban areas have an international character
in contrast to country areas where dialects show a more regional uniformity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04985</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04985</id><created>2015-11-16</created><authors><author><keyname>Dang</keyname><forenames>Huynh Tu</forenames></author><author><keyname>Canini</keyname><forenames>Marco</forenames></author><author><keyname>Pedone</keyname><forenames>Fernando</forenames></author><author><keyname>Soul&#xe9;</keyname><forenames>Robert</forenames></author></authors><title>Paxos Made Switch-y</title><categories>cs.DC cs.NI</categories><report-no>USI-INF-TR-2015-05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes an implementation of the well-known consensus protocol,
Paxos, in the P4 programming language. P4 is a language for programming the
behavior of network forwarding devices (i.e., the network data plane). Moving
consensus logic into network devices could significantly improve the
performance of the core infrastructure and services in data centers. Moreover,
implementing Paxos in P4 provides a critical use case and set of requirements
for data plane language designers. In the long term, we imagine that consensus
could someday be offered as a network service, just as point-to-point
communication is provided today.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04986</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04986</id><created>2015-11-16</created><authors><author><keyname>Serr&#xe0;</keyname><forenames>Joan</forenames></author><author><keyname>Matic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Arcos</keyname><forenames>Josep Luis</forenames></author><author><keyname>Karatzoglou</keyname><forenames>Alexandros</forenames></author></authors><title>A genetic algorithm to discover flexible motifs with support</title><categories>cs.LG cs.NE</categories><comments>19 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding repeated patterns or motifs in a time series is an important
unsupervised task that has still a number of open issues, starting by the
definition of motif. In this paper, we revise the notion of motif support,
characterizing it as the number of patterns or repetitions that define a motif.
We then propose GENMOTIF, a genetic algorithm to discover motifs with support
which, at the same time, is flexible enough to accommodate other motif
specifications and task characteristics. GENMOTIF is an anytime algorithm that
easily adapts to many situations: searching in a range of segment lengths,
applying uniform scaling, dealing with multiple dimensions, using different
similarity and grouping criteria, etc. GENMOTIF is also parameter-friendly: it
has only two intuitive parameters which, if set within reasonable bounds, do
not substantially affect its performance. We demonstrate the value of our
approach in a number of synthetic and real-world settings, including traffic
volume measurements and accelerometer signals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.04996</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.04996</id><created>2015-11-16</created><authors><author><keyname>Bayhan</keyname><forenames>Suzan</forenames></author><author><keyname>Hyyti&#xe4;</keyname><forenames>Esa</forenames></author><author><keyname>Kangasharju</keyname><forenames>Jussi</forenames></author><author><keyname>Ott</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>Two Hops or More: On Hop-Limited Search in Opportunistic Networks</title><categories>cs.NI</categories><comments>11 pages</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  While there is a drastic shift from host-centric networking to
content-centric networking, how to locate and retrieve the relevant content
efficiently, especially in a mobile network, is still an open question. Mobile
devices host increasing volume of data which could be shared with the nearby
nodes in a multi-hop fashion. However, searching for content in this
resource-restricted setting is not trivial due to the lack of a content index,
as well as, desire for keeping the search cost low. In this paper, we analyze a
lightweight search scheme, hop-limited search, that forwards the search
messages only till a maximum number of hops, and requires no prior knowledge
about the network. We highlight the effect of the hop limit on both search
performance (i.e., success ratio and delay) and associated cost along with the
interplay between content availability, tolerated waiting time, network
density, and mobility. Our analysis, using the real mobility traces, as well as
synthetic models, shows that the most substantial benefit is achieved at the
first few hops and that after several hops the extra gain diminishes as a
function of content availability and tolerated delay. We also observe that the
return path taken by a response is on average longer than the forward path of
the query and that the search cost increases only marginally after several hops
due to the small network diameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05006</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05006</id><created>2015-11-16</created><authors><author><keyname>Epstein</keyname><forenames>Samuel</forenames></author></authors><title>On Quantum Noncompression</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a quantum transmission problem, in which Alice is
trying to send a number of qbits to Bob. Alice has access to two channels, one
that sends classical bits and another that sends quantum bits. We show that
under certain error terms, Alice can optimize transmission, up to logarithmic
precision, by sending only a classical description of the qbits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05009</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05009</id><created>2015-11-16</created><authors><author><keyname>Johnson</keyname><forenames>Matthew</forenames></author><author><keyname>Paulusma</keyname><forenames>Daniel</forenames></author><author><keyname>van Leeuwen</keyname><forenames>Erik Jan</forenames></author></authors><title>What Graphs are 2-Dot Product Graphs?</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $d \geq 1$ be an integer. From a set of $d$-dimensional vectors, we
obtain a $d$-dot product graph by letting each vector ${\bf a}^u$ correspond to
a vertex $u$ and by adding an edge between two vertices $u$ and $v$ if and only
if their dot product ${\bf a}^{u} \cdot {\bf a}^{v} \geq t$, for some fixed,
positive threshold~$t$. Dot product graphs can be used to model social
networks. Recognizing a $d$-dot product graph is known to be \NP-hard for all
fixed $d\geq 2$. To understand the position of $d$-dot product graphs in the
landscape of graph classes, we consider the case $d=2$, and investigate how
$2$-dot product graphs relate to a number of other known graph classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05010</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05010</id><created>2015-11-16</created><authors><author><keyname>Zawirski</keyname><forenames>Marek</forenames></author><author><keyname>Baquero</keyname><forenames>Carlos</forenames></author><author><keyname>Bieniusa</keyname><forenames>Annette</forenames></author><author><keyname>Pregui&#xe7;a</keyname><forenames>Nuno</forenames></author><author><keyname>Shapiro</keyname><forenames>Marc</forenames></author></authors><title>Eventually Consistent Register Revisited</title><categories>cs.DC cs.DB cs.DS</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to converge in the presence of concurrent updates, modern eventually
consistent replication systems rely on causality information and operation
semantics. It is relatively easy to use semantics of high-level operations on
replicated data structures, such as sets, lists, etc. However, it is difficult
to exploit semantics of operations on registers, which store opaque data. In
existing register designs, concurrent writes are resolved either by the
application, or by arbitrating them according to their timestamps. The former
is complex and may require user intervention, whereas the latter causes
arbitrary updates to be lost. In this work, we identify a register construction
that generalizes existing ones by combining runtime causality ordering, to
identify concurrent writes, with static data semantics, to resolve them. We
propose a simple conflict resolution template based on an
application-predefined order on the domain of values. It eliminates or reduces
the number of conflicts that need to be resolved by the user or by an explicit
application logic. We illustrate some variants of our approach with use cases,
and how it generalizes existing designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05012</identifier>
 <datestamp>2016-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05012</id><created>2015-11-16</created><authors><author><keyname>Calabuig</keyname><forenames>Daniel</forenames></author><author><keyname>Gohary</keyname><forenames>Ramy H.</forenames></author><author><keyname>Yanikomeroglu</keyname><forenames>Halim</forenames></author></authors><title>Optimum Transmission Through the Multiple-Antenna Gaussian Multiple
  Access Channel</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Information Theory, 2015</comments><journal-ref>IEEE Transactions on Information Theory, vol. 62, no. 1, pp.
  230-243, Jan. 2016</journal-ref><doi>10.1109/TIT.2015.2502244</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the optimal points in the capacity region of Gaussian
multiple access channels (GMACs) with constant fading, multiple antennas and
various power constraints. The points of interest maximize general rate
objectives that arise in practical communication scenarios. Achieving these
points constitutes the task of jointly optimizing the time-sharing parameters,
the input covariance matrices and the order of decoding used by the successive
interference cancellation receiver. To approach this problem, Carath\'eodory's
theorem is invoked to represent time-sharing and decoding orders jointly as a
finite-dimensional matrix variable. This variable enables us to use variational
inequalities to extend results pertaining to problems with linear rate
objectives to more general, potentially nonconvex, problems, and to obtain a
necessary and sufficient condition for the optimality of the transmission
parameters in a wide range of problems. Using the insights gained from this
condition, we develop and analyze the convergence of an algorithm for solving,
otherwise daunting, GMAC-based optimization problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05023</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05023</id><created>2015-11-04</created><updated>2015-12-02</updated><authors><author><keyname>Mercer</keyname><forenames>Idris</forenames></author></authors><title>Improved bounds on the peak sidelobe level of binary sequences</title><categories>math.CO cs.IT math.IT math.PR</categories><comments>Added Corollary 4 and its proof</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Schmidt proved in 2014 that if $\varepsilon&gt;0$, almost all binary sequences
of length $n$ have peak sidelobe level between
$(\sqrt{2}-\varepsilon)\sqrt{n\log n}$ and $(\sqrt{2}+\varepsilon)\sqrt{n\log
n}$. Because of the small gap between his upper and lower bounds, it is
difficult to find improved upper bounds that hold for almost all binary
sequences. In this note, we prove that if $\varepsilon&gt;0$, then almost all
binary sequences of length $n$ have peak sidelobe level at most $\sqrt{2n(\log
n-(1-\varepsilon)\log\log n)}$, and we provide a slightly better upper bound
that holds for a positive proportion of binary sequences of length $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05027</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05027</id><created>2015-11-16</created><authors><author><keyname>Moser</keyname><forenames>Philippe</forenames></author><author><keyname>Stephan</keyname><forenames>Frank</forenames></author></authors><title>Depth, Highness and DNR degrees</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study Bennett deep sequences in the context of recursion theory; in
particular we investigate the notions of O(1)-deepK, O(1)-deepC , order-deep K
and order-deep C sequences. Our main results are that Martin-Loef random sets
are not order-deepC , that every many-one degree contains a set which is not
O(1)-deepC , that O(1)-deepC sets and order-deepK sets have high or DNR Turing
degree and that no K-trival set is O(1)-deepK.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05042</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05042</id><created>2015-11-16</created><updated>2016-02-28</updated><authors><author><keyname>de Br&#xe9;bisson</keyname><forenames>Alexandre</forenames></author><author><keyname>Vincent</keyname><forenames>Pascal</forenames></author></authors><title>An Exploration of Softmax Alternatives Belonging to the Spherical Loss
  Family</title><categories>cs.NE cs.LG stat.ML</categories><comments>Published at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a multi-class classification problem, it is standard to model the output
of a neural network as a categorical distribution conditioned on the inputs.
The output must therefore be positive and sum to one, which is traditionally
enforced by a softmax. This probabilistic mapping allows to use the maximum
likelihood principle, which leads to the well-known log-softmax loss. However
the choice of the softmax function seems somehow arbitrary as there are many
other possible normalizing functions. It is thus unclear why the log-softmax
loss would perform better than other loss alternatives. In particular Vincent
et al. (2015) recently introduced a class of loss functions, called the
spherical family, for which there exists an efficient algorithm to compute the
updates of the output weights irrespective of the output size. In this paper,
we explore several loss functions from this family as possible alternatives to
the traditional log-softmax. In particular, we focus our investigation on
spherical bounds of the log-softmax loss and on two spherical log-likelihood
losses, namely the log-Spherical Softmax suggested by Vincent et al. (2015) and
the log-Taylor Softmax that we introduce. Although these alternatives do not
yield as good results as the log-softmax loss on two language modeling tasks,
they surprisingly outperform it in our experiments on MNIST and CIFAR-10,
suggesting that they might be relevant in a broad range of applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05045</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05045</id><created>2015-11-16</created><updated>2015-11-19</updated><authors><author><keyname>Lan</keyname><forenames>Zhenzhong</forenames></author><author><keyname>Yu</keyname><forenames>Shoou-I</forenames></author><author><keyname>Lin</keyname><forenames>Ming</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author><author><keyname>Hauptmann</keyname><forenames>Alexander G.</forenames></author></authors><title>Handcrafted Local Features are Convolutional Neural Networks</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image and video classification research has made great progress through the
development of handcrafted local features and learning based features. These
two architectures were proposed roughly at the same time and have flourished at
overlapping stages of history. However, they are typically viewed as distinct
approaches. In this paper, we emphasize their structural similarities and show
how such a unified view helps us in designing features that balance efficiency
and effectiveness. As an example, we study the problem of designing efficient
video feature learning algorithms for action recognition.
  We approach this problem by first showing that local handcrafted features and
Convolutional Neural Networks (CNNs) share the same convolution-pooling network
structure. We then propose a two-stream Convolutional ISA (ConvISA) that adopts
the convolution-pooling structure of the state-of-the-art handcrafted video
feature with greater modeling capacities and a cost-effective training
algorithm. Through custom designed network structures for pixels and optical
flow, our method also reflects distinctive characteristics of these two data
sources.
  Our experimental results on standard action recognition benchmarks show that
by focusing on the structure of CNNs, rather than end-to-end training methods,
we are able to design an efficient and powerful video feature learning
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05049</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05049</id><created>2015-11-16</created><authors><author><keyname>Yang</keyname><forenames>Heng</forenames></author><author><keyname>Jia</keyname><forenames>Xuhui</forenames></author><author><keyname>Loy</keyname><forenames>Chen Change</forenames></author><author><keyname>Robinson</keyname><forenames>Peter</forenames></author></authors><title>An Empirical Study of Recent Face Alignment Methods</title><categories>cs.CV</categories><comments>under review of a conference. Project page:
  https://www.cl.cam.ac.uk/~hy306/FaceAlignment.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of face alignment has been intensively studied in the past years.
A large number of novel methods have been proposed and reported very good
performance on benchmark dataset such as 300W. However, the differences in the
experimental setting and evaluation metric, missing details in the description
of the methods make it hard to reproduce the results reported and evaluate the
relative merits. For instance, most recent face alignment methods are built on
top of face detection but from different face detectors. In this paper, we
carry out a rigorous evaluation of these methods by making the following
contributions: 1) we proposes a new evaluation metric for face alignment on a
set of images, i.e., area under error distribution curve within a threshold,
AUC$_\alpha$, given the fact that the traditional evaluation measure (mean
error) is very sensitive to big alignment error. 2) we extend the 300W database
with more practical face detections to make fair comparison possible. 3) we
carry out face alignment sensitivity analysis w.r.t. face detection, on both
synthetic and real data, using both off-the-shelf and re-retrained models. 4)
we study factors that are particularly important to achieve good performance
and provide suggestions for practical applications. Most of the conclusions
drawn from our comparative analysis cannot be inferred from the original
publications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05053</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05053</id><created>2015-11-16</created><authors><author><keyname>Belovs</keyname><forenames>Aleksandrs</forenames></author><author><keyname>Blais</keyname><forenames>Eric</forenames></author></authors><title>A Polynomial Lower Bound for Testing Monotonicity</title><categories>cs.CC cs.DM cs.DS</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that every algorithm for testing $n$-variate Boolean functions for
monotonicity must have query complexity $\tilde{\Omega}(n^{1/4})$. All previous
lower bounds for this problem were designed for non-adaptive algorithms and, as
a result, the best previous lower bound for general (possibly adaptive)
monotonicity testers was only $\Omega(\log n)$. Combined with the query
complexity of the non-adaptive monotonicity tester of Khot, Minzer, and Safra
(FOCS 2015), our lower bound shows that adaptivity can result in at most a
quadratic reduction in the query complexity for testing monotonicity.
  By contrast, we show that there is an exponential gap between the query
complexity of adaptive and non-adaptive algorithms for testing regular linear
threshold functions (LTFs) for monotonicity. Chen, De, Servedio, and Tan (STOC
2015) recently showed that non-adaptive algorithms require almost
$\Omega(n^{1/2})$ queries for this task. We introduce a new adaptive
monotonicity testing algorithm which has query complexity $O(\log n)$ when the
input is a regular LTF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05060</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05060</id><created>2015-11-16</created><authors><author><keyname>Sahin</keyname><forenames>Sureyya</forenames></author></authors><title>Solving the Forward Position Problem of an In-Parallel Planar
  Manipulator in the Gauss Plane</title><categories>cs.RO cs.SC</categories><comments>11 pages, 4 figures</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We study determining the posture of an in-parallel planar manipulator, which
has three connectors composed of revolute, prismatic and revolute joints, from
specified active joint variables. We construct an ideal in the field of complex
numbers, and we introduce self inversive polynomials. We provide results for an
in-parallel planar manipulator, which has a base and moving platform in right
triangular shape. Using Sage computer algebra system, we compute its Groebner
bases. We illustrate that the single variable polynomials obtained from the
Groebner bases are self reciprocal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05065</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05065</id><created>2015-11-16</created><updated>2016-03-04</updated><authors><author><keyname>Ham</keyname><forenames>Bumsub</forenames></author><author><keyname>Cho</keyname><forenames>Minsu</forenames></author><author><keyname>Schmid</keyname><forenames>Cordelia</forenames></author><author><keyname>Ponce</keyname><forenames>Jean</forenames></author></authors><title>Proposal Flow</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding image correspondences remains a challenging problem in the presence
of intra-class variations and large changes in scene layout, typical in scene
flow computation. We introduce a novel approach to this problem, dubbed
proposal flow, that establishes reliable correspondences using object
proposals. Unlike prevailing scene flow approaches that operate on pixels or
regularly sampled local regions, proposal flow benefits from the
characteristics of modern object proposals, that exhibit high repeatability at
multiple scales, and can take advantage of both local and geometric consistency
constraints among proposals. We also show that proposal flow can effectively be
transformed into a conventional dense flow field. We introduce a new dataset
that can be used to evaluate both general scene flow techniques and
region-based approaches such as proposal flow. We use this benchmark to compare
different matching algorithms, object proposals, and region features within
proposal flow with the state of the art in scene flow. This comparison, along
with experiments on standard datasets, demonstrates that proposal flow
significantly outperforms existing scene flow methods in various settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05067</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05067</id><created>2015-11-16</created><updated>2015-11-19</updated><authors><author><keyname>Kirillov</keyname><forenames>Alexander</forenames></author><author><keyname>Schlesinger</keyname><forenames>Dmitrij</forenames></author><author><keyname>Forkel</keyname><forenames>Walter</forenames></author><author><keyname>Zelenin</keyname><forenames>Anatoly</forenames></author><author><keyname>Zheng</keyname><forenames>Shuai</forenames></author><author><keyname>Torr</keyname><forenames>Philip</forenames></author><author><keyname>Rother</keyname><forenames>Carsten</forenames></author></authors><title>Efficient Likelihood Learning of a Generic CNN-CRF Model for Semantic
  Segmentation</title><categories>cs.CV</categories><comments>ICLR 2016 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Models, such as Convolutional Neural Networks (CNNs), are omnipresent in
computer vision, as well as, structured models, such as Conditional Random
Fields (CRFs). Combining them brings many advantages, foremost the ability to
in-cooperate prior knowledge into CNNs, e.g. by explicitly modelling the
dependencies between output variables. In this work we present a CRF model were
unary factors are dependent on a CNN. Our main contribution is an efficient and
scalable, maximum likelihood-based, learning procedure to infer all model
parameters jointly. Previous work either concentrated on piecewise-training, or
maximum likelihood learning of restricted model families, such as Gaussian CRFs
or CRFs with a few variables only. In contrast, we are the first to perform
maximum likelihood learning for large-sized factor graphs with non-parametric
potentials. We have applied our model to the task of semantic labeling of body
parts in depth images. We show that it is superior to selected competing models
and learning strategies. Furthermore, we empirically observe that our model can
capture shape and context information of relating body parts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05070</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05070</id><created>2015-11-16</created><authors><author><keyname>Izadi</keyname><forenames>Mohammad</forenames></author><author><keyname>Masoudian</keyname><forenames>Saeed</forenames></author><author><keyname>Mozaffari</keyname><forenames>Sahand</forenames></author></authors><title>Joining Transition Systems of Records: Some Congruency and
  Language-Theoretic Results</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  B\&quot;uchi automaton of records (BAR) has been proposed as a basic operational
semantics for Reo coordination language. It is an extension of B\&quot;uchi
automaton by using a set of records as its alphabet or transition labels.
Records are used to express the synchrony between the externally visible
actions of coordinated components modeled by BARs. The main composition
operator on the set of BARs is called as join which is the semantics of its
counterpart in Reo. In this paper, we define the notion of labeled transition
systems of records as a generalization of the notion of BAR, abstracting away
from acceptance or rejection of strings. Then, we consider four equivalence
relations (semantics) over the set of labeled transition systems of records and
investigate their congruency with respect to the join composition operator. In
fact, we prove that the finite-traces-based, infinite-traces-based, and
nondeterministic finite automata (NFA)-based equivalence relations all are
congruence relations over the set of all labeled transition systems of records
with respect to the join operation. However, the equivalence relation using
B\&quot;uchi acceptance condition is not so. In addition, using these results, we
introduce the language-theoretic definitions of the join operation considering
both finite and infinite strings notions. Also, we show that there is no
language-based and structure-independent definition of the join operation on
B\&quot;uchi automata of records.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05073</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05073</id><created>2015-11-16</created><authors><author><keyname>Tabassum</keyname><forenames>Hina</forenames></author><author><keyname>Sakr</keyname><forenames>Ahmed Hamdi</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author></authors><title>Analysis of Massive MIMO-Enabled Downlink Wireless Backhauling for
  Full-Duplex Small Cells</title><categories>cs.IT math.IT</categories><comments>15 pages, 7 figures, IEEE Transactions on Communications (under
  review)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using tools from stochastic geometry, we develop a framework to model the
downlink rate coverage probability of a user in a given small cell network
(SCN) with massive MIMO-enabled wireless backhauls. The considered SCN is
composed of a mixture of small cells that are configured in either in-band or
out-of-band backhaul modes with a certain probability. The performance of the
user in the considered hierarchical network is limited by several sources of
interference such as the backhaul interference, small cell base station
(SBS)-to-SBS interference and the SI. Moreover, due to the channel hardening
effect in massive MIMO, the backhaul links experience long term channel effects
only, whereas the access links experience both the long term and short term
channel effects. Consequently, the developed framework is flexible to
characterize different sources of interference while capturing the
heterogeneity of the access and backhaul channels. In specific scenarios, the
framework enables deriving closed-form coverage probability expressions. Under
perfect backhaul coverage, the simplified expressions are utilized to optimize
the proportion of in-band and out-of-band small cells in the SCN in
closed-form. Finally, few remedial solutions are proposed that can potentially
mitigate the backhaul interference and in turn improve the performance of
in-band FD wireless backhauling. Numerical results investigate the scenarios in
which in-band wireless backhauling is useful and demonstrate that maintaining a
correct proportion of in-band and out-of-band FD small cells is crucial in
wireless backhauled SCNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05076</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05076</id><created>2015-11-16</created><authors><author><keyname>Doulaty</keyname><forenames>Mortaza</forenames></author><author><keyname>Saz</keyname><forenames>Oscar</forenames></author><author><keyname>Ng</keyname><forenames>Raymond W. M.</forenames></author><author><keyname>Hain</keyname><forenames>Thomas</forenames></author></authors><title>Latent Dirichlet Allocation Based Organisation of Broadcast Media
  Archives for Deep Neural Network Adaptation</title><categories>cs.CL</categories><comments>IEEE Automatic Speech Recognition and Understanding Workshop (ASRU
  2015), 13-17 Dec 2015, Scottsdale, Arizona, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method for the discovery of latent domains in
diverse speech data, for the use of adaptation of Deep Neural Networks (DNNs)
for Automatic Speech Recognition. Our work focuses on transcription of
multi-genre broadcast media, which is often only categorised broadly in terms
of high level genres such as sports, news, documentary, etc. However, in terms
of acoustic modelling these categories are coarse. Instead, it is expected that
a mixture of latent domains can better represent the complex and diverse
behaviours within a TV show, and therefore lead to better and more robust
performance. We propose a new method, whereby these latent domains are
discovered with Latent Dirichlet Allocation, in an unsupervised manner. These
are used to adapt DNNs using the Unique Binary Code (UBIC) representation for
the LDA domains. Experiments conducted on a set of BBC TV broadcasts, with more
than 2,000 shows for training and 47 shows for testing, show that the use of
LDA-UBIC DNNs reduces the error up to 13% relative compared to the baseline
hybrid DNN models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05077</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05077</id><created>2015-11-16</created><updated>2016-02-03</updated><authors><author><keyname>Mariet</keyname><forenames>Zelda</forenames></author><author><keyname>Sra</keyname><forenames>Suvrit</forenames></author></authors><title>Diversity Networks</title><categories>cs.LG cs.NE</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  We introduce Divnet, a flexible technique for learning networks with diverse
neurons. Divnet models neuronal diversity by placing a Determinantal Point
Process (DPP) over neurons in a given layer. It uses this DPP to select a
subset of diverse neurons and subsequently fuses the redundant neurons into the
selected ones. Compared with previous approaches, Divnet offers a more
principled, flexible technique for capturing neuronal diversity and thus
implicitly enforcing regularization. This enables effective auto-tuning of
network architecture and leads to smaller network sizes without hurting
performance. Moreover, through its focus on diversity and neuron fusing, Divnet
remains compatible with other procedures that seek to reduce memory footprints
of networks. We present experimental results to corroborate our claims: for
pruning neural networks, Divnet is seen to be notably superior to competing
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05078</identifier>
 <datestamp>2016-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05078</id><created>2015-11-16</created><updated>2016-02-17</updated><authors><author><keyname>Klavans</keyname><forenames>Richard</forenames></author><author><keyname>Boyack</keyname><forenames>Kevin W.</forenames></author></authors><title>Which type of citation analysis generates the most accurate taxonomy of
  scientific and technical knowledge?</title><categories>cs.DL</categories><comments>26 pages, 4 figures, 7 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1965, Derek de Solla Price foresaw the day when a citation-based taxonomy
of science and technology would be delineated and correspondingly used for
science policy. A taxonomy needs to be comprehensive and accurate if it is to
be useful for policy making, especially now that policy makers are utilizing
citation-based indicators to evaluate people, institutions and laboratories.
Determining the accuracy of a taxonomy, however, remains a challenge. Previous
work on the accuracy of partition solutions is sparse, and the results of those
studies, while useful, have not been definitive. In this study we compare the
accuracies of topic-level taxonomies based on the clustering of documents using
direct citation, bibliographic coupling, and co-citation. Using a set of new
gold standards - articles with at least 100 references - we find that direct
citation is better at concentrating references than either bibliographic
coupling or co-citation. Using the assumption that higher concentrations of
references denote more accurate clusters, direct citation thus provides a more
accurate representation of the taxonomy of scientific and technical knowledge
than either bibliographic coupling or co-citation. We also find that
discipline-level taxonomies based on journal schema are highly inaccurate
compared to topic-level taxonomies, and recommend against their use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05081</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05081</id><created>2015-11-16</created><authors><author><keyname>Coogan</keyname><forenames>Samuel</forenames></author><author><keyname>Arcak</keyname><forenames>Murat</forenames></author><author><keyname>Kurzhanskiy</keyname><forenames>Alexander A.</forenames></author></authors><title>On the Mixed Monotonicity of FIFO Traffic Flow Models</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At diverging junctions in vehicular traffic networks, congestion on one
outgoing link may impede traffic flow to other outgoing links. This phenomenon
is referred to as the first-in-first-out (FIFO) property. Traffic network
models that do not include the FIFO property result in monotone dynamics for
which powerful analysis techniques exist. This note shows that a large class of
FIFO network models are nonetheless mixed monotone. Mixed monotone systems
significantly generalize the class of monotone systems and enable similarly
powerful analysis techniques. The studied class of models includes the case
when the FIFO property is only partial, that is, traffic flow through diverging
junctions exhibit both FIFO and non-FIFO phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05082</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05082</id><created>2015-11-16</created><authors><author><keyname>Resheff</keyname><forenames>Yehezkel S.</forenames></author><author><keyname>Rotics</keyname><forenames>Shay</forenames></author><author><keyname>Nathan</keyname><forenames>Ran</forenames></author><author><keyname>Weinshall</keyname><forenames>Daphna</forenames></author></authors><title>Topic Modeling of Behavioral Modes Using Sensor Data</title><categories>cs.LG</categories><comments>Invited Extended version of a paper \cite{resheffmatrix} presented at
  the international conference \textit{Data Science and Advanced Analytics},
  Paris, France, 19-21 OCtober 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The field of Movement Ecology, like so many other fields, is experiencing a
period of rapid growth in availability of data. As the volume rises,
traditional methods are giving way to machine learning and data science, which
are playing an increasingly large part it turning this data into
science-driving insights. One rich and interesting source is the bio-logger.
These small electronic wearable devices are attached to animals free to roam in
their natural habitats, and report back readings from multiple sensors,
including GPS and accelerometer bursts. A common use of accelerometer data is
for supervised learning of behavioral modes. However, we need unsupervised
analysis tools as well, in order to overcome the inherent difficulties of
obtaining a labeled dataset, which in some cases is either infeasible or does
not successfully encompass the full repertoire of behavioral modes of interest.
Here we present a matrix factorization based topic-model method for
accelerometer bursts, derived using a linear mixture property of patch
features. Our method is validated via comparison to a labeled dataset, and is
further compared to standard clustering algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05084</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05084</id><created>2015-11-16</created><updated>2015-11-17</updated><authors><author><keyname>Rafegas</keyname><forenames>Ivet</forenames></author><author><keyname>Vanrell</keyname><forenames>Maria</forenames></author></authors><title>Understanding learned CNN features through Filter Decoding with
  Substitution</title><categories>cs.CV</categories><comments>10 pages, 7 figures (including supplementary material). Submitted for
  review for CVPR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In parallel with the success of CNNs to solve vision problems, there is a
growing interest in developing methodologies to understand and visualize the
internal representations of these networks. How the responses of a trained CNN
encode the visual information is a fundamental question both for computer and
human vision research. Image representations provided by the first
convolutional layer as well as the resolution change provided by the
max-polling operation are easy to understand, however, as soon as a second and
further convolutional layers are added in the representation, any intuition is
lost. A usual way to deal with this problem has been to define deconvolutional
networks that somehow allow to explore the internal representations of the most
important activations towards the image space, where deconvolution is assumed
as a convolution with the transposed filter. However, this assumption is not
the best approximation of an inverse convolution. In this paper we propose a
new assumption based on filter substitution to reverse the encoding of a
convolutional layer. This provides us with a new tool to directly visualize any
CNN single neuron as a filter in the first layer, this is in terms of the image
space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05099</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05099</id><created>2015-11-16</created><updated>2016-01-31</updated><authors><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Goyal</keyname><forenames>Yash</forenames></author><author><keyname>Summers-Stay</keyname><forenames>Douglas</forenames></author><author><keyname>Batra</keyname><forenames>Dhruv</forenames></author><author><keyname>Parikh</keyname><forenames>Devi</forenames></author></authors><title>Yin and Yang: Balancing and Answering Binary Visual Questions</title><categories>cs.CL cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complex compositional structure of language makes problems at the
intersection of vision and language challenging. But language also provides a
strong prior that can result in good superficial performance, without the
underlying models truly understanding the visual content. This can hinder
progress in pushing state of art in the computer vision aspects of multi-modal
AI. In this paper, we address binary Visual Question Answering (VQA) on
abstract scenes. We formulate this problem as visual verification of concepts
inquired in the questions. Specifically, we convert the question to a tuple
that concisely summarizes the visual concept to be detected in the image. If
the concept can be found in the image, the answer to the question is yes, and
otherwise no. Abstract scenes play two roles (1) They allow us to focus on the
high-level semantics of the VQA task as opposed to the low-level recognition
problems, and perhaps more importantly, (2) They provide us the modality to
balance the dataset such that language priors are controlled, and the role of
vision is essential. In particular, we collect pairs of scenes for every
question, such that the answer to the question is &quot;yes&quot; for one scene, and &quot;no&quot;
for the other for the exact same question. Indeed, language priors alone do not
perform better than chance on our balanced dataset. Moreover, our proposed
approach outperforms a state-of-the-art VQA system on both balanced and
unbalanced datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05101</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05101</id><created>2015-11-16</created><authors><author><keyname>Husz&#xe1;r</keyname><forenames>Ferenc</forenames></author></authors><title>How (not) to Train your Generative Model: Scheduled Sampling,
  Likelihood, Adversary?</title><categories>stat.ML cs.AI cs.IT cs.LG math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern applications and progress in deep learning research have created
renewed interest for generative models of text and of images. However, even
today it is unclear what objective functions one should use to train and
evaluate these models. In this paper we present two contributions.
  Firstly, we present a critique of scheduled sampling, a state-of-the-art
training method that contributed to the winning entry to the MSCOCO image
captioning benchmark in 2015. Here we show that despite this impressive
empirical performance, the objective function underlying scheduled sampling is
improper and leads to an inconsistent learning algorithm.
  Secondly, we revisit the problems that scheduled sampling was meant to
address, and present an alternative interpretation. We argue that maximum
likelihood is an inappropriate training objective when the end-goal is to
generate natural-looking samples. We go on to derive an ideal objective
function to use in this situation instead. We introduce a generalisation of
adversarial training, and show how such method can interpolate between maximum
likelihood training and our ideal training objective. To our knowledge this is
the first theoretical analysis that explains why adversarial training tends to
produce samples with higher perceived quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05102</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05102</id><created>2015-11-16</created><authors><author><keyname>Reeves</keyname><forenames>Denise M.</forenames></author></authors><title>Resolving the Geometric Locus Dilemma for Support Vector Learning
  Machines</title><categories>cs.LG stat.ML</categories><comments>170 pages, 33 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Capacity control, the bias/variance dilemma, and learning unknown functions
from data, are all concerned with identifying effective and consistent fits of
unknown geometric loci to random data points. A geometric locus is a curve or
surface formed by points, all of which possess some uniform property. A
geometric locus of an algebraic equation is the set of points whose coordinates
are solutions of the equation. Any given curve or surface must pass through
each point on a specified locus. This paper argues that it is impossible to fit
random data points to algebraic equations of partially configured geometric
loci that reference arbitrary Cartesian coordinate systems. It also argues that
the fundamental curve of a linear decision boundary is actually a principal
eigenaxis. It is shown that learning principal eigenaxes of linear decision
boundaries involves finding a point of statistical equilibrium for which
eigenenergies of principal eigenaxis components are symmetrically balanced with
each other. It is demonstrated that learning linear decision boundaries
involves strong duality relationships between a statistical eigenlocus of
principal eigenaxis components and its algebraic forms, in primal and dual,
correlated Hilbert spaces. Locus equations are introduced and developed that
describe principal eigen-coordinate systems for lines, planes, and hyperplanes.
These equations are used to introduce and develop primal and dual statistical
eigenlocus equations of principal eigenaxes of linear decision boundaries.
Important generalizations for linear decision boundaries are shown to be
encoded within a dual statistical eigenlocus of principal eigenaxis components.
Principal eigenaxes of linear decision boundaries are shown to encode Bayes'
likelihood ratio for common covariance data and a robust likelihood ratio for
all other data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05104</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05104</id><created>2015-11-16</created><authors><author><keyname>Giachino</keyname><forenames>Elena</forenames><affiliation>DISI, FOCUS</affiliation></author><author><keyname>Johnsen</keyname><forenames>Einar Broch</forenames><affiliation>DISI, FOCUS</affiliation></author><author><keyname>Laneve</keyname><forenames>Cosimo</forenames><affiliation>DISI, FOCUS</affiliation></author><author><keyname>Pun</keyname><forenames>Ka I</forenames></author></authors><title>Time complexity of concurrent programs</title><categories>cs.PL</categories><comments>FACS 2015, Oct 2015, Niter\'oi, Rio de Janeiro, Brazil</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of automatically computing the time complexity of
concurrent object-oriented programs. To determine this complexity we use
intermediate abstract descriptions that record relevant information for the
time analysis (cost of statements, creations of objects, and concurrent
operations), called behavioural types. Then, we define a translation function
that takes behavioural types and makes the parallelism explicit into so-called
cost equations, which are fed to an automatic off-the-shelf solver for
obtaining the time complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05109</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05109</id><created>2015-11-16</created><authors><author><keyname>Dragan</keyname><forenames>Feodor F.</forenames></author><author><keyname>Leitert</keyname><forenames>Arne</forenames></author></authors><title>Minimum Eccentricity Shortest Paths in some Structured Graph Classes</title><categories>cs.DM</categories><comments>Results of this paper were partially presented at WG 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the Minimum Eccentricity Shortest Path problem in some
structured graph classes. It asks for a given graph to find a shortest path
with minimum eccentricity. Although it is NP-hard in general graphs, we
demonstrate that a minimum eccentricity shortest path can be found in linear
time for distance-hereditary graphs (generalizing the previous result for
trees) and give a generalised approach which allows to solve the problem in
polynomial time for other graph classes. This includes chordal graphs, dually
chordal graphs, graphs with bounded tree-length, and graphs with bounded
hyperbolicity. Additionally, we give a simple algorithm to compute an additive
approximation for graphs with bounded tree-length and graphs with bounded
hyperbolicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05118</identifier>
 <datestamp>2015-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05118</id><created>2015-11-16</created><authors><author><keyname>Puy</keyname><forenames>Gilles</forenames></author><author><keyname>Tremblay</keyname><forenames>Nicolas</forenames></author><author><keyname>Gribonval</keyname><forenames>R&#xe9;mi</forenames></author><author><keyname>Vandergheynst</keyname><forenames>Pierre</forenames></author></authors><title>Random sampling of bandlimited signals on graphs</title><categories>cs.SI cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of sampling k-bandlimited signals on graphs. We propose
two sampling strategies that consist in selecting a small subset of nodes at
random. The first strategy is non-adaptive, i.e., independent of the graph
structure, and its performance depends on a parameter called the graph
coherence. On the contrary, the second strategy is adaptive but yields optimal
results. Indeed, no more than O(k log(k)) measurements are sufficient to ensure
an accurate and stable recovery of all k-bandlimited signals. This second
strategy is based on a careful choice of the sampling distribution, which can
be estimated quickly. Then, we propose a computationally efficient decoder to
reconstruct k-bandlimited signals from their samples. We prove that it yields
accurate reconstructions and that it is also stable to noise. Finally, we
conduct several experiments to test these techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05121</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05121</id><created>2015-11-16</created><updated>2015-11-25</updated><authors><author><keyname>Krishnan</keyname><forenames>Rahul G.</forenames></author><author><keyname>Shalit</keyname><forenames>Uri</forenames></author><author><keyname>Sontag</keyname><forenames>David</forenames></author></authors><title>Deep Kalman Filters</title><categories>stat.ML cs.LG</categories><comments>17 pages, 14 figures: Fixed typo in Fig. 1(b) and added reference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kalman Filters are one of the most influential models of time-varying
phenomena. They admit an intuitive probabilistic interpretation, have a simple
functional form, and enjoy widespread adoption in a variety of disciplines.
Motivated by recent variational methods for learning deep generative models, we
introduce a unified algorithm to efficiently learn a broad spectrum of Kalman
filters. Of particular interest is the use of temporal generative models for
counterfactual inference. We investigate the efficacy of such models for
counterfactual inference, and to that end we introduce the &quot;Healing MNIST&quot;
dataset where long-term structure, noise and actions are applied to sequences
of digits. We show the efficacy of our method for modeling this dataset. We
further show how our model can be used for counterfactual inference for
patients, based on electronic health record data of 8,000 patients over 4.5
years.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05122</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05122</id><created>2015-11-16</created><updated>2016-03-04</updated><authors><author><keyname>Sabour</keyname><forenames>Sara</forenames></author><author><keyname>Cao</keyname><forenames>Yanshuai</forenames></author><author><keyname>Faghri</keyname><forenames>Fartash</forenames></author><author><keyname>Fleet</keyname><forenames>David J.</forenames></author></authors><title>Adversarial Manipulation of Deep Representations</title><categories>cs.CV cs.LG cs.NE</categories><comments>Accepted as a conference paper at ICLR 2016</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We show that the representation of an image in a deep neural network (DNN)
can be manipulated to mimic those of other natural images, with only minor,
imperceptible perturbations to the original image. Previous methods for
generating adversarial images focused on image perturbations designed to
produce erroneous class labels, while we concentrate on the internal layers of
DNN representations. In this way our new class of adversarial images differs
qualitatively from others. While the adversary is perceptually similar to one
image, its internal representation appears remarkably similar to a different
image, one from a different class, bearing little if any apparent similarity to
the input; they appear generic and consistent with the space of natural images.
This phenomenon raises questions about DNN representations, as well as the
properties of natural images themselves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05132</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05132</id><created>2015-11-13</created><authors><author><keyname>Ghaffari</keyname><forenames>H. O.</forenames></author><author><keyname>Griffith</keyname><forenames>W. A.</forenames></author><author><keyname>Benson</keyname><forenames>P. M.</forenames></author></authors><title>Dynamic Evolution of Microscopic Wet Cracking Noises</title><categories>physics.geo-ph cond-mat.mtrl-sci cond-mat.soft cs.CE</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Characterizing the interaction between water and microscopic defects is one
of the long-standing challenges in understanding a broad range of cracking
processes. Different physical aspects of microscopic events, driven or
influenced by water, have been extensively discussed in atomistic calculations
but have not been accessible in microscale experiments. Through the analysis of
the emitted noises during the evolution of individual, dynamic microcracking
events, we show that the onset of a secondary instability known as hybrid
events occurs during the fast healing phase of microcracking, which leads to
(local) sudden increase of pore water pressure in the process zone, inducing a
secondary instability, which is followed by a fast-locking phase on the
microscopic faults (pulse-like rupture).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05133</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05133</id><created>2015-11-14</created><authors><author><keyname>Lu</keyname><forenames>Canyi</forenames></author><author><keyname>Li</keyname><forenames>Huan</forenames></author><author><keyname>Lin</keyname><forenames>Zhouchen</forenames></author><author><keyname>Yan</keyname><forenames>Shuicheng</forenames></author></authors><title>Fast Proximal Linearized Alternating Direction Method of Multiplier with
  Parallel Splitting</title><categories>math.OC cs.LG cs.NA</categories><comments>AAAI 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Augmented Lagragian Method (ALM) and Alternating Direction Method of
Multiplier (ADMM) have been powerful optimization methods for general convex
programming subject to linear constraint. We consider the convex problem whose
objective consists of a smooth part and a nonsmooth but simple part. We propose
the Fast Proximal Augmented Lagragian Method (Fast PALM) which achieves the
convergence rate $O(1/K^2)$, compared with $O(1/K)$ by the traditional PALM. In
order to further reduce the per-iteration complexity and handle the
multi-blocks problem, we propose the Fast Proximal ADMM with Parallel Splitting
(Fast PL-ADMM-PS) method. It also partially improves the rate related to the
smooth part of the objective function. Experimental results on both synthesized
and real world data demonstrate that our fast methods significantly improve the
previous PALM and ADMM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05169</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05169</id><created>2015-11-16</created><authors><author><keyname>Huang</keyname><forenames>Siyuan</forenames></author><author><keyname>Lu</keyname><forenames>Jiwen</forenames></author><author><keyname>Zhou</keyname><forenames>Jie</forenames></author><author><keyname>Jain</keyname><forenames>Anil K.</forenames></author></authors><title>Nonlinear Local Metric Learning for Person Re-identification</title><categories>cs.CV</categories><comments>Submitted to CVPR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Person re-identification aims at matching pedestrians observed from
non-overlapping camera views. Feature descriptor and metric learning are two
significant problems in person re-identification. A discriminative metric
learning method should be capable of exploiting complex nonlinear
transformations due to the large variations in feature space. In this paper, we
propose a nonlinear local metric learning (NLML) method to improve the
state-of-the-art performance of person re-identification on public datasets.
Motivated by the fact that local metric learning has been introduced to handle
the data which varies locally and deep neural network has presented outstanding
capability in exploiting the nonlinearity of samples, we utilize the merits of
both local metric learning and deep neural network to learn multiple sets of
nonlinear transformations. By enforcing a margin between the distances of
positive pedestrian image pairs and distances of negative pairs in the
transformed feature subspace, discriminative information can be effectively
exploited in the developed neural networks. Our experiments show that the
proposed NLML method achieves the state-of-the-art results on the widely used
VIPeR, GRID, and CUHK 01 datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05174</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05174</id><created>2015-11-16</created><authors><author><keyname>Saragadam</keyname><forenames>Vishwanath</forenames></author><author><keyname>Sankaranarayanan</keyname><forenames>Aswin</forenames></author><author><keyname>Li</keyname><forenames>Xin</forenames></author></authors><title>Cross-scale predictive dictionaries</title><categories>cs.CV stat.ML</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel signal model, based on sparse representations, that
captures cross-scale features for visual signals. We show that cross-scale
predictive model enables faster solutions to sparse approximation problems.
This is achieved by first solving the sparse approximation problem for the
downsampled signal and using the support of the solution to constrain the
support at the original resolution. The speedups obtained are especially
compelling for high-dimensional signals that require large dictionaries to
provide precise sparse approximations. We demonstrate speedups in the order of
10-100x for denoising and up to 15x speedups for compressive sensing of images,
videos, hyperspectral images and light-field images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05175</identifier>
 <datestamp>2016-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05175</id><created>2015-11-16</created><updated>2016-02-22</updated><authors><author><keyname>Elhoseiny</keyname><forenames>Mohamed</forenames></author><author><keyname>El-Gaaly</keyname><forenames>Tarek</forenames></author><author><keyname>Bakry</keyname><forenames>Amr</forenames></author><author><keyname>Elgammal</keyname><forenames>Ahmed</forenames></author></authors><title>Convolutional Models for Joint Object Categorization and Pose Estimation</title><categories>cs.CV cs.AI cs.LG</categories><comments>only for workshop presentation at ICLR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the task of Object Recognition, there exists a dichotomy between the
categorization of objects and estimating object pose, where the former
necessitates a view-invariant representation, while the latter requires a
representation capable of capturing pose information over different categories
of objects. With the rise of deep architectures, the prime focus has been on
object category recognition. Deep learning methods have achieved wide success
in this task. In contrast, object pose regression using these approaches has
received relatively much less attention. In this paper we show how deep
architectures, specifically Convolutional Neural Networks (CNN), can be adapted
to the task of simultaneous categorization and pose estimation of objects. We
investigate and analyze the layers of various CNN models and extensively
compare between them with the goal of discovering how the layers of distributed
representations of CNNs represent object pose information and how this
contradicts with object category representations. We extensively experiment on
two recent large and challenging multi-view datasets. Our models achieve better
than state-of-the-art performance on both datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05176</identifier>
 <datestamp>2016-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05176</id><created>2015-11-16</created><updated>2016-02-25</updated><authors><author><keyname>Gu</keyname><forenames>Shixiang</forenames></author><author><keyname>Levine</keyname><forenames>Sergey</forenames></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author><author><keyname>Mnih</keyname><forenames>Andriy</forenames></author></authors><title>MuProp: Unbiased Backpropagation for Stochastic Neural Networks</title><categories>cs.LG</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks are powerful parametric models that can be trained
efficiently using the backpropagation algorithm. Stochastic neural networks
combine the power of large parametric functions with that of graphical models,
which makes it possible to learn very complex distributions. However, as
backpropagation is not directly applicable to stochastic networks that include
discrete sampling operations within their computational graph, training such
networks remains difficult. We present MuProp, an unbiased gradient estimator
for stochastic networks, designed to make this task easier. MuProp improves on
the likelihood-ratio estimator by reducing its variance using a control variate
based on the first-order Taylor expansion of a mean-field network. Crucially,
unlike prior attempts at using backpropagation for training stochastic
networks, the resulting estimator is unbiased and well behaved. Our experiments
on structured output prediction and discrete latent variable modeling
demonstrate that MuProp yields consistently good performance across a range of
difficult tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05178</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05178</id><created>2015-11-16</created><authors><author><keyname>Jozeph</keyname><forenames>Shlomo</forenames></author></authors><title>A Note on Almost Perfect Probabilistically Checkable Proofs of Proximity</title><categories>cs.CC</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Probabilistically checkable proofs of proximity (PCPP) are proof systems
where the verifier is given a 3SAT formula, but has only oracle access to an
assignment and a proof. The verifier accepts a satisfying assignment with a
valid proof, and rejects (with high enough probability) an assignment that is
far from all satisfying assignments (for any given proof).
  In this work, we focus on the type of computation the verifier is allowed to
make. Assuming P $\neq$ NP, there can be no PCPP when the verifier is only
allowed to answer according to constraints from a set that forms a CSP that is
solvable in P. Therefore, the notion of PCPP is relaxed to almost perfect
probabilistically checkable proofs of proximity (APPCPP), where the verifier is
allowed to reject a satisfying assignment with a valid proof, with arbitrary
small probability.
  We show, unconditionally, a dichotomy of sets of allowable computations: sets
that have APPCPPs (which actually follows because they have PCPPs) and sets
that do not. This dichotomy turns out to be the same as that of the Dichotomy
Theorem, which can be thought of as dividing sets of allowable verifier
computations into sets that give rise to NP-hard CSPs, and sets that give rise
to CSPs that are solvable in P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05180</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05180</id><created>2015-11-16</created><authors><author><keyname>Chen</keyname><forenames>Bo</forenames></author><author><keyname>Sion</keyname><forenames>Radu</forenames></author></authors><title>HiFlash: A History Independent Flash Device</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Retention regulations require timely and irrecoverable disposal of data, a
challenging task, as data and its side effects are stored and maintained at all
layers of a computing system. Those side effects can be used as an oracle to
derive the past existence of deleted data.
  Fortunately, history independence can be utilized to eliminate such
history-related oracles. HIFS can provide history independence for file storage
over mechanical disk drives. However, HIFS cannot provide history independence
when deployed on top of flash devices, as flash memory manages its own internal
block placement, which is often inherently history dependent.
  In this work, we initiate research on history independent flash devices. We
design HiFlash, which achieves a strong notion of history independence by
defending against an adversary allowed access to the flash at multiple
different points in time. In addition, we design a simple, yet history
independence friendly wear-leveling mechanism that allows HiFlash to smartly
and advantageously trade off a tunable small amount of history leakage for a
significant increase in the device's lifetime. Our prototype built in an actual
flash device as well as extensive simulations validate the effectiveness of
HiFlash.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05186</identifier>
 <datestamp>2016-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05186</id><created>2015-11-16</created><updated>2016-01-12</updated><authors><author><keyname>Rafieisakhaei</keyname><forenames>Mohammadhussein</forenames></author><author><keyname>Tamjidi</keyname><forenames>Amirhossein</forenames></author><author><keyname>Chakravorty</keyname><forenames>Suman</forenames></author><author><keyname>Kumar</keyname><forenames>P. R.</forenames></author></authors><title>Feedback Motion Planning Under Non-Gaussian Uncertainty and Non-Convex
  State Constraints</title><categories>cs.RO</categories><comments>7 pages, 4 figures, Submitted to IEEE International Conference on
  Robotics and Automation (ICRA) 2016 on 9/15/2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Planning under process and measurement uncertainties is a challenging
problem. In its most general form it can be modeled as a Partially Observed
Markov Decision Process (POMDP) problem. However POMDPs are generally difficult
to solve when the underlying spaces are continuous, particularly when beliefs
are non-Gaussian, and the difficulty is further exacerbated when there are also
non-convex constraints on states. Existing algorithms to address such
challenging POMDPs are expensive in terms of computation and memory. In this
paper, we provide a feedback policy in non-Gaussian belief space via solving a
convex program for common non-linear observation models. The solution involves
a Receding Horizon Control strategy using particle filters for the non-Gaussian
belief representation. We develop a way of capturing non-convex constraints in
the state space and adapt the optimization to incorporate such constraints, as
well. A key advantage of this method is that it does not introduce additional
variables in the optimization problem and is therefore more scalable than
existing constrained problems in belief space. We demonstrate the performance
of the method on different scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05191</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05191</id><created>2015-11-16</created><authors><author><keyname>Naeini</keyname><forenames>Mahdi Pakdaman</forenames></author><author><keyname>Cooper</keyname><forenames>Gregory F.</forenames></author></authors><title>Binary Classifier Calibration using an Ensemble of Near Isotonic
  Regression Models</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning accurate probabilistic models from data is crucial in many practical
tasks in data mining. In this paper we present a new non-parametric calibration
method called \textit{ensemble of near isotonic regression} (ENIR). The method
can be considered as an extension of BBQ, a recently proposed calibration
method, as well as the commonly used calibration method based on isotonic
regression. ENIR is designed to address the key limitation of isotonic
regression which is the monotonicity assumption of the predictions. Similar to
BBQ, the method post-processes the output of a binary classifier to obtain
calibrated probabilities. Thus it can be combined with many existing
classification models. We demonstrate the performance of ENIR on synthetic and
real datasets for the commonly used binary classification models. Experimental
results show that the method outperforms several common binary classifier
calibration methods. In particular on the real data, ENIR commonly performs
statistically significantly better than the other methods, and never worse. It
is able to improve the calibration power of classifiers, while retaining their
discrimination power. The method is also computationally tractable for large
scale datasets, as it is $O(N \log N)$ time, where $N$ is the number of
samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05194</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05194</id><created>2015-11-16</created><authors><author><keyname>Zhu</keyname><forenames>Lingchen</forenames></author><author><keyname>Liu</keyname><forenames>Entao</forenames></author><author><keyname>McClellan</keyname><forenames>James H.</forenames></author></authors><title>Sparse-promoting Full Waveform Inversion based on Online Orthonormal
  Dictionary Learning</title><categories>physics.geo-ph cs.LG cs.NA math.NA</categories><comments>This paper has been submitted to Geophysics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full waveform inversion (FWI) delivers high-resolution images of a subsurface
medium model by minimizing iteratively the least-squares misfit between the
observed and simulated seismic data. Due to the limited accuracy of the
starting model and the inconsistency of the seismic waveform data, the FWI
problem is inherently ill-posed, so that regularization techniques are
typically applied to obtain better models. FWI is also a computationally
expensive problem because modern seismic surveys cover very large areas of
interest and collect massive volumes of data. The dimensionality of the problem
and the heterogeneity of the medium both stress the need for faster algorithms
and sparse regularization techniques to accelerate and improve imaging results.
  This paper reaches these goals by developing a compressive sensing approach
for the FWI problem, where the sparsity of model perturbations is exploited
within learned dictionaries. Based on stochastic approximations, the
dictionaries are updated iteratively to adapt to dynamic model perturbations.
Meanwhile, the dictionaries are kept orthonormal in order to maintain the
corresponding transform in a fast and compact manner without introducing extra
computational overhead to FWI. Such a sparsity regularization on model
perturbations enables us to take randomly subsampled data for computation and
thus significantly reduce the cost. Compared with other approaches that employ
sparsity constraints in the fixed curvelet transform domain, our approach can
achieve more robust inversion results with better model fit and visual quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05196</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05196</id><created>2015-11-16</created><updated>2015-12-03</updated><authors><author><keyname>Goyal</keyname><forenames>Sanjeev</forenames></author><author><keyname>Jabbari</keyname><forenames>Shahin</forenames></author><author><keyname>Kearns</keyname><forenames>Michael</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author><author><keyname>Morgenstern</keyname><forenames>Jamie</forenames></author></authors><title>Strategic Network Formation with Attack and Immunization</title><categories>cs.GT</categories><comments>V2 contains a new section on behavioral experiments compared to V1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Strategic network formation arises in settings where agents receive benefit
from connections to other agents, but also incur costs for forming links. We
consider a new network formation game that incorporates an adversarial attack,
as well as immunization against attack. An agent's benefit is the expected size
of her connected component post-attack, and agents may also choose to immunize
themselves from attack at some additional cost. Our framework is a stylized
model of settings where reachability rather than centrality is the primary
concern, and vertices vulnerable to attacks may reduce risk via costly
measures.
  In the reachability network benefit model without attack or immunization, the
set of equilibria is the empty graph and any tree. The introduction of attack
and immunization changes the game dramatically; new equilibrium topologies
emerge, some more sparse and some more dense than trees. We show that every
equilibrium network with $n$ agents contains at most $2n-4$ edges for $n &gt;= 4$.
This shows that despite permitting topologies denser than trees, the amount of
overbuilding is sharply limited. We also show that attack and immunization
don't significantly erode social welfare: every non-trivial equilibrium
asymptotically has welfare at least as that of any equilibrium in the
attack-free model.
  We complement our theory with simulations demonstrating fast convergence of a
new bounded rationality dynamic which generalizes linkstable best response but
is considerably more powerful in our game. The simulations further elucidate
the wide variety of asymmetric equilibria and demonstrate topological
consequences of the dynamics e.g., heavy-tailed degree distributions arising
from immunization. Finally, we report on a behavioral experiment on our game
with over 100 participants, where despite the complexity of the game, the
resulting network was surprisingly close to equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05197</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05197</id><created>2015-11-16</created><authors><author><keyname>Lin</keyname><forenames>Tsung-Yu</forenames></author><author><keyname>Maji</keyname><forenames>Subhransu</forenames></author></authors><title>Visualizing and Understanding Deep Texture Representations</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A number of recent approaches have used deep convolutional neural networks
(CNNs) to build texture representations. Nevertheless, it is still unclear how
these models represent texture and invariances to categorical variations. This
work conducts a systematic evaluation of recent CNN-based texture descriptors
for recognition and attempts to understand the nature of invariances captured
by these representations. First we show that the recently proposed bilinear CNN
model [23] is an excellent general-purpose texture descriptor and compares
favorably to other CNN-based descriptors on various texture and scene
recognition benchmarks. The model is translationally invariant and obtains
better accuracy on the ImageNet dataset without requiring spatial jittering of
data compared to corresponding models trained with spatial jittering. Based on
recent work [26, 12] we propose a technique to visualize pre-images, providing
a means for understanding categorical properties that are captured by these
representations. Finally, we show preliminary results on how a unified
parametric model of texture analysis and synthesis can be used for
attribute-based image manipulation, e.g. to make an image more swirly,
honeycombed, or knitted. The source code and supplementary visualization will
be made available at http://vis-www.cs.umass.edu/texture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05201</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05201</id><created>2015-11-16</created><authors><author><keyname>Aldridge</keyname><forenames>Matthew</forenames></author></authors><title>The capacity of Bernoulli nonadaptive group testing</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>7 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider nonadaptive group testing with Bernoulli tests, where each item
is placed in each test independently with some fixed probability. We give a
tight threshold on the maximum number of tests required to find the defective
set under optimal Bernoulli testing. Achievability is given by a result of
Scarlett and Cevher; here we give a converse bound showing that this result is
best possible. Our new converse requires three parts: a typicality bound
generalising the trivial counting bound, a converse on the COMP algorithm of
Chan et al, and a bound on the SSS algorithm similar to that given by Aldridge,
Baldassini, and Johnson. Our result has a number of important corollaries, in
particular that, in denser cases, Bernoulli nonadaptive group testing is
strictly worse than the best adaptive strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05202</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05202</id><created>2015-11-16</created><updated>2015-11-26</updated><authors><author><keyname>Welleck</keyname><forenames>Sean J.</forenames></author></authors><title>Efficient AUC Optimization for Information Ranking Applications</title><categories>cs.IR stat.ML</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adequate evaluation of an information retrieval system to estimate future
performance is a crucial task. Area under the ROC curve (AUC) is widely used to
evaluate the generalization of a retrieval system. However, the objective
function optimized in many retrieval systems is the error rate and not the AUC
value. This paper provides an efficient and effective non-linear approach to
optimize AUC using additive regression trees, with a special emphasis on the
use of multi-class AUC (MAUC) because multiple relevance levels are widely used
in many ranking applications. Compared to a conventional linear approach, the
performance of the non-linear approach is comparable in the bi-relevance
benchmark datasets and is better in the multi-relevance benchmark datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05204</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05204</id><created>2015-11-16</created><authors><author><keyname>Liu</keyname><forenames>Mengyi</forenames></author><author><keyname>Shan</keyname><forenames>Shiguang</forenames></author><author><keyname>Wang</keyname><forenames>Ruiping</forenames></author><author><keyname>Chen</keyname><forenames>Xilin</forenames></author></authors><title>Learning Expressionlets via Universal Manifold Model for Dynamic Facial
  Expression Recognition</title><categories>cs.CV</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Facial expression is temporally dynamic event which can be decomposed into a
set of muscle motions occurring in different facial regions over various time
intervals. For dynamic expression recognition, two key issues, temporal
alignment and semantics-aware dynamic representation, must be taken into
account. In this paper, we attempt to solve both problems via manifold modeling
of videos based on a novel mid-level representation, i.e.
\textbf{expressionlet}. Specifically, our method contains three key stages: 1)
each expression video clip is characterized as a spatial-temporal manifold
(STM) formed by dense low-level features; 2) a Universal Manifold Model (UMM)
is learned over all low-level features and represented as a set of local modes
to statistically unify all the STMs. 3) the local modes on each STM can be
instantiated by fitting to UMM, and the corresponding expressionlet is
constructed by modeling the variations in each local mode. With above strategy,
expression videos are naturally aligned both spatially and temporally. To
enhance the discriminative power, the expressionlet-based STM representation is
further processed with discriminant embedding. Our method is evaluated on four
public expression databases, CK+, MMI, Oulu-CASIA, and FERA. In all cases, our
method outperforms the known state-of-the-art by a large margin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05208</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05208</id><created>2015-11-16</created><authors><author><keyname>Saibaba</keyname><forenames>Arvind K.</forenames></author></authors><title>HOID: Higher Order Interpolatory Decomposition for tensors based on
  Tucker representation</title><categories>math.NA cs.NA</categories><comments>24 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a CUR-type factorization for tensors in the Tucker format based on
interpolatory decomposition, which we will denote as Higher Order Interpolatory
Decomposition (HOID). Given a tensor $\ten{X}$, the algorithm provides a set of
column vectors $\{ \mat{C}_n\}_{n=1}^d$ which are columns extracted from the
mode-$n$ tensor unfolding, along with a core tensor $\ten{G}$ and together,
they satisfy some error bounds. Compared to the Higher Order SVD (HOSVD)
algorithm, the HOID provides a decomposition that preserves certain important
features of the original tensor such as sparsity, non-negativity, integer
values, etc. Error bounds along with detailed estimates of computational costs
are provided. The algorithms proposed in this paper have been validated against
carefully chosen numerical examples which highlight the favorable properties of
the algorithms. Related methods for subset selection proposed for matrix CUR
decomposition, such as Discrete Empirical Interpolation method (DEIM) and
leverage score sampling, have also been extended to tensors and are compared
against our proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05210</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05210</id><created>2015-11-16</created><updated>2016-01-17</updated><authors><author><keyname>Petersen</keyname><forenames>Holger</forenames></author></authors><title>Counting Ones Without Broadword Operations</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lower time bound $\Omega(\min(\nu(x), n-\nu(x))$ for counting the number of
ones in a binary input word $x$ of length $n$ is presented, where $\nu(x)$ is
the number of ones. The operations available are increment, decrement, bit-wise
logical operations, and assignment. The only constant available is zero. An
almost matching upper bound is also obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05212</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05212</id><created>2015-11-16</created><updated>2016-02-01</updated><authors><author><keyname>Choromanska</keyname><forenames>Anna</forenames></author><author><keyname>Choromanski</keyname><forenames>Krzysztof</forenames></author><author><keyname>Bojarski</keyname><forenames>Mariusz</forenames></author><author><keyname>Jebara</keyname><forenames>Tony</forenames></author><author><keyname>Kumar</keyname><forenames>Sanjiv</forenames></author><author><keyname>LeCun</keyname><forenames>Yann</forenames></author></authors><title>Binary embeddings with structured hashed projections</title><categories>cs.LG</categories><comments>arXiv admin note: text overlap with arXiv:1505.03190</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the hashing mechanism for constructing binary embeddings, that
involves pseudo-random projections followed by nonlinear (sign function)
mappings. The pseudo-random projection is described by a matrix, where not all
entries are independent random variables but instead a fixed &quot;budget of
randomness&quot; is distributed across the matrix. Such matrices can be efficiently
stored in sub-quadratic or even linear space, provide reduction in randomness
usage (i.e. number of required random values), and very often lead to
computational speed ups. We prove several theoretical results showing that
projections via various structured matrices followed by nonlinear mappings
accurately preserve the angular distance between input high-dimensional
vectors. To the best of our knowledge, these results are the first that give
theoretical ground for the use of general structured matrices in the nonlinear
setting. In particular, they generalize previous extensions of the
Johnson-Lindenstrauss lemma and prove the plausibility of the approach that was
so far only heuristically confirmed for some special structured matrices.
Consequently, we show that many structured matrices can be used as an efficient
information compression mechanism. Our findings build a better understanding of
certain deep architectures, which contain randomly weighted and untrained
layers, and yet achieve high performance on different learning tasks. We
empirically verify our theoretical findings and show the dependence of learning
via structured hashed projections on the performance of neural network as well
as nearest neighbor classifier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05219</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05219</id><created>2015-11-16</created><authors><author><keyname>Russo</keyname><forenames>Daniel</forenames></author><author><keyname>Zou</keyname><forenames>James</forenames></author></authors><title>Controlling Bias in Adaptive Data Analysis Using Information Theory</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern data is messy and high-dimensional, and it is often not clear a priori
what are the right questions to ask. Instead, the analyst typically needs to
use the data to search for interesting analyses to perform and hypotheses to
test. This is an adaptive process, where the choice of analysis to be performed
next depends on the results of the previous analyses on the same data. It's
widely recognized that this process, even if well-intentioned, can lead to
biases and false discoveries, contributing to the crisis of reproducibility in
science. But while adaptivity renders standard statistical theory invalid,
folklore and experience suggest that not all types of adaptive analysis are
equally at risk for false discoveries. In this paper, we propose a general
information-theoretic framework to quantify and provably bound the bias and
other statistics of an arbitrary adaptive analysis process. We prove that our
mutual information based bound is tight in natural models, and then use it to
give rigorous insights into when commonly used procedures do or do not lead to
substantially biased estimation. We first consider several popular feature
selection protocols, like rank selection or variance-based selection. We then
consider the practice of adding random noise to the observations or to the
reported statistics, which is advocated by related ideas from differential
privacy and blinded data analysis. We discuss the connections between these
techniques and our framework, and supplement our results with illustrative
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05223</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05223</id><created>2015-11-16</created><authors><author><keyname>Trimpe</keyname><forenames>Sebastian</forenames></author></authors><title>Distributed Event-based State Estimation</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An event-based state estimation approach for reducing communication in a
networked control system is proposed. Multiple distributed
sensor-actuator-agents observe a dynamic process and sporadically exchange
their measurements and inputs over a bus network. Based on these data, each
agent estimates the full state of the dynamic system, which may exhibit
arbitrary inter-agent couplings. Local event-based protocols ensure that data
is transmitted only when necessary to meet a desired estimation accuracy. This
event-based scheme is shown to mimic a centralized Luenberger observer design
up to guaranteed bounds, and stability is proven in the sense of bounded
estimation errors for bounded disturbances. The stability result extends to the
distributed control system that results when the local state estimates are used
for distributed feedback control. Simulation results highlight the benefit of
the event-based approach over classical periodic ones in reducing communication
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05234</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05234</id><created>2015-11-16</created><authors><author><keyname>Xu</keyname><forenames>Huijuan</forenames></author><author><keyname>Saenko</keyname><forenames>Kate</forenames></author></authors><title>Ask, Attend and Answer: Exploring Question-Guided Spatial Attention for
  Visual Question Answering</title><categories>cs.CV cs.AI cs.CL cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of Visual Question Answering (VQA) requires joint image and
language understanding to answer a question about a given photograph. Recent
approaches have applied deep image captioning methods based on recurrent LSTM
networks to this problem, but have failed to model spatial inference. In this
paper, we propose a memory network with spatial attention for the VQA task.
Memory networks are recurrent neural networks with an explicit attention
mechanism that selects certain parts of the information stored in memory. We
store neuron activations from different spatial receptive fields in the memory,
and use the question to choose relevant regions for computing the answer. We
experiment with spatial attention architectures that use different question
representations to choose regions, and also show that two attention steps
(hops) obtain improved results compared to a single step. To understand the
inference process learned by the network, we design synthetic questions that
specifically require spatial inference and visualize the attention weights. We
evaluate our model on two published visual question answering datasets, DAQUAR
and VQA, and obtain promising results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05236</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05236</id><created>2015-11-16</created><updated>2016-01-08</updated><authors><author><keyname>Judd</keyname><forenames>Patrick</forenames></author><author><keyname>Albericio</keyname><forenames>Jorge</forenames></author><author><keyname>Hetherington</keyname><forenames>Tayler</forenames></author><author><keyname>Aamodt</keyname><forenames>Tor</forenames></author><author><keyname>Jerger</keyname><forenames>Natalie Enright</forenames></author><author><keyname>Urtasun</keyname><forenames>Raquel</forenames></author><author><keyname>Moshovos</keyname><forenames>Andreas</forenames></author></authors><title>Reduced-Precision Strategies for Bounded Memory in Deep Neural Nets</title><categories>cs.LG cs.NE</categories><comments>Submitted to ICLR 2016, 12 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work investigates how using reduced precision data in Convolutional
Neural Networks (CNNs) affects network accuracy during classification. More
specifically, this study considers networks where each layer may use different
precision data. Our key result is the observation that the tolerance of CNNs to
reduced precision data not only varies across networks, a well established
observation, but also within networks. Tuning precision per layer is appealing
as it could enable energy and performance improvements. In this paper we study
how error tolerance across layers varies and propose a method for finding a low
precision configuration for a network while maintaining high accuracy. A
diverse set of CNNs is analyzed showing that compared to a conventional
implementation using a 32-bit floating-point representation for all layers, and
with less than 1% loss in relative accuracy, the data footprint required by
these networks can be reduced by an average of 74% and up to 92%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05240</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05240</id><created>2015-11-16</created><authors><author><keyname>Combes</keyname><forenames>Richard</forenames></author></authors><title>An extension of McDiarmid's inequality</title><categories>cs.LG math.PR math.ST stat.TH</categories><comments>Note (4 pages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive an extension of McDiarmid's inequality for functions $f$ with
bounded differences on a high probability set ${\cal Y}$ (instead of almost
surely). The behavior of $f$ outside ${\cal Y}$ may be arbitrary. The proof is
short and elementary, and relies on an extension argument similar to
Kirszbraun's theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05252</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05252</id><created>2015-11-16</created><authors><author><keyname>Duff</keyname><forenames>Igor Pontes</forenames></author><author><keyname>Poussot-Vassal</keyname><forenames>Charles</forenames></author><author><keyname>Seren</keyname><forenames>C&#xe9;dric</forenames></author></authors><title>Optimal $\mathcal{H}_{2}$ model approximation based on multiple
  input/output delays systems</title><categories>cs.SY math.DS math.NA</categories><comments>14 pages, 3 figures, submitted to Automatica Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the $\mathcal{H}_{2}$ optimal approximation of a
$n_{y}\times{n_{u}}$ transfer function $\mathbf{G}(s)$ by a finite dimensional
system $\hat{\mathbf{H}}_{d}(s)$ including input/output delays, is addressed.
The underlying $\mathcal{H}_{2}$ optimality conditions of the approximation
problem are firstly derived and established in the case of a poles/residues
decomposition. These latter form an extension of the tangential interpolatory
conditions, presented in~\cite{gugercin2008h_2,dooren2007} for the delay-free
case, which is the main contribution of this paper. Secondly, a two stage
algorithm is proposed in order to practically obtain such an approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05254</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05254</id><created>2015-11-16</created><authors><author><keyname>Javadi</keyname><forenames>Hamid</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>The Hidden Subgraph Problem</title><categories>math.ST cs.DM cs.IT math.IT stat.TH</categories><comments>32 pages, 1 pdf figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a statistical model for the problem of finding a subgraph with
specified topology in an otherwise random graph. This task plays an important
role in the analysis of social and biological networks. In these type of
networks, small subgraphs with a specific structure have important functional
roles.
  Within our model, a single copy of a subgraph is added (`planted') in an
Erd\H{o}s-Renyi random graph with $n$ vertices and edge probability $q_0$. We
ask whether the resulting graph can be distinguished reliably from a pure
Erd\H{o}s-Renyi random graph, and present two types of result. First we
investigate the question from a purely statistical perspective, and ask whether
there is \emph{any} test that can distinguish between the two graph models. We
provide necessary and sufficient conditions that are essentially tight for
subgraphs of size asymptotically smaller than $n^{2/5}$.
  Next we study two polynomial-time algorithms for solving the same problem: a
spectral algorithm, and a semidefinite programming (SDP) relaxation. For the
spectral algorithm, we establish sufficient conditions under which it
distinguishes the two graph models with high probability. Under the same
conditions the spectral algorithm indeed identifies the hidden subgraph.
  The spectral algorithm is substantially sub-optimal with respect to the
optimal test. We show that a similar gap is present for the SDP approach. This
points at a large gap between statistical and computational limits for this
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05259</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05259</id><created>2015-11-16</created><updated>2015-11-20</updated><authors><author><keyname>Caron</keyname><forenames>St&#xe9;phane</forenames></author><author><keyname>Pham</keyname><forenames>Quang-Cuong</forenames></author><author><keyname>Nakamura</keyname><forenames>Yoshihiko</forenames></author></authors><title>Completeness of Randomized Kinodynamic Planners with State-based
  Steering</title><categories>cs.RO</categories><comments>21 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Probabilistic completeness is an important property in motion planning.
Although it has been established with clear assumptions for geometric planners,
the panorama of completeness results for kinodynamic planners is still
incomplete, as most existing proofs rely on strong assumptions that are
difficult, if not impossible, to verify on practical systems. In this paper, we
focus on an important class of kinodynamic planners, namely those that
interpolate trajectories in the state space. We provide a proof of
probabilistic completeness for these planners under assumptions that can be
readily verified from the system's equations of motion and the user-defined
interpolation function. Our proof relies crucially on a property of
interpolated trajectories, termed second-order continuity (SOC), which we show
is tightly related to the ability of a planner to benefit from denser sampling.
We analyze the impact of this property in simulations on a low-torque pendulum.
Our results show that a simple RRT using a second-order continuous
interpolation swiftly finds solution, while it is impossible for the same
planner using standard Bezier curves (which are not SOC) to find any solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05261</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05261</id><created>2015-11-16</created><authors><author><keyname>Kang</keyname><forenames>Zhao</forenames></author><author><keyname>Peng</keyname><forenames>Chong</forenames></author><author><keyname>Cheng</keyname><forenames>Qiang</forenames></author></authors><title>Robust PCA via Nonconvex Rank Approximation</title><categories>cs.CV cs.LG cs.NA stat.ML</categories><comments>IEEE International Conference on Data Mining</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerous applications in data mining and machine learning require recovering
a matrix of minimal rank. Robust principal component analysis (RPCA) is a
general framework for handling this kind of problems. Nuclear norm based convex
surrogate of the rank function in RPCA is widely investigated. Under certain
assumptions, it can recover the underlying true low rank matrix with high
probability. However, those assumptions may not hold in real-world
applications. Since the nuclear norm approximates the rank by adding all
singular values together, which is essentially a $\ell_1$-norm of the singular
values, the resulting approximation error is not trivial and thus the resulting
matrix estimator can be significantly biased. To seek a closer approximation
and to alleviate the above-mentioned limitations of the nuclear norm, we
propose a nonconvex rank approximation. This approximation to the matrix rank
is tighter than the nuclear norm. To solve the associated nonconvex
minimization problem, we develop an efficient augmented Lagrange multiplier
based optimization algorithm. Experimental results demonstrate that our method
outperforms current state-of-the-art algorithms in both accuracy and
efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05262</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05262</id><created>2015-11-16</created><updated>2016-02-24</updated><authors><author><keyname>Portugal</keyname><forenames>Ivens</forenames></author><author><keyname>Alencar</keyname><forenames>Paulo</forenames></author><author><keyname>Cowan</keyname><forenames>Donald</forenames></author></authors><title>Requirements Engineering for General Recommender Systems</title><categories>cs.SE cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In requirements engineering for recommender systems, software engineers must
identify the data that drives the recommendations. This is a labor-intensive
task, which is error-prone and expensive. One possible solution to this problem
is the adoption of automatic recommender system development approach based on a
general recommender framework. One step towards the creation of such a
framework is to determine the type of data used in recommender systems. In this
paper, a systematic review has been conducted to identify the type of user and
recommendation data items needed by a general recommender system. A user and
item model is proposed, and some considerations about algorithm specific
parameters are explained. A further goal is to study the impact of the fields
of big data and Internet of things on the development of recommender systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05263</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05263</id><created>2015-11-16</created><updated>2016-02-24</updated><authors><author><keyname>Portugal</keyname><forenames>Ivens</forenames></author><author><keyname>Alencar</keyname><forenames>Paulo</forenames></author><author><keyname>Cowan</keyname><forenames>Donald</forenames></author></authors><title>The Use of Machine Learning Algorithms in Recommender Systems: A
  Systematic Review</title><categories>cs.SE cs.IR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems use algorithms to provide users with product or service
recommendations. Recently, these systems have been using machine learning
algorithms from the field of artificial intelligence. However, choosing a
suitable machine learning algorithm for a recommender system is difficult
because of the number of algorithms described in the literature. Researchers
and practitioners developing recommender systems are left with little
information about the current approaches in algorithm usage. Moreover, the
development of a recommender system using a machine learning algorithm often
has problems and open questions that must be evaluated, so software engineers
know where to focus research efforts. This paper presents a systematic review
of the literature that analyzes the use of machine learning algorithms in
recommender systems and identifies research opportunities for software
engineering research. The study concludes that Bayesian and decision tree
algorithms are widely used in recommender systems because of their relative
simplicity, and that requirement and design phases of recommender system
development appear to offer opportunities for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05265</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05265</id><created>2015-11-16</created><updated>2015-11-19</updated><authors><author><keyname>Wang</keyname><forenames>Sheng</forenames></author><author><keyname>Sun</keyname><forenames>Siqi</forenames></author><author><keyname>Xu</keyname><forenames>Jinbo</forenames></author></authors><title>AUC-maximized Deep Convolutional Neural Fields for Sequence Labeling</title><categories>stat.ML cs.LG</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Convolutional Neural Networks (DCNN) has shown excellent performance in
a variety of machine learning tasks. This manuscript presents Deep
Convolutional Neural Fields (DeepCNF), a combination of DCNN with Conditional
Random Field (CRF), for sequence labeling with highly imbalanced label
distribution. The widely-used training methods, such as maximum-likelihood and
maximum labelwise accuracy, do not work well on highly imbalanced data. To
handle this, we present a new training algorithm called maximum-AUC for
DeepCNF. That is, we train DeepCNF by directly maximizing the empirical Area
Under the ROC Curve (AUC), which is an unbiased measurement for imbalanced
data. To fulfill this, we formulate AUC in a pairwise ranking framework,
approximate it by a polynomial function and then apply a gradient-based
procedure to optimize it. We then test our AUC-maximized DeepCNF on three very
different protein sequence labeling tasks: solvent accessibility prediction,
8-state secondary structure prediction, and disorder prediction. Our
experimental results confirm that maximum-AUC greatly outperforms the other two
training methods on 8-state secondary structure prediction and disorder
prediction since their label distributions are highly imbalanced and also have
similar performance as the other two training methods on the solvent
accessibility prediction problem which has three equally-distributed labels.
Furthermore, our experimental results also show that our AUC-trained DeepCNF
models greatly outperform existing popular predictors of these three tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05266</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05266</id><created>2015-11-16</created><authors><author><keyname>Barjasteh</keyname><forenames>Iman</forenames></author><author><keyname>Forsati</keyname><forenames>Rana</forenames></author><author><keyname>Esfahanian</keyname><forenames>Abdol-Hossein</forenames></author><author><keyname>Radha</keyname><forenames>Hayder</forenames></author></authors><title>Semi-supervised Collaborative Ranking with Push at Top</title><categories>cs.LG cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing collaborative ranking based recommender systems tend to perform best
when there is enough observed ratings for each user and the observation is made
completely at random. Under this setting recommender systems can properly
suggest a list of recommendations according to the user interests. However,
when the observed ratings are extremely sparse (e.g. in the case of cold-start
users where no rating data is available), and are not sampled uniformly at
random, existing ranking methods fail to effectively leverage side information
to transduct the knowledge from existing ratings to unobserved ones. We propose
a semi-supervised collaborative ranking model, dubbed \texttt{S$^2$COR}, to
improve the quality of cold-start recommendation. \texttt{S$^2$COR} mitigates
the sparsity issue by leveraging side information about both observed and
missing ratings by collaboratively learning the ranking model. This enables it
to deal with the case of missing data not at random, but to also effectively
incorporate the available side information in transduction. We experimentally
evaluated our proposed algorithm on a number of challenging real-world datasets
and compared against state-of-the-art models for cold-start recommendation. We
report significantly higher quality recommendations with our algorithm compared
to the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05270</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05270</id><created>2015-11-16</created><authors><author><keyname>Chau</keyname><forenames>Chi-Kin</forenames></author><author><keyname>Elbassioni</keyname><forenames>Khaled</forenames></author></authors><title>Strong Price of Anarchy of Coalition Formation Game with Fair Cost
  Sharing and Bounded Capacity for Sharing Economy</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a coalition formation game subject to the capacity of $K$
participants per coalition. The participants in each coalition are supposed to
split the associated cost according to a given cost sharing solution. A stable
coalition structure is established, when no group of participants can opt out
to form another coalition that leads to lower individual payments. We
investigate the strong price of anarchy (PoA) comparing a worst-case stable
coalition structure and a social optimum considering several fair cost sharing
solutions (e.g., equal-split, proportional-split, egalitarian and Nash
bargaining solutions of bargaining games, and usage based cost sharing). Our
coalition formation game is motivated by applications in sharing economy, where
users form coalitions to share certain replaceable resources. Our model can be
applied to several problems such as hotel room sharing among travelers,
taxi-ride sharing among passengers, and pass sharing among users. We show that
the strong PoA for equal-split, proportional-split, and usage based cost
sharing (under certain conditions) is $\Theta(\log K)$, whereas the one for
egalitarian and Nash bargaining solutions is $O(\sqrt{K} \log K)$. We also
study the existence of a stable coalition structure in these cost sharing
solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05271</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05271</id><created>2015-11-16</created><authors><author><keyname>Taylor</keyname><forenames>Dane</forenames></author><author><keyname>Shai</keyname><forenames>Saray</forenames></author><author><keyname>Stanley</keyname><forenames>Natalie</forenames></author><author><keyname>Mucha</keyname><forenames>Peter J.</forenames></author></authors><title>Enhanced detectability of community structure in multilayer networks
  through layer aggregation</title><categories>physics.soc-ph cond-mat.dis-nn cs.SI math-ph math.MP math.PR</categories><comments>5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Community detection is a central pursuit for understanding the structure and
function of biological, social and technological networks, and it is important
to understand the fundamental limitations on detectability. Many systems are
naturally represented by a multilayer network in which edges exist in multiple
layers that encode different--but potentially related--types of interactions.
Using random matrix theory for stochastic block models, we analyze
detectability limitations for multilayer networks and find that by aggregating
together similar layers, it is possible to identify structure that is
undetectable in a single layer. We explore this phenomenon for several
aggregation methods including summation of the layers' adjacency matrices, for
which detectability limit vanishes with increasing number of layers, L,
decaying as O(L^{-1/2}). Interestingly, we find a similar scaling behavior when
the summation is thresholded at an optimal value, supporting the common--but
not well understood--practice of thresholding data matrices to obtain sparse
network representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05273</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05273</id><created>2015-11-17</created><updated>2015-11-18</updated><authors><author><keyname>Abbas</keyname><forenames>Houssam</forenames></author><author><keyname>Fainekos</keyname><forenames>Georgios</forenames></author></authors><title>Towards composition of conformant systems</title><categories>cs.SY</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the Model-Based Design process for Cyber-Physical Systems, we
consider issues in conformance testing of systems. Conformance is a
quantitative notion of similarity between the output trajectories of systems,
which considers both temporal and spatial aspects of the outputs. Previous work
developed algorithms for computing the conformance degree between two systems,
and demonstrated how formal verification results for one system can be re-used
for a system that is conformant to it. In this paper, we study the relation
between conformance and a generalized approximate simulation relation for the
class of Open Metric Transition Systems (OMTS). This allows us to prove a
small-gain theorem for OMTS, which gives sufficient conditions under which the
feedback interconnection of systems respects the conformance relation, thus
allowing the building of more complex systems from conformant components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05284</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05284</id><created>2015-11-17</created><authors><author><keyname>Hendricks</keyname><forenames>Lisa Anne</forenames></author><author><keyname>Venugopalan</keyname><forenames>Subhashini</forenames></author><author><keyname>Rohrbach</keyname><forenames>Marcus</forenames></author><author><keyname>Mooney</keyname><forenames>Raymond</forenames></author><author><keyname>Saenko</keyname><forenames>Kate</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Deep Compositional Captioning: Describing Novel Object Categories
  without Paired Training Data</title><categories>cs.CV cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While recent deep neural network models have achieved promising results on
the image captioning task, they rely largely on the availability of corpora
with paired image and sentence captions to describe objects in context. In this
work, we propose the Deep Compositional Captioner (DCC) to address the task of
generating descriptions of novel objects which are not present in paired
image-sentence datasets. Our method achieves this by leveraging large object
recognition datasets and external text corpora and by transferring knowledge
between semantically similar concepts. Current deep caption models can only
describe objects contained in paired image-sentence corpora, despite the fact
that they are pre-trained with large object recognition datasets, namely
ImageNet. In contrast, our model can compose sentences that describe novel
objects and their interactions with other objects. We demonstrate our model's
ability to describe novel concepts by empirically evaluating its performance on
MSCOCO and show qualitative results on ImageNet images of objects for which no
paired image-caption data exist. Further, we extend our approach to generate
descriptions of objects in video clips. Our results show that DCC has distinct
advantages over existing image and video captioning approaches for generating
descriptions of new objects in context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05286</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05286</id><created>2015-11-17</created><authors><author><keyname>Kraus</keyname><forenames>Oren Z.</forenames></author><author><keyname>Ba</keyname><forenames>Lei Jimmy</forenames></author><author><keyname>Frey</keyname><forenames>Brendan</forenames></author></authors><title>Classifying and Segmenting Microscopy Images Using Convolutional
  Multiple Instance Learning</title><categories>cs.CV q-bio.SC stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional neural networks (CNN) have achieved state of the art
performance on both classification and segmentation tasks. Applying CNNs to
microscopy images is challenging due to the lack of datasets labeled at the
single cell level. We extend the application of CNNs to microscopy image
classification and segmentation using multiple instance learning (MIL). We
present the adaptive Noisy-AND MIL pooling function, a new MIL operator that is
robust to outliers. Combining CNNs with MIL enables training CNNs using full
resolution microscopy images with global labels. We base our approach on the
similarity between the aggregation function used in MIL and pooling layers used
in CNNs. We show that training MIL CNNs end-to-end outperforms several previous
methods on both mammalian and yeast microscopy images without requiring any
segmentation steps.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05292</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05292</id><created>2015-11-17</created><updated>2015-11-23</updated><authors><author><keyname>Wang</keyname><forenames>Jinghua</forenames></author><author><keyname>Wang</keyname><forenames>Gang</forenames></author></authors><title>Hierarchical Spatial Sum-Product Networks for action recognition in
  Still Images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recognizing actions from still images is popularly studied recently. In this
paper, we model an action class as a flexible number of spatial configurations
of body parts by proposing a new spatial SPN (Sum-Product Networks). First, we
discover a set of parts in image collections via unsupervised learning. Then,
our new spatial SPN is applied to model the spatial relationship and also the
high-order correlations of parts. To learn robust networks, we further develop
a hierarchical spatial SPN method, which models pairwise spatial relationship
between parts inside sub-images and models the correlation of sub-images via
extra layers of SPN. Our method is shown to be effective on two benchmark
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05296</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05296</id><created>2015-11-17</created><updated>2015-11-23</updated><authors><author><keyname>Wang</keyname><forenames>Jinghua</forenames></author><author><keyname>Nabi</keyname><forenames>Abrar Abdul</forenames></author><author><keyname>Wang</keyname><forenames>Gang</forenames></author><author><keyname>Wan</keyname><forenames>Chengde</forenames></author><author><keyname>Ng</keyname><forenames>Tian-Tsong</forenames></author></authors><title>Towards Predicting the Likeability of Fashion Images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a method for ranking fashion images to find the
ones which might be liked by more people. We collect two new datasets from
image sharing websites (Pinterest and Polyvore). We represent fashion images
based on attributes: semantic attributes and data-driven attributes. To learn
semantic attributes from limited training data, we use an algorithm on
multi-task convolutional neural networks to share visual knowledge among
different semantic attribute categories. To discover data-driven attributes
unsupervisedly, we propose an algorithm to simultaneously discover visual
clusters and learn fashion-specific feature representations. Given attributes
as representations, we propose to learn a ranking SPN (sum product networks) to
rank pairs of fashion images. The proposed ranking SPN can capture the
high-order correlations of the attributes. We show the effectiveness of our
method on our two newly collected datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05297</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05297</id><created>2015-11-17</created><updated>2016-01-18</updated><authors><author><keyname>Ithapu</keyname><forenames>Vamsi K</forenames></author><author><keyname>Ravi</keyname><forenames>Sathya</forenames></author><author><keyname>Singh</keyname><forenames>Vikas</forenames></author></authors><title>On the interplay of network structure and gradient convergence in deep
  learning</title><categories>cs.LG stat.ML</categories><comments>Under review for iclr2016, additional experiments and some comments
  added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The regularization and output consistency behavior of dropout and layer-wise
pretraining for learning deep networks have been fairly well studied. However,
our understanding of how the asymptotic convergence of backpropagation in deep
architectures is related to the structural properties of the network and other
design choices (like denoising and dropout rate) is less clear at this time. An
interesting question one may ask is whether the network architecture and input
data statistics may guide the choices of learning parameters and vice versa. In
this work, we explore the association between such structural, distributional
and learnability aspects vis-\`a-vis their interaction with parameter
convergence rates. We present a framework to address these questions based on
the backpropagation convergence for general nonconvex objectives using
first-order information. This analysis suggests an interesting relationship
between feature denoising and dropout. Building upon the results, we obtain a
setup that provides systematic guidance regarding the choice of learning
parameters and network sizes that achieve a certain level of convergence (in
the optimization sense) often mediated by statistical attributes of the inputs.
Our results are supported by a set of experiments we conducted as well as
independent empirical observations reported by other groups in recent papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05298</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05298</id><created>2015-11-17</created><updated>2015-11-19</updated><authors><author><keyname>Jain</keyname><forenames>Ashesh</forenames></author><author><keyname>Zamir</keyname><forenames>Amir R.</forenames></author><author><keyname>Savarese</keyname><forenames>Silvio</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author></authors><title>Structural-RNN: Deep Learning on Spatio-Temporal Graphs</title><categories>cs.CV cs.LG cs.NE cs.RO</categories><comments>Video http://www.cs.stanford.edu/people/ashesh/srnn/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep Recurrent Neural Network architectures, though remarkably capable at
modeling sequences, lack an intuitive high-level spatio-temporal structure.
That is while many problems in computer vision inherently have an underlying
high-level structure and can benefit from it. Spatio-temporal graphs are a
popular flexible tool for imposing such high-level intuitions in the
formulation of real world problems. In this paper, we propose an approach for
combining the power of high-level spatio-temporal graphs and sequence learning
success of Recurrent Neural Networks (RNNs). We develop a scalable method for
casting an arbitrary spatio-temporal graph as a rich RNN mixture that is
feedforward, fully differentiable, and jointly trainable. The proposed method
is generic and principled as it can be used for transforming any
spatio-temporal graph through employing a certain set of well defined steps.
The evaluations of the proposed approach on a diverse set of problems, ranging
from modeling human motion to object interactions, shows improvement over the
state-of-the-art with a large margin. We expect this method to empower a new
convenient approach to problem formulation through high-level spatio-temporal
graphs and Recurrent Neural Networks, and be of broad interest to the
community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05300</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05300</id><created>2015-11-17</created><authors><author><keyname>Li</keyname><forenames>Shengli</forenames></author><author><keyname>Zhou</keyname><forenames>Xichuan</forenames></author></authors><title>Research of the Correlation between the H1N1 Morbidity Data and Google
  Trends in Egypt</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The search engine based on influenza monitoring system has been widely
applied in many European and American countries. However, there are not any
correlative researches reported for African developing countries. Especially,
the countries Egypt has not designed an influenza monitoring system on the
basis of the Internet search data. This study aims at analyzing the correlation
between the Google search data and the H1N1 morbidity data of Egypt, and
examining the feasibility of Google Flu Model in predicting the H1N1 influenza
trend.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05318</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05318</id><created>2015-11-17</created><authors><author><keyname>Zhang</keyname><forenames>Lin</forenames></author><author><keyname>Stein</keyname><forenames>Manuel</forenames></author><author><keyname>Nossek</keyname><forenames>Josef A.</forenames></author></authors><title>Asymptotic Performance Analysis for 1-bit Bayesian Smoothing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy-efficient signal processing systems require estimation methods
operating on data collected with low-complexity devices. Using
analog-to-digital converters (ADC) with $1$-bit amplitude resolution has been
identified as a possible option in order to obtain low power consumption. The
$1$-bit performance loss, in comparison to an ideal receiver with $\infty$-bit
ADC, is well-established and moderate for low SNR applications ($2/\pi$ or
$-1.96$ dB). Recently it has been shown that for parameter estimation with
state-space models the $1$-bit performance loss with Bayesian filtering can be
significantly smaller ($\sqrt{2/\pi}$ or $-0.98$ dB). Here we extend the
analysis to Bayesian smoothing where additional measurements are used to
reconstruct the current state of the system parameter. Our results show that a
$1$-bit receiver performing smoothing is able to outperform an ideal
$\infty$-bit system carrying out filtering by the cost of an additional
processing delay $\Delta$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05324</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05324</id><created>2015-11-17</created><authors><author><keyname>Tsvetkova</keyname><forenames>Milena</forenames></author><author><keyname>Yasseri</keyname><forenames>Taha</forenames></author><author><keyname>Meyer</keyname><forenames>Eric T.</forenames></author><author><keyname>Pickering</keyname><forenames>J. Brian</forenames></author><author><keyname>Engen</keyname><forenames>Vegard</forenames></author><author><keyname>Walland</keyname><forenames>Paul</forenames></author><author><keyname>L&#xfc;ders</keyname><forenames>Marika</forenames></author><author><keyname>F&#xf8;lstad</keyname><forenames>Asbj&#xf8;rn</forenames></author><author><keyname>Bravos</keyname><forenames>George</forenames></author></authors><title>Understanding Human-Machine Networks: A Cross-Disciplinary Survey</title><categories>cs.SI cs.CY cs.HC</categories><comments>37 pages, 4 figures</comments><acm-class>A.1; C.2.4; H.1.2; J.4; K.6.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the current hyper-connected era, modern Information and Communication
Technology systems form sophisticated networks where not only do people
interact with other people, but also machines take an increasingly visible and
participatory role. Such human-machine networks (HMNs) are embedded in the
daily lives of people, both or personal and professional use. They can have a
significant impact by producing synergy and innovations.
  The challenge in designing successful HMNs is that they cannot be developed
and implemented in the same manner as networks of machines nodes alone, nor
following a wholly human-centric view of the network. The problem requires an
interdisciplinary approach. Here, we review current research of relevance to
HMNs across many disciplines. Extending the previous theoretical concepts of
socio-technical systems, actor-network theory, and social machines, we
concentrate on the interactions among humans and between humans and machines.
We identify eight types of HMNs: public-resource computing, crowdsourcing, web
search engines, crowdsensing, online markets, social media, multiplayer online
games and virtual worlds, and mass collaboration. We systematically select
literature on each of these types and review it with a focus on implications
for designing HMNs. Moreover, we discuss risks associated with HMNs and
identify emerging design and development trends.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05334</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05334</id><created>2015-11-17</created><authors><author><keyname>Grygiel</keyname><forenames>Katarzyna</forenames><affiliation>TCS</affiliation></author><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>TCS, LIP</affiliation></author></authors><title>Counting and Generating Terms in the Binary Lambda Calculus (Extended
  version)</title><categories>cs.LO</categories><comments>extended version of arXiv:1401.0379</comments><proxy>ccsd</proxy><journal-ref>J. Funct. Prog. 25 (2015) e24</journal-ref><doi>10.1017/S0956796815000271</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a paper entitled Binary lambda calculus and combinatory logic, John Tromp
presents a simple way of encoding lambda calculus terms as binary sequences. In
what follows, we study the numbers of binary strings of a given size that
represent lambda terms and derive results from their generating functions,
especially that the number of terms of size n grows roughly like 1.963447954.
.. n. In a second part we use this approach to generate random lambda terms
using Boltzmann samplers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05338</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05338</id><created>2015-11-17</created><authors><author><keyname>Porat</keyname><forenames>Idan</forenames></author><author><keyname>Benguigui</keyname><forenames>Lucien</forenames></author></authors><title>World Migration Degree Global migration flows in directed networks</title><categories>physics.soc-ph cs.SI</categories><comments>22 pages 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we analyze the global flow of migrants from 206 source
countries to 145 destination countries (2006-2010) and focus on the differences
in the migration network pattern between destination and source counters as
represented by its degree and weight distribution. Degree represents the
connectivity of a country to the global migration network, and plays an
important role in defining migration processes and characteristics. Global
analysis of migration degree distribution offers a strong potential
contribution to understanding of migration as a global phenomenon. In regard to
immigration, we found that it is possible to classify destination countries
into three classes: global migration hubs with high connectivity and high
migration rate; local migration hubs with low connectivity and high migration
rate; and local migration hubs with opposite strategy of high connectivity and
low migration rate. The different migration strategies of destination countries
are emerging from similar and homogenies pattern of emigration from source
countries were similar network patterns were found for most of the countries.
These findings, of similar behavior which creates different results is a
complex phenomenon which represents the diverse nature of migration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05341</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05341</id><created>2015-11-17</created><authors><author><keyname>Cao</keyname><forenames>Zhengjun</forenames></author><author><keyname>Liu</keyname><forenames>Lihua</forenames></author></authors><title>On the Weakness of Fully Homomorphic Encryption</title><categories>cs.CR</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fully homomorphic encryption (FHE) allows anyone to perform computations on
encrypted data, despite not having the secret decryption key. Since the
Gentry's work in 2009, the primitive has interested many researchers. In this
paper, we stress that any computations performed on encrypted data are
constrained to the encrypted domain (finite fields or rings). This restriction
makes the primitive useless for most computations involving common arithmetic
expressions and relational expressions. It is only applicable to the
computations related to modular arithmetic. We want to reaffirm that
cryptography uses modular arithmetic a lot in order to obscure and dissipate
the redundancies in a plaintext message, not to perform any numerical
calculations. We think it might be an overstated claim that FHE is of great
importance to client-server computing or cloud computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05357</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05357</id><created>2015-11-17</created><authors><author><keyname>Wu</keyname><forenames>Xiaofu</forenames></author><author><keyname>Yang</keyname><forenames>Zhen</forenames></author><author><keyname>Ling</keyname><forenames>Cong</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author></authors><title>Artificial-Noise-Aided Message Authentication Codes with
  Information-Theoretic Security</title><categories>cs.IT cs.CR math.IT</categories><comments>12 pages, 4 figures, submitted for possible publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past, two main approaches for the purpose of authentication, including
information-theoretic authentication codes and complexity-theoretic message
authentication codes (MACs), were almost independently developed. In this
paper, we propose a new cryptographic primitive, namely, artificial-noise-aided
MACs (ANA-MACs), which can be considered as both computationally secure and
information-theoretically secure. For ANA-MACs, we introduce artificial noise
to interfere with the complexity-theoretic MACs and quantization is further
employed to facilitate packet-based transmission. With a channel coding
formulation of key recovery in the MACs, the generation of standard
authentication tags can be seen as an encoding process for the ensemble of
codes, where the shared key between Alice and Bob is considered as the input
and the message is used to specify a code from the ensemble of codes. Then, we
show that the introduction of artificial noise in ANA-MACs can be well employed
to resist the key recovery attack even if the opponent has an unlimited
computing power. Finally, a pragmatic approach for the analysis of ANA-MACs is
provided, and we show how to balance the three performance metrics, including
the completeness error, the false acceptance probability, and the conditional
equivocation about the key. The analysis can be well applied to a class of
ANA-MACs, where MACs with Rijndael cipher are employed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05358</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05358</id><created>2015-11-17</created><authors><author><keyname>Rumpe</keyname><forenames>Bernhard</forenames></author><author><keyname>Schulze</keyname><forenames>Christoph</forenames></author><author><keyname>von Wenckstern</keyname><forenames>Michael</forenames></author><author><keyname>Ringert</keyname><forenames>Jan Oliver</forenames></author><author><keyname>Manhart</keyname><forenames>Peter</forenames></author></authors><title>Behavioral Compatibility of Simulink Models for Product Line Maintenance
  and Evolution</title><categories>cs.SE</categories><comments>10 pages, 12 figures, 4 tables, Proceedings of the 19th International
  Conference on Software Product Line (SPLC)</comments><doi>10.1145/2791060.2791077</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Embedded software systems, e.g. automotive, robotic or automation systems are
highly configurable and consist of many software components being available in
different variants and versions. To identify the degree of reusability between
these different occurrences of a component, it is necessary to determine the
functional backward and forward compatibility between them. Based on this
information it is possible to identify in which system context a component can
be replaced safely by another version, e.g. exchanging an older component, or
variant, e.g. introducing new features, to achieve the same functionality. This
paper presents a model checking approach to determine behavioral compatibility
of Simulink models, obtained from different component variants or during
evolution. A prototype for automated compatibility checking demonstrates its
feasibility. In addition implemented optimizations make the analysis more
efficient, when the compared variants or versions are structurally similar. A
case study on a driver assistance system provided by Daimler AG shows the
effectiveness of the approach to automatically compare Simulink components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05359</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05359</id><created>2015-11-17</created><authors><author><keyname>Zidane</keyname><forenames>Karine</forenames></author><author><keyname>Lacan</keyname><forenames>J&#xe9;rome</forenames></author><author><keyname>Gineste</keyname><forenames>Mathieu</forenames></author><author><keyname>Bes</keyname><forenames>Caroline</forenames></author><author><keyname>Deramecourt</keyname><forenames>Arnaud</forenames></author><author><keyname>Dervin</keyname><forenames>Mathieu</forenames></author></authors><title>Performance Evaluation of MARSALA with Synchronisation Errors in
  Satellite Communications</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-replicA decoding using correlation baSed LocAlisAtion (MARSALA) is a
recent random access method for satellite communications. It follows the
multiple transmission and interference cancellation scheme of Contention
Resolution Diversity Slotted Aloha (CRDSA). Besides, at the receiver side,
MARSALA uses autocorrelation to localise replicas of a same packet so as to
combine them. This signal combination increases the decoding probability of the
packet, especially in case of collisions. Previous work has shown good
performance of MARSALA with an assumption of perfect signal combination.
However, phase and timing parameters are unknown at the receiver and they are
different for the replicas on separate time slots . In this paper, we describe
a method to estimate and compensate the timing and phase differences between
the replicas prior to signal combination. We also propose to enhance the signal
combination by using the principle of Maximum Ratio Combining (MRC). Then, we
evaluate the impact of synchronisation errors on MARSALA using our estimation
method. We also assess the performance gain achieved with MRC. Finally we
compare the performance of MARSALA and CRDSA in various scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05362</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05362</id><created>2015-11-17</created><updated>2015-11-18</updated><authors><author><keyname>Li</keyname><forenames>Yujun</forenames></author><author><keyname>Mo</keyname><forenames>Kaichun</forenames></author><author><keyname>Ye</keyname><forenames>Haishan</forenames></author></authors><title>Accelerating Random Kaczmarz Algorithm Based on Clustering Information</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kaczmarz algorithm is an efficient iterative algorithm to solve
overdetermined consistent system of linear equations. During each updating
step, Kaczmarz chooses a hyperplane based on an individual equation and
projects the current estimate for the exact solution onto that space to get a
new estimate. Many vairants of Kaczmarz algorithms are proposed on how to
choose better hyperplanes. Using the property of randomly sampled data in
high-dimensional space, we propose an accelerated algorithm based on clustering
information to improve block Kaczmarz and Kaczmarz via Johnson-Lindenstrauss
lemma. Additionally, we theoretically demonstrate convergence improvement on
block Kaczmarz algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05363</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05363</id><created>2015-11-17</created><authors><author><keyname>Reijsbergen</keyname><forenames>Dani&#xeb;l</forenames></author><author><keyname>Ratan</keyname><forenames>Rajeev</forenames></author></authors><title>Probabilistic Modelling of the Impact on Bus Punctuality of a Speed
  Limit Proposal in Edinburgh (Extended Version)</title><categories>cs.CY cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a data-driven methodology for evaluating the impact of the
introduction of a speed limit on the punctuality of bus services. In
particular, we use high-frequency Automatic Vehicle Location data to
parameterise a model that represents the movement of a bus along predefined
patches of the route. We fit the probability distributions of the time spent in
each patch to two classes of probability distributions: hyper-Erlang
distributions, for which we use the tool HyperStar, and a variation of the
three-parameter gamma distributions recommended by the Traffic Engineering
Handbook. In both cases we obtain models that can be expressed using the
framework of Probabilistic Timed Automata, allowing us to evaluate bus
punctuality using the model checking tool UPPAAL. We conduct a case study
involving a proposed speed limit in Edinburgh. This is an extended version of a
paper presented at ValueTools 2015.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05364</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05364</id><created>2015-11-17</created><authors><author><keyname>Ringert</keyname><forenames>Jan O.</forenames></author><author><keyname>Rumpe</keyname><forenames>Bernhard</forenames></author><author><keyname>Wortmann</keyname><forenames>Andreas</forenames></author></authors><title>Tailoring the MontiArcAutomaton Component &amp; Connector ADL for Generative
  Development</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Component&amp;connector (C&amp;C) architecture description languages (ADLs) combine
component-based software engineering and model-driven engineering to increase
reuse and to abstract from implementation details. Applied to robotics
application development, current C&amp;C ADLs often require domain experts to
provide component behavior descriptions as programming language artifacts or as
models of a-priori mixed behavior modeling languages. They are limited to
specific target platforms or require extensive handcrafting to transform
platform-independent software architecture models into platform-specific
implementations. We have developed the MontiArcAutomaton framework that
combines structural extension of C&amp;C concepts with integration of
application-specific component behavior modeling languages, seamless
transformation from logical into platform-specific software architectures, and
a-posteriori black-box composition of code generators for different robotics
platforms. This paper describes the roles and activities for tailoring
MontiArcAutomaton to application-specific demands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05365</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05365</id><created>2015-11-17</created><authors><author><keyname>Ringert</keyname><forenames>Jan O.</forenames></author><author><keyname>Rumpe</keyname><forenames>Bernhard</forenames></author><author><keyname>Wortmann</keyname><forenames>Andreas</forenames></author></authors><title>Transforming Platform-Independent to Platform-Specific Component and
  Connector Software Architecture Models</title><categories>cs.SE</categories><comments>6 pages, 4 figures, 2 listings 2nd International Workshop on
  Model-Driven Engineering for Component-Based Software Systems (ModComp)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Combining component &amp; connector architecture
descriptionlanguageswithcomponentbehaviormodelinglanguages enables modeling
great parts of software architectures platformindependently. Nontrivial systems
typically contain components with programming language behavior descriptions to
interface with APIs. These components tie the complete software architecture to
a specific platform and thus hamper reuse. Previous work on software
architecture reuse with multiple platforms either requires platform-specific
handcrafting or the effort of explicit platform models. We present an automated
approach to transform platform-independent, logical software architectures into
architectures with platform-specific components. This approach introduces
abstract components to the platform-independent architecture and refines the se
with components specific to the target platform prior to code generation.
Consequently, a single logical software architecture model can be reused with
multiple target platforms, which increases architecture maturity and reduces
the maintenance effort of multiple similar software architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05366</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05366</id><created>2015-11-17</created><authors><author><keyname>H&#xf6;lldobler</keyname><forenames>Katrin</forenames></author><author><keyname>Weisem&#xf6;ller</keyname><forenames>Bernhard Rumpe Ingo</forenames></author></authors><title>Systematically Deriving Domain-Specific Transformation Languages</title><categories>cs.SE</categories><comments>10 listings, 1 figure, Conference on Model Driven Engineering
  Languages and Systems (MODELS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model transformations are helpful to evolve, refactor, refine and maintain
models. While domain-specific languages are normally intuitive for modelers,
common model transformation approaches (regardless of whether they transform
graphical or textual models) are based on the modeling language's abstract
syntax requiring the modeler to learn the internal representation of the model
to describe transformations. This paper presents a process that allows to
systematically derive a textual domainspecific transformation language from the
grammar of a given textual modeling language. As example, we apply this
systematic derivation to UML class diagrams to obtain a domain-specific
transformation language called CDTrans. CDTrans incorporates the concrete
syntax of class diagrams which is already familiar to the modeler and extends
it with a few transformation operators. To demonstrate the usefulness of the
derived transformation language, we describe several refactoring
transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05371</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05371</id><created>2015-11-17</created><authors><author><keyname>Schneider</keyname><forenames>Markus</forenames></author><author><keyname>Ertel</keyname><forenames>Wolfgang</forenames></author><author><keyname>Palm</keyname><forenames>G&#xfc;nther</forenames></author></authors><title>Constant Time EXPected Similarity Estimation using Stochastic
  Optimization</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new algorithm named EXPected Similarity Estimation (EXPoSE) was recently
proposed to solve the problem of large-scale anomaly detection. It is a
non-parametric and distribution free kernel method based on the Hilbert space
embedding of probability measures. Given a dataset of $n$ samples, EXPoSE needs
only $\mathcal{O}(n)$ (linear time) to build a model and $\mathcal{O}(1)$
(constant time) to make a prediction. In this work we improve the linear
computational complexity and show that an $\epsilon$-accurate model can be
estimated in constant time, which has significant implications for large-scale
learning problems. To achieve this goal, we cast the original EXPoSE
formulation into a stochastic optimization problem. It is crucial that this
approach allows us to determine the number of iteration based on a desired
accuracy $\epsilon$, independent of the dataset size $n$. We will show that the
proposed stochastic gradient descent algorithm works in general (possible
infinite-dimensional) Hilbert spaces, is easy to implement and requires no
additional step-size parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05384</identifier>
 <datestamp>2016-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05384</id><created>2015-11-17</created><authors><author><keyname>Bakalarski</keyname><forenames>S&#x142;awomir</forenames></author><author><keyname>Zygad&#x142;o</keyname><forenames>Jakub</forenames></author></authors><title>On path sequences of graphs</title><categories>math.CO cs.DM</categories><comments>10 pages, 3 tables; submitted to Schedae Informaticae</comments><msc-class>05C38, 68R10</msc-class><journal-ref>Schedae Informaticae, vol. 24 (2015), pp. 230-242</journal-ref><doi>10.4467/20838476SI.16.020.4361</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subset $S$ of vertices of a graph $G=(V,E)$ is called a $k$-path vertex
cover if every path on $k$ vertices in $G$ contains at least one vertex from
$S$. Denote by $\psi_k(G)$ the minimum cardinality of a $k$-path vertex cover
in $G$ and form a sequence
$\psi(G)=(\psi_1(G),\psi_2(G),\ldots,\psi_{|V|}(G))$, called the path sequence
of $G$. In this paper we prove necessary and sufficient conditions for two
integers to appear on fixed positions in $\psi(G)$. A complete list of all
possible path sequences (with multiplicities) for small connected graphs is
also given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05385</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05385</id><created>2015-11-17</created><authors><author><keyname>Ulmasov</keyname><forenames>Doniyor</forenames></author><author><keyname>Baroukh</keyname><forenames>Caroline</forenames></author><author><keyname>Chachuat</keyname><forenames>Benoit</forenames></author><author><keyname>Deisenroth</keyname><forenames>Marc Peter</forenames></author><author><keyname>Misener</keyname><forenames>Ruth</forenames></author></authors><title>Bayesian Optimization with Dimension Scheduling: Application to
  Biological Systems</title><categories>stat.ML cs.LG math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bayesian Optimization (BO) is a data-efficient method for global black-box
optimization of an expensive-to-evaluate fitness function. BO typically assumes
that computation cost of BO is cheap, but experiments are time consuming or
costly. In practice, this allows us to optimize ten or fewer critical
parameters in up to 1,000 experiments. But experiments may be less expensive
than BO methods assume: In some simulation models, we may be able to conduct
multiple thousands of experiments in a few hours, and the computational burden
of BO is no longer negligible compared to experimentation time. To address this
challenge we introduce a new Dimension Scheduling Algorithm (DSA), which
reduces the computational burden of BO for many experiments. The key idea is
that DSA optimizes the fitness function only along a small set of dimensions at
each iteration. This DSA strategy (1) reduces the necessary computation time,
(2) finds good solutions faster than the traditional BO method, and (3) can be
parallelized straightforwardly. We evaluate the DSA in the context of
optimizing parameters of dynamic models of microalgae metabolism and show
faster convergence than traditional BO.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05389</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05389</id><created>2015-11-17</created><updated>2016-03-01</updated><authors><author><keyname>Sheikh</keyname><forenames>Imran</forenames></author><author><keyname>Illina</keyname><forenames>Irina</forenames></author><author><keyname>Fohr</keyname><forenames>Dominique</forenames></author><author><keyname>Linar&#xe8;s</keyname><forenames>Georges</forenames></author></authors><title>Learning to retrieve out-of-vocabulary words in speech recognition</title><categories>cs.CL</categories><comments>Updated references, added appendix discussing more results; added
  more discussion, replaced simple phone search results with KWS results; added
  KWS results for both training phase, probably last update</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many Proper Names (PNs) are Out-Of-Vocabulary (OOV) words for speech
recognition systems used to process diachronic audio data. To help recovery of
the PNs missed by the system, relevant OOV PNs can be retrieved out of the many
OOVs by exploiting semantic context of the spoken content. In this paper, we
propose two neural network models targeted to retrieve OOV PNs relevant to an
audio document: (a) Document level Continuous Bag of Words (D-CBOW), (b)
Document level Continuous Bag of Weighted Words (D-CBOW2). Both these models
take document words as input and learn with an objective to maximise the
retrieval of co-occurring OOV PNs. With the D-CBOW2 model we propose a new
approach in which the input embedding layer is augmented with a context anchor
layer. This layer learns to assign importance to input words and has the
ability to capture (task specific) key-words in a bag-of-word neural network
model. With experiments on French broadcast news videos we show that these two
models outperform the baseline methods based on raw embeddings from LDA,
Skip-gram and Paragraph Vectors. Combining the D-CBOW and D-CBOW2 models gives
faster convergence during training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05392</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05392</id><created>2015-11-17</created><updated>2015-11-19</updated><authors><author><keyname>Nalisnick</keyname><forenames>Eric</forenames></author><author><keyname>Ravi</keyname><forenames>Sachin</forenames></author></authors><title>Infinite Dimensional Word Embeddings</title><categories>stat.ML cs.CL cs.LG</categories><comments>ICLR 2016 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a method for learning word embeddings with stochastic
dimensionality. Our Infinite Skip-Gram (iSG) model specifies an energy-based
joint distribution over a word vector, a context vector, and their
dimensionality. By employing the same techniques used to make the Infinite
Restricted Boltzmann Machine (Cote &amp; Larochelle, 2015) tractable, we define
vector dimensionality over a countably infinite domain, allowing vectors to
grow as needed during training. After training, we find that the distribution
over embedding dimensionality for a given word is highly interpretable and
leads to an elegant probabilistic mechanism for word sense induction. We show
qualitatively and quantitatively that the iSG produces parameter-efficient
representations that are robust to language's inherent ambiguity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05398</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05398</id><created>2015-11-17</created><authors><author><keyname>Araujo</keyname><forenames>Julio</forenames></author><author><keyname>Cezar</keyname><forenames>Alexandre A.</forenames></author><author><keyname>Silva</keyname><forenames>Ana</forenames></author></authors><title>On the Existence of Tree Backbones that Realize the Chromatic Number on
  a Backbone Coloring</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A proper $k$-coloring of a graph $G=(V,E)$ is a function $c: V(G)\to
\{1,\ldots,k\}$ such that $c(u)\neq c(v)$, for every $uv\in E(G)$. The
chromatic number $\chi(G)$ is the minimum $k$ such that there exists a proper
$k$-coloring of $G$. Given a spanning subgraph $H$ of $G$, a $q$-backbone
$k$-coloring of $(G,H)$ is a proper $k$-coloring $c$ of $V(G)$ such that
$\lvert c(u)-c(v)\rvert \ge q$, for every edge $uv\in E(H)$. The $q$-backbone
chromatic number $BBC_q(G,H)$ is the smallest $k$ for which there exists a
$q$-backbone $k$-coloring of $(G,H)$. In this work, we show that every
connected graph $G$ has a generating tree $T$ such that $BBC_q(G,T) =
\max\{\chi(G),\left\lceil\frac{\chi(G)}{2}\right\rceil+q\}$, and that this
value is the best possible.
  As a direct consequence, we get that every connected graph $G$ has a spanning
tree $T$ for which $BBC_2(G,T)=\chi(G)$, if $\chi(G)\ge 4$, or
$BBC_2(G,T)=\chi(G)+1$, otherwise. Thus, by applying the Four Color Theorem, we
have that every connected nonbipartite planar graph $G$ has a spanning tree $T$
such that $BBC_2(G,T)=4$. This settles a question by Wang, Bu, Montassier and
Raspaud (2012), and generalizes a number of previous partial results to their
question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05404</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05404</id><created>2015-11-17</created><authors><author><keyname>Vidmer</keyname><forenames>Alexandre</forenames></author><author><keyname>Zeng</keyname><forenames>An</forenames></author><author><keyname>Medo</keyname><forenames>Mat&#xfa;&#x161;</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Prediction in complex systems: the case of the international trade
  network</title><categories>physics.soc-ph cs.SI q-fin.TR</categories><journal-ref>Vidmer, A., Zeng, A., Medo, M., &amp; Zhang, Y. C. (2015). Prediction
  in complex systems: The case of the international trade network. Physica A:
  Statistical Mechanics and its Applications, 436, 188-199</journal-ref><doi>10.1016/j.physa.2015.05.057</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Predicting the future evolution of complex systems is one of the main
challenges in complexity science. Based on a current snapshot of a network,
link prediction algorithms aim to predict its future evolution. We apply here
link prediction algorithms to data on the international trade between
countries. This data can be represented as a complex network where links
connect countries with the products that they export. Link prediction
techniques based on heat and mass diffusion processes are employed to obtain
predictions for products exported in the future. These baseline predictions are
improved using a recent metric of country fitness and product similarity. The
overall best results are achieved with a newly developed metric of product
similarity which takes advantage of causality in the network evolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05410</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05410</id><created>2015-11-17</created><authors><author><keyname>Xiang</keyname><forenames>Lin</forenames></author><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Islam</keyname><forenames>Toufiqul</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Wong</keyname><forenames>Vincent W. S.</forenames></author></authors><title>Cross-Layer Optimization of Fast Video Delivery in Cache-Enabled
  Relaying Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>7 pages, 4 figures; accepted for presentation at IEEE Globecom, San
  Diego, CA, Dec. 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the cross-layer optimization of fast video delivery
and caching for minimization of the overall video delivery time in a two-hop
relaying network. The half-duplex relay nodes are equipped with both a cache
and a buffer which facilitate joint scheduling of fetching and delivery to
exploit the channel diversity for improving the overall delivery performance.
The fast delivery control is formulated as a two-stage functional non-convex
optimization problem. By exploiting the underlying convex and quasi-convex
structures, the problem can be solved exactly and efficiently by the developed
algorithm. Simulation results show that significant caching and buffering gains
can be achieved with the proposed framework, which translates into a reduction
of the overall video delivery time. Besides, a trade-off between caching and
buffering gains is unveiled.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05413</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05413</id><created>2015-11-17</created><authors><author><keyname>Cao</keyname><forenames>Yonglin</forenames></author><author><keyname>Cao</keyname><forenames>Yuan</forenames></author><author><keyname>Fu</keyname><forenames>Fang-Wei</forenames></author></authors><title>Cyclic codes over $\mathbb{F}_{2^m}[u]/\langle u^k\rangle$ of oddly even
  length</title><categories>cs.IT math.IT</categories><comments>AAECC-1522</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\mathbb{F}_{2^m}$ be a finite field of characteristic $2$ and
$R=\mathbb{F}_{2^m}[u]/\langle u^k\rangle=\mathbb{F}_{2^m}
+u\mathbb{F}_{2^m}+\ldots+u^{k-1}\mathbb{F}_{2^m}$ ($u^k=0$) where $k\in
\mathbb{Z}^{+}$ satisfies $k\geq 2$. For any odd positive integer $n$, it is
known that cyclic codes over $R$ of length $2n$ are identified with ideals of
the ring $R[x]/\langle x^{2n}-1\rangle$. In this paper, an explicit
representation for each cyclic code over $R$ of length $2n$ is provided and a
formula to count the number of codewords in each code is given. Then a formula
to calculate the number of cyclic codes over $R$ of length $2n$ is obtained.
Moreover, the dual code of each cyclic code and self-dual cyclic codes over $R$
of length $2n$ are investigated. (AAECC-1522)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05422</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05422</id><created>2015-11-17</created><authors><author><keyname>Campos</keyname><forenames>Victor</forenames></author><author><keyname>Silva</keyname><forenames>Ana</forenames></author></authors><title>Edge-b-coloring Trees</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A b-coloring of the vertices of a graph is a proper coloring where each color
class contains a vertex which is adjacent to at least one vertex in each other
color class. The b-chromatic number of $G$ is the maximum integer $b(G)$ for
which $G$ has a b-coloring with $b(G)$ colors. This problem was introduced by
Irving and Manlove in 1999, where they showed that computing $b(G)$ is
$\mathcal{NP}$-hard in general and polynomial-time solvable for trees. Since
then, a number of complexity results were shown, including NP-hardness results
for chordal graphs (Havet et. al., 2011) and line graphs (Campos et. al.,
2015). In this article, we present a polynomial time algorithm that solves the
problem restricted to claw-free block graphs, an important subclass of chordal
graphs and line graphs. This is equivalent to solving the edge coloring version
of the problem restricted to trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05427</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05427</id><created>2015-11-17</created><updated>2016-02-03</updated><authors><author><keyname>Allili</keyname><forenames>Madjid</forenames></author><author><keyname>Kaczynski</keyname><forenames>Tomasz</forenames></author><author><keyname>Landi</keyname><forenames>Claudia</forenames></author><author><keyname>Masoni</keyname><forenames>Filippo</forenames></author></authors><title>A New Matching Algorithm for Multidimensional Persistence</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An algorithm is presented that constructs an acyclic partial matching on the
cells of a given simplicial complex from a vector-valued function defined on
the vertices and extended to each simplex by taking the least common upper
bound of the values on its vertices. The resulting acyclic partial matching may
be used to construct a reduced filtered complex with the same multidimensional
persistent homology as the original simplicial complex filtered by the sublevel
sets of the function. Numerical tests show that in practical cases the rate of
reduction in the number of cells achieved by the algorithm is substantial. This
promises to be useful for the computation of multidimensional persistent
homology of simplicial complexes filtered by sublevel sets of vector-valued
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05432</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05432</id><created>2015-11-17</created><updated>2016-01-16</updated><authors><author><keyname>Shaham</keyname><forenames>Uri</forenames></author><author><keyname>Yamada</keyname><forenames>Yutaro</forenames></author><author><keyname>Negahban</keyname><forenames>Sahand</forenames></author></authors><title>Understanding Adversarial Training: Increasing Local Stability of Neural
  Nets through Robust Optimization</title><categories>stat.ML cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a general framework for increasing local stability of Artificial
Neural Nets (ANNs) using Robust Optimization (RO). We achieve this through an
alternating minimization-maximization procedure, in which the loss of the
network is minimized over perturbed examples that are generated at each
parameter update. We show that adversarial training of ANNs is in fact
robustification of the network optimization, and that our proposed framework
generalizes previous approaches for increasing local stability of ANNs.
Experimental results reveal that our approach increases the robustness of the
network to existing adversarial examples, while making it harder to generate
new ones. Furthermore, our algorithm improves the accuracy of the network also
on the original test data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05437</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05437</id><created>2015-11-17</created><updated>2015-11-26</updated><authors><author><keyname>Wang</keyname><forenames>Bo</forenames></author><author><keyname>Wang</keyname><forenames>Hanyu</forenames></author><author><keyname>Qi</keyname><forenames>Miao</forenames></author></authors><title>PPV modelling of memristor-based oscillator</title><categories>cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, we propose for the first time a method of abstracting the PPV
(Perturbation Projection Vector) characteristic of the up-to-date
memristor-based oscillators. Inspired from biological oscillators and its
characteristic named PRC (Phase Response Curve), we build a bridge between PRC
and PPV. This relationship is verified rigorously using the transistor level
simulation of Colpitts and ring oscillators, i.e., comparing the PPV converted
from PRC and the PPV obtained from accurate PSS+PXF simulation. Then we apply
this method to the PPV calculation of the memristor-based oscillator. By
keeping the phase dynamics of the oscillator and dropping the details of
voltage/current amplitude, the PPV modelling is highly efficient to describe
the phase dynamics due to the oscillator coupling, and will be very suitable
for the fast simulation of large scale oscillatory neural networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05440</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05440</id><created>2015-11-17</created><updated>2016-02-26</updated><authors><author><keyname>Mathieu</keyname><forenames>Michael</forenames></author><author><keyname>Couprie</keyname><forenames>Camille</forenames></author><author><keyname>LeCun</keyname><forenames>Yann</forenames></author></authors><title>Deep multi-scale video prediction beyond mean square error</title><categories>cs.LG cs.CV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning to predict future images from a video sequence involves the
construction of an internal representation that models the image evolution
accurately, and therefore, to some degree, its content and dynamics. This is
why pixel-space video prediction may be viewed as a promising avenue for
unsupervised feature learning. In addition, while optical flow has been a very
studied problem in computer vision for a long time, future frame prediction is
rarely approached. Still, many vision applications could benefit from the
knowledge of the next frames of videos, that does not require the complexity of
tracking every pixel trajectories. In this work, we train a convolutional
network to generate future frames given an input sequence. To deal with the
inherently blurry predictions obtained from the standard Mean Squared Error
(MSE) loss function, we propose three different and complementary feature
learning strategies: a multi-scale architecture, an adversarial training
method, and an image gradient difference loss function. We compare our
predictions to different published results based on recurrent neural networks
on the UCF101 dataset
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05449</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05449</id><created>2015-11-17</created><authors><author><keyname>Komusiewicz</keyname><forenames>Christian</forenames></author></authors><title>Tight Running Time Lower Bounds for Vertex Deletion Problems</title><categories>cs.DS cs.CC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The $\Pi$-Vertex Deletion problem has as input an undirected graph $G=(V,E)$
and an integer $k$ and asks whether there is a set of at most $k$ vertices that
can be deleted such that the resulting graph is a member of the graph class
$\Pi$. By a classic result of Lewis and Yannakakis [J. Comput. Syst. Sci. '80],
$\Pi$-Vertex Deletion is NP-hard for all hereditary properties $\Pi$. We adapt
the original NP-hardness construction to show that under the Exponential Time
Hypothesis (ETH) tight complexity results can be obtained. We show that
$\Pi$-Vertex Deletion does not admit a $2^{o(n)}$-time algorithm where $n$ is
the number of vertices in $G$. We also obtain a dichotomy for the number $m$ of
edges in the input graph: If $\Pi$ contains all independent sets, then there is
no $2^{o(m)}$-time algorithm for $\Pi$-Vertex Deletion. If there is a fixed
independent set that is not contained in $\Pi$, then $\Pi$-Vertex Deletion can
be solved in $2^{o(m)}$ time. Finally, we consider the special case that $G$ is
planar and obtain that $\Pi$-Vertex Deletion cannot be solved in
$2^{o(\sqrt{n})}$ time for all hereditary $\Pi$ containing and excluding
infinitely many planar graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05453</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05453</id><created>2015-11-17</created><authors><author><keyname>Johnson</keyname><forenames>Aaron</forenames></author><author><keyname>Jansen</keyname><forenames>Rob</forenames></author><author><keyname>Jaggard</keyname><forenames>Aaron D.</forenames></author><author><keyname>Feigenbaum</keyname><forenames>Joan</forenames></author><author><keyname>Syverson</keyname><forenames>Paul</forenames></author></authors><title>Avoiding The Man on the Wire: Improving Tor's Security with Trust-Aware
  Path Selection</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tor users are vulnerable to deanonymization by an adversary that can observe
some Tor relays or some parts of the network. We propose that users use trust
to choose paths through Tor that are less likely to be observed. We present a
system to model this trust as probability distributions on the location of the
user's adversaries. We propose the Trust-Aware Path Selection algorithm for Tor
that helps users avoid traffic-analysis attacks while still choosing paths that
could have been selected by many other users. We evaluate this algorithm in two
settings using a high-level map of Internet routing: (i) users try to avoid a
single global adversary that has an independent chance to control each
Autonomous System organization, Internet Exchange Point organization, and Tor
relay family, and (ii) users try to avoid deanonymization by any single
country. We also examine the performance of trust-aware path selection using
the Shadow Tor network simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05464</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05464</id><created>2015-11-17</created><authors><author><keyname>Colin</keyname><forenames>Igor</forenames></author><author><keyname>Bellet</keyname><forenames>Aur&#xe9;lien</forenames></author><author><keyname>Salmon</keyname><forenames>Joseph</forenames></author><author><keyname>Cl&#xe9;men&#xe7;on</keyname><forenames>St&#xe9;phan</forenames></author></authors><title>Extending Gossip Algorithms to Distributed Estimation of U-Statistics</title><categories>stat.ML cs.DC cs.LG cs.SY</categories><comments>to be presented at NIPS 2015</comments><msc-class>68Uxx, 62J15, 68Q32, 62-04,</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient and robust algorithms for decentralized estimation in networks are
essential to many distributed systems. Whereas distributed estimation of sample
mean statistics has been the subject of a good deal of attention, computation
of $U$-statistics, relying on more expensive averaging over pairs of
observations, is a less investigated area. Yet, such data functionals are
essential to describe global properties of a statistical population, with
important examples including Area Under the Curve, empirical variance, Gini
mean difference and within-cluster point scatter. This paper proposes new
synchronous and asynchronous randomized gossip algorithms which simultaneously
propagate data across the network and maintain local estimates of the
$U$-statistic of interest. We establish convergence rate bounds of $O(1/t)$ and
$O(\log t / t)$ for the synchronous and asynchronous cases respectively, where
$t$ is the number of iterations, with explicit data and network dependent
terms. Beyond favorable comparisons in terms of rate analysis, numerical
experiments provide empirical evidence the proposed algorithms surpasses the
previously introduced approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05479</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05479</id><created>2015-11-17</created><authors><author><keyname>Buchet</keyname><forenames>Micka&#xeb;l</forenames></author><author><keyname>Dey</keyname><forenames>Tamal K.</forenames></author><author><keyname>Wang</keyname><forenames>Jiayuan</forenames></author><author><keyname>Wang</keyname><forenames>Yusu</forenames></author></authors><title>Declutter and Resample: Towards parameter free denoising</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many data analysis applications the following scenario is commonplace: we
are given a point set that is supposed to sample a hidden ground truth $K$ in a
metric space, but it got corrupted with noise so that some of the data points
lie far away from $K$ creating outliers also termed as {\em ambient noise}. One
of the main goals of denoising algorithms is to eliminate such noise so that
the curated data lie within a bounded Hausdorff distance of $K$. Deconvolution
and thresholding, the two prevailing techniques for this problem suffer from
the difficulty that they burden the user with setting several parameters and/or
choosing an appropriate noise model while guaranteeing only asymptotic
convergence. Our goal is to lighten this burden as much as possible while
ensuring the theoretical guarantees in all cases. First, we show that there
exists an algorithm requiring only a single parameter under a sampling
condition that is not any more restrictive than the known prevailing models.
Under such sampling conditions, this parameter cannot be avoided. We present a
simple algorithm that avoids even this parameter by paying for it with a slight
strengthening of the sampling condition which is not unrealistic. We provide
some empirical evidence that our algorithms are effective in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05488</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05488</id><created>2015-11-17</created><authors><author><keyname>Blum</keyname><forenames>Christian</forenames></author><author><keyname>Hafner</keyname><forenames>Verena V.</forenames></author></authors><title>Active exploration of sensor networks from a robotics perspective</title><categories>cs.RO cs.AI cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional algorithms for robots who need to integrate into a wireless
network often focus on one specific task. In this work we want to develop
simple, adaptive and reusable algorithms for real world applications for this
scenario. Starting with the most basic task for mobile wireless network nodes,
finding the position of another node, we introduce an algorithm able to solve
this task. We then show how this algorithm can readily be employed to solve a
large number of other related tasks like finding the optimal position to bridge
two static network nodes. For this we first introduce a meta-algorithm inspired
by autonomous robot learning strategies and the concept of internal models
which yields a class of source seeking algorithms for mobile nodes. The
effectiveness of this algorithm is demonstrated in real world experiments using
a physical mobile robot and standard 802.11 wireless LAN in an office
environment. We also discuss the differences to conventional algorithms and
give the robotics perspective on this class of algorithms. Then we proceed to
show how more complex tasks, which might be encountered by mobile nodes, can be
encoded in the same framework and how the introduced algorithm can solve them.
These tasks can be direct (cross layer) optimization tasks or can also encode
more complex tasks like bridging two network nodes. We choose the bridging
scenario as an example, implemented on a real physical robot, and show how the
robot can solve it in a real world experiment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05490</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05490</id><created>2015-11-17</created><updated>2015-12-02</updated><authors><author><keyname>Cascone</keyname><forenames>Carmelo</forenames></author><author><keyname>Pollini</keyname><forenames>Luca</forenames></author><author><keyname>Sanvito</keyname><forenames>Davide</forenames></author><author><keyname>Capone</keyname><forenames>Antonio</forenames></author><author><keyname>Sans&#xf2;</keyname><forenames>Brunilde</forenames></author></authors><title>SPIDER: Fault Resilient SDN Pipeline with Recovery Delay Guarantees</title><categories>cs.NI</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When dealing with node or link failures in Software Defined Networking (SDN),
the network capability to establish an alternative path depends on controller
reachability and on the round trip times (RTTs) between controller and involved
switches. Moreover, current SDN data plane abstractions for failure detection
(e.g. OpenFlow &quot;Fast-failover&quot;) do not allow programmers to tweak switches'
detection mechanism, thus leaving SDN operators still relying on proprietary
management interfaces (when available) to achieve guaranteed detection and
recovery delays. We propose SPIDER, an OpenFlow-like pipeline design that
provides i) a detection mechanism based on switches' periodic link probing and
ii) fast reroute of traffic flows even in case of distant failures, regardless
of controller availability. SPIDER can be implemented using stateful data plane
abstractions such as OpenState or Open vSwitch, and it offers guaranteed short
(i.e. ms) failure detection and recovery delays, with a configurable trade off
between overhead and failover responsiveness. We present here the SPIDER
pipeline design, behavioral model, and analysis on flow tables' memory impact.
We also implemented and experimentally validated SPIDER using OpenState (an
OpenFlow 1.3 extension for stateful packet processing), showing numerical
results on its performance in terms of recovery latency and packet losses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05493</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05493</id><created>2015-11-17</created><updated>2015-11-19</updated><authors><author><keyname>Li</keyname><forenames>Yujia</forenames></author><author><keyname>Tarlow</keyname><forenames>Daniel</forenames></author><author><keyname>Brockschmidt</keyname><forenames>Marc</forenames></author><author><keyname>Zemel</keyname><forenames>Richard</forenames></author></authors><title>Gated Graph Sequence Neural Networks</title><categories>cs.LG cs.AI cs.NE stat.ML</categories><comments>Submitted as a conference paper to ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph-structured data appears frequently in domains including chemistry,
natural language semantics, social networks, and knowledge bases. In this work,
we study feature learning techniques for graph-structured inputs. Our starting
point is previous work on Graph Neural Networks (Scarselli et al., 2009), which
we modify to use gated recurrent units and modern optimization techniques and
then extend to output sequences. The result is a flexible and broadly useful
class of neural network models that has favorable inductive biases relative to
purely sequence-based models (e.g., LSTMs) when the problem is
graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and
graph algorithm learning tasks. We then show it achieves state-of-the-art
performance on a problem from program verification, in which subgraphs need to
be matched to abstract data structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05497</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05497</id><created>2015-11-17</created><authors><author><keyname>Srinivas</keyname><forenames>Suraj</forenames></author><author><keyname>Babu</keyname><forenames>R. Venkatesh</forenames></author></authors><title>Learning the Architecture of Deep Neural Networks</title><categories>cs.LG cs.CV cs.NE</categories><comments>ICLR 2016 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks with millions of parameters are at the heart of many
state of the art machine learning models today. However, recent works have
shown that models with much smaller number of parameters can also perform just
as well. In this work, we introduce the problem of architecture-learning, i.e;
learning the architecture of a neural network along with weights. We introduce
a new trainable parameter called tri-state ReLU, which helps in eliminating
unnecessary neurons. We also propose a smooth regularizer which encourages the
total number of neurons after elimination to be small. The resulting objective
is differentiable and simple to optimize. We experimentally validate our method
on both small and large networks, and show that it can learn models with a
considerably small number of parameters without affecting prediction accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05498</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05498</id><created>2015-11-17</created><authors><author><keyname>Kim</keyname><forenames>Joongheon</forenames></author><author><keyname>Ryu</keyname><forenames>Eun-Seok</forenames></author></authors><title>Feasibility Study of Stochastic Streaming with 4K UHD Video Traces</title><categories>cs.NI</categories><comments>Presented at the International Conference on ICT Convergence (ICTC),
  Jeju Island, Korea, 28 - 30 October 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper performs the feasibility study of stochastic video streaming
algorithms with up-to-date 4K ultra-high-definition (UHD) video traces. In
previous work, various stochastic video streaming algorithms were proposed
which maximize time-average video streaming quality subject to queue stability
based on the information of queue-backlog length. The performance improvements
with the stochastic video streaming algorithms were verified with traditional
MPEG test sequences; but there is no study how much the proposed stochastic
algorithm is better when we consider up-to-date 4K UHD video traces. Therefore,
this paper evaluates the stochastic streaming algorithms with 4K UHD video
traces; and verifies that the stochastic algorithms perform better than
queue-independent algorithms, as desired.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05499</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05499</id><created>2015-11-17</created><authors><author><keyname>Messai</keyname><forenames>Malek</forenames></author><author><keyname>Piemontese</keyname><forenames>Amina</forenames></author><author><keyname>Colavolpe</keyname><forenames>Giulio</forenames></author><author><keyname>Amis</keyname><forenames>Karine</forenames></author><author><keyname>Guilloud</keyname><forenames>Frederic</forenames></author></authors><title>Binary CPMs with Improved Spectral Efficiency</title><categories>cs.IT math.IT</categories><comments>This paper is accepted to be published as an IEEE Communication
  Letter</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design new continuous phase modulation (CPM) formats which are based on
the combination of a proper precoder with binary input and a ternary CPM. The
proposed precoder constrains the signal phase evolution in order to increase
the minimum Euclidean distance, and to limit the bandwidth expansion due to the
use of a ternary CPM. The resulting schemes are highly spectrally efficient and
outperform classical binary and quaternary formats in terms of coded and
uncoded performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05506</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05506</id><created>2015-11-17</created><authors><author><keyname>Chernodub</keyname><forenames>Artem</forenames></author><author><keyname>Dziuba</keyname><forenames>Dmitry</forenames></author></authors><title>Neurocontrol methods review</title><categories>cs.AI cs.RO</categories><comments>in Russian</comments><journal-ref>Problems in Systems Programming, 2011, No. 2, p. 79-94</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods of applying neural networks to control plants are considered. Methods
and schemes are described, their advantages and disadvantages are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05509</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05509</id><created>2015-11-17</created><updated>2015-11-18</updated><authors><author><keyname>Liu</keyname><forenames>Yang</forenames></author><author><keyname>Li</keyname><forenames>Jing</forenames></author><author><keyname>Xie</keyname><forenames>Kai</forenames></author></authors><title>Analysis of Performance of Linear Analog Codes</title><categories>cs.IT math.IT</categories><comments>This manuscript has been withdrawn since a new kind of nonlinear
  analog code is now being developed and the results of the linear analog codes
  in this paper will be included as parts of a new manuscript</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we carefully study the MSE performance of the linear analog
codes. We have derived a lower bound of the MSE performance under
Likelihood(ML) and Linear Minimal Mean Square Error(LMMSE) decoding criteria
respectively. It is proved in this essay that a kind of linear analog codes
called \emph {unitary codes} can simultaneously achieve both of these two
bounds. At the same time, we compare the obtained linear analog codes' MSE
bounds with the performance of some existing nonlinear codes. The results
showed that linear analog codes are actually not very satisfying and convinced
us that more concerns should be cast onto the nonlinear class in order to find
powerful analog codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05512</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05512</id><created>2015-11-17</created><authors><author><keyname>Jug</keyname><forenames>Florian</forenames></author><author><keyname>Levinkov</keyname><forenames>Evgeny</forenames></author><author><keyname>Blasse</keyname><forenames>Corinna</forenames></author><author><keyname>Myers</keyname><forenames>Eugene W.</forenames></author><author><keyname>Andres</keyname><forenames>Bjoern</forenames></author></authors><title>Moral Lineage Tracing</title><categories>cs.CV cs.DM</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lineage tracing, the tracking of living cells as they move and divide, is a
central problem in biological image analysis. Solutions, called lineage
forests, are key to understanding how the structure of multicellular organisms
emerges. We propose an integer linear program (ILP) whose feasible solutions
define a decomposition of each image in a sequence into cells (segmentation),
and a lineage forest of cells across images (tracing). Unlike previous
formulations, we do not constrain the set of decompositions, except by
contracting pixels to superpixels. The main challenge, as we show, is to
enforce the morality of lineages, i.e., the constraint that cells do not merge.
To enforce morality, we introduce path-cut inequalities. To find feasible
solutions of the NP-hard ILP, with certified bounds to the global optimum, we
define efficient separation procedures and apply these as part of a
branch-and-cut algorithm. We show the effectiveness of this approach by
analyzing feasible solutions for real microscopy data in terms of bounds and
run-time, and by their weighted edit distance to ground truth lineage forests
traced by humans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05514</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05514</id><created>2015-11-17</created><authors><author><keyname>Gottschalk</keyname><forenames>Corinna</forenames></author><author><keyname>Vygen</keyname><forenames>Jens</forenames></author></authors><title>Better $s$-$t$-Tours by Gao Trees</title><categories>cs.DM cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the $s$-$t$-path TSP: given a finite metric space with two
elements $s$ and $t$, we look for a path from $s$ to $t$ that contains all the
elements and has minimum total distance. We improve the approximation ratio for
this problem from 1.599 to 1.566. Like previous algorithms, we solve the
natural LP relaxation and represent an optimum solution $x^*$ as a convex
combination of spanning trees. Gao showed that there exists a spanning tree in
the support of $x^*$ that has only one edge in each narrow cut (i.e., each cut
$C$ with $x^*(C)&lt;2$). Our main theorem says that the spanning trees in the
convex combination can be chosen such that many of them are such &quot;Gao trees''.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05520</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05520</id><created>2015-11-17</created><authors><author><keyname>Li</keyname><forenames>Peter</forenames></author><author><keyname>Qian</keyname><forenames>Jiyuan</forenames></author><author><keyname>Wang</keyname><forenames>Tian</forenames></author></authors><title>Automatic Instrument Recognition in Polyphonic Music Using Convolutional
  Neural Networks</title><categories>cs.SD cs.IR cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional methods to tackle many music information retrieval tasks
typically follow a two-step architecture: feature engineering followed by a
simple learning algorithm. In these &quot;shallow&quot; architectures, feature
engineering and learning are typically disjoint and unrelated. Additionally,
feature engineering is difficult, and typically depends on extensive domain
expertise.
  In this paper, we present an application of convolutional neural networks for
the task of automatic musical instrument identification. In this model, feature
extraction and learning algorithms are trained together in an end-to-end
fashion. We show that a convolutional neural network trained on raw audio can
achieve performance surpassing traditional methods that rely on hand-crafted
features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05526</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05526</id><created>2015-11-17</created><authors><author><keyname>Wu</keyname><forenames>Zhengyang</forenames></author><author><keyname>Bansal</keyname><forenames>Mohit</forenames></author><author><keyname>Walter</keyname><forenames>Matthew R.</forenames></author></authors><title>Articulated Motion Learning via Visual and Lingual Signals</title><categories>cs.RO cs.CL cs.CV</categories><comments>Submitted to ICRA 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order for robots to operate effectively in homes and workplaces, they must
be able to manipulate the articulated objects common to environments built for
and by humans. Previous work learns kinematic models that prescribe this
manipulation from visual demonstrations. Lingual signals, such as natural
language descriptions and instructions, offer a complementary means of
conveying knowledge of such manipulation models and are suitable to a wide
range of interactions (e.g., remote manipulation). In this paper, we present a
multimodal learning framework that incorporates both visual and lingual
information to estimate the structure and parameters that define kinematic
models of articulated objects. The visual signal takes the form of an RGB-D
image stream that opportunistically captures object motion in an unprepared
scene. Accompanying natural language descriptions of the motion constitute the
lingual signal. We present a probabilistic language model that uses word
embeddings to associate lingual verbs with their corresponding kinematic
structures. By exploiting the complementary nature of the visual and lingual
input, our method infers correct kinematic structures for various multiple-part
objects on which the previous state-of-the-art, visual-only system fails. We
evaluate our multimodal learning framework on a dataset comprised of a variety
of household objects, and demonstrate a 36% improvement in model accuracy over
the vision-only baseline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05538</identifier>
 <datestamp>2016-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05538</id><created>2015-11-14</created><updated>2016-01-21</updated><authors><author><keyname>Xu</keyname><forenames>C.</forenames></author><author><keyname>Mudunuru</keyname><forenames>M. K.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author></authors><title>Material degradation due to moisture and temperature. Part 1:
  Mathematical model, analysis, and analytical solutions</title><categories>cond-mat.mtrl-sci cond-mat.soft cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mechanical response, serviceability, and load bearing capacity of
materials and structural components can be adversely affected due to external
stimuli, which include exposure to a corrosive chemical species, high
temperatures, temperature fluctuations (i.e., freezing-thawing), cyclic
mechanical loading, just to name a few. It is, therefore, of paramount
importance in several branches of engineering -- ranging from aerospace
engineering, civil engineering to biomedical engineering -- to have a
fundamental understanding of degradation of materials, as the materials in
these applications are often subjected to adverse environments. As a result of
recent advancements in material science, new materials like fiber-reinforced
polymers and multi-functional materials that exhibit high ductility have been
developed and widely used; for example, as infrastructural materials or in
medical devices (e.g., stents). The traditional small-strain approaches of
modeling these materials will not be adequate. In this paper, we study
degradation of materials due to an exposure to chemical species and temperature
under large-strain and large-deformations. In the first part of our research
work, we present a consistent mathematical model with firm thermodynamic
underpinning. We then obtain semi-analytical solutions of several canonical
problems to illustrate the nature of the quasi-static and unsteady behaviors of
degrading hyperelastic solids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05539</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05539</id><created>2015-11-17</created><authors><author><keyname>Wu</keyname><forenames>Qingqing</forenames></author><author><keyname>Tao</keyname><forenames>Meixia</forenames></author><author><keyname>Ng</keyname><forenames>Derrick Wing Kwan</forenames></author><author><keyname>Chen</keyname><forenames>Wen</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Energy-Efficient Resource Allocation for Wireless Powered Communication
  Networks</title><categories>cs.IT math.IT</categories><comments>Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a wireless powered communication network (WPCN), where
multiple users harvest energy from a dedicated power station and then
communicate with an information receiving station. Our goal is to investigate
the maximum achievable energy efficiency (EE) of the network via joint time
allocation and power control while taking into account the initial battery
energy of each user. We first study the EE maximization problem in the WPCN
without any system throughput requirement. We show that the EE maximization
problem for the WPCN can be cast into EE maximization problems for two
simplified networks via exploiting its special structure. For each problem, we
derive the optimal solution and provide the corresponding physical
interpretation, despite the non-convexity of the problems. Subsequently, we
study the EE maximization problem under a minimum system throughput constraint.
Exploiting fractional programming theory, we transform the resulting non-convex
problem into a standard convex optimization problem. This allows us to
characterize the optimal solution structure of joint time allocation and power
control and to derive an efficient iterative algorithm for obtaining the
optimal solution. Simulation results verify our theoretical findings and
demonstrate the effectiveness of the proposed joint time and power
optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05546</identifier>
 <datestamp>2015-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05546</id><created>2015-11-17</created><authors><author><keyname>Dell</keyname><forenames>Holger</forenames></author><author><keyname>Kim</keyname><forenames>Eun Jung</forenames></author><author><keyname>Lampis</keyname><forenames>Michael</forenames></author><author><keyname>Mitsou</keyname><forenames>Valia</forenames></author><author><keyname>M&#xf6;mke</keyname><forenames>Tobias</forenames></author></authors><title>Complexity and Approximability of Parameterized MAX-CSPs</title><categories>cs.CC cs.DS</categories><comments>Appeared in IPEC 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the optimization version of constraint satisfaction problems
(Max-CSPs) in the framework of parameterized complexity; the goal is to compute
the maximum fraction of constraints that can be satisfied simultaneously. In
standard CSPs, we want to decide whether this fraction equals one. The
parameters we investigate are structural measures, such as the treewidth or the
clique-width of the variable-constraint incidence graph of the CSP instance.
  We consider Max-CSPs with the constraint types AND, OR, PARITY, and MAJORITY,
and with various parameters k, and we attempt to fully classify them into the
following three cases:
  1. The exact optimum can be computed in FPT time.
  2. It is W[1]-hard to compute the exact optimum, but there is a randomized
FPT approximation scheme (FPTAS), which computes a $(1-\epsilon)$-approximation
in time $f(k,\epsilon)\cdot poly(n)$.
  3. There is no FPTAS unless FPT=W[1].
  For the corresponding standard CSPs, we establish FPT vs. W[1]-hardness
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05547</identifier>
 <datestamp>2015-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05547</id><created>2015-11-17</created><updated>2015-12-09</updated><authors><author><keyname>Sun</keyname><forenames>Baochen</forenames></author><author><keyname>Feng</keyname><forenames>Jiashi</forenames></author><author><keyname>Saenko</keyname><forenames>Kate</forenames></author></authors><title>Return of Frustratingly Easy Domain Adaptation</title><categories>cs.CV cs.AI cs.LG cs.NE</categories><comments>Fixed typos. Full paper to appear in AAAI-16. Extended Abstract of
  the full paper to appear in TASK-CV 2015 workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike human learning, machine learning often fails to handle changes between
training (source) and test (target) input distributions. Such domain shifts,
common in practical scenarios, severely damage the performance of conventional
machine learning methods. Supervised domain adaptation methods have been
proposed for the case when the target data have labels, including some that
perform very well despite being &quot;frustratingly easy&quot; to implement. However, in
practice, the target domain is often unlabeled, requiring unsupervised
adaptation. We propose a simple, effective, and efficient method for
unsupervised domain adaptation called CORrelation ALignment (CORAL). CORAL
minimizes domain shift by aligning the second-order statistics of source and
target distributions, without requiring any target labels. Even though it is
extraordinarily simple--it can be implemented in four lines of Matlab
code--CORAL performs remarkably well in extensive evaluations on standard
benchmark datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05552</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05552</id><created>2015-11-16</created><updated>2016-03-04</updated><authors><author><keyname>Chang</keyname><forenames>Andre Xian Ming</forenames></author><author><keyname>Martini</keyname><forenames>Berin</forenames></author><author><keyname>Culurciello</keyname><forenames>Eugenio</forenames></author></authors><title>Recurrent Neural Networks Hardware Implementation on FPGA</title><categories>cs.NE</categories><comments>7 pages, 8 figures, changed format, added figures, added references,
  modified introduction</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Recurrent Neural Networks (RNNs) have the ability to retain memory and learn
data sequences. Due to the recurrent nature of RNNs, it is sometimes hard to
parallelize all its computations on conventional hardware. CPUs do not
currently offer large parallelism, while GPUs offer limited parallelism due to
sequential components of RNN models. In this paper we present a hardware
implementation of Long-Short Term Memory (LSTM) recurrent network on the
programmable logic Zynq 7020 FPGA from Xilinx. We implemented a RNN with $2$
layers and $128$ hidden units in hardware and it has been tested using a
character level language model. The implementation is more than $21\times$
faster than the ARM CPU embedded on the Zynq 7020 FPGA. This work can
potentially evolve to a RNN co-processor for future mobile devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05578</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05578</id><created>2015-11-17</created><authors><author><keyname>Chan</keyname><forenames>Jennifer Y. H.</forenames></author><author><keyname>Leistedt</keyname><forenames>Boris</forenames></author><author><keyname>Kitching</keyname><forenames>Thomas D.</forenames></author><author><keyname>McEwen</keyname><forenames>Jason D.</forenames></author></authors><title>Second-Generation Curvelets on the Sphere</title><categories>cs.IT astro-ph.IM math.IT</categories><comments>10 pages, 7 figures, Code available at
  http://astro-informatics.github.io/s2let/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Curvelets are efficient to represent highly anisotropic signal content, such
as local linear and curvilinear structure. First-generation curvelets on the
sphere, however, suffered from blocking artefacts. We present a new second-
generation curvelet transform, where scale-discretised curvelets are
constructed directly on the sphere. Scale-discretised curvelets exhibit a
parabolic scaling relation, are well-localised in both spatial and harmonic
domains, support the exact analysis and synthesis of both scalar and spin
signals, and are free of blocking artefacts. We present fast algorithms to
compute the exact curvelet transform, reducing computational complexity from
$\mathcal{O}(L^5)$ to $\mathcal{O}(L^3\log_{2}{L})$ for signals band-limited at
$L$. The implementation of these algorithms is made publicly available.
Finally, we present an illustrative application demonstrating the effectiveness
of curvelets for representing directional curve-like features in natural
spherical images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05583</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05583</id><created>2015-11-17</created><authors><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Design of Massive-MIMO-NOMA with Limited Feedback</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter, a low-feedback non-orthogonal multiple access (NOMA) scheme
using massive multiple-input multiple-output (MIMO) transmission is proposed.
In particular, the proposed scheme can decompose a massive-MIMO-NOMA system
into multiple separated single-input single-output NOMA channels, and
analytical results are developed to evaluate the performance of the proposed
scheme for two scenarios, with perfect user ordering and with one-bit feedback,
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05585</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05585</id><created>2015-11-17</created><authors><author><keyname>Adjiashvili</keyname><forenames>David</forenames></author><author><keyname>Haus</keyname><forenames>Utz-Uwe</forenames></author><author><keyname>Tate</keyname><forenames>Adrian</forenames></author></authors><title>Model-Driven Automatic Tiling with Cache Associativity Lattices</title><categories>cs.PF</categories><acm-class>D.3.4; B.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional compiler optimization theory distinguishes three separate classes
of cache miss -- Cold, Conflict and Capacity. Tiling for cache is typically
guided by capacity miss counts. Models of cache function have not been
effectively used to guide cache tiling optimizations due to model error and
expense. Instead, heuristic or empirical approaches are used to select tilings.
We argue that conflict misses, traditionally neglected or seen as a small
constant effect, are the only fundamentally important cache miss category, that
they form a solid basis by which caches can become modellable, and that models
leaning on cache associatvity analysis can be used to generate cache performant
tilings. We develop a mathematical framework that expresses potential and
actual cache misses in associative caches using Associativity Lattices. We show
these lattices to possess two theoretical advantages over rectangular tiles --
volume maximization and miss regularity. We also show that to generate such
lattice tiles requires, unlike rectangular tiling, no explicit, expensive
lattice point counting. We also describe an implementation of our lattice
tiling approach, show that it can be used to give speedups of over 10x versus
unoptimized code, and despite currently only tiling for one level of cache, can
already be competitive with the aggressive compiler optimizations used in
general purposes compares such as GCC and Intel's ICC. We also show that the
tiling approach can lead to reasonable automatic parallelism when compared to
existing auto-threading compilers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05587</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05587</id><created>2015-11-17</created><authors><author><keyname>Lipi&#x144;ski</keyname><forenames>Zbigniew</forenames></author></authors><title>Maximum lifetime broadcasting problem in sensor networks</title><categories>cs.NI</categories><comments>11 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve the maximum lifetime problem for the point-to-point and
point-to-multipoint broadcast data transmission in one dimensional regular
sensor network. Based on the analytical solution of the problem for one
dimension we propose an algorithm solving the maximum lifetime broadcasting
problem for point-to-point data transmission for any dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05607</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05607</id><created>2015-11-17</created><updated>2015-11-20</updated><authors><author><keyname>Li</keyname><forenames>Min</forenames></author><author><keyname>Gaddam</keyname><forenames>Sudeep</forenames></author><author><keyname>Li</keyname><forenames>Xiaolin</forenames></author><author><keyname>Zhao</keyname><forenames>Yinan</forenames></author><author><keyname>Ma</keyname><forenames>Jingzhe</forenames></author><author><keyname>Ge</keyname><forenames>Jian</forenames></author></authors><title>Identifying the Absorption Bump with Deep Learning</title><categories>cs.CV cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The pervasive interstellar dust grains provide significant insights to
understand the formation and evolution of the stars, planetary systems, and the
galaxies, and may harbor the building blocks of life. One of the most effective
way to analyze the dust is via their interaction with the light from background
sources. The observed extinction curves and spectral features carry the size
and composition information of dust. The broad absorption bump at 2175 Angstrom
is the most prominent feature in the extinction curves. Traditionally,
statistical methods are applied to detect the existence of the absorption bump.
These methods require heavy preprocessing and the co-existence of other
reference features to alleviate the influence from the noises. In this paper,
we apply Deep Learning techniques to detect the broad absorption bump. We
demonstrate the key steps for training the selected models and their results.
The success of Deep Learning based method inspires us to generalize a common
methodology for broader science discovery problems. We present our on-going
work to build the DeepDis system for such kind of applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05610</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05610</id><created>2015-11-17</created><updated>2015-11-19</updated><authors><author><keyname>Manaffam</keyname><forenames>Saeed</forenames></author><author><keyname>Seyedi</keyname><forenames>Alireza</forenames></author><author><keyname>Vosoughi</keyname><forenames>Azadeh</forenames></author><author><keyname>Javidi</keyname><forenames>Tara</forenames></author></authors><title>Bounded Stability in Networked Systems with Parameter Mismatch and
  Adaptive Decentralized Estimation</title><categories>cs.SY</categories><comments>6 pages, 3 figures, Accepted and presented in IEEE Conference
  Allerton 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here, we study the ultimately bounded stability of network of mismatched
systems using Lyapunov direct method. The upper bound on the error of
oscillators from the center of the neighborhood is derived. Then the
performance of an adaptive compensation via decentralized control is analyzed.
Finally, the analytical results for a network of globally connected Lorenz
oscillators are verified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05612</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05612</id><created>2015-11-17</created><authors><author><keyname>Pan</keyname><forenames>Huimin</forenames></author><author><keyname>Liu</keyname><forenames>Jingchu</forenames></author><author><keyname>Zhou</keyname><forenames>Sheng</forenames></author><author><keyname>Niu</keyname><forenames>Zhisheng</forenames></author></authors><title>A Block Regression Model for Short-Term Mobile Traffic Forecasting</title><categories>cs.NI cs.LG</categories><comments>5 pages, 6 figures. IEEE/CIC ICCC'15</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate mobile traffic forecast is important for efficient network planning
and operations. However, existing traffic forecasting models have high
complexity, making the forecasting process slow and costly. In this paper, we
analyze some characteristics of mobile traffic such as periodicity, spatial
similarity and short term relativity. Based on these characteristics, we
propose a \emph{Block Regression} ({BR}) model for mobile traffic forecasting.
This model employs seasonal differentiation so as to take into account of the
temporally repetitive nature of mobile traffic. One of the key features of our
{BR} model lies in its low complexity since it constructs a single model for
all base stations. We evaluate the accuracy of {BR} model based on real traffic
data and compare it with the existing models. Results show that our {BR} model
offers equal accuracy to the existing models but has much less complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05616</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05616</id><created>2015-11-17</created><updated>2015-11-19</updated><authors><author><keyname>Hu</keyname><forenames>Hexiang</forenames></author><author><keyname>Zhou</keyname><forenames>Guang-Tong</forenames></author><author><keyname>Deng</keyname><forenames>Zhiwei</forenames></author><author><keyname>Liao</keyname><forenames>Zicheng</forenames></author><author><keyname>Mori</keyname><forenames>Greg</forenames></author></authors><title>Learning Structured Inference Neural Networks with Label Relations</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Images of scenes have various objects as well as abundant attributes, and
diverse levels of visual categorization are possible. A natural image could be
assigned with fine-grained labels that describe major components,
coarse-grained labels that depict high level abstraction or a set of labels
that reveal attributes. Such categorization at different concept layers can be
modeled with label graphs encoding label information. In this paper, we exploit
this rich information with a state-of-art deep learning framework, and propose
a generic structured model that leverages diverse label relations to improve
image classification performance. Our approach employs a novel stacked label
prediction neural network, capturing both inter-level and intra-level label
semantics. We evaluate our method on benchmark image datasets, and empirical
results illustrate the efficacy of our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05618</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05618</id><created>2015-11-17</created><authors><author><keyname>Leng</keyname><forenames>Bingjie</forenames></author><author><keyname>Liu</keyname><forenames>Jingchu</forenames></author><author><keyname>Pan</keyname><forenames>Huimin</forenames></author><author><keyname>Zhou</keyname><forenames>Sheng</forenames></author><author><keyname>Niu</keyname><forenames>Zhisheng</forenames></author></authors><title>Topic Model Based Behaviour Modeling and Clustering Analysis for
  Wireless Network Users</title><categories>cs.SI</categories><comments>6 pages, 6 figures. APCC'15</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  User behaviour analysis based on traffic log in wireless networks can be
beneficial to many fields in real life: not only for commercial purposes, but
also for improving network service quality and social management. We cluster
users into groups marked by the most frequently visited websites to find their
preferences. In this paper, we propose a user behaviour model based on Topic
Model from document classification problems. We use the logarithmic TF-IDF
(term frequency - inverse document frequency) weighing to form a
high-dimensional sparse feature matrix. Then we apply LSA (Latent semantic
analysis) to deduce the latent topic distribution and generate a
low-dimensional dense feature matrix. K-means++, which is a classic clustering
algorithm, is then applied to the dense feature matrix and several
interpretable user clusters are found. Moreover, by combining the clustering
results with additional demographical information, including age, gender, and
financial information, we are able to uncover more realistic implications from
the clustering results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05619</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05619</id><created>2015-11-17</created><authors><author><keyname>Scopatz</keyname><forenames>Anthony M.</forenames></author><author><keyname>Gidden</keyname><forenames>Matthew J.</forenames></author><author><keyname>Carlsen</keyname><forenames>Robert W.</forenames></author><author><keyname>Flanagan</keyname><forenames>Robert R.</forenames></author><author><keyname>Huff</keyname><forenames>Kathryn D.</forenames></author><author><keyname>McGarry</keyname><forenames>Meghan B.</forenames></author><author><keyname>Opotowsky</keyname><forenames>Arrielle C.</forenames></author><author><keyname>Rakhimov</keyname><forenames>Olzhas</forenames></author><author><keyname>Welch</keyname><forenames>Zach</forenames></author><author><keyname>Wilson</keyname><forenames>Paul P. H.</forenames></author></authors><title>Cyclus Archetypes</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The current state of nuclear fuel cycle simulation exists in highly
customized form. Satisfying a wide range of users requires model modularity
within such a tool. Cyclus is a fuel cycle simulator specifically designed to
combat the lack of adaptability of previous generations of simulators. This is
accomplished through an agent-based infrastructure and treating time
discretely. The Cyclus kernel was developed to allow for models, called
archetypes, of differing fidelity and function depending on need of the users.
To take advantage of this flexibility, a user must write an archetype for their
desired simulation if it does not yet exist within the Cyclus ecosystem. At
this stage, a user graduates to the title of archetype developer.
  Without automation, archetype development is difficult for the uninitiated.
This paper presents the framework developed for simplifying the writing of
archetypes: the Cyclus preprocessor, or cycpp. cycpp addresses the computer
science and software development aspects of archetype development that can be
addressed algorithmically, allowing the developer to focus on modeling the
physics, social policies, and economics. cycpp passes through the code three
times to perform the following tasks: normalizing the code via the C
preprocessor, accumulation of notations, and code generation. Not only does
this reduce the amount of code a developer must write by approximately an order
of magnitude, but the archetypes are automatically validated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05622</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05622</id><created>2015-11-17</created><updated>2015-11-23</updated><authors><author><keyname>Dauphin</keyname><forenames>Yann N.</forenames></author><author><keyname>Grangier</keyname><forenames>David</forenames></author></authors><title>Predicting distributions with Linearizing Belief Networks</title><categories>cs.LG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conditional belief networks introduce stochastic binary variables in neural
networks. Contrary to a classical neural network, a belief network can predict
more than the expected value of the output $Y$ given the input $X$. It can
predict a distribution of outputs $Y$ which is useful when an input can admit
multiple outputs whose average is not necessarily a valid answer. Such networks
are particularly relevant to inverse problem such as image prediction for
denoising, or text to speech. However, traditional sigmoid belief networks are
hard to train and are not suited to continuous problems. This work introduces a
new family of networks called linearizing belief nets or LBNs. A LBN decomposes
into a deep linear network where each linear unit can be turned on or off by
non-deterministic binary latent units. It is a universal approximator of
real-valued conditional distributions and can be trained using gradient
descent. Moreover, the linear pathways efficiently propagate continuous
information and they act as multiplicative skip-connections that help
optimization by removing gradient diffusion. This yields a model which trains
efficiently and improves the state-of-the-art on image denoising and facial
expression generation with the Toronto faces dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05625</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05625</id><created>2015-11-17</created><authors><author><keyname>de Souza</keyname><forenames>Murilo Zangari</forenames></author><author><keyname>Santana</keyname><forenames>Roberto</forenames></author><author><keyname>Pozo</keyname><forenames>Aurora Trinidad Ramirez</forenames></author><author><keyname>Mendiburu</keyname><forenames>Alexander</forenames></author></authors><title>MOEA/D-GM: Using probabilistic graphical models in MOEA/D for solving
  combinatorial optimization problems</title><categories>cs.NE</categories><comments>13 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolutionary algorithms based on modeling the statistical dependencies
(interactions) between the variables have been proposed to solve a wide range
of complex problems. These algorithms learn and sample probabilistic graphical
models able to encode and exploit the regularities of the problem. This paper
investigates the effect of using probabilistic modeling techniques as a way to
enhance the behavior of MOEA/D framework. MOEA/D is a decomposition based
evolutionary algorithm that decomposes a multi-objective optimization problem
(MOP) in a number of scalar single-objective subproblems and optimizes them in
a collaborative manner. MOEA/D framework has been widely used to solve several
MOPs. The proposed algorithm, MOEA/D using probabilistic Graphical Models
(MOEA/D-GM) is able to instantiate both univariate and multi-variate
probabilistic models for each subproblem. To validate the introduced framework
algorithm, an experimental study is conducted on a multi-objective version of
the deceptive function Trap5. The results show that the variant of the
framework (MOEA/D-Tree), where tree models are learned from the matrices of the
mutual information between the variables, is able to capture the structure of
the problem. MOEA/D-Tree is able to achieve significantly better results than
both MOEA/D using genetic operators and MOEA/D using univariate probability
models, in terms of the approximation to the true Pareto front.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05635</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05635</id><created>2015-11-17</created><authors><author><keyname>Liao</keyname><forenames>Zhibin</forenames></author><author><keyname>Carneiro</keyname><forenames>Gustavo</forenames></author></authors><title>Competitive Multi-scale Convolution</title><categories>cs.CV cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a new deep convolutional neural network (ConvNet)
module that promotes competition among a set of multi-scale convolutional
filters. This new module is inspired by the inception module, where we replace
the original collaborative pooling stage (consisting of a concatenation of the
multi-scale filter outputs) by a competitive pooling represented by a maxout
activation unit. This extension has the following two objectives: 1) the
selection of the maximum response among the multi-scale filters prevents filter
co-adaptation and allows the formation of multiple sub-networks within the same
model, which has been shown to facilitate the training of complex learning
problems; and 2) the maxout unit reduces the dimensionality of the outputs from
the multi-scale filters. We show that the use of our proposed module in typical
deep ConvNets produces classification results that are either better than or
comparable to the state of the art on the following benchmark datasets: MNIST,
CIFAR-10, CIFAR-100 and SVHN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05641</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05641</id><created>2015-11-17</created><updated>2016-01-07</updated><authors><author><keyname>Chen</keyname><forenames>Tianqi</forenames></author><author><keyname>Goodfellow</keyname><forenames>Ian</forenames></author><author><keyname>Shlens</keyname><forenames>Jonathon</forenames></author></authors><title>Net2Net: Accelerating Learning via Knowledge Transfer</title><categories>cs.LG</categories><comments>ICLR 2016 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce techniques for rapidly transferring the information stored in
one neural net into another neural net. The main purpose is to accelerate the
training of a significantly larger neural net. During real-world workflows, one
often trains very many different neural networks during the experimentation and
design process. This is a wasteful process in which each new model is trained
from scratch. Our Net2Net technique accelerates the experimentation process by
instantaneously transferring the knowledge from a previous network to each new
deeper or wider network. Our techniques are based on the concept of
function-preserving transformations between neural network specifications. This
differs from previous approaches to pre-training that altered the function
represented by a neural net when adding layers to it. Using our knowledge
transfer mechanism to add depth to Inception modules, we demonstrate a new
state of the art accuracy rating on the ImageNet dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05643</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05643</id><created>2015-11-17</created><authors><author><keyname>Hasan</keyname><forenames>Md Kamrul</forenames></author><author><keyname>Pal</keyname><forenames>Christopher J.</forenames></author></authors><title>A New Smooth Approximation to the Zero One Loss with a Probabilistic
  Interpretation</title><categories>cs.CV cs.AI cs.IR cs.LG</categories><comments>32 pages, 7 figures, 15 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine a new form of smooth approximation to the zero one loss in which
learning is performed using a reformulation of the widely used logistic
function. Our approach is based on using the posterior mean of a novel
generalized Beta-Bernoulli formulation. This leads to a generalized logistic
function that approximates the zero one loss, but retains a probabilistic
formulation conferring a number of useful properties. The approach is easily
generalized to kernel logistic regression and easily integrated into methods
for structured prediction. We present experiments in which we learn such models
using an optimization method consisting of a combination of gradient descent
and coordinate descent using localized grid search so as to escape from local
minima. Our experiments indicate that optimization quality is improved when
learning meta-parameters are themselves optimized using a validation set. Our
experiments show improved performance relative to widely used logistic and
hinge loss methods on a wide variety of problems ranging from standard UC
Irvine and libSVM evaluation datasets to product review predictions and a
visual information extraction task. We observe that the approach: 1) is more
robust to outliers compared to the logistic and hinge losses; 2) outperforms
comparable logistic and max margin models on larger scale benchmark problems;
3) when combined with Gaussian- Laplacian mixture prior on parameters the
kernelized version of our formulation yields sparser solutions than Support
Vector Machine classifiers; and 4) when integrated into a probabilistic
structured prediction technique our approach provides more accurate
probabilities yielding improved inference and increasing information extraction
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05644</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05644</id><created>2015-11-17</created><authors><author><keyname>Makhzani</keyname><forenames>Alireza</forenames></author><author><keyname>Shlens</keyname><forenames>Jonathon</forenames></author><author><keyname>Jaitly</keyname><forenames>Navdeep</forenames></author><author><keyname>Goodfellow</keyname><forenames>Ian</forenames></author></authors><title>Adversarial Autoencoders</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a new method for regularizing autoencoders by
imposing an arbitrary prior on the latent representation of the autoencoder.
Our method, named &quot;adversarial autoencoder&quot;, uses the recently proposed
generative adversarial networks (GAN) in order to match the aggregated
posterior of the hidden code vector of the autoencoder with an arbitrary prior.
Matching the aggregated posterior to the prior ensures that there are no
&quot;holes&quot; in the prior, and generating from any part of prior space results in
meaningful samples. As a result, the decoder of the adversarial autoencoder
learns a deep generative model that maps the imposed prior to the data
distribution. We show how adversarial autoencoders can be used to disentangle
style and content of images and achieve competitive generative performance on
MNIST, Street View House Numbers and Toronto Face datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05646</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05646</id><created>2015-11-17</created><authors><author><keyname>Cohen-Addad</keyname><forenames>Vincent</forenames></author><author><keyname>Eden</keyname><forenames>Alon</forenames></author><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Fiat</keyname><forenames>Amos</forenames></author></authors><title>The Invisible Hand of Dynamic Market Pricing</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Walrasian prices, if they exist, have the property that one can assign every
buyer some bundle in her demand set, such that the resulting assignment will
maximize social welfare. Unfortunately, this assumes carefully breaking ties
amongst different bundles in the buyer demand set. Presumably, the shopkeeper
cleverly convinces the buyer to break ties in a manner consistent with
maximizing social welfare. Lacking such a shopkeeper, if buyers arrive
sequentially and simply choose some arbitrary bundle in their demand set, the
social welfare may be arbitrarily bad. In the context of matching markets, we
show how to compute dynamic prices, based upon the current inventory, that
guarantee that social welfare is maximized. Such prices are set without knowing
the identity of the next buyer to arrive. We also show that this is impossible
in general (e.g., for coverage valuations), but consider other scenarios where
this can be done.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05650</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05650</id><created>2015-11-17</created><authors><author><keyname>Lee</keyname><forenames>Juho</forenames></author><author><keyname>Choi</keyname><forenames>Seungjin</forenames></author></authors><title>Tree-Guided MCMC Inference for Normalized Random Measure Mixture Models</title><categories>stat.ML cs.LG</categories><comments>12 pages, 10 figures, NIPS-2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normalized random measures (NRMs) provide a broad class of discrete random
measures that are often used as priors for Bayesian nonparametric models.
Dirichlet process is a well-known example of NRMs. Most of posterior inference
methods for NRM mixture models rely on MCMC methods since they are easy to
implement and their convergence is well studied. However, MCMC often suffers
from slow convergence when the acceptance rate is low. Tree-based inference is
an alternative deterministic posterior inference method, where Bayesian
hierarchical clustering (BHC) or incremental Bayesian hierarchical clustering
(IBHC) have been developed for DP or NRM mixture (NRMM) models, respectively.
Although IBHC is a promising method for posterior inference for NRMM models due
to its efficiency and applicability to online inference, its convergence is not
guaranteed since it uses heuristics that simply selects the best solution after
multiple trials are made. In this paper, we present a hybrid inference
algorithm for NRMM models, which combines the merits of both MCMC and IBHC.
Trees built by IBHC outlines partitions of data, which guides
Metropolis-Hastings procedure to employ appropriate proposals. Inheriting the
nature of MCMC, our tree-guided MCMC (tgMCMC) is guaranteed to converge, and
enjoys the fast convergence thanks to the effective proposals guided by trees.
Experiments on both synthetic and real-world datasets demonstrate the benefit
of our method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05653</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05653</id><created>2015-11-17</created><updated>2015-11-19</updated><authors><author><keyname>Arora</keyname><forenames>Sanjeev</forenames></author><author><keyname>Liang</keyname><forenames>Yingyu</forenames></author><author><keyname>Ma</keyname><forenames>Tengyu</forenames></author></authors><title>Why are deep nets reversible: A simple theory, with implications for
  training</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generative models for deep learning are promising both to improve
understanding of the model, and yield training methods requiring fewer labeled
samples.
  Recent works use generative model approaches to produce the deep net's input
given the value of a hidden layer several levels above. However, there is no
accompanying &quot;proof of correctness&quot; for the generative model, showing that the
feedforward deep net is the correct inference method for recovering the hidden
layer given the input. Furthermore, these models are complicated.
  The current paper takes a more theoretical tack. It presents a very simple
generative model for RELU deep nets, with the following characteristics: (i)
The generative model is just the reverse of the feedforward net: if the forward
transformation at a layer is $A$ then the reverse transformation is $A^T$.
(This can be seen as an explanation of the old weight tying idea for denoising
autoencoders.) (ii) Its correctness can be proven under a clean theoretical
assumption: the edge weights in real-life deep nets behave like random numbers.
Under this assumption ---which is experimentally tested on real-life nets like
AlexNet--- it is formally proved that feed forward net is a correct inference
method for recovering the hidden layer.
  The generative model suggests a simple modification for training: use the
generative model to produce synthetic data with labels and include it in the
training set. Experiments are shown to support this theory of random-like deep
nets; and that it helps the training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05659</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05659</id><created>2015-11-18</created><authors><author><keyname>Jiang</keyname><forenames>Aiwen</forenames></author><author><keyname>Li</keyname><forenames>Hanxi</forenames></author><author><keyname>Li</keyname><forenames>Yi</forenames></author><author><keyname>Wang</keyname><forenames>Mingwen</forenames></author></authors><title>Learning Discriminative Representations for Semantic Cross Media
  Retrieval</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous gap among different modalities emerges as one of the critical
issues in modern AI problems. Unlike traditional uni-modal cases, where raw
features are extracted and directly measured, the heterogeneous nature of cross
modal tasks requires the intrinsic semantic representation to be compared in a
unified framework. This paper studies the learning of different representations
that can be retrieved across different modality contents. A novel approach for
mining cross-modal representations is proposed by incorporating explicit linear
semantic projecting in Hilbert space. The insight is that the discriminative
structures of different modality data can be linearly represented in
appropriate high dimension Hilbert spaces, where linear operations can be used
to approximate nonlinear decisions in the original spaces. As a result, an
efficient linear semantic down mapping is jointly learned for multimodal data,
leading to a common space where they can be compared. The mechanism of &quot;feature
up-lifting and down-projecting&quot; works seamlessly as a whole, which accomplishes
crossmodal retrieval tasks very well. The proposed method, named as shared
discriminative semantic representation learning (\textbf{SDSRL}), is tested on
two public multimodal dataset for both within- and inter- modal retrieval. The
experiments demonstrate that it outperforms several state-of-the-art methods in
most scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05660</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05660</id><created>2015-11-18</created><authors><author><keyname>Zayyani</keyname><forenames>H.</forenames></author><author><keyname>Korki</keyname><forenames>M.</forenames></author><author><keyname>Marvasti</keyname><forenames>F.</forenames></author></authors><title>Bayesian hypothesis testing for one bit compressed sensing with sensing
  matrix perturbation</title><categories>stat.ML cs.IT math.IT</categories><comments>2 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter proposes a low-computational Bayesian algorithm for noisy sparse
recovery in the context of one bit compressed sensing with sensing matrix
perturbation. The proposed algorithm which is called BHT-MLE comprises a sparse
support detector and an amplitude estimator. The support detector utilizes
Bayesian hypothesis test, while the amplitude estimator uses an ML estimator
which is obtained by solving a convex optimization problem. Simulation results
show that BHT-MLE algorithm offers more reconstruction accuracy than that of an
ML estimator (MLE) at a low computational cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05662</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05662</id><created>2015-11-18</created><authors><author><keyname>Tian</keyname><forenames>Xin</forenames></author><author><keyname>Zhuo</keyname><forenames>Hankz Hankui</forenames></author><author><keyname>Kambhampati</keyname><forenames>Subbarao</forenames></author></authors><title>Discovering Underlying Plans Based on Distributed Representations of
  Actions</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plan recognition aims to discover target plans (i.e., sequences of actions)
behind observed actions, with history plan libraries or domain models in hand.
Previous approaches either discover plans by maximally &quot;matching&quot; observed
actions to plan libraries, assuming target plans are from plan libraries, or
infer plans by executing domain models to best explain the observed actions,
assuming complete domain models are available. In real world applications,
however, target plans are often not from plan libraries and complete domain
models are often not available, since building complete sets of plans and
complete domain models are often difficult or expensive. In this paper we view
plan libraries as corpora and learn vector representations of actions using the
corpora; we then discover target plans based on the vector representations. Our
approach is capable of discovering underlying plans that are not from plan
libraries, without requiring domain models provided. We empirically demonstrate
the effectiveness of our approach by comparing its performance to traditional
plan recognition approaches in three planning domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05666</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05666</id><created>2015-11-18</created><updated>2016-03-01</updated><authors><author><keyname>Bruna</keyname><forenames>Joan</forenames></author><author><keyname>Sprechmann</keyname><forenames>Pablo</forenames></author><author><keyname>LeCun</keyname><forenames>Yann</forenames></author></authors><title>Super-Resolution with Deep Convolutional Sufficient Statistics</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inverse problems in image and audio, and super-resolution in particular, can
be seen as high-dimensional structured prediction problems, where the goal is
to characterize the conditional distribution of a high-resolution output given
its low-resolution corrupted observation. When the scaling ratio is small,
point estimates achieve impressive performance, but soon they suffer from the
regression-to-the-mean problem, result of their inability to capture the
multi-modality of this conditional distribution. Modeling high-dimensional
image and audio distributions is a hard task, requiring both the ability to
model complex geometrical structures and textured regions. In this paper, we
propose to use as conditional model a Gibbs distribution, where its sufficient
statistics are given by deep convolutional neural networks. The features
computed by the network are stable to local deformation, and have reduced
variance when the input is a stationary texture. These properties imply that
the resulting sufficient statistics minimize the uncertainty of the target
signals given the degraded observations, while being highly informative. The
filters of the CNN are initialized by multiscale complex wavelets, and then we
propose an algorithm to fine-tune them by estimating the gradient of the
conditional log-likelihood, which bears some similarities with Generative
Adversarial Networks. We evaluate experimentally the proposed approach in the
image super-resolution task, but the approach is general and could be used in
other challenging ill-posed problems such as audio bandwidth extension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05667</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05667</id><created>2015-11-18</created><authors><author><keyname>Fikri</keyname></author><author><keyname>Abdillah</keyname><forenames>Leon Andretti</forenames></author><author><keyname>Apriyani</keyname><forenames>Ema</forenames></author></authors><title>Perancangan teknologi cloud untuk penjualan online kain songket
  Palembang</title><categories>cs.CY</categories><comments>6 pages in Seminar Nasional Sistem Informasi Indonesia ke-8
  (SESINDO2015), Institut Teknologi Sepuluh Nopember (ITS), Surabaya, 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud Computing is a paradigm in which information is permanently stored in
servers on the Internet and temporarily stored on the user's computer (client)
including the desktop. This study aims to design an online sales application
based cloud computing technology to help the artisans Palembang songket and do
not rule out the possibility for other small medium enterprises (SMEs) to
manage assets and market their products online so it can be accessed anytime
and anywhere via personal computer, laptop, tabblet, mobile phone or
smartphone. Cloud infrastructure used in this study is a Software-as-a-service
(SaaS) that enables cloud users to exploit online sales application without
having to install on your local computer, set up a dedicated server, operator
labor, maintenance costs and other support resources that can make savings in
terms of cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05671</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05671</id><created>2015-11-18</created><updated>2016-01-08</updated><authors><author><keyname>Wang</keyname><forenames>Rongrong</forenames></author></authors><title>Sigma Delta quantization with Harmonic frames and partial Fourier
  ensembles</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known that a discrete band-limited signal can be made broad-banded
if we randomly permute its entries. In this paper, we study the efficacy of
such spectral whitening procedure and its application to Sigma Delta
quantization in Compressed Sensing. As a side result, we show that a similar
whitening phenomenon can be observed in a broad class of non-Fourier orthogonal
transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05672</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05672</id><created>2015-11-18</created><updated>2016-01-28</updated><authors><author><keyname>Uzun</keyname><forenames>Yasin</forenames></author><author><keyname>Bicakci</keyname><forenames>Kemal</forenames></author><author><keyname>Uzunay</keyname><forenames>Yusuf</forenames></author></authors><title>Could We Distinguish Child Users from Adults Using Keystroke Dynamics?</title><categories>cs.HC cs.CY</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Significant portion of contemporary computer users are children, who are
vulnerable to threats coming from the Internet. To protect children from such
threats, in this study, we investigate how successfully typing data can be used
to distinguish children from adults. For this purpose, we collect a dataset
comprising keystroke data of 100 users and show that distinguishing child
Internet users from adults is possible using Keystroke Dynamics with equal
error rates less than 10 percent. However the error rates increase
significantly when there are impostors in the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05676</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05676</id><created>2015-11-18</created><authors><author><keyname>Jiang</keyname><forenames>Aiwen</forenames></author><author><keyname>Wang</keyname><forenames>Fang</forenames></author><author><keyname>Porikli</keyname><forenames>Fatih</forenames></author><author><keyname>Li</keyname><forenames>Yi</forenames></author></authors><title>Compositional Memory for Visual Question Answering</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual Question Answering (VQA) emerges as one of the most fascinating topics
in computer vision recently. Many state of the art methods naively use holistic
visual features with language features into a Long Short-Term Memory (LSTM)
module, neglecting the sophisticated interaction between them. This coarse
modeling also blocks the possibilities of exploring finer-grained local
features that contribute to the question answering dynamically over time.
  This paper addresses this fundamental problem by directly modeling the
temporal dynamics between language and all possible local image patches. When
traversing the question words sequentially, our end-to-end approach explicitly
fuses the features associated to the words and the ones available at multiple
local patches in an attention mechanism, and further combines the fused
information to generate dynamic messages, which we call episode. We then feed
the episodes to a standard question answering module together with the
contextual visual information and linguistic information. Motivated by recent
practices in deep learning, we use auxiliary loss functions during training to
improve the performance. Our experiments on two latest public datasets suggest
that our method has a superior performance. Notably, on the DARQUAR dataset we
advanced the state of the art by 6$\%$, and we also evaluated our approach on
the most recent MSCOCO-VQA dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05677</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05677</id><created>2015-11-18</created><authors><author><keyname>Eksin</keyname><forenames>Ceyhun</forenames></author><author><keyname>Delic</keyname><forenames>Hakan</forenames></author><author><keyname>Ribeiro</keyname><forenames>Alejandro</forenames></author></authors><title>Demand Response with Cooperating Rational Consumers</title><categories>cs.SY cs.GT math.OC</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The performance of an energy system under a real-time pricing mechanism
depends on the consumption behavior of its customers, which involves
uncertainties. In this paper, we consider a system operator that charges its
customers with a real-time price that depends on the total realized
consumption. Customers have unknown and heterogeneous consumption preferences.
We propose behavior models in which customers act selfishly, altruistically or
as welfare-maximizers. In addition, we consider information models where
customers keep their consumption levels private, communicate with a neighboring
set of customers, or receive broadcasted demand from the operator. Our analysis
focuses on the dispersion of the system performance under different consumption
models. To this end, for each pair of behavior and information model we define
and characterize optimal rational behavior, and provide a local algorithm that
can be implemented by the consumption scheduler devices. Numerical comparisons
show that communication model is beneficial for the expected aggregate customer
utility while it does not affect the expected net revenue of the system
operator. Additional information to customers reduces the variance of demand.
While communication is beneficial overall, behavioral change from selfish to
altruistic has a stronger positive impact on the system welfare.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05678</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05678</id><created>2015-11-18</created><updated>2016-01-07</updated><authors><author><keyname>Pan</keyname><forenames>Xingyuan</forenames></author><author><keyname>Srikumar</keyname><forenames>Vivek</forenames></author></authors><title>Expressiveness of Rectifier Networks</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rectified Linear Units (ReLUs) have been shown to ameliorate the vanishing
gradient problem, allow for efficient backpropagation, and empirically promote
sparsity in the learned parameters. Their use has led to state-of-the-art
results in a variety of applications. In this paper, we characterize the
expressiveness of ReLU networks. From this perspective, unlike the sign
(threshold) and sigmoid activations, ReLU networks are less explored. We show
that, while the decision boundary of a two-layer ReLU network can be captured
by a sign network, the sign network can require an exponentially larger number
of hidden units. Furthermore, we formulate sufficient conditions for a
corresponding logarithmic reduction in the number of hidden units to represent
a sign network as a ReLU network. Finally, using synthetic data, we
experimentally demonstrate that back propagation can recover the much smaller
ReLU networks as predicted by the theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05680</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05680</id><created>2015-11-18</created><updated>2015-11-19</updated><authors><author><keyname>Jiang</keyname><forenames>Wuxuan</forenames></author><author><keyname>Xie</keyname><forenames>Cong</forenames></author><author><keyname>Zhang</keyname><forenames>Zhihua</forenames></author></authors><title>Wishart Mechanism for Differentially Private Principal Components
  Analysis</title><categories>cs.CR cs.DS stat.ML</categories><comments>A full version with technical proofs. Accepted to AAAI-16</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new input perturbation mechanism for publishing a covariance
matrix to achieve $(\epsilon,0)$-differential privacy. Our mechanism uses a
Wishart distribution to generate matrix noise. In particular, We apply this
mechanism to principal component analysis. Our mechanism is able to keep the
positive semi-definiteness of the published covariance matrix. Thus, our
approach gives rise to a general publishing framework for input perturbation of
a symmetric positive semidefinite matrix. Moreover, compared with the classic
Laplace mechanism, our method has better utility guarantee. To the best of our
knowledge, Wishart mechanism is the best input perturbation approach for
$(\epsilon,0)$-differentially private PCA. We also compare our work with
previous exponential mechanism algorithms in the literature and provide near
optimal bound while having more flexibility and less computational
intractability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05682</identifier>
 <datestamp>2015-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05682</id><created>2015-11-18</created><updated>2015-12-27</updated><authors><author><keyname>Uzunay</keyname><forenames>Yusuf</forenames></author><author><keyname>Bicakci</keyname><forenames>Kemal</forenames></author></authors><title>Trust-in-the-Middle: Towards Establishing Trustworthiness of
  Authentication Proxies using Trusted Computing</title><categories>cs.CR</categories><comments>34 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Authentication proxies, which store users' secret credentials and submit them
to servers on their behalf, offer benefits with respect to security of the
authentication and usability of credential management. However, as being a
service that is not in control of users, one important problem they suffer is
the trust problem; how users trust that their secrets are handled securely in
the proxy and not revealed to third parties. In this paper, we present a
solution called Trust-in-the-Middle, a TPM based proxy system which ensures
that user credentials are securely stored and submitted without disclosing them
even if the proxy is compromised. We build our architecture on a trust chain
bootstrapped by TPM DRTM and prevent access to credentials if any entity in the
chain is maliciously modified. We use remote attestation to guarantee that all
critical operations on the proxy are performed securely and credentials are
cryptographically protected when they are not in DRTM-supported isolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05683</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05683</id><created>2015-11-18</created><authors><author><keyname>Wang</keyname><forenames>Ying</forenames></author><author><keyname>Sun</keyname><forenames>Ruijin</forenames></author><author><keyname>Wang</keyname><forenames>Xinshui</forenames></author></authors><title>Transceiver Design to Maximize Sum Secrecy Rate in Full Duplex SWIPT
  Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter considers secrecy simultaneous wireless information and power
transfer (SWIPT) in full duplex systems. In such a system, full duplex capable
base station (FD-BS) is designed to transmit data to one downlink user and
concurrently receive data from one uplink user, while one idle user harvests
the radio-frequency (RF) signals energy to extend its lifetime. Moreover, to
prevent eavesdropping, artificial noise (AN) is exploited by FD-BS to degrade
the channel of the idle user, as well as to provide energy supply to the idle
user. To maximize the sum of downlink secrecy rate and uplink secrecy rate, we
jointly optimize the information covariance matrix, AN covariance matrix and
receiver vector, under the constraints of the sum transmission power of FD-BS
and the minimum harvested energy of the idle user. Since the problem is
non-convex, the log-exponential reformulation and sequential parametric convex
approximation (SPCA) method are used. Extensive simulation results are provided
and demonstrate that our proposed full duplex scheme extremely outperforms the
half duplex scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05688</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05688</id><created>2015-11-18</created><updated>2015-11-20</updated><authors><author><keyname>Eetemadi</keyname><forenames>Ameen</forenames></author><author><keyname>Tagkopoulos</keyname><forenames>Ilias</forenames></author></authors><title>A Distribution Adaptive Framework for Prediction Interval Estimation
  Using Nominal Variables</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Proposed methods for prediction interval estimation so far focus on cases
where input variables are numerical. In datasets with solely nominal input
variables, we observe records with the exact same input $x^u$, but different
real valued outputs due to the inherent noise in the system. Existing
prediction interval estimation methods do not use representations that can
accurately model such inherent noise in the case of nominal inputs. We propose
a new prediction interval estimation method tailored for this type of data,
which is prevalent in biology and medicine. We call this method Distribution
Adaptive Prediction Interval Estimation given Nominal inputs (DAPIEN) and has
four main phases. First, we select a distribution function that can best
represent the inherent noise of the system for all unique inputs. Then we infer
the parameters $\theta_i$ (e.g. $\theta_i=[mean_i, variance_i]$) of the
selected distribution function for all unique input vectors $x^u_i$ and
generate a new corresponding training set using pairs of $x^u_i, \theta_i$.
III). Then, we train a model to predict $\theta$ given a new $x_u$. Finally, we
calculate the prediction interval for a new sample using the inverse of the
cumulative distribution function once the parameters $\theta$ is predicted by
the trained model. We compared DAPIEN to the commonly used Bootstrap method on
three synthetic datasets. Our results show that DAPIEN provides tighter
prediction intervals while preserving the requested coverage when compared to
Bootstrap. This work can facilitate broader usage of regression methods in
medicine and biology where it is necessary to provide tight prediction
intervals while preserving coverage when input variables are nominal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05690</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05690</id><created>2015-11-18</created><authors><author><keyname>Serang</keyname><forenames>Oliver</forenames></author></authors><title>One to rule them all: a general method for fast computation on semirings
  isomorphic to $(\times, \max)$ on $\mathbb{R}_+$</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Important problems across multiple disciplines involve computations on the
semiring $(\times, \max)$ (or its equivalents, the negated version $(\times,
\min)$), the log-transformed version $(+, \max)$, or the negated
log-transformed version $(+, \min)$): max-convolution, all-pairs shortest paths
in a weighted graph, and finding the largest $k$ values in $x_i+y_j$ for two
lists $x$ and $y$. However, fast algorithms such as those enabling FFT
convolution, sub-cubic matrix multiplication, \emph{etc.}, require inverse
operations, and thus cannot be computed on semirings. This manuscript
generalizes recent advances on max-convolution: in this approach a small family
of $p$-norm rings are used to efficiently approximate results on a nonnegative
semiring. The general approach can be used to easily compute sub-cubic
estimates of the all-pairs shortest paths in a graph with nonnegative edge
weights and sub-quadratic estimates of the top $k$ values in $x_i+y_j$ when $x$
and $y$ are nonnegative. These methods are fast in practice and can benefit
from coarse parallelization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05706</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05706</id><created>2015-11-18</created><authors><author><keyname>Jawanpuria</keyname><forenames>Pratik</forenames></author><author><keyname>Lapin</keyname><forenames>Maksim</forenames></author><author><keyname>Hein</keyname><forenames>Matthias</forenames></author><author><keyname>Schiele</keyname><forenames>Bernt</forenames></author></authors><title>Efficient Output Kernel Learning for Multiple Tasks</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paradigm of multi-task learning is that one can achieve better
generalization by learning tasks jointly and thus exploiting the similarity
between the tasks rather than learning them independently of each other. While
previously the relationship between tasks had to be user-defined in the form of
an output kernel, recent approaches jointly learn the tasks and the output
kernel. As the output kernel is a positive semidefinite matrix, the resulting
optimization problems are not scalable in the number of tasks as an
eigendecomposition is required in each step. \mbox{Using} the theory of
positive semidefinite kernels we show in this paper that for a certain class of
regularizers on the output kernel, the constraint of being positive
semidefinite can be dropped as it is automatically satisfied for the relaxed
problem. This leads to an unconstrained dual problem which can be solved
efficiently. Experiments on several multi-task and multi-class data sets
illustrate the efficacy of our approach in terms of computational efficiency as
well as generalization performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05709</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05709</id><created>2015-11-18</created><authors><author><keyname>Kud&#x11b;lka</keyname><forenames>Milo&#x161;</forenames></author><author><keyname>Plato&#x161;</keyname><forenames>Jan</forenames></author><author><keyname>Kr&#xf6;mer</keyname><forenames>Pavel</forenames></author></authors><title>Author Evaluation Based on H-index and Citation Response</title><categories>cs.DL cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An accurate and fair assessment of the efficiency and impact of scientific
work is, despite a lot of recent research effort, still an open problem. The
measurement of quality and success of individual scientists and research groups
can be approached from many different directions, none of which is universal. A
reason for this is inherently different behavior of different scientists within
the global research community. A complex evaluation of ones publication
activities requires a careful consideration of a wide variety of factors. The
well-known H-index is one of the most used bibliometric indices. Despite its
many imperfections, its simplicity and ease of interpretation make it a popular
scientometric method. This short paper uses the ideas behind the H-index ~to
analyze communities of authors who cite publishing scientists. A new author
evaluation measure named aH-index is proposed, and intuitive interpretations of
its properties and semantics are presented. Preliminary experiments with
authors with high H-index active in the area of computer science are presented
to demonstrate the properties of the proposed measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05710</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05710</id><created>2015-11-18</created><authors><author><keyname>Boloix-Tortosa</keyname><forenames>Rafael</forenames></author><author><keyname>Arias-de-Reyna</keyname><forenames>Eva</forenames></author><author><keyname>Payan-Somet</keyname><forenames>F. Javier</forenames></author><author><keyname>Murillo-Fuentes</keyname><forenames>Juan J.</forenames></author></authors><title>Complex-Valued Gaussian Processes for Regression: A Widely Non-Linear
  Approach</title><categories>cs.LG</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a novel Bayesian kernel based solution for
regression in complex fields. We develop the formulation of the Gaussian
process for regression (GPR) to deal with complex-valued outputs. Previous
solutions for kernels methods usually assume a complexification approach, where
the real-valued kernel is replaced by a complex-valued one. However, based on
the results in complex-valued linear theory, we prove that both a kernel and a
pseudo-kernel are to be included in the solution. This is the starting point to
develop the new formulation for the complex-valued GPR. The obtained
formulation resembles the one of the widely linear minimum mean-squared
(WLMMSE) approach. Just in the particular case where the outputs are proper,
the pseudo-kernel cancels and the solution simplifies to a real-valued GPR
structure, as the WLMMSE does into a strictly linear solution. We include some
numerical experiments to show that the novel solution, denoted as widely
non-linear complex GPR (WCGPR), outperforms a strictly complex GPR where a
pseudo-kernel is not included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05719</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05719</id><created>2015-11-18</created><authors><author><keyname>Schoenfisch</keyname><forenames>Joerg</forenames></author><author><keyname>von Stulpnagel</keyname><forenames>Janno</forenames></author><author><keyname>Ortmann</keyname><forenames>Jens</forenames></author><author><keyname>Meilicke</keyname><forenames>Christian</forenames></author><author><keyname>Stuckenschmidt</keyname><forenames>Heiner</forenames></author></authors><title>Using Abduction in Markov Logic Networks for Root Cause Analysis</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  IT infrastructure is a crucial part in most of today's business operations.
High availability and reliability, and short response times to outages are
essential. Thus a high amount of tool support and automation in risk management
is desirable to decrease outages. We propose a new approach for calculating the
root cause for an observed failure in an IT infrastructure. Our approach is
based on Abduction in Markov Logic Networks. Abduction aims to find an
explanation for a given observation in the light of some background knowledge.
In failure diagnosis, the explanation corresponds to the root cause, the
observation to the failure of a component, and the background knowledge to the
dependency graph extended by potential risks. We apply a method to extend a
Markov Logic Network in order to conduct abductive reasoning, which is not
naturally supported in this formalism. Our approach exhibits a high amount of
reusability and enables users without specific knowledge of a concrete
infrastructure to gain viable insights in the case of an incident. We
implemented the method in a tool and illustrate its suitability for root cause
analysis by applying it to a sample scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05720</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05720</id><created>2015-11-18</created><authors><author><keyname>Weed</keyname><forenames>Jonathan</forenames></author><author><keyname>Perchet</keyname><forenames>Vianney</forenames></author><author><keyname>Rigollet</keyname><forenames>Philippe</forenames></author></authors><title>Online learning in repeated auctions</title><categories>cs.GT cs.LG stat.ML</categories><msc-class>Primary 62L05, secondary 62C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by online advertising auctions, we consider repeated Vickrey
auctions where goods of unknown value are sold sequentially and bidders only
learn (potentially noisy) information about a good's value once it is
purchased. We adopt an online learning approach with bandit feedback to model
this problem and derive bidding strategies for two models: stochastic and
adversarial. In the stochastic model, the observed values of the goods are
random variables centered around the true value of the good. In this case,
logarithmic regret is achievable when competing against well behaved
adversaries. In the adversarial model, the goods need not be identical and we
simply compare our performance against that of the best fixed bid in hindsight.
We show that sublinear regret is also achievable in this case and prove
matching minimax lower bounds. To our knowledge, this is the first complete set
of strategies for bidders participating in auctions of this type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05732</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05732</id><created>2015-11-18</created><authors><author><keyname>Saxena</keyname><forenames>Akrati</forenames></author><author><keyname>Malik</keyname><forenames>Vaibhav</forenames></author><author><keyname>Iyengar</keyname><forenames>S. R. S.</forenames></author></authors><title>Estimating the Degree Centrality Ranking of a Node</title><categories>cs.SI physics.soc-ph</categories><comments>Submitted in Complenet 2016 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks have gained more attention from the last few years. The size
of the real world complex networks, such as online social networks, WWW
networks, collaboration networks, is exponentially increasing with time. It is
not feasible to completely collect, store and process these networks. In the
present work, we propose a method to estimate the degree centrality ranking of
a node without having complete structure of the graph. The proposed algorithm
uses degree of a node and power law exponent of the degree distribution to
calculate the ranking. We also study simulation results on Barabasi-Albert
model. Simulation results show that the average error in the estimated ranking
is approximately $5\%$ of the total number of nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05737</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05737</id><created>2015-11-18</created><updated>2015-11-23</updated><authors><author><keyname>Goyal</keyname><forenames>Nitesh</forenames></author><author><keyname>Fussell</keyname><forenames>Susan R.</forenames></author></authors><title>Designing for Collaborative Sensemaking: Leveraging Human Cognition For
  Complex Tasks</title><categories>cs.HC</categories><comments>Conference. Companion of 15th IFIP TC 13 Human-Computer Interaction
  INTERACT 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  My research aims to design systems for complex sensemaking by remotely
located non-expert collaborators (crowds), to solve computationally hard
problems like crimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05740</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05740</id><created>2015-11-18</created><authors><author><keyname>Peters</keyname><forenames>Gareth William</forenames></author><author><keyname>Panayi</keyname><forenames>Efstathios</forenames></author></authors><title>Understanding Modern Banking Ledgers through Blockchain Technologies:
  Future of Transaction Processing and Smart Contracts on the Internet of Money</title><categories>cs.CY cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter we provide an overview of the concept of blockchain
technology and its potential to disrupt the world of banking through
facilitating global money remittance, smart contracts, automated banking
ledgers and digital assets. In this regard, we first provide a brief overview
of the core aspects of this technology, as well as the second-generation
contract-based developments. From there we discuss key issues that must be
considered in developing such ledger based technologies in a banking context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05743</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05743</id><created>2015-11-18</created><authors><author><keyname>Zhang</keyname><forenames>Ning</forenames></author><author><keyname>Chandrasekar</keyname><forenames>Prathamesh</forenames></author></authors><title>Sparse learning of maximum likelihood model for optimization of complex
  loss function</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional machine learning methods usually minimize a simple loss function
to learn a predictive model, and then use a complex performance measure to
measure the prediction performance. However, minimizing a simple loss function
cannot guarantee that an optimal performance. In this paper, we study the
problem of optimizing the complex performance measure directly to obtain a
predictive model. We proposed to construct a maximum likelihood model for this
problem, and to learn the model parameter, we minimize a com- plex loss
function corresponding to the desired complex performance measure. To optimize
the loss function, we approximate the upper bound of the complex loss. We also
propose impose the sparsity to the model parameter to obtain a sparse model. An
objective is constructed by combining the upper bound of the loss function and
the sparsity of the model parameter, and we develop an iterative algorithm to
minimize it by using the fast iterative shrinkage- thresholding algorithm
framework. The experiments on optimization on three different complex
performance measures, including F-score, receiver operating characteristic
curve, and recall precision curve break even point, over three real-world
applications, aircraft event recognition of civil aviation safety, in- trusion
detection in wireless mesh networks, and image classification, show the
advantages of the proposed method over state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05747</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05747</id><created>2015-11-18</created><authors><author><keyname>Wulff</keyname><forenames>Enrique</forenames></author></authors><title>HistComp : bibliographic analysis and visualization of 'The Biological
  Bulletin'</title><categories>cs.DL cs.SI</categories><comments>32nd IAMSLIC Annual Conference: Every continent, every ocean., Oct
  2006, Portland, Oregon, United States</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A collection of citation data, the HistComp, is available from the Internet
as a database of examples of real life citation networks. The purposes of this
approach is the analysis of these citation networks on learned literature by
presenting its typical steps and results. We have selected the bibliographic
insights into the &quot;The Biological Bulletin&quot;, the journal published since 1897
by the Woods Hole Marine Biological Laboratory. Since the bibliographic
networks tend to be very scattered, their visualization requires of criteria of
convergence. To simplify, the main features in such a structure should include
the survey for authoritative sources in the hyperlinked environment and the
identification of thematic areas. By avoiding excessive loose connections and
too dense clustered layouts to be useful, a smooth presentation is obtained by
graphically depicting the citation patterns. HistComp computes 8884 articles
published by 'The Biological Bulletin' between 1945-2003. A two-dimensional
positioning of these papers that represent the extent of their bibliographic
coupling and co-citation is offered as a histograph. The criteria to construct
it is the adequateness of the visualization relative to the 8884 data set. The
spatial representation obtained optimizes the identification of the clusters or
topic areas. The thematic importance of marine science involves its
participation in 7 of the 7 presenting clusters. The mainstream subjects were
crustaceans and echinoderms, with some 60% of the material presented in the
graph. But sea anemone, with about 16% of the total, remains as the best
visualized topical area. A perspective of the highly relevant papers is readily
confirmed by the visual inspection of width of the glyphs used for nodes
representation. For user interaction, HistComp employs mouse-over labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05749</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05749</id><created>2015-11-18</created><authors><author><keyname>Khaled</keyname><forenames>Oumaima</forenames></author></authors><title>Solution Repair/Recovery in Uncertain Optimization Environment</title><categories>cs.AI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Operation management problems (such as Production Planning and Scheduling)
are represented and formulated as optimization models. The resolution of such
optimization models leads to solutions which have to be operated in an
organization. However, the conditions under which the optimal solution is
obtained rarely correspond exactly to the conditions under which the solution
will be operated in the organization.Therefore, in most practical contexts, the
computed optimal solution is not anymore optimal under the conditions in which
it is operated. Indeed, it can be &quot;far from optimal&quot; or even not feasible. For
different reasons, we hadn't the possibility to completely re-optimize the
existing solution or plan. As a consequence, it is necessary to look for
&quot;repair solutions&quot;, i.e., solutions that have a good behavior with respect to
possible scenarios, or with respect to uncertainty of the parameters of the
model. To tackle the problem, the computed solution should be such that it is
possible to &quot;repair&quot; it through a local re-optimization guided by the user or
through a limited change aiming at minimizing the impact of taking into
consideration the scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05750</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05750</id><created>2015-11-18</created><authors><author><keyname>Aubert</keyname><forenames>Cl&#xe9;ment</forenames><affiliation>LACL</affiliation></author><author><keyname>Cristescu</keyname><forenames>Ioana</forenames><affiliation>PPS</affiliation></author></authors><title>Contextual equivalences in configuration structures and reversibility</title><categories>cs.LO cs.CC math.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contextual equivalence equate terms that have the same observable behaviour
in any context. A standard contextual equivalence for CCS is the strong barbed
congruence. Configuration structures are a denotational semantics for processes
in which one define equivalences that are more discriminating, i.e. that
distinguish the denotation of terms equated by barbed congruence. Hereditary
history preserving bisimulation (HHPB) is such a relation. We define a strong
back-and-forth barbed congruence on RCCS, a reversible variant of CCS. We show
that the relation induced by the back-and-forth congruence on configuration
structures is equivalent to HHPB, thus providing a contextual characterization
of HHPB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05756</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05756</id><created>2015-11-18</created><authors><author><keyname>Noh</keyname><forenames>Hyeonwoo</forenames></author><author><keyname>Seo</keyname><forenames>Paul Hongsuck</forenames></author><author><keyname>Han</keyname><forenames>Bohyung</forenames></author></authors><title>Image Question Answering using Convolutional Neural Network with Dynamic
  Parameter Prediction</title><categories>cs.CV cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle image question answering (ImageQA) problem by learning a
convolutional neural network (CNN) with a dynamic parameter layer whose weights
are determined adaptively based on questions. For the adaptive parameter
prediction, we employ a separate parameter prediction network, which consists
of gated recurrent unit (GRU) taking a question as its input and a
fully-connected layer generating a set of candidate weights as its output.
However, it is challenging to construct a parameter prediction network for a
large number of parameters in the fully-connected dynamic parameter layer of
the CNN. We reduce the complexity of this problem by incorporating a hashing
technique, where the candidate weights given by the parameter prediction
network are selected using a predefined hash function to determine individual
weights in the dynamic parameter layer. The proposed network---joint network
with the CNN for ImageQA and the parameter prediction network---is trained
end-to-end through back-propagation, where its weights are initialized using a
pre-trained CNN and GRU. The proposed algorithm illustrates the
state-of-the-art performance on all available public ImageQA benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05757</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05757</id><created>2015-11-18</created><authors><author><keyname>Ikeda</keyname><forenames>Takuya</forenames></author><author><keyname>Nagahara</keyname><forenames>Masaaki</forenames></author></authors><title>Maximum Hands-off Control without Normality Assumption</title><categories>cs.SY math.OC</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum hands-off control is a control that has the minimum L0 norm among all
feasible controls. It is known that the maximum hands-off (or L0-optimal)
control problem is equivalent to the L1-optimal control under the assumption of
normality. In this article, we analyze the maximum hands-off control for linear
time-invariant systems without the normality assumption. For this purpose, we
introduce the Lp-optimal control with 0&lt;p&lt;1, which is a natural relaxation of
the L0 problem. By using this, we investigate the existence and the
bang-off-bang property (i.e. the control takes values of 1, 0 and -1) of the
maximum hands-off control. We then describe a general relation between the
maximum hands-off control and the L1-optimal control. We also prove the
continuity and convexity property of the value function, which plays an
important role to prove the stability when the (finite-horizon) control is
extended to model predictive control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05768</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05768</id><created>2015-11-18</created><authors><author><keyname>Tonsen</keyname><forenames>Marc</forenames></author><author><keyname>Zhang</keyname><forenames>Xucong</forenames></author><author><keyname>Sugano</keyname><forenames>Yusuke</forenames></author><author><keyname>Bulling</keyname><forenames>Andreas</forenames></author></authors><title>Labeled pupils in the wild: A dataset for studying pupil detection in
  unconstrained environments</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present labelled pupils in the wild (LPW), a novel dataset of 66
high-quality, high-speed eye region videos for the development and evaluation
of pupil detection algorithms. The videos in our dataset were recorded from 22
participants in everyday locations at about 95 FPS using a state-of-the-art
dark-pupil head-mounted eye tracker. They cover people with different
ethnicities, a diverse set of everyday indoor and outdoor illumination
environments, as well as natural gaze direction distributions. The dataset also
includes participants wearing glasses, contact lenses, as well as make-up. We
benchmark five state-of-the-art pupil detection algorithms on our dataset with
respect to robustness and accuracy. We further study the influence of image
resolution, vision aids, as well as recording location (indoor, outdoor) on
pupil detection performance. Our evaluations provide valuable insights into the
general pupil detection problem and allow us to identify key challenges for
robust pupil detection on head-mounted eye trackers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05770</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05770</id><created>2015-11-18</created><authors><author><keyname>Blum</keyname><forenames>Norbert</forenames></author></authors><title>On LR(k)-parsers of polynomial size</title><categories>cs.FL</categories><comments>An extended abstract of this paper appeared in 37th International
  Colloquium, ICALP 2010, Bordeaux, France, July 2010, Proceedings, Part II,
  LNCS 6199, pp. 163--174, Springer-Verlag Berlin Heidelberg 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Usually, a parser for an $LR(k)$-grammar $G$ is a deterministic pushdown
transducer which produces backwards the unique rightmost derivation for a given
input string $x \in L(G)$. The best known upper bound for the size of such a
parser is $O(2^{|G||\Sigma|^k+k\log |\Sigma| + \log |G|})$ where $|G|$ and
$|\Sigma|$ are the sizes of the grammar $G$ and the terminal alphabet $\Sigma$,
respectively. If we add to a parser the possibility to manipulate a directed
graph of size $O(|G|n)$ where $n$ is the length of the input then we obtain an
extended parser. The graph is used for an efficient parallel simulation of all
potential leftmost derivations of the current right sentential form such that
the unique rightmost derivation of the input can be computed. Given an
arbitrary $LR(k)$-grammar $G$, we show how to construct an extended parser of
$O(|G| + \#LA |N|2^k k \log k)$ size where $|N|$ is the number of nonterminal
symbols and $\#LA$ is the number of relevant lookaheads with respect to the
grammar $G$. As the usual parser, this extended parser uses only tables as data
structure. Using some ingenious data structures and increasing the parsing time
by a small constant factor, the size of the extended parser can be reduced to
$O(|G| + \#LA|N|k^2)$. The parsing time is $O(ld(input) + k|G|n)$ where
$ld(input)$ is the length of the derivation of the input. Moreover, we have
constructed a one pass parser.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05771</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05771</id><created>2015-11-18</created><updated>2015-11-20</updated><authors><author><keyname>Delporte</keyname><forenames>Baptiste</forenames></author><author><keyname>Rigamonti</keyname><forenames>Roberto</forenames></author><author><keyname>Dassatti</keyname><forenames>Alberto</forenames></author></authors><title>Toward Transparent Heterogeneous Systems</title><categories>cs.PF cs.DC</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous parallel systems are widely spread nowadays. Despite their
availability, their usage and adoption are still limited, and even more rarely
they are used to full power. Indeed, compelling new technologies are constantly
developed and keep changing the technological landscape, but each of them
targets a limited sub-set of supported devices, and nearly all of them require
new programming paradigms and specific toolsets. Software, however, can hardly
keep the pace with the growing number of computational capabilities, and
developers are less and less motivated in learning skills that could quickly
become obsolete. In this paper we present our effort in the direction of a
transparent system optimization based on automatic code profiling and
Just-In-Time compilation, that resulted in a fully-working embedded prototype
capable of dynamically detect computing-intensive code blocks and automatically
dispatch them to different computation units. Experimental results show that
our system allows gains up to 32x in performance --- after an initial warm-up
phase --- without requiring any human intervention.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05774</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05774</id><created>2015-11-18</created><authors><author><keyname>Jones</keyname><forenames>Jeff</forenames></author></authors><title>Applications of Multi-Agent Slime Mould Computing</title><categories>cs.ET</categories><journal-ref>Int. J. of Parallel, Emergent and Distributed Systems, 1-30 (2015)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The giant single-celled slime mould Physarum polycephalum has inspired rapid
develop- ments in unconventional computing substrates since the start of this
century. This is primarily due to its simple component parts and the
distributed nature of the computation which it approximates during its growth,
foraging and adaptation to a changing environment. Slime mould functions as a
living embodied computational material which can be influenced (or pro-
grammed) by the placement of external stimuli. The goal of exploiting this
material behaviour for unconventional computation led to the development of a
multi-agent approach to the ap- proximation of slime mould behaviour. The basis
of the model is a simple dynamical pattern formation mechanism which exhibits
self-organised formation and subsequent adaptation of collective transport
networks. The system exhibits emergent properties such as relaxation and
minimisation and it can be considered as a virtual computing material,
influenced by the external application of spatial concentration gradients. In
this paper we give an overview of this multi-agent approach to unconventional
computing. We describe its computational mechanisms and different generic
application domains, together with concrete example ap- plications of material
computation. We examine the potential exploitation of the approach for
computational geometry, path planning, combinatorial optimisation, data
smoothing and statistical applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05778</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05778</id><created>2015-11-18</created><updated>2015-11-19</updated><authors><author><keyname>Paulino</keyname><forenames>Herv&#xe9;</forenames></author><author><keyname>Delgado</keyname><forenames>Nuno</forenames></author></authors><title>Cache-Conscious Run-time Decomposition of Data Parallel Computations</title><categories>cs.DC</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-core architectures feature an intricate hierarchy of cache memories,
with multiple levels and sizes. To adequately decompose an application
according to the traits of a particular memory hierarchy is a cumbersome task
that may be rewarded with significant performance gains. The current
state-of-the-art in memory-hierarchy-aware parallel computing delegates this
endeavour on the programmer, demanding from him deep knowledge of both parallel
programming and computer architecture. In this paper we propose the shifting of
these memory-hierarchy-related concerns to the run-time system, which then
takes on the responsibility of distributing the computation's data across the
target memory hierarchy. We evaluate our approach from a performance
perspective, comparing it against the common cache-neglectful data
decomposition strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05779</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05779</id><created>2015-11-18</created><authors><author><keyname>Jones</keyname><forenames>Jeff</forenames></author></authors><title>Towards Lateral Inhibition and Collective Perception in Unorganised
  Non-Neural Systems</title><categories>cs.ET</categories><comments>Computational Intelligence, Medicine and Biology, Eds. Pancerz, K.,
  Zaitseva, E., p. 103-122</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Could simple organisms such as slime mould approximate LI without recourse to
neural tissue? We describe a model whereby LI can emerge without explicit
inhibitory wiring, using only bulk transport effects. We use a multi-agent
model of slime mould to reproduce the char- acteristic edge contrast
amplification effects of LI using excitation via attractant based stimuli. We
also explore a counterpart behaviour, Lateral Activation (where stimulated
regions are inhibited and lateral regions are excited), using simulated
exposure to light irradiation. In both cases restoration of baseline activity
occurs when the stimuli are removed. In addition to the enhancement of local
edge contrast the long-term change in population density distribution
corresponds to a collective response to the global brightness of 2D image
stimuli, including the scalloped inten- sity profile of the Chevreul staircase
and the perceived difference of two identically bright patches in the
Simultaneous Brightness Contrast (SBC) effect. This simple
modelapproximatesLIcontrastenhancementphenomenaandglobalbrightnessper- ception
in collective unorganised systems without fixed neural architectures. This may
encourage further research into unorganised analogues of neural processes in
simple organisms and suggests novel mechanisms to generate collective
perception of contrast and brightness in distributed computing and robotic
devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05787</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05787</id><created>2015-11-18</created><authors><author><keyname>Cao</keyname><forenames>Zhengjun</forenames></author><author><keyname>Liu</keyname><forenames>Lihua</forenames></author></authors><title>The Paillier's Cryptosystem and Some Variants Revisited</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At Eurocrypt'99, Paillier presented a public-key cryptosystem based on a
novel computational problem. It has interested many researchers because it was
additively homomorphic. In this paper, we show that there is a big difference
between the original Paillier's encryption and some variants. The Paillier's
encryption can be naturally transformed into a signature scheme but these
variants miss the feature. In particular, we simplify the alternative
decryption procedure of Bresson-Catalano-Pointcheval encryption scheme proposed
at Asiacrypt'03. The new version is more applicable to cloud computing because
of its double trapdoor decryption mechanism and its flexibility to be
integrated into other cryptographic schemes. It captures a new feature that its
two groups of secret keys can be distributed to different users so as to
enhance the robustness of key management.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05788</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05788</id><created>2015-11-18</created><updated>2015-11-19</updated><authors><author><keyname>Edwards</keyname><forenames>Michael</forenames></author><author><keyname>Deng</keyname><forenames>Jingjing</forenames></author><author><keyname>Xie</keyname><forenames>Xianghua</forenames></author></authors><title>From Pose to Activity: Surveying Datasets and Introducing CONVERSE</title><categories>cs.CV</categories><comments>Presentation of pose-based conversational human interaction dataset,
  review of current appearance and depth based action recognition datasets,
  public dataset, 38 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a review on the current state of publicly available datasets
within the human action recognition community; highlighting the revival of pose
based methods and recent progress of understanding person-person interaction
modeling. We categorize datasets regarding several key properties for usage as
a benchmark dataset; including the number of class labels, ground truths
provided, and application domain they occupy. We also consider the level of
abstraction of each dataset; grouping those that present actions, interactions
and higher level semantic activities. The survey identifies key appearance and
pose based datasets, noting a tendency for simplistic, emphasized, or scripted
action classes that are often readily definable by a stable collection of
sub-action gestures. There is a clear lack of datasets that provide closely
related actions, those that are not implicitly identified via a series of poses
and gestures, but rather a dynamic set of interactions. We therefore propose a
novel dataset that represents complex conversational interactions between two
individuals via 3D pose. 8 pairwise interactions describing 7 separate
conversation based scenarios were collected using two Kinect depth sensors. The
intention is to provide events that are constructed from numerous primitive
actions, interactions and motions, over a period of time; providing a set of
subtle action classes that are more representative of the real world, and a
challenge to currently developed recognition methodologies. We believe this is
among one of the first datasets devoted to conversational interaction
classification using 3D pose features and the attributed papers show this task
is indeed possible. The full dataset is made publicly available to the research
community at www.csvision.swansea.ac.uk/converse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05789</identifier>
 <datestamp>2016-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05789</id><created>2015-11-18</created><updated>2016-02-18</updated><authors><author><keyname>Wauquier</keyname><forenames>Pauline</forenames></author><author><keyname>Keller</keyname><forenames>Mikaela</forenames></author></authors><title>Metric learning approach for graph-based label propagation</title><categories>cs.LG</categories><comments>Workshop track submission ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The efficiency of graph-based semi-supervised algorithms depends on the graph
of instances on which they are applied. The instances are often in a vectorial
form before a graph linking them is built. The construction of the graph relies
on a metric over the vectorial space that help define the weight of the
connection between entities. The classic choice for this metric is usually a
distance measure or a similarity measure based on the euclidean norm. We claim
that in some cases the euclidean norm on the initial vectorial space might not
be the more appropriate to solve the task efficiently. We propose an algorithm
that aims at learning the most appropriate vectorial representation for
building a graph on which the task at hand is solved efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05797</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05797</id><created>2015-11-18</created><authors><author><keyname>Mryglod</keyname><forenames>Olesya</forenames></author><author><keyname>Holovatch</keyname><forenames>Yurij</forenames></author><author><keyname>Kenna</keyname><forenames>Ralph</forenames></author><author><keyname>Berche</keyname><forenames>Bertrand</forenames></author></authors><title>Quantifying the evolution of a scientific topic: reaction of the
  academic community to the Chornobyl disaster</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the reaction of academic communities to a particular urgent topic
which abruptly arises as a scientific problem. To this end, we have chosen the
disaster that occurred in 1986 in Chornobyl (Chernobyl), Ukraine, considered as
one of the most devastating nuclear power plant accidents in history. The
academic response is evaluated using scientific-publication data concerning the
disaster using the Scopus database to present the picture on an international
scale and the bibliographic database &quot;Ukrainika naukova&quot; to consider it on a
national level. We measured distributions of papers in different scientific
fields, their growth rates and properties of co-authorship networks. {The
elements of descriptive statistics and the tools of the complex network theory
are used to highlight the interdisciplinary as well as international effects.}
Our analysis allows to compare contributions of the international community to
Chornobyl-related research as well as integration of Ukraine in the
international research on this subject. Furthermore, the content analysis of
titles and abstracts of the publications allowed to detect the most important
terms used for description of Chornobyl-related problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05798</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05798</id><created>2015-11-18</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>Problems with the use of Web search engines to find results in foreign
  languages</title><categories>cs.IR</categories><comments>Research paper, World Wide Web, search engines, advanced search
  options, language restriction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose - To test the ability of major search engines, Google, Yahoo, MSN,
and Ask, to distinguish between German and English-language documents
  Design/methodology/approach - 50 queries, using words common in German and in
English, were posed to the engines. The advanced search option of language
restriction was used, once in German and once in English. The first 20 results
per engine in each language were investigated.
  Findings - While none of the search engines faces problems in providing
results in the language of the interface that is used, both Google and MSN face
problems when the results are restricted to a foreign language.
  Research limitations/implications - Search engines were only tested in German
and in English. We have only anecdotal evidence that the problems are the same
with other languages.
  Practical implications - Searchers should not use the language restriction in
Google and MSN when searching for foreign-language documents. Instead,
searchers should use Yahoo or Ask. If searching for foreign language documents
in Google or MSN, the interface in the target language/country should be used.
  Value of paper - Demonstrates a problem with search engines that has not been
previously investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05800</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05800</id><created>2015-11-18</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>The Retrieval Effectiveness of Web Search Engines: Considering Results
  Descriptions</title><categories>cs.IR</categories><comments>Research paper, Word Wide Web, search engines, retrieval
  effectiveness, results descriptions, retrieval measures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: To compare five major Web search engines (Google, Yahoo, MSN,
Ask.com, and Seekport) for their retrieval effectiveness, taking into account
not only the results but also the results descriptions.
  Design/Methodology/Approach: The study uses real-life queries. Results are
made anonymous and are randomised. Results are judged by the persons posing the
original queries.
  Findings: The two major search engines, Google and Yahoo, perform best, and
there are no significant differences between them. Google delivers
significantly more relevant result descriptions than any other search engine.
This could be one reason for users perceiving this engine as superior.
  Research Limitations: The study is based on a user model where the user takes
into account a certain amount of results rather systematically. This may not be
the case in real life.
  Practical Implications: Implies that search engines should focus on relevant
descriptions. Searchers are advised to use other search engines in addition to
Google.
  Originality/Value: This is the first major study comparing results and
descriptions systematically and proposes new retrieval measures to take into
account results descriptions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05802</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05802</id><created>2015-11-18</created><authors><author><keyname>Hoechstoetter</keyname><forenames>Nadine</forenames></author><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>What Users See - Structures in Search Engine Results Pages</title><categories>cs.IR</categories><comments>Search engines, evaluation, search engine results pages, search
  shortcuts</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the composition of search engine results pages. We
define what elements the most popular web search engines use on their results
pages (e.g., organic results, advertisements, shortcuts) and to which degree
they are used for popular vs. rare queries. Therefore, we send 500 queries of
both types to the major search engines Google, Yahoo, Live.com and Ask. We
count how often the different elements are used by the individual engines. In
total, our study is based on 42,758 elements. Findings include that search
engines use quite different approaches to results pages composition and
therefore, the user gets to see quite different results sets depending on the
search engine and search query used. Organic results still play the major role
in the results pages, but different shortcuts are of some importance, too.
Regarding the frequency of certain host within the results sets, we find that
all search engines show Wikipedia results quite often, while other hosts shown
depend on the search engine used. Both Google and Yahoo prefer results from
their own offerings (such as YouTube or Yahoo Answers). Since we used the .com
interfaces of the search engines, results may not be valid for other
country-specific interfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05806</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05806</id><created>2015-11-18</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>Ranking library materials</title><categories>cs.DL cs.IR</categories><comments>Conceptual paper, OPAC, search engines, ranking, results presentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: This paper discusses ranking factors suitable for library materials
and shows that ranking in general is a complex process and that ranking for
library materials requires a variety of techniques.
Design/methodology/approach: The relevant literature is reviewed to provide a
systematic overview of suitable ranking factors. The discussion is based on an
overview of ranking factors used in Web search engines. Findings: While there
are a wide variety of ranking factors applicable to library materials, todays
library systems use only some of them. When designing a ranking component for
the library catalogue, an individual weighting of applicable factors is
necessary. Research limitations/applications: While this article discusses
different factors, no particular ranking formula is given. However, this
article presents the argument that such a formula must always be individual to
a certain use case. Practical implications: The factors presented can be
considered when designing a ranking component for a librarys search system or
when discussing such a project with an ILS vendor. Originality/value: This
paper is original in that it is the first to systematically discuss ranking of
library materials based on the main factors used by Web search engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05807</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05807</id><created>2015-11-18</created><authors><author><keyname>Brenner</keyname><forenames>R.</forenames></author><author><keyname>Ceuterickx</keyname><forenames>S.</forenames></author><author><keyname>Dehos</keyname><forenames>C.</forenames></author><author><keyname>De Lurgio</keyname><forenames>P.</forenames></author><author><keyname>Djurcic</keyname><forenames>Z.</forenames></author><author><keyname>Drake</keyname><forenames>G.</forenames></author><author><keyname>Gimenez</keyname><forenames>J. L. Gonzalez</forenames></author><author><keyname>Gustafsson</keyname><forenames>L.</forenames></author><author><keyname>Kim</keyname><forenames>D. W.</forenames></author><author><keyname>Locci</keyname><forenames>E.</forenames></author><author><keyname>Roehrich</keyname><forenames>D.</forenames></author><author><keyname>Schoening</keyname><forenames>A.</forenames></author><author><keyname>Siligaris</keyname><forenames>A.</forenames></author><author><keyname>Soltveit</keyname><forenames>H. K.</forenames></author><author><keyname>Ullaland</keyname><forenames>K.</forenames></author><author><keyname>Vincent</keyname><forenames>P.</forenames></author><author><keyname>Wiednert</keyname><forenames>D.</forenames></author><author><keyname>Yang</keyname><forenames>S.</forenames></author></authors><title>Development of Wireless Techniques in Data and Power Transmission -
  Application for Particle Physics Detectors</title><categories>physics.ins-det cs.NI hep-ex</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless techniques have developed extremely fast over the last decade and
using them for data and power transmission in particle physics detectors is not
science- fiction any more. During the last years several research groups have
independently thought of making it a reality. Wireless techniques became a
mature field for research and new developments might have impact on future
particle physics experiments. The Instrumentation Frontier was set up as a part
of the SnowMass 2013 Community Summer Study [1] to examine the instrumentation
R&amp;D for the particle physics research over the coming decades: {\guillemotleft}
To succeed we need to make technical and scientific innovation a priority in
the field {\guillemotright}. Wireless data transmission was identified as one
of the innovations that could revolutionize the transmission of data out of the
detector. Power delivery was another challenge mentioned in the same report. We
propose a collaboration to identify the specific needs of different projects
that might benefit from wireless techniques. The objective is to provide a
common platform for research and development in order to optimize effectiveness
and cost, with the aim of designing and testing wireless demonstrators for
large instrumentation systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05808</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05808</id><created>2015-11-18</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>Using Search Engine Technology to Improve Library Catalogs</title><categories>cs.DL</categories><comments>Search engines, online catalogs, ranking, information seeking
  behavior, query types</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter outlines how search engine technology can be used in online
public access library catalogs (OPACs) to help improve users experiences, to
identify users intentions, and to indicate how it can be applied in the library
context, along with how sophisticated ranking criteria can be applied to the
online library catalog. A review of the literature and current OPAC
developments form the basis of recommendations on how to improve OPACs.
Findings were that the major shortcomings of current OPACs are that they are
not sufficiently user-centered and that their results presentations lack
sophistication. Further, these shortcomings are not addressed in current 2.0
developments. It is argued that OPAC development should be made search-centered
before additional features are applied. While the recommendations on ranking
functionality and the use of user intentions are only conceptual and not yet
applied to a library catalogue, practitioners will find recommendations for
developing better OPACs in this chapter. In short, readers will find a
systematic view on how the search engines strengths can be applied to improving
libraries online catalogs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05809</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05809</id><created>2015-11-18</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>Google Scholar as a tool for discovering journal articles in library and
  information science</title><categories>cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: The purpose of this paper is to measure the coverage of Google
Scholar for the Library and Information Science (LIS) journal literature as
identified by a list of core LIS journals from a study by Schloegl and
Petschnig (2005).
  Methods: We checked every article from 35 major LIS journals from the years
2004 to 2006 for availability in Google Scholar (GS). We also collected
information on the type of availability-i.e., whether a certain article was
available as a PDF for a fee, as a free PDF, or as a preprint.
  Results: We found that only some journals are completely indexed by Google
Scholar, that the ratio of versions available depends on the type of publisher,
and that availability varies a lot from journal to journal. Google Scholar
cannot substitute for abstracting and indexing services in that it does not
cover the complete literature of the field. However, it can be used in many
cases to easily find available full texts of articles already found using
another tool.
  Originality/value: This study differs from other Google Scholar coverage
studies in that it takes into account not only whether an article is indexed in
GS at all, but also the type of availability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05810</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05810</id><created>2015-11-18</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>The Influence of Commercial Intent of Search Results on Their Perceived
  Relevance</title><categories>cs.IR</categories><comments>Measurement, Performance, Experimentation, Worldwide Web, search
  engines, commerciality, evaluation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We carried out a retrieval effectiveness test on the three major web search
engines (i.e., Google, Microsoft and Yahoo). In addition to relevance
judgments, we classified the results according to their commercial intent and
whether or not they carried any advertising. We found that all search engines
provide a large number of results with a commercial intent. Google provides
significantly more commercial results than the other search engines do.
However, the commercial intent of a result did not influence jurors in their
relevance judgments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05812</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05812</id><created>2015-11-18</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>The retrieval effectiveness of search engines on navigational queries</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose - To test major Web search engines on their performance on
navigational queries, i.e. searches for homepages. Design/methodology/approach
- 100 real user queries are posed to six search engines (Google, Yahoo, MSN,
Ask, Seekport, and Exalead). Users described the desired pages, and the results
position of these is recorded. Measured success N and mean reciprocal rank are
calculated. Findings - Performance of the major search engines Google, Yahoo,
and MSN is best, with around 90 percent of queries answered correctly. Ask and
Exalead perform worse but receive good scores as well. Research
limitations/implications - All queries were in German, and the German-language
interfaces of the search engines were used. Therefore, the results are only
valid for German queries. Practical implications - When designing a search
engine to compete with the major search engines, care should be taken on the
performance on navigational queries. Users can be influenced easily in their
quality ratings of search engines based on this performance. Originality/value
- This study systematically compares the major search engines on navigational
queries and compares the findings with studies on the retrieval effectiveness
of the engines on informational queries. Paper type - research paper
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05817</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05817</id><created>2015-11-18</created><authors><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>A Framework for Evaluating the Retrieval Effectiveness of Search Engines</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This chapter presents a theoretical framework for evaluating next generation
search engines. We focus on search engines whose results presentation is
enriched with additional information and does not merely present the usual list
of 10 blue links, that is, of ten links to results, accompanied by a short
description. While Web search is used as an example here, the framework can
easily be applied to search engines in any other area. The framework not only
addresses the results presentation, but also takes into account an extension of
the general design of retrieval effectiveness tests. The chapter examines the
ways in which this design might influence the results of such studies and how a
reliable test is best designed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05819</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05819</id><created>2015-11-18</created><authors><author><keyname>Singer</keyname><forenames>Georg</forenames></author><author><keyname>Pruulmann-Vengerfeldt</keyname><forenames>Pille</forenames></author><author><keyname>Norbisrath</keyname><forenames>Ulrich</forenames></author><author><keyname>Lewandowski</keyname><forenames>Dirk</forenames></author></authors><title>The relationship between internet user type and user performance when
  carrying out simple vs. complex search tasks</title><categories>cs.IR</categories><comments>http://firstmonday.org/htbin/cgiwrap/bin/ojs/index.php/fm/article/view/3960/3245</comments><doi>10.5210/fm.v17i6.3960</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is widely known that people become better at an activity if they perform
this activity long and often. Yet, the question is whether being active in
related areas like communicating online, writing blog articles or commenting on
community forums have an impact on a persons ability to perform Web searches,
is still unanswered. Web searching has become a key task conducted online; in
this paper we present our findings on whether the user type, which categorises
a persons online activities, has an impact on her or his search capabilities.
We show (1) the characteristics of different user types when carrying out
simple search tasks; (2) their characteristics when carrying out complex search
tasks; and, (3) the significantly different user type characteristics between
simple and complex search tasks. The results are based on an experiment with 56
ordinary Web users in a laboratory environment. The Search-Logger study
framework was used to analyze and measure user behavior when carrying out a set
of 12 predefined search tasks. Our findings include the fact that depending on
task type (simple or complex) significant differences can be observed between
users of different types.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05823</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05823</id><created>2015-11-18</created><updated>2015-12-07</updated><authors><author><keyname>Carri&#xe8;re</keyname><forenames>Mathieu</forenames></author><author><keyname>Oudot</keyname><forenames>Steve</forenames></author></authors><title>Structure and Stability of the 1-Dimensional Mapper</title><categories>math.AT cs.CG</categories><comments>Minor corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a continuous function $f:X\to\mathbb{R}$ and a cover $\mathcal{I}$ of
its image by intervals, the Mapper is the nerve of a refinement of the pullback
cover $f^{-1}(\mathcal{I})$. Despite its success in applications, little is
known about the structure and stability of this construction from a theoretical
point of view. As a pixelized version of the Reeb graph of $f$, it is expected
to capture a subset of its features (branches, holes), depending on how the
interval cover is positioned with respect to the critical values of the
function. Its stability should also depend on this positioning. We propose a
theoretical framework that relates the structure of the Mapper to the one of
the Reeb graph, making it possible to predict which features will be present
and which will be absent in the Mapper given the function and the cover, and
for each feature, to quantify its degree of (in-)stability. Using this
framework, we can derive guarantees on the structure of the Mapper, on its
stability, and on its convergence to the Reeb graph as the granularity of the
cover $\mathcal{I}$ goes to zero.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05834</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05834</id><created>2015-11-18</created><updated>2016-03-01</updated><authors><author><keyname>Fozooni</keyname><forenames>Milad</forenames></author><author><keyname>Matthaiou</keyname><forenames>Michail</forenames></author><author><keyname>Jin</keyname><forenames>Shi</forenames></author><author><keyname>Alexandropoulos</keyname><forenames>George C.</forenames></author></authors><title>Massive MIMO Relaying with Hybrid Processing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive multiple-input multiple-output (MIMO) relaying is a promising
technological paradigm which can offer high spectral efficiency and
substantially improved coverage. Yet, these configurations face some formidable
challenges in terms of digital signal processing (DSP) power consumption and
circuitry complexity, since the number of radio frequency (RF) chains may scale
with the number of antennas at the relay station. In this paper, we advocate
that performing a portion of the power-intensive DSP in the analog domain,
using simple phase shifters and with a reduced number of RF paths, can address
these challenges. In particular, we consider a multipair amplify-and-forward
(AF) relay system with maximum ratio combining/transmission (MRC/MRT) and we
determine the asymptotic spectral efficiency for this hybrid analog/digital
architecture. After that, we extend our analytical results to account for
heavily quantized analog phase shifters and show that the performance loss with
2 quantization bits is only 10%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05835</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05835</id><created>2015-11-18</created><updated>2016-02-19</updated><authors><author><keyname>Pe&#xf1;a</keyname><forenames>Jose M.</forenames></author></authors><title>Alternative Markov and Causal Properties for Acyclic Directed Mixed
  Graphs</title><categories>stat.ML cs.AI</categories><comments>Minor changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend Andersson-Madigan-Perlman chain graphs by (i) relaxing the
semidirected acyclity constraint so that only directed cycles are forbidden,
and (ii) allowing up to two edges between any pair of nodes. We introduce
global, and ordered local and pairwise Markov properties for the new models. We
show the equivalence of these properties for strictly positive probability
distributions. We also show that when the random variables are continuous, the
new models can be interpreted as systems of structural equations with
correlated errors. This enables us to adapt Pearl's do-calculus to them.
Finally, we describe an exact algorithm for learning the new models from
observational and interventional data via answer set programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05842</identifier>
 <datestamp>2015-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05842</id><created>2015-11-18</created><updated>2015-12-09</updated><authors><author><keyname>Kung</keyname><forenames>Pau Perng-Hwa</forenames></author><author><keyname>Roy</keyname><forenames>Deb</forenames></author></authors><title>Measuring Responsiveness in the Online Public Sphere for the 2016 U.S.
  Election: Concepts</title><categories>cs.CY</categories><comments>7 pages, Workshop on Networks in the Social and Information Sciences
  NIPS 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The election narrative is formed under the competitions of ideas among
critical players involving politicians, news media, public influentials, and
the general public. Untangling the complex process of narrative formation,
however, is no easy task due to implicit influences among the key players. This
paper outlines a conceptual framework to untangle this complex process. We
propose the problem of measuring &quot;responsiveness&quot; that quantifies a player's
influence on another given a specific election topic over time. In particular,
we make use of multivariate Hawkes Process to infer the influence network
between pairs of election players. We demonstrate an early version system of
analytic pipeline of online public sphere discussions from data ingestion,
influence inference, to visualization. The paper concludes by showcasing some
preliminary results based on Twitter and news media election-related contents
from July to October 2015 and discussing plans for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05846</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05846</id><created>2015-11-18</created><authors><author><keyname>Tzoumas</keyname><forenames>Stratis</forenames></author><author><keyname>Nunes</keyname><forenames>Antonio</forenames></author><author><keyname>Olefir</keyname><forenames>Ivan</forenames></author><author><keyname>Stangl</keyname><forenames>Stefan</forenames></author><author><keyname>Symvoulidis</keyname><forenames>Panagiotis</forenames></author><author><keyname>Glasl</keyname><forenames>Sarah</forenames></author><author><keyname>Bayer</keyname><forenames>Christine</forenames></author><author><keyname>Multhoff</keyname><forenames>Gabriele</forenames></author><author><keyname>Ntziachristos</keyname><forenames>Vasilis</forenames></author></authors><title>Eigenspectra optoacoustic tomography achieves quantitative blood
  oxygenation imaging deep in tissues</title><categories>physics.med-ph cs.CV physics.optics q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Light propagating in tissue attains a spectrum that varies with location due
to wavelength-dependent fluence attenuation by tissue optical properties, an
effect that causes spectral corruption. Predictions of the spectral variations
of light fluence in tissue are challenging since the spatial distribution of
optical properties in tissue cannot be resolved in high resolution or with high
accuracy by current methods. Spectral corruption has fundamentally limited the
quantification accuracy of optical and optoacoustic methods and impeded the
long sought-after goal of imaging blood oxygen saturation (sO2) deep in
tissues; a critical but still unattainable target for the assessment of
oxygenation in physiological processes and disease. We discover a new principle
underlying light fluence in tissues, which describes the wavelength dependence
of light fluence as an affine function of a few reference base spectra,
independently of the specific distribution of tissue optical properties. This
finding enables the introduction of a previously undocumented concept termed
eigenspectra Multispectral Optoacoustic Tomography (eMSOT) that can effectively
account for wavelength dependent light attenuation without explicit knowledge
of the tissue optical properties. We validate eMSOT in more than 2000
simulations and with phantom and animal measurements. We find that eMSOT can
quantitatively image tissue sO2 reaching in many occasions a better than
10-fold improved accuracy over conventional spectral optoacoustic methods.
Then, we show that eMSOT can spatially resolve sO2 in muscle and tumor;
revealing so far unattainable tissue physiology patterns. Last, we related
eMSOT readings to cancer hypoxia and found congruence between eMSOT tumor sO2
images and tissue perfusion and hypoxia maps obtained by correlative
histological analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05847</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05847</id><created>2015-11-18</created><authors><author><keyname>Silva</keyname><forenames>Ana</forenames></author></authors><title>Trees with small b-chromatic index</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent article [5], the authors claim that the distance between the
b-chromatic index of a tree and a known upper bound is at most 1. At the same
time, in [7] the authors claim to be able to construct a tree where this
difference is bigger than 1. However, the given example was disconnected, i.e.,
actually consisted of a forest. Here, we slightly modify their construction in
order to produce trees, thus getting that indeed the difference between the
b-chromatic index of trees and the known upper bound can be arbitrarily large.
We also point out the mistake made in [5].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05850</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05850</id><created>2015-11-18</created><authors><author><keyname>Manrique</keyname><forenames>Pedro D.</forenames></author><author><keyname>Qi</keyname><forenames>Hong</forenames></author><author><keyname>Zheng</keyname><forenames>Minzhang</forenames></author><author><keyname>Xu</keyname><forenames>Chen</forenames></author><author><keyname>Hui</keyname><forenames>Pak Ming</forenames></author><author><keyname>Johnson</keyname><forenames>Neil F.</forenames></author></authors><title>Anomalous Contagion and Renormalization in Dynamical Networks with Nodal
  Mobility</title><categories>physics.soc-ph cs.SI nlin.AO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The common real-world feature of individuals migrating through a network --
either in real space or online -- significantly complicates understanding of
network processes. Here we show that even though a network may appear static on
average, underlying nodal mobility can dramatically distort outbreak profiles.
Highly nonlinear dynamical regimes emerge in which increasing mobility either
amplifies or suppresses outbreak severity. Predicted profiles mimic recent
outbreaks of real-space contagion (social unrest) and online contagion
(pro-ISIS support). We show that this nodal mobility can be renormalized in a
precise way for a particular class of dynamical networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05860</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05860</id><created>2015-11-18</created><updated>2015-11-21</updated><authors><author><keyname>Barbier</keyname><forenames>Jean</forenames></author><author><keyname>Tramel</keyname><forenames>Eric W.</forenames></author><author><keyname>Krzakala</keyname><forenames>Florent</forenames></author></authors><title>Scampi: a robust approximate message-passing framework for compressive
  imaging</title><categories>cs.IT math.IT</categories><comments>Presented at the 2015 International Meeting on High-Dimensional Data
  Driven Science, Kyoto, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconstruction of images from noisy linear measurements is a core problem in
image processing, for which convex optimization methods based on total
variation (TV) minimization have been the long-standing state-of-the-art. We
present an alternative probabilistic reconstruction procedure based on
approximate message-passing, Scampi, which operates in the compressive regime,
where the inverse imaging problem is underdetermined. While the proposed method
is related to the recently proposed GrAMPA algorithm of Borgerding, Schniter,
and Rangan, we further develop the probabilistic approach to compressive
imaging by introducing an expectation-maximizaiton learning of model
parameters, making the Scampi robust to model uncertainties. Additionally, our
numerical experiments indicate that Scampi can provide reconstruction
performance superior to both GrAMPA as well as convex approaches to TV
reconstruction. Finally, through exhaustive best-case experiments, we show that
in many cases the maximal performance of both Scampi and convex TV can be quite
close, even though the approaches are a prori distinct. The theoretical reasons
for this correspondence remain an open question. Nevertheless, the proposed
algorithm remains more practical, as it requires far less parameter tuning to
perform optimally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05862</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05862</id><created>2015-11-18</created><authors><author><keyname>Jones</keyname><forenames>Jeff</forenames></author><author><keyname>Mayne</keyname><forenames>Richard</forenames></author><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Representation of Shape Mediated by Environmental Stimuli in Physarum
  polycephalum and a Multi-agent Model</title><categories>cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The slime mould Physarum polycephalum is known to construct proto- plasmic
transport networks which approximate proximity graphs by forag- ing for
nutrients during its plasmodial life cycle stage. In these networks, nodes are
represented by nutrients and edges are represented by proto- plasmic tubes.
These networks have been shown to be efficient in terms of length and
resilience of the overall network to random damage. However relatively little
research has been performed in the potential for Physarum transport networks to
approximate the overall shape of a dataset. In this paper we distinguish
between connectivity and shape of a planar point dataset and demonstrate, using
scoping experiments with plasmodia of P. polycephalum and a multi-agent model
of the organism, how we can gen- erate representations of the external and
internal shapes of a set of points. As with proximity graphs formed by P.
polycephalum, the behaviour of the plasmodium (real and model) is mediated by
environmental stimuli. We further explore potential morphological computation
approaches with the multi-agent model, presenting methods which approximate the
Convex Hull and the Concave Hull. We demonstrate how a growth parameter in the
model can be used to transition between Convex and Concave Hulls. These results
suggest novel mechanisms of morphological computation mediated by environmental
stimuli.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05865</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05865</id><created>2015-11-18</created><authors><author><keyname>Jones</keyname><forenames>Jeff</forenames></author><author><keyname>Whiting</keyname><forenames>James G. H.</forenames></author><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Quantitative Transformation for Implementation of Adder Circuits in
  Physical Systems</title><categories>cs.ET</categories><journal-ref>Quantitative Transformation for Implementation of Adder Circuits
  in Physical Systems, Biosystems, 134, p. 16-23 (2015)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing devices are composed of spatial arrangements of simple funda-
mental logic gates. These gates may be combined to form more complex adding
circuits and, ultimately, complete computer systems. Implementing classical
adding circuits using unconventional, or even living substrates such as slime
mould Physarum polycephalum, is made difficult and often impracti- cal by the
challenges of branching fan-out of inputs and regions where circuit lines must
cross without interference. In this report we explore whether it is possible to
avoid spatial propagation, branching and crossing completely in the design of
adding circuits. We analyse the input and output patterns of a single-bit full
adder circuit. A simple quantitative transformation of the input patterns which
considers the total number of bits in the input string allows us to map the
respective input combinations to the correct outputs patterns of the full adder
circuit, reducing the circuit combinations from a 2:1 mapping to a 1:1 mapping.
The mapping of inputs to outputs also shows an incremental linear progression,
suggesting its implementation in a range of physical systems. We demonstrate an
example implementation, first in simulation, inspired by self-oscillatory
dynamics of the acellular slime mould Physarum polycephalum. We then assess the
potential implementation using plasmodium of slime mould itself. This simple
transformation may enrich the potential for using unconventional computing
substrates to implement digital circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05866</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05866</id><created>2015-11-18</created><updated>2015-12-21</updated><authors><author><keyname>Latella</keyname><forenames>Diego</forenames><affiliation>CNR-ISTI</affiliation></author><author><keyname>Massink</keyname><forenames>Mieke</forenames><affiliation>CNR-ISTI</affiliation></author><author><keyname>De Vink</keyname><forenames>Erik P</forenames><affiliation>Eindhoven University of Technology - Department of Mathematics and Computer Science</affiliation></author></authors><title>Bisimulation of Labelled State-to-Function Transition Systems
  Coalgebraically</title><categories>cs.LO</categories><proxy>LMCS</proxy><journal-ref>LMCS 11 (4:16) 2015</journal-ref><doi>10.2168/LMCS-11(4:16)2015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Labeled state-to-function transition systems, FuTS for short, are
characterized by transitions which relate states to functions of states over
general semirings, equipped with a rich set of higher-order operators. As such,
FuTS constitute a convenient modeling instrument to deal with process languages
and their quantitative extensions in particular. In this paper, the notion of
bisimulation induced by a FuTS is addressed from a coalgebraic point of view. A
correspondence result is established stating that FuTS-bisimilarity coincides
with behavioural equivalence of the associated functor. As generic examples,
the equivalences underlying substantial fragments of major examples of
quantitative process algebras are related to the bisimilarity of specific FuTS.
The examples range from a stochastic process language, PEPA, to a language for
Interactive Markov Chains, IML, a (discrete) timed process language, TPC, and a
language for Markov Automata, MAL. The equivalences underlying these languages
are related to the bisimilarity of their specific FuTS. By the correspondence
result coalgebraic justification of the equivalences of these calculi is
obtained. The specific selection of languages, besides covering a large variety
of process interaction models and modelling choices involving quantities,
allows us to show different classes of FuTS, namely so-called simple FuTS,
combined FuTS, nested FuTS, and general FuTS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05869</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05869</id><created>2015-11-18</created><authors><author><keyname>Jones</keyname><forenames>Jeff</forenames></author></authors><title>Mechanisms Inducing Parallel Computation in a Model of Physarum
  polycephalum Transport Networks</title><categories>cs.ET</categories><journal-ref>Transport Networks, Parallel Processing Letters, (25), 1, 1540004
  (2015)</journal-ref><doi>10.1142/S0129626415400046</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  P. polycephalum may be considered as a spatially represented parallel
unconventional computing substrate, but how can this `computer' be programmed?
In this paper we examine and catalogue individual low-level mechanisms which
may be used to induce network formation and adaptation in a multi-agent model
of P. polycephalum. These mechanisms include those intrinsic to the model
(particle sensor angle, rotation angle, and scaling parameters) and those
mediated by the environment (stimulus loca- tion, distance, angle,
concentration, engulfment and consumption of nutrients, and the presence of
simulated light irradiation, repellents and obstacles). The mechanisms in- duce
a concurrent integration of chemoattractant and chemorepellent gradients
di?using within the 2D lattice upon which the agent population resides,
stimulating growth, move- ment, morphological adaptation and network
minimisation. Chemoattractant gradients, and their modulation by the engulfment
and consumption of nutrients by the model population, represent an e?cient
outsourcing of spatial computation. The mechanisms may prove useful in
understanding the search strategies and adaptation of distributed organisms
within their environment, in understanding the minimal requirements for com-
plex adaptive behaviours, and in developing methods of spatially programming
parallel unconventional computers and robotic devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05875</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05875</id><created>2015-11-18</created><authors><author><keyname>Rao</keyname><forenames>Micha&#xeb;l</forenames></author><author><keyname>Rosenfeld</keyname><forenames>Matthieu</forenames></author></authors><title>On M\&quot;akel\&quot;a's Conjectures: deciding if a morphic word avoids long
  abelian-powers</title><categories>math.CO cs.DM cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We exhibit an algorithm to decide if the fixed-points of a morphism avoid
(long) abelian repetitions and we use it to show that long abelian squares are
avoidable over the ternary alphabet. This gives a partial answer to one of
M\&quot;akel\&quot;a's questions.
  Our algorithm can also decide if a morphism avoids additive repetitions or
k-abelian repetitions and we use it to show that long 2-abelian square are
avoidable over the binary alphabet and additive repetitions are avoidable over
$\mathbb{Z}^2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05879</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05879</id><created>2015-11-18</created><updated>2016-02-24</updated><authors><author><keyname>Tolias</keyname><forenames>Giorgos</forenames></author><author><keyname>Sicre</keyname><forenames>Ronan</forenames></author><author><keyname>J&#xe9;gou</keyname><forenames>Herv&#xe9;</forenames></author></authors><title>Particular object retrieval with integral max-pooling of CNN activations</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, image representation built upon Convolutional Neural Network (CNN)
has been shown to provide effective descriptors for image search, outperforming
pre-CNN features as short-vector representations. Yet such models are not
compatible with geometry-aware re-ranking methods and still outperformed, on
some particular object retrieval benchmarks, by traditional image search
systems relying on precise descriptor matching, geometric re-ranking, or query
expansion. This work revisits both retrieval stages, namely initial search and
re-ranking, by employing the same primitive information derived from the CNN.
We build compact feature vectors that encode several image regions without the
need to feed multiple inputs to the network. Furthermore, we extend integral
images to handle max-pooling on convolutional layer activations, allowing us to
efficiently localize matching objects. The resulting bounding box is finally
used for image re-ranking. As a result, this paper significantly improves
existing CNN-based recognition pipeline: We report for the first time results
competing with traditional methods on the challenging Oxford5k and Paris6k
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05886</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05886</id><created>2015-11-18</created><authors><author><keyname>Mikkelsen</keyname><forenames>Jesper W.</forenames></author></authors><title>Randomization can be as helpful as a glimpse of the future in online
  computation</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide simple but surprisingly useful direct product theorems for proving
lower bounds on online algorithms with a limited amount of advice about the
future. As a consequence, we are able to translate decades of research on
randomized online algorithms to the advice complexity model. Doing so improves
significantly on the previous best advice complexity lower bounds for many
online problems, or provides the first known lower bounds. For example, if $n$
is the number of requests, we show that:
  (1) A paging algorithm needs $\Omega(n)$ bits of advice to achieve a
competitive ratio better than $H_k=\Omega(\log k)$, where $k$ is the cache
size. Previously, it was only known that $\Omega(n)$ bits of advice were
necessary to achieve a constant competitive ratio smaller than $5/4$.
  (2) Every $O(n^{1-\varepsilon})$-competitive vertex coloring algorithm must
use $\Omega(n\log n)$ bits of advice. Previously, it was only known that
$\Omega(n\log n)$ bits of advice were necessary to be optimal.
  For certain online problems, including the MTS, $k$-server, paging, list
update, and dynamic binary search tree problem, our results imply that
randomization and sublinear advice are equally powerful (if the underlying
metric space or node set is finite). This means that several long-standing open
questions regarding randomized online algorithms can be equivalently stated as
questions regarding online algorithms with sublinear advice. For example, we
show that there exists a deterministic $O(\log k)$-competitive $k$-server
algorithm with advice complexity $o(n)$ if and only if there exists a
randomized $O(\log k)$-competitive $k$-server algorithm without advice.
  Technically, our main direct product theorem is obtained by extending an
information theoretical lower bound technique due to Emek, Fraigniaud, Korman,
and Ros\'en [ICALP'09].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05888</identifier>
 <datestamp>2015-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05888</id><created>2015-11-18</created><updated>2015-12-27</updated><authors><author><keyname>Harwath</keyname><forenames>Frederik</forenames><affiliation>Goethe-Universit&#xc3;&#xa4;t Frankfurt am Main</affiliation></author><author><keyname>Heimberg</keyname><forenames>Lucas</forenames><affiliation>Humboldt-Universit&#xc3;&#xa4;t zu Berlin</affiliation></author><author><keyname>Schweikardt</keyname><forenames>Nicole</forenames><affiliation>Humboldt-Universit&#xc3;&#xa4;t zu Berlin</affiliation></author></authors><title>Preservation and decomposition theorems for bounded degree structures</title><categories>cs.LO</categories><comments>42 pages and 3 figures. This is the full version of: Frederik
  Harwath, Lucas Heimberg, and Nicole Schweikardt. Preservation and
  decomposition theorems for bounded degree structures. In Joint Meeting of the
  23rd EACSL Annual Conference on Computer Science Logic (CSL) and the 29th
  Annual ACM/IEEE Symposium on Logic in Computer Science (LICS), CSL-LICS'14,
  pages 49:1-49:10. ACM, 2014</comments><proxy>LMCS</proxy><journal-ref>LMCS 11 (4:17) 2015</journal-ref><doi>10.2168/LMCS-11(4:17)2015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide elementary algorithms for two preservation theorems for
first-order sentences (FO) on the class &#xe2;&#x84;&#xad;d of all finite structures of degree
at most d: For each FO-sentence that is preserved under extensions
(homomorphisms) on &#xe2;&#x84;&#xad;d, a &#xe2;&#x84;&#xad;d-equivalent existential (existential-positive)
FO-sentence can be constructed in 5-fold (4-fold) exponential time. This is
complemented by lower bounds showing that a 3-fold exponential blow-up of the
computed existential (existential-positive) sentence is unavoidable. Both
algorithms can be extended (while maintaining the upper and lower bounds on
their time complexity) to input first-order sentences with modulo m counting
quantifiers (FO+MODm). Furthermore, we show that for an input FO-formula, a
&#xe2;&#x84;&#xad;d-equivalent Feferman-Vaught decomposition can be computed in 3-fold
exponential time. We also provide a matching lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05892</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05892</id><created>2015-11-18</created><updated>2015-11-19</updated><authors><author><keyname>Tassi</keyname><forenames>Andrea</forenames></author><author><keyname>Chatzigeorgiou</keyname><forenames>Ioannis</forenames></author><author><keyname>Lucani</keyname><forenames>Daniel E.</forenames></author></authors><title>Analysis and Optimization of Sparse Random Linear Network Coding for
  Reliable Multicast Services</title><categories>cs.IT cs.MM cs.NI cs.PF math.IT</categories><comments>To appear on IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Point-to-multipoint communications are expected to play a pivotal role in
next-generation networks. This paper refers to a cellular system transmitting
layered multicast services to a multicast group of users. Reliability of
communications is ensured via different Random Linear Network Coding (RLNC)
techniques. We deal with a fundamental problem: the computational complexity of
the RLNC decoder. The higher the number of decoding operations is, the more the
user's computational overhead grows and, consequently, the faster the battery
of mobile devices drains. By referring to several sparse RLNC techniques, and
without any assumption on the implementation of the RLNC decoder in use, we
provide an efficient way to characterize the performance of users targeted by
ultra-reliable layered multicast services. The proposed modeling allows to
efficiently derive the average number of coded packet transmissions needed to
recover one or more service layers. We design a convex resource allocation
framework that allows to minimize the complexity of the RLNC decoder by jointly
optimizing the transmission parameters and the sparsity of the code. The
designed optimization framework also ensures service guarantees to
predetermined fractions of users. The performance of the proposed optimization
framework is then investigated in a LTE-A eMBMS network multicasting H.264/SVC
video services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05897</identifier>
 <datestamp>2016-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05897</id><created>2015-11-18</created><updated>2016-03-04</updated><authors><author><keyname>Edwards</keyname><forenames>Harrison</forenames></author><author><keyname>Storkey</keyname><forenames>Amos</forenames></author></authors><title>Censoring Representations with an Adversary</title><categories>cs.LG cs.AI stat.ML</categories><comments>Paper accepted to ICLR</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In practice, there are often explicit constraints on what representations or
decisions are acceptable in an application of machine learning. For example it
may be a legal requirement that a decision must not favour a particular group.
Alternatively it can be that that representation of data must not have
identifying information. We address these two related issues by learning
flexible representations that minimize the capability of an adversarial critic.
This adversary is trying to predict the relevant sensitive variable from the
representation, and so minimizing the performance of the adversary ensures
there is little or no information in the representation about the sensitive
variable. We demonstrate this adversarial approach on two problems: making
decisions free from discrimination and removing private information from
images. We formulate the adversarial model as a minimax problem, and optimize
that minimax objective using a stochastic gradient alternate min-max optimizer.
We demonstrate the ability to provide discriminant free representations for
standard test problems, and compare with previous state of the art methods for
fairness, showing statistically significant improvement across most cases. The
flexibility of this method is shown via a novel problem: removing annotations
from images, from unaligned training examples of annotated and unannotated
images, and with no a priori knowledge of the form of annotation provided to
the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05904</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05904</id><created>2015-11-18</created><authors><author><keyname>Wei</keyname><forenames>Lingyu</forenames></author><author><keyname>Huang</keyname><forenames>Qixing</forenames></author><author><keyname>Ceylan</keyname><forenames>Duygu</forenames></author><author><keyname>Vouga</keyname><forenames>Etienne</forenames></author><author><keyname>Li</keyname><forenames>Hao</forenames></author></authors><title>Dense Human Body Correspondences Using Convolutional Networks</title><categories>cs.CV cs.GR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a deep learning approach for finding dense correspondences between
3D scans of people. Our method requires only partial geometric information in
the form of two depth maps or partial reconstructed surfaces, works for humans
in arbitrary poses and wearing any clothing, does not require the two people to
be scanned from similar viewpoints, and runs in real time. We use a deep
convolutional neural network to train a feature descriptor on depth map pixels,
but crucially, rather than training the network to solve the shape
correspondence problem directly, we train it to solve a body region
classification problem, modified to increase the smoothness of the learned
descriptors near region boundaries. This approach ensures that nearby points on
the human body are nearby in feature space, and vice versa, rendering the
feature descriptor suitable for computing dense correspondences between the
scans. We validate our method on real and synthetic data for both clothed and
unclothed humans, and show that our correspondences are more robust than is
possible with state-of-the-art unsupervised methods, and more accurate than
those found using methods that require full watertight 3D geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05911</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05911</id><created>2015-11-18</created><updated>2015-11-19</updated><authors><author><keyname>Zong</keyname><forenames>Bo</forenames></author><author><keyname>Xiao</keyname><forenames>Xusheng</forenames></author><author><keyname>Li</keyname><forenames>Zhichun</forenames></author><author><keyname>Wu</keyname><forenames>Zhenyu</forenames></author><author><keyname>Qian</keyname><forenames>Zhiyun</forenames></author><author><keyname>Yan</keyname><forenames>Xifeng</forenames></author><author><keyname>Singh</keyname><forenames>Ambuj K.</forenames></author><author><keyname>Jiang</keyname><forenames>Guofei</forenames></author></authors><title>Behavior Query Discovery in System-Generated Temporal Graphs</title><categories>cs.SI cs.AI cs.DB</categories><comments>The full version of the paper &quot;Behavior Query Discovery in
  System-Generated Temporal Graphs&quot;, to appear in VLDB'16</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Computer system monitoring generates huge amounts of logs that record the
interaction of system entities. How to query such data to better understand
system behaviors and identify potential system risks and malicious behaviors
becomes a challenging task for system administrators due to the dynamics and
heterogeneity of the data. System monitoring data are essentially heterogeneous
temporal graphs with nodes being system entities and edges being their
interactions over time. Given the complexity of such graphs, it becomes
time-consuming for system administrators to manually formulate useful queries
in order to examine abnormal activities, attacks, and vulnerabilities in
computer systems.
  In this work, we investigate how to query temporal graphs and treat query
formulation as a discriminative temporal graph pattern mining problem. We
introduce TGMiner to mine discriminative patterns from system logs, and these
patterns can be taken as templates for building more complex queries. TGMiner
leverages temporal information in graphs to prune graph patterns that share
similar growth trend without compromising pattern quality. Experimental results
on real system data show that TGMiner is 6-32 times faster than baseline
methods. The discovered patterns were verified by system experts; they achieved
high precision (97%) and recall (91%).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05913</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05913</id><created>2015-11-18</created><authors><author><keyname>Borowski</keyname><forenames>Holly</forenames></author><author><keyname>Marden</keyname><forenames>Jason</forenames></author></authors><title>Fast Convergence in Semi-Anonymous Potential Games</title><categories>cs.GT</categories><comments>12 pages, 5 figures (including bio pictures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Log-linear learning has been extensively studied in both the game theoretic
and distributed control literature. It is appealing for many applications
because it often guarantees that the agents' collective behavior will converge
in probability to the optimal system configuration. However, the worst case
convergence time can be prohibitively long, i.e., exponential in the number of
players. We formalize a modified log-linear learning algorithm whose worst case
convergence time is roughly linear in the number of players. We prove this
characterization for a class of potential games where agents' utility functions
can be expressed as a function of aggregate behavior within a finite collection
of populations. Finally, we show that the convergence time remains roughly
linear in the number of players even when the players are permitted to enter
and exit the game over time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05914</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05914</id><created>2015-11-18</created><authors><author><keyname>Barrett</keyname><forenames>Daniel Paul</forenames></author><author><keyname>Xu</keyname><forenames>Ran</forenames></author><author><keyname>Yu</keyname><forenames>Haonan</forenames></author><author><keyname>Siskind</keyname><forenames>Jeffrey Mark</forenames></author></authors><title>Collecting and Annotating the Large Continuous Action Dataset</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We make available to the community a new dataset to support
action-recognition research. This dataset is different from prior datasets in
several key ways. It is significantly larger. It contains streaming video with
long segments containing multiple action occurrences that often overlap in
space and/or time. All actions were filmed in the same collection of
backgrounds so that background gives little clue as to action class. We had
five humans replicate the annotation of temporal extent of action occurrences
labeled with their class and measured a surprisingly low level of intercoder
agreement. A baseline experiment shows that recent state-of-the-art methods
perform poorly on this dataset. This suggests that this will be a challenging
dataset to foster advances in action-recognition research. This manuscript
serves to describe the novel content and characteristics of the LCA dataset,
present the design decisions made when filming the dataset, and document the
novel methods employed to annotate the dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05926</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05926</id><created>2015-11-18</created><authors><author><keyname>Nguyen</keyname><forenames>Thien Huu</forenames></author><author><keyname>Grishman</keyname><forenames>Ralph</forenames></author></authors><title>Combining Neural Networks and Log-linear Models to Improve Relation
  Extraction</title><categories>cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last decade has witnessed the success of the traditional feature-based
method on exploiting the discrete structures such as words or lexical patterns
to extract relations from text. Recently, convolutional and recurrent neural
networks has provided very effective mechanisms to capture the hidden
structures within sentences via continuous representations, thereby
significantly advancing the performance of relation extraction. The advantage
of convolutional neural networks is their capacity to generalize the
consecutive k-grams in the sentences while recurrent neural networks are
effective to encode long ranges of sentence context. This paper proposes to
combine the traditional feature-based method, the convolutional and recurrent
neural networks to simultaneously benefit from their advantages. Our systematic
evaluation of different network architectures and combination methods
demonstrates the effectiveness of this approach and results in the
state-of-the-art performance on the ACE 2005 and SemEval dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05932</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05932</id><created>2015-11-18</created><authors><author><keyname>Lacoste-Julien</keyname><forenames>Simon</forenames></author><author><keyname>Jaggi</keyname><forenames>Martin</forenames></author></authors><title>On the Global Linear Convergence of Frank-Wolfe Optimization Variants</title><categories>math.OC cs.LG stat.ML</categories><comments>Appears in: Advances in Neural Information Processing Systems 28
  (NIPS 2015). 26 pages</comments><msc-class>90C52, 90C90, 68T05</msc-class><acm-class>G.1.6; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Frank-Wolfe (FW) optimization algorithm has lately re-gained popularity
thanks in particular to its ability to nicely handle the structured constraints
appearing in machine learning applications. However, its convergence rate is
known to be slow (sublinear) when the solution lies at the boundary. A simple
less-known fix is to add the possibility to take 'away steps' during
optimization, an operation that importantly does not require a feasibility
oracle. In this paper, we highlight and clarify several variants of the
Frank-Wolfe optimization algorithm that have been successfully applied in
practice: away-steps FW, pairwise FW, fully-corrective FW and Wolfe's minimum
norm point algorithm, and prove for the first time that they all enjoy global
linear convergence, under a weaker condition than strong convexity of the
objective. The constant in the convergence rate has an elegant interpretation
as the product of the (classical) condition number of the function with a novel
geometric quantity that plays the role of a 'condition number' of the
constraint set. We provide pointers to where these algorithms have made a
difference in practice, in particular with the flow polytope, the marginal
polytope and the base polytope for submodular optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05933</identifier>
 <datestamp>2016-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05933</id><created>2015-11-18</created><updated>2016-03-03</updated><authors><author><keyname>Dasgupta</keyname><forenames>Sayantan</forenames></author></authors><title>Probabilistic K-Means using Method of Moments</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  K-means is one of the most widely used algorithms for clustering in Data
Mining applications, which attempts to minimize the sum of Euclidean distance
of the points in the clusters from the respective means of the clusters. The
simplicity and scalability of K-means makes it very appealing. However, K-means
suffers from local minima problem, and comes with no guarantee to converge to
the optimal cost. K-means++ tries to address the problem by seeding the means
using a distance based sampling scheme. However, seeding the means in K-means++
needs O(K) passes through the entire dataset, which could be very costly in
large amount of dataset. Here we propose a method of seeding initial means
based on higher order moments of the data, which takes O(1) passes through the
entire dataset to extract the initial set of means. Our method yields
competitive performance with respect to all the existing K-means algorithms,
whilst avoiding the expensive mean selection steps of K-means++ and other
heuristics. We demonstrate the performance of our algorithm in comparison with
the existing algorithms on various benchmark datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05939</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05939</id><created>2015-11-18</created><updated>2016-03-01</updated><authors><author><keyname>Rippel</keyname><forenames>Oren</forenames></author><author><keyname>Paluri</keyname><forenames>Manohar</forenames></author><author><keyname>Dollar</keyname><forenames>Piotr</forenames></author><author><keyname>Bourdev</keyname><forenames>Lubomir</forenames></author></authors><title>Metric Learning with Adaptive Density Discrimination</title><categories>stat.ML cs.LG</categories><comments>ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distance metric learning (DML) approaches learn a transformation to a
representation space where distance is in correspondence with a predefined
notion of similarity. While such models offer a number of compelling benefits,
it has been difficult for these to compete with modern classification
algorithms in performance and even in feature extraction.
  In this work, we propose a novel approach explicitly designed to address a
number of subtle yet important issues which have stymied earlier DML
algorithms. It maintains an explicit model of the distributions of the
different classes in representation space. It then employs this knowledge to
adaptively assess similarity, and achieve local discrimination by penalizing
class distribution overlap.
  We demonstrate the effectiveness of this idea on several tasks. Our approach
achieves state-of-the-art classification results on a number of fine-grained
visual recognition datasets, surpassing the standard softmax classifier and
outperforming triplet loss by a relative margin of 30-40%. In terms of
computational performance, it alleviates training inefficiencies in the
traditional triplet loss, reaching the same error in 5-30 times fewer
iterations. Beyond classification, we further validate the saliency of the
learnt representations via their attribute concentration and hierarchy recovery
properties, achieving 10-25% relative gains on the softmax classifier and
25-50% on triplet loss in these tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05942</identifier>
 <datestamp>2016-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05942</id><created>2015-11-18</created><updated>2016-02-17</updated><authors><author><keyname>Choi</keyname><forenames>Edward</forenames></author><author><keyname>Bahadori</keyname><forenames>Mohammad Taha</forenames></author><author><keyname>Sun</keyname><forenames>Jimeng</forenames></author></authors><title>Doctor AI: Predicting Clinical Events via Recurrent Neural Networks</title><categories>cs.LG</categories><comments>Updating</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large amount of Electronic Health Record (EHR) data have been collected over
millions of patients over multiple years. The rich longitudinal EHR data
documented the collective experiences of physicians including diagnosis,
medication prescription and procedures. We argue it is possible now to leverage
the EHR data to model how physicians behave, and we call our model Doctor AI.
Towards this direction of modeling clinical behavior of physicians, we develop
a successful application of Recurrent Neural Networks (RNN) to jointly forecast
the future disease diagnosis and medication prescription along with their
timing. Unlike traditional classification models where a single target is of
interest, our model can assess the entire history of patients and make
continuous and multilabel predictions based on patients' historical data. We
evaluate the performance of the proposed method on a large real-world EHR data
over 260K patients over 8 years. We observed Doctor AI can perform differential
diagnosis with similar accuracy to physicians. In particular, Doctor AI
achieves up to 79% recall@30, significantly higher than several baselines.
Moreover, we demonstrate great generalizability of Doctor AI by applying the
resulting models on data from a completely different medication institution
achieving comparable performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05943</identifier>
 <datestamp>2015-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05943</id><created>2015-11-18</created><authors><author><keyname>Pal</keyname><forenames>Dipan K.</forenames></author><author><keyname>Savvides</keyname><forenames>Marios</forenames></author></authors><title>Unitary-Group Invariant Kernels and Features from Transformed Unlabeled
  Data</title><categories>cs.LG</categories><comments>11 page main paper (including references), 2 page supplementary, for
  a total of 13 pages. Submitted for review at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of representations invariant to common transformations of the data
is important to learning. Most techniques have focused on local approximate
invariance implemented within expensive optimization frameworks lacking
explicit theoretical guarantees. In this paper, we study kernels that are
invariant to the unitary group while having theoretical guarantees in
addressing practical issues such as (1) unavailability of transformed versions
of labelled data and (2) not observing all transformations. We present a
theoretically motivated alternate approach to the invariant kernel SVM. Unlike
previous approaches to the invariant SVM, the proposed formulation solves both
issues mentioned. We also present a kernel extension of a recent technique to
extract linear unitary-group invariant features addressing both issues and
extend some guarantees regarding invariance and stability. We present
experiments on the UCI ML datasets to illustrate and validate our methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05946</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05946</id><created>2015-11-18</created><updated>2016-02-29</updated><authors><author><keyname>Moczulski</keyname><forenames>Marcin</forenames></author><author><keyname>Denil</keyname><forenames>Misha</forenames></author><author><keyname>Appleyard</keyname><forenames>Jeremy</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>ACDC: A Structured Efficient Linear Layer</title><categories>cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear layer is one of the most pervasive modules in deep learning
representations. However, it requires $O(N^2)$ parameters and $O(N^2)$
operations. These costs can be prohibitive in mobile applications or prevent
scaling in many domains. Here, we introduce a deep, differentiable,
fully-connected neural network module composed of diagonal matrices of
parameters, $\mathbf{A}$ and $\mathbf{D}$, and the discrete cosine transform
$\mathbf{C}$. The core module, structured as $\mathbf{ACDC^{-1}}$, has $O(N)$
parameters and incurs $O(N log N )$ operations. We present theoretical results
showing how deep cascades of ACDC layers approximate linear layers. ACDC is,
however, a stand-alone module and can be used in combination with any other
types of module. In our experiments, we show that it can indeed be successfully
interleaved with ReLU modules in convolutional neural networks for image
recognition. Our experiments also study critical factors in the training of
these structured modules, including initialization and depth. Finally, this
paper also provides a connection between structured linear transforms used in
deep learning and the field of Fourier optics, illustrating how ACDC could in
principle be implemented with lenses and diffractive elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05950</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05950</id><created>2015-11-18</created><updated>2015-12-19</updated><authors><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Gupta</keyname><forenames>Suyog</forenames></author><author><keyname>Lian</keyname><forenames>Xiangru</forenames></author><author><keyname>Liu</keyname><forenames>Ji</forenames></author></authors><title>Staleness-aware Async-SGD for Distributed Deep Learning</title><categories>cs.LG</categories><comments>Under review as a conference paper at ICLR 2016. arXiv admin note:
  text overlap with arXiv:1509.04210</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the effect of stale (delayed) gradient updates within
the context of asynchronous stochastic gradient descent (Async-SGD)
optimization for distributed training of deep neural networks. We demonstrate
that our implementation of Async-SGD on a HPC cluster can achieve a tight bound
on the gradient staleness while providing near-linear speedup. We propose a
variant of the SGD algorithm in which the learning rate is modulated according
to the gradient staleness and provide theoretical guarantees for convergence of
this algorithm. Experimental verification is performed on commonly-used image
classification benchmarks: CIFAR10 and ImageNet to demonstrate the
effectiveness of the proposed approach. Additionally, our experiments show that
there exists a fundamental tradeoff between model accuracy and runtime
performance that places a limit on the maximum amount of parallelism that may
be extracted from this workload under the constraints of preserving the model
quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05952</identifier>
 <datestamp>2016-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05952</id><created>2015-11-18</created><updated>2016-02-25</updated><authors><author><keyname>Schaul</keyname><forenames>Tom</forenames></author><author><keyname>Quan</keyname><forenames>John</forenames></author><author><keyname>Antonoglou</keyname><forenames>Ioannis</forenames></author><author><keyname>Silver</keyname><forenames>David</forenames></author></authors><title>Prioritized Experience Replay</title><categories>cs.LG</categories><comments>Published at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Experience replay lets online reinforcement learning agents remember and
reuse experiences from the past. In prior work, experience transitions were
uniformly sampled from a replay memory. However, this approach simply replays
transitions at the same frequency that they were originally experienced,
regardless of their significance. In this paper we develop a framework for
prioritizing experience, so as to replay important transitions more frequently,
and therefore learn more efficiently. We use prioritized experience replay in
Deep Q-Networks (DQN), a reinforcement learning algorithm that achieved
human-level performance across many Atari games. DQN with prioritized
experience replay achieves a new state-of-the-art, outperforming DQN with
uniform replay on 41 out of 49 games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05957</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05957</id><created>2015-11-18</created><authors><author><keyname>S&#xe1;nchez</keyname><forenames>David</forenames></author><author><keyname>Mart&#xed;nez</keyname><forenames>Sergio</forenames></author><author><keyname>Domingo-Ferrer</keyname><forenames>Josep</forenames></author></authors><title>Supplementary Materials for &quot;How to Avoid Reidentification with Proper
  Anonymization&quot;</title><categories>cs.CR</categories><msc-class>68</msc-class><acm-class>K.4.1</acm-class><journal-ref>Supplementary materials to a Technical Comment in &quot;Science&quot; (2015)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent study claims that most customers can be reidentified from an
anonymized credit card transaction database. Such a claim deserves detailed
quantitative scrutiny, as it might seriously undermine the willingness of data
owners and subjects to share data for research. We demonstrate here that the
reported reidentification risk is due to the choice of a poor anonymization
method, to flawed experiments and to a general disregard of 40 years of
anonymization literature. We show how to properly anonymize transaction data,
in order to reduce unequivocal reidentifications to zero while retaining even
more analytical utility than with the poor anonymization mechanism. In
conclusion, data owners, subjects and users can be reassured that sound privacy
models and anonymization methods exist to produce safe and useful anonymized
data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05958</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05958</id><created>2015-11-18</created><authors><author><keyname>Libby</keyname><forenames>Thomas</forenames></author><author><keyname>Johnson</keyname><forenames>Aaron M.</forenames></author><author><keyname>Chang-Siu</keyname><forenames>Evan</forenames></author><author><keyname>Full</keyname><forenames>Robert J.</forenames></author><author><keyname>Koditschek</keyname><forenames>D. E.</forenames></author></authors><title>Comparative Design, Scaling, and Control of Appendages for Inertial
  Reorientation</title><categories>cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops a comparative framework for the design of an actuated
inertial appendage for planar reorientation. We define the Inertial
Reorientation template, the simplest model of this behavior, and leverage its
linear dynamics to reveal the design constraints linking a task with the body
designs capable of completing it. As practicable inertial appendage designs
lead to physical bodies that are generally more complex, we advance a notion of
&quot;anchoring&quot; whereby a judicious choice of physical design in concert with an
appropriate control policy yields a system whose closed loop dynamics are
sufficiently captured by the template as to permit all further design to take
place in its far simpler parameter space. This approach is effective and
accurate over the diverse design spaces afforded by existing platforms,
enabling performance comparison through the shared task space. We analyze
examples from the literature and find advantages to each body type, but
conclude that tails provide the highest potential performance for reasonable
designs. Thus motivated, we build a physical example by retrofitting a tail to
a RHex robot and present empirical evidence of its efficacy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05960</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05960</id><created>2015-11-18</created><authors><author><keyname>Chen</keyname><forenames>Kan</forenames></author><author><keyname>Wang</keyname><forenames>Jiang</forenames></author><author><keyname>Chen</keyname><forenames>Liang-Chieh</forenames></author><author><keyname>Gao</keyname><forenames>Haoyuan</forenames></author><author><keyname>Xu</keyname><forenames>Wei</forenames></author><author><keyname>Nevatia</keyname><forenames>Ram</forenames></author></authors><title>ABC-CNN: An Attention Based Convolutional Neural Network for Visual
  Question Answering</title><categories>cs.CV</categories><comments>Submitted to CVPR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel attention based deep learning architecture for visual
question answering task (VQA). Given an image and an image related natural
language question, VQA generates the natural language answer for the question.
Generating the correct answers requires the model's attention to focus on the
regions corresponding to the question, because different questions inquire
about the attributes of different image regions. We introduce an attention
based configurable convolutional neural network (ABC-CNN) to learn such
question-guided attention. ABC-CNN determines an attention map for an
image-question pair by convolving the image feature map with configurable
convolutional kernels derived from the question's semantics. We evaluate the
ABC-CNN architecture on three benchmark VQA datasets: Toronto COCO-QA, DAQUAR,
and VQA dataset. ABC-CNN model achieves significant improvements over
state-of-the-art methods on these datasets. The question-guided attention
generated by ABC-CNN is also shown to reflect the regions that are highly
relevant to the questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05986</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05986</id><created>2015-11-15</created><authors><author><keyname>Axler</keyname><forenames>Sheldon</forenames></author></authors><title>Computing with Harmonic Functions</title><categories>cs.MS</categories><comments>65 pages. Software available at http://axler.net/HFT_Math.html</comments><msc-class>31B05, 31B20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document is the manual for a free Mathematica package for computing with
harmonic functions. This package allows the user to make calculations that
would take a prohibitive amount of time if done without a computer. For
example, the Poisson integral of any polynomial can be computed exactly. This
software can find exact solutions to Dirichlet, Neumann, and biDirichlet
problems in R^n with polynomial data on balls, ellipsoids, and annular regions.
It can also find bases for spaces of spherical harmonics, compute projections
onto the harmonic Bergman space, and perform other manipulations with harmonic
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05987</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05987</id><created>2015-11-18</created><authors><author><keyname>Czyzowicz</keyname><forenames>Jerzy</forenames></author><author><keyname>Diks</keyname><forenames>Krzysztof</forenames></author><author><keyname>Moussi</keyname><forenames>Jean</forenames></author><author><keyname>Rytter</keyname><forenames>Wojciech</forenames></author></authors><title>Algorithms for Communication Problems for Mobile Agents Exchanging
  Energy</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider communication problems in the setting of mobile agents deployed
in an edge-weighted network. The assumption of the paper is that each agent has
some energy that it can transfer to any other agent when they meet (together
with the information it holds).
  The paper deals with three communication problems: data delivery,convergecast
and broadcast. These problems are posed for a centralized scheduler which has
full knowledge of the instance.
  It is already known that, without energy exchange, all three problems are
NP-complete even if the network is a line. Surprisingly, if we allow the agents
to exchange energy, we show that all three problems are polynomially solvable
on trees and have linear time algorithms on the line. On the other hand for
general undirected and directed graphs we show that these problems, even if
energy exchange is allowed, are still NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.05996</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.05996</id><created>2015-11-18</created><authors><author><keyname>Owan</keyname><forenames>Parker</forenames></author><author><keyname>Garbini</keyname><forenames>Joseph</forenames></author><author><keyname>Devasia</keyname><forenames>Santosh</forenames></author></authors><title>Uncertainty-based Arbitration of Human-Machine Shared Control</title><categories>cs.SY cs.RO</categories><comments>8 pages, 11 figures. Submitted to the 2016 American Control
  Conference</comments><msc-class>93C85 (primary), 68T40 (secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manufacturing requires consistent production rate and task success for
sustainable operation. Some manufacturing tasks require a semi-autonomous
approach, exploiting the combination of human adaptability and machine
precision and speed, to be cost effective. The main contribution of this paper
is a new approach to determine the level of autonomy for human-machine shared
control based on the automation uncertainty. Moreover, the haptic feedback is
scaled by the level of autonomy to indicate machine confidence to the operator.
Experimentation results, with a human-robot peg-in-a-hole testbed, show more
than 5 times improvement in the error tolerance for task completion with the
shared control approach when compared to a purely autonomous method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06000</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06000</id><created>2015-11-18</created><authors><author><keyname>Schalekamp</keyname><forenames>Frans</forenames></author><author><keyname>van Zuylen</keyname><forenames>Anke</forenames></author><author><keyname>van der Ster</keyname><forenames>Suzanne</forenames></author></authors><title>A Duality Based 2-Approximation Algorithm for Maximum Agreement Forest</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a 2-approximation algorithm for the Maximum Agreement Forest problem
on two rooted binary trees. This NP-hard problem has been studied extensively
in the past two decades, since it can be used to compute the Subtree
Prune-and-Regraft (SPR) distance between two phylogenetic trees. Our result
improves on the very recent 2.5-approximation algorithm due to Shi, Feng, You
and Wang (2015). Our algorithm is the first approximation algorithm for this
problem that uses LP duality in its analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06001</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06001</id><created>2015-11-18</created><updated>2015-11-24</updated><authors><author><keyname>Giordaniello</keyname><forenames>Francesca</forenames></author></authors><title>A pilot study on the daily control capability of s-EMG prosthetic hands
  by amputees</title><categories>cs.LG cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Surface electromyography is a valid tool to gather muscular contraction
signals from intact and amputated subjects. Electromyographic signals can be
used to control prosthetic devices in a noninvasive way distinguishing the
movements performed by the particular EMG electrodes activity. According to the
literature, several algorithms have been used to control prosthetic hands
through s-EMG signals. The main issue is to correctly classify the signals
acquired as the movement actually performed. This work presents a study on the
Support Vector Machine's performance in a short-time period, gained using two
different feature representation (Mean Absolute Value and Waveform Length) of
the sEMG signals. In particular, we paid close attention to the repeatability
problem, that is the capability to achieve a stable and satisfactory level of
accuracy in repeated experiments. Results on a limited setting are encouraging,
as they show an average accuracy above 73% even in the worst case scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06004</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06004</id><created>2015-11-18</created><authors><author><keyname>Graziani</keyname><forenames>Mara</forenames></author></authors><title>Studying the control of non invasive prosthetic hands over large time
  spans</title><categories>cs.LG cs.HC</categories><comments>10 pages, 18 figures, 8 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The electromyography (EMG) signal is the electrical manifestation of a
neuromuscular activation that provides access to physiological processes which
cause the muscle to generate force and produce movement. Non invasive
prostheses use such signals detected by the electrodes placed on the user's
stump, as input to generate hand posture movements according to the intentions
of the prosthesis wearer. The aim of this pilot study is to explore the
repeatability issue, i.e. the ability to classify 17 different hand postures,
represented by EMG signal, across a time span of days by a control algorithm.
Data collection experiments lasted four days and signals were collected from
the forearm of a single subject. We find that Support Vector Machine (SVM)
classification results are high enough to guarantee a correct classification of
more than 10 postures in each moment of the considered time span.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06014</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06014</id><created>2015-11-18</created><updated>2016-02-21</updated><authors><author><keyname>Lattimore</keyname><forenames>Tor</forenames></author></authors><title>Regret Analysis of the Finite-Horizon Gittins Index Strategy for
  Multi-Armed Bandits</title><categories>cs.LG math.ST stat.ML stat.TH</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I analyse the frequentist regret of the famous Gittins index strategy for
multi-armed bandits with Gaussian noise and a finite horizon. Remarkably it
turns out that this approach leads to finite-time regret guarantees comparable
to those available for the popular UCB algorithm. Along the way I derive
finite-time bounds on the Gittins index that are asymptotically exact and may
be of independent interest. I also discuss some computational issues and
present experimental results suggesting that a particular version of the
Gittins index strategy is a modest improvement on existing algorithms with
finite-time regret guarantees such as UCB and Thompson sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06015</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06015</id><created>2015-11-18</created><authors><author><keyname>Caicedo</keyname><forenames>Juan C.</forenames></author><author><keyname>Lazebnik</keyname><forenames>Svetlana</forenames></author></authors><title>Active Object Localization with Deep Reinforcement Learning</title><categories>cs.CV</categories><comments>IEEE ICCV 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an active detection model for localizing objects in scenes. The
model is class-specific and allows an agent to focus attention on candidate
regions for identifying the correct location of a target object. This agent
learns to deform a bounding box using simple transformation actions, with the
goal of determining the most specific location of target objects following
top-down reasoning. The proposed localization agent is trained using deep
reinforcement learning, and evaluated on the Pascal VOC 2007 dataset. We show
that agents guided by the proposed model are able to localize a single instance
of an object after analyzing only between 11 and 25 regions in an image, and
obtain the best detection results among systems that do not use object
proposals for object localization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06017</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06017</id><created>2015-11-18</created><authors><author><keyname>Abernethy</keyname><forenames>Jacob</forenames></author><author><keyname>Lahaie</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Telgarsky</keyname><forenames>Matus</forenames></author></authors><title>Rate of Price Discovery in Iterative Combinatorial Auctions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a class of iterative combinatorial auctions which can be viewed as
subgradient descent methods for the problem of pricing bundles to balance
supply and demand. We provide concrete convergence rates for auctions in this
class, bounding the number of auction rounds needed to reach clearing prices.
Our analysis allows for a variety of pricing schemes, including item, bundle,
and polynomial pricing, and the respective convergence rates confirm that more
expressive pricing schemes come at the cost of slower convergence. We consider
two models of bidder behavior. In the first model, bidders behave
stochastically according to a random utility model, which includes standard
best-response bidding as a special case. In the second model, bidders behave
arbitrarily (even adversarially), and meaningful convergence relies on properly
designed activity rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06018</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06018</id><created>2015-11-18</created><updated>2016-03-01</updated><authors><author><keyname>Kong</keyname><forenames>Lingpeng</forenames></author><author><keyname>Dyer</keyname><forenames>Chris</forenames></author><author><keyname>Smith</keyname><forenames>Noah A.</forenames></author></authors><title>Segmental Recurrent Neural Networks</title><categories>cs.CL cs.LG</categories><comments>10 pages, published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce segmental recurrent neural networks (SRNNs) which define, given
an input sequence, a joint probability distribution over segmentations of the
input and labelings of the segments. Representations of the input segments
(i.e., contiguous subsequences of the input) are computed by encoding their
constituent tokens using bidirectional recurrent neural nets, and these
&quot;segment embeddings&quot; are used to define compatibility scores with output
labels. These local compatibility scores are integrated using a global
semi-Markov conditional random field. Both fully supervised training -- in
which segment boundaries and labels are observed -- as well as partially
supervised training -- in which segment boundaries are latent -- are
straightforward. Experiments on handwriting recognition and joint Chinese word
segmentation/POS tagging show that, compared to models that do not explicitly
represent segments such as BIO tagging schemes and connectionist temporal
classification (CTC), SRNNs obtain substantially higher accuracies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06022</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06022</id><created>2015-11-18</created><authors><author><keyname>Abboud</keyname><forenames>Amir</forenames></author><author><keyname>Hansen</keyname><forenames>Thomas Dueholm</forenames></author><author><keyname>Williams</keyname><forenames>Virginia Vassilevska</forenames></author><author><keyname>Williams</keyname><forenames>Ryan</forenames></author></authors><title>Simulating Branching Programs with Edit Distance and Friends or: A
  Polylog Shaved is a Lower Bound Made</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A recent and active line of work achieves tight lower bounds for fundamental
problems under the Strong Exponential Time Hypothesis (SETH). A celebrated
result of Backurs and Indyk (STOC'15) proves that the Edit Distance of two
sequences of length n cannot be computed in strongly subquadratic time under
SETH. The result was extended by follow-up works to simpler looking problems
like finding the Longest Common Subsequence (LCS).
  SETH is a very strong assumption, asserting that even linear size CNF
formulas cannot be analyzed for satisfiability with an exponential speedup over
exhaustive search. We consider much safer assumptions, e.g. that such a speedup
is impossible for SAT on much more expressive representations, like NC
circuits. Intuitively, this seems much more plausible: NC circuits can
implement complex cryptographic primitives, while CNFs cannot even
approximately compute an XOR of bits.
  Our main result is a surprising reduction from SAT on Branching Programs to
fundamental problems in P like Edit Distance, LCS, and many others. Truly
subquadratic algorithms for these problems therefore have consequences that we
consider to be far more remarkable than merely faster CNF SAT algorithms. For
example, SAT on arbitrary o(n)-depth bounded fan-in circuits (and therefore
also NC-Circuit-SAT) can be solved in (2-eps)^n time.
  A very interesting feature of our work is that we can prove major
consequences even from mildly subquadratic algorithms for Edit Distance or LCS.
For example, we show that if we can shave an arbitrarily large polylog factor
from n^2 for Edit Distance then NEXP does not have non-uniform NC^1 circuits. A
more fine-grained examination shows that even shaving a $\log^c{n}$ factor, for
a specific constant $c \approx 10^3$, already implies new circuit lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06029</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06029</id><created>2015-11-18</created><authors><author><keyname>Corona</keyname><forenames>Eduardo</forenames></author><author><keyname>Rahimian</keyname><forenames>Abtin</forenames></author><author><keyname>Zorin</keyname><forenames>Denis</forenames></author></authors><title>A Tensor-Train accelerated solver for integral equations in complex
  geometries</title><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework using the Tensor Train decomposition (TT) to
accurately and efficiently solve volume and boundary integral equations in
three dimensions. We describe how the TT decomposition can be used as a
hierarchical compression and inversion scheme for matrices arising from the
discretization of integral equations. For a broad range of problems,
computational and storage costs of the inversion scheme are extremely modest
$O(\log N)$ and once the inverse is computed, it can be applied in $O(N\log
N)$.
  We analyze the TT ranks for hierarchically low rank matrices and discuss its
relationship to commonly used hierarchical compression techniques such as FMM,
HSS, and wavelets. We prove that the TT ranks are bounded for
translation-invariant systems and argue that this behavior extends to
non-translation invariant volume and boundary integrals.
  For volume integrals, the TT decomposition provides an efficient direct
solver requiring significantly less memory compared to other fast direct
solvers. We present results demonstrating the remarkable performance of the
TT-based solver when applied to both translation and non-translation invariant
volume integrals in 3D.
  For boundary integral equations, we demonstrate that using a TT decomposition
to construct preconditioners for a Krylov subspace method leads to an efficient
and robust solver with a small memory footprint. We test the TT preconditioners
in the iterative solution of an exterior elliptic boundary value problem
(Laplace) formulated as a boundary integral equation in complex, multiply
connected geometries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06030</identifier>
 <datestamp>2016-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06030</id><created>2015-11-18</created><updated>2016-03-07</updated><authors><author><keyname>Hooi</keyname><forenames>Bryan</forenames></author><author><keyname>Shah</keyname><forenames>Neil</forenames></author><author><keyname>Beutel</keyname><forenames>Alex</forenames></author><author><keyname>Gunnemann</keyname><forenames>Stephan</forenames></author><author><keyname>Akoglu</keyname><forenames>Leman</forenames></author><author><keyname>Kumar</keyname><forenames>Mohit</forenames></author><author><keyname>Makhija</keyname><forenames>Disha</forenames></author><author><keyname>Faloutsos</keyname><forenames>Christos</forenames></author></authors><title>BIRDNEST: Bayesian Inference for Ratings-Fraud Detection</title><categories>cs.AI</categories><comments>9 pages; v2: minor typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Review fraud is a pervasive problem in online commerce, in which fraudulent
sellers write or purchase fake reviews to manipulate perception of their
products and services. Fake reviews are often detected based on several signs,
including 1) they occur in short bursts of time; 2) fraudulent user accounts
have skewed rating distributions. However, these may both be true in any given
dataset. Hence, in this paper, we propose an approach for detecting fraudulent
reviews which combines these 2 approaches in a principled manner, allowing
successful detection even when one of these signs is not present. To combine
these 2 approaches, we formulate our Bayesian Inference for Rating Data (BIRD)
model, a flexible Bayesian model of user rating behavior. Based on our model we
formulate a likelihood-based suspiciousness metric, Normalized Expected
Surprise Total (NEST). We propose a linear-time algorithm for performing
Bayesian inference using our model and computing the metric. Experiments on
real data show that BIRDNEST successfully spots review fraud in large,
real-world graphs: the 50 most suspicious users of the Flipkart platform
flagged by our algorithm were investigated and all identified as fraudulent by
domain experts at Flipkart.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06033</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06033</id><created>2015-11-18</created><authors><author><keyname>Nikolakopoulos</keyname><forenames>Athanasios N.</forenames></author><author><keyname>Kalantzis</keyname><forenames>Vassilis</forenames></author><author><keyname>Garofalakis</keyname><forenames>John D.</forenames></author></authors><title>EIGENREC: An Efficient and Scalable Latent Factor Family for Top-N
  Recommendation</title><categories>cs.IR cs.DB cs.DC cs.NA cs.SI</categories><comments>14 pages, 6 Figures, submitted to the IEEE Transactions on Knowledge
  and Data Engineering. A preliminary version appeared in
  http://dl.acm.org/citation.cfm?id=2611078</comments><acm-class>H.3.3; H.2.8; G.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparsity presents one of the major challenges of Collaborative Filtering.
Graph-based methods are known to alleviate its effects, however their use is
often computationally prohibitive; Latent-Factor methods, on the other hand,
present a reasonable and viable alternative. In this paper, we introduce
EigenRec; a versatile and efficient Latent-Factor framework for Top-N
Recommendations, that generalizes the well-known PureSVD algorithm (a)
providing intuition about its inner structure, (b) paving the path towards
improving its efficacy and, at the same time, (c) reducing its complexity. One
of our central goals in this work is to ensure the applicability of our method
in realistic big-data scenarios. To this end, we propose building our model
using a computationally efficient Lanczos-based procedure, we discuss its
Parallel Implementation in distributed computing environments, and we verify
its favourable performance using real-world datasets. Furthermore, from a
qualitative point of view, a comprehensive set of experiments on the MovieLens
and the Yahoo!R2Music datasets based on widely applied performance metrics,
indicate that EigenRec outperforms several state-of-the-art algorithms, in
terms of Standard and Long-Tail recommendation accuracy, exhibiting low
susceptibility to sparsity, even in its most extreme manifestations -- the
Cold-Start problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06034</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06034</id><created>2015-11-18</created><authors><author><keyname>Song</keyname><forenames>Wentu</forenames></author><author><keyname>Yuen</keyname><forenames>Chau</forenames></author></authors><title>Binary Locally Repairable Codes ---Sequential Repair for Multiple
  Erasures</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Locally repairable codes (LRC) for distribute storage allow two approaches to
locally repair multiple failed nodes: 1) parallel approach, by which each
newcomer access a set of $r$ live nodes $(r$ is the repair locality$)$ to
download data and recover the lost packet; and 2) sequential approach, by which
the newcomers are properly ordered and each newcomer access a set of $r$ other
nodes, which can be either a live node or a newcomer ordered before it. An
$[n,k]$ linear code with locality $r$ and allows local repair for up to $t$
failed nodes by sequential approach is called an $(n,k,r,t)$-exact locally
repairable code (ELRC).
  In this paper, we present a family of binary codes which is equivalent to the
direct product of $m$ copies of the $[r+1,r]$ single-parity-check code. We
prove that such codes are $(n,k,r,t)$-ELRC with $n=(r+1)^m,k=r^m$ and
$t=2^m-1$, which implies that they permit local repair for up to $2^m-1$
erasures by sequential approach. Our result shows that the sequential approach
has much bigger advantage than parallel approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06035</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06035</id><created>2015-11-18</created><updated>2016-02-28</updated><authors><author><keyname>Dice</keyname><forenames>Dave</forenames></author></authors><title>Malthusian Locks</title><categories>cs.DC</categories><acm-class>D.4.1; D.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applications running in modern multithreaded environments are sometimes
\emph{over-threaded}. The excess threads do not improve performance, and in
fact may act to degrade performance via \emph{scalability collapse}. Often,
such software also has highly contended locks. We opportunistically leverage
the existence of such locks by modifying the lock admission policy so as to
intentionally limit the number of threads circulating over the lock in a given
period. Specifically, if there are more threads circulating than are necessary
to keep the lock saturated, our approach will selectively cull and passivate
some of those threads. We borrow the concept of \emph{swapping} from the field
of memory management and intentionally impose \emph{concurrency restriction}
(CR) if a lock is oversubscribed. In the worst case CR does no harm, but it
often yields performance benefits. The resultant admission order is unfair over
the short term but we explicitly provide long-term fairness by periodically
shifting threads between the set of passivated threads and those actively
circulating. Our approach is palliative, but often effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06036</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06036</id><created>2015-11-18</created><authors><author><keyname>Ohzeki</keyname><forenames>Masayuki</forenames></author></authors><title>Stochastic gradient method with accelerated stochastic dynamics</title><categories>stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.CV</categories><comments>12 pages, proceedings for International Meeting on High-Dimensional
  Data Driven Science (HD3-2015)
  (http://www.sparse-modeling.jp/HD3-2015/index_e.html)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel technique to implement stochastic gradient
methods, which are beneficial for learning from large datasets, through
accelerated stochastic dynamics. A stochastic gradient method is based on
mini-batch learning for reducing the computational cost when the amount of data
is large. The stochasticity of the gradient can be mitigated by the injection
of Gaussian noise, which yields the stochastic Langevin gradient method; this
method can be used for Bayesian posterior sampling. However, the performance of
the stochastic Langevin gradient method depends on the mixing rate of the
stochastic dynamics. In this study, we propose violating the detailed balance
condition to enhance the mixing rate. Recent studies have revealed that
violating the detailed balance condition accelerates the convergence to a
stationary state and reduces the correlation time between the samplings. We
implement this violation of the detailed balance condition in the stochastic
gradient Langevin method and test our method for a simple model to demonstrate
its performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06037</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06037</id><created>2015-11-18</created><authors><author><keyname>Iriza</keyname><forenames>Alexander</forenames></author></authors><title>Enumeration and Random Generation of Unlabeled Classes of Graphs: A
  Practical Study of Cycle Pointing and the Dissymmetry Theorem</title><categories>cs.DM cs.DS math.CO</categories><comments>59 pages, 43 figures. Master's thesis, supervised by J\'er\'emie
  Lumbroso and Robert Sedgewick. Full code available at
  https://github.com/alexiriza/unlabeled-graph-samplers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our work studies the enumeration and random generation of unlabeled
combinatorial classes of unrooted graphs. While the technique of vertex
pointing provides a straightforward procedure for analyzing a labeled class of
unrooted graphs by first studying its rooted counterpart, the existence of
nontrivial symmetries in the unlabeled case causes this technique to break
down. Instead, techniques such as the dissymmetry theorem (of Otter) and cycle
pointing (of Bodirsky et al.) have emerged in the unlabeled case, with the
former providing an enumeration of the class and the latter providing both an
enumeration and an unbiased sampler. In this work, we extend the power of the
dissymmetry theorem by showing that it in fact provides a Boltzmann sampler for
the class in question. We then present an exposition of the cycle pointing
technique, with a focus on the enumeration and random generation of the
underlying unpointed class. Finally, we apply cycle pointing to enumerate and
implement samplers for the classes of distance-hereditary graphs and three-leaf
power graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06038</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06038</id><created>2015-11-18</created><updated>2016-01-07</updated><authors><author><keyname>Miao</keyname><forenames>Yishu</forenames></author><author><keyname>Yu</keyname><forenames>Lei</forenames></author><author><keyname>Blunsom</keyname><forenames>Phil</forenames></author></authors><title>Neural Variational Inference for Text Processing</title><categories>cs.CL cs.LG stat.ML</categories><comments>ICLR 2016 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent advances in neural variational inference have spawned a renaissance in
deep latent variable models. In this paper we introduce a generic variational
inference framework for generative and conditional models of text. While
traditional variational methods derive an analytic approximation for the
intractable distributions over latent variables, here we construct an inference
network conditioned on the discrete text input to provide the variational
distribution. We validate this framework on two very different text modelling
applications, generative document modelling and supervised question answering.
Our neural variational document model combines a continuous stochastic document
representation with a bag-of-words generative model and achieves the lowest
reported perplexities on two standard test corpora. The neural answer selection
model employs a stochastic representation layer within an attention mechanism
to extract the semantics between a question and answer pair. On two question
answering benchmarks this model exceeds all previous published benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06040</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06040</id><created>2015-11-18</created><authors><author><keyname>Ibrahim</keyname><forenames>Moustafa</forenames></author><author><keyname>Muralidharan</keyname><forenames>Srikanth</forenames></author><author><keyname>Deng</keyname><forenames>Zhiwei</forenames></author><author><keyname>Vahdat</keyname><forenames>Arash</forenames></author><author><keyname>Mori</keyname><forenames>Greg</forenames></author></authors><title>A Hierarchical Deep Temporal Model for Group Activity Recognition</title><categories>cs.CV</categories><comments>cs.cv</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In group activity recognition, the temporal dynamics of the whole activity
can be inferred based on the dynamics of the individual people representing the
activity. We build a deep model to capture these dynamics based on LSTM
(long-short term memory) models. To make use of these ob- servations, we
present a 2-stage deep temporal model for the group activity recognition
problem. In our model, a LSTM model is designed to represent action dynamics of
in- dividual people in a sequence and another LSTM model is designed to
aggregate human-level information for whole activity understanding. We evaluate
our model over two datasets: the collective activity dataset and a new volley-
ball dataset. Experimental results demonstrate that our proposed model improves
group activity recognition perfor- mance with compared to baseline methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06049</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06049</id><created>2015-11-18</created><authors><author><keyname>Meng</keyname><forenames>Deyu</forenames></author><author><keyname>Zhao</keyname><forenames>Qian</forenames></author></authors><title>What Objective Does Self-paced Learning Indeed Optimize?</title><categories>cs.LG cs.CV</categories><comments>11 pages, 2 figures</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Self-paced learning (SPL) has been attracting increasing attention in machine
learning and computer vision. Albeit empirically substantiated to be effective,
the investigation on its theoretical insight is still a blank. It is even
unknown that what objective a general SPL regime converges to. To this issue,
this study attempts to initially provide some new insights under this
&quot;heuristic&quot; learning scheme. Specifically, we prove that the solving strategy
on SPL exactly accords with a majorization minimization algorithm, a well known
technique in optimization and machine learning, implemented on a latent
objective. A more interesting finding is that, the loss function contained in
this latent objective has a similar configuration with non-convex regularized
penalty, an attractive topic in statistics and machine learning. In particular,
we show that the previous hard and linear self-paced regularizers are
equivalent to the capped norm and minimax concave plus penalties, respectively,
both being widely investigated in statistics. Such connections between SPL and
previous known researches enhance new insightful comprehension on SPL, like
convergence and parameter setting rationality. The correctness of the proposed
theory is substantiated by experimental results on synthetic and UCI data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06051</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06051</id><created>2015-11-18</created><updated>2016-02-28</updated><authors><author><keyname>Moritz</keyname><forenames>Philipp</forenames></author><author><keyname>Nishihara</keyname><forenames>Robert</forenames></author><author><keyname>Stoica</keyname><forenames>Ion</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>SparkNet: Training Deep Networks in Spark</title><categories>stat.ML cs.DC cs.LG cs.NE math.OC</categories><comments>12 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Training deep networks is a time-consuming process, with networks for object
recognition often requiring multiple days to train. For this reason, leveraging
the resources of a cluster to speed up training is an important area of work.
However, widely-popular batch-processing computational frameworks like
MapReduce and Spark were not designed to support the asynchronous and
communication-intensive workloads of existing distributed deep learning
systems. We introduce SparkNet, a framework for training deep networks in
Spark. Our implementation includes a convenient interface for reading data from
Spark RDDs, a Scala interface to the Caffe deep learning framework, and a
lightweight multi-dimensional tensor library. Using a simple parallelization
scheme for stochastic gradient descent, SparkNet scales well with the cluster
size and tolerates very high-latency communication. Furthermore, it is easy to
deploy and use with no parameter tuning, and it is compatible with existing
Caffe models. We quantify the dependence of the speedup obtained by SparkNet on
the number of machines, the communication frequency, and the cluster's
communication overhead, and we benchmark our system's performance on the
ImageNet dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06052</identifier>
 <datestamp>2015-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06052</id><created>2015-11-18</created><updated>2015-12-23</updated><authors><author><keyname>Yang</keyname><forenames>Yi</forenames></author><author><keyname>Eisenstein</keyname><forenames>Jacob</forenames></author></authors><title>Putting Things in Context: Community-specific Embedding Projections for
  Sentiment Analysis</title><categories>cs.CL cs.AI cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variation in language is ubiquitous, and is particularly evident in newer
forms of writing such as social media. Fortunately, variation is not random,
but is usually linked to social factors. By exploiting linguistic homophily ---
the tendency of socially linked individuals to use language similarly --- it is
possible to build models that are more robust to variation. In this paper, we
focus on social network communities, which make it possible to generalize
sociolinguistic properties from authors in the training set to authors in the
test sets, without requiring demographic author metadata. We detect communities
via standard graph clustering algorithms, and then exploit these communities by
learning community-specific projections of word embeddings. These projections
capture shifts in word meaning in different social groups; by modeling them, we
are able to improve the overall accuracy of Twitter sentiment analysis by a
significant margin over competitive prior work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06053</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06053</id><created>2015-11-18</created><updated>2015-11-23</updated><authors><author><keyname>Goyal</keyname><forenames>Nitesh</forenames></author></authors><title>Designing for Collaborative Sensemaking: Using Expert &amp; Non-Expert Crowd</title><categories>cs.HC</categories><comments>conference in Companion of The Third AAAI Conference on Human
  Computation and Crowdsourcing (HCOMP-2015). arXiv admin note: substantial
  text overlap with arXiv:1511.05737</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crime solving is a domain where solution discovery is often serendipitous.
Unstructured mechanisms, like Reddit, for crime solving through crowds have
failed so far. Mechanisms, collaborations, workflows, and micro-tasks necessary
for successful crime solving might also vary across different crimes.
Cognitively, while experts might have deeper domain knowledge, they might also
fall prey to biased analysis. Non-experts, while lacking formal training, might
instead offer non-conventional perspectives requiring direction. The analytical
process is itself an iterative process of foraging and sensemaking. Users would
explore to broaden solution space and narrow down to a solution iteratively
until identifying the global maxima instead of local maxima. In this proposal,
my research aims to design systems for enabling complex sensemaking tasks that
require collaboration between remotely located non-expert crowds with expert
crowds to compensate for their cognitive challenges and lack of training. This
would require better understanding of the structure, workflow, and micro-tasks
necessary for successful collaborations. This proposal builds upon previous
work on collaborative sensemaking between remote partners in lab experiments
and endeavors to scale it across multiple team members, with varying expertise
levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06061</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06061</id><created>2015-11-19</created><authors><author><keyname>Lokhandwala</keyname><forenames>Hatim</forenames></author><author><keyname>Kala</keyname><forenames>Srikant Manas</forenames></author><author><keyname>Tamma</keyname><forenames>Bheemarjuna Reddy</forenames></author></authors><title>Min-O-Mee: A Proximity Based Network Application Leveraging The AllJoyn
  Framework</title><categories>cs.NI</categories><comments>Accepted in 2015 International Conference on Computing and Network
  Communications (CoCoNet'15) (IEEE)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Close proximity of mobile devices can be utilized to create ad hoc and
dynamic networks. These mobile Proximity Based Networks (PBNs) are
Opportunistic Networks that enable devices to identify and communicate with
each other without relying on any communication infrastructure. In addition,
these networks are self organizing, highly dynamic and facilitate effective
real-time communication. These characteristics render them very useful in a
wide variety of complex scenarios such as vehicular communication, e-health,
disaster networks, mobile social networks etc. In this work we employ the
AllJoyn framework from Qualcomm which facilitates smooth discovery, attachment
and data sharing between devices in close proximity. We develop
\textit{Min-O-Mee}, a Minutes-of-Meeting app prototype in the Android platform,
utilizing the AllJoyn framework. Min-O-Mee allows one of the participants to
create a minutes-of-meeting document which can be shared with and edited by the
other participants in the meeting. The app harnesses the spatial proximity of
participants in a meeting and enables seamless data exchange between them. This
characteristic allows Min-O-Mee to share not just minutes-of-meeting, but any
data that needs to be exchanged among the participants, making it a versatile
app. Further, we extend the basic AllJoyn framework to enable multi-hop
communication among the devices in the PBN. We devise a novel routing mechanism
that is suited to a proximity centric wireless network as it facilitates data
routing and delivery over several hops to devices that are at the fringe of the
PBN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06062</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06062</id><created>2015-11-19</created><authors><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Beijbom</keyname><forenames>Oscar</forenames></author><author><keyname>Zhang</keyname><forenames>Ning</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Compact Bilinear Pooling</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bilinear models has been shown to achieve impressive performance on a wide
range of visual tasks, such as semantic segmentation, fine grained recognition
and face recognition. However, bilinear features are high dimensional,
typically on the order of hundreds of thousands to a few million, which makes
them impractical for subsequent analysis. We propose two compact bilinear
representations with the same discriminative power as the full bilinear
representation but with only a few thousand dimensions. Our compact
representations allow back-propagation of classification errors enabling an
end-to-end optimization of the visual recognition system. The compact bilinear
representations are derived through a novel kernelized analysis of bilinear
pooling which provide insights into the discriminative power of bilinear
pooling, and a platform for further research in compact pooling methods.
Extensive experimentation illustrate the applicability of the proposed compact
representations, for image classification and few-shot learning across several
visual recognition tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06063</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06063</id><created>2015-11-19</created><authors><author><keyname>P</keyname><forenames>Satya Jayadev</forenames></author><author><keyname>Bhatt</keyname><forenames>Nirav P</forenames></author><author><keyname>Pasumarthy</keyname><forenames>Ramkrishna</forenames></author></authors><title>A Novel Approach for Phase Identification in Smart Grids Using Graph
  Theory and Principal Component Analysis</title><categories>cs.LG stat.AP stat.ML</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In general, low load consumers like households are supplied single-phase
power by connecting their service mains to one of the phases of a distribution
transformer. Here, the distribution companies face the problem of identifying
which consumer is connected to which phase and many solutions have evolved in
the past years to address this problem. The exact phase connectivity
information is important for the efficient operation and control of
distribution system. We propose a new data driven approach to the problem based
on Graph Theory and Principal Component Analysis (PCA), using energy
measurements in short time intervals, generated from smart meters. We propose
an algorithm for the noiseless case and then extend it to noisy case. The
algorithm will be demonstrated using simulated data for phase connectivities in
distribution networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06065</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06065</id><created>2015-11-19</created><authors><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Hendricks</keyname><forenames>Lisa Anne</forenames></author><author><keyname>Kuchenbecker</keyname><forenames>Katherine J.</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Deep Learning for Tactile Understanding From Visual and Haptic Data</title><categories>cs.RO cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robots that need to interact with the physical world will benefit from a
fine-grained tactile understanding of objects and surfaces. Additionally, for
certain tasks, robots may need to know the haptic properties of an object
before touching it. To enable better tactile understanding for robots, we
propose a method of classifying surfaces with haptic adjectives (e.g.,
compressible or smooth) from both visual and physical interaction data. Humans
typically combine visual predictions and feedback from physical interactions to
accurately predict haptic properties and interact with the world. Inspired by
this cognitive pattern, we propose and explore a purely visual haptic
prediction model. Purely visual models enable a robot to &quot;feel&quot; without
physical interaction. Furthermore, we demonstrate that using both visual and
physical interaction signals together yields more accurate haptic
classification. Our models take advantage of recent advances in deep neural
networks by employing a unified approach to learning features for physical
interaction and visual observations. Our approach is beneficial not only
because it results in better performance, but also because it eliminates the
need for domain-specific knowledge in feature design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06066</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06066</id><created>2015-11-19</created><authors><author><keyname>Wang</keyname><forenames>Dong</forenames></author><author><keyname>Zheng</keyname><forenames>Thomas Fang</forenames></author></authors><title>Transfer Learning for Speech and Language Processing</title><categories>cs.CL cs.LG</categories><comments>13 pages, APSIPA 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transfer learning is a vital technique that generalizes models trained for
one setting or task to other settings or tasks. For example in speech
recognition, an acoustic model trained for one language can be used to
recognize speech in another language, with little or no re-training data.
Transfer learning is closely related to multi-task learning (cross-lingual vs.
multilingual), and is traditionally studied in the name of `model adaptation'.
Recent advance in deep learning shows that transfer learning becomes much
easier and more effective with high-level abstract features learned by deep
models, and the `transfer' can be conducted not only between data distributions
and data types, but also between model structures (e.g., shallow nets and deep
nets) or even model types (e.g., Bayesian models and neural models). This
review paper summarizes some recent prominent research towards this direction,
particularly for speech and language processing. We also report some results
from our group and highlight the potential of this very interesting research
field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06067</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06067</id><created>2015-11-19</created><updated>2016-02-13</updated><authors><author><keyname>Tai</keyname><forenames>Cheng</forenames></author><author><keyname>Xiao</keyname><forenames>Tong</forenames></author><author><keyname>Zhang</keyname><forenames>Yi</forenames></author><author><keyname>Wang</keyname><forenames>Xiaogang</forenames></author><author><keyname>E</keyname><forenames>Weinan</forenames></author></authors><title>Convolutional neural networks with low-rank regularization</title><categories>cs.LG cs.CV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large CNNs have delivered impressive performance in various computer vision
applications. But the storage and computation requirements make it problematic
for deploying these models on mobile devices. Recently, tensor decompositions
have been used for speeding up CNNs. In this paper, we further develop the
tensor decomposition technique. We propose a new algorithm for computing the
low-rank tensor decomposition for removing the redundancy in the convolution
kernels. The algorithm finds the exact global optimizer of the decomposition
and is more effective than iterative methods. Based on the decomposition, we
further propose a new method for training low-rank constrained CNNs from
scratch. Interestingly, while achieving a significant speedup, sometimes the
low-rank constrained CNNs delivers significantly better performance than their
non-constrained counterparts. On the CIFAR-10 dataset, the proposed low-rank
NIN model achieves $91.31\%$ accuracy (without data augmentation), which also
improves upon state-of-the-art result. We evaluated the proposed method on
CIFAR-10 and ILSVRC12 datasets for a variety of modern CNNs, including AlexNet,
NIN, VGG and GoogleNet with success. For example, the forward time of VGG-16 is
reduced by half while the performance is still comparable. Empirical success
suggests that low-rank tensor decompositions can be a very useful tool for
speeding up large CNNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06068</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06068</id><created>2015-11-19</created><updated>2016-02-29</updated><authors><author><keyname>Cogswell</keyname><forenames>Michael</forenames></author><author><keyname>Ahmed</keyname><forenames>Faruk</forenames></author><author><keyname>Girshick</keyname><forenames>Ross</forenames></author><author><keyname>Zitnick</keyname><forenames>Larry</forenames></author><author><keyname>Batra</keyname><forenames>Dhruv</forenames></author></authors><title>Reducing Overfitting in Deep Networks by Decorrelating Representations</title><categories>cs.LG stat.ML</categories><comments>12 pages, 5 figures, 5 tables, Accepted to ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One major challenge in training Deep Neural Networks is preventing
overfitting. Many techniques such as data augmentation and novel regularizers
such as Dropout have been proposed to prevent overfitting without requiring a
massive amount of training data. In this work, we propose a new regularizer
called DeCov which leads to significantly reduced overfitting (as indicated by
the difference between train and val performance), and better generalization.
Our regularizer encourages diverse or non-redundant representations in Deep
Neural Networks by minimizing the cross-covariance of hidden activations. This
simple intuition has been explored in a number of past works but surprisingly
has never been applied as a regularizer in supervised learning. Experiments
across a range of datasets and network architectures show that this loss always
reduces overfitting while almost always maintaining or increasing
generalization performance and often improving performance over Dropout.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06069</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06069</id><created>2015-11-19</created><authors><author><keyname>Reed</keyname><forenames>Martin J.</forenames></author><author><keyname>Al-Naday</keyname><forenames>Mays</forenames></author><author><keyname>Thomos</keyname><forenames>Nikolaos</forenames></author><author><keyname>Trossen</keyname><forenames>Dirk</forenames></author><author><keyname>Petropoulos</keyname><forenames>George</forenames></author><author><keyname>Spirou</keyname><forenames>Spiros</forenames></author></authors><title>Stateless multicast switching in software defined networks</title><categories>cs.NI</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multicast data delivery can significantly reduce traffic in operators'
networks, but has been limited in deployment due to concerns such as the
scalability of state management. This paper shows how multicast can be
implemented in contemporary software defined networking (SDN) switches, with
less state than existing unicast switching strategies, by utilising a Bloom
Filter (BF) based switching technique. Furthermore, the proposed mechanism uses
only proactive rule insertion, and thus, is not limited by congestion or delay
incurred by reactive controller-aided rule insertion. We compare our solution
against common switching mechanisms such as layer-2 switching and MPLS in
realistic network topologies by modelling the TCAM state sizes in SDN switches.
The results demonstrate that our approach has significantly smaller state size
compared to existing mechanisms and thus is a multicast switching solution for
next generation networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06070</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06070</id><created>2015-11-19</created><authors><author><keyname>Liu</keyname><forenames>Miaomiao</forenames></author><author><keyname>Salzmann</keyname><forenames>Mathieu</forenames></author><author><keyname>He</keyname><forenames>Xuming</forenames></author></authors><title>Structured Depth Prediction in Challenging Monocular Video Sequences</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  In this paper, we tackle the problem of estimating the depth of a scene from
a monocular video sequence. In particular, we handle challenging scenarios,
such as non-translational camera motion and dynamic scenes, where traditional
structure from motion and motion stereo methods do not apply. To this end, we
first study the problem of depth estimation from a single image. In this
context, we exploit the availability of a pool of images for which the depth is
known, and formulate monocular depth estimation as a discrete-continuous
optimization problem, where the continuous variables encode the depth of the
superpixels in the input image, and the discrete ones represent relationships
between neighboring superpixels. The solution to this discrete-continuous
optimization problem is obtained by performing inference in a graphical model
using particle belief propagation. To handle video sequences, we then extend
our single image model to a two-frame one that naturally encodes short-range
temporal consistency and inherently handles dynamic objects. Based on the
prediction of this model, we then introduce a fully-connected pairwise CRF that
accounts for longer range spatio-temporal interactions throughout a video. We
demonstrate the effectiveness of our model in both the indoor and outdoor
scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06071</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06071</id><created>2015-11-19</created><authors><author><keyname>Hsieh</keyname><forenames>Min-Hsiu</forenames></author><author><keyname>Watanabe</keyname><forenames>Shun</forenames></author></authors><title>Channel Simulation and Coded Source Compression</title><categories>cs.IT math.IT quant-ph</categories><comments>The manuscript is a combination of results in arXiv:1501.04366 and
  arXiv:1504.05227. In particular, we show that channel simulation is a
  subroutine that the helper employs in the task of coded source compression in
  both classical and quantum regimes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work establishes connection between channel simulation and coded source
compression. First, we consider classical source coding with quantum
side-information where the quantum side-information is observed by a helper and
sent to the decoder via a classical channel. We derive a single-letter
characterization of the achievable rate region for this problem. The direct
part of our result is proved via the measurement compression theory by Winter,
a quantum to classical channel simulation. Our result reveals that a helper's
scheme that separately conducts a measurement and a compression is suboptimal,
and the measurement compression is fundamentally needed to achieve the optimal
rate region. We then study coded source compression in the fully quantum
regime. We characterise the quantum resources involved in this problem, and
derive a single-letter expression of the achievable rate region when
entanglement assistance is available. The direct coding proof is based on a
combination of two fundamental protocols, namely the quantum state merging
protocol and the quantum reverse Shannon theorem. Our work hence resolves coded
source compression in the quantum regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06072</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06072</id><created>2015-11-19</created><authors><author><keyname>Agethen</keyname><forenames>Sebastian</forenames></author><author><keyname>Hsu</keyname><forenames>Winston H.</forenames></author></authors><title>Mediated Experts for Deep Convolutional Networks</title><categories>cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new supervised architecture termed Mediated Mixture-of-Experts
(MMoE) that allows us to improve classification accuracy of Deep Convolutional
Networks (DCN). Our architecture achieves this with the help of expert
networks: A network is trained on a disjoint subset of a given dataset and then
run in parallel to other experts during deployment. A mediator is employed if
experts contradict each other. This allows our framework to naturally support
incremental learning, as adding new classes requires (re-)training of the new
expert only. We also propose two measures to control computational complexity:
An early-stopping mechanism halts experts that have low confidence in their
prediction. The system allows to trade-off accuracy and complexity without
further retraining. We also suggest to share low-level convolutional layers
between experts in an effort to avoid computation of a near-duplicate feature
set. We evaluate our system on a popular dataset and report improved accuracy
compared to a single model of same configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06074</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06074</id><created>2015-11-19</created><authors><author><keyname>Nafkha</keyname><forenames>Amor</forenames></author><author><keyname>Demni</keyname><forenames>Nizar</forenames></author><author><keyname>Bonnefoi</keyname><forenames>Remi</forenames></author></authors><title>New Expressions for Ergodic Capacities of Optical Fibers and Wireless
  MIMO Channels</title><categories>cs.IT math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multimode/multicore fibers are expected to provide an attractive solution to
overcome the capacity limit of current optical communication system. In
presence of high crosstalk between modes/cores, the squared singular values of
the input/output transfer matrix follow the law of the Jacobi ensemble of
random matrices. Assuming that the channel state information is only available
at the receiver, we derive in this paper a new expression for the ergodic
capacity of the Jacobi MIMO channel. This expression involves double integrals
which can be evaluated easily and efficiently. Moreover, the method used in
deriving this expression does not appeal to the classical one-point correlation
function of the random matrix model. Using a limiting transition between Jacobi
and Laguerre polynomials, we derive a similar formula for the ergodic capacity
of the Gaussian MIMO channel. The analytical results are compared with Monte
Carlo simulations and related results available in the literature. A perfect
agreement is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06078</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06078</id><created>2015-11-19</created><authors><author><keyname>Wang</keyname><forenames>Liwei</forenames></author><author><keyname>Li</keyname><forenames>Yin</forenames></author><author><keyname>Lazebnik</keyname><forenames>Svetlana</forenames></author></authors><title>Learning Deep Structure-Preserving Image-Text Embeddings</title><categories>cs.CV cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a method for learning joint embeddings of images and text
using a two-branch neural network with multiple layers of linear projections
followed by nonlinearities. The network is trained using a novel large-margin
objective that combines cross-view ranking constraints with within-view
neighborhood structure preservation constraints inspired by metric learning
literature. Extensive experiments show that both contributions of our method,
the nonlinear network structure and the structure-preserving objective
function, achieve significant improvements in accuracy for image-to-text and
text-to-image retrieval. Our method achieves new state-of-the-art results on
the Flickr30K and MSCOCO image-sentence datasets and shows promise on the new
task of phrase localization on the Flickr30K Entities dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06085</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06085</id><created>2015-11-19</created><updated>2016-03-01</updated><authors><author><keyname>Toderici</keyname><forenames>George</forenames></author><author><keyname>O'Malley</keyname><forenames>Sean M.</forenames></author><author><keyname>Hwang</keyname><forenames>Sung Jin</forenames></author><author><keyname>Vincent</keyname><forenames>Damien</forenames></author><author><keyname>Minnen</keyname><forenames>David</forenames></author><author><keyname>Baluja</keyname><forenames>Shumeet</forenames></author><author><keyname>Covell</keyname><forenames>Michele</forenames></author><author><keyname>Sukthankar</keyname><forenames>Rahul</forenames></author></authors><title>Variable Rate Image Compression with Recurrent Neural Networks</title><categories>cs.CV cs.LG cs.NE</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large fraction of Internet traffic is now driven by requests from mobile
devices with relatively small screens and often stringent bandwidth
requirements. Due to these factors, it has become the norm for modern
graphics-heavy websites to transmit low-resolution, low-bytecount image
previews (thumbnails) as part of the initial page load process to improve
apparent page responsiveness. Increasing thumbnail compression beyond the
capabilities of existing codecs is therefore a current research focus, as any
byte savings will significantly enhance the experience of mobile device users.
Toward this end, we propose a general framework for variable-rate image
compression and a novel architecture based on convolutional and deconvolutional
LSTM recurrent networks. Our models address the main issues that have prevented
autoencoder neural networks from competing with existing image compression
algorithms: (1) our networks only need to be trained once (not per-image),
regardless of input image dimensions and the desired compression rate; (2) our
networks are progressive, meaning that the more bits are sent, the more
accurate the image reconstruction; and (3) the proposed architecture is at
least as efficient as a standard purpose-trained autoencoder for a given number
of bits. On a large-scale benchmark of 32$\times$32 thumbnails, our LSTM-based
approaches provide better visual quality than (headerless) JPEG, JPEG2000 and
WebP, with a storage size that is reduced by 10% or more.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06090</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06090</id><created>2015-11-19</created><authors><author><keyname>Saito</keyname><forenames>Genki</forenames></author><author><keyname>Stringhini</keyname><forenames>Gianluca</forenames></author></authors><title>Master of Puppets: Analyzing And Attacking A Botnet For Fun And Profit</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A botnet is a network of compromised machines (bots), under the control of an
attacker. Many of these machines are infected without their owners' knowledge,
and botnets are the driving force behind several misuses and criminal
activities on the Internet (for example spam emails). Depending on its
topology, a botnet can have zero or more command and control (C&amp;C) servers,
which are centralized machines controlled by the cybercriminal that issue
commands and receive reports back from the co-opted bots.
  In this paper, we present a comprehensive analysis of the command and control
infrastructure of one of the world's largest proprietary spamming botnets
between 2007 and 2012: Cutwail/Pushdo. We identify the key functionalities
needed by a spamming botnet to operate effectively. We then develop a number of
attacks against the command and control logic of Cutwail that target those
functionalities, and make the spamming operations of the botnet less effective.
This analysis was made possible by having access to the source code of the C&amp;C
software, as well as setting up our own Cutwail C&amp;C server, and by implementing
a clone of the Cutwail bot. With the help of this tool, we were able to
enumerate the number of bots currently registered with the C&amp;C server,
impersonate an existing bot to report false information to the C&amp;C server, and
manipulate spamming statistics of an arbitrary bot stored in the C&amp;C database.
Furthermore, we were able to make the control server inaccessible by conducting
a distributed denial of service (DDoS) attack. Our results may be used by law
enforcement and practitioners to develop better techniques to mitigate and
cripple other botnets, since many of findings are generic and are due to the
workflow of C&amp;C communication in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06098</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06098</id><created>2015-11-19</created><authors><author><keyname>Randrianantenaina</keyname><forenames>Itsikiantsoa</forenames></author><author><keyname>Elsawy</keyname><forenames>Hesham</forenames></author><author><keyname>Dahrouj</keyname><forenames>Hayssam</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Interference Management with Partial Uplink/Downlink Spectrum Overlap</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simultaneous reuse of spectral resources by uplink and downlink, denoted as
in-band full duplex (FD) communication, is promoted to double the spectral
efficiency when compared to its half-duplex (HD) counterpart. Interference
management, however, remains challenging in FD cellular networks, especially
when high disparity between uplink and downlink transmission powers exists. The
uplink performance can be particularly deteriorated when operating on channels
that are simultaneously occupied with downlink transmission. This paper
considers a cellular wireless system with partial spectrum overlap between the
downlink and uplink. The performance of the system becomes, therefore, a
function of the overlap fraction, as well as the power level of both the uplink
and downlink transmissions. The paper considers the problem of maximizing an
overall network utility to find the uplink/downlink transmission powers and the
spectrum overlap fraction between the uplink and downlink spectrum in each
cell, and proposes solving the problem using interior point method. Simulations
results confirm the vulnerability of the uplink performance to the FD
operation, and show the superiority of the proposed scheme over the FD and HD
schemes. The results further show that explicit uplink and downlink performance
should be considered for efficient design of cellular networks with overlapping
uplink/downlink resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06099</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06099</id><created>2015-11-19</created><authors><author><keyname>Andoni</keyname><forenames>Alexandr</forenames></author><author><keyname>Chen</keyname><forenames>Jiecao</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author><author><keyname>Qin</keyname><forenames>Bo</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author><author><keyname>Zhang</keyname><forenames>Qin</forenames></author></authors><title>On Sketching Quadratic Forms</title><categories>cs.DS</categories><comments>46 pages; merging of arXiv:1403.7058 and arXiv:1412.8225</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We undertake a systematic study of sketching a quadratic form: given an $n
\times n$ matrix $A$, create a succinct sketch $\textbf{sk}(A)$ which can
produce (without further access to $A$) a multiplicative
$(1+\epsilon)$-approximation to $x^T A x$ for any desired query $x \in
\mathbb{R}^n$. While a general matrix does not admit non-trivial sketches,
positive semi-definite (PSD) matrices admit sketches of size
$\Theta(\epsilon^{-2} n)$, via the Johnson-Lindenstrauss lemma, achieving the
&quot;for each&quot; guarantee, namely, for each query $x$, with a constant probability
the sketch succeeds. (For the stronger &quot;for all&quot; guarantee, where the sketch
succeeds for all $x$'s simultaneously, again there are no non-trivial
sketches.)
  We design significantly better sketches for the important subclass of graph
Laplacian matrices, which we also extend to symmetric diagonally dominant
matrices. A sequence of work culminating in that of Batson, Spielman, and
Srivastava (SIAM Review, 2014), shows that by choosing and reweighting
$O(\epsilon^{-2} n)$ edges in a graph, one achieves the &quot;for all&quot; guarantee.
Our main results advance this front.
  $\bullet$ For the &quot;for all&quot; guarantee, we prove that Batson et al.'s bound is
optimal even when we restrict to &quot;cut queries&quot; $x\in \{0,1\}^n$.
  In contrast, previous lower bounds showed the bound only for {\em
spectral-sparsifiers}.
  $\bullet$ For the &quot;for each&quot; guarantee, we design a sketch of size $\tilde
O(\epsilon^{-1} n)$ bits for &quot;cut queries&quot; $x\in \{0,1\}^n$. We prove a
nearly-matching lower bound of $\Omega(\epsilon^{-1} n)$ bits. For general
queries $x \in \mathbb{R}^n$, we construct sketches of size
$\tilde{O}(\epsilon^{-1.6} n)$ bits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06103</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06103</id><created>2015-11-19</created><updated>2015-12-03</updated><authors><author><keyname>Baqu&#xe9;</keyname><forenames>Pierre</forenames></author><author><keyname>Bagautdinov</keyname><forenames>Timur</forenames></author><author><keyname>Fleuret</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Fua</keyname><forenames>Pascal</forenames></author></authors><title>Principled Parallel Mean-Field Inference for Discrete Random Fields</title><categories>cs.CV cs.LG</categories><comments>The first two authors contributed equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mean-field variational inference is one of the most popular approaches to
inference in discrete random fields. Standard mean-field optimization is based
on coordinate descent and in many situations can be impractical. Thus, in
practice, various parallel techniques are used, which either rely on ad-hoc
smoothing with heuristically set parameters, or put strong constraints on the
type of models. In this paper, we propose a novel proximal gradient-based
approach to optimizing the variational objective. It is naturally
parallelizable and easy to implement. We prove its convergence, and then
demonstrate that, in practice, it yields faster convergence and often finds
better optima than more traditional mean-field optimization techniques.
Moreover, our method is less sensitive to the choice of parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06104</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06104</id><created>2015-11-19</created><updated>2016-01-18</updated><authors><author><keyname>Bai</keyname><forenames>Sheng-Yi</forenames></author><author><keyname>Agethen</keyname><forenames>Sebastian</forenames></author><author><keyname>Chao</keyname><forenames>Ting-Hsuan</forenames></author><author><keyname>Hsu</keyname><forenames>Winston</forenames></author></authors><title>Semi-supervised Learning for Convolutional Neural Networks via Online
  Graph Construction</title><categories>cs.NE cs.CV cs.LG</categories><comments>As the original submission of iclr is withdrawn, the arxiv submission
  should be withdrawn as well</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recent promising achievements of deep learning rely on the large amount
of labeled data. Considering the abundance of data on the web, most of them do
not have labels at all. Therefore, it is important to improve generalization
performance using unlabeled data on supervised tasks with few labeled
instances. In this work, we revisit graph-based semi-supervised learning
algorithms and propose an online graph construction technique which suits deep
convolutional neural network better. We consider an EM-like algorithm for
semi-supervised learning on deep neural networks: In forward pass, the graph is
constructed based on the network output, and the graph is then used for loss
calculation to help update the network by back propagation in the backward
pass. We demonstrate the strength of our online approach compared to the
conventional ones whose graph is constructed on static but not robust enough
feature representations beforehand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06106</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06106</id><created>2015-11-19</created><updated>2015-11-26</updated><authors><author><keyname>Peng</keyname><forenames>Ting</forenames></author><author><keyname>Qu</keyname><forenames>Aiping</forenames></author><author><keyname>Wang</keyname><forenames>Xiaoling</forenames></author></authors><title>Quantitative Analysis of Particles Segregation</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segregation is a popular phenomenon. It has considerable effects on material
performance. To the author's knowledge, there is still no automated objective
quantitative indicator for segregation. In order to full fill this task,
segregation of particles is analyzed. Edges of the particles are extracted from
the digital picture. Then, the whole picture of particles is splintered to
small rectangles with the same shape. Statistical index of the edges in each
rectangle is calculated. Accordingly, segregation between the indexes
corresponding to the rectangles is evaluated. The results show coincident with
subjective evaluated results. Further more, it can be implemented as an
automated system, which would facilitate the materials quality control
mechanism during production process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06114</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06114</id><created>2015-11-19</created><updated>2016-03-01</updated><authors><author><keyname>Luong</keyname><forenames>Minh-Thang</forenames></author><author><keyname>Le</keyname><forenames>Quoc V.</forenames></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author><author><keyname>Vinyals</keyname><forenames>Oriol</forenames></author><author><keyname>Kaiser</keyname><forenames>Lukasz</forenames></author></authors><title>Multi-task Sequence to Sequence Learning</title><categories>cs.LG cs.CL stat.ML</categories><comments>10 pages, 4 figures, ICLR 2016 camera-ready, added parsing SOTA
  results</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequence to sequence learning has recently emerged as a new paradigm in
supervised learning. To date, most of its applications focused on only one task
and not much work explored this framework for multiple tasks. This paper
examines three multi-task learning (MTL) settings for sequence to sequence
models: (a) the oneto-many setting - where the encoder is shared between
several tasks such as machine translation and syntactic parsing, (b) the
many-to-one setting - useful when only the decoder can be shared, as in the
case of translation and image caption generation, and (c) the many-to-many
setting - where multiple encoders and decoders are shared, which is the case
with unsupervised objectives and translation. Our results show that training on
a small amount of parsing and image caption data can improve the translation
quality between English and German by up to 1.5 BLEU points over strong
single-task baselines on the WMT benchmarks. Furthermore, we have established a
new state-of-the-art result in constituent parsing with 93.0 F1. Lastly, we
reveal interesting properties of the two unsupervised learning objectives,
autoencoder and skip-thought, in the MTL context: autoencoder helps less in
terms of perplexities but more on BLEU scores compared to skip-thought.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06117</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06117</id><created>2015-11-19</created><authors><author><keyname>Wu</keyname><forenames>Nan</forenames></author><author><keyname>Yuan</keyname><forenames>Weijie</forenames></author><author><keyname>Wang</keyname><forenames>Hua</forenames></author><author><keyname>Kuang</keyname><forenames>Jingming</forenames></author></authors><title>TOA-based passive localization of multiple targets with inaccurate
  receivers based on belief propagation on factor graph</title><categories>cs.IT math.IT</categories><comments>37 pages, 11 figures, accepted by Digital Signal Processing</comments><doi>10.1016/j.dsp.2015.10.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location awareness is now becoming a vital requirement for many practical
applications. In this paper, we consider passive localization of multiple
targets with one transmitter and several receivers based on time of arrival
(TOA) measurements. Existing studies assume that positions of receivers are
perfectly known. However, in practice, receivers' positions might be
inaccurate, which leads to localization error of targets. We propose factor
graph (FG)-based belief propagation (BP) algorithms to locate the passive
targets and improve the position accuracy of receivers simultaneously. Due to
the nonlinearity of the likelihood function, messages on the FG cannot be
derived in closed form. We propose both sample-based and parametric methods to
solve this problem. In the sample-based BP algorithm, particle swarm
optimization is employed to reduce the number of particles required to
represent messages. In parametric BP algorithm, the nonlinear terms in messages
are linearized, which results in closed-form Gaussian message passing on FG.
The Bayesian Cramer-Rao bound (BCRB) for passive targets localization with
uncertain receivers is derived to evaluate the performance of the proposed
algorithms. Simulation results show that both the sample-based and parametric
BP algorithms outperform the conventional method and attain the proposed BCRB.
Receivers' positions can also be improved via the proposed BP algorithms.
Although the parametric BP algorithm performs slightly worse than the
sample-based BP method, it could be more attractive in practical applications
due to the significantly lower computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06132</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06132</id><created>2015-11-19</created><authors><author><keyname>Shang</keyname><forenames>Yilun</forenames></author></authors><title>Bounds of distance Estrada index of graphs</title><categories>math.CO cs.DM</categories><comments>To appear in Ars Combin</comments><msc-class>05C12, 15A42</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\lambda_1,\lambda_2,\cdots,\lambda_n$ be the eigenvalues of the distance
matrix of a connected graph $G$. The distance Estrada index of $G$ is defined
as $DEE(G)=\sum_{i=1}^ne^{\lambda_i}$. In this note, we present new lower and
upper bounds for $DEE(G)$. In addition, a Nordhaus-Gaddum type inequality for
$DEE(G)$ is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06146</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06146</id><created>2015-11-19</created><updated>2015-11-19</updated><authors><author><keyname>Lee</keyname><forenames>Kiryung</forenames></author><author><keyname>Junge</keyname><forenames>Marius</forenames></author></authors><title>RIP-like Properties in Subsampled Blind Deconvolution</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive near optimal performance guarantees for subsampled blind
deconvolution. Blind deconvolution is an ill-posed bilinear inverse problem and
additional subsampling makes the problem even more challenging. Sparsity and
spectral flatness priors on unknown signals are introduced to overcome these
difficulties. While being crucial for deriving desired near optimal performance
guarantees, unlike the sparsity prior with a nice union-of-subspaces structure,
the spectral flatness prior corresponds to a nonconvex cone structure, which is
not preserved by elementary set operations. This prohibits the operator arising
in subsampled blind deconvolution from satisfying the standard restricted
isometry property (RIP) at near optimal sample complexity, which motivated us
to study other RIP-like properties. Combined with the performance guarantees
derived using these RIP-like properties in a companion paper, we show that
subsampled blind deconvolution is provably solved at near optimal sample
complexity by a practical algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06147</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06147</id><created>2015-11-19</created><authors><author><keyname>Dubey</keyname><forenames>Abhimanyu</forenames></author><author><keyname>Naik</keyname><forenames>Nikhil</forenames></author><author><keyname>Raviv</keyname><forenames>Dan</forenames></author><author><keyname>Sukthankar</keyname><forenames>Rahul</forenames></author><author><keyname>Raskar</keyname><forenames>Ramesh</forenames></author></authors><title>Coreset-Based Adaptive Tracking</title><categories>cs.CV cs.LG</categories><comments>8 pages, 5 figures, In submission to IEEE TPAMI (Transactions on
  Pattern Analysis and Machine Intelligence)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for learning from streaming visual data using a compact,
constant size representation of all the data that was seen until a given
moment. Specifically, we construct a 'coreset' representation of streaming data
using a parallelized algorithm, which is an approximation of a set with
relation to the squared distances between this set and all other points in its
ambient space. We learn an adaptive object appearance model from the coreset
tree in constant time and logarithmic space and use it for object tracking by
detection. Our method obtains excellent results for object tracking on three
standard datasets over more than 100 videos. The ability to summarize data
efficiently makes our method ideally suited for tracking in long videos in
presence of space and time constraints. We demonstrate this ability by
outperforming a variety of algorithms on the TLD dataset with 2685 frames on
average. This coreset based learning approach can be applied for both real-time
learning of small, varied data and fast learning of big data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06149</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06149</id><created>2015-11-19</created><updated>2015-11-19</updated><authors><author><keyname>Lee</keyname><forenames>Kiryung</forenames></author><author><keyname>Li</keyname><forenames>Yanjun</forenames></author><author><keyname>Junge</keyname><forenames>Marius</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author></authors><title>Blind Recovery of Sparse Signals from Subsampled Convolution</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subsampled blind deconvolution is the recovery of two unknown signals from
samples of their convolution. To overcome the ill-posedness of this problem,
solutions based on priors tailored to specific application have been developed
in practical applications. In particular, sparsity models have provided
promising priors. However, in spite of empirical success of these methods in
many applications, existing analyses are rather limited in two main ways: by
disparity between the theoretical assumptions on the signal and/or measurement
model versus practical setups; or by failure to provide a performance guarantee
for parameter values within the optimal regime defined by the information
theoretic limits. In particular, it has been shown that a naive sparsity model
is not a strong enough prior for identifiability in the blind deconvolution
problem. Instead, in addition to sparsity, we adopt a conic constraint, which
enforces spectral flatness of the signals. Under this prior, we provide an
iterative algorithm that achieves guaranteed performance in blind deconvolution
at near optimal sample complexity. Numerical results show the empirical
performance of the iterative algorithm agrees with the performance guarantee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06181</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06181</id><created>2015-11-19</created><updated>2015-12-01</updated><authors><author><keyname>Maksai</keyname><forenames>Andrii</forenames></author><author><keyname>Wang</keyname><forenames>Xinchao</forenames></author><author><keyname>Fua</keyname><forenames>Pascal</forenames></author></authors><title>What Players do with the Ball: A Physically Constrained Interaction
  Modeling</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tracking the ball is critical for video-based analysis of team sports.
However, it is difficult, especially in low-resolution images, due to the small
size of the ball, its speed that creates motion blur, and its often being
occluded by players. In this paper, we propose a generic and principled
approach to modeling the interaction between the ball and the players while
also imposing appropriate physical constraints on the ball's trajectory. We
show that our approach, formulated in terms of a Mixed Integer Program, is more
robust and more accurate than several state-of-the-art approaches on real-life
volleyball, basketball, and soccer sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06191</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06191</id><created>2015-11-19</created><authors><author><keyname>Borchmann</keyname><forenames>Daniel</forenames></author><author><keyname>Ganter</keyname><forenames>Bernhard</forenames></author></authors><title>Abstract Attribute Exploration with Partial Object Descriptions</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Attribute exploration has been investigated in several studies, with
particular emphasis on the algorithmic aspects of this knowledge acquisition
method. In its basic version the method itself is rather simple and
transparent. But when background knowledge and partially described
counter-examples are admitted, it gets more difficult. Here we discuss this
case in an abstract, somewhat &quot;axiomatic&quot; setting, providing a terminology that
clarifies the abstract strategy of the method rather than its algorithmic
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06198</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06198</id><created>2015-11-19</created><authors><author><keyname>Zhang</keyname><forenames>Kai</forenames></author></authors><title>Spherical Cap Packing Asymptotics and Rank-Extreme Detection</title><categories>math.ST cs.IT math.IT physics.data-an stat.ME stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the spherical cap packing problem with a probabilistic approach.
Such probabilistic considerations result in an asymptotic sharp universal
uniform bound on the maximal inner product between any set of unit vectors and
a stochastically independent uniformly distributed unit vector. When the set of
unit vectors are themselves independently uniformly distributed, we further
develop the extreme value distribution limit of the maximal inner product,
which characterizes its uncertainty around the bound.
  As applications of the above asymptotic results, we derive (1) an asymptotic
sharp universal uniform bound on the maximal spurious correlation, as well as
its uniform convergence in distribution when the explanatory variables are
independently Gaussian distributed; and (2) an asymptotic sharp universal bound
on the maximum norm of a low-rank elliptically distributed vector, as well as
related limiting distributions. With these results, we develop a fast detection
method for a low-rank structure in high-dimensional Gaussian data without using
the spectrum information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06201</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06201</id><created>2015-11-19</created><authors><author><keyname>Wu</keyname><forenames>Zhirong</forenames></author><author><keyname>Lin</keyname><forenames>Dahua</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoou</forenames></author></authors><title>Adjustable Bounded Rectifiers: Towards Deep Binary Representations</title><categories>cs.LG stat.ML</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Binary representation is desirable for its memory efficiency, computation
speed and robustness. In this paper, we propose adjustable bounded rectifiers
to learn binary representations for deep neural networks. While hard
constraining representations across layers to be binary makes training
unreasonably difficult, we softly encourage activations to diverge from real
values to binary by approximating step functions. Our final representation is
completely binary. We test our approach on MNIST, CIFAR10, and ILSVRC2012
dataset, and systematically study the training dynamics of the binarization
process. Our approach can binarize the last layer representation without loss
of performance and binarize all the layers with reasonably small degradations.
The memory space that it saves may allow more sophisticated models to be
deployed, thus compensating the loss. To the best of our knowledge, this is the
first work to report results on current deep network architectures using
complete binary middle representations. Given the learned representations, we
find that the firing or inhibition of a binary neuron is usually associated
with a meaningful interpretation across different classes. This suggests that
the semantic structure of a neural network may be manifested through a guided
binarization process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06208</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06208</id><created>2015-11-19</created><authors><author><keyname>Salhov</keyname><forenames>Moshe</forenames></author><author><keyname>Bermanis</keyname><forenames>Amit</forenames></author><author><keyname>Wolf</keyname><forenames>Guy</forenames></author><author><keyname>Averbuch</keyname><forenames>Amir</forenames></author></authors><title>Diffusion Representations</title><categories>stat.ML cs.LG math.SP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diffusion Maps framework is a kernel based method for manifold learning and
data analysis that defines diffusion similarities by imposing a Markovian
process on the given dataset. Analysis by this process uncovers the intrinsic
geometric structures in the data. Recently, it was suggested to replace the
standard kernel by a measure-based kernel that incorporates information about
the density of the data. Thus, the manifold assumption is replaced by a more
general measure-based assumption.
  The measure-based diffusion kernel incorporates two separate independent
representations. The first determines a measure that correlates with a density
that represents normal behaviors and patterns in the data. The second consists
of the analyzed multidimensional data points.
  In this paper, we present a representation framework for data analysis of
datasets that is based on a closed-form decomposition of the measure-based
kernel. The proposed representation preserves pairwise diffusion distances that
does not depend on the data size while being invariant to scale. For a
stationary data, no out-of-sample extension is needed for embedding newly
arrived data points in the representation space. Several aspects of the
presented methodology are demonstrated on analytically generated data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06214</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06214</id><created>2015-11-19</created><authors><author><keyname>Henderson</keyname><forenames>Paul</forenames></author><author><keyname>Ferrari</keyname><forenames>Vittorio</forenames></author></authors><title>Automatically selecting inference algorithms for discrete energy
  minimisation</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimisation of discrete energies defined over factors is an important
problem in computer vision, and a vast number of MAP inference algorithms have
been proposed. Different inference algorithms perform better on factor graph
models (GMs) from different underlying problem classes, and in general it is
difficult to know which algorithm will yield the lowest energy for a given GM.
To mitigate this difficulty, survey papers advise the practitioner on what
algorithms perform well on what classes of models. We take the next step
forward, and present a technique to automatically select the best inference
algorithm for an input GM. We validate our method experimentally on an extended
version of the OpenGM2 benchmark, containing a diverse set of vision problems.
On average, our method selects an inference algorithm yielding labellings with
96% of variables the same as the best available algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06219</identifier>
 <datestamp>2016-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06219</id><created>2015-11-19</created><updated>2016-03-03</updated><authors><author><keyname>Sterckx</keyname><forenames>Lucas</forenames></author><author><keyname>Demeester</keyname><forenames>Thomas</forenames></author><author><keyname>Deleu</keyname><forenames>Johannes</forenames></author><author><keyname>Develder</keyname><forenames>Chris</forenames></author></authors><title>Knowledge Base Population using Semantic Label Propagation</title><categories>cs.CL cs.LG</categories><comments>Submitted to Knowledge Based Systems, special issue on Knowledge
  Bases for Natural Language Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A crucial aspect of a knowledge base population system that extracts new
facts from text corpora, is the generation of training data for its relation
extractors. In this paper, we present a method that maximizes the effectiveness
of newly trained relation extractors at a minimal annotation cost. Manual
labeling can be significantly reduced by Distant Supervision, which is a method
to construct training data automatically by aligning a large text corpus with
an existing knowledge base of known facts. For example, all sentences
mentioning both 'Barack Obama' and 'US' may serve as positive training
instances for the relation born_in(subject,object). However, distant
supervision typically results in a highly noisy training set: many training
sentences do not really express the intended relation. We propose to combine
distant supervision with minimal manual supervision in a technique called
feature labeling, to eliminate noise from the large and noisy initial training
set, resulting in a significant increase of precision. We further improve on
this approach by introducing the Semantic Label Propagation method, which uses
the similarity between low-dimensional representations of candidate training
instances, to extend the training set in order to increase recall while
maintaining high precision. Our proposed strategy for generating training data
is studied and evaluated on an established test collection designed for
knowledge base population tasks. The experimental results show that the
Semantic Label Propagation strategy leads to substantial performance gains when
compared to existing approaches, while requiring an almost negligible manual
annotation effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06227</identifier>
 <datestamp>2015-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06227</id><created>2015-11-19</created><updated>2015-12-04</updated><authors><author><keyname>Wang</keyname><forenames>Ran</forenames></author><author><keyname>He</keyname><forenames>Xinrui</forenames></author></authors><title>Empirical Research and Automatic Processing Method of Precision-specific
  Operation</title><categories>cs.NA</categories><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Significant inaccuracy often occurs during the process of mathematical
calculation due to the digit limitation of floating point, which may lead to
catastrophic loss. Normally, people believe that adjustment of floating-point
precision is an effective way to solve this problem, since high-precision
floating-point has more digits to store information. Thus, it is a prevalent
method to reduce the inaccuracy in much floating-point related research, that
performing all the operations with higher precision. However, we discover that
some operations may lead to larger error in higher precision. In this paper, we
define this kind of operation that generates large error due to precision
adjustment a precision-specific operation. Furthermore, we propose a
light-weight searching algorithm for detecting precision-specific operations
and figure out an automatic processing method to fixing them. In addition, we
conducted an experiment on the scientific mathematical library of GLIBC. The
result shows that there are many precision-specific operations, and our fixing
approach can significantly reduce the inaccuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06230</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06230</id><created>2015-11-19</created><authors><author><keyname>Geil</keyname><forenames>Olav</forenames></author><author><keyname>Martin</keyname><forenames>Stefano</forenames></author><author><keyname>Mart&#xed;nez-Pe&#xf1;as</keyname><forenames>Umberto</forenames></author><author><keyname>Ruano</keyname><forenames>Diego</forenames></author></authors><title>Refined analysis of RGHWs of code pairs coming from Garcia-Stichtenoth's
  second tower</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Asymptotically good sequences of ramp secret sharing schemes were given in
[Asymptotically good ramp secret sharing schemes, arXiv:1502.05507] by using
one-point algebraic geometric codes defined from asymptotically good towers of
function fields. Their security is given by the relative generalized Hamming
weights of the corresponding codes. In this paper we demonstrate how to obtain
refined information on the RGHWs when the codimension of the codes is small.
For general codimension, we give an improved estimate for the highest RGHW.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06233</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06233</id><created>2015-11-19</created><authors><author><keyname>Bendale</keyname><forenames>Abhijit</forenames></author><author><keyname>Boult</keyname><forenames>Terrance</forenames></author></authors><title>Towards Open Set Deep Networks</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep networks have produced significant gains for various visual recognition
problems, leading to high impact academic and commercial applications. Recent
work in deep networks highlighted that it is easy to generate images that
humans would never classify as a particular object class, yet networks classify
such images high confidence as that given class - deep network are easily
fooled with images humans do not consider meaningful. The closed set nature of
deep networks forces them to choose from one of the known classes leading to
such artifacts. Recognition in the real world is open set, i.e. the recognition
system should reject unknown/unseen classes at test time. We present a
methodology to adapt deep networks for open set recognition, by introducing a
new model layer, OpenMax, which estimates the probability of an input being
from an unknown class. A key element of estimating the unknown probability is
adapting Meta-Recognition concepts to the activation patterns in the
penultimate layer of the network. OpenMax allows rejection of &quot;fooling&quot; and
unrelated open set images presented to the system; OpenMax greatly reduces the
number of obvious errors made by a deep network. We prove that the OpenMax
concept provides bounded open space risk, thereby formally providing an open
set recognition solution. We evaluate the resulting open set deep networks
using pre-trained networks from the Caffe Model-zoo on ImageNet 2012 validation
data, and thousands of fooling and open set images. The proposed OpenMax model
significantly outperforms open set recognition accuracy of basic deep networks
as well as deep networks with thresholding of SoftMax probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06236</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06236</id><created>2015-11-19</created><authors><author><keyname>Muguerza</keyname><forenames>Maria</forenames><affiliation>LAAS-ROC</affiliation></author><author><keyname>Briand</keyname><forenames>Cyril</forenames><affiliation>LAAS-ROC</affiliation></author><author><keyname>Jozefowiez</keyname><forenames>Nicolas</forenames><affiliation>LAAS-ROC</affiliation></author><author><keyname>Ngueveu</keyname><forenames>Sandra Ulrich</forenames><affiliation>LAAS-ROC</affiliation></author><author><keyname>Rodr&#xed;guez</keyname><forenames>Victoria</forenames></author><author><keyname>Moris</keyname><forenames>Matias Urenda</forenames></author></authors><title>A mass-flow MILP formulation for energy-efficient supplying in assembly
  lines</title><categories>cs.RO</categories><comments>MISTA 2015, Aug 2015, Prague, Czech Republic. The MISTA conference
  series ISSN 2305-249X. 2015</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the problem of supplying the workstations of assembly
lines with components during the production process. For that specific problem,
this paper presents a Mixed Integer Linear Program (MILP) that aims at
minimizing the energy consumption of the supplying strategy. More specifically,
in contrast of the usual formulations that only consider component flows, this
MILP handles the mass flow that are routed from one workstation to the other.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06238</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06238</id><created>2015-11-19</created><updated>2016-03-02</updated><authors><author><keyname>Cha</keyname><forenames>Miriam</forenames></author><author><keyname>Gwon</keyname><forenames>Youngjune</forenames></author><author><keyname>Kung</keyname><forenames>H. T.</forenames></author></authors><title>Multimodal sparse representation learning and applications</title><categories>cs.LG cs.CV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unsupervised methods have proven effective for discriminative tasks in a
single-modality scenario. In this paper, we present a multimodal framework for
learning sparse representations that can capture semantic correlation between
modalities. The framework can model relationships at a higher level by forcing
the shared sparse representation. In particular, we propose the use of joint
dictionary learning technique for sparse coding and formulate the joint
representation for concision, cross-modal representations (in case of a missing
modality), and union of the cross-modal representations. Given the accelerated
growth of multimodal data posted on the Web such as YouTube, Wikipedia, and
Twitter, learning good multimodal features is becoming increasingly important.
We show that the shared representations enabled by our framework substantially
improve the classification performance under both unimodal and multimodal
settings. We further show how deep architectures built on the proposed
framework are effective for the case of highly nonlinear correlations between
modalities. The effectiveness of our approach is demonstrated experimentally in
image denoising, multimedia event detection and retrieval on the TRECVID
dataset (audio-video), category classification on the Wikipedia dataset
(image-text), and sentiment classification on PhotoTweet (image-text).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06241</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06241</id><created>2015-11-19</created><updated>2016-02-16</updated><authors><author><keyname>Dundar</keyname><forenames>Aysegul</forenames></author><author><keyname>Jin</keyname><forenames>Jonghoon</forenames></author><author><keyname>Culurciello</keyname><forenames>Eugenio</forenames></author></authors><title>Convolutional Clustering for Unsupervised Learning</title><categories>cs.LG cs.CV</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The task of labeling data for training deep neural networks is daunting and
tedious, requiring millions of labels to achieve the current state-of-the-art
results. Such reliance on large amounts of labeled data can be relaxed by
exploiting hierarchical features via unsupervised learning techniques. In this
work, we propose to train a deep convolutional network based on an enhanced
version of the k-means clustering algorithm, which reduces the number of
correlated parameters in the form of similar filters, and thus increases test
categorization accuracy. We call our algorithm convolutional k-means
clustering. We further show that learning the connection between the layers of
a deep convolutional neural network improves its ability to be trained on a
smaller amount of labeled data. Our experiments show that the proposed
algorithm outperforms other techniques that learn filters unsupervised.
Specifically, we obtained a test accuracy of 74.1% on STL-10 and a test error
of 0.5% on MNIST.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06244</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06244</id><created>2015-11-19</created><authors><author><keyname>Cano</keyname><forenames>Cristina</forenames></author><author><keyname>Leith</keyname><forenames>Douglas J.</forenames></author></authors><title>Unlicensed LTE/WiFi Coexistence: Is LBT Inherently Fairer Than CSAT?</title><categories>cs.NI</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ensuring fair co-existence between unlicensed LTE and WiFi networks is
currently of major concern to both cellular operators and WiFi providers. Two
main unlicensed LTE approaches currently being discussed, namely Carrier Sense
Adaptive Transmission (CSAT) and Listen Before Talk (LBT). While these
mechanisms differ in their compatibility with existing LTE specifications and
regulatory compliance in different countries, they also use fundamentally
different approaches to access the channel. Nevertheless, we show in this
article that when optimally configured both approaches are capable of providing
the same level of fairness to WiFi and that the choice between CSAT and LBT is
solely driven by the LTE operator's interests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06246</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06246</id><created>2015-11-19</created><authors><author><keyname>Chen</keyname><forenames>Xinchi</forenames></author><author><keyname>Qiu</keyname><forenames>Xipeng</forenames></author><author><keyname>Jiang</keyname><forenames>Jingxiang</forenames></author><author><keyname>Huang</keyname><forenames>Xuanjing</forenames></author></authors><title>Gaussian Mixture Embeddings for Multiple Word Prototypes</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, word representation has been increasingly focused on for its
excellent properties in representing the word semantics. Previous works mainly
suffer from the problem of polysemy phenomenon. To address this problem, most
of previous models represent words as multiple distributed vectors. However, it
cannot reflect the rich relations between words by representing words as points
in the embedded space. In this paper, we propose the Gaussian mixture skip-gram
(GMSG) model to learn the Gaussian mixture embeddings for words based on
skip-gram framework. Each word can be regarded as a gaussian mixture
distribution in the embedded space, and each gaussian component represents a
word sense. Since the number of senses varies from word to word, we further
propose the Dynamic GMSG (D-GMSG) model by adaptively increasing the sense
number of words during training. Experiments on four benchmarks show the
effectiveness of our proposed model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06247</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06247</id><created>2015-11-19</created><updated>2015-11-21</updated><authors><author><keyname>Vieira</keyname><forenames>Armando</forenames></author></authors><title>Predicting online user behaviour using deep learning algorithms</title><categories>cs.LG stat.ML</categories><comments>21 pages, 3 figures. arXiv admin note: text overlap with
  arXiv:1412.6601, arXiv:1406.1231, arXiv:1508.03856 by other authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a robust classifier to predict buying intentions based on user
behaviour within a large e-commerce website. In this work we compare
traditional machine learning techniques with the most advanced deep learning
approaches. We show that both Deep Belief Networks and Stacked Denoising
auto-Encoders achieved a substantial improvement by extracting features from
high dimensional data during the pre-train phase. They prove also to be more
convenient to deal with severe class imbalance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06248</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06248</id><created>2015-11-19</created><authors><author><keyname>Herrmann</keyname><forenames>J. Michael</forenames></author><author><keyname>Erskine</keyname><forenames>Adam</forenames></author><author><keyname>Joyce</keyname><forenames>Thomas</forenames></author></authors><title>Critical Parameters in Particle Swarm Optimisation</title><categories>cs.NE</categories><comments>9 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Particle swarm optimisation is a metaheuristic algorithm which finds
reasonable solutions in a wide range of applied problems if suitable parameters
are used. We study the properties of the algorithm in the framework of random
dynamical systems which, due to the quasi-linear swarm dynamics, yields
analytical results for the stability properties of the particles. Such
considerations predict a relationship between the parameters of the algorithm
that marks the edge between convergent and divergent behaviours. Comparison
with simulations indicates that the algorithm performs best near this margin of
instability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06251</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06251</id><created>2015-11-19</created><updated>2015-11-20</updated><authors><author><keyname>Li</keyname><forenames>Qianxiao</forenames></author><author><keyname>Tai</keyname><forenames>Cheng</forenames></author><author><keyname>E</keyname><forenames>Weinan</forenames></author></authors><title>Dynamics of Stochastic Gradient Algorithms</title><categories>cs.LG stat.ML</categories><comments>Changes: 1. Fixed a sign mistake in eq. (74). 2. Factor of d in eq.
  (98), and thus figure 10's estimate of k^*. 3. Fixed some typos and figure
  scales</comments><msc-class>68W20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic gradient algorithms (SGA) are increasingly popular in machine
learning applications and have become &quot;the algorithm&quot; for extremely large scale
problems. Although there are some convergence results, little is known about
their dynamics. In this paper, We propose the method of stochastic modified
equations (SME) to analyze the dynamics of the SGA. Using this technique, we
can give precise characterizations for both the initial convergence speed and
the eventual oscillations, at least in some special cases. Furthermore, the SME
formalism allows us to characterize various speed-up techniques, such as
introducing momentum, adjusting the learning rate and the mini-batch sizes.
Previously, these techniques relied mostly on heuristics. Besides introducing
simple examples to illustrate the SME formalism, we also apply the framework to
improve the relaxed randomized Kaczmarz method for solving linear equations.
The SME framework is a precise and unifying approach to understanding and
improving the SGA, and has the potential to be applied to many more stochastic
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06252</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06252</id><created>2015-11-19</created><authors><author><keyname>Yu</keyname><forenames>Fei</forenames></author><author><keyname>Zeng</keyname><forenames>An</forenames></author><author><keyname>Gillard</keyname><forenames>Sebastien</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author></authors><title>Network-based recommendation algorithms: A review</title><categories>cs.IR physics.soc-ph</categories><comments>review article; 16 pages, 4 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recommender systems are a vital tool that helps us to overcome the
information overload problem. They are being used by most e-commerce web sites
and attract the interest of a broad scientific community. A recommender system
uses data on users' past preferences to choose new items that might be
appreciated by a given individual user. While many approaches to recommendation
exist, the approach based on a network representation of the input data has
gained considerable attention in the past. We review here a broad range of
network-based recommendation algorithms and for the first time compare their
performance on three distinct real datasets. We present recommendation topics
that go beyond the mere question of which algorithm to use - such as the
possible influence of recommendation on the evolution of systems that use it -
and finally discuss open research directions and challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06253</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06253</id><created>2015-11-19</created><authors><author><keyname>Koufogiannis</keyname><forenames>Fragkiskos</forenames></author><author><keyname>Pappas</keyname><forenames>George</forenames></author></authors><title>Diffusing Private Data over Networks</title><categories>cs.DS cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The emergence of social and technological networks has enabled rapid sharing
of data and information. This has resulted in significant privacy concerns
where private information can be either leaked or inferred from public data.
The problem is significantly harder for social networks where we may reveal
more information to our friends than to strangers. Nonetheless, our private
information can still leak to strangers as our friends are their friends and so
on. In order to address this important challenge, in this paper, we present a
privacy-preserving mechanism that enables private data to be diffused over a
network. In particular, whenever a user wants to access another users' data,
the proposed mechanism returns a differentially private response that ensures
that the amount of private data leaked depends on the distance between the two
users in the network. While allowing global statistics to be inferred by users
acting as analysts, our mechanism guarantees that no individual user, or a
group of users, can harm the privacy guarantees of any other user. We
illustrate our mechanism with two examples: one on synthetic data where the
users share their GPS coordinates; and one on a Facebook ego-network where a
user shares her infection status.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06260</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06260</id><created>2015-11-19</created><updated>2015-11-27</updated><authors><author><keyname>Aschieri</keyname><forenames>Federico</forenames></author></authors><title>Game Semantics and the Geometry of Backtracking: a New Complexity
  Analysis of Interaction</title><categories>math.LO cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present abstract complexity results about Coquand and Hyland-Ong game
semantics, that will lead to new bounds on the length of first-order
cut-elimination, normalization, interaction between expansion trees and any
other dialogical process game semantics can model and apply to. In particular,
we provide a novel method to bound the length of interactions between visible
strategies and to measure precisely the tower of exponentials defining the
worst-case complexity. Our study improves the old estimates on average by
several exponentials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06266</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06266</id><created>2015-11-19</created><authors><author><keyname>Cao</keyname><forenames>Pan</forenames></author><author><keyname>Liu</keyname><forenames>Wenjia</forenames></author><author><keyname>Thompson</keyname><forenames>John S.</forenames></author><author><keyname>Yang</keyname><forenames>Chenyang</forenames></author><author><keyname>Jorswieck</keyname><forenames>Eduard A.</forenames></author></authors><title>Semi-dynamic Green Resource Management in Downlink Heterogeneous
  Networks by Group Sparse Power Control</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Journal on Selected Areas in Communications Green
  Communications and Networking: Second Issue (under revision)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the energy-saving problem for the downlink of
heterogeneous networks, which aims at minimizing the total base stations (BSs)
power consumption while each user's rate requirement is supported. The basic
idea of this work is to make use of the flexibility and scalability of the
system such that more benefits can be gained by efficient resource management.
This motivates us to propose a flexible BS power consumption model, which can
control system resources, such as antennas, frequency carriers and transmit
power allocation in an energy efficient manner rather than the &quot;on/off&quot; binary
sleep mode for BSs. To denote these power-saving modes, we employ the group
sparsity of the transmit power vector instead of the {0, 1} variables. Based on
this power model, a semi-dynamic green resource management mechanism is
proposed, which can jointly solve a series of resource management problems,
including BS association, frequency carriers (FCs) assignment, and the transmit
power allocation, by group sparse power control based on the large scale fading
values. In particular, the successive convex approximation (SCA)-based
algorithm is applied to solve a stationary solution to the original non-convex
problem. Simulation results also verify the proposed BS power model and the
green resource management mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06267</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06267</id><created>2015-11-19</created><updated>2016-02-09</updated><authors><author><keyname>Mroueh</keyname><forenames>Youssef</forenames></author><author><keyname>Marcheret</keyname><forenames>Etienne</forenames></author><author><keyname>Goel</keyname><forenames>Vaibhava</forenames></author></authors><title>Asymmetrically Weighted CCA And Hierarchical Kernel Sentence Embedding
  For Multimodal Retrieval</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Joint modeling of language and vision has been drawing increasing interest. A
multimodal data representation allowing for bidirectional retrieval of images
by sentences and vice versa is a key aspect. In this paper we present three
contributions in canonical correlation analysis (CCA) based multimodal
retrieval. Firstly, we show that an asymmetric weighting of the canonical
weights, while achieving a cross-view mapping from the search to the query
space, it improves the retrieval performance. Secondly, we devise a
computationally efficient model selection - crucial to generalization and
stability - in the framework of the Bjork Golub algorithm for regularized CCA
via spectral filtering. Finally, we introduce a Hierarchical Kernel Sentence
Embedding (HKSE) that approximates Kernel CCA for a special similarity kernel
between words distributions. State of the art results are obtained on MSCOCO
and Flickr benchmarks when these three techniques are used in conjunction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06276</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06276</id><created>2015-11-19</created><authors><author><keyname>Sihag</keyname><forenames>Saurabh</forenames></author><author><keyname>Dutta</keyname><forenames>Pranab Kumar</forenames></author></authors><title>Faster method for Deep Belief Network based Object classification using
  DWT</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Deep Belief Network (DBN) requires large, multiple hidden layers with high
number of hidden units to learn good features from the raw pixels of large
images. This implies more training time as well as computational complexity. By
integrating DBN with Discrete Wavelet Transform (DWT), both training time and
computational complexity can be reduced. The low resolution images obtained
after application of DWT are used to train multiple DBNs. The results obtained
from these DBNs are combined using a weighted voting algorithm. The performance
of this method is found to be competent and faster in comparison with that of
traditional DBNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06278</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06278</id><created>2015-11-18</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Watkins</keyname><forenames>Jennifer H.</forenames></author></authors><title>Quantum Walks with Gremlin</title><categories>quant-ph cs.DM</categories><comments>GraphDay '16, 1(1), pages 1-16, Austin Texas, January 2016</comments><report-no>LA-UR-15-29103</report-no><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  A quantum walk places a traverser into a superposition of both graph location
and traversal &quot;spin.&quot; The walk is defined by an initial condition, an evolution
determined by a unitary coin/shift-operator, and a measurement based on the
sampling of the probability distribution generated from the quantum
wavefunction. Simple quantum walks are studied analytically, but for large
graph structures with complex topologies, numerical solutions are typically
required. For the quantum theorist, the Gremlin graph traversal machine and
language can be used for the numerical analysis of quantum walks on such
structures. Additionally, for the graph theorist, the adoption of quantum walk
principles can transform what are currently side-effect laden traversals into
pure, stateless functional flows. This is true even when the constraints of
quantum mechanics are not fully respected (e.g. reversible and unitary
evolution). In sum, Gremlin allows both types of theorist to leverage each
other's constructs for the advancement of their respective disciplines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06279</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06279</id><created>2015-11-19</created><updated>2016-02-29</updated><authors><author><keyname>Reed</keyname><forenames>Scott</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>Neural Programmer-Interpreters</title><categories>cs.LG cs.NE</categories><comments>ICLR 2016 conference submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the neural programmer-interpreter (NPI): a recurrent and
compositional neural network that learns to represent and execute programs. NPI
has three learnable components: a task-agnostic recurrent core, a persistent
key-value program memory, and domain-specific encoders that enable a single NPI
to operate in multiple perceptually diverse environments with distinct
affordances. By learning to compose lower-level programs to express
higher-level programs, NPI reduces sample complexity and increases
generalization ability compared to sequence-to-sequence LSTMs. The program
memory allows efficient learning of additional tasks by building on existing
programs. NPI can also harness the environment (e.g. a scratch pad with
read-write pointers) to cache intermediate results of computation, lessening
the long-term memory burden on recurrent hidden units. In this work we train
the NPI with fully-supervised execution traces; each program has example
sequences of calls to the immediate subprograms conditioned on the input.
Rather than training on a huge number of relatively weak labels, NPI learns
from a small number of rich examples. We demonstrate the capability of our
model to learn several types of compositional programs: addition, sorting, and
canonicalizing 3D models. Furthermore, a single NPI learns to execute these
programs and all 21 associated subprograms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06281</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06281</id><created>2015-11-19</created><updated>2016-02-29</updated><authors><author><keyname>Ball&#xe9;</keyname><forenames>Johannes</forenames></author><author><keyname>Laparra</keyname><forenames>Valero</forenames></author><author><keyname>Simoncelli</keyname><forenames>Eero P.</forenames></author></authors><title>Density Modeling of Images using a Generalized Normalization
  Transformation</title><categories>cs.LG cs.CV</categories><comments>published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a parametric nonlinear transformation that is well-suited for
Gaussianizing data from natural images. The data are linearly transformed, and
each component is then normalized by a pooled activity measure, computed by
exponentiating a weighted sum of rectified and exponentiated components and a
constant. We optimize the parameters of the full transformation (linear
transform, exponents, weights, constant) over a database of natural images,
directly minimizing the negentropy of the responses. The optimized
transformation substantially Gaussianizes the data, achieving a significantly
smaller mutual information between transformed components than alternative
methods including ICA and radial Gaussianization. The transformation is
differentiable and can be efficiently inverted, and thus induces a density
model on images. We show that samples of this model are visually similar to
samples of natural image patches. We demonstrate the use of the model as a
prior probability density that can be used to remove additive noise. Finally,
we show that the transformation can be cascaded, with each layer optimized
using the same Gaussianization objective, thus offering an unsupervised method
of optimizing a deep network architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06285</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06285</id><created>2015-11-18</created><authors><author><keyname>Wo&#x142;k</keyname><forenames>Krzysztof</forenames></author><author><keyname>Rejmund</keyname><forenames>Emilia</forenames></author><author><keyname>Marasek</keyname><forenames>Krzysztof</forenames></author></authors><title>Harvesting comparable corpora and mining them for equivalent bilingual
  sentences using statistical classification and analogy- based heuristics</title><categories>cs.CL stat.ML</categories><comments>Springer p. 433-441, 2015</comments><doi>10.1007/978-3-319-25252-0_46</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parallel sentences are a relatively scarce but extremely useful resource for
many applications including cross-lingual retrieval and statistical machine
translation. This research explores our new methodologies for mining such data
from previously obtained comparable corpora. The task is highly practical since
non-parallel multilingual data exist in far greater quantities than parallel
corpora, but parallel sentences are a much more useful resource. Here we
propose a web crawling method for building subject-aligned comparable corpora
from e.g. Wikipedia dumps and Euronews web page. The improvements in machine
translation are shown on Polish-English language pair for various text domains.
We also tested another method of building parallel corpora based on comparable
corpora data. It lets automatically broad existing corpus of sentences from
subject of corpora based on analogies between them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06292</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06292</id><created>2015-11-19</created><updated>2016-01-19</updated><authors><author><keyname>Luo</keyname><forenames>Yan</forenames></author><author><keyname>Boix</keyname><forenames>Xavier</forenames></author><author><keyname>Roig</keyname><forenames>Gemma</forenames></author><author><keyname>Poggio</keyname><forenames>Tomaso</forenames></author><author><keyname>Zhao</keyname><forenames>Qi</forenames></author></authors><title>Foveation-based Mechanisms Alleviate Adversarial Examples</title><categories>cs.LG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that adversarial examples, i.e., the visually imperceptible
perturbations that result in Convolutional Neural Networks (CNNs) fail, can be
alleviated with a mechanism based on foveations---applying the CNN in different
image regions. To see this, first, we report results in ImageNet that lead to a
revision of the hypothesis that adversarial perturbations are a consequence of
CNNs acting as a linear classifier: CNNs act locally linearly to changes in the
image regions with objects recognized by the CNN, and in other regions the CNN
may act non-linearly. Then, we corroborate that when the neural responses are
linear, applying the foveation mechanism to the adversarial example tends to
significantly reduce the effect of the perturbation. This is because,
hypothetically, the CNNs for ImageNet are robust to changes of scale and
translation of the object produced by the foveation, but this property does not
generalize to transformations of the perturbation. As a result, the accuracy
after a foveation is almost the same as the accuracy of the CNN without the
adversarial perturbation, even if the adversarial perturbation is calculated
taking into account a foveation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06295</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06295</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Rusu</keyname><forenames>Andrei A.</forenames></author><author><keyname>Colmenarejo</keyname><forenames>Sergio Gomez</forenames></author><author><keyname>Gulcehre</keyname><forenames>Caglar</forenames></author><author><keyname>Desjardins</keyname><forenames>Guillaume</forenames></author><author><keyname>Kirkpatrick</keyname><forenames>James</forenames></author><author><keyname>Pascanu</keyname><forenames>Razvan</forenames></author><author><keyname>Mnih</keyname><forenames>Volodymyr</forenames></author><author><keyname>Kavukcuoglu</keyname><forenames>Koray</forenames></author><author><keyname>Hadsell</keyname><forenames>Raia</forenames></author></authors><title>Policy Distillation</title><categories>cs.LG</categories><comments>Submitted to ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Policies for complex visual tasks have been successfully learned with deep
reinforcement learning, using an approach called deep Q-networks (DQN), but
relatively large (task-specific) networks and extensive training are needed to
achieve good performance. In this work, we present a novel method called policy
distillation that can be used to extract the policy of a reinforcement learning
agent and train a new network that performs at the expert level while being
dramatically smaller and more efficient. Furthermore, the same method can be
used to consolidate multiple task-specific policies into a single policy. We
demonstrate these claims using the Atari domain and show that the multi-task
distilled agent outperforms the single-task teachers as well as a
jointly-trained DQN agent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06297</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06297</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Bengio</keyname><forenames>Emmanuel</forenames></author><author><keyname>Bacon</keyname><forenames>Pierre-Luc</forenames></author><author><keyname>Pineau</keyname><forenames>Joelle</forenames></author><author><keyname>Precup</keyname><forenames>Doina</forenames></author></authors><title>Conditional Computation in Neural Networks for faster models</title><categories>cs.LG</categories><comments>ICLR 2016 submission, revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning has become the state-of-art tool in many applications, but the
evaluation and training of deep models can be time-consuming and
computationally expensive. The conditional computation approach has been
proposed to tackle this problem (Bengio et al., 2013; Davis &amp; Arel, 2013). It
operates by selectively activating only parts of the network at a time. In this
paper, we use reinforcement learning as a tool to optimize conditional
computation policies. More specifically, we cast the problem of learning
activation-dependent policies for dropping out blocks of units as a
reinforcement learning problem. We propose a learning scheme motivated by
computation speed, capturing the idea of wanting to have parsimonious
activations while maintaining prediction accuracy. We apply a policy gradient
algorithm for learning policies that optimize this loss function and propose a
regularization mechanism that encourages diversification of the dropout policy.
We present encouraging empirical results showing that this approach improves
the speed of computation without impacting the quality of the approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06303</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06303</id><created>2015-11-19</created><updated>2015-11-24</updated><authors><author><keyname>Bojanowski</keyname><forenames>Piotr</forenames></author><author><keyname>Joulin</keyname><forenames>Armand</forenames></author><author><keyname>Mikolov</keyname><forenames>Tomas</forenames></author></authors><title>Alternative structures for character-level RNNs</title><categories>cs.LG cs.CL</categories><comments>First revision. Updated Table 3, extended Sec. 5.3 and added a
  paragraph to the conclusion,</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent neural networks are convenient and efficient models for language
modeling. However, when applied on the level of characters instead of words,
they suffer from several problems. In order to successfully model long-term
dependencies, the hidden representation needs to be large. This in turn implies
higher computational costs, which can become prohibitive in practice. We
propose two alternative structural modifications to the classical RNN model.
The first one consists on conditioning the character level representation on
the previous word representation. The other one uses the character history to
condition the output probability. We evaluate the performance of the two
proposed modifications on challenging, multi-lingual real world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06306</identifier>
 <datestamp>2016-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06306</id><created>2015-11-19</created><updated>2016-02-25</updated><authors><author><keyname>Jin</keyname><forenames>Jonghoon</forenames></author><author><keyname>Dundar</keyname><forenames>Aysegul</forenames></author><author><keyname>Culurciello</keyname><forenames>Eugenio</forenames></author></authors><title>Robust Convolutional Neural Networks under Adversarial Noise</title><categories>cs.LG cs.CV</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent studies have shown that Convolutional Neural Networks (CNNs) are
vulnerable to a small perturbation of input called &quot;adversarial examples&quot;. In
this work, we propose a new feedforward CNN that improves robustness in the
presence of adversarial noise. Our model uses stochastic additive noise added
to the input image and to the CNN models. The proposed model operates in
conjunction with a CNN trained with either standard or adversarial objective
function. In particular, convolution, max-pooling, and ReLU layers are modified
to benefit from the noise model. Our feedforward model is parameterized by only
a mean and variance per pixel which simplifies computations and makes our
method scalable to a deep architecture. From CIFAR-10 and ImageNet test, the
proposed model outperforms other methods and the improvement is more evident
for difficult classification tasks or stronger adversarial noise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06309</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06309</id><created>2015-11-19</created><updated>2015-11-30</updated><authors><author><keyname>Patraucean</keyname><forenames>Viorica</forenames></author><author><keyname>Handa</keyname><forenames>Ankur</forenames></author><author><keyname>Cipolla</keyname><forenames>Roberto</forenames></author></authors><title>Spatio-temporal video autoencoder with differentiable memory</title><categories>cs.LG cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We describe a new spatio-temporal video autoencoder, based on a classic
spatial image autoencoder and a novel nested temporal autoencoder. The temporal
encoder is represented by a differentiable visual memory composed of
convolutional long short-term memory (LSTM) cells that integrate changes over
time. Here we target motion changes and use as temporal decoder a robust
optical flow prediction module together with an image sampler serving as
built-in feedback loop. The architecture is end-to-end differentiable. At each
time step, the system receives as input a video frame, predicts the optical
flow based on the current observation and the LSTM memory state as a dense
transformation map, and applies it to the current frame to generate the next
frame. By minimising the reconstruction error between the predicted next frame
and the corresponding ground truth next frame, we train the whole system to
extract features useful for motion estimation without any supervision effort.
We believe these features can in turn facilitate learning high-level tasks such
as path planning, semantic segmentation, or action recognition, reducing the
overall supervision effort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06312</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06312</id><created>2015-11-19</created><authors><author><keyname>Cross</keyname><forenames>James</forenames></author><author><keyname>Xiang</keyname><forenames>Bing</forenames></author><author><keyname>Zhou</keyname><forenames>Bowen</forenames></author></authors><title>Good, Better, Best: Choosing Word Embedding Context</title><categories>cs.CL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We propose two methods of learning vector representations of words and
phrases that each combine sentence context with structural features extracted
from dependency trees. Using several variations of neural network classifier,
we show that these combined methods lead to improved performance when used as
input features for supervised term-matching.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06313</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06313</id><created>2015-11-19</created><authors><author><keyname>Li</keyname><forenames>Xiaoming</forenames></author><author><keyname>Lv</keyname><forenames>Zhihan</forenames></author><author><keyname>Wang</keyname><forenames>Weixi</forenames></author><author><keyname>Zhang</keyname><forenames>Baoyun</forenames></author><author><keyname>Hu</keyname><forenames>Jinxing</forenames></author><author><keyname>Yin</keyname><forenames>Ling</forenames></author><author><keyname>Feng</keyname><forenames>Shengzhong</forenames></author></authors><title>Preprint WebVRGIS Based Traffic Analysis and Visualization System</title><categories>cs.OH</categories><comments>This is the preprint version of our paper on Advances in Engineering
  Software. arXiv admin note: substantial text overlap with arXiv:1504.01057,
  arXiv:1504.01375</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the preprint version of our paper on Advances in Engineering
Software. With several characteristics, such as large scale, diverse
predictability and timeliness, the city traffic data falls in the range of
definition of Big Data. A Virtual Reality GIS based traffic analysis and
visualization system is proposed as a promising and inspiring approach to
manage and develop traffic big data. In addition to the basic GIS interaction
functions, the proposed system also includes some intelligent visual analysis
and forecasting functions. The passenger flow forecasting algorithm is
introduced in detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06314</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06314</id><created>2015-11-19</created><authors><author><keyname>Lee</keyname><forenames>Stefan</forenames></author><author><keyname>Purushwalkam</keyname><forenames>Senthil</forenames></author><author><keyname>Cogswell</keyname><forenames>Michael</forenames></author><author><keyname>Crandall</keyname><forenames>David</forenames></author><author><keyname>Batra</keyname><forenames>Dhruv</forenames></author></authors><title>Why M Heads are Better than One: Training a Diverse Ensemble of Deep
  Networks</title><categories>cs.CV cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks have achieved state-of-the-art performance on a
wide range of tasks. Most benchmarks are led by ensembles of these powerful
learners, but ensembling is typically treated as a post-hoc procedure
implemented by averaging independently trained models with model variation
induced by bagging or random initialization. In this paper, we rigorously treat
ensembling as a first-class problem to explicitly address the question: what
are the best strategies to create an ensemble? We first compare a large number
of ensembling strategies, and then propose and evaluate novel strategies, such
as parameter sharing (through a new family of models we call TreeNets) as well
as training under ensemble-aware and diversity-encouraging losses. We
demonstrate that TreeNets can improve ensemble performance and that diverse
ensembles can be trained end-to-end under a unified loss, achieving
significantly higher &quot;oracle&quot; accuracies than classical ensembles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06316</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06316</id><created>2015-11-19</created><authors><author><keyname>Boulkenafet</keyname><forenames>Zinelabidine</forenames></author><author><keyname>Komulainen</keyname><forenames>Jukka</forenames></author><author><keyname>Hadid</keyname><forenames>Abdenour</forenames></author></authors><title>face anti-spoofing based on color texture analysis</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research on face spoofing detection has mainly been focused on analyzing the
luminance of the face images, hence discarding the chrominance information
which can be useful for discriminating fake faces from genuine ones. In this
work, we propose a new face anti-spoofing method based on color texture
analysis. We analyze the joint color-texture information from the luminance and
the chrominance channels using a color local binary pattern descriptor. More
specifically, the feature histograms are extracted from each image band
separately. Extensive experiments on two benchmark datasets, namely CASIA face
anti-spoofing and Replay-Attack databases, showed excellent results compared to
the state-of-the-art. Most importantly, our inter-database evaluation depicts
that the proposed approach showed very promising generalization capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06321</identifier>
 <datestamp>2016-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06321</id><created>2015-11-19</created><updated>2016-01-05</updated><authors><author><keyname>Hsu</keyname><forenames>Yen-Chang</forenames></author><author><keyname>Kira</keyname><forenames>Zsolt</forenames></author></authors><title>Neural network-based clustering using pairwise constraints</title><categories>cs.LG stat.ML</categories><comments>10 pages, 5 figures, Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we address the problem of finding a clustering of
high-dimensional data using only pairwise constraints provided as input. Our
strategy utilizes the back-propagation algorithm for optimizing neural networks
to discover the clusters, while at the same time the features are also learned
during the same training process. In order to do this, we design a novel
architecture that can incorporate cost functions associated with KL divergence
in order to minimize the distance for similar pairs while maximizing the
distance for dissimilar pairs. We also propose an implementation that optimizes
the parameters of the architecture more efficiently than a naive
implementation, e.g. via Siamese networks. Experiments on MNIST and CIFAR-10
show that the accuracy of the proposed approach is comparable or exceeds the
results of classification. Reasonable clusters could also be discovered when
only partial pairwise constraints were available. The robustness analysis shows
the method can tolerate moderate noise and is largely insensitive to the number
of clusters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06324</identifier>
 <datestamp>2016-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06324</id><created>2015-11-18</created><updated>2016-03-05</updated><authors><author><keyname>Wang</keyname><forenames>Yu</forenames></author><author><keyname>Yin</keyname><forenames>Wotao</forenames></author><author><keyname>Zeng</keyname><forenames>Jinshan</forenames></author></authors><title>Global Convergence of ADMM in Nonconvex Nonsmooth Optimization</title><categories>math.OC cs.NA math.NA</categories><comments>29 pages, 1 figure</comments><report-no>UCLA CAM Report 15-62</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the convergence of the alternating direction method
of multipliers (ADMM) for minimizing a nonconvex and possibly nonsmooth
objective function, $\phi(x_1,\ldots,x_p,y)$, subject to coupled linear
equality constraints. Our ADMM updates each of the primal variables
$x_1,\ldots,x_p,y$, followed by updating the dual variable. We separate the
variable $y$ from $x_i$'s as it has a special role in our analysis.
  The developed convergence guarantee covers a variety of nonconvex functions
such as piecewise linear functions, $\ell_q$ quasi-norm, Schatten-$q$
quasi-norm ($0&lt;q&lt;1$) and SCAD, as well as the indicator functions of compact
smooth manifolds (e.g., spherical, Stiefel, and Grassman manifolds). By
applying our analysis, we show, for the first time, that several ADMM
algorithms applied to solve nonconvex models in statistical learning,
optimization on manifold, and matrix decomposition are guaranteed to converge.
  Our results provide sufficient conditions for ADMM to converge on (convex or
nonconvex) monotropic programs with three or more blocks, as they are special
cases of our model.
  ADMM has been regarded as a variant to the augmented Lagrangian method (ALM).
We present a simple example to illustrate how ADMM converges but ALM diverges
with bounded penalty parameter $\beta$. Indicated by this example and other
analysis in this paper, ADMM might be a better choice than ALM for some
nonconvex \emph{nonsmooth} problems, because ADMM is not only easier to
implement, it is also more likely to converge for the concerned scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06328</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06328</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Zhai</keyname><forenames>Shuangfei</forenames></author><author><keyname>Zhang</keyname><forenames>Zhongfei</forenames></author></authors><title>Manifold Regularized Discriminative Neural Networks</title><categories>cs.LG</categories><comments>In submission to ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unregularized deep neural networks (DNNs) can be easily overfit with a
limited sample size. We argue that this is mostly due to the disriminative
nature of DNNs which directly model the conditional probability (or score) of
labels given the input. The ignorance of input distribution makes DNNs
difficult to generalize to unseen data. Recent advances in regularization
techniques, such as pretraining and dropout, indicate that modeling input data
distribution (either explicitly or implicitly) greatly improves the
generalization ability of a DNN. In this work, we explore the manifold
hypothesis which assumes that instances within the same class lie in a smooth
manifold. We accordingly propose two simple regularizers to a standard
discriminative DNN. The first one, named Label-Aware Manifold Regularization,
assumes the availability of labels and penalizes large norms of the loss
function w.r.t. data points. The second one, named Label-Independent Manifold
Regularization, does not use label information and instead penalizes the
Frobenius norm of the Jacobian matrix of prediction scores w.r.t. data points,
which makes semi-supervised learning possible. We perform extensive control
experiments on fully supervised and semi-supervised tasks using the MNIST,
CIFAR10 and SVHN datasets and achieve excellent results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06333</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06333</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Ravishankar</keyname><forenames>Saiprasad</forenames></author><author><keyname>Nadakuditi</keyname><forenames>Raj Rao</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author></authors><title>Efficient Sum of Sparse Outer Products Dictionary Learning (SOUP-DIL)</title><categories>cs.LG</categories><comments>This paper was submitted to ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sparsity of natural signals in a transform domain or dictionary has been
extensively exploited in several applications. More recently, the data-driven
adaptation of synthesis dictionaries has shown promise in many applications
compared to fixed or analytical dictionaries. However, dictionary learning
problems are typically non-convex and NP-hard, and the usual alternating
minimization approaches for these problems are often computationally expensive,
with the computations dominated by the NP-hard synthesis sparse coding step. In
this work, we investigate an efficient method for $\ell_{0}$ &quot;norm&quot;-based
dictionary learning by first approximating the training data set with a sum of
sparse rank-one matrices and then using a block coordinate descent approach to
estimate the rank-one terms. The proposed algorithm involves efficient
closed-form solutions. In particular, the sparse coding step involves a simple
form of thresholding. We provide a convergence analysis for the proposed block
coordinate descent method. Our experiments show the promising performance and
significant speed-ups provided by our method over the classical K-SVD scheme in
sparse signal representation and image denoising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06335</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06335</id><created>2015-11-19</created><authors><author><keyname>Xie</keyname><forenames>Junyuan</forenames></author><author><keyname>Girshick</keyname><forenames>Ross</forenames></author><author><keyname>Farhadi</keyname><forenames>Ali</forenames></author></authors><title>Unsupervised Deep Embedding for Clustering Analysis</title><categories>cs.LG cs.CV</categories><comments>iclr2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clustering is central to many data-driven application domains and has been
studied extensively in terms of distance functions and grouping algorithms.
Relatively little work has focused on learning representations for clustering.
In this paper, we propose Deep Embedded Clustering (DEC), a method that
simultaneously learns feature representations and cluster assignments using
deep neural networks. DEC learns a mapping from the data space to a
lower-dimensional feature space in which it iteratively optimizes a clustering
objective. Our experimental evaluations on image and text corpora show
significant improvement over state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06340</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06340</id><created>2015-11-19</created><authors><author><keyname>Fu</keyname><forenames>Yanwei</forenames></author><author><keyname>Huang</keyname><forenames>De-An</forenames></author><author><keyname>Sigal</keyname><forenames>Leonid</forenames></author></authors><title>Robust Classification by Pre-conditioned LASSO and Transductive
  Diffusion Component Analysis</title><categories>cs.LG cs.CV math.ST stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern machine learning-based recognition approaches require large-scale
datasets with large number of labelled training images. However, such datasets
are inherently difficult and costly to collect and annotate. Hence there is a
great and growing interest in automatic dataset collection methods that can
leverage the web. % which are collected % in a cheap, efficient and yet
unreliable way. Collecting datasets in this way, however, requires robust and
efficient ways for detecting and excluding outliers that are common and
prevalent. % Outliers are thus a % prominent treat of using these dataset. So
far, there have been a limited effort in machine learning community to directly
detect outliers for robust classification. Inspired by the recent work on
Pre-conditioned LASSO, this paper formulates the outlier detection task using
Pre-conditioned LASSO and employs \red{unsupervised} transductive diffusion
component analysis to both integrate the topological structure of the data
manifold, from labeled and unlabeled instances, and reduce the feature
dimensionality. Synthetic experiments as well as results on two real-world
classification tasks show that our framework can robustly detect the outliers
and improve classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06341</identifier>
 <datestamp>2016-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06341</id><created>2015-11-19</created><updated>2016-03-07</updated><authors><author><keyname>Guha</keyname><forenames>Ramanathan V</forenames></author><author><keyname>Gupta</keyname><forenames>Vineet</forenames></author></authors><title>Communicating Semantics: Reference by Description</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Messages often refer to entities such as people, places and events. Correct
identification of the intended reference is an essential part of communication.
Lack of shared unique names often complicates entity reference. Shared
knowledge can be used to construct uniquely identifying descriptive references
for entities with ambiguous names. We introduce a mathematical model for
`Reference by Description', derive results on the conditions under which, with
high probability, programs can construct unambiguous references to most
entities in the domain of discourse and provide empirical validation of these
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06342</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06342</id><created>2015-11-19</created><updated>2016-02-22</updated><authors><author><keyname>Parisotto</keyname><forenames>Emilio</forenames></author><author><keyname>Ba</keyname><forenames>Jimmy Lei</forenames></author><author><keyname>Salakhutdinov</keyname><forenames>Ruslan</forenames></author></authors><title>Actor-Mimic: Deep Multitask and Transfer Reinforcement Learning</title><categories>cs.LG</categories><comments>Accepted as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to act in multiple environments and transfer previous knowledge
to new situations can be considered a critical aspect of any intelligent agent.
Towards this goal, we define a novel method of multitask and transfer learning
that enables an autonomous agent to learn how to behave in multiple tasks
simultaneously, and then generalize its knowledge to new domains. This method,
termed &quot;Actor-Mimic&quot;, exploits the use of deep reinforcement learning and model
compression techniques to train a single policy network that learns how to act
in a set of distinct tasks by using the guidance of several expert teachers. We
then show that the representations learnt by the deep policy network are
capable of generalizing to new tasks with no prior expert guidance, speeding up
learning in novel environments. Although our method can in general be applied
to a wide range of problems, we use Atari games as a testing environment to
demonstrate these methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06343</identifier>
 <datestamp>2016-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06343</id><created>2015-11-19</created><updated>2016-01-22</updated><authors><author><keyname>Loshchilov</keyname><forenames>Ilya</forenames></author><author><keyname>Hutter</keyname><forenames>Frank</forenames></author></authors><title>Online Batch Selection for Faster Training of Neural Networks</title><categories>cs.LG cs.NE math.OC</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks are commonly trained using stochastic non-convex
optimization procedures, which are driven by gradient information estimated on
fractions (batches) of the dataset. While it is commonly accepted that batch
size is an important parameter for offline tuning, the benefits of online
selection of batches remain poorly understood. We investigate online batch
selection strategies for two state-of-the-art methods of stochastic
gradient-based optimization, AdaDelta and Adam. As the loss function to be
minimized for the whole dataset is an aggregation of loss functions of
individual datapoints, intuitively, datapoints with the greatest loss should be
considered (selected in a batch) more frequently. However, the limitations of
this intuition and the proper control of the selection pressure over time are
open questions. We propose a simple strategy where all datapoints are ranked
w.r.t. their latest known loss value and the probability to be selected decays
exponentially as a function of rank. Our experimental results on the MNIST
dataset suggest that selecting batches speeds up both AdaDelta and Adam by a
factor of about 5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06344</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06344</id><created>2015-11-19</created><authors><author><keyname>Razi</keyname><forenames>Abolfazl</forenames></author><author><keyname>Afghah</keyname><forenames>Fatemeh</forenames></author><author><keyname>Abedi</keyname><forenames>Ali</forenames></author></authors><title>Channel-Adaptive Packetization Policy for Minimal Latency and Maximal
  Energy Efficiency</title><categories>cs.NI</categories><comments>IEEE Transactions on Wireless Communications, to appear 2015</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  This article considers the problem of delay optimal bundling of the input
symbols into transmit packets in the entry point of a wireless sensor network
such that the link delay is minimized under an arbitrary arrival rate and a
given channel error rate. The proposed policy exploits the variable packet
length feature of contemporary communications protocols in order to minimize
the link delay via packet length regularization. This is performed through
concrete characterization of the end-to-end link delay for zero error tolerance
system with First Come First Serve (FCFS)queuing discipline and Automatic
Repeat Request (ARQ) retransmission mechanism. The derivations are provided for
an uncoded system as well as a coded system with a given bit error rate. The
proposed packetization policy provides an optimal packetization interval that
minimizes the end-to-end delay for a given channel with certain bit error
probability. This algorithm can also be used for near-optimal bundling of input
symbols for dynamic channel conditions provided that the channel condition
varies slowly over time with respect to symbol arrival rate. This algorithm
complements the current network-based delay-optimal routing and scheduling
algorithms in order to further reduce the end-to-end delivery time. Moreover,
the proposed method is employed to solve the problem of energy efficiency
maximization under an average delay constraint by recasting it as a convex
optimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06348</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06348</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Cho</keyname><forenames>Junghwan</forenames></author><author><keyname>Lee</keyname><forenames>Kyewook</forenames></author><author><keyname>Shin</keyname><forenames>Ellie</forenames></author><author><keyname>Choy</keyname><forenames>Garry</forenames></author><author><keyname>Do</keyname><forenames>Synho</forenames></author></authors><title>How much data is needed to train a medical image deep learning system to
  achieve necessary high accuracy?</title><categories>cs.LG cs.CV cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The use of Convolutional Neural Networks (CNN) in natural image
classification systems has produced very impressive results. Combined with the
inherent nature of medical images that make them ideal for deep-learning,
further application of such systems to medical image classification holds much
promise. However, the usefulness and potential impact of such a system can be
completely negated if it does not reach a target accuracy. In this paper, we
present a study on determining the optimum size of the training data set
necessary to achieve high classification accuracy with low variance in medical
image classification systems. The CNN was applied to classify axial Computed
Tomography (CT) images into six anatomical classes. We trained the CNN using
six different sizes of training data set (5, 10, 20, 50, 100, and 200) and then
tested the resulting system with a total of 6000 CT images. All images were
acquired from the Massachusetts General Hospital (MGH) Picture Archiving and
Communication System (PACS). Using this data, we employ the learning curve
approach to predict classification accuracy at a given training sample size.
Our research will present a general methodology for determining the training
data set size necessary to achieve a certain target classification accuracy
that can be easily applied to other problems within such systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06349</identifier>
 <datestamp>2016-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06349</id><created>2015-11-19</created><updated>2016-01-25</updated><authors><author><keyname>Bowman</keyname><forenames>Samuel R.</forenames></author><author><keyname>Vilnis</keyname><forenames>Luke</forenames></author><author><keyname>Vinyals</keyname><forenames>Oriol</forenames></author><author><keyname>Dai</keyname><forenames>Andrew M.</forenames></author><author><keyname>Jozefowicz</keyname><forenames>Rafal</forenames></author><author><keyname>Bengio</keyname><forenames>Samy</forenames></author></authors><title>Generating Sentences from a Continuous Space</title><categories>cs.LG cs.CL</categories><comments>First two authors contributed equally. Work was done when all authors
  were at Google, Inc. Under review for ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The standard unsupervised recurrent neural network language model (RNNLM)
generates sentences one word at a time and does not work from an explicit
global distributed sentence representation. In this work, we present an
RNN-based variational autoencoder language model that incorporates distributed
latent representations of entire sentences. This factorization allows it to
explicitly model holistic properties of sentences such as style, topic, and
high-level syntactic features. Samples from the prior over these sentence
representations remarkably produce diverse and well-formed sentences through
simple deterministic decoding. By examining paths through this latent space, we
are able to generate coherent novel sentences that interpolate between known
sentences. We present techniques for solving the difficult learning problem
presented by this model, demonstrate strong performance in the imputation of
missing tokens, and explore many interesting properties of the latent sentence
space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06350</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06350</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Belanger</keyname><forenames>David</forenames></author><author><keyname>McCallum</keyname><forenames>Andrew</forenames></author></authors><title>Structured Prediction Energy Networks</title><categories>cs.LG</categories><comments>Updated version of ICLR 2016 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce structured prediction energy networks (SPENs), a flexible
framework for structured prediction. A deep architecture is used to define an
energy function of candidate labels, and then predictions are produced by using
back-propagation to iteratively optimize the energy with respect to the labels.
This deep architecture captures dependencies between labels that would lead to
intractable graphical models, and performs structure learning by automatically
learning discriminative features of the structured output. One natural
application of our technique is multi-label classification, which traditionally
has required strict prior assumptions about the interactions between labels to
ensure tractable learning and prediction problems. We are able to apply SPENs
to multi-label problems with substantially larger label sets than previous
applications of structured prediction, while modeling high-order interactions
using minimal structural assumptions. Overall, deep learning provides
remarkable tools for learning features of the inputs to a prediction problem,
and this work extends these techniques to learning features of structured
outputs. Our experiments provide impressive performance on a variety of
benchmark multi-label classification tasks, demonstrate that our technique can
be used to provide interpretable structure learning, and illuminate fundamental
trade-offs between feed-forward and iterative structured prediction techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06351</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06351</id><created>2015-11-19</created><authors><author><keyname>Sarroff</keyname><forenames>Andy M.</forenames></author><author><keyname>Shepardson</keyname><forenames>Victor</forenames></author><author><keyname>Casey</keyname><forenames>Michael A.</forenames></author></authors><title>Learning Representations Using Complex-Valued Nets</title><categories>cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex-valued neural networks (CVNNs) are an emerging field of research in
neural networks due to their potential representational properties for audio,
image, and physiological signals. It is common in signal processing to
transform sequences of real values to the complex domain via a set of complex
basis functions, such as the Fourier transform. We show how CVNNs can be used
to learn complex representations of real valued time-series data. We present
methods and results using a framework that can compose holomorphic and
non-holomorphic functions in a multi-layer network using a theoretical result
called the Wirtinger derivative. We test our methods on a representation
learning task for real-valued signals, recurrent complex-valued networks and
their real-valued counterparts. Our results show that recurrent complex-valued
networks can perform as well as their real-valued counterparts while learning
filters that are representative of the domain of the data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06353</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06353</id><created>2015-11-19</created><authors><author><keyname>Chen</keyname><forenames>Xiaojie</forenames></author><author><keyname>Sasaki</keyname><forenames>Tatsuya</forenames></author><author><keyname>Perc</keyname><forenames>Matjaz</forenames></author></authors><title>Evolution of public cooperation in a monitored society with implicated
  punishment and within-group enforcement</title><categories>q-bio.PE cs.GT physics.soc-ph</categories><comments>9 two-column pages, 5 figures; accepted for publication in Scientific
  Reports</comments><journal-ref>Sci. Rep. 5 (2015) 17050</journal-ref><doi>10.1038/srep17050</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monitoring with implicated punishment is common in human societies to avert
freeriding on common goods. But is it effective in promoting public
cooperation? We show that the introduction of monitoring and implicated
punishment is indeed effective, as it transforms the public goods game to a
coordination game, thus rendering cooperation viable in infinite and finite
well-mixed populations. We also show that the addition of within-group
enforcement further promotes the evolution of public cooperation. However,
although the group size in this context has nonlinear effects on collective
action, an intermediate group size is least conductive to cooperative
behaviour. This contradicts recent field observations, where an intermediate
group size was declared optimal with the conjecture that group-size effects and
within-group enforcement are responsible. Our theoretical research thus
clarifies key aspects of monitoring with implicated punishment in human
societies, and additionally, it reveals fundamental group-size effects that
facilitate prosocial collective action.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06359</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06359</id><created>2015-11-19</created><updated>2016-01-08</updated><authors><author><keyname>Wen</keyname><forenames>Bihan</forenames></author><author><keyname>Ravishankar</keyname><forenames>Saiprasad</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author></authors><title>FRIST - Flipping and Rotation Invariant Sparsifying Transform Learning
  and Applications</title><categories>cs.LG cs.CV</categories><comments>11 pages (including the references and supplementary material), under
  review as conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Features based on sparse representation, especially using synthesis
dictionary model, have been heavily exploited in signal processing and computer
vision. However, synthesis dictionary learning involves NP-hard sparse coding
and expensive learning steps. Recently, sparsifying transform learning received
interest for its cheap computation and closed-form solution. In this work, we
develop a methodology for learning of Flipping and Rotation Invariant
Sparsifying Transform, dubbed FRIST, to better represent natural images that
contain textures with various geometrical directions. The proposed alternating
learning algorithm involves simple closed-form solutions. We demonstrate
empirical convergence behavior of the proposed FRIST learning scheme.
Preliminary experiments show the usefulness of adaptive sparse representation
by FRIST for image sparse representation, segmentation, denoising, and robust
inpainting with promising performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06361</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06361</id><created>2015-11-19</created><updated>2016-03-01</updated><authors><author><keyname>Vendrov</keyname><forenames>Ivan</forenames></author><author><keyname>Kiros</keyname><forenames>Ryan</forenames></author><author><keyname>Fidler</keyname><forenames>Sanja</forenames></author><author><keyname>Urtasun</keyname><forenames>Raquel</forenames></author></authors><title>Order-Embeddings of Images and Language</title><categories>cs.LG cs.CL cs.CV</categories><comments>ICLR camera-ready version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hypernymy, textual entailment, and image captioning can be seen as special
cases of a single visual-semantic hierarchy over words, sentences, and images.
In this paper we advocate for explicitly modeling the partial order structure
of this hierarchy. Towards this goal, we introduce a general method for
learning ordered representations, and show how it can be applied to a variety
of tasks involving images and language. We show that the resulting
representations improve performance over current approaches for hypernym
prediction and image-caption retrieval.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06362</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06362</id><created>2015-11-19</created><updated>2016-02-16</updated><authors><author><keyname>Huang</keyname><forenames>Jonathan</forenames></author><author><keyname>Murphy</keyname><forenames>Kevin</forenames></author></authors><title>Efficient inference in occlusion-aware generative models of images</title><categories>cs.LG cs.CV</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a generative model of images based on layering, in which image
layers are individually generated, then composited from front to back. We are
thus able to factor the appearance of an image into the appearance of
individual objects within the image --- and additionally for each individual
object, we can factor content from pose. Unlike prior work on layered models,
we learn a shape prior for each object/layer, allowing the model to tease out
which object is in front by looking for a consistent shape, without needing
access to motion cues or any labeled data. We show that ordinary stochastic
gradient variational bayes (SGVB), which optimizes our fully differentiable
lower-bound on the log-likelihood, is sufficient to learn an interpretable
representation of images. Finally we present experiments demonstrating the
effectiveness of the model for inferring foreground and background objects in
images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06363</identifier>
 <datestamp>2015-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06363</id><created>2015-11-15</created><authors><author><keyname>Ignatov</keyname><forenames>M.</forenames></author><author><keyname>Hansen</keyname><forenames>M.</forenames></author><author><keyname>Ziegler</keyname><forenames>M.</forenames></author><author><keyname>Kohlstedt</keyname><forenames>H.</forenames></author></authors><title>Synchronization of two memristive coupled van der Pol oscillators</title><categories>cs.ET physics.ins-det</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The objective of this paper is to explore the possibility to couple two van
der Pol (vdP) oscillators via a resistance-capacitance (RC) network comprising
a Ag-TiOx-Al memristive device. The coupling was mediated by connecting the
gate terminals of two programmable unijunction transistors (PUTs) through the
network. In the high resistance state (HRS) the memresistance was in the order
of MOhm leading to two independent selfsustained oscillators characterized by
the different frequencies f1 and f2 and no phase relation between the
oscillations. After a few cycles and in dependency of the mediated pulse
amplitude the memristive device switched to the low resistance state (LRS) and
a frequency adaptation and phase locking was observed. The experimental results
are underlined by theoretically considering a system of two coupled vdP
equations. The presented neuromorphic circuitry conveys two essentials
principle of interacting neuronal ensembles: synchronization and memory. The
experiment may path the way to larger neuromorphic networks in which the
coupling parameters can vary in time and strength and are realized by
memristive devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06379</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06379</id><created>2015-11-19</created><authors><author><keyname>Searle</keyname><forenames>Richard</forenames></author><author><keyname>Bingham-Walker</keyname><forenames>Megan</forenames></author></authors><title>Dynamic Adaptive Network Intelligence</title><categories>cs.CL cs.LG</categories><comments>8 pages, 2 figures, 3 tables, ICLR 2016 conference paper submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Accurate representational learning of both the explicit and implicit
relationships within data is critical to the ability of machines to perform
more complex and abstract reasoning tasks. We describe the efficient weakly
supervised learning of such inferences by our Dynamic Adaptive Network
Intelligence (DANI) model. We report state-of-the-art results for DANI over
question answering tasks in the bAbI dataset that have proved difficult for
contemporary approaches to learning representation (Weston et al., 2015).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06380</identifier>
 <datestamp>2016-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06380</id><created>2015-11-19</created><updated>2016-01-20</updated><authors><author><keyname>Lotter</keyname><forenames>William</forenames></author><author><keyname>Kreiman</keyname><forenames>Gabriel</forenames></author><author><keyname>Cox</keyname><forenames>David</forenames></author></authors><title>Unsupervised Learning of Visual Structure using Predictive Generative
  Networks</title><categories>cs.LG cs.AI cs.CV q-bio.NC</categories><comments>under review as conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to predict future states of the environment is a central pillar
of intelligence. At its core, effective prediction requires an internal model
of the world and an understanding of the rules by which the world changes.
Here, we explore the internal models developed by deep neural networks trained
using a loss based on predicting future frames in synthetic video sequences,
using a CNN-LSTM-deCNN framework. We first show that this architecture can
achieve excellent performance in visual sequence prediction tasks, including
state-of-the-art performance in a standard 'bouncing balls' dataset (Sutskever
et al., 2009). Using a weighted mean-squared error and adversarial loss
(Goodfellow et al., 2014), the same architecture successfully extrapolates
out-of-the-plane rotations of computer-generated faces. Furthermore, despite
being trained end-to-end to predict only pixel-level information, our
Predictive Generative Networks learn a representation of the latent structure
of the underlying three-dimensional objects themselves. Importantly, we find
that this representation is naturally tolerant to object transformations, and
generalizes well to new tasks, such as classification of static images. Similar
models trained solely with a reconstruction loss fail to generalize as
effectively. We argue that prediction can serve as a powerful unsupervised loss
for learning rich internal representations of high-level object features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06381</identifier>
 <datestamp>2016-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06381</id><created>2015-11-19</created><updated>2016-01-14</updated><authors><author><keyname>Lee</keyname><forenames>Taehoon</forenames></author><author><keyname>Choi</keyname><forenames>Minsuk</forenames></author><author><keyname>Yoon</keyname><forenames>Sungroh</forenames></author></authors><title>Manifold Regularized Deep Neural Networks using Adversarial Examples</title><categories>cs.LG cs.CV</categories><comments>Figure 2, 5, 7, and several descriptions revised</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning meaningful representations using deep neural networks involves
designing efficient training schemes and well-structured networks. Currently,
the method of stochastic gradient descent that has a momentum with dropout is
one of the most popular training protocols. Based on that, more advanced
methods (i.e., Maxout and Batch Normalization) have been proposed in recent
years, but most still suffer from performance degradation caused by small
perturbations, also known as adversarial examples. To address this issue, we
propose manifold regularized networks (MRnet) that utilize a novel training
objective function that minimizes the difference between multi-layer embedding
results of samples and those adversarial. Our experimental results demonstrated
that MRnet is more resilient to adversarial examples and helps us to generalize
representations on manifolds. Furthermore, combining MRnet and dropout allowed
us to achieve competitive classification performances for three well-known
benchmarks: MNIST, CIFAR-10, and SVHN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06382</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06382</id><created>2015-11-19</created><updated>2016-01-03</updated><authors><author><keyname>Hjelm</keyname><forenames>R Devon</forenames></author><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author><author><keyname>Chung</keyname><forenames>Junyoung</forenames></author><author><keyname>Salakhutdinov</keyname><forenames>Russ</forenames></author><author><keyname>Calhoun</keyname><forenames>Vince</forenames></author><author><keyname>Jojic</keyname><forenames>Nebojsa</forenames></author></authors><title>Iterative Refinement of Approximate Posterior for Training Directed
  Belief Networks</title><categories>cs.LG stat.ML</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep directed graphical models, while a potentially powerful class of
generative representations, are challenging to train due to difficult
inference. Recent advances in variational inference that make use of an
inference or recognition network have advanced well beyond traditional
variational inference and Markov chain Monte Carlo methods. While these
techniques offer higher flexibility as well as simpler and faster inference,
they are still limited by approximate posterior inference and require variance
reduction techniques. Less focus has been given to improving or refining the
approximate posterior beyond what is provided by variational inference. We show
that iterative refinement of an approximate posterior can provide notable gains
in maximizing the lower bound of the log likelihood, either by using adaptive
importance sampling or by applying gradient descent as inference during the
E-step of a variational expectation-maximization algorithm. We show our
approach achieves state of the art for training directed belief networks with
binary latent variables, and provides a unique means of refining the posterior
for directed belief networks with Gaussian latent variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06384</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06384</id><created>2015-02-10</created><authors><author><keyname>Dubey</keyname><forenames>Pradeep</forenames></author></authors><title>Decentralization of a Machine: Some Definitions</title><categories>cs.CC</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define some notions of the decentralization of a deterministic
input-output machine. This opens the possibility for introducing game-theoretic
elements -- such as strategic players -- inside the machine, as part of its
design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06385</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06385</id><created>2015-11-19</created><authors><author><keyname>Lyu</keyname><forenames>Chunchuan</forenames></author><author><keyname>Huang</keyname><forenames>Kaizhu</forenames></author><author><keyname>Liang</keyname><forenames>Hai-Ning</forenames></author></authors><title>A Unified Gradient Regularization Family for Adversarial Examples</title><categories>cs.LG stat.ML</categories><comments>The paper has been presented at ICDM 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Adversarial examples are augmented data points generated by imperceptible
perturbation of input samples. They have recently drawn much attention with the
machine learning and data mining community. Being difficult to distinguish from
real examples, such adversarial examples could change the prediction of many of
the best learning models including the state-of-the-art deep learning models.
Recent attempts have been made to build robust models that take into account
adversarial examples. However, these methods can either lead to performance
drops or lack mathematical motivations. In this paper, we propose a unified
framework to build robust machine learning models against adversarial examples.
More specifically, using the unified framework, we develop a family of gradient
regularization methods that effectively penalize the gradient of loss function
w.r.t. inputs. Our proposed framework is appealing in that it offers a unified
view to deal with adversarial examples. It incorporates another
recently-proposed perturbation based approach as a special case. In addition,
we present some visual effects that reveals semantic meaning in those
perturbations, and thus support our regularization method and provide another
explanation for generalizability of adversarial examples. By applying this
technique to Maxout networks, we conduct a series of experiments and achieve
encouraging results on two benchmark datasets. In particular,we attain the best
accuracy on MNIST data (without data augmentation) and competitive performance
on CIFAR-10 data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06388</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06388</id><created>2015-11-19</created><authors><author><keyname>Trask</keyname><forenames>Andrew</forenames></author><author><keyname>Michalak</keyname><forenames>Phil</forenames></author><author><keyname>Liu</keyname><forenames>John</forenames></author></authors><title>sense2vec - A Fast and Accurate Method for Word Sense Disambiguation In
  Neural Word Embeddings</title><categories>cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural word representations have proven useful in Natural Language Processing
(NLP) tasks due to their ability to efficiently model complex semantic and
syntactic word relationships. However, most techniques model only one
representation per word, despite the fact that a single word can have multiple
meanings or &quot;senses&quot;. Some techniques model words by using multiple vectors
that are clustered based on context. However, recent neural approaches rarely
focus on the application to a consuming NLP algorithm. Furthermore, the
training process of recent word-sense models is expensive relative to
single-sense embedding processes. This paper presents a novel approach which
addresses these concerns by modeling multiple embeddings for each word based on
supervised disambiguation, which provides a fast and accurate way for a
consuming NLP model to select a sense-disambiguated embedding. We demonstrate
that these embeddings can disambiguate both contrastive senses such as nominal
and verbal senses as well as nuanced senses such as sarcasm. We further
evaluate Part-of-Speech disambiguated embeddings on neural dependency parsing,
yielding a greater than 8% average error reduction in unlabeled attachment
scores across 6 languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06390</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06390</id><created>2015-11-19</created><authors><author><keyname>Springenberg</keyname><forenames>Jost Tobias</forenames></author></authors><title>Unsupervised and Semi-supervised Learning with Categorical Generative
  Adversarial Networks</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a method for learning a discriminative classifier
from unlabeled or partially labeled data. Our approach is based on an objective
function that trades-off mutual information between observed examples and their
predicted categorical class distribution, against robustness of the classifier
to an adversarial generative model. The resulting algorithm can either be
interpreted as a natural generalization of the generative adversarial networks
(GAN) framework or as an extension of the regularized information maximization
(RIM) framework to robust classification against an optimal adversary. We
empirically evaluate our method - which we dub categorical generative
adversarial networks (or CatGAN) - on synthetic data as well as on challenging
image classification tasks, demonstrating the robustness of the learned
classifiers. We further qualitatively assess the fidelity of samples generated
by the adversarial generator that is learned alongside the discriminative
classifier, and identify links between the CatGAN objective and discriminative
clustering algorithms (such as RIM).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06391</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06391</id><created>2015-11-19</created><updated>2016-02-23</updated><authors><author><keyname>Vinyals</keyname><forenames>Oriol</forenames></author><author><keyname>Bengio</keyname><forenames>Samy</forenames></author><author><keyname>Kudlur</keyname><forenames>Manjunath</forenames></author></authors><title>Order Matters: Sequence to sequence for sets</title><categories>stat.ML cs.CL cs.LG</categories><comments>Accepted as a conference paper at ICLR 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequences have become first class citizens in supervised learning thanks to
the resurgence of recurrent neural networks. Many complex tasks that require
mapping from or to a sequence of observations can now be formulated with the
sequence-to-sequence (seq2seq) framework which employs the chain rule to
efficiently represent the joint probability of sequences. In many cases,
however, variable sized inputs and/or outputs might not be naturally expressed
as sequences. For instance, it is not clear how to input a set of numbers into
a model where the task is to sort them; similarly, we do not know how to
organize outputs when they correspond to random variables and the task is to
model their unknown joint probability. In this paper, we first show using
various examples that the order in which we organize input and/or output data
matters significantly when learning an underlying model. We then discuss an
extension of the seq2seq framework that goes beyond sequences and handles input
sets in a principled way. In addition, we propose a loss which, by searching
over possible orders during training, deals with the lack of structure of
output sets. We show empirical evidence of our claims regarding ordering, and
on the modifications to the seq2seq framework on benchmark language modeling
and parsing tasks, as well as two artificial tasks -- sorting numbers and
estimating the joint probability of unknown graphical models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06392</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06392</id><created>2015-11-19</created><updated>2016-02-09</updated><authors><author><keyname>Kurach</keyname><forenames>Karol</forenames></author><author><keyname>Andrychowicz</keyname><forenames>Marcin</forenames></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author></authors><title>Neural Random-Access Machines</title><categories>cs.LG cs.NE</categories><comments>ICLR submission, 17 pages, 9 figures, 6 tables (with bibliography and
  appendix)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose and investigate a new neural network architecture
called Neural Random Access Machine. It can manipulate and dereference pointers
to an external variable-size random-access memory. The model is trained from
pure input-output examples using backpropagation.
  We evaluate the new model on a number of simple algorithmic tasks whose
solutions require pointer manipulation and dereferencing. Our results show that
the proposed model can learn to solve algorithmic tasks of such type and is
capable of operating on simple data structures like linked-lists and binary
trees. For easier tasks, the learned solutions generalize to sequences of
arbitrary length. Moreover, memory access during inference can be done in a
constant time under some assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06393</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06393</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Lin</keyname><forenames>Darryl D.</forenames></author><author><keyname>Talathi</keyname><forenames>Sachin S.</forenames></author><author><keyname>Annapureddy</keyname><forenames>V. Sreekanth</forenames></author></authors><title>Fixed Point Quantization of Deep Convolutional Networks</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years increasingly complex architectures for deep convolution
networks (DCNs) have been proposed to boost the performance on image
recognition tasks. However, the gains in performance have come at a cost of
substantial increase in compute resources, the model size and processing speed
of the network for training and evaluation. Fixed point implementation of these
networks has the potential to alleviate some of the burden of these additional
complexities. In this paper, we propose a quantizer design for fixed point
implementation for DCNs. We then formulate an optimization problem to identify
optimal fixed point bit-width allocation across DCN layers. We perform
experiments on a recently proposed DCN architecture for CIFAR-10 benchmark that
generates test error of less than 7%. We evaluate the effectiveness of our
proposed fixed point bit-width allocation for this DCN. Our experiments show
that in comparison to equal bit-width settings, the fixed point DCNs with
optimized bit width allocation offer &gt;20% reduction in the model size without
any loss in performance. We also demonstrate that fine tuning can further
enhance the accuracy of fixed point DCNs beyond that of the original floating
point model. In doing so, we report a new state-of-the-art fixed point
performance of 6.78% error-rate on CIFAR-10 benchmark.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06394</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06394</id><created>2015-11-19</created><updated>2016-02-22</updated><authors><author><keyname>H&#xe9;naff</keyname><forenames>Olivier J.</forenames></author><author><keyname>Simoncelli</keyname><forenames>Eero P.</forenames></author></authors><title>Geodesics of learned representations</title><categories>cs.CV cs.LG</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new method for visualizing and refining the invariances of
learned representations. Specifically, we test for a general form of
invariance, linearization, in which the action of a transformation is confined
to a low-dimensional subspace. Given two reference images (typically, differing
by some transformation), we synthesize a sequence of images lying on a path
between them that is of minimal length in the space of the representation (a
&quot;representational geodesic&quot;). If the transformation relating the two reference
images is linearized by the representation, this sequence should follow the
gradual evolution of this transformation. We use this method to assess the
invariance properties of a state-of-the-art image classification network and
find that geodesics generated for image pairs differing by translation,
rotation, and dilation do not evolve according to their associated
transformations. Our method also suggests a remedy for these failures, and
following this prescription, we show that the modified representation is able
to linearize a variety of geometric image transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06396</identifier>
 <datestamp>2016-03-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06396</id><created>2015-11-19</created><updated>2016-03-03</updated><authors><author><keyname>Verga</keyname><forenames>Patrick</forenames></author><author><keyname>Belanger</keyname><forenames>David</forenames></author><author><keyname>Strubell</keyname><forenames>Emma</forenames></author><author><keyname>Roth</keyname><forenames>Benjamin</forenames></author><author><keyname>McCallum</keyname><forenames>Andrew</forenames></author></authors><title>Multilingual Relation Extraction using Compositional Universal Schema</title><categories>cs.CL cs.LG</categories><comments>Accepted to NAACL 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Universal schema builds a knowledge base (KB) of entities and relations by
jointly embedding all relation types from input KBs as well as textual patterns
expressing relations from raw text. In most previous applications of universal
schema, each textual pattern is represented as a single embedding, preventing
generalization to unseen patterns. Recent work employs a neural network to
capture patterns' compositional semantics, providing generalization to all
possible input text. In response, this paper introduces significant further
improvements to the coverage and flexibility of universal schema relation
extraction: predictions for entities unseen in training and multilingual
transfer learning to domains with no annotation. We evaluate our model through
extensive experiments on the English and Spanish TAC KBP benchmark,
outperforming the top system from TAC 2013 slot-filling using no handwritten
patterns or additional annotation. We also consider a multilingual setting in
which English training data entities overlap with the seed KB, but Spanish text
does not. Despite having no annotation for Spanish data, we train an accurate
predictor, with additional improvements obtained by tying word embeddings
across languages. Furthermore, we find that multilingual training improves
English relation extraction accuracy. Our approach is thus suited to
broad-coverage automated knowledge base construction in a variety of languages
and domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06397</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06397</id><created>2015-11-19</created><authors><author><keyname>Andrews</keyname><forenames>Martin</forenames></author></authors><title>Compressing Word Embeddings</title><categories>cs.CL cs.LG</categories><comments>10 pages, 6 figures, ICLR-2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent methods for learning vector space representations of words have
succeeded in capturing fine-grained semantic and syntactic regularities using
vector arithmetic. However, these vector space representations (created through
large-scale text analysis) are typically stored verbatim, since their internal
structure is opaque. Using word-analogy tests to monitor the level of detail
stored in compressed re-representations of the same vector space, the
trade-offs between the reduction in memory usage and expressiveness are
investigated. A simple scheme is outlined that can reduce the memory footprint
of a state-of-the-art embedding by a factor of 10, with only minimal impact on
performance. Then, using the same 'bit budget', a binary (approximate)
factorisation of the same space is also explored, with the aim of creating an
equivalent representation with better interpretability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06406</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06406</id><created>2015-11-19</created><updated>2016-01-04</updated><authors><author><keyname>Im</keyname><forenames>Daniel Jiwoong</forenames></author><author><keyname>Ahn</keyname><forenames>Sungjin</forenames></author><author><keyname>Memisevic</keyname><forenames>Roland</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Denoising Criterion for Variational Auto-Encoding Framework</title><categories>cs.LG</categories><comments>ICLR conference submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Denoising autoencoders (DAE) are trained to reconstruct their clean inputs
with noise injected at the input level, while variational autoencoders (VAE)
are trained with noise injected in their stochastic hidden layer, with a
regularizer that encourages this noise injection. In this paper, we show that
injecting noise both in input and in the stochastic hidden layer can be
advantageous and we propose a modified variational lower bound as an improved
objective function in this setup. When input is corrupted, then the standard
VAE lower bound involves marginalizing the encoder conditional distribution
over the input noise, which makes the training criterion intractable. Instead,
we propose a modified training criterion which corresponds to a tractable bound
when input is corrupted. Experimentally, we find that the proposed denoising
variational autoencoder (DVAE) yields better average log-likelihood than the
VAE and the importance weighted autoencoder on the MNIST and Frey Face
datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06407</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06407</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Kim</keyname><forenames>Suyoun</forenames></author><author><keyname>Lane</keyname><forenames>Ian</forenames></author></authors><title>Recurrent Models for Auditory Attention in Multi-Microphone Distance
  Speech Recognition</title><categories>cs.LG cs.CL</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integration of multiple microphone data is one of the key ways to achieve
robust speech recognition in noisy environments or when the speaker is located
at some distance from the input device. Signal processing techniques such as
beamforming are widely used to extract a speech signal of interest from
background noise. These techniques, however, are highly dependent on prior
spatial information about the microphones and the environment in which the
system is being used. In this work, we present a neural attention network that
directly combines multi-channel audio to generate phonetic states without
requiring any prior knowledge of the microphone layout or any explicit signal
preprocessing for speech enhancement. We embed an attention mechanism within a
Recurrent Neural Network (RNN) based acoustic model to automatically tune its
attention to a more reliable input source. Unlike traditional multi-channel
preprocessing, our system can be optimized towards the desired output in one
step. Although attention-based models have recently achieved impressive results
on sequence-to-sequence learning, no attention mechanisms have previously been
applied to learn potentially asynchronous and non-stationary multiple inputs.
We evaluate our neural attention model on the CHiME-3 challenge task, and show
that the model achieves comparable performance to beamforming using a purely
data-driven method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06408</identifier>
 <datestamp>2015-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06408</id><created>2015-11-19</created><updated>2015-12-09</updated><authors><author><keyname>Lindsay</keyname><forenames>Grace W.</forenames></author></authors><title>Feature-based Attention in Convolutional Neural Networks</title><categories>cs.CV</categories><comments>9 pages (plus 3 page Appendix), 7 figures total, submitted to ICLR
  2016</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Convolutional neural networks (CNNs) have proven effective for image
processing tasks, such as object recognition and classification. Recently, CNNs
have been enhanced with concepts of attention, similar to those found in
biology. Much of this work on attention has focused on effective serial spatial
processing. In this paper, I introduce a simple procedure for applying
feature-based attention (FBA) to CNNs and compare multiple implementation
options. FBA is a top-down signal applied globally to an input image which
aides in detecting chosen objects in cluttered or noisy settings. The concept
of FBA and the implementation details tested here were derived from what is
known (and debated) about biological object- and feature-based attention. The
implementations of FBA described here increase performance on challenging
object detection tasks using a procedure that is simple, fast, and does not
require additional iterative training. Furthermore, the comparisons performed
here suggest that a proposed model of biological FBA (the &quot;feature similarity
gain model&quot;) is effective in increasing performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06409</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06409</id><created>2015-11-19</created><authors><author><keyname>Ridgeway</keyname><forenames>Karl</forenames></author><author><keyname>Snell</keyname><forenames>Jake</forenames></author><author><keyname>Roads</keyname><forenames>Brett</forenames></author><author><keyname>Zemel</keyname><forenames>Richard</forenames></author><author><keyname>Mozer</keyname><forenames>Michael</forenames></author></authors><title>Learning to generate images with perceptual similarity metrics</title><categories>cs.LG cs.CV</categories><comments>Submitted to ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep networks are increasingly being applied to problems involving image
synthesis, e.g., generating images from textual descriptions, or generating
reconstructions of an input image in an autoencoder architecture. Supervised
training of image-synthesis networks typically uses a pixel-wise squared error
(SE) loss to indicate the mismatch between a generated image and its
corresponding target image. We propose to instead use a loss function that is
better calibrated to human perceptual judgments of image quality: the
structural-similarity (SSIM) score of Wang, Bovik, Sheikh, and Simoncelli
(2004). Because the SSIM score is differentiable, it is easily incorporated
into gradient-descent learning. We compare the consequences of using SSIM
versus SE loss on representations formed in deep autoencoder and recurrent
neural network architectures. SSIM-optimized representations yield a superior
basis for image classification compared to SE-optimized representations.
Further, human observers prefer images generated by the SSIM-optimized networks
by nearly a 7:1 ratio. Just as computer vision has advanced through the use of
convolutional architectures that mimic the structure of the mammalian visual
system, we argue that significant additional advances can be made in modeling
images through the use of training objectives that are well aligned to
characteristics of human perception.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06410</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06410</id><created>2015-11-19</created><updated>2016-02-29</updated><authors><author><keyname>Tian</keyname><forenames>Yuandong</forenames></author><author><keyname>Zhu</keyname><forenames>Yan</forenames></author></authors><title>Better Computer Go Player with Neural Network and Long-term Prediction</title><categories>cs.LG cs.AI</categories><comments>10 pages, 9 without references. Submission for ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Competing with top human players in the ancient game of Go has been a
long-term goal of artificial intelligence. Go's high branching factor makes
traditional search techniques ineffective, even on leading-edge hardware, and
Go's evaluation function could change drastically with one stone change. Recent
works [Maddison et al. (2015); Clark &amp; Storkey (2015)] show that search is not
strictly necessary for machine Go players. A pure pattern-matching approach,
based on a Deep Convolutional Neural Network (DCNN) that predicts the next
move, can perform as well as Monte Carlo Tree Search (MCTS)-based open source
Go engines such as Pachi [Baudis &amp; Gailly (2012)] if its search budget is
limited. We extend this idea in our bot named darkforest, which relies on a
DCNN designed for long-term predictions. Darkforest substantially improves the
win rate for pattern-matching approaches against MCTS-based approaches, even
with looser search budgets. Against human players, the newest versions,
darkfores2, achieve a stable 3d level on KGS Go Server as a ranked bot, a
substantial improvement upon the estimated 4k-5k ranks for DCNN reported in
Clark &amp; Storkey (2015) based on games against other machine players. Adding
MCTS to darkfores2 creates a much stronger player named darkfmcts3: with 5000
rollouts, it beats Pachi with 10k rollouts in all 250 games; with 75k rollouts
it achieves a stable 5d level in KGS server, on par with state-of-the-art Go
AIs (e.g., Zen, DolBaram, CrazyStone) except for AlphaGo [Silver et al.
(2016)]; with 110k rollouts, it won the 3rd place in January KGS Go Tournament.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06411</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06411</id><created>2015-11-19</created><authors><author><keyname>Song</keyname><forenames>Yang</forenames></author><author><keyname>Schwing</keyname><forenames>Alexander G.</forenames></author><author><keyname>Zemel</keyname><forenames>Richard S.</forenames></author><author><keyname>Urtasun</keyname><forenames>Raquel</forenames></author></authors><title>Direct Loss Minimization for Training Deep Neural Nets</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised training of deep neural nets typically relies on minimizing
cross-entropy. However, in many domains, we are interested in performing well
on specific application-specific metrics. In this paper we proposed a direct
loss minimization approach to train deep neural networks, taking into account
the application-specific loss functions. This can be non-trivial, when these
functions are non-smooth and non-decomposable. We demonstrate the effectiveness
of our approach in the context of maximizing average precision for ranking
problems. Towards this goal, we propose a dynamic programming algorithm that
can efficiently compute the weight updates. Our approach proves superior to a
variety of baselines in the context of action classification and object
detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06412</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06412</id><created>2015-11-19</created><updated>2015-11-26</updated><authors><author><keyname>Ducoffe</keyname><forenames>Melanie</forenames></author><author><keyname>Precioso</keyname><forenames>Frederic</forenames></author></authors><title>QBDC: Query by dropout committee for training deep supervised
  architecture</title><categories>cs.LG cs.CV</categories><comments>Submitted to ICLR2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the current trend is to increase the depth of neural networks to
increase their performance, the size of their training database has to grow
accordingly. We notice an emergence of tremendous databases, although providing
labels to build a training set still remains a very expensive task. We tackle
the problem of selecting the samples to be labelled in an online fashion. In
this paper, we present an active learning strategy based on query by committee
and dropout technique to train a Convolutional Neural Network (CNN). We derive
a commmittee of partial CNNs resulting from batchwise dropout runs on the
initial CNN. We evaluate our active learning strategy for CNN on MNIST
benchmark, showing in particular that selecting less than 30 % from the
annotated database is enough to get similar error rate as using the full
training set on MNIST. We also studied the robustness of our method against
adversarial examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06416</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06416</id><created>2015-11-19</created><authors><author><keyname>Seita</keyname><forenames>Daniel</forenames></author><author><keyname>Chen</keyname><forenames>Haoyu</forenames></author><author><keyname>Canny</keyname><forenames>John</forenames></author></authors><title>Fast Parallel SAME Gibbs Sampling on General Discrete Bayesian Networks</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fundamental task in machine learning and related fields is to perform
inference on Bayesian networks. Since exact inference takes exponential time in
general, a variety of approximate methods are used. Gibbs sampling is one of
the most accurate approaches and provides unbiased samples from the posterior
but it has historically been too expensive for large models. In this paper, we
present an optimized, parallel Gibbs sampler augmented with state replication
(SAME or State Augmented Marginal Estimation) to decrease convergence time. We
find that SAME can improve the quality of parameter estimates while
accelerating convergence. Experiments on both synthetic and real data show that
our Gibbs sampler is substantially faster than the state of the art sampler,
JAGS, without sacrificing accuracy. Our ultimate objective is to introduce the
Gibbs sampler to researchers in many fields to expand their range of feasible
inference problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06418</identifier>
 <datestamp>2016-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06418</id><created>2015-11-19</created><updated>2016-01-20</updated><authors><author><keyname>Greff</keyname><forenames>Klaus</forenames></author><author><keyname>Srivastava</keyname><forenames>Rupesh Kumar</forenames></author><author><keyname>Schmidhuber</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>Binding via Reconstruction Clustering</title><categories>cs.LG cs.NE</categories><comments>12 pages, plus 12 pages Appendix</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Disentangled distributed representations of data are desirable for machine
learning, since they are more expressive and can generalize from fewer
examples. However, for complex data, the distributed representations of
multiple objects present in the same input can interfere and lead to
ambiguities, which is commonly referred to as the binding problem. We argue for
the importance of the binding problem to the field of representation learning,
and develop a probabilistic framework that explicitly models inputs as a
composition of multiple objects. We propose an unsupervised algorithm that uses
denoising autoencoders to dynamically bind features together in multi-object
inputs through an Expectation-Maximization-like clustering process. The
effectiveness of this method is demonstrated on artificially generated datasets
of binary images, showing that it can even generalize to bind together new
objects never seen by the autoencoder during training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06419</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06419</id><created>2015-11-19</created><authors><author><keyname>De-Arteaga</keyname><forenames>Maria</forenames></author><author><keyname>Dubrawski</keyname><forenames>Artur</forenames></author><author><keyname>Huggins</keyname><forenames>Peter</forenames></author></authors><title>Canonical Autocorrelation Analysis</title><categories>stat.ML cs.LG</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an extension of sparse Canonical Correlation Analysis (CCA)
designed for finding multiple-to-multiple linear correlations within a single
set of variables. Unlike CCA, which finds correlations between two sets of data
where the rows are matched exactly but the columns represent separate sets of
variables, the method proposed here, Canonical Autocorrelation Analysis (CAA),
finds multivariate correlations within just one set of variables. This can be
useful when we look for hidden parsimonious structures in data, each involving
only a small subset of all features. In addition, the discovered correlations
are highly interpretable as they are formed by pairs of sparse linear
combinations of the original features. We show how CAA can be of use as a tool
for anomaly detection when the expected structure of correlations is not
followed by anomalous data. We illustrate the utility of CAA in two application
domains where single-class and unsupervised learning of correlation structures
are particularly relevant: breast cancer diagnosis and radiation threat
detection. When applied to the Wisconsin Breast Cancer data, single-class CAA
is competitive with supervised methods used in literature. On the radiation
threat detection task, unsupervised CAA performs significantly better than an
unsupervised alternative prevalent in the domain, while providing valuable
additional insights for threat analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06420</identifier>
 <datestamp>2015-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06420</id><created>2015-11-19</created><updated>2015-11-23</updated><authors><author><keyname>Caballero</keyname><forenames>Ethan</forenames></author></authors><title>Skip-Thought Memory Networks</title><categories>cs.NE cs.CL cs.LG</categories><comments>Removed by arXiv administrators because submission violated the terms
  of arXiv's license agreement</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Question Answering (QA) is fundamental to natural language processing in that
most nlp problems can be phrased as QA (Kumar et al., 2015). Current weakly
supervised memory network models that have been proposed so far struggle at
answering questions that involve relations among multiple entities (such as
facebook's bAbi qa5-three-arg-relations in (Weston et al., 2015)). To address
this problem of learning multi-argument multi-hop semantic relations for the
purpose of QA, we propose a method that combines the jointly learned long-term
read-write memory and attentive inference components of end-to-end memory
networks (MemN2N) (Sukhbaatar et al., 2015) with distributed sentence vector
representations encoded by a Skip-Thought model (Kiros et al., 2015). This
choice to append Skip-Thought Vectors to the existing MemN2N framework is
motivated by the fact that Skip-Thought Vectors have been shown to accurately
model multi-argument semantic relations (Kiros et al., 2015).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06421</identifier>
 <datestamp>2016-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06421</id><created>2015-11-19</created><updated>2016-01-11</updated><authors><author><keyname>Gardner</keyname><forenames>Jacob R.</forenames></author><author><keyname>Kusner</keyname><forenames>Matt J.</forenames></author><author><keyname>Li</keyname><forenames>Yixuan</forenames></author><author><keyname>Upchurch</keyname><forenames>Paul</forenames></author><author><keyname>Weinberger</keyname><forenames>Kilian Q.</forenames></author><author><keyname>Hopcroft</keyname><forenames>John E.</forenames></author></authors><title>Deep Manifold Traversal: Changing Labels with Convolutional Features</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Machine learning is increasingly used in high impact applications such as
prediction of hospital re-admission, cancer screening or bio-medical research
applications. As predictions become increasingly accurate, practitioners may be
interested in identifying actionable changes to inputs in order to alter their
class membership. For example, a doctor might want to know what changes to a
patient's status would predict him/her to not be re-admitted to the hospital
soon. Szegedy et al. (2013b) demonstrated that identifying such changes can be
very hard in image classification tasks. In fact, tiny, imperceptible changes
can result in completely different predictions without any change to the true
class label of the input. In this paper we ask the question if we can make
small but meaningful changes in order to truly alter the class membership of
images from a source class to a target class. To this end we propose deep
manifold traversal, a method that learns the manifold of natural images and
provides an effective mechanism to move images from one area (dominated by the
source class) to another (dominated by the target class).The resulting
algorithm is surprisingly effective and versatile. It allows unrestricted
movements along the image manifold and only requires few images from source and
target to identify meaningful changes. We demonstrate that the exact same
procedure can be used to change an individual's appearance of age, facial
expressions or even recolor black and white images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06422</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06422</id><created>2015-11-19</created><updated>2016-02-19</updated><authors><author><keyname>Mishkin</keyname><forenames>Dmytro</forenames></author><author><keyname>Matas</keyname><forenames>Jiri</forenames></author></authors><title>All you need is a good init</title><categories>cs.LG</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Layer-sequential unit-variance (LSUV) initialization - a simple method for
weight initialization for deep net learning - is proposed. The method consists
of the two steps. First, pre-initialize weights of each convolution or
inner-product layer with orthonormal matrices. Second, proceed from the first
to the final layer, normalizing the variance of the output of each layer to be
equal to one.
  Experiment with different activation functions (maxout, ReLU-family, tanh)
show that the proposed initialization leads to learning of very deep nets that
(i) produces networks with test accuracy better or equal to standard methods
and (ii) is at least as fast as the complex schemes proposed specifically for
very deep nets such as FitNets (Romero et al. (2015)) and Highway (Srivastava
et al. (2015)).
  Performance is evaluated on GoogLeNet, CaffeNet, FitNets and Residual nets
and the state-of-the-art, or very close to it, is achieved on the MNIST,
CIFAR-10/100 and ImageNet datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06423</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06423</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Lin</keyname><forenames>Ziyuan</forenames></author><author><keyname>Peltonen</keyname><forenames>Jaakko</forenames></author></authors><title>An Information Retrieval Approach to Finding Dependent Subspaces of
  Multiple Views</title><categories>stat.ML cs.LG</categories><comments>9 pages, 15 figures. Submitted for ICLR 2016; the authors contributed
  equally</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finding relationships between multiple views of data is essential both for
exploratory analysis and as pre-processing for predictive tasks. A prominent
approach is to apply variants of Canonical Correlation Analysis (CCA), a
classical method seeking correlated components between views. The basic CCA is
restricted to maximizing a simple dependency criterion, correlation, measured
directly between data coordinates. We introduce a new method that finds
dependent subspaces of views directly optimized for the data analysis task of
\textit{neighbor retrieval between multiple views}. We optimize mappings for
each view such as linear transformations to maximize cross-view similarity
between neighborhoods of data samples. The criterion arises directly from the
well-defined retrieval task, detects nonlinear and local similarities, is able
to measure dependency of data relationships rather than only individual data
coordinates, and is related to well understood measures of information
retrieval quality. In experiments we show the proposed method outperforms
alternatives in preserving cross-view neighborhood similarities, and yields
insights into local dependencies between multiple views.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06425</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06425</id><created>2015-11-19</created><updated>2015-11-25</updated><authors><author><keyname>Gan</keyname><forenames>Quan</forenames></author><author><keyname>Guo</keyname><forenames>Qipeng</forenames></author><author><keyname>Zhang</keyname><forenames>Zheng</forenames></author><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author></authors><title>First Step toward Model-Free, Anonymous Object Tracking with Recurrent
  Neural Networks</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose and study a novel visual object tracking approach
based on convolutional networks and recurrent networks. The proposed approach
is distinct from the existing approaches to visual object tracking, such as
filtering-based ones and tracking-by-detection ones, in the sense that the
tracking system is explicitly trained off-line to track anonymous objects in a
noisy environment. The proposed visual tracking model is end-to-end trainable,
minimizing any adversarial effect from mismatches in object representation and
between the true underlying dynamics and learning dynamics. We empirically show
that the proposed tracking approach works well in various scenarios by
generating artificial video sequences with varying conditions; the number of
objects, amount of noise and the match between the training shapes and test
shapes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06426</identifier>
 <datestamp>2016-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06426</id><created>2015-11-19</created><updated>2016-02-26</updated><authors><author><keyname>Lee</keyname><forenames>Moontae</forenames></author><author><keyname>He</keyname><forenames>Xiaodong</forenames></author><author><keyname>Yih</keyname><forenames>Wen-tau</forenames></author><author><keyname>Gao</keyname><forenames>Jianfeng</forenames></author><author><keyname>Deng</keyname><forenames>Li</forenames></author><author><keyname>Smolensky</keyname><forenames>Paul</forenames></author></authors><title>Reasoning in Vector Space: An Exploratory Study of Question Answering</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Question answering tasks have shown remarkable progress with distributed
vector representation. In this paper, we investigate the recently proposed
Facebook bAbI tasks which consist of twenty different categories of questions
that require complex reasoning. Because the previous work on bAbI are all
end-to-end models, errors could come from either an imperfect understanding of
semantics or in certain steps of the reasoning. For clearer analysis, we
propose two vector space models inspired by Tensor Product Representation (TPR)
to perform knowledge encoding and logical reasoning based on common-sense
inference. They together achieve near-perfect accuracy on all categories
including positional reasoning and path finding that have proved difficult for
most of the previous approaches. We hypothesize that the difficulties in these
categories are due to the multi-relations in contrast to uni-relational
characteristic of other categories. Our exploration sheds light on designing
more sophisticated dataset and moving one step toward integrating transparent
and interpretable formalism of TPR into existing learning paradigms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06428</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06428</id><created>2015-11-19</created><updated>2016-02-09</updated><authors><author><keyname>Moczulski</keyname><forenames>Marcin</forenames></author><author><keyname>Xu</keyname><forenames>Kelvin</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author></authors><title>A Controller-Recognizer Framework: How necessary is recognition for
  control?</title><categories>cs.LG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently there has been growing interest in building active visual object
recognizers, as opposed to the usual passive recognizers which classifies a
given static image into a predefined set of object categories. In this paper we
propose to generalize these recently proposed end-to-end active visual
recognizers into a controller-recognizer framework. A model in the
controller-recognizer framework consists of a controller, which interfaces with
an external manipulator, and a recognizer which classifies the visual input
adjusted by the manipulator. We describe two most recently proposed
controller-recognizer models: recurrent attention model and spatial transformer
network as representative examples of controller-recognizer models. Based on
this description we observe that most existing end-to-end
controller-recognizers tightly, or completely, couple a controller and
recognizer. We ask a question whether this tight coupling is necessary, and try
to answer this empirically by building a controller-recognizer model with a
decoupled controller and recognizer. Our experiments revealed that it is not
always necessary to tightly couple them and that by decoupling a controller and
recognizer, there is a possibility of building a generic controller that is
pretrained and works together with any subsequent recognizer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06429</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06429</id><created>2015-11-19</created><updated>2016-02-10</updated><authors><author><keyname>Jonschkowski</keyname><forenames>Rico</forenames></author><author><keyname>H&#xf6;fer</keyname><forenames>Sebastian</forenames></author><author><keyname>Brock</keyname><forenames>Oliver</forenames></author></authors><title>Patterns for Learning with Side Information</title><categories>cs.LG stat.ML</categories><comments>The first two authors contributed equally to this work</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Supervised, semi-supervised, and unsupervised learning estimate a function
given input/output samples. Generalization of the learned function to unseen
data can be improved by incorporating side information into learning. Side
information are data that are neither from the input space nor from the output
space of the function, but include useful information for learning it. In this
paper we show that learning with side information subsumes a variety of related
approaches, e.g. multi-task learning, multi-view learning and learning using
privileged information. Our main contributions are (i) a new perspective that
connects these previously isolated approaches, (ii) insights about how these
methods incorporate different types of prior knowledge, and hence implement
different patterns, (iii) facilitating the application of these methods in
novel tasks, as well as (iv) a systematic experimental evaluation of these
patterns in two supervised learning tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06430</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06430</id><created>2015-11-19</created><updated>2016-01-05</updated><authors><author><keyname>Pezeshki</keyname><forenames>Mohammad</forenames></author><author><keyname>Fan</keyname><forenames>Linxi</forenames></author><author><keyname>Brakel</keyname><forenames>Philemon</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Deconstructing the Ladder Network Architecture</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Manual labeling of data is and will remain a costly endeavor. For this
reason, semi-supervised learning remains a topic of practical importance. The
recently proposed Ladder Network is one such approach that has proven to be
very successful. In addition to the supervised objective, the Ladder Network
also adds an unsupervised objective corresponding to the reconstruction costs
of a stack of denoising autoencoders. Although the empirical results are
impressive, the Ladder Network has many components intertwined, whose
contributions are not obvious in such a complex architecture. In order to help
elucidate and disentangle the different ingredients in the Ladder Network
recipe, this paper presents an extensive experimental investigation of variants
of the Ladder Network in which we replace or remove individual components to
gain more insight into their relative importance. We find that all of the
components are necessary for achieving optimal performance, but they do not
contribute equally. For semi-supervised tasks, we conclude that the most
important contribution is made by the lateral connection, followed by the
application of noise, and finally the choice of what we refer to as the
`combinator function' in the decoder path. We also find that as the number of
labeled training examples increases, the lateral connections and reconstruction
criterion become less important, with most of the improvement in generalization
being due to the injection of noise in each layer. Furthermore, we present a
new type of combinator function that outperforms the original design in both
fully- and semi-supervised tasks, reducing record test error rates on
Permutation-Invariant MNIST to 0.57% for the supervised setting, and to 0.97%
and 1.0% for semi-supervised settings with 1000 and 100 labeled examples
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06432</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06432</id><created>2015-11-19</created><updated>2016-03-01</updated><authors><author><keyname>Ballas</keyname><forenames>Nicolas</forenames></author><author><keyname>Yao</keyname><forenames>Li</forenames></author><author><keyname>Pal</keyname><forenames>Chris</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author></authors><title>Delving Deeper into Convolutional Networks for Learning Video
  Representations</title><categories>cs.CV cs.LG cs.NE</categories><comments>ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an approach to learn spatio-temporal features in videos from
intermediate visual representations we call &quot;percepts&quot; using
Gated-Recurrent-Unit Recurrent Networks (GRUs).Our method relies on percepts
that are extracted from all level of a deep convolutional network trained on
the large ImageNet dataset. While high-level percepts contain highly
discriminative information, they tend to have a low-spatial resolution.
Low-level percepts, on the other hand, preserve a higher spatial resolution
from which we can model finer motion patterns. Using low-level percepts can
leads to high-dimensionality video representations. To mitigate this effect and
control the model number of parameters, we introduce a variant of the GRU model
that leverages the convolution operations to enforce sparse connectivity of the
model units and share parameters across the input spatial locations.
  We empirically validate our approach on both Human Action Recognition and
Video Captioning tasks. In particular, we achieve results equivalent to
state-of-art on the YouTube2Text dataset using a simpler text-decoder model and
without extra 3D CNN features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06433</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06433</id><created>2015-11-19</created><updated>2016-03-04</updated><authors><author><keyname>Geras</keyname><forenames>Krzysztof J.</forenames></author><author><keyname>Mohamed</keyname><forenames>Abdel-rahman</forenames></author><author><keyname>Caruana</keyname><forenames>Rich</forenames></author><author><keyname>Urban</keyname><forenames>Gregor</forenames></author><author><keyname>Wang</keyname><forenames>Shengjie</forenames></author><author><keyname>Aslan</keyname><forenames>Ozlem</forenames></author><author><keyname>Philipose</keyname><forenames>Matthai</forenames></author><author><keyname>Richardson</keyname><forenames>Matthew</forenames></author><author><keyname>Sutton</keyname><forenames>Charles</forenames></author></authors><title>Blending LSTMs into CNNs</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider whether deep convolutional networks (CNNs) can represent decision
functions with similar accuracy as recurrent networks such as LSTMs. First, we
show that a deep CNN with an architecture inspired by the models recently
introduced in image recognition can yield better accuracy than previous
convolutional and LSTM networks on the standard 309h Switchboard automatic
speech recognition task. Then we show that even more accurate CNNs can be
trained under the guidance of LSTMs using a variant of model compression, which
we call model blending because the teacher and student models are similar in
complexity but different in inductive bias. Blending further improves the
accuracy of our CNN, yielding a computationally efficient model of accuracy
higher than any of the other individual models. Examining the effect of &quot;dark
knowledge&quot; in this model compression task, we find that less than 1% of the
highest probability labels are needed for accurate model compression.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06434</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06434</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Radford</keyname><forenames>Alec</forenames></author><author><keyname>Metz</keyname><forenames>Luke</forenames></author><author><keyname>Chintala</keyname><forenames>Soumith</forenames></author></authors><title>Unsupervised Representation Learning with Deep Convolutional Generative
  Adversarial Networks</title><categories>cs.LG cs.CV</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, supervised learning with convolutional networks (CNNs) has
seen huge adoption in computer vision applications. Comparatively, unsupervised
learning with CNNs has received less attention. In this work we hope to help
bridge the gap between the success of CNNs for supervised learning and
unsupervised learning. We introduce a class of CNNs called deep convolutional
generative adversarial networks (DCGANs), that have certain architectural
constraints, and demonstrate that they are a strong candidate for unsupervised
learning. Training on various image datasets, we show convincing evidence that
our deep convolutional adversarial pair learns a hierarchy of representations
from object parts to scenes in both the generator and discriminator.
Additionally, we use the learned features for novel tasks - demonstrating their
applicability as general image representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06435</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06435</id><created>2015-11-19</created><updated>2016-01-04</updated><authors><author><keyname>Bahrampour</keyname><forenames>Soheil</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Naveen</forenames></author><author><keyname>Schott</keyname><forenames>Lukas</forenames></author><author><keyname>Shah</keyname><forenames>Mohak</forenames></author></authors><title>Comparative Study of Caffe, Neon, Theano, and Torch for Deep Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning methods have resulted in significant performance improvements
in several application domains and as such several software frameworks have
been developed to facilitate their implementation. This paper presents a
comparative study of four deep learning frameworks, namely Caffe, Neon, Theano,
and Torch, on three aspects: extensibility, hardware utilization, and speed.
The study is performed on several types of deep learning architectures and we
evaluate the performance of the above frameworks when employed on a single
machine for both (multi-threaded) CPU and GPU (Nvidia Titan X) settings. The
speed performance metrics used here include the gradient computation time,
which is important during the training phase of deep networks, and the forward
time, which is important from the deployment perspective of trained networks.
For convolutional networks, we also report how each of these frameworks support
various convolutional algorithms and their corresponding performance. From our
experiments, we observe that Theano and Torch are the most easily extensible
frameworks. We observe that Torch is best suited for any deep architecture on
CPU, followed by Theano. It also achieves the best performance on the GPU for
large convolutional and fully connected networks, followed closely by Neon.
Theano achieves the best performance on GPU for training and deployment of LSTM
networks. Finally Caffe is the easiest for evaluating the performance of
standard deep architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06436</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06436</id><created>2015-11-19</created><authors><author><keyname>Spencer</keyname><forenames>Gwen</forenames></author><author><keyname>Rolnick</keyname><forenames>David</forenames></author></authors><title>On the robust hardness of Gr\&quot;{o}bner basis computation</title><categories>cs.SC</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new problem in the approximate computation of Gr\&quot;{o}bner
bases that allows the algorithm to ignore a constant fraction of the generators
- of the algorithm's choice - then compute a Gr\&quot;{o}bner basis for the
remaining polynomial system. The set ignored is subject to one quite-natural
structural constraint. For lexicographic orders, when the discarded fraction is
less than $(1/4-\epsilon)$, for $\epsilon&gt;0$, we prove that this problem cannot
be solved in polynomial time, even when the original polynomial system has
maximum degree 3 and each polynomial contains at most 3 variables.
Qualitatively, even for sparse systems composed of low-degree polynomials, we
show that Gr\&quot;{o}bner basis computation is robustly hard: even producing a
Gr\&quot;{o}bner basis for a large subset of the generators is NP-hard.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06437</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06437</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Hosang</keyname><forenames>Jan</forenames></author><author><keyname>Benenson</keyname><forenames>Rodrigo</forenames></author><author><keyname>Schiele</keyname><forenames>Bernt</forenames></author></authors><title>A convnet for non-maximum suppression</title><categories>cs.CV cs.LG</categories><comments>Included comments from reviewers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-maximum suppression (NMS) is used in virtually all state-of-the-art
object detection pipelines. While essential object detection ingredients such
as features, classifiers, and proposal methods have been extensively researched
surprisingly little work has aimed to systematically address NMS. The de-facto
standard for NMS is based on greedy clustering with a fixed distance threshold,
which forces to trade-off recall versus precision. We propose a convnet
designed to perform NMS of a given set of detections. We report experiments on
a synthetic setup, and results on crowded pedestrian detection scenes. Our
approach overcomes the intrinsic limitations of greedy NMS, obtaining better
recall and precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06438</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06438</id><created>2015-11-19</created><authors><author><keyname>Bollegala</keyname><forenames>Danushka</forenames></author><author><keyname>Mohammed</keyname><forenames>Alsuhaibani</forenames></author><author><keyname>Maehara</keyname><forenames>Takanori</forenames></author><author><keyname>Kawarabayashi</keyname><forenames>Ken-ichi</forenames></author></authors><title>Joint Word Representation Learning using a Corpus and a Semantic Lexicon</title><categories>cs.CL cs.AI</categories><comments>Accepted to AAAI-2016</comments><journal-ref>Proceedings of the AAAI 2016</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods for learning word representations using large text corpora have
received much attention lately due to their impressive performance in numerous
natural language processing (NLP) tasks such as, semantic similarity
measurement, and word analogy detection. Despite their success, these
data-driven word representation learning methods do not consider the rich
semantic relational structure between words in a co-occurring context. On the
other hand, already much manual effort has gone into the construction of
semantic lexicons such as the WordNet that represent the meanings of words by
defining the various relationships that exist among the words in a language. We
consider the question, can we improve the word representations learnt using a
corpora by integrating the knowledge from semantic lexicons?. For this purpose,
we propose a joint word representation learning method that simultaneously
predicts the co-occurrences of two words in a sentence subject to the
relational constrains given by the semantic lexicon. We use relations that
exist between words in the lexicon to regularize the word representations
learnt from the corpus. Our proposed method statistically significantly
outperforms previously proposed methods for incorporating semantic lexicons
into word representations on several benchmark datasets for semantic similarity
and word analogy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06440</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06440</id><created>2015-11-19</created><updated>2015-12-03</updated><authors><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author><author><keyname>Jozefowicz</keyname><forenames>Rafal</forenames></author><author><keyname>Gregor</keyname><forenames>Karol</forenames></author><author><keyname>Rezende</keyname><forenames>Danilo</forenames></author><author><keyname>Lillicrap</keyname><forenames>Tim</forenames></author><author><keyname>Vinyals</keyname><forenames>Oriol</forenames></author></authors><title>Towards Principled Unsupervised Learning</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General unsupervised learning is a long-standing conceptual problem in
machine learning. Supervised learning is successful because it can be solved by
the minimization of the training error cost function. Unsupervised learning is
not as successful, because the unsupervised objective may be unrelated to the
supervised task of interest. For an example, density modelling and
reconstruction have often been used for unsupervised learning, but they did not
produced the sought-after performance gains, because they have no knowledge of
the supervised tasks.
  In this paper, we present an unsupervised cost function which we name the
Output Distribution Matching (ODM) cost, which measures a divergence between
the distribution of predictions and distributions of labels. The ODM cost is
appealing because it is consistent with the supervised cost in the following
sense: a perfect supervised classifier is also perfect according to the ODM
cost. Therefore, by aggressively optimizing the ODM cost, we are almost
guaranteed to improve our supervised performance whenever the space of possible
predictions is exponentially large.
  We demonstrate that the ODM cost works well on number of small and
semi-artificial datasets using no (or almost no) labelled training cases.
Finally, we show that the ODM cost can be used for one-shot domain adaptation,
which allows the model to classify inputs that differ from the input
distribution in significant ways without the need for prior exposure to the new
domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06441</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06441</id><created>2015-11-19</created><authors><author><keyname>Matic</keyname><forenames>Ivan</forenames></author></authors><title>A parallel algorithm for the constrained shortest path problem on
  lattice graphs</title><categories>math.OC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a parallel algorithm for finding the shortest path whose total
weight is smaller than a pre-determined value. The passage times over the edges
are assumed to be positive integers. In each step the processing elements are
not analyzing the entire graph. Instead they are focusing on a subset of
vertices called {\em active vertices}. The set of active vertices at time $t$
is related to the boundary of the ball $B_t$ of radius $t$ in the first passage
percolation metric. Although it is believed that the number of active vertices
is an order of magnitude smaller than the size of the graph, we prove that this
need not be the case with an example of a graph for which the active vertices
form a large fractal. We analyze an OpenCL implementation of the algorithm on
GPU for cubes in $\mathbb Z^d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06442</identifier>
 <datestamp>2016-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06442</id><created>2015-11-19</created><updated>2016-02-16</updated><authors><author><keyname>Gouk</keyname><forenames>Henry</forenames></author><author><keyname>Pfahringer</keyname><forenames>Bernhard</forenames></author><author><keyname>Cree</keyname><forenames>Michael</forenames></author></authors><title>Learning Similarity Metrics by Factorising Adjacency Matrices</title><categories>cs.LG cs.CV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Similarity metrics are a core component of many information retrieval and
machine learning systems. In this work we propose a method capable of learning
a similarity metric from data equipped with a binary relation. By factorising
the adjacency matrix of the relation we are able to learn target vectors for
each instance. A regression model can then be constructed that maps instances
to these learned targets, resulting in a feature extractor that computes
vectors for which the inner product is a meaningful measure of similarity. The
primary advantage of our approach is the vastly improved running time compared
to other methods that rely on pairwise similarity constraints. We present
results demonstrating our method can converge several times faster, while also
exhibiting competitive or superior accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06443</identifier>
 <datestamp>2015-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06443</id><created>2015-11-19</created><updated>2015-12-14</updated><authors><author><keyname>Dziugaite</keyname><forenames>Gintare Karolina</forenames></author><author><keyname>Roy</keyname><forenames>Daniel M.</forenames></author></authors><title>Neural Network Matrix Factorization</title><categories>cs.LG stat.ML</categories><comments>Minor modifications to notation. Added additional experiments and
  discussion. 7 pages, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data often comes in the form of an array or matrix. Matrix factorization
techniques attempt to recover missing or corrupted entries by assuming that the
matrix can be written as the product of two low-rank matrices. In other words,
matrix factorization approximates the entries of the matrix by a simple, fixed
function---namely, the inner product---acting on the latent feature vectors for
the corresponding row and column. Here we consider replacing the inner product
by an arbitrary function that we learn from the data at the same time as we
learn the latent feature vectors. In particular, we replace the inner product
by a multi-layer feed-forward neural network, and learn by alternating between
optimizing the network for fixed latent features, and optimizing the latent
features for a fixed network. The resulting approach---which we call neural
network matrix factorization or NNMF, for short---dominates standard low-rank
techniques on a suite of benchmark but is dominated by some recent proposals
that take advantage of the graph features. Given the vast range of
architectures, activation functions, regularizers, and optimization techniques
that could be used within the NNMF framework, it seems likely the true
potential of the approach has yet to be reached.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06444</identifier>
 <datestamp>2016-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06444</id><created>2015-11-19</created><updated>2016-01-12</updated><authors><author><keyname>Sagun</keyname><forenames>Levent</forenames></author><author><keyname>Trogdon</keyname><forenames>Thomas</forenames></author><author><keyname>LeCun</keyname><forenames>Yann</forenames></author></authors><title>Universality in halting time and its applications in optimization</title><categories>cs.LG math.NA math.PR</categories><msc-class>65K10, 82D30, 37E20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The authors present empirical universal distributions for the halting time
(measured by the number of iterations to reach a given accuracy) of
optimization algorithms applied to two random systems: spin glasses and deep
learning. Given an algorithm, which we take to be both the optimization routine
and the form of the random landscape, the fluctuations of the halting time
follow a distribution that remains unchanged even when the input is changed
drastically. We observe two main universality classes, a Gumbel-like
distribution that appears in Google searches, human decision times, QR
factorization and spin glasses, and a Gaussian-like distribution that appears
in conjugate gradient method, deep network with MNIST input data and deep
network with random input data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06448</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06448</id><created>2015-11-19</created><updated>2016-02-29</updated><authors><author><keyname>Bashivan</keyname><forenames>Pouya</forenames></author><author><keyname>Rish</keyname><forenames>Irina</forenames></author><author><keyname>Yeasin</keyname><forenames>Mohammed</forenames></author><author><keyname>Codella</keyname><forenames>Noel</forenames></author></authors><title>Learning Representations from EEG with Deep Recurrent-Convolutional
  Neural Networks</title><categories>cs.LG cs.CV</categories><comments>To be published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the challenges in modeling cognitive events from electroencephalogram
(EEG) data is finding representations that are invariant to inter- and
intra-subject differences, as well as to inherent noise associated with such
data. Herein, we propose a novel approach for learning such representations
from multi-channel EEG time-series, and demonstrate its advantages in the
context of mental load classification task. First, we transform EEG activities
into a sequence of topology-preserving multi-spectral images, as opposed to
standard EEG analysis techniques that ignore such spatial information. Next, we
train a deep recurrent-convolutional network inspired by state-of-the-art video
classification to learn robust representations from the sequence of images. The
proposed approach is designed to preserve the spatial, spectral, and temporal
structure of EEG which leads to finding features that are less sensitive to
variations and distortions within each dimension. Empirical evaluation on the
cognitive load classification task demonstrated significant improvements in
classification accuracy over current state-of-the-art approaches in this field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06449</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06449</id><created>2015-11-19</created><updated>2015-11-30</updated><authors><author><keyname>Park</keyname><forenames>Eunbyung</forenames></author><author><keyname>Berg</keyname><forenames>Alexander C.</forenames></author></authors><title>Learning to decompose for object detection and instance segmentation</title><categories>cs.CV cs.LG</categories><comments>ICLR 2016 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although deep convolutional neural networks(CNNs) have achieved remarkable
results on object detection and segmentation, pre- and post-processing steps
such as region proposals and non-maximum suppression(NMS), have been required.
These steps result in high computational complexity and sensitivity to
hyperparameters, e.g. thresholds for NMS. In this work, we propose a novel
end-to-end trainable deep neural network architecture, which consists of
convolutional and recurrent layers, that generates the correct number of object
instances and their bounding boxes (or segmentation masks) given an image,
using only a single network evaluation without any pre- or post-processing
steps. We have tested on detecting digits in multi-digit images synthesized
using MNIST, automatically segmenting digits in these images, and detecting
cars in the KITTI benchmark dataset. The proposed approach outperforms a strong
CNN baseline on the synthesized digits datasets and shows promising results on
KITTI car detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06452</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06452</id><created>2015-11-19</created><authors><author><keyname>Song</keyname><forenames>Hyun Oh</forenames></author><author><keyname>Xiang</keyname><forenames>Yu</forenames></author><author><keyname>Jegelka</keyname><forenames>Stefanie</forenames></author><author><keyname>Savarese</keyname><forenames>Silvio</forenames></author></authors><title>Deep Metric Learning via Lifted Structured Feature Embedding</title><categories>cs.CV cs.LG</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning the distance metric between pairs of examples is of great importance
for learning and visual recognition. With the remarkable success from the state
of the art convolutional neural networks, recent works have shown promising
results on discriminatively training the networks to learn semantic feature
embeddings where similar examples are mapped close to each other and dissimilar
examples are mapped farther apart. In this paper, we describe an algorithm for
taking full advantage of the training batches in the neural network training by
lifting the vector of pairwise distances within the batch to the matrix of
pairwise distances. This step enables the algorithm to learn the state of the
art feature embedding by optimizing a novel structured prediction objective on
the lifted problem. Additionally, we collected Online Products dataset: 120k
images of 23k classes of online products for metric learning. Our experiments
on the CUB-200-2011, CARS196, and Online Products datasets demonstrate
significant improvement over existing deep feature embedding methods on all
experimented embedding sizes with the GoogLeNet network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06455</identifier>
 <datestamp>2016-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06455</id><created>2015-11-19</created><updated>2016-02-29</updated><authors><author><keyname>Dai</keyname><forenames>Zhenwen</forenames></author><author><keyname>Damianou</keyname><forenames>Andreas</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Javier</forenames></author><author><keyname>Lawrence</keyname><forenames>Neil</forenames></author></authors><title>Variational Auto-encoded Deep Gaussian Processes</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a scalable deep non-parametric generative model by augmenting deep
Gaussian processes with a recognition model. Inference is performed in a novel
scalable variational framework where the variational posterior distributions
are reparametrized through a multilayer perceptron. The key aspect of this
reformulation is that it prevents the proliferation of variational parameters
which otherwise grow linearly in proportion to the sample size. We derive a new
formulation of the variational lower bound that allows us to distribute most of
the computation in a way that enables to handle datasets of the size of
mainstream deep learning tasks. We show the efficacy of the method on a variety
of challenges including deep unsupervised learning and deep Bayesian
optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06456</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06456</id><created>2015-11-19</created><updated>2016-01-19</updated><authors><author><keyname>Bahdanau</keyname><forenames>Dzmitry</forenames></author><author><keyname>Serdyuk</keyname><forenames>Dmitriy</forenames></author><author><keyname>Brakel</keyname><forenames>Phil&#xe9;mon</forenames></author><author><keyname>Ke</keyname><forenames>Nan Rosemary</forenames></author><author><keyname>Chorowski</keyname><forenames>Jan</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Task Loss Estimation for Sequence Prediction</title><categories>cs.LG</categories><comments>Submitted to ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often, the performance on a supervised machine learning task is evaluated
with a emph{task loss} function that cannot be optimized directly. Examples of
such loss functions include the classification error, the edit distance and the
BLEU score. A common workaround for this problem is to instead optimize a
emph{surrogate loss} function, such as for instance cross-entropy or hinge
loss. In order for this remedy to be effective, it is important to ensure that
minimization of the surrogate loss results in minimization of the task loss, a
condition that we call emph{consistency with the task loss}. In this work, we
propose another method for deriving differentiable surrogate losses that
provably meet this requirement. We focus on the broad class of models that
define a score for every input-output pair. Our idea is that this score can be
interpreted as an estimate of the task loss, and that the estimation error may
be used as a consistent surrogate loss. A distinct feature of such an approach
is that it defines the desirable value of the score for every input-output
pair. We use this property to design specialized surrogate losses for
Encoder-Decoder models often used for sequence prediction tasks. In our
experiment, we benchmark on the task of speech recognition. Using a new
surrogate loss instead of cross-entropy to train an Encoder-Decoder speech
recognizer brings a significant ~13% relative improvement in terms of Character
Error Rate (CER) in the case when no extra corpora are used for language
modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06457</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06457</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Yuille</keyname><forenames>Alan</forenames></author></authors><title>DOC: Deep OCclusion Estimation From A Single Image</title><categories>cs.CV cs.LG</categories><comments>Submitted to ICLR (Updated Fig.2)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering the occlusion relationships between objects is a fundamental human
visual ability which yields important information about the 3D world. In this
paper we propose a deep network architecture, called DOC, which acts on a
single image, detects object boundaries and estimates the border ownership
(i.e. which side of the boundary is foreground and which is background). We
represent occlusion relations by a binary edge map, to indicate the object
boundary, and an occlusion orientation variable which is tangential to the
boundary and whose direction specifies border ownership by a left-hand rule,
see Fig.1. We train two related deep convolutional neural networks, called DOC,
which exploit local and non-local image cues to estimate this representation
and hence recover occlusion relations. In order to train and test DOC we
construct a large-scale instance occlusion boundary dataset using PASCAL VOC
images, which we call the PASCAL instance occlusion dataset (PIOD). This
contains 10,000 images and hence is two orders of magnitude larger than
existing occlusion datasets for outdoor images. We test two variants of DOC on
PIOD and on the BSDS occlusion dataset and show they outperform
state-of-the-art methods typically by more than 5AP. Finally, we perform
numerous experiments investigating multiple settings of DOC and transfer
between BSDS and PIOD, which provides more insights for further study of
occlusion estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06458</identifier>
 <datestamp>2015-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06458</id><created>2015-11-19</created><updated>2015-12-02</updated><authors><author><keyname>Wiebe</keyname><forenames>Nathan</forenames></author><author><keyname>Granade</keyname><forenames>Christopher</forenames></author><author><keyname>Kapoor</keyname><forenames>Ashish</forenames></author><author><keyname>Svore</keyname><forenames>Krysta M</forenames></author></authors><title>Bayesian inference via rejection filtering</title><categories>cs.LG quant-ph stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a method for approximating Bayesian inference using rejection
sampling. We not only make the process efficient, but also dramatically reduce
the memory required relative to conventional methods by combining rejection
sampling with particle filtering. We also provide an approximate form of
rejection sampling that makes rejection filtering tractable in cases where
exact rejection sampling is not efficient. Finally, we present several
numerical examples of rejection filtering that show its ability to track time
dependent parameters in online settings and also benchmark its performance on
MNIST classification problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06459</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06459</id><created>2015-11-19</created><authors><author><keyname>Schultz</keyname><forenames>Patrick</forenames></author><author><keyname>Spivak</keyname><forenames>David I.</forenames></author><author><keyname>Wisnesky</keyname><forenames>Ryan</forenames></author></authors><title>QINL: Query-integrated Languages</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an alternative solution to the impedance-mismatch problem between
programming and query languages: rather than embed queries in a programming
language, as done in LINQ systems, we embed programs in a query language, and
dub the result QINL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06463</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06463</id><created>2015-11-19</created><authors><author><keyname>Soundarajan</keyname><forenames>Sucheta</forenames></author><author><keyname>Eliassi-Rad</keyname><forenames>Tina</forenames></author><author><keyname>Gallagher</keyname><forenames>Brian</forenames></author><author><keyname>Pinar</keyname><forenames>Ali</forenames></author></authors><title>MaxOutProbe: An Algorithm for Increasing the Size of Partially Observed
  Networks</title><categories>cs.SI physics.soc-ph</categories><comments>NIPS Workshop on Networks in the Social and Information Sciences</comments><report-no>LLNL-CONF-677677</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Networked representations of real-world phenomena are often partially
observed, which lead to incomplete networks. Analysis of such incomplete
networks can lead to skewed results. We examine the following problem: given an
incomplete network, which $b$ nodes should be probed to bring the largest
number of new nodes into the observed network? Many graph-mining tasks require
having observed a considerable amount of the network. Examples include
community discovery, belief propagation, influence maximization, etc. For
instance, consider someone who has observed a portion (say 1%) of the Twitter
retweet network via random tweet sampling. She wants to estimate the size of
the largest connected component of the fully observed retweet network. To
improve her estimate, how should she use her limited budget to reduce the
incompleteness of the network? In this work, we propose a novel algorithm,
called MaxOutProbe, which uses a budget $b$ (on nodes probed) to increase the
size of the observed network in terms of the number of nodes. Our experiments,
across a range of datasets and conditions, demonstrate the advantages of
MaxOutProbe over existing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06464</identifier>
 <datestamp>2016-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06464</id><created>2015-11-19</created><updated>2016-02-17</updated><authors><author><keyname>Arjovsky</keyname><forenames>Martin</forenames></author><author><keyname>Shah</keyname><forenames>Amar</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Unitary Evolution Recurrent Neural Networks</title><categories>cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recurrent neural networks (RNNs) are notoriously difficult to train. When the
eigenvalues of the hidden to hidden weight matrix deviate from absolute value
1, optimization becomes difficult due to the well studied issue of vanishing
and exploding gradients, especially when trying to learn long-term
dependencies. To circumvent this problem, we propose a new architecture that
learns a unitary weight matrix, with eigenvalues of absolute value exactly 1.
The challenge we address is that of parametrizing unitary matrices in a way
that does not require expensive computations (such as eigendecomposition) after
each weight update. We construct an expressive unitary weight matrix by
composing several structured matrices that act as building blocks with
parameters to be learned. Optimization with this parameterization becomes
feasible only when considering hidden states in the complex domain. We
demonstrate the potential of this architecture by achieving state of the art
results in several hard tasks involving very long-term dependencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06468</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06468</id><created>2015-11-19</created><authors><author><keyname>Wang</keyname><forenames>Di</forenames></author><author><keyname>Mahoney</keyname><forenames>Michael</forenames></author><author><keyname>Mohan</keyname><forenames>Nishanth</forenames></author><author><keyname>Rao</keyname><forenames>Satish</forenames></author></authors><title>Faster Parallel Solver for Positive Linear Programs via
  Dynamically-Bucketed Selective Coordinate Descent</title><categories>cs.DS cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide improved parallel approximation algorithms for the important class
of packing and covering linear programs. In particular, we present new parallel
$\epsilon$-approximate packing and covering solvers which run in
$\tilde{O}(1/\epsilon^2)$ expected time, i.e., in expectation they take
$\tilde{O}(1/\epsilon^2)$ iterations and they do $\tilde{O}(N/\epsilon^2)$
total work, where $N$ is the size of the constraint matrix and $\epsilon$ is
the error parameter, and where the $\tilde{O}$ hides logarithmic factors. To
achieve our improvement, we introduce an algorithmic technique of broader
interest: dynamically-bucketed selective coordinate descent (DB-SCD). At each
step of the iterative optimization algorithm, the DB-SCD method dynamically
buckets the coordinates of the gradient into those of roughly equal magnitude,
and it updates all the coordinates in one of the buckets. This
dynamically-bucketed updating permits us to take steps along several
coordinates with similar-sized gradients, thereby permitting more appropriate
step sizes at each step of the algorithm. In particular, this technique allows
us to use in a straightforward manner the recent analysis from the breakthrough
results of Allen-Zhu and Orecchia [2] to achieve our still-further improved
bounds. More generally, this method addresses &quot;interference&quot; among coordinates,
by which we mean the impact of the update of one coordinate on the gradients of
other coordinates. Such interference is a core issue in parallelizing
optimization routines that rely on smoothness properties. Since our DB-SCD
method reduces interference via updating a selective subset of variables at
each iteration, we expect it may also have more general applicability in
optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06470</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06470</id><created>2015-11-19</created><authors><author><keyname>Cao</keyname><forenames>Zhengjun</forenames></author><author><keyname>Liu</keyname><forenames>Lihua</forenames></author></authors><title>Comment on Two schemes for Secure Outsourcing of Linear Programming</title><categories>cs.CR</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, Wang et al. [IEEE INFOCOM 2011, 820-828], and Nie et al. [IEEE AINA
2014, 591-596] have proposed two schemes for secure outsourcing of large-scale
linear programming (LP). They did not consider the standard form: minimize
c^{T}x, subject to Ax=b, x&gt;0. Instead, they studied a peculiar form: minimize
c^{T}x, subject to Ax = b, Bx&gt;0, where B is a non-singular matrix. In this
note, we stress that the proposed peculiar form is unsolvable and meaningless.
The two schemes have confused the functional inequality constraints Bx&gt;0 with
the nonnegativity constraints x&gt;0 in the linear programming model. But the
condition x&gt;0 is indispensable to the simplex method. Therefore, both two
schemes failed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06477</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06477</id><created>2015-11-19</created><authors><author><keyname>Bhatt</keyname><forenames>Nirav</forenames></author><author><keyname>Srinivasan</keyname><forenames>Sriniketh</forenames></author></authors><title>On Cooperative Behavior of Open Homogeneous Chemical Reaction Systems in
  the Extent Domain</title><categories>cs.SY math.DS</categories><comments>The paper was presented in the first Indian Control Conference 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Material balance equations describe the dynamics of the species in open
reaction systems and contain information regarding reaction topology, kinetics
and operation mode. For reaction systems, the state variables (the numbers of
moles, or concentrations) have recently been transformed into decoupled
reaction variants (extents of reaction), and reaction invariants (extents of
flow) (Amrhein et al., AIChE Journal, 2010). This paper analyses the conditions
under which an open homogeneous reaction system is cooperative in the extents
domain. Further, it is shown that the dynamics of the extents of flow exhibit
cooperative behavior. Further, we provide the conditions under which the
dynamics of the extents of reaction exhibit cooperative behavior. Our results
provide physical insights into cooperative and competitive nature of the
underlying reaction system in the presence of material exchange with
surrounding (i.e., inlet and outlet flows). The results of the article are
demonstrated via examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06480</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06480</id><created>2015-11-19</created><updated>2015-12-04</updated><authors><author><keyname>Yu</keyname><forenames>Felix X.</forenames></author><author><keyname>Bhaskara</keyname><forenames>Aditya</forenames></author><author><keyname>Kumar</keyname><forenames>Sanjiv</forenames></author><author><keyname>Gong</keyname><forenames>Yunchao</forenames></author><author><keyname>Chang</keyname><forenames>Shih-Fu</forenames></author></authors><title>On Binary Embedding using Circulant Matrices</title><categories>cs.DS cs.LG</categories><comments>This is an extended version of a paper by the first, third, fourth
  and fifth authors that appeared in ICML 2014 [arXiv:1405.3162]</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Binary embeddings provide efficient and powerful ways to perform operations
on large scale data. However binary embedding typically requires long codes in
order to preserve the discriminative power of the input space. Thus binary
coding methods traditionally suffer from high computation and storage costs in
such a scenario. To address this problem, we propose Circulant Binary Embedding
(CBE) which generates binary codes by projecting the data with a circulant
matrix. The circulant structure allows us to use Fast Fourier Transform
algorithms to speed up the computation. For obtaining $k$-bit binary codes from
$d$-dimensional data, this improves the time complexity from $O(dk)$ to
$O(d\log{d})$, and the space complexity from $O(dk)$ to $O(d)$.
  We study two settings, which differ in the way we choose the parameters of
the circulant matrix. In the first, the parameters are chosen randomly and in
the second, the parameters are learned using the data. For randomized CBE, we
give a theoretical analysis comparing it with binary embedding using an
unstructured random projection matrix. The challenge here is to show that the
dependencies in the entries of the circulant matrix do not lead to a loss in
performance. In the second setting, we design a novel time-frequency
alternating optimization to learn data-dependent circulant projections, which
alternatively minimizes the objective in original and Fourier domains. In both
the settings, we show by extensive experiments that the CBE approach gives much
better performance than the state-of-the-art approaches if we fix a running
time, and provides much faster computation with negligible performance
degradation if we fix the number of bits in the embedding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06481</identifier>
 <datestamp>2016-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06481</id><created>2015-11-19</created><updated>2016-01-20</updated><authors><author><keyname>Alain</keyname><forenames>Guillaume</forenames></author><author><keyname>Lamb</keyname><forenames>Alex</forenames></author><author><keyname>Sankar</keyname><forenames>Chinnadhurai</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Variance Reduction in SGD by Distributed Importance Sampling</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Humans are able to accelerate their learning by selecting training materials
that are the most informative and at the appropriate level of difficulty. We
propose a framework for distributing deep learning in which one set of workers
search for the most informative examples in parallel while a single worker
updates the model on examples selected by importance sampling. This leads the
model to update using an unbiased estimate of the gradient which also has
minimum variance when the sampling proposal is proportional to the L2-norm of
the gradient. We show experimentally that this method reduces gradient variance
even in a context where the cost of synchronization across machines cannot be
ignored, and where the factors for importance sampling are not updated
instantly across the training set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06483</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06483</id><created>2015-11-19</created><authors><author><keyname>Barati</keyname><forenames>C. Nicolas</forenames></author><author><keyname>Hosseini</keyname><forenames>S. Amir</forenames></author><author><keyname>Mezzavilla</keyname><forenames>Marco</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author><author><keyname>Korakis</keyname><forenames>Thanasis</forenames></author><author><keyname>Panwar</keyname><forenames>Shivendra S.</forenames></author><author><keyname>Zorzi</keyname><forenames>Michele</forenames></author></authors><title>Directional Initial Access for Millimeter Wave Cellular Systems</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The millimeter wave (mmWave) bands have recently attracted considerable
interest for next-generation cellular systems due to the massive available
bandwidths at these frequencies. However, a key challenge in designing mmWave
cellular systems is initial access -- the procedure by which a mobile
establishes an initial link-layer connection to a base station cell. MmWave
communication relies on highly directional transmissions and the initial access
procedure must thus provide a mechanism by which initial transmission
directions can be searched in a potentially large angular space. Design options
are compared considering different scanning and signaling procedures to
evaluate access delay and system overhead. The channel structure and multiple
access issues are also considered. The analysis demonstrates significant
benefits of low-resolution fully digital architectures in comparison to single
stream analog beamforming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06485</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06485</id><created>2015-11-19</created><updated>2016-02-07</updated><authors><author><keyname>Chaudhari</keyname><forenames>Pratik</forenames></author><author><keyname>Soatto</keyname><forenames>Stefano</forenames></author></authors><title>The Effect of Gradient Noise on the Energy Landscape of Deep Networks</title><categories>cs.LG</categories><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We analyze the regularization properties of additive gradient noise in the
training of deep networks by posing it as finding the ground state of the
Hamiltonian of a spherical spin glass in an external magnetic field. We show
that depending upon the magnitude of the magnetic field, the Hamiltonian
changes dramatically from a highly non-convex energy landscape with
exponentially many critical points to a regime with polynomially many critical
points and finally, &quot;trivializes&quot;' to exactly one minimum. This phenomenon,
known as topology trivialization in the physics literature, can be leveraged to
devise annealing schemes for additive noise such that the training starts in
the polynomial regime but gradually morphs the energy landscape into the
original one as training progresses. We demonstrate through experiments on
fully-connected and convolutional neural networks that annealing schemes based
on trivialization lead to accelerated training and also improve generalization
error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06487</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06487</id><created>2015-11-19</created><updated>2015-12-02</updated><authors><author><keyname>Avis</keyname><forenames>David</forenames></author><author><keyname>Jordan</keyname><forenames>Charles</forenames></author></authors><title>mplrs: A scalable parallel vertex/facet enumeration code</title><categories>cs.MS cs.CG cs.DC</categories><comments>Revised pseudocode to make it clearer and corrected an error in the
  previous version</comments><msc-class>90C05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new parallel implementation, mplrs, of the vertex enumeration
code lrs that uses the MPI parallel environment and can be run on a network of
computers. The implementation makes use of a C wrapper that essentially uses
the existing lrs code with only minor modifications. mplrs was derived from the
earlier parallel implementation plrs, written by G. Roumanis in C++. plrs uses
the Boost library and runs on a shared memory machine. In developing mplrs we
discovered a method of balancing the parallel tree search, called budgeting,
that greatly improves parallelization beyond the bottleneck encountered
previously at around 32 cores. This method can be readily adapted for use in
other reverse search enumeration codes. We also report some preliminary
computational results comparing parallel and sequential codes for vertex/facet
enumeration problems for convex polyhedra. The problems chosen span the range
from simple to highly degenerate polytopes. For most problems tested, the
results clearly show the advantage of using the parallel implementation mplrs
of the reverse search based code lrs, even when as few as 8 cores are
available. For some problems almost linear speedup was observed up to 1200
cores, the largest number of cores tested.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06488</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06488</id><created>2015-11-19</created><updated>2016-01-07</updated><authors><author><keyname>Sung</keyname><forenames>Wonyong</forenames></author><author><keyname>Shin</keyname><forenames>Sungho</forenames></author><author><keyname>Hwang</keyname><forenames>Kyuyeon</forenames></author></authors><title>Resiliency of Deep Neural Networks under Quantization</title><categories>cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The complexity of deep neural network algorithms for hardware implementation
can be much lowered by optimizing the word-length of weights and signals.
Direct quantization of floating-point weights, however, does not show good
performance when the number of bits assigned is small. Retraining of quantized
networks has been developed to relieve this problem. In this work, the effects
of retraining are analyzed for a feedforward deep neural network (FFDNN) and a
convolutional neural network (CNN). The network complexity is controlled to
know their effects on the resiliency of quantized networks by retraining. The
complexity of the FFDNN is controlled by varying the unit size in each hidden
layer and the number of layers, while that of the CNN is done by modifying the
feature map configuration. We find that the performance gap between the
floating-point and the retrain-based ternary (+1, 0, -1) weight neural networks
exists with a fair amount in 'complexity limited' networks, but the discrepancy
almost vanishes in fully complex networks whose capability is limited by the
training data, rather than by the number of connections. This research shows
that highly complex DNNs have the capability of absorbing the effects of severe
weight quantization through retraining, but connection limited networks are
less resilient. This paper also presents the effective compression ratio to
guide the trade-off between the network size and the precision when the
hardware resource is limited.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06489</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06489</id><created>2015-11-19</created><authors><author><keyname>Fei</keyname><forenames>Xiaohan</forenames></author><author><keyname>Tsotsos</keyname><forenames>Konstantine</forenames></author><author><keyname>Soatto</keyname><forenames>Stefano</forenames></author></authors><title>A Simple Hierarchical Pooling Data Structure for Loop Closure</title><categories>cs.CV cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a data structure obtained by hierarchically averaging bag-of-word
descriptors during a sequence of views that achieves average speedups in
large-scale loop closure applications ranging from 4 to 20 times on benchmark
datasets. Although simple, the method works as well as sophisticated
agglomerative schemes at a fraction of the cost with minimal loss of
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06491</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06491</id><created>2015-11-20</created><authors><author><keyname>Zhang</keyname><forenames>Xiao</forenames></author><author><keyname>Mollahosseini</keyname><forenames>Ali</forenames></author><author><keyname>B.</keyname><forenames>Amir H. Kargar</forenames></author><author><keyname>Boucher</keyname><forenames>Evan</forenames></author><author><keyname>Voyles</keyname><forenames>Richard M.</forenames></author><author><keyname>Nielsen</keyname><forenames>Rodney</forenames></author><author><keyname>Mahoor</keyname><forenames>Mohammd H.</forenames></author></authors><title>eBear: An Expressive Bear-Like Robot</title><categories>cs.RO</categories><journal-ref>The 23rd IEEE International Symposium on Robot and Human
  Interactive Communication, 2014 RO-MAN</journal-ref><doi>10.1109/ROMAN.2014.6926378</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an anthropomorphic robotic bear for the exploration of
human-robot interaction including verbal and non-verbal communications. This
robot is implemented with a hybrid face composed of a mechanical faceplate with
10 DOFs and an LCD-display-equipped mouth. The facial emotions of the bear are
designed based on the description of the Facial Action Coding System as well as
some animal-like gestures described by Darwin. The mouth movements are realized
by synthesizing emotions with speech. User acceptance investigations have been
conducted to evaluate the likability of these facial behaviors exhibited by the
eBear. Multiple Kernel Learning is proposed to fuse different features for
recognizing user's facial expressions. Our experimental results show that the
developed Bear-Like robot can perceive basic facial expressions and provide
emotive conveyance towards human beings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06493</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06493</id><created>2015-11-20</created><authors><author><keyname>Belletti</keyname><forenames>Francois</forenames></author><author><keyname>Sparks</keyname><forenames>Evan</forenames></author><author><keyname>Franklin</keyname><forenames>Michael</forenames></author><author><keyname>Bayen</keyname><forenames>Alexandre M.</forenames></author></authors><title>Embarrassingly Parallel Time Series Analysis for Large Scale Weak Memory
  Systems</title><categories>cs.DC</categories><msc-class>68M14, 37M10, 62M10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Second order stationary models in time series analysis are based on the
analysis of essential statistics whose computations follow a common pattern. In
particular, with a map-reduce nomenclature, most of these operations can be
modeled as mapping a kernel that only depends on short windows of consecutive
data and reducing the results produced by each computation. This computational
pattern stems from the ergodicity of the model under consideration and is often
referred to as weak or short memory when it comes to data indexed with respect
to time. In the following we will show how studying weak memory systems can be
done in a scalable manner thanks to a framework relying on specifically
designed overlapping distributed data structures that enable fragmentation and
replication of the data across many machines as well as parallelism in
computations. This scheme has been implemented for Apache Spark but is
certainly not system specific. Indeed we prove it is also adapted to leveraging
high bandwidth fragmented memory blocks on GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06494</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06494</id><created>2015-11-20</created><authors><author><keyname>Mollahosseini</keyname><forenames>Ali</forenames></author><author><keyname>Mahoor</keyname><forenames>Mohammad H.</forenames></author></authors><title>Bidirectional Warping of Active Appearance Model</title><categories>cs.CV</categories><journal-ref>2013 IEEE Conference on Computer Vision and Pattern Recognition
  Workshops (CVPRW)</journal-ref><doi>10.1109/CVPRW.2013.129</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active Appearance Model (AAM) is a commonly used method for facial image
analysis with applications in face identification and facial expression
recognition. This paper proposes a new approach based on image alignment for
AAM fitting called bidirectional warping. Previous approaches warp either the
input image or the appearance template. We propose to warp both the input
image, using incremental update by an affine transformation, and the appearance
template, using an inverse compositional approach. Our experimental results on
Multi-PIE face database show that the bidirectional approach outperforms
state-of-the-art inverse compositional fitting approaches in extracting
landmark points of faces with shape and pose variations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06499</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06499</id><created>2015-11-20</created><updated>2016-03-04</updated><authors><author><keyname>Tran</keyname><forenames>Dustin</forenames></author><author><keyname>Ranganath</keyname><forenames>Rajesh</forenames></author><author><keyname>Blei</keyname><forenames>David M.</forenames></author></authors><title>Variational Gaussian Process</title><categories>stat.ML cs.LG cs.NE stat.CO</categories><comments>Appears in International Conference on Learning Representations, 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Variational inference is a powerful tool for approximate inference, and it
has been recently applied for representation learning with deep generative
models. We develop the variational Gaussian process (VGP), a Bayesian
nonparametric variational family, which adapts its shape to match complex
posterior distributions. The VGP generates approximate posterior samples by
generating latent inputs and warping them through random non-linear mappings;
the distribution over random mappings is learned during inference, enabling the
transformed outputs to adapt to varying complexity. We prove a universal
approximation theorem for the VGP, demonstrating its representative power for
learning any model. For inference we present a variational objective inspired
by auto-encoders and perform black box inference over a wide class of models.
The VGP achieves new state-of-the-art results for unsupervised learning,
inferring models such as the deep latent Gaussian model and the recently
proposed DRAW.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06502</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06502</id><created>2015-11-20</created><authors><author><keyname>Mollahosseini</keyname><forenames>Ali</forenames></author><author><keyname>Graitzer</keyname><forenames>Gabriel</forenames></author><author><keyname>Borts</keyname><forenames>Eric</forenames></author><author><keyname>Conyers</keyname><forenames>Stephen</forenames></author><author><keyname>Voyles</keyname><forenames>Richard M.</forenames></author><author><keyname>Cole</keyname><forenames>Ronald</forenames></author><author><keyname>Mahoor</keyname><forenames>Mohammad H.</forenames></author></authors><title>ExpressionBot: An Emotive Lifelike Robotic Face for Face-to-Face
  Communication</title><categories>cs.RO</categories><journal-ref>14th IEEE-RAS International Conference on Humanoid Robots
  (Humanoids), 2014</journal-ref><doi>10.1109/HUMANOIDS.2014.7041505</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article proposes an emotive lifelike robotic face, called ExpressionBot,
that is designed to support verbal and non-verbal communication between the
robot and humans, with the goal of closely modeling the dynamics of natural
face-to-face communication. The proposed robotic head consists of two major
components: 1) a hardware component that contains a small projector, a fish-eye
lens, a custom-designed mask and a neck system with 3 degrees of freedom; 2) a
facial animation system, projected onto the robotic mask, that is capable of
presenting facial expressions, realistic eye movement, and accurate visual
speech. We present three studies that compare Human-Robot Interaction with
Human-Computer Interaction with a screen-based model of the avatar. The studies
indicate that the robotic face is well accepted by users, with some advantages
in recognition of facial expression and mutual eye gaze contact.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06504</identifier>
 <datestamp>2015-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06504</id><created>2015-11-20</created><updated>2015-12-10</updated><authors><author><keyname>Zhang</keyname><forenames>Jianhui</forenames></author><author><keyname>Wang</keyname><forenames>Mengmeng</forenames></author><author><keyname>Li</keyname><forenames>Zhi</forenames></author></authors><title>Stochastic Duty Cycling for Heterogenous Energy Harvesting Networks</title><categories>cs.NI</categories><comments>Publised on 34th IEEE-International Performance Computing and
  Communications Conference (IPCCC 2015)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, there have been several kinds of energy harvesting networks
containing some tiny devices, such as ambient backscatter, ring and renewable
sensor networks. During energy harvesting, such networks suffer from the energy
heterogeneity, dynamics and prediction hardness because the access to natural
resources is often spatiotemporal different and timely changing among the
devices. Meanwhile, the charging efficiency is quite low especially when the
power of the harvested energy is weak. It results in the energy waste to store
the harvested energy indirectly. These features bring challenging and
interesting issues on efficient allocation of the harvested energy. This paper
studies the \emph{stochastic duty cycling} by considering these features with
the objective characterized by maximizing the common active time. We consider
two cases: offline and online stochastic duty cycling. For the offline case, we
design an optimal solution: offline duty cycling algorithm. For the online
case, we design an online duty cycling algorithm, which achieves the
approximation ratio with at least $1-e^{-\gamma^2}$, where $\gamma$ is the
probability able to harvest energy. We also evaluate our algorithms with the
experiment on a real energy harvesting network. The experiment results show
that the performance of the online algorithm can be very close to the offline
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06510</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06510</id><created>2015-11-20</created><authors><author><keyname>Gervais</keyname><forenames>Renaud</forenames><affiliation>Potioc</affiliation></author><author><keyname>Frey</keyname><forenames>J{&#xe9;}r{&#xe9;}my</forenames><affiliation>UB, LaBRI, Potioc</affiliation></author><author><keyname>Gay</keyname><forenames>Alexis</forenames><affiliation>Potioc, LaBRI</affiliation></author><author><keyname>Lotte</keyname><forenames>Fabien</forenames><affiliation>Potioc, LaBRI</affiliation></author><author><keyname>Hachet</keyname><forenames>Martin</forenames><affiliation>Potioc, LaBRI</affiliation></author></authors><title>TOBE: Tangible Out-of-Body Experience</title><categories>cs.HC</categories><proxy>ccsd</proxy><journal-ref>Tangible, Embedded and Embodied Interaction (TEI), Feb 2016,
  Eindhoven, Netherlands. 2016, \&amp;lt;http://www.tei-conf.org/16/\&amp;gt;.
  \&amp;lt;10.1145/2839462.2839486\&amp;gt;</journal-ref><doi>10.1145/2839462.2839486</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a toolkit for creating Tangible Out-of-Body Experiences: exposing
the inner states of users using physiological signals such as heart rate or
brain activity. Tobe can take the form of a tangible avatar displaying live
physiological readings to reflect on ourselves and others. Such a toolkit could
be used by researchers and designers to create a multitude of potential
tangible applications, including (but not limited to) educational tools about
Science Technologies Engineering and Mathematics (STEM) and cognitive science,
medical applications or entertainment and social experiences with one or
several users or Tobes involved. Through a co-design approach, we investigated
how everyday people picture their physiology and we validated the acceptability
of Tobe in a scientific museum. We also give a practical example where two
users relax together, with insights on how Tobe helped them to synchronize
their signals and share a moment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06518</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06518</id><created>2015-11-20</created><authors><author><keyname>Alves</keyname><forenames>Hirley</forenames></author><author><keyname>Tom&#xe9;</keyname><forenames>Mauricio</forenames></author><author><keyname>Nardelli</keyname><forenames>Pedro H. J.</forenames></author><author><keyname>de Lima</keyname><forenames>Carlos H. M.</forenames></author><author><keyname>Latva-aho</keyname><forenames>Matti</forenames></author></authors><title>Enhanced Transmit Antenna Selection Scheme for Secure Throughput
  Maximization Without CSI at the Transmitter and its Applications on Smart
  Grids</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the establishment of secure communication links between
smart-meters (Alice) and an aggregator (Bob) in the presence of an eavesdropper
(Eve). The proposed scenario assumes: (i) MIMOME wiretap channel; (ii) transmit
antenna selection at the Alice; (iii) no channel state information at the
transmitter; (iv) fixed Wyner codes; and (v) guarantee of secure throughput by
both quality of service and secrecy outage constraints. We propose a simple
protocol to enhance security via transmit antenna selection, and then assess
its performance in closed-form by means of secrecy outage and successful
transmission probabilities. We assume these probabilities are our constraints
and then maximize the secure throughput, establishing a security-reliability
trade-off for the proposed scenario. Our numerical results illustrate the
effect of this trade-off on the secure throughput as well as on the number of
antennas at Alice, Bob and Eve. Interestingly, a small sacrifice in reliability
allows secrecy enhancement in terms of secure bps/Hz. We apply this idea in our
smart grid application to exemplify that, although Eve may acquire some samples
of the average power demand of a household, it is not enough to properly
reconstruct such curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06522</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06522</id><created>2015-11-20</created><updated>2016-02-22</updated><authors><author><keyname>Zhang</keyname><forenames>Yan</forenames></author><author><keyname>Ozay</keyname><forenames>Mete</forenames></author><author><keyname>Liu</keyname><forenames>Xing</forenames></author><author><keyname>Okatani</keyname><forenames>Takayuki</forenames></author></authors><title>Integrating Deep Features for Material Recognition</title><categories>cs.CV cs.LG</categories><comments>9 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for integration of features extracted using deep
representations of Convolutional Neural Networks (CNNs) each of which is
learned using a different image dataset of objects and materials for material
recognition. Given a set of representations of multiple pre-trained CNNs, we
first compute activations of features using the representations on the images
to select a set of samples which are best represented by the features. Then, we
measure the uncertainty of the features by computing the entropy of class
distributions for each sample set. Finally, we compute the contribution of each
feature to representation of classes for feature selection and integration. We
examine the proposed method on three benchmark datasets for material
recognition. Experimental results show that the proposed method achieves
state-of-the-art performance by integrating deep features. Additionally, we
introduce a new material dataset called EFMD by extending Flickr Material
Database (FMD). By the employment of the EFMD with transfer learning for
updating the learned CNN models, we achieve 84.0%+/-1.8% accuracy on the FMD
dataset which is close to human performance that is 84.9%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06523</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06523</id><created>2015-11-20</created><authors><author><keyname>Yang</keyname><forenames>Shuo</forenames></author><author><keyname>Luo</keyname><forenames>Ping</forenames></author><author><keyname>Loy</keyname><forenames>Chen Change</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoou</forenames></author></authors><title>WIDER FACE: A Face Detection Benchmark</title><categories>cs.CV</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Face detection is one of the most studied topics in the computer vision
community. Much of the progresses have been made by the availability of face
detection benchmark datasets. We show that there is a gap between current face
detection performance and the real world requirements. To facilitate future
face detection research, we introduce the WIDER FACE dataset, which is 10 times
larger than existing datasets. The dataset contains rich annotations, including
occlusions, poses, event categories, and face bounding boxes. Faces in the
proposed dataset are extremely challenging due to large variations in scale,
pose and occlusion, as shown in Fig. 1. Furthermore, we show that WIDER FACE
dataset is an effective training source for face detection. We benchmark
several representative detection systems, providing an overview of
state-of-the-art performance and propose a solution to deal with large scale
variation. Finally, we discuss common failure cases that worth to be further
investigated. Dataset can be downloaded at:
mmlab.ie.cuhk.edu.hk/projects/WIDERFace
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06530</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06530</id><created>2015-11-20</created><updated>2016-02-24</updated><authors><author><keyname>Kim</keyname><forenames>Yong-Deok</forenames></author><author><keyname>Park</keyname><forenames>Eunhyeok</forenames></author><author><keyname>Yoo</keyname><forenames>Sungjoo</forenames></author><author><keyname>Choi</keyname><forenames>Taelim</forenames></author><author><keyname>Yang</keyname><forenames>Lu</forenames></author><author><keyname>Shin</keyname><forenames>Dongjun</forenames></author></authors><title>Compression of Deep Convolutional Neural Networks for Fast and Low Power
  Mobile Applications</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although the latest high-end smartphone has powerful CPU and GPU, running
deeper convolutional neural networks (CNNs) for complex tasks such as ImageNet
classification on mobile devices is challenging. To deploy deep CNNs on mobile
devices, we present a simple and effective scheme to compress the entire CNN,
which we call one-shot whole network compression. The proposed scheme consists
of three steps: (1) rank selection with variational Bayesian matrix
factorization, (2) Tucker decomposition on kernel tensor, and (3) fine-tuning
to recover accumulated loss of accuracy, and each step can be easily
implemented using publicly available tools. We demonstrate the effectiveness of
the proposed scheme by testing the performance of various compressed CNNs
(AlexNet, VGGS, GoogLeNet, and VGG-16) on the smartphone. Significant
reductions in model size, runtime, and energy consumption are obtained, at the
cost of small loss in accuracy. In addition, we address the important
implementation level issue on 1?1 convolution, which is a key operation of
inception module of GoogLeNet as well as CNNs compressed by our proposed
scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06545</identifier>
 <datestamp>2015-12-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06545</id><created>2015-11-20</created><updated>2015-12-19</updated><authors><author><keyname>Chakraborty</keyname><forenames>Souradeep</forenames></author><author><keyname>Mitra</keyname><forenames>Pabitra</forenames></author></authors><title>A dense subgraph based algorithm for compact salient image region
  detection</title><categories>cs.CV</categories><comments>33 pages, 18 figures, Single column manuscript pre-print, Accepted at
  Computer Vision and Image Understanding, Elsevier</comments><doi>10.1016/j.cviu.2015.12.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for graph based saliency computation that utilizes
the underlying dense subgraphs in finding visually salient regions in an image.
To compute the salient regions, the model first obtains a saliency map using
random walks on a Markov chain. Next, k-dense subgraphs are detected to further
enhance the salient regions in the image. Dense subgraphs convey more
information about local graph structure than simple centrality measures. To
generate the Markov chain, intensity and color features of an image in addition
to region compactness is used. For evaluating the proposed model, we do
extensive experiments on benchmark image data sets. The proposed method
performs comparable to well-known algorithms in salient region detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06554</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06554</id><created>2015-11-20</created><authors><author><keyname>Li</keyname><forenames>Li</forenames></author><author><keyname>Bissyand&#xe9;</keyname><forenames>Tegawend&#xe9; F.</forenames></author><author><keyname>Klein</keyname><forenames>Jacques</forenames></author><author><keyname>Traon</keyname><forenames>Yves Le</forenames></author></authors><title>An Investigation into the Use of Common Libraries in Android Apps</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The packaging model of Android apps requires the entire code necessary for
the execution of an app to be shipped into one single apk file. Thus, an
analysis of Android apps often visits code which is not part of the
functionality delivered by the app. Such code is often contributed by the
common libraries which are used pervasively by all apps. Unfortunately, Android
analyses, e.g., for piggybacking detection and malware detection, can produce
inaccurate results if they do not take into account the case of library code,
which constitute noise in app features. Despite some efforts on investigating
Android libraries, the momentum of Android research has not yet produced a
complete set of common libraries to further support in-depth analysis of
Android apps. In this paper, we leverage a dataset of about 1.5 million apps
from Google Play to harvest potential common libraries, including advertisement
libraries. With several steps of refinements, we finally collect by far the
largest set of 1,113 libraries supporting common functionalities and 240
libraries for advertisement. We use the dataset to investigates several aspects
of Android libraries, including their popularity and their proportion in
Android app code. Based on these datasets, we have further performed several
empirical investigations to confirm the motivations behind our work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06558</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06558</id><created>2015-11-20</created><authors><author><keyname>Manurangsi</keyname><forenames>Pasin</forenames></author><author><keyname>Nakkiran</keyname><forenames>Preetum</forenames></author><author><keyname>Trevisan</keyname><forenames>Luca</forenames></author></authors><title>Near-Optimal UGC-hardness of Approximating Max k-CSP_R</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we prove an almost-optimal hardness for Max $k$-CSP$_R$ based
on Khot's Unique Games Conjecture (UGC). In Max $k$-CSP$_R$, we are given a set
of predicates each of which depends on exactly $k$ variables. Each variable can
take any value from $1, 2, \dots, R$. The goal is to find an assignment to
variables that maximizes the number of satisfied predicates.
  Assuming the Unique Games Conjecture, we show that it is NP-hard to
approximate Max $k$-CSP$_R$ to within factor $2^{O(k \log k)}(\log
R)^{k/2}/R^{k - 1}$ for any $k, R$. To the best of our knowledge, this result
improves on all the known hardness of approximation results when $3 \leq k =
o(\log R/\log \log R)$. In this case, the previous best hardness result was
NP-hardness of approximating within a factor $O(k/R^{k-2})$ by Chan. When $k =
2$, our result matches the best known UGC-hardness result of Khot, Kindler,
Mossel and O'Donnell.
  In addition, by extending an algorithm for Max 2-CSP$_R$ by Kindler, Kolla
and Trevisan, we provide an $\Omega(\log R/R^{k - 1})$-approximation algorithm
for Max $k$-CSP$_R$. This algorithm implies that our inapproximability result
is tight up to a factor of $2^{O(k \log k)}(\log R)^{k/2 - 1}$. In comparison,
when $3 \leq k$ is a constant, the previously known gap was $O(R)$, which is
significantly larger than our gap of $O(\text{polylog } R)$.
  Finally, we show that we can replace the Unique Games Conjecture assumption
with Khot's $d$-to-1 Conjecture and still get asymptotically the same hardness
of approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06559</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06559</id><created>2015-11-20</created><updated>2016-02-29</updated><authors><author><keyname>Laekhanukit</keyname><forenames>Bundit</forenames></author></authors><title>Approximating Directed Steiner Problems via Tree Embedding</title><categories>cs.DS</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the k-edge connected directed Steiner tree (k-DST) problem, we are given a
directed graph G on n vertices with edge-costs, a root vertex r, a set of h
terminals T and an integer k. The goal is to find a min-cost subgraph H of G
that connects r to each terminal t by k edge-disjoint r,t-paths. This problem
includes as special cases the well-known directed Steiner tree (DST) problem
(the case k = 1) and the group Steiner tree (GST) problem. Despite having been
studied and mentioned many times in literature, e.g., by Feldman et al.
[SODA'09, JCSS'12], by Cheriyan et al. [SODA'12, TALG'14] and by Laekhanukit
[SODA'14], there was no known non-trivial approximation algorithm for k-DST for
k &gt;= 2 even in the special case that an input graph is directed acyclic and has
a constant number of layers. If an input graph is not acyclic, the complexity
status of k-DST is not known even for a very strict special case that k= 2 and
|T| = 2.
  In this paper, we make a progress toward developing a non-trivial
approximation algorithm for k-DST. We present an O(D k^{D-1} log
n)-approximation algorithm for k-DST on directed acyclic graphs (DAGs) with D
layers, which can be extended to a special case of k-DST on &quot;general graphs&quot;
when an instance has a D-shallow optimal solution, i.e., there exist k
edge-disjoint r,t-paths, each of length at most D, for every terminal t. For
the case k= 1 (DST), our algorithm yields an approximation ratio of O(D log h),
thus implying an O(log^3 h)-approximation algorithm for DST that runs in
quasi-polynomial-time (due to the height-reduction of Zelikovsky
[Algorithmica'97]). Consequently, as our algorithm works for general graphs, we
obtain an O(D k^{D-1} log n)-approximation algorithm for a D-shallow instance
of the k-edge-connected directed Steiner subgraph problem, where we wish to
connect every pair of terminals by k-edge-disjoint paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06566</identifier>
 <datestamp>2016-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06566</id><created>2015-11-20</created><updated>2016-02-10</updated><authors><author><keyname>Valkonen</keyname><forenames>Tuomo</forenames></author><author><keyname>Pock</keyname><forenames>Thomas</forenames></author></authors><title>Acceleration of the PDHGM on strongly convex subspaces</title><categories>math.OC cs.CV</categories><msc-class>90C25, 49M29, 94A08</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose several variants of the primal-dual method due to Chambolle and
Pock. Without requiring full strong convexity of the objective functions, our
methods are accelerated on subspaces with strong convexity. This yields mixed
rates, $O(1/N^2)$ with respect to initialisation and $O(1/N)$ with respect to
the dual sequence, and the residual part of the primal sequence. We demonstrate
the efficacy of the proposed methods on image processing problems lacking
strong convexity, such as total generalised variation denoising and total
variation deblurring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06568</identifier>
 <datestamp>2016-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06568</id><created>2015-11-20</created><updated>2016-01-23</updated><authors><author><keyname>Dvo&#x159;&#xe1;k</keyname><forenames>Tom&#xe1;&#x161;</forenames></author></authors><title>Matchings of quadratic size extend to long cycles in hypercubes</title><categories>cs.DM</categories><comments>9 pages, corrected typos, added clarifications, simplified notation</comments><msc-class>05C38, 05C45, 05C70</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ruskey and Savage in 1993 asked whether every matching in a hypercube can be
extended to a Hamiltonian cycle. A positive answer is known for perfect
matchings, but the general case has been resolved only for matchings of linear
size. In this paper we show that there is a quadratic function $f(n)$ such that
every matching in the $n$-dimensional hypercube of size at most $f(n)$ may be
extended to a cycle which covers at least $\frac34$ of the vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06569</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06569</id><created>2015-11-20</created><updated>2016-02-04</updated><authors><author><keyname>Fokkink</keyname><forenames>Robbert J.</forenames></author><author><keyname>Kraaikamp</keyname><forenames>Cor</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Hankel Matrices for the Period-Doubling Sequence</title><categories>math.CO cs.DM cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an explicit evaluation, in terms of products of Jacobsthal numbers,
of the Hankel determinants of order a power of two for the period-doubling
sequence. We also explicitly give the eigenvalues and eigenvectors of the
corresponding Hankel matrices. Similar considerations give the Hankel
determinants for other orders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06575</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06575</id><created>2015-11-20</created><updated>2015-11-23</updated><authors><author><keyname>Fuhl</keyname><forenames>Wolfgang</forenames></author><author><keyname>Santini</keyname><forenames>Thiago C.</forenames></author><author><keyname>Kuebler</keyname><forenames>Thomas</forenames></author><author><keyname>Kasneci</keyname><forenames>Enkelejda</forenames></author></authors><title>ElSe: Ellipse Selection for Robust Pupil Detection in Real-World
  Environments</title><categories>cs.CV</categories><acm-class>I.4.3; I.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fast and robust pupil detection is an essential prerequisite for video-based
eye-tracking in real-world settings. Several algorithms for image-based pupil
detection have been proposed, their applicability is mostly limited to
laboratory conditions. In realworld scenarios, automated pupil detection has to
face various challenges, such as illumination changes, reflections (on
glasses), make-up, non-centered eye recording, and physiological eye
characteristics. We propose ElSe, a novel algorithm based on ellipse evaluation
of a filtered edge image. We aim at a robust, resource-saving approach that can
be integrated in embedded architectures e.g. driving. The proposed algorithm
was evaluated against four state-of-the-art methods on over 93,000 hand-labeled
images from which 55,000 are new images contributed by this work. On average,
the proposed method achieved a 14.53% improvement on the detection rate
relative to the best state-of-the-art performer.
download:ftp://emmapupildata@messor.informatik.unituebingen. de
(password:eyedata).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06578</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06578</id><created>2015-11-20</created><authors><author><keyname>Keegan</keyname><forenames>Brian C.</forenames></author><author><keyname>Matias</keyname><forenames>J. Nathan</forenames></author></authors><title>Actually, It's About Ethics in Computational Social Science: A
  Multi-party Risk-Benefit Framework for Online Community Research</title><categories>cs.CY</categories><comments>5 pages, 1 figure; AAAI Spring Symp. on Observational Studies through
  Social Media and Other Human-Generated Content, 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Managers regularly face a complex ethical dilemma over how to best govern
online communities by evaluating the effectiveness of different social or
technical strategies. What ethical considerations should guide researchers and
managers when they employ causal research methods that make different community
members bear different risks and benefits, under different levels of consent?
We introduce a structural framework for evaluating the flows of risks and
benefits in social systems with multiple interacting parties. This framework
has implications for understanding the governmentality of managing
socio-technical systems, for making research ethics discussions more
commensurable, and for enumerating alternative goals researchers might pursue
with interventions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06581</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06581</id><created>2015-11-20</created><updated>2016-01-08</updated><authors><author><keyname>Wang</keyname><forenames>Ziyu</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author><author><keyname>Lanctot</keyname><forenames>Marc</forenames></author></authors><title>Dueling Network Architectures for Deep Reinforcement Learning</title><categories>cs.LG</categories><comments>14 pages, 6 figures, and 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years there have been many successes of using deep representations
in reinforcement learning. Still, many of these applications use conventional
architectures, such as convolutional networks, LSTMs, or auto-encoders. In this
paper, we present a new neural network architecture for model-free
reinforcement learning inspired by advantage learning. Our dueling architecture
represents two separate estimators: one for the state value function and one
for the state-dependent action advantage function. The main benefit of this
factoring is to generalize learning across actions without imposing any change
to the underlying reinforcement learning algorithm. Our results show that this
architecture leads to better policy evaluation in the presence of many
similar-valued actions. Moreover, the dueling architecture enables our RL agent
to outperform the state-of-the-art Double DQN method of van Hasselt et al.
(2015) in 46 out of 57 Atari games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06586</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06586</id><created>2015-11-20</created><authors><author><keyname>Kok</keyname><forenames>Ven Jyn</forenames></author><author><keyname>Lim</keyname><forenames>Mei Kuan</forenames></author><author><keyname>Chan</keyname><forenames>Chee Seng</forenames></author></authors><title>Crowd Behavior Analysis: A Review where Physics meets Biology</title><categories>cs.CV cs.AI cs.NE</categories><comments>Accepted in Neurocomputing, 31 pages, 180 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although the traits emerged in a mass gathering are often non-deliberative,
the act of mass impulse may lead to irre- vocable crowd disasters. The two-fold
increase of carnage in crowd since the past two decades has spurred significant
advances in the field of computer vision, towards effective and proactive crowd
surveillance. Computer vision stud- ies related to crowd are observed to
resonate with the understanding of the emergent behavior in physics (complex
systems) and biology (animal swarm). These studies, which are inspired by
biology and physics, share surprisingly common insights, and interesting
contradictions. However, this aspect of discussion has not been fully explored.
Therefore, this survey provides the readers with a review of the
state-of-the-art methods in crowd behavior analysis from the physics and
biologically inspired perspectives. We provide insights and comprehensive
discussions for a broader understanding of the underlying prospect of blending
physics and biology studies in computer vision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06591</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06591</id><created>2015-11-20</created><authors><author><keyname>Gruzitis</keyname><forenames>Normunds</forenames></author><author><keyname>Barzdins</keyname><forenames>Guntis</forenames></author></authors><title>Polysemy in Controlled Natural Language Texts</title><categories>cs.CL</categories><journal-ref>Lecture Notes in Computer Science, Vol. 5972, Springer, 2010, pp.
  102-120</journal-ref><doi>10.1007/978-3-642-14418-9_7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational semantics and logic-based controlled natural languages (CNL) do
not address systematically the word sense disambiguation problem of content
words, i.e., they tend to interpret only some functional words that are crucial
for construction of discourse representation structures. We show that
micro-ontologies and multi-word units allow integration of the rich and
polysemous multi-domain background knowledge into CNL thus providing
interpretation for the content words. The proposed approach is demonstrated by
extending the Attempto Controlled English (ACE) with polysemous and procedural
constructs resulting in a more natural CNL named PAO covering narrative
multi-domain texts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06594</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06594</id><created>2015-11-20</created><authors><author><keyname>Khan</keyname><forenames>Khalid</forenames></author><author><keyname>Lobiyal</keyname><forenames>D. K.</forenames></author><author><keyname>Kilicman</keyname><forenames>Adem</forenames></author></authors><title>Bezier curves and surfaces based on modified Bernstein polynomials</title><categories>cs.GR</categories><comments>11 pages, 2 figures. arXiv admin note: substantial text overlap with
  arXiv:1507.04110</comments><msc-class>65D17, 41A10, 41A25, 41A36</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use the blending functions of Bernstein polynomials with
shifted knots for construction of Bezier curves and surfaces. We study the
nature of degree elevation and degree reduction for Bezier Bernstein functions
with shifted knots.
  Parametric curves are represented using these modified Bernstein basis and
the concept of total positivity is applied to investigate the shape properties
of the curve. We get Bezier curve defined on [0, 1] when we set the parameter
\alpha=\beta to the value 0. We also present a de Casteljau algorithm to
compute Bernstein Bezier curves and surfaces with shifted knots. The new curves
have some properties similar to Bezier curves. Furthermore, some fundamental
properties for Bernstein Bezier curves and surfaces are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06603</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06603</id><created>2015-11-20</created><authors><author><keyname>Zand</keyname><forenames>Ghazal</forenames></author><author><keyname>Taherkhani</keyname><forenames>Mojtaba</forenames></author><author><keyname>Safabakhsh</keyname><forenames>Reza</forenames></author></authors><title>Exponential Natural Particle Filter</title><categories>cs.LG cs.NE cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Particle Filter algorithm (PF) suffers from some problems such as the loss of
particle diversity, the need for large number of particles, and the costly
selection of the importance density functions. In this paper, a novel
Exponential Natural Particle Filter (xNPF) is introduced to solve the above
problems. In this approach, a state transitional probability with the use of
natural gradient learning is proposed which balances exploration and
exploitation more robustly. The results show that xNPF converges much closer to
the true target states than the other state of the art particle filter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06606</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06606</id><created>2015-11-20</created><updated>2016-02-23</updated><authors><author><keyname>Paskov</keyname><forenames>Hristo S.</forenames></author><author><keyname>Mitchell</keyname><forenames>John C.</forenames></author><author><keyname>Hastie</keyname><forenames>Trevor J.</forenames></author></authors><title>Data Representation and Compression Using Linear-Programming
  Approximations</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose `Dracula', a new framework for unsupervised feature selection from
sequential data such as text. Dracula learns a dictionary of $n$-grams that
efficiently compresses a given corpus and recursively compresses its own
dictionary; in effect, Dracula is a `deep' extension of Compressive Feature
Learning. It requires solving a binary linear program that may be relaxed to a
linear program. Both problems exhibit considerable structure, their solution
paths are well behaved, and we identify parameters which control the depth and
diversity of the dictionary. We also discuss how to derive features from the
compressed documents and show that while certain unregularized linear models
are invariant to the structure of the compressed dictionary, this structure may
be used to regularize learning. Experiments are presented that demonstrate the
efficacy of Dracula's features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06613</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06613</id><created>2015-11-20</created><authors><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames></author></authors><title>Probabilistic Diffusion in Random Network Graphs</title><categories>cs.SI physics.soc-ph</categories><comments>7 papers; 5 figures</comments><journal-ref>International Journal in Foundations of Computer Science and
  Technology (IJFCST), vol. 5, no. 5, pp. 1-7, September 2015</journal-ref><doi>10.5121/ijfcst.2015.5501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a random network such that there could be a link
between any two nodes in the network with a certain probability (plink).
Diffusion is the phenomenon of spreading information throughout the network,
starting from one or more initial set of nodes (called the early adopters).
Information spreads along the links with a certain probability (pdiff).
Diffusion happens in rounds with the first round involving the early adopters.
The nodes that receive the information for the first time are said to be
covered and become candidates for diffusion in the subsequent round. Diffusion
continues until all the nodes in the network have received the information
(successful diffusion) or there are no more candidate nodes to spread the
information but one or more nodes are yet to receive the information (diffusion
failure). On the basis of exhaustive simulations conducted in this paper, we
observe that for a given plink and pdiff values, the fraction of successful
diffusion attempts does not appreciably change with increase in the number of
early adopters; whereas, the average number of rounds per successful diffusion
attempt decreases with increase in the number of early adopters. The invariant
nature of the fraction of successful diffusion attempts with increase in the
number of early adopters for a random network (for fixed plink and pdiff
values) is an interesting and noteworthy observation (for further research) and
it has not been hitherto reported in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06620</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06620</id><created>2015-11-20</created><authors><author><keyname>Meghanathan</keyname><forenames>Natarajan</forenames></author></authors><title>Use of Eigenvector Centrality to Detect Graph Isomorphism</title><categories>cs.SI cs.DM cs.DS</categories><comments>9 pages, 4 figures; Proceedings of the Fourth International
  Conference on Advanced Information Technologies and Applications (ICAITA),
  pp. 1-9, Dubai, UAE, November 6-7, 2015</comments><doi>10.5121/csit.2015.51501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph Isomorphism is one of the classical problems of graph theory for which
no deterministic polynomial-time algorithm is currently known, but has been
neither proven to be NP-complete. Several heuristic algorithms have been
proposed to determine whether or not two graphs are isomorphic (i.e.,
structurally the same). In this research, we propose to use the sequence
(either the non-decreasing or nonincreasing order) of eigenvector centrality
(EVC) values of the vertices of two graphs as a precursor step to decide
whether or not to further conduct tests for graph isomorphism. The eigenvector
centrality of a vertex in a graph is a measure of the degree of the vertex as
well as the degrees of its neighbors. We hypothesize that if the non-increasing
(or non-decreasing) order of listings of the EVC values of the vertices of two
test graphs are not the same, then the two graphs are not isomorphic. If two
test graphs have an identical non-increasing order of the EVC sequence, then
they are declared to be potentially isomorphic and confirmed through additional
heuristics. We test our hypothesis on random graphs (generated according to the
Erdos-Renyi model) and we observe the hypothesis to be indeed true: graph pairs
that have the same sequence of non-increasing order of EVC values have been
confirmed to be isomorphic using the well-known Nauty software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06624</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06624</id><created>2015-11-20</created><authors><author><keyname>Meng</keyname><forenames>Ting Wei</forenames></author><author><keyname>Choi</keyname><forenames>Pui Tung</forenames></author><author><keyname>Lui</keyname><forenames>Lok Ming</forenames></author></authors><title>TEMPO: Feature-Endowed Teichm\&quot;{u}ller Extremal Mappings of Point Clouds</title><categories>cs.CG cs.CV cs.GR math.DG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent decades, the use of 3D point clouds has been widespread in computer
industry. The development of techniques in analyzing point clouds is
increasingly important. In particular, mapping of point clouds has been a
challenging problem. In this paper, we develop a discrete analogue of the
Teichm\&quot;{u}ller extremal mappings, which guarantee uniform conformality
distortions, on point cloud surfaces. Based on the discrete analogue, we
propose a novel method called TEMPO for computing Teichm\&quot;{u}ller extremal
mappings between feature-endowed point clouds. Using our proposed method, the
Teichm\&quot;{u}ller metric is introduced for evaluating the dissimilarity of point
clouds. Consequently, our algorithm enables accurate recognitions and
classifications of point clouds. Experimental results demonstrate the
effectiveness of our proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06627</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06627</id><created>2015-11-20</created><authors><author><keyname>Zhu</keyname><forenames>Shizhan</forenames></author><author><keyname>Li</keyname><forenames>Cheng</forenames></author><author><keyname>Loy</keyname><forenames>Chen Change</forenames></author><author><keyname>Tang</keyname><forenames>Xiaoou</forenames></author></authors><title>Towards Arbitrary-View Face Alignment by Recommendation Trees</title><categories>cs.CV</categories><comments>This is our original submission to ICCV 2015</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Learning to simultaneously handle face alignment of arbitrary views, e.g.
frontal and profile views, appears to be more challenging than we thought. The
difficulties lay in i) accommodating the complex appearance-shape relations
exhibited in different views, and ii) encompassing the varying landmark point
sets due to self-occlusion and different landmark protocols. Most existing
studies approach this problem via training multiple viewpoint-specific models,
and conduct head pose estimation for model selection. This solution is
intuitive but the performance is highly susceptible to inaccurate head pose
estimation. In this study, we address this shortcoming through learning an
Ensemble of Model Recommendation Trees (EMRT), which is capable of selecting
optimal model configuration without prior head pose estimation. The unified
framework seamlessly handles different viewpoints and landmark protocols, and
it is trained by optimising directly on landmark locations, thus yielding
superior results on arbitrary-view face alignment. This is the first study that
performs face alignment on the full AFLWdataset with faces of different views
including profile view. State-of-the-art performances are also reported on
MultiPIE and AFW datasets containing both frontaland profile-view faces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06631</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06631</id><created>2015-11-20</created><authors><author><keyname>Ehrhardt</keyname><forenames>Matthias J.</forenames></author><author><keyname>Betcke</keyname><forenames>Marta M.</forenames></author></authors><title>Multi-Contrast MRI Reconstruction with Structure-Guided Total Variation</title><categories>math.NA cs.CV math.OC</categories><comments>18 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Magnetic resonance imaging (MRI) is a versatile imaging technique that allows
different contrasts depending on the acquisition parameters. Many clinical
imaging studies acquire MRI data for more than one of these contrasts---such as
for instance T1 and T2 weighted images---which makes the overall scanning
procedure very time consuming. As all of these images show the same underlying
anatomy one can try to omit unnecessary measurements by taking the similarity
into account during reconstruction. We will discuss two modifications of total
variation---based on i) location and ii) direction---that take structural a
priori knowledge into account and reduce to total variation in the degenerate
case when no structural knowledge is available. We solve the resulting convex
minimization problem with the alternating direction method of multipliers that
separates the forward operator from the prior. For both priors the
corresponding proximal operator can be implemented as an extension of the fast
gradient projection method on the dual problem for total variation. We tested
the priors on six data sets that are based on phantoms and real MRI images. In
all test cases exploiting the structural information from the other contrast
yields better results than separate reconstruction with total variation in
terms of standard metrics like peak signal-to-noise ratio and structural
similarity index. Furthermore, we found that exploiting the two dimensional
directional information results in images with well defined edges, superior to
those reconstructed solely using a priori information about the edge location.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06639</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06639</id><created>2015-11-20</created><authors><author><keyname>Zebadua</keyname><forenames>Augusto</forenames></author><author><keyname>Amblard</keyname><forenames>Pierre-Olivier</forenames></author><author><keyname>Moisan</keyname><forenames>Eric</forenames></author><author><keyname>Michel</keyname><forenames>Olivier . J. J.</forenames></author></authors><title>Compressed and quantized correlation estimators</title><categories>stat.AP cs.IT math.IT</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In passive monitoring using sensor networks, low energy supplies drastically
constrain sensors in terms of calculation and communication abilities.
Designing processing algorithms at the sensor level that take into account
these constraints is an important problem in this context. We study here the
estimation of correlation functions between sensors using compressed
acquisition and one-bit-quantization. The estimation is achieved directly using
compressed samples, without considering any reconstruction of the signals. We
show that if the signals of interest are far from white noise, estimation of
the correlation using $M$ compressed samples out of $N\geq M$ can be more
advantageous than estimation of the correlation using $M$ consecutive samples.
The analysis consists of studying the asymptotic performance of the estimators
at a fixed compression rate. We provide the analysis when the compression is
realized by a random projection matrix composed of independent and identically
distributed entries. The framework includes widely used random projection
matrices, such as Gaussian and Bernoulli matrices, and it also includes very
sparse matrices. However, it does not include subsampling without replacement,
for which a separate analysis is provided. When considering
one-bit-quantization as well, the theoretical analysis is not tractable.
However, empirical evidence allows the conclusion that in practical situations,
compressed and quantized estimators behave sufficiently correctly to be useful
in, for example, time-delay estimation and model estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06641</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06641</id><created>2015-11-20</created><authors><author><keyname>Vazquez</keyname><forenames>Rafael</forenames></author><author><keyname>Krstic</keyname><forenames>Miroslav</forenames></author></authors><title>Boundary Control of Reaction-Diffusion PDEs on Balls in Spaces of
  Arbitrary Dimensions</title><categories>math.OC cs.SY</categories><comments>Submitted to ESAIM: Control and Calculus of Variations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An explicit output-feedback boundary feedback law is introduced that
stabilizes an unstable linear constant-coefficient reaction-diffusion equation
on an $n$-ball (which in 2-D reduces to a disk and in 3-D reduces to a sphere)
using only measurements from the boundary. The backstepping method is used to
design both the control law and a boundary observer. To apply backstepping the
system is reduced to an infinite sequence of 1-D systems using spherical
harmonics. Well-posedness and stability are proved in the $H^1$ space. The
resulting control and output injection gain kernels are the product of the
backstepping kernel used in control of one-dimensional reaction-diffusion
equations and a function closely related to the Poisson kernel in the $n$-ball.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06644</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06644</id><created>2015-11-20</created><updated>2016-02-24</updated><authors><author><keyname>Mattos</keyname><forenames>C&#xe9;sar Lincoln C.</forenames></author><author><keyname>Dai</keyname><forenames>Zhenwen</forenames></author><author><keyname>Damianou</keyname><forenames>Andreas</forenames></author><author><keyname>Forth</keyname><forenames>Jeremy</forenames></author><author><keyname>Barreto</keyname><forenames>Guilherme A.</forenames></author><author><keyname>Lawrence</keyname><forenames>Neil D.</forenames></author></authors><title>Recurrent Gaussian Processes</title><categories>cs.LG stat.ML</categories><comments>Published as a conference paper at ICLR 2016. 12 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define Recurrent Gaussian Processes (RGP) models, a general family of
Bayesian nonparametric models with recurrent GP priors which are able to learn
dynamical patterns from sequential data. Similar to Recurrent Neural Networks
(RNNs), RGPs can have different formulations for their internal states,
distinct inference methods and be extended with deep structures. In such
context, we propose a novel deep RGP model whose autoregressive states are
latent, thereby performing representation and dynamical learning
simultaneously. To fully exploit the Bayesian nature of the RGP model we
develop the Recurrent Variational Bayes (REVARB) framework, which enables
efficient inference and strong regularization through coherent propagation of
uncertainty across the RGP layers and states. We also introduce a RGP extension
where variational parameters are greatly reduced by being reparametrized
through RNN-based sequential recognition models. We apply our model to the
tasks of nonlinear system identification and human motion modeling. The
promising obtained results indicate that our RGP model maintains its highly
flexibility while being able to avoid overfitting and being applicable even
when larger datasets are not available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06645</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06645</id><created>2015-11-20</created><authors><author><keyname>Pishchulin</keyname><forenames>Leonid</forenames></author><author><keyname>Insafutdinov</keyname><forenames>Eldar</forenames></author><author><keyname>Tang</keyname><forenames>Siyu</forenames></author><author><keyname>Andres</keyname><forenames>Bjoern</forenames></author><author><keyname>Andriluka</keyname><forenames>Mykhaylo</forenames></author><author><keyname>Gehler</keyname><forenames>Peter</forenames></author><author><keyname>Schiele</keyname><forenames>Bernt</forenames></author></authors><title>DeepCut: Joint Subset Partition and Labeling for Multi Person Pose
  Estimation</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the task of articulated human pose estimation of
multiple people in real-world images. We propose an approach that jointly
solves the tasks of detection and pose estimation: it infers the number of
persons in a scene, identifies occluded body parts, and disambiguates body
parts between people in close proximity of each other. This joint formulation
is in contrast to previous strategies, that address the problem by first
detecting people and subsequently estimating their body pose. We propose a
partitioning and labeling formulation of a set of body-part hypotheses
generated with CNN-based part detectors. Our formulation, an instance of an
integer linear program, implicitly performs non-maximum suppression on the set
of part candidates and groups them to form configurations of body parts
respecting geometric and appearance constraints. Experiments on four different
datasets demonstrate state-of-the-art results for both single person and multi
person pose estimation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06653</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06653</id><created>2015-11-20</created><authors><author><keyname>Harvey</keyname><forenames>F&#xe9;lix G.</forenames></author><author><keyname>Pal</keyname><forenames>Christopher</forenames></author></authors><title>Semi-supervised Learning with Encoder-Decoder Recurrent Neural Networks:
  Experiments with Motion Capture Sequences</title><categories>cs.CV cs.LG</categories><comments>Submitted for review for ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work on sequence to sequence translation using Recurrent Neural
Networks (RNNs) based on Long Short Term Memory (LSTM) architectures has shown
great potential for learning useful representations of sequential data. These
architectures, using one recurrent neural network to encode sequences into
fixed-length representations, and one or more network(s) to decode
representations into new sequences have the advantages of being modular, while
also allowing modules to be jointly trained. A one-to-many encoder-decoder(s)
scheme allows for a single encoder to provide representations serving multiple
purposes. In our case, we present an LSTM encoder network able to produce
representations used by two decoders: one that reconstructs, and one that
classifies if the training sequence has a labelling. This allows the network to
learn representations that are useful for both discriminative and generative
tasks at the same time. We show how this paradigm is very well suited for
semi-supervised learning with sequences. We test our proposed approach on an
action recognition task using motion capture (MOCAP) sequences and show that
semi-supervised feature learning can improve movement classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06654</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06654</id><created>2015-11-20</created><authors><author><keyname>Wang</keyname><forenames>Bing</forenames></author><author><keyname>Wang</keyname><forenames>Gang</forenames></author><author><keyname>Chan</keyname><forenames>Kap Luk</forenames></author><author><keyname>Wang</keyname><forenames>Li</forenames></author></authors><title>Tracklet Association by Online Target-Specific Metric Learning and
  Coherent Dynamics Estimation</title><categories>cs.CV</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel method based on online target-specific
metric learning and coherent dynamics estimation for tracklet (track fragment)
association by network flow optimization in long-term multi-person tracking.
Our proposed framework aims to exploit appearance and motion cues to prevent
identity switches during tracking and to recover missed detections.
Furthermore, target-specific metrics (appearance cue) and motion dynamics
(motion cue) are proposed to be learned and estimated online, i.e. during the
tracking process. Our approach is effective even when such cues fail to
identify or follow the target due to occlusions or object-to-object
interactions.We also propose to learn the weights of these two tracking cues to
handle the difficult situations, such as severe occlusions and object-to-object
interactions effectively. Our method has been validated on several public
datasets and the experimental results show that it outperforms several
state-of-the-art tracking methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06656</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06656</id><created>2015-11-20</created><authors><author><keyname>Sarraute</keyname><forenames>Carlos</forenames></author><author><keyname>Blanc</keyname><forenames>Pablo</forenames></author><author><keyname>Burroni</keyname><forenames>Javier</forenames></author></authors><title>A Study of Age and Gender seen through Mobile Phone Usage Patterns in
  Mexico</title><categories>cs.SI physics.soc-ph</categories><journal-ref>Proc. 2014 IEEE/ACM International Conference on Advances in Social
  Networks Analysis and Mining (ASONAM), Beijing, China, 17-20 August 2014, pp.
  836 - 843</journal-ref><doi>10.1109/ASONAM.2014.6921683</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Mobile phone usage provides a wealth of information, which can be used to
better understand the demographic structure of a population. In this paper we
focus on the population of Mexican mobile phone users. Our first contribution
is an observational study of mobile phone usage according to gender and age
groups. We were able to detect significant differences in phone usage among
different subgroups of the population. Our second contribution is to provide a
novel methodology to predict demographic features (namely age and gender) of
unlabeled users by leveraging individual calling patterns, as well as the
structure of the communication graph. We provide details of the methodology and
show experimental results on a real world dataset that involves millions of
users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06660</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06660</id><created>2015-11-20</created><updated>2016-02-13</updated><authors><author><keyname>Felbo</keyname><forenames>Bjarke</forenames></author><author><keyname>Sunds&#xf8;y</keyname><forenames>P&#xe5;l</forenames></author><author><keyname>Pentland</keyname><forenames>Alex 'Sandy'</forenames></author><author><keyname>Lehmann</keyname><forenames>Sune</forenames></author><author><keyname>de Montjoye</keyname><forenames>Yves-Alexandre</forenames></author></authors><title>Using Deep Learning to Predict Demographics from Mobile Phone Metadata</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile phone metadata are increasingly used to study human behavior at
large-scale. There has recently been a growing interest in predicting
demographic information from metadata. Previous approaches relied on
hand-engineered features. We here apply, for the first time, deep learning
methods to mobile phone metadata using a convolutional network. Our method
provides high accuracy on both age and gender prediction. These results show
great potential for deep learning approaches for prediction tasks using
standard mobile phone metadata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06663</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06663</id><created>2015-11-20</created><authors><author><keyname>Talenti</keyname><forenames>Luca</forenames></author><author><keyname>Luck</keyname><forenames>Margaux</forenames></author><author><keyname>Yartseva</keyname><forenames>Anastasia</forenames></author><author><keyname>Argy</keyname><forenames>Nicolas</forenames></author><author><keyname>Houz&#xe9;</keyname><forenames>Sandrine</forenames></author><author><keyname>Damon</keyname><forenames>Cecilia</forenames></author></authors><title>L1 logistic regression as a feature selection step for training stable
  classification trees for the prediction of severity criteria in imported
  malaria</title><categories>cs.LG q-bio.QM stat.AP</categories><comments>18 pages, 10 figures, ICLR, computational science - Learning,
  Imported Malaria, L1 logistic regression, Decision tree</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multivariate classification methods using explanatory and predictive models
are necessary for characterizing subgroups of patients according to their risk
profiles. Popular methods include logistic regression and classification trees
with performances that vary according to the nature and the characteristics of
the dataset. In the context of imported malaria, we aimed at classifying
severity criteria based on a heterogeneous patient population. We investigated
these approaches by implementing two different strategies: L1 logistic
regression (L1LR) that models a single global solution and classification trees
that model multiple local solutions corresponding to discriminant subregions of
the feature space. For each strategy, we built a standard model, and a sparser
version of it. As an alternative to pruning, we explore a promising approach
that first constrains the tree model with an L1LR-based feature selection, an
approach we called L1LR-Tree. The objective is to decrease its vulnerability to
small data variations by removing variables corresponding to unstable local
phenomena. Our study is twofold: i) from a methodological perspective comparing
the performances and the stability of the three previous methods, i.e L1LR,
classification trees and L1LR-Tree, for the classification of severe forms of
imported malaria, and ii) from an applied perspective improving the actual
classification of severe forms of imported malaria by identifying more
personalized profiles predictive of several clinical criteria based on
variables dismissed for the clinical definition of the disease. The main
methodological results show that the combined method L1LR-Tree builds sparse
and stable models that significantly predicts the different severity criteria
and outperforms all the other methods in terms of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06668</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06668</id><created>2015-11-20</created><authors><author><keyname>Kafle</keyname><forenames>Bishoksan</forenames></author></authors><title>Solving non-linear Horn clauses using a linear solver</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developing an efficient non-linear Horn clause solver is a challenging task
since the solver has to reason about the tree structures rather than the linear
ones as in a linear solver. In this paper we propose an incremental approach to
solving a set of non-linear Horn clauses using a linear Horn clause solver. We
achieve this by interleaving a program transformation and a linear solver. The
program transformation is based on the notion of tree dimension, which we apply
to trees corresponding to Horn clause derivations. The dimension of a tree is a
measure of its non-linearity -- for example a linear tree (whose nodes have at
most one child) has dimension zero while a complete binary tree has dimension
equal to its height.
  A given set of Horn clauses $P$ can be transformed into a new set of clauses
$P^k$ (whose derivation trees are the subset of $P$'s derivation trees with
dimension at most $k$). We start by generating $P^k$ with $k=0$, which is
linear by definition, then pass it to a linear solver. If $P^k$ has a solution
$M$, and is a solution to $P$ then $P$ has a solution $M$. If $M$ is not a
solution of $P$, we plugged $M$ to $P^{(k+1)}$ which again becomes linear and
pass it to the solver and continue successively for increasing value of $k$
until we find a solution to $P$ or resources are exhausted. Experiment on some
Horn clause verification benchmarks indicates that this is a promising approach
for solving a set of non-linear Horn clauses using a linear solver. It
indicates that many times a solution obtained for some under-approximation
$P^k$ of $P$ becomes a solution for $P$ for a fairly small value of $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06669</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06669</id><created>2015-11-20</created><authors><author><keyname>de Lamare</keyname><forenames>Rodrigo C.</forenames></author></authors><title>Study of Sparsity-Aware Distributed Conjugate Gradient Algorithms for
  Sensor Networks</title><categories>cs.IT math.IT</categories><comments>1 figure, 7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes distributed adaptive algorithms based on the conjugate
gradient (CG) method and the diffusion strategy for parameter estimation over
sensor networks. We present sparsity-aware conventional and modified
distributed CG algorithms using $l_{1}$ and log-sum penalty functions. The
proposed sparsity-aware diffusion distributed CG algorithms have an improved
performance in terms of mean square deviation (MSD) and convergence as compared
with the consensus least-mean square (Diffusion-LMS) algorithm, the diffusion
CG algorithms and a close performance to the diffusion distributed recursive
least squares (Consensus-RLS) algorithm. Numerical results show that the
proposed algorithms are reliable and can be applied in several scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06674</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06674</id><created>2015-11-20</created><authors><author><keyname>Goyal</keyname><forenames>Anirudh</forenames></author><author><keyname>Leordeanu</keyname><forenames>Marius</forenames></author></authors><title>Stories in the Eye: Contextual Visual Interactions for Efficient Video
  to Language Translation</title><categories>cs.CV cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Integrating higher level visual and linguistic interpretations is at the
heart of human intelligence. As automatic visual category recognition in images
is approaching human performance, the high level understanding in the dynamic
spatiotemporal domain of videos and its translation into natural language is
still far from being solved. While most works on vision-to-text translations
use pre-learned or pre-established computational linguistic models, in this
paper we present an approach that uses vision alone to efficiently learn how to
translate into language the video content. We discover, in simple form, the
story played by main actors, while using only visual cues for representing
objects and their interactions. Our method learns in a hierarchical manner
higher level representations for recognizing subjects, actions and objects
involved, their relevant contextual background and their interaction to one
another over time. We have a three stage approach: first we take in
consideration features of the individual entities at the local level of
appearance, then we consider the relationship between these objects and actions
and their video background, and third, we consider their spatiotemporal
relations as inputs to classifiers at the highest level of interpretation.
Thus, our approach finds a coherent linguistic description of videos in the
form of a subject, verb and object based on their role played in the overall
visual story learned directly from training data, without using a known
language model. We test the efficiency of our approach on a large scale dataset
containing YouTube clips taken in the wild and demonstrate state-of-the-art
performance, often superior to current approaches that use more complex,
pre-learned linguistic knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06676</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06676</id><created>2015-11-20</created><authors><author><keyname>Charles</keyname><forenames>James</forenames></author><author><keyname>Pfister</keyname><forenames>Tomas</forenames></author><author><keyname>Magee</keyname><forenames>Derek</forenames></author><author><keyname>Hogg</keyname><forenames>David</forenames></author><author><keyname>Zisserman</keyname><forenames>Andrew</forenames></author></authors><title>Personalizing Human Video Pose Estimation</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a personalized ConvNet pose estimator that automatically adapts
itself to the uniqueness of a person's appearance to improve pose estimation in
long videos. We make the following contributions: (i) we show that given a few
high-precision pose annotations, e.g. from a generic ConvNet pose estimator,
additional annotations can be generated throughout the video using a
combination of image-based matching for temporally distant frames, and dense
optical flow for temporally local frames; (ii) we develop an occlusion aware
self-evaluation model that is able to automatically select the high-quality and
reject the erroneous additional annotations; and (iii) we demonstrate that
these high-quality annotations can be used to fine-tune a ConvNet pose
estimator and thereby personalize it to lock on to key discriminative features
of the person's appearance. The outcome is a substantial improvement in the
pose estimates for the target video using the personalized ConvNet compared to
the original generic ConvNet. Our method outperforms the state of the art
(including top ConvNet methods) by a large margin on two standard benchmarks,
as well as on a new challenging YouTube video dataset. Furthermore, we show
that training from the automatically generated annotations can be used to
improve the performance of a generic ConvNet on other benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06681</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06681</id><created>2015-11-20</created><authors><author><keyname>Tran</keyname><forenames>Du</forenames></author><author><keyname>Bourdev</keyname><forenames>Lubomir</forenames></author><author><keyname>Fergus</keyname><forenames>Rob</forenames></author><author><keyname>Torresani</keyname><forenames>Lorenzo</forenames></author><author><keyname>Paluri</keyname><forenames>Manohar</forenames></author></authors><title>Deep End2End Voxel2Voxel Prediction</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the last few years deep learning methods have emerged as one of the most
prominent approaches for video analysis. However, so far their most successful
applications have been in the area of video classification and detection, i.e.,
problems involving the prediction of a single class label or a handful of
output variables per video. Furthermore, while deep networks are commonly
recognized as the best models to use in these domains, there is a widespread
perception that in order to yield successful results they often require
time-consuming architecture search, manual tweaking of parameters and
computationally intensive pre-processing or post-processing methods.
  In this paper we challenge these views by presenting a deep 3D convolutional
architecture trained end to end to perform voxel-level prediction, i.e., to
output a variable at every voxel of the video. Most importantly, we show that
the same exact architecture can be used to achieve competitive results on three
widely different voxel-prediction tasks: video semantic segmentation, optical
flow estimation, and video coloring. The three networks learned on these
problems are trained from raw video without any form of preprocessing and their
outputs do not require post-processing to achieve outstanding performance.
Thus, they offer an efficient alternative to traditional and much more
computationally expensive methods in these video domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06683</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06683</id><created>2015-11-20</created><authors><author><keyname>Lapin</keyname><forenames>Maksim</forenames></author><author><keyname>Hein</keyname><forenames>Matthias</forenames></author><author><keyname>Schiele</keyname><forenames>Bernt</forenames></author></authors><title>Top-k Multiclass SVM</title><categories>stat.ML cs.CV cs.LG</categories><comments>NIPS 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Class ambiguity is typical in image classification problems with a large
number of classes. When classes are difficult to discriminate, it makes sense
to allow k guesses and evaluate classifiers based on the top-k error instead of
the standard zero-one loss. We propose top-k multiclass SVM as a direct method
to optimize for top-k performance. Our generalization of the well-known
multiclass SVM is based on a tight convex upper bound of the top-k error. We
propose a fast optimization scheme based on an efficient projection onto the
top-k simplex, which is of its own interest. Experiments on five datasets show
consistent improvements in top-k accuracy compared to various baselines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06692</identifier>
 <datestamp>2015-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06692</id><created>2015-11-20</created><updated>2015-12-13</updated><authors><author><keyname>Tekin</keyname><forenames>Bugra</forenames></author><author><keyname>Rozantsev</keyname><forenames>Artem</forenames></author><author><keyname>Lepetit</keyname><forenames>Vincent</forenames></author><author><keyname>Fua</keyname><forenames>Pascal</forenames></author></authors><title>Direct Prediction of 3D Body Poses from Motion Compensated Sequences</title><categories>cs.CV</categories><comments>supersedes arXiv:1504.08200</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an efficient approach to exploiting motion information from
consecutive frames of a video sequence to recover the 3D pose of people.
Previous approaches typically compute candidate poses in individual frames and
then link them in a post-processing step to resolve ambiguities. By contrast,
we directly regress from a spatio-temporal volume of bounding boxes to a 3D
pose in the central frame.
  We further show that, for this approach to achieve its full potential, it is
essential to compensate for the motion in consecutive frames so that the
subject remains centered. This then allows us to effectively overcome
ambiguities and improve upon the state-of-the-art by a large margin on the
Human3.6m, HumanEva, and KTH Multiview Football 3D human pose estimation
benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06702</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06702</id><created>2015-11-20</created><authors><author><keyname>Tatarchenko</keyname><forenames>Maxim</forenames></author><author><keyname>Dosovitskiy</keyname><forenames>Alexey</forenames></author><author><keyname>Brox</keyname><forenames>Thomas</forenames></author></authors><title>Single-view to Multi-view: Reconstructing Unseen Views with a
  Convolutional Network</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a convolutional network capable of generating images of a
previously unseen object from arbitrary viewpoints given a single image of this
object. The input to the network is a single image and the desired new
viewpoint; the output is a view of the object from this desired viewpoint. The
network is trained on renderings of synthetic 3D models. It learns an implicit
3D representation of the object class, which allows it to transfer shape
knowledge from training instances to a new object instance. Beside the color
image, the network can also generate the depth map of an object from arbitrary
viewpoints. This allows us to predict 3D point clouds from a single image,
which can be fused into a surface mesh. We experimented with cars and chairs.
Even though the network is trained on artificial data, it generalizes well to
objects in natural images without any modifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06703</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06703</id><created>2015-11-20</created><authors><author><keyname>Hillyard</keyname><forenames>Peter</forenames><affiliation>Department of Electrical and Computer Engineering, University of Utah</affiliation></author><author><keyname>Maas</keyname><forenames>Dustin</forenames><affiliation>Xandem Technology</affiliation></author><author><keyname>Premnath</keyname><forenames>Sriram</forenames><affiliation>Qualcomm Research</affiliation></author><author><keyname>Patwari</keyname><forenames>Neal</forenames><affiliation>Department of Electrical and Computer Engineering, University of Utah</affiliation><affiliation>Xandem Technology</affiliation></author><author><keyname>Kasera</keyname><forenames>Sneha</forenames><affiliation>School of Computing, University of Utah</affiliation></author></authors><title>Through-Wall Person Localization Using Transceivers in Motion</title><categories>cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop novel methods for device-free localization (DFL) using
transceivers in motion. Such localization technologies are useful in various
cross-layer applications/protocols including those that are related to security
situations where it is important to know the presence and position of an
unauthorized person; in monitoring the daily activities of elderly or special
needs individuals; or in emergency situations when police or firefighters can
use the locations of people inside of a building in order to save lives. We
propose that transceivers mounted on autonomous vehicles could be both quickly
deployed and kept moving to ``sweep'' an area for changes in the channel that
would indicate the location of moving people and objects. The challenge is that
changes to channel measurements are introduced both by changes in the
environment and from motion of the transceivers. In this paper, we demonstrate
a method to detect human movement despite transceiver motion using
ultra-wideband impulse radar (UWB-IR) transceivers. The measurements reliably
detect a person's presence on a link line despite small-scale fading. We
explore via multiple experiments the ability of mobile UWB-IR transceivers,
moving outside of the walls of a room, to measure many lines crossing through
the room and accurately locate a person inside within 0.25 m average error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06704</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06704</id><created>2015-11-20</created><authors><author><keyname>Penatti</keyname><forenames>Ot&#xe1;vio A. B.</forenames></author><author><keyname>Avila</keyname><forenames>Sandra</forenames></author><author><keyname>Valle</keyname><forenames>Eduardo</forenames></author><author><keyname>Torres</keyname><forenames>Ricardo da S.</forenames></author></authors><title>Semantic Diversity versus Visual Diversity in Visual Dictionaries</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Visual dictionaries are a critical component for image
classification/retrieval systems based on the bag-of-visual-words (BoVW) model.
Dictionaries are usually learned without supervision from a training set of
images sampled from the collection of interest. However, for large,
general-purpose, dynamic image collections (e.g., the Web), obtaining a
representative sample in terms of semantic concepts is not straightforward. In
this paper, we evaluate the impact of semantics in the dictionary quality,
aiming at verifying the importance of semantic diversity in relation visual
diversity for visual dictionaries. In the experiments, we vary the amount of
classes used for creating the dictionary and then compute different BoVW
descriptors, using multiple codebook sizes and different coding and pooling
methods (standard BoVW and Fisher Vectors). Results for image classification
show that as visual dictionaries are based on low-level visual appearances,
visual diversity is more important than semantic diversity. Our conclusions
open the opportunity to alleviate the burden in generating visual dictionaries
as we need only a visually diverse set of images instead of the whole
collection to create a good dictionary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06709</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06709</id><created>2015-11-20</created><authors><author><keyname>Sennrich</keyname><forenames>Rico</forenames></author><author><keyname>Haddow</keyname><forenames>Barry</forenames></author><author><keyname>Birch</keyname><forenames>Alexandra</forenames></author></authors><title>Improving Neural Machine Translation Models with Monolingual Data</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural Machine Translation (NMT) has obtained state-of-the art performance
for several language pairs, while only using parallel data for training.
Monolingual data plays an important role in boosting fluency for phrase-based
statistical machine translation, and we investigate the use of monolingual data
for neural machine translation (NMT). In contrast to previous work, which
integrates a separately trained RNN language model into an NMT architecture, we
note that encoder-decoder NMT architectures already have the capacity to learn
the same information as a language model, and we explore strategies to include
monolingual training data in the training process. Through our use of
monolingual data, we obtain substantial improvements on the WMT 15 (+2.8--3.4
BLEU) task for English-&gt;German, and for the low-resourced IWSLT 14 task
Turkish-&gt;English (+2.1--3.4 BLEU), obtaining new state-of-the-art results. We
also show that fine-tuning on in-domain monolingual and parallel data gives
substantial improvements for the IWSLT 15 task for English-&gt;German.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06715</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06715</id><created>2015-11-20</created><authors><author><keyname>Dai</keyname><forenames>Mingbo</forenames></author><author><keyname>Clerckx</keyname><forenames>Bruno</forenames></author></authors><title>Hybrid Precoding for Physical Layer Multicasting</title><categories>cs.IT math.IT</categories><comments>Accepted to IEEE Commun. Lett</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work investigates the problem of downlink transmit precoding for
physical layer multicasting with a limited number of radio-frequency (RF)
chains. To tackle the RF hardware constraint, we consider a hybrid precoder
that is partitioned into a high-dimensional RF precoder and a low-dimensional
baseband precoder. Considering a total transmit power constraint over the RF
chains, the goal is to maximize the minimum (max-min) received signal-to-noise
ratio (SNR) among all users. We propose a low complexity algorithm to compute
the RF precoder that achieves near-optimal max-min performance. Moreover, we
derive a simple condition under which the hybrid precoding driven by a limited
number of RF chains incurs no loss of optimality with respect to the fully
digital precoding case. Finally, numerical results validate the effectiveness
of the proposed algorithm and theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06718</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06718</id><created>2015-11-20</created><authors><author><keyname>Stark</keyname><forenames>Cyril</forenames></author></authors><title>Top-N recommendations from expressive recommender systems</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Normalized nonnegative models assign probability distributions to users and
random variables to items; see [Stark, 2015]. Rating an item is regarded as
sampling the random variable assigned to the item with respect to the
distribution assigned to the user who rates the item. Models of that kind are
highly expressive. For instance, using normalized nonnegative models we can
understand users' preferences as mixtures of interpretable user stereotypes,
and we can arrange properties of users and items in a hierarchical manner.
These features would not be useful if the predictive power of normalized
nonnegative models was poor. Thus, we analyze here the performance of
normalized nonnegative models for top-N recommendation and observe that their
performance matches the performance of methods like PureSVD which was
introduced in [Cremonesi et al., 2010]. We conclude that normalized nonnegative
models not only provide accurate recommendations but they also deliver (for
free) representations that are interpretable. We deepen the discussion of
normalized nonnegative models by providing further theoretical insights. In
particular, we introduce total variational distance as an operational
similarity measure, we discover scenarios where normalized nonnegative models
yield unique representations of users and items, we prove that the inference of
optimal normalized nonnegative models is NP-hard and finally, we discuss the
relationship between normalized nonnegative models and nonnegative matrix
factorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06722</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06722</id><created>2015-11-20</created><authors><author><keyname>Sadaf</keyname></author><author><keyname>Soomro</keyname><forenames>Safeeullah</forenames></author><author><keyname>Abbasi</keyname><forenames>Suhni</forenames></author></authors><title>Analysis of SVN Repositories for Remote Access</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software Evolution is considered to be essential and challenging
characteristic in the field of software engineering. Version control system is
an incremental versions tracking system, introduced to avoid unnecessary
overwriting of files such as programming code, web pages and records. It also
helps to decrease the confusion affected by duplicate or outdated data. In this
proposed research SVN repository is maintained and analyzed for
msitone.wikispaces.com to minimize the efforts as well as resources for the
future users. We have used two semester data for the analysis purpose that is
observed SVN repository. The result shows that, implementing the SVN
repositories are helpful for maintenance of the Wikispaces as it also reduce
the cost, time and efforts for their evolution. Whereas without implementing
the SVN repositories Wikispaces were just supposed to be building the house by
putting each brick from start.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06726</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06726</id><created>2015-11-20</created><authors><author><keyname>Kadayinti</keyname><forenames>Naveen</forenames></author><author><keyname>Sharma</keyname><forenames>Dinesh K.</forenames></author></authors><title>Testable Design of Repeaterless Low Swing On-Chip Interconnect</title><categories>cs.AR</categories><comments>6 pages, 9 figures</comments><journal-ref>Proceedings of Design Automation and Test in Europe (DATE) 2016</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Repeaterless low swing interconnects use mixed signal circuits to achieve
high performance at low power. When these interconnects are used in large scale
and high volume digital systems their testability becomes very important. This
paper discusses the testability of low swing repeaterless on-chip interconnects
with equalization and clock synchronization. A capacitively coupled transmitter
with a weak driver is used as the transmitter. The receiver samples the low
swing input data at the center of the data eye and converts it to rail to rail
levels and also synchronizes the data to the receiver's clock domain. The
system is a mixed signal circuit and the digital components are all scan
testable. For the analog section, just a DC test has a fault coverage of 50% of
the structural faults. Simple techniques allow integration of the analog
components into the digital scan chain increasing the coverage to 74%. Finally,
a BIST with low overhead enhances the coverage to 95% of the structural faults.
The design and simulations have been done in UMC 130 nm CMOS technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06727</identifier>
 <datestamp>2015-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06727</id><created>2015-11-20</created><updated>2015-12-16</updated><authors><author><keyname>Luketina</keyname><forenames>Jelena</forenames></author><author><keyname>Berglund</keyname><forenames>Mathias</forenames></author><author><keyname>Raiko</keyname><forenames>Tapani</forenames></author></authors><title>Scalable Gradient-Based Tuning of Continuous Regularization
  Hyperparameters</title><categories>cs.LG</categories><comments>8 pages, 5 figures. added references, fixed typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hyperparameter selection generally relies on running multiple full training
trials, with hyperparameter selection based on validation set performance. We
propose a gradient-based approach for locally adjusting hyperparameters on the
fly in which we adjust the hyperparameters so as to make the model parameter
gradients, and hence updates, more advantageous for the validation cost. We
explore the approach for tuning regularization hyperparameters and find that in
experiments on MNIST the resulting regularization levels are within the optimal
regions. The method is less computationally demanding compared to similar
gradient-based approaches to hyperparameter selection, only requires a few
trials, and consistently finds solid hyperparameter values which makes it a
useful tool for training neural network models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06728</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06728</id><created>2015-11-20</created><authors><author><keyname>Neverova</keyname><forenames>Natalia</forenames></author><author><keyname>Wolf</keyname><forenames>Christian</forenames></author><author><keyname>Nebout</keyname><forenames>Florian</forenames></author><author><keyname>Taylor</keyname><forenames>Graham</forenames></author></authors><title>Hand Pose Estimation through Weakly-Supervised Learning of a Rich
  Intermediate Representation</title><categories>cs.CV cs.AI cs.LG</categories><comments>10 pages, 7 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for hand pose estimation based on a deep regressor
trained on two different kinds of input. Raw depth data is fused with an
intermediate representation in the form of a segmentation of the hand into
parts. This intermediate representation contains important topological
information and provides useful cues for reasoning about joint locations. The
mapping from raw depth to segmentation maps is learned in a
semi/weakly-supervised way from two different datasets: (i) a synthetic dataset
created through a rendering pipeline including densely labeled ground truth
(pixelwise segmentations); and (ii) a dataset with real images for which ground
truth joint positions are available, but not dense segmentations. Loss for
training on real images is generated from a patch-wise restoration process,
which aligns tentative segmentation maps with a large dictionary of synthetic
poses. The underlying premise is that the domain shift between synthetic and
real data is smaller in the intermediate representation, where labels carry
geometric and topological meaning, than in the raw input domain. Experiments on
the NYU dataset show that the proposed training method decreases error on
joints over direct regression of joints from depth data by 15.7%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06729</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06729</id><created>2015-11-20</created><authors><author><keyname>Gallos</keyname><forenames>Lazaros K.</forenames></author><author><keyname>Fefferman</keyname><forenames>Nina H.</forenames></author></authors><title>Simple and efficient self-healing strategy for damaged complex networks</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 8 figures</comments><journal-ref>Physical Review E 92, 052806 (2015)</journal-ref><doi>10.1103/PhysRevE.92.052806</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The process of destroying a complex network through node removal has been the
subject of extensive interest and research. Node loss typically leaves the
network disintegrated into many small and isolated clusters. Here we show that
these clusters typically remain close to each other and we suggest a simple
algorithm that is able to reverse the inflicted damage by restoring the
network's functionality. After damage, each node decides independently whether
to create a new link depending on the fraction of neighbors it has lost. In
addition to relying only on local information, where nodes do not need
knowledge of the global network status, we impose the additional constraint
that new links should be as short as possible (i.e. that the new edge completes
a shortest possible new cycle). We demonstrate that this self-healing method
operates very efficiently, both in model and real networks. For example, after
removing the most connected airports in USA, the self-healing algorithm
re-joined almost 90\% of the surviving airports.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06732</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06732</id><created>2015-11-20</created><updated>2016-02-12</updated><authors><author><keyname>Ranzato</keyname><forenames>Marc'Aurelio</forenames></author><author><keyname>Chopra</keyname><forenames>Sumit</forenames></author><author><keyname>Auli</keyname><forenames>Michael</forenames></author><author><keyname>Zaremba</keyname><forenames>Wojciech</forenames></author></authors><title>Sequence Level Training with Recurrent Neural Networks</title><categories>cs.LG cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many natural language processing applications use language models to generate
text. These models are typically trained to predict the next word in a
sequence, given the previous words and some context such as an image. However,
at test time the model is expected to generate the entire sequence from
scratch. This discrepancy makes generation brittle, as errors may accumulate
along the way. We address this issue by proposing a novel sequence level
training algorithm that directly optimizes the metric used at test time, such
as BLEU or ROUGE. On three different tasks, our approach outperforms several
strong baselines for greedy generation. The method is also competitive when
these baselines employ beam search, while being several times faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06735</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06735</id><created>2015-11-20</created><updated>2015-12-20</updated><authors><author><keyname>Galinina</keyname><forenames>Olga</forenames></author><author><keyname>Tabassum</keyname><forenames>Hina</forenames></author><author><keyname>Mikhaylov</keyname><forenames>Konstantin</forenames></author><author><keyname>Andreev</keyname><forenames>Sergey</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author><author><keyname>Koucheryavy</keyname><forenames>Yevgeni</forenames></author></authors><title>On Feasibility of 5G-Grade Dedicated RF Charging Technology for
  Wireless-Powered Wearables</title><categories>cs.NI</categories><comments>9 pages, 5 figures, 15 references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For decades, wireless energy transfer and harvesting remained of focused
attention in the research community, but with limited practical applications.
Recently, with the development of fifth-generation (5G) mobile technology, the
concept of dedicated radio-frequency (RF) charging promises to support the
growing market of wearable devices. In this work, we shed light on the
potential of wireless RF power transfer by elaborating upon feasible system
parameters and architecture, emphasizing the basic trade-offs behind
omni-directional and directional out-of-band energy transmission, providing
system-level performance evaluation, as well as discussing open challenges on
the way to sustainable wireless-powered wearables. The key aspects highlighted
in this article include system operation choices, user mobility effects, impact
of network and user densities, as well as regulatory issues. Ultimately, our
research targets to facilitate the integration of wireless RF charging
technology into the emerging 5G ecosystem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06739</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06739</id><created>2015-11-20</created><updated>2016-01-08</updated><authors><author><keyname>Gadde</keyname><forenames>Raghudeep</forenames></author><author><keyname>Jampani</keyname><forenames>Varun</forenames></author><author><keyname>Kiefel</keyname><forenames>Martin</forenames></author><author><keyname>Gehler</keyname><forenames>Peter V.</forenames></author></authors><title>Superpixel Convolutional Networks using Bilateral Inceptions</title><categories>cs.CV</categories><comments>Conference track submission to ICLR-2016</comments><acm-class>I.2.10; I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a CNN architecture for image segmentation. We
introduce a new &quot;bilateral inception&quot; layer that is used on top of a
convolutional architecture. The bilateral inception performs a filtering
between superpixels in an image. This addresses two problems that arise with
CNN segmentation architectures. First, this layer propagates information
between (super) pixels while respecting image edges, thus using the structured
information of the problem for improved results. Second, the layer recovers a
full resolution segmentation result from the lower resolution solution of a
CNN. In the experiments we replace the deconvolution networks and Dense-CRF
that have previously been proposed to address these problems with bilateral
inception layers. The reduction to superpixels reduces the amount of
computations and simplifies the network design. Further, we report better
empirical results by replacing De-convolutional and CNN+Dense-CRF steps in four
different semantic segmentation CNN architecutres, even with-out re-training
their filter weights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06744</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06744</id><created>2015-11-20</created><updated>2016-02-07</updated><authors><author><keyname>Ioannou</keyname><forenames>Yani</forenames></author><author><keyname>Robertson</keyname><forenames>Duncan</forenames></author><author><keyname>Shotton</keyname><forenames>Jamie</forenames></author><author><keyname>Cipolla</keyname><forenames>Roberto</forenames></author><author><keyname>Criminisi</keyname><forenames>Antonio</forenames></author></authors><title>Training CNNs with Low-Rank Filters for Efficient Image Classification</title><categories>cs.CV cs.LG cs.NE</categories><comments>Published as a conference paper at ICLR 2016. v3: updated ICLR
  status. v2: Incorporated reviewer's feedback including: Amend Fig. 2 and 5
  descriptions to explain that there are no ReLUs within the figures. Fix
  headings of Table 5 - Fix typo in the sentence at bottom of page 6. Add ref.
  to Predicting Parameters in Deep Learning. Fix Table 6, GMP-LR and GMP-LR-2x
  had incorrect numbers of filters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method for creating computationally efficient convolutional
neural networks (CNNs) by using low-rank representations of convolutional
filters. Rather than approximating filters in previously-trained networks with
more efficient versions, we learn a set of small basis filters from scratch;
during training, the network learns to combine these basis filters into more
complex filters that are discriminative for image classification. To train such
networks, a novel weight initialization scheme is used. This allows effective
initialization of connection weights in convolutional layers composed of groups
of differently-shaped filters. We validate our approach by applying it to
several existing CNN architectures and training these networks from scratch
using the CIFAR, ILSVRC and MIT Places datasets. Our results show similar or
higher accuracy than conventional CNNs with much less compute. Applying our
method to an improved version of VGG-11 network using global max-pooling, we
achieve comparable validation accuracy using 41% less compute and only 24% of
the original VGG-11 model parameters; another variant of our method gives a 1
percentage point increase in accuracy over our improved VGG-11 model, giving a
top-5 center-crop validation accuracy of 89.7% while reducing computation by
16% relative to the original VGG-11 model. Applying our method to the GoogLeNet
architecture for ILSVRC, we achieved comparable accuracy with 26% less compute
and 41% fewer model parameters. Applying our method to a near state-of-the-art
network for CIFAR, we achieved comparable accuracy with 46% less compute and
55% fewer parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06746</identifier>
 <datestamp>2015-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06746</id><created>2015-11-20</created><authors><author><keyname>Lynch</keyname><forenames>Corey</forenames></author><author><keyname>Aryafar</keyname><forenames>Kamelia</forenames></author><author><keyname>Attenberg</keyname><forenames>Josh</forenames></author></authors><title>Images Don't Lie: Transferring Deep Visual Semantic Features to
  Large-Scale Multimodal Learning to Rank</title><categories>cs.CV cs.LG</categories><comments>9 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Search is at the heart of modern e-commerce. As a result, the task of ranking
search results automatically (learning to rank) is a multibillion dollar
machine learning problem. Traditional models optimize over a few
hand-constructed features based on the item's text. In this paper, we introduce
a multimodal learning to rank model that combines these traditional features
with visual semantic features transferred from a deep convolutional neural
network. In a large scale experiment using data from the online marketplace
Etsy, we verify that moving to a multimodal representation significantly
improves ranking quality. We show how image features can capture fine-grained
style information not available in a text-only representation. In addition, we
show concrete examples of how image information can successfully disentangle
pairs of highly different items that are ranked similarly by a text-only model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06747</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06747</id><created>2015-11-20</created><updated>2016-01-19</updated><authors><author><keyname>Neyshabur</keyname><forenames>Behnam</forenames></author><author><keyname>Tomioka</keyname><forenames>Ryota</forenames></author><author><keyname>Salakhutdinov</keyname><forenames>Ruslan</forenames></author><author><keyname>Srebro</keyname><forenames>Nathan</forenames></author></authors><title>Data-Dependent Path Normalization in Neural Networks</title><categories>cs.LG</categories><comments>17 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a unified framework for neural net normalization, regularization
and optimization, which includes Path-SGD and Batch-Normalization and
interpolates between them across two different dimensions. Through this
framework we investigate issue of invariance of the optimization, data
dependence and the connection with natural gradients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06759</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06759</id><created>2015-11-20</created><authors><author><keyname>Kumar</keyname><forenames>Tanesh</forenames></author><author><keyname>Khan</keyname><forenames>Faizan</forenames></author><author><keyname>Soomro</keyname><forenames>Safeeullah</forenames></author><author><keyname>Memon</keyname><forenames>Areez Khalil</forenames></author></authors><title>WLAN Specific IoT Enable Power Efficient RAM Design on 40nm FPGA</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Increasing the speed of computer is one of the important aspects of the
Random Access Memory (RAM) and for better and fast processing it should be
efficient. In this work, the main focus is to design energy efficient RAM and
it also can be accessed through internet. A 128-bit IPv6 address is added to
the RAM in order to control it via internet. Four different types of Low
Voltage CMOS (LCVMOS) IO standards are used to make it low power under five
different WLAN frequencies is taken. At WLAN frequency 2.4GHz, there is maximum
power reduction of 85% is achieved when LVCMOS12 is taken in place of LVCMOS25.
This design is implemented using Virtex-6 FPGA, Device xc6vlx75t and Package
FF484
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06773</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06773</id><created>2015-11-20</created><authors><author><keyname>Henzinger</keyname><forenames>Monika</forenames></author><author><keyname>Krinninger</keyname><forenames>Sebastian</forenames></author><author><keyname>Nanongkai</keyname><forenames>Danupon</forenames></author><author><keyname>Saranurak</keyname><forenames>Thatchaphol</forenames></author></authors><title>Unifying and Strengthening Hardness for Dynamic Problems via the Online
  Matrix-Vector Multiplication Conjecture</title><categories>cs.DS</categories><comments>A preliminary version of this paper was presented at the 47th ACM
  Symposium on Theory of Computing (STOC 2015)</comments><doi>10.1145/2746539.2746609</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the following Online Boolean Matrix-Vector Multiplication problem:
We are given an $n\times n$ matrix $M$ and will receive $n$ column-vectors of
size $n$, denoted by $v_1,\ldots,v_n$, one by one. After seeing each vector
$v_i$, we have to output the product $Mv_i$ before we can see the next vector.
A naive algorithm can solve this problem using $O(n^3)$ time in total, and its
running time can be slightly improved to $O(n^3/\log^2 n)$ [Williams SODA'07].
We show that a conjecture that there is no truly subcubic ($O(n^{3-\epsilon})$)
time algorithm for this problem can be used to exhibit the underlying
polynomial time hardness shared by many dynamic problems. For a number of
problems, such as subgraph connectivity, Pagh's problem, $d$-failure
connectivity, decremental single-source shortest paths, and decremental
transitive closure, this conjecture implies tight hardness results. Thus,
proving or disproving this conjecture will be very interesting as it will
either imply several tight unconditional lower bounds or break through a common
barrier that blocks progress with these problems. This conjecture might also be
considered as strong evidence against any further improvement for these
problems since refuting it will imply a major breakthrough for combinatorial
Boolean matrix multiplication and other long-standing problems if the term
&quot;combinatorial algorithms&quot; is interpreted as &quot;non-Strassen-like algorithms&quot;
[Ballard et al. SPAA'11]. The conjecture also leads to hardness results for
problems that were previously based on diverse problems and conjectures, such
as 3SUM, combinatorial Boolean matrix multiplication, triangle detection, and
multiphase, thus providing a uniform way to prove polynomial hardness results
for dynamic algorithms; some of the new proofs are also simpler or even become
trivial. The conjecture also leads to stronger and new, non-trivial, hardness
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06783</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06783</id><created>2015-11-20</created><authors><author><keyname>Ohnishi</keyname><forenames>Katsunori</forenames></author><author><keyname>Kanehira</keyname><forenames>Atsushi</forenames></author><author><keyname>Kanezaki</keyname><forenames>Asako</forenames></author><author><keyname>Harada</keyname><forenames>Tatsuya</forenames></author></authors><title>Recognizing Activities of Daily Living with a Wrist-mounted Camera</title><categories>cs.CV</categories><comments>14 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel dataset and a novel algorithm for recognizing activities
of daily living (ADL) from a first-person wearable camera. Handled objects are
crucially important for egocentric ADL recognition. For specific examination of
objects related to users' actions separately from other objects in an
environment, many previous works have addressed the detection of handled
objects in images captured from head-mounted and chest-mounted cameras.
Nevertheless, detecting handled objects is not always easy because they tend to
appear small in images. They can be occluded by a user's body. As described
herein, we mount a camera on a user's wrist. A wrist-mounted camera can capture
handled objects at a large scale, and thus it enables us to skip object
detection process. To compare a wrist-mounted camera and a head-mounted camera,
we also develop a novel and publicly available dataset that includes videos and
annotations of daily activities captured simultaneously by both cameras.
Additionally, we propose a discriminative video representation that retains
spatial and temporal information after encoding frame descriptors extracted by
Convolutional Neural Networks (CNN).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06787</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06787</id><created>2015-11-20</created><authors><author><keyname>Abeysiriwardana</keyname><forenames>Prabath Chaminda</forenames></author><author><keyname>Kodituwakku</keyname><forenames>S. R.</forenames></author></authors><title>A Model for Web-Intelligence Index to Evaluate the Web Intelligence
  Capacity of Government Web Sites of Sri Lanka</title><categories>cs.CY</categories><journal-ref>British Journal of Mathematics &amp; Computer Science, 12(6): 1-12,
  2016, Article no.BJMCS.22654, ISSN: 2231-0851</journal-ref><doi>10.9734/BJMCS/2016/22654</doi><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Web intelligence can be considered as a subset of Artificial Intelligence. It
uses existing data in web to produce new data, knowledge and wisdom to support
decision making and new predictions for web users. Artificial Intelligence is
ever changing and evolving field of computer science and it is extensively used
in wide array of web based business applications. Although it is used
substantially in web based systems in developed countries, it is not examined
whether it is being substantially used in Sri Lanka. Every Sri Lankan citizen
depends on Public Service more or less throughout his/ her life time and at
least more than 3 times: at birth, marriage and death. So providing most of
these services to its citizen, Sri Lankan Government uses more or less of its
country web portal. This paper presents a model to evaluate web intelligence
capability based on weight to key functionalities with respect to web
intelligence. The government websites were checked by the proposed criteria to
show the potential of using web intelligent technology to provide website based
services. The result indicates that the use of web intelligence techniques
openly and publicly to provide web based services through government web portal
to its citizens is not satisfactory. It also indicates that lack of using the
technologies pertaining to web intelligence in the public service web hinders
the most of the advantages that citizen and government can gain from such
technological involvement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06789</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06789</id><created>2015-11-20</created><authors><author><keyname>Krause</keyname><forenames>Jonathan</forenames></author><author><keyname>Sapp</keyname><forenames>Benjamin</forenames></author><author><keyname>Howard</keyname><forenames>Andrew</forenames></author><author><keyname>Zhou</keyname><forenames>Howard</forenames></author><author><keyname>Toshev</keyname><forenames>Alexander</forenames></author><author><keyname>Duerig</keyname><forenames>Tom</forenames></author><author><keyname>Philbin</keyname><forenames>James</forenames></author><author><keyname>Fei-Fei</keyname><forenames>Li</forenames></author></authors><title>The Unreasonable Effectiveness of Noisy Data for Fine-Grained
  Recognition</title><categories>cs.CV</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While models of fine-grained recognition have made great progress in recent
years, little work has focused on a key ingredient of making recognition work:
data. We use publicly available, noisy data sources to train generic models
which vastly improve upon state-of-the-art on fine-grained benchmarks. First,
we present an active learning system using non-expert human raters, and improve
upon state-of-the-art performance without any text or other metadata associated
with the images. Second, we show that training on publicly-available noisy web
image search results achieves even higher accuracies, without using any
expert-annotated training data, while scaling to over ten thousand fine-grained
categories. We analyze the behavior of our models and data and make a strong
case for the importance of data over special-purpose modeling: using only an
off-the-shelf CNN, we obtain top-1 accuracies of 92.8\% on CUB-200-2011 Birds,
85.4\% on Birdsnap, 95.9\% on FGVC-Aircraft, and 82.6\% on Stanford Dogs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06795</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06795</id><created>2015-11-20</created><authors><author><keyname>Gonzalez</keyname><forenames>Elias</forenames></author><author><keyname>Kish</keyname><forenames>Laszlo B.</forenames></author></authors><title>Key Exchange Trust Evaluation in Peer-to-Peer Sensor Networks with
  Unconditionally Secure Key Exchange</title><categories>cs.CR</categories><comments>17 pages, 2 figures, submitted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the utilization of sensor networks continue to increase, the importance of
security becomes more profound. Many industries depend on sensor networks for
critical tasks, and a malicious entity can potentially cause catastrophic
damage. We propose a new key exchange trust evaluation for peer-to-peer sensor
networks, where part of the network has unconditionally secure key exchange.
For a given sensor, the higher the portion of channels with unconditionally
secure key exchange the higher the trust value. We give a brief introduction to
unconditionally secured key exchange concepts and mention current trust
measures in sensor networks. We demonstrate the new key exchange trust measure
on a hypothetical sensor network using both wired and wireless communication
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06798</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06798</id><created>2015-11-20</created><authors><author><keyname>Miratrix</keyname><forenames>Luke</forenames></author><author><keyname>Ackerman</keyname><forenames>Robin</forenames></author></authors><title>Conducting sparse feature selection on arbitrarily long phrases in text
  corpora with a focus on interpretability</title><categories>cs.CL cs.IR stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a general framework for topic-specific summarization of large text
corpora, and illustrate how it can be used for analysis in two quite different
contexts: an OSHA database of fatality and catastrophe reports (to facilitate
surveillance for patterns in circumstances leading to injury or death) and
legal decisions on workers' compensation claims (to explore relevant case law).
Our summarization framework, built on sparse classification methods, is a
compromise between simple word frequency based methods currently in wide use,
and more heavyweight, model-intensive methods such as Latent Dirichlet
Allocation (LDA). For a particular topic of interest (e.g., mental health
disability, or chemical reactions), we regress a labeling of documents onto the
high-dimensional counts of all the other words and phrases in the documents.
The resulting small set of phrases found as predictive are then harvested as
the summary. Using a branch-and-bound approach, this method can be extended to
allow for phrases of arbitrary length, which allows for potentially rich
summarization. We discuss how focus on the purpose of the summaries can inform
choices of regularization parameters and model constraints. We evaluate this
tool by comparing computational time and summary statistics of the resulting
word lists to three other methods in the literature. We also present a new R
package, textreg. Overall, we argue that sparse methods have much to offer text
analysis, and is a branch of research that should be considered further in this
context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06807</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06807</id><created>2015-11-20</created><authors><author><keyname>Neelakantan</keyname><forenames>Arvind</forenames></author><author><keyname>Vilnis</keyname><forenames>Luke</forenames></author><author><keyname>Le</keyname><forenames>Quoc V.</forenames></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author><author><keyname>Kaiser</keyname><forenames>Lukasz</forenames></author><author><keyname>Kurach</keyname><forenames>Karol</forenames></author><author><keyname>Martens</keyname><forenames>James</forenames></author></authors><title>Adding Gradient Noise Improves Learning for Very Deep Networks</title><categories>stat.ML cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep feedforward and recurrent networks have achieved impressive results in
many perception and language processing applications. This success is partially
attributed to architectural innovations such as convolutional and long
short-term memory networks. The main motivation for these architectural
innovations is that they capture better domain knowledge, and importantly are
easier to optimize than more basic architectures. Recently, more complex
architectures such as Neural Turing Machines and Memory Networks have been
proposed for tasks including question answering and general computation,
creating a new set of optimization challenges. In this paper, we discuss a
low-overhead and easy-to-implement technique of adding gradient noise which we
find to be surprisingly effective when training these very deep architectures.
The technique not only helps to avoid overfitting, but also can result in lower
training loss. This method alone allows a fully-connected 20-layer deep network
to be trained with standard gradient descent, even starting from a poor
initialization. We see consistent improvements for many complex models,
including a 72% relative reduction in error rate over a carefully-tuned
baseline on a challenging question-answering task, and a doubling of the number
of accurate binary multiplication models learned across 7,000 random restarts.
We encourage further application of this technique to additional complex modern
architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06811</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06811</id><created>2015-11-20</created><authors><author><keyname>Isola</keyname><forenames>Phillip</forenames></author><author><keyname>Zoran</keyname><forenames>Daniel</forenames></author><author><keyname>Krishnan</keyname><forenames>Dilip</forenames></author><author><keyname>Adelson</keyname><forenames>Edward H.</forenames></author></authors><title>Learning visual groups from co-occurrences in space and time</title><categories>cs.LG cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a self-supervised framework that learns to group visual entities
based on their rate of co-occurrence in space and time. To model statistical
dependencies between the entities, we set up a simple binary classification
problem in which the goal is to predict if two visual primitives occur in the
same spatial or temporal context. We apply this framework to three domains:
learning patch affinities from spatial adjacency in images, learning frame
affinities from temporal adjacency in videos, and learning photo affinities
from geospatial proximity in image collections. We demonstrate that in each
case the learned affinities uncover meaningful semantic groupings. From patch
affinities we generate object proposals that are competitive with
state-of-the-art supervised methods. From frame affinities we generate movie
scene segmentations that correlate well with DVD chapter structure. Finally,
from geospatial affinities we learn groups that relate well to semantic place
categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06815</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06815</id><created>2015-11-20</created><authors><author><keyname>Lu</keyname><forenames>Xinzhong</forenames></author><author><keyname>Shen</keyname><forenames>Ju</forenames></author><author><keyname>Perugini</keyname><forenames>Saverio</forenames></author><author><keyname>Yang</keyname><forenames>Jianjun</forenames></author></authors><title>An Immersive Telepresence System using RGB-D Sensors and Head Mounted
  Display</title><categories>cs.CV cs.HC cs.MM</categories><comments>IEEE International Symposium on Multimedia 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a tele-immersive system that enables people to interact with each
other in a virtual world using body gestures in addition to verbal
communication. Beyond the obvious applications, including general online
conversations and gaming, we hypothesize that our proposed system would be
particularly beneficial to education by offering rich visual contents and
interactivity. One distinct feature is the integration of egocentric pose
recognition that allows participants to use their gestures to demonstrate and
manipulate virtual objects simultaneously. This functionality enables the
instructor to ef- fectively and efficiently explain and illustrate complex
concepts or sophisticated problems in an intuitive manner. The highly
interactive and flexible environment can capture and sustain more student
attention than the traditional classroom setting and, thus, delivers a
compelling experience to the students. Our main focus here is to investigate
possible solutions for the system design and implementation and devise
strategies for fast, efficient computation suitable for visual data processing
and network transmission. We describe the technique and experiments in details
and provide quantitative performance results, demonstrating our system can be
run comfortably and reliably for different application scenarios. Our
preliminary results are promising and demonstrate the potential for more
compelling directions in cyberlearning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06820</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06820</id><created>2015-11-20</created><authors><author><keyname>Liu</keyname><forenames>Yike</forenames></author><author><keyname>Shah</keyname><forenames>Neil</forenames></author><author><keyname>Koutra</keyname><forenames>Danai</forenames></author></authors><title>An Empirical Comparison of the Summarization Power of Graph Clustering
  Methods</title><categories>cs.IR cs.SI</categories><comments>NIPS workshop: Networks in the Social and Information Sciences</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  How do graph clustering techniques compare with respect to their
summarization power? How well can they summarize a million-node graph with a
few representative structures? Graph clustering or community detection
algorithms can summarize a graph in terms of coherent and tightly connected
clusters. In this paper, we compare and contrast different techniques: METIS,
Louvain, spectral clustering, SlashBurn and KCBC, our proposed k-core-based
clustering method. Unlike prior work that focuses on various measures of
cluster quality, we use vocabulary structures that often appear in real graphs
and the Minimum Description Length (MDL) principle to obtain a graph summary
per clustering method. Our main contributions are: (i) Formulation: We propose
a summarization-based evaluation of clustering methods. Our method,
VOG-OVERLAP, concisely summarizes graphs in terms of their important structures
which lead to small edge overlap, and large node/edge coverage; (ii) Algorithm:
we introduce KCBC, a graph decomposition technique, in the heart of which lies
the k-core algorithm (iii) Evaluation: We compare the summarization power of
five clustering techniques on large real graphs, and analyze their compression
performance, summary statistics and runtimes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06825</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06825</id><created>2015-11-20</created><authors><author><keyname>Quang-Hung</keyname><forenames>Nguyen</forenames></author><author><keyname>Thoai</keyname><forenames>Nam</forenames></author></authors><title>EMinRET: Heuristic for Energy-Aware VM Placement with Fixed Intervals
  and Non-preemption</title><categories>cs.NI cs.DC</categories><comments>8 pages, 4 figures, The International Conference on Advanced
  Computing and Applications (ACOMP)</comments><acm-class>C.2.4, F.2, H.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Infrastructure-as-a-Service (IaaS) clouds have become more popular enabling
users to run applications under virtual machines. This paper investigates the
energy-aware virtual machine (VM) allocation problems in IaaS clouds along
characteristics: multiple resources, and fixed interval times and
non-preemption of virtual machines. Many previous works proposed to use a
minimum number of physical machines, however, this is not necessarily a good
solution to minimize total energy consumption in the VM placement with multiple
resources, fixed interval times and non-preemption. We observed that minimizing
total energy consumption of physical machines is equivalent to minimize the sum
of total completion time of all physical machines. Based on the observation, we
propose EMinRET algorithm. The EMinRET algorithm swaps an allocating VM with a
suitable overlapped VM, which is of the same VM type and is allocated on the
same physical machine, to minimize total completion time of all physical
machines. The EMinRET uses resource utilization during executing time period of
a physical machine as the evaluation metric, and will then choose a host that
minimizes the metric to allocate a new VM. In addition, this work studies some
heuristics for sorting the list of virtual machines (e.g., sorting by the
earliest starting time, or the longest duration time first, etc.) to allocate
VM. Using the realistic log-trace in the Parallel Workloads Archive, our
simulation results show that the EMinRET algorithm could reduce from 25% to 45%
energy consumption compared with power-aware best-fit decreasing (PABFD)) and
vector bin-packing norm-based greedy algorithms. Moreover, the EMinRET
heuristic has also less total energy consumption than our previous heuristics
(e.g. MinDFT and EPOBF) in the simulations (using same virtual machines sorting
method).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06827</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06827</id><created>2015-11-20</created><authors><author><keyname>Almeida</keyname><forenames>Diogo</forenames></author><author><keyname>Sauder</keyname><forenames>Nate</forenames></author></authors><title>GradNets: Dynamic Interpolation Between Neural Architectures</title><categories>cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In machine learning, there is a fundamental trade-off between ease of
optimization and expressive power. Neural Networks, in particular, have
enormous expressive power and yet are notoriously challenging to train. The
nature of that optimization challenge changes over the course of learning.
Traditionally in deep learning, one makes a static trade-off between the needs
of early and late optimization. In this paper, we investigate a novel
framework, GradNets, for dynamically adapting architectures during training to
get the benefits of both. For example, we can gradually transition from linear
to non-linear networks, deterministic to stochastic computation, shallow to
deep architectures, or even simple downsampling to fully differentiable
attention mechanisms. Benefits include increased accuracy, easier convergence
with more complex architectures, solutions to test-time execution of batch
normalization, and the ability to train networks of up to 200 layers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06828</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06828</id><created>2015-11-20</created><authors><author><keyname>Duan</keyname><forenames>Huiping</forenames></author><author><keyname>Tuo</keyname><forenames>Tiantian</forenames></author><author><keyname>Fang</keyname><forenames>Jun</forenames></author><author><keyname>Zeng</keyname><forenames>Bing</forenames></author></authors><title>Real-Valued Khatri-Rao Subspace Approaches on the ULA and a New Nested
  Array</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In underdetermined direction-of-arrival (DOA) estimation using the
covariance-based signal models, the computational complexity turns into a
noticeable issue because of the high dimension of the virtual array manifold.
In this paper, real-valued Khatri-Rao (KR) approaches are developed on the
uniform linear array (ULA) and the nested array. The complexities of subspace
decomposition and spectral search are reduced compared with the complex-valued
KR approach. By designing a special transformation matrix, the influence of the
noise is removed in the mean time while the data is transformed from the
complex domain to the real domain. Deploying the sensors with nonuniform
spacings can raise the degree of freedom (DOF) and hence help detect more
sources in the underdetermined situation. To increase the DOF further, a new
nested array geometry is designed. The real-valued denoising KR approach
developed on the new nested array can resolve more sources with reduced
complexities. The performance improvement is demonstrated by numerical studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06830</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06830</id><created>2015-11-20</created><updated>2016-02-18</updated><authors><author><keyname>Dong</keyname><forenames>Xuan</forenames></author><author><keyname>Bonev</keyname><forenames>Boyan</forenames></author><author><keyname>Li</keyname><forenames>Weixin</forenames></author><author><keyname>Qiu</keyname><forenames>Weichao</forenames></author><author><keyname>Chen</keyname><forenames>Xianjie</forenames></author><author><keyname>Yuille</keyname><forenames>Alan</forenames></author></authors><title>Ground-truth dataset and baseline evaluations for image base-detail
  separation algorithms</title><categories>cs.CV</categories><comments>This paper has been withdrawn by the author due to some un-proper
  examples</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Base-detail separation is a fundamental computer vision problem consisting of
modeling a smooth base layer with the coarse structures, and a detail layer
containing the texture-like structures. One of the challenges of estimating the
base is to preserve sharp boundaries between objects or parts to avoid halo
artifacts. Many methods have been proposed to address this problem, but there
is no ground-truth dataset of real images for quantitative evaluation. We
proposed a procedure to construct such a dataset, and provide two datasets:
Pascal Base-Detail and Fashionista Base-Detail, containing 1000 and 250 images,
respectively. Our assumption is that the base is piecewise smooth and we label
the appearance of each piece by a polynomial model. The pieces are objects and
parts of objects, obtained from human annotations. Finally, we proposed a way
to evaluate methods with our base-detail ground-truth and we compared the
performances of seven state-of-the-art algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06833</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06833</id><created>2015-11-20</created><authors><author><keyname>Thenmalar</keyname><forenames>S.</forenames></author><author><keyname>Balaji</keyname><forenames>J.</forenames></author><author><keyname>Geetha</keyname><forenames>T. V.</forenames></author></authors><title>Semi-supervised Bootstrapping approach for Named Entity Recognition</title><categories>cs.CL cs.IR</categories><comments>13 pages, 2 figures, 5 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of Named Entity Recognition (NER) is to identify references of named
entities in unstructured documents, and to classify them into pre-defined
semantic categories. NER often aids from added background knowledge in the form
of gazetteers. However using such a collection does not deal with name variants
and cannot resolve ambiguities associated in identifying the entities in
context and associating them with predefined categories. We present a
semi-supervised NER approach that starts with identifying named entities with a
small set of training data. Using the identified named entities, the word and
the context features are used to define the pattern. This pattern of each named
entity category is used as a seed pattern to identify the named entities in the
test set. Pattern scoring and tuple value score enables the generation of the
new patterns to identify the named entity categories. We have evaluated the
proposed system for English language with the dataset of tagged (IEER) and
untagged (CoNLL 2003) named entity corpus and for Tamil language with the
documents from the FIRE corpus and yield an average f-measure of 75% for both
the languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06834</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06834</id><created>2015-11-20</created><authors><author><keyname>Dong</keyname><forenames>Xuan</forenames></author><author><keyname>Zhu</keyname><forenames>Yu</forenames></author><author><keyname>Li</keyname><forenames>Weixin</forenames></author><author><keyname>Xie</keyname><forenames>Lingxi</forenames></author><author><keyname>Wong</keyname><forenames>Alex</forenames></author><author><keyname>Yuille</keyname><forenames>Alan</forenames></author></authors><title>Fidelity-Naturalness Evaluation of Single Image Super Resolution</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of evaluating super resolution methods. Traditional
evaluation methods usually judge the quality of super resolved images based on
a single measure of their difference with the original high resolution images.
In this paper, we proposed to use both fidelity (the difference with original
images) and naturalness (human visual perception of super resolved images) for
evaluation. For fidelity evaluation, a new metric is proposed to solve the bias
problem of traditional evaluation. For naturalness evaluation, we let humans
label preference of super resolution results using pair-wise comparison, and
test the correlation between human labeling results and image quality
assessment metrics' outputs. Experimental results show that our
fidelity-naturalness method is better than the traditional evaluation method
for super resolution methods, which could help future research on single-image
super resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06838</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06838</id><created>2015-11-20</created><authors><author><keyname>Narihira</keyname><forenames>Takuya</forenames></author><author><keyname>Borth</keyname><forenames>Damian</forenames></author><author><keyname>Yu</keyname><forenames>Stella X.</forenames></author><author><keyname>Ni</keyname><forenames>Karl</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Mapping Images to Sentiment Adjective Noun Pairs with Factorized Neural
  Nets</title><categories>cs.CV cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the visual sentiment task of mapping an image to an adjective
noun pair (ANP) such as &quot;cute baby&quot;. To capture the two-factor structure of our
ANP semantics as well as to overcome annotation noise and ambiguity, we propose
a novel factorized CNN model which learns separate representations for
adjectives and nouns but optimizes the classification performance over their
product. Our experiments on the publicly available SentiBank dataset show that
our model significantly outperforms not only independent ANP classifiers on
unseen ANPs and on retrieving images of novel ANPs, but also image captioning
models which capture word semantics from co-occurrence of natural text; the
latter turn out to be surprisingly poor at capturing the sentiment evoked by
pure visual experience. That is, our factorized ANP CNN not only trains better
from noisy labels, generalizes better to new images, but can also expands the
ANP vocabulary on its own.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06841</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06841</id><created>2015-11-21</created><updated>2016-01-07</updated><authors><author><keyname>Hwang</keyname><forenames>Kyuyeon</forenames></author><author><keyname>Sung</keyname><forenames>Wonyong</forenames></author></authors><title>Online Sequence Training of Recurrent Neural Networks with Connectionist
  Temporal Classification</title><categories>cs.LG cs.NE</categories><comments>Submitted to ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Connectionist temporal classification (CTC) based supervised sequence
training of recurrent neural networks (RNNs) has shown great success in many
machine learning areas including end-to-end speech and handwritten character
recognition. For the CTC training, however, it is required to unroll (or
unfold) the RNN by the length of an input sequence. This unrolling requires a
lot of memory and hinders a small footprint implementation of online learning
or adaptation. Furthermore, the length of training sequences is usually not
uniform, which makes parallel training with multiple sequences inefficient on
shared memory models such as graphics processing units (GPUs). In this work, we
introduce an expectation-maximization (EM) based online CTC algorithm that
enables unidirectional RNNs to learn sequences that are longer than the amount
of unrolling. The RNNs can also be trained to process an infinitely long input
sequence without pre-segmentation or external reset. Moreover, the proposed
approach allows efficient parallel training on GPUs. For evaluation, phoneme
recognition and end-to-end speech recognition examples are presented on the
TIMIT and Wall Street Journal (WSJ) corpora, respectively. Our online model
achieves 20.7% phoneme error rate (PER) on the very long input sequence that is
generated by concatenating all 192 utterances in the TIMIT core test set. On
WSJ, a network can be trained with only 64 times of unrolling while sacrificing
4.5% relative word error rate (WER).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06852</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06852</id><created>2015-11-21</created><authors><author><keyname>Li</keyname><forenames>Jingwen</forenames></author><author><keyname>Wang</keyname><forenames>Wen-Xu</forenames></author><author><keyname>Lai</keyname><forenames>Ying-Cheng</forenames></author><author><keyname>Grebogi</keyname><forenames>Celso</forenames></author></authors><title>Reconstructing complex networks with binary-state dynamics</title><categories>physics.soc-ph cs.SI nlin.AO</categories><comments>For Supplementary Information, see
  http://sss.bnu.edu.cn/~wenxuw/publications/SI_reconstruct_binary.pdf</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The prerequisite for our understanding of many complex networked systems lies
in the reconstruction of network structure from measurable data. Although
binary-state dynamics occurring in a broad class of complex networked systems
in nature and society and has been intensively investigated, a general
framework for reconstructing complex networks from binary states, the inverse
problem, is lacking. Here we offer a general solution to the reconstruction
problem by developing a data-based linearization approach for binary-state
dynamics with linear, nonlinear, discrete and stochastic switching functions.
The linearization allows us to convert the network reconstruction problem into
a sparse signal reconstruction problem that can be resolved efficiently and
credibly by convex optimization based on compressed sensing. The completely
data-based linearization method and the sparse signal reconstruction
constitutes a general framework for reconstructing complex networks without any
knowledge of the binary-state dynamics occurring on them in an extremely
efficient and robust manner. Our framework has been validated by several
different kinds of binary-state dynamics in combination with a large number of
artificial and real complex networks. A universal high reconstruction accuracy
is achieved in spite of the measurement noise and missing data of partial
nodes. Our approach opens a new route to the inverse problem in complex
networked systems with binary-state dynamics and improves our ability to fully
understand and control their emergent dynamics in a comprehensive way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06853</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06853</id><created>2015-11-21</created><authors><author><keyname>Xu</keyname><forenames>Yichao</forenames></author><author><keyname>Nagahara</keyname><forenames>Hajime</forenames></author><author><keyname>Shimada</keyname><forenames>Atsushi</forenames></author><author><keyname>Taniguchi</keyname><forenames>Rin-ichiro</forenames></author></authors><title>TransCut: Transparent Object Segmentation from a Light-Field Image</title><categories>cs.CV</categories><comments>9 pages, 14 figures, 2 tables, ICCV 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The segmentation of transparent objects can be very useful in computer vision
applications. However, because they borrow texture from their background and
have a similar appearance to their surroundings, transparent objects are not
handled well by regular image segmentation methods. We propose a method that
overcomes these problems using the consistency and distortion properties of a
light-field image. Graph-cut optimization is applied for the pixel labeling
problem. The light-field linearity is used to estimate the likelihood of a
pixel belonging to the transparent object or Lambertian background, and the
occlusion detector is used to find the occlusion boundary. We acquire a light
field dataset for the transparent object, and use this dataset to evaluate our
method. The results demonstrate that the proposed method successfully segments
transparent objects from the background.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06855</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06855</id><created>2015-11-21</created><updated>2016-01-07</updated><authors><author><keyname>Wang</keyname><forenames>Jianyu</forenames></author><author><keyname>Zhang</keyname><forenames>Zhishuai</forenames></author><author><keyname>Premachandran</keyname><forenames>Vittal</forenames></author><author><keyname>Yuille</keyname><forenames>Alan</forenames></author></authors><title>Discovering Internal Representations from Object-CNNs Using Population
  Encoding</title><categories>cs.LG cs.CV</categories><comments>This is the submission for ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we provide a method for understanding the internal
representations of Convolutional Neural Networks (CNNs) trained on objects. We
hypothesize that the information is distributed across multiple neuronal
responses and propose a simple clustering technique to extract this
information, which we call \emph{population encoding}. The population encoding
technique looks into the entrails of an object-CNN at multiple layers of the
network and shows the implicit presence of mid-level object part semantics
distributed in the neuronal responses. Our qualitative visualizations show that
population encoding can extract mid-level image patches that are visually
tighter than the patches that produce high single-filter activations. Moreover,
our comprehensive quantitative experiments using the object key point
annotations from the PASCAL3D+ dataset corroborate the visualizations by
demonstrating the superiority of population encoding over single-filter
detectors, in the task of object-part detection. We also perform some
preliminary experiments where we uncover the compositional relations between
the adjacent layers using the parts detected by population encoding clusters.
Finally, based on the insights gained from this work, we point to various new
directions which will enable us to have a better understanding of the CNN's
internal representations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06856</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06856</id><created>2015-11-21</created><authors><author><keyname>Kr&#xe4;henb&#xfc;hl</keyname><forenames>Philipp</forenames></author><author><keyname>Doersch</keyname><forenames>Carl</forenames></author><author><keyname>Donahue</keyname><forenames>Jeff</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Data-dependent Initializations of Convolutional Neural Networks</title><categories>cs.CV cs.LG</categories><comments>12 pages, Under review at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks spread through computer vision like a wildfire,
impacting almost all visual tasks imaginable. Despite this, few researchers
dare to train their models from scratch. Most work builds on one of a handful
of ImageNet pre-trained models, and fine-tunes or adapts these for specific
tasks. This is in large part due to the difficulty of properly initializing
these networks from scratch. A small miscalibration of the initial weights
leads to vanishing or exploding gradients, as well as poor convergence
properties. In this work we present a fast and simple data-dependent
initialization procedure, that sets the weights of a network such that all
units in the network train at roughly the same rate, avoiding vanishing or
exploding gradients. Our initialization matches the current state-of-the-art
unsupervised or self-supervised pre-training methods on standard computer
vision tasks, such as image classification and object detection, while being
roughly three orders of magnitude faster. When combined with pre-training
methods, our initialization significantly outperforms prior work, narrowing the
gap between supervised and unsupervised pre-training.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06858</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06858</id><created>2015-11-21</created><authors><author><keyname>Agarwal</keyname><forenames>Swati</forenames></author><author><keyname>Sureka</keyname><forenames>Ashish</forenames></author></authors><title>Applying Social Media Intelligence for Predicting and Identifying
  On-line Radicalization and Civil Unrest Oriented Threats</title><categories>cs.CY cs.SI</categories><comments>18 pages, 16 figures, 4 tables. This paper is a comprehensive and
  detailed literature survey to understand current state-of-the-art of Online
  Social Media Intelligence to counter and combat ISI related threats</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research shows that various social media platforms on Internet such as
Twitter, Tumblr (micro-blogging websites), Facebook (a popular social
networking website), YouTube (largest video sharing and hosting website), Blogs
and discussion forums are being misused by extremist groups for spreading their
beliefs and ideologies, promoting radicalization, recruiting members and
creating online virtual communities sharing a common agenda. Popular
microblogging websites such as Twitter are being used as a real-time platform
for information sharing and communication during planning and mobilization if
civil unrest related events. Applying social media intelligence for predicting
and identifying online radicalization and civil unrest oriented threats is an
area that has attracted several researchers' attention over past 10 years.
There are several algorithms, techniques and tools that have been proposed in
existing literature to counter and combat cyber-extremism and predicting
protest related events in much advance. In this paper, we conduct a literature
review of all these existing techniques and do a comprehensive analysis to
understand state-of-the-art, trends and research gaps. We present a one class
classification approach to collect scholarly articles targeting the topics and
subtopics of our research scope. We perform characterization, classification
and an in-depth meta analysis meta-anlaysis of about 100 conference and journal
papers to gain a better understanding of existing literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06860</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06860</id><created>2015-11-21</created><authors><author><keyname>Lu</keyname><forenames>Canyi</forenames></author><author><keyname>Yan</keyname><forenames>Shuicheng</forenames></author><author><keyname>Lin</keyname><forenames>Zhouchen</forenames></author></authors><title>Convex Sparse Spectral Clustering: Single-view to Multi-view</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectral Clustering (SC) is one of the most widely used methods for data
clustering. It first finds a low-dimensonal embedding $U$ of data by computing
the eigenvectors of the normalized Laplacian matrix, and then performs k-means
on $U^\top$ to get the final clustering result. In this work, we observe that,
in the ideal case, $UU^\top$ should be block diagonal and thus sparse.
Therefore we propose the Sparse Spectral Clustering (SSC) method which extends
SC with sparse regularization on $UU^\top$. To address the computational issue
of the nonconvex SSC model, we propose a novel convex relaxation of SSC based
on the convex hull of the fixed rank projection matrices. Then the convex SSC
model can be efficiently solved by the Alternating Direction Method of
Multiplier (ADMM). Furthermore, we propose the Pairwise Sparse Spectral
Clustering (PSSC) which extends SSC to boost the clustering performance by
using the multi-view information of data. Experimental comparisons with several
baselines on real-world datasets testify to the efficacy of our proposed
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06866</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06866</id><created>2015-11-21</created><authors><author><keyname>Gattami</keyname><forenames>Ather</forenames></author></authors><title>Feedback Capacity of Gaussian Channels Revisited</title><categories>cs.IT math.IT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we revisit the problem of finding the capacity of the Gaussian
feedback channel where we show new results and give new proofs to existing
results. In particular, we show that the channel capacity at stationarity can
be found by solving a semi-definite program, and hence computationally
tractable. We also give new proofs and structural results of the non stationary
solution which bridges the gap between results for the stationary and non
stationary feedback channel capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06881</identifier>
 <datestamp>2016-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06881</id><created>2015-11-21</created><updated>2016-01-07</updated><authors><author><keyname>Xia</keyname><forenames>Fangting</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Chen</keyname><forenames>Liang-Chieh</forenames></author><author><keyname>Yuille</keyname><forenames>Alan L.</forenames></author></authors><title>Zoom Better to See Clearer: Human Part Segmentation with Auto Zoom Net</title><categories>cs.CV cs.LG</categories><comments>Submitted to ICLR 2016 (Updated with more experiments)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parsing human regions into semantic parts, e.g., body, head and arms etc.,
from a random natural image is challenging while fundamental for computer
vision and widely applicable in industry. One major difficulty to handle such a
problem is the high flexibility of scale and location of a human instance and
its corresponding parts, making the parsing task either lack of boundary
details or suffer from local confusions. To tackle such problems, in this work,
we propose the &quot;Auto-Zoom Net&quot; (AZN) for human part parsing, which is a unified
fully convolutional neural network structure that: (1) parses each human
instance into detailed parts. (2) predicts the locations and scales of human
instances and their corresponding parts. In our unified network, the two tasks
are mutually beneficial. The score maps obtained for parsing help estimate the
locations and scales for human instances and their parts. With the predicted
locations and scales, our model &quot;zooms&quot; the region into a right scale to
further refine the parsing. In practice, we perform the two tasks iteratively
so that detailed human parts are gradually recovered. We conduct extensive
experiments over the challenging PASCAL-Person-Part segmentation, and show our
approach significantly outperforms the state-of-art parsing techniques
especially for instances and parts at small scale. In addition, we perform
experiments for horse and cow segmentation and also obtain results which are
considerably better than state-of-the-art methods (by over 5%)., which is
contribued by the proposed iterative zooming process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06888</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06888</id><created>2015-11-21</created><updated>2016-01-09</updated><authors><author><keyname>Kuang</keyname><forenames>Quan</forenames></author><author><keyname>Yu</keyname><forenames>Xiangbin</forenames></author><author><keyname>Utschick</keyname><forenames>Wolfgang</forenames></author></authors><title>Network Topology Adaptation and Interference Coordination for Energy
  Saving in Heterogeneous Networks</title><categories>cs.NI</categories><comments>accepted to 41st IEEE International Conference on Acoustics, Speech
  and Signal Processing (ICASSP 2016). This version includes the proof of
  Proposition 1</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference coupling in heterogeneous networks introduces the inherent
non-convexity to the network resource optimization problem, hindering the
development of effective solutions. A new framework based on multi-pattern
formulation has been proposed in this paper to study the energy efficient
strategy for joint cell activation, user association and multicell multiuser
channel allocation. One key feature of this interference pattern formulation is
that the patterns remain fixed and independent of the optimization process.
This creates a favorable opportunity for a linear programming formulation while
still taking interference coupling into account. A tailored algorithm is
developed to solve the formulated network energy saving problem in the dual
domain by exploiting the problem structure, which gives a significant
complexity saving compared to using standard solvers. Numerical results show a
huge improvement in energy saving achieved by the proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06890</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06890</id><created>2015-11-21</created><authors><author><keyname>Ling</keyname><forenames>Chun Kai</forenames></author><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author><author><keyname>Jaillet</keyname><forenames>Patrick</forenames></author></authors><title>Gaussian Process Planning with Lipschitz Continuous Reward Functions:
  Towards Unifying Bayesian Optimization, Active Learning, and Beyond</title><categories>stat.ML cs.AI cs.LG cs.RO</categories><comments>30th AAAI Conference on Artificial Intelligence (AAAI 2016), Extended
  version with proofs, 17 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel nonmyopic adaptive Gaussian process planning
(GPP) framework endowed with a general class of Lipschitz continuous reward
functions that can unify some active learning/sensing and Bayesian optimization
criteria and offer practitioners some flexibility to specify their desired
choices for defining new tasks/problems. In particular, it utilizes a
principled Bayesian sequential decision problem framework for jointly and
naturally optimizing the exploration-exploitation trade-off. In general, the
resulting induced GPP policy cannot be derived exactly due to an uncountable
set of candidate observations. A key contribution of our work here thus lies in
exploiting the Lipschitz continuity of the reward functions to solve for a
nonmyopic adaptive epsilon-optimal GPP (epsilon-GPP) policy. To plan in real
time, we further propose an asymptotically optimal, branch-and-bound anytime
variant of epsilon-GPP with performance guarantee. We empirically demonstrate
the effectiveness of our epsilon-GPP policy and its anytime variant in Bayesian
optimization and an energy harvesting task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06891</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06891</id><created>2015-11-21</created><updated>2015-11-24</updated><authors><author><keyname>Zhang</keyname><forenames>Yehong</forenames></author><author><keyname>Hoang</keyname><forenames>Trong Nghia</forenames></author><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author><author><keyname>Kankanhalli</keyname><forenames>Mohan</forenames></author></authors><title>Near-Optimal Active Learning of Multi-Output Gaussian Processes</title><categories>stat.ML cs.AI cs.LG</categories><comments>30th AAAI Conference on Artificial Intelligence (AAAI 2016), Extended
  version with proofs, 13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of active learning of a multi-output
Gaussian process (MOGP) model representing multiple types of coexisting
correlated environmental phenomena. In contrast to existing works, our active
learning problem involves selecting not just the most informative sampling
locations to be observed but also the types of measurements at each selected
location for minimizing the predictive uncertainty (i.e., posterior joint
entropy) of a target phenomenon of interest given a sampling budget.
Unfortunately, such an entropy criterion scales poorly in the numbers of
candidate sampling locations and selected observations when optimized. To
resolve this issue, we first exploit a structure common to sparse MOGP models
for deriving a novel active learning criterion. Then, we exploit a relaxed form
of submodularity property of our new criterion for devising a polynomial-time
approximation algorithm that guarantees a constant-factor approximation of that
achieved by the optimal set of selected observations. Empirical evaluation on
real-world datasets shows that our proposed approach outperforms existing
algorithms for active learning of MOGP and single-output GP models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06892</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06892</id><created>2015-11-21</created><authors><author><keyname>Frackiewicz</keyname><forenames>Piotr</forenames></author></authors><title>Quantum approach to Bertrand duopoly</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of the paper is to study the Bertrand duopoly example in the quantum
domain. We use two ways to write the game in terms of quantum theory. The first
one adapts the Li-Du-Massar scheme for the Cournot duopoly. The second one is a
simplified model that exploits a two qubit entangled state. In both cases we
focus on finding Nash equilibria in the resulting games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06905</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06905</id><created>2015-11-21</created><authors><author><keyname>Kare</keyname><forenames>Anjeneya Swami</forenames></author></authors><title>A Simple Algorithm For Replacement Paths Problem</title><categories>cs.DS</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let G=(V,E)(|V|=n and |E|=m) be an undirected graph with positive edge
weights. Let P_{G}(s, t) be a shortest s-t path in G. Let l be the number of
edges in P_{G}(s, t). The \emph{Edge Replacement Path} problem is to compute a
shortest s-t path in G\{e}, for every edge e in P_{G}(s, t). The \emph{Node
Replacement Path} problem is to compute a shortest s-t path in G\{v}, for every
vertex v in P_{G}(s, t). In this paper we present an O(T_{SPT}(G)+m+l^2) time
and O(m+l^2) space algorithm for both the problems. Where, T_{SPT}(G) is the
asymptotic time to compute a single source shortest path tree in G. The
proposed algorithm is simple and easy to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06909</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06909</id><created>2015-11-21</created><updated>2016-02-21</updated><authors><author><keyname>Ji</keyname><forenames>Shihao</forenames></author><author><keyname>Vishwanathan</keyname><forenames>S. V. N.</forenames></author><author><keyname>Satish</keyname><forenames>Nadathur</forenames></author><author><keyname>Anderson</keyname><forenames>Michael J.</forenames></author><author><keyname>Dubey</keyname><forenames>Pradeep</forenames></author></authors><title>BlackOut: Speeding up Recurrent Neural Network Language Models With Very
  Large Vocabularies</title><categories>cs.LG cs.CL cs.NE stat.ML</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose BlackOut, an approximation algorithm to efficiently train massive
recurrent neural network language models (RNNLMs) with million word
vocabularies. BlackOut is motivated by using a discriminative loss, and we
describe a new sampling strategy which significantly reduces computation while
improving stability, sample efficiency, and rate of convergence. One way to
understand BlackOut is to view it as an extension of the DropOut strategy to
the output layer, wherein we use a discriminative training loss and a weighted
sampling scheme. We also establish close connections between BlackOut,
importance sampling, and noise contrastive estimation (NCE). Our experiments,
on the recently released one billion word language modeling benchmark,
demonstrate scalability and accuracy of BlackOut; we outperform the
state-of-the art, and achieve the lowest perplexity scores on this dataset.
Moreover, unlike other established methods which typically require GPUs or CPU
clusters, we show that a carefully implemented version of BlackOut requires
only 1-10 days on a single machine to train a RNNLM with a million word
vocabulary and billions of parameters on one billion words. Although we
describe BlackOut in the context of RNNLM training, it can be used to any
networks with large softmax output layers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06910</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06910</id><created>2015-11-21</created><authors><author><keyname>AlNuaimi</keyname><forenames>Noura</forenames></author><author><keyname>Masud</keyname><forenames>Mohammad M</forenames></author><author><keyname>Mohammed</keyname><forenames>Farhan</forenames></author></authors><title>ICU Patient Deterioration prediction: a Data-Mining Approach</title><categories>cs.CY cs.LG</categories><comments>16 pages, 3 figures, 10 tables, confeence</comments><doi>10.5121/csit.2015.51517</doi><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  A huge amount of medical data is generated every day, which presents a
challenge in analysing these data. The obvious solution to this challenge is to
reduce the amount of data without information loss. Dimension reduction is
considered the most popular approach for reducing data size and also to reduce
noise and redundancies in data. In this paper, we investigate the effect of
feature selection in improving the prediction of patient deterioration in ICUs.
We consider lab tests as features. Thus, choosing a subset of features would
mean choosing the most important lab tests to perform. If the number of tests
can be reduced by identifying the most important tests, then we could also
identify the redundant tests. By omitting the redundant tests, observation time
could be reduced and early treatment could be provided to avoid the risk.
Additionally, unnecessary monetary cost would be avoided. Our approach uses
state-ofthe- art feature selection for predicting ICU patient deterioration
using the medical lab results. We apply our technique on the publicly available
MIMIC-II database and show the effectiveness of the feature selection. We also
provide a detailed analysis of the best features identified by our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06911</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06911</id><created>2015-11-21</created><authors><author><keyname>Minaee</keyname><forenames>Shervin</forenames></author><author><keyname>Abdolrashidi</keyname><forenames>Amirali</forenames></author><author><keyname>Wang</keyname><forenames>Yao</forenames></author></authors><title>Screen Content Image Segmentation Using Sparse-Smooth Decomposition</title><categories>cs.CV</categories><comments>Asilomar Conference on Signals, Systems and Computers, IEEE, 2015,
  (to Appear)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse decomposition has been extensively used for different applications
including signal compression and denoising and document analysis. In this
paper, sparse decomposition is used for image segmentation. The proposed
algorithm separates the background and foreground using a sparse-smooth
decomposition technique such that the smooth and sparse components correspond
to the background and foreground respectively. This algorithm is tested on
several test images from HEVC test sequences and is shown to have superior
performance over other methods, such as the hierarchical k-means clustering in
DjVu. This segmentation algorithm can also be used for text extraction, video
compression and medical image segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06915</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06915</id><created>2015-11-21</created><authors><author><keyname>Wilcox</keyname><forenames>H.</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Maumita</forenames></author></authors><title>Countering Social Engineering through Social Media: An Enterprise
  Security Perspective</title><categories>cs.CY cs.CR</categories><comments>Proceedings of The 7th International Conference on Computational
  Collective Intelligence Technologies and Applications (ICCCI 2015), LNAI,
  Springer, Vol. 9330, pp. 54-64</comments><msc-class>68-06</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing threat of social engineers targeting social media channels to
advance their attack effectiveness on company data has seen many organizations
introducing initiatives to better understand these vulnerabilities. This paper
examines concerns of social engineering through social media within the
enterprise and explores countermeasures undertaken to stem ensuing risk. Also
included is an analysis of existing social media security policies and
guidelines within the public and private sectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06918</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06918</id><created>2015-11-21</created><authors><author><keyname>Roughgarden</keyname><forenames>Tim</forenames></author><author><keyname>Schrijvers</keyname><forenames>Okke</forenames></author></authors><title>Ironing in the Dark</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the first polynomial-time algorithm for position and
matroid auction environments that learns, from samples from an unknown bounded
valuation distribution, an auction with expected revenue arbitrarily close to
the maximum possible. In contrast to most previous work, our results apply to
arbitrary (not necessarily regular) distributions and the strongest possible
benchmark, the Myerson-optimal auction. Learning a near-optimal auction for an
irregular distribution is technically challenging because it requires learning
the appropriate &quot;ironed intervals,&quot; a delicate global property of the
distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06919</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06919</id><created>2015-11-21</created><authors><author><keyname>Kainz</keyname><forenames>Philipp</forenames></author><author><keyname>Pfeiffer</keyname><forenames>Michael</forenames></author><author><keyname>Urschler</keyname><forenames>Martin</forenames></author></authors><title>Semantic Segmentation of Colon Glands with Deep Convolutional Neural
  Networks and Total Variation Segmentation</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Segmentation of histopathology sections is an ubiquitous requirement in
digital pathology and due to the large variability of biological tissue,
machine learning techniques have shown superior performance over standard image
processing methods. As part of the GlaS@MICCAI2015 colon gland segmentation
challenge, we present a learning-based algorithm to segment glands in tissue of
benign and malignant colorectal cancer. Images are preprocessed according to
the Hematoxylin-Eosin staining protocol and two deep convolutional neural
networks (CNN) are trained as pixel classifiers. The CNN predictions are then
regularized using a figure-ground segmentation based on weighted total
variation to produce the final segmentation result. On two test sets, our
approach achieves a tissue classification accuracy of 98% and 94%, making use
of the inherent capability of our system to distinguish between benign and
malignant tissue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06931</identifier>
 <datestamp>2016-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06931</id><created>2015-11-21</created><updated>2016-01-05</updated><authors><author><keyname>Dodge</keyname><forenames>Jesse</forenames></author><author><keyname>Gane</keyname><forenames>Andreea</forenames></author><author><keyname>Zhang</keyname><forenames>Xiang</forenames></author><author><keyname>Bordes</keyname><forenames>Antoine</forenames></author><author><keyname>Chopra</keyname><forenames>Sumit</forenames></author><author><keyname>Miller</keyname><forenames>Alexander</forenames></author><author><keyname>Szlam</keyname><forenames>Arthur</forenames></author><author><keyname>Weston</keyname><forenames>Jason</forenames></author></authors><title>Evaluating Prerequisite Qualities for Learning End-to-End Dialog Systems</title><categories>cs.CL cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A long-term goal of machine learning is to build intelligent conversational
agents. One recent popular approach is to train end-to-end models on a large
amount of real dialog transcripts between humans (Sordoni et al., 2015; Vinyals
&amp; Le, 2015; Shang et al., 2015). However, this approach leaves many questions
unanswered as an understanding of the precise successes and shortcomings of
each model is hard to assess. A contrasting recent proposal are the bAbI tasks
(Weston et al., 2015b) which are synthetic data that measure the ability of
learning machines at various reasoning tasks over toy language. Unfortunately,
those tests are very small and hence may encourage methods that do not scale.
In this work, we propose a suite of new tasks of a much larger scale that
attempt to bridge the gap between the two regimes. Choosing the domain of
movies, we provide tasks that test the ability of models to answer factual
questions (utilizing OMDB), provide personalization (utilizing MovieLens),
carry short conversations about the two, and finally to perform on natural
dialogs from Reddit. We provide a dataset covering 75k movie entities and with
3.5M training examples. We present results of various models on these tasks,
and evaluate their performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06936</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06936</id><created>2015-11-21</created><authors><author><keyname>Sabokrou</keyname><forenames>Mohammad</forenames></author><author><keyname>Fathy</keyname><forenames>Mahmood</forenames></author><author><keyname>Hosseini</keyname><forenames>Mojtaba</forenames></author><author><keyname>Klette</keyname><forenames>Reinhard</forenames></author></authors><title>Real-Time Anomaly Detection and Localization in Crowded Scenes</title><categories>cs.CV</categories><comments>CVPRw 2015</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In this paper, we propose a method for real-time anomaly detection and
localization in crowded scenes. Each video is defined as a set of
non-overlapping cubic patches, and is described using two local and global
descriptors. These descriptors capture the video properties from different
aspects. By incorporating simple and cost-effective Gaussian classifiers, we
can distinguish normal activities and anomalies in videos. The local and global
features are based on structure similarity between adjacent patches and the
features learned in an unsupervised way, using a sparse auto- encoder.
Experimental results show that our algorithm is comparable to a
state-of-the-art procedure on UCSD ped2 and UMN benchmarks, but even more
time-efficient. The experiments confirm that our system can reliably detect and
localize anomalies as soon as they happen in a video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06938</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06938</id><created>2015-11-21</created><updated>2016-02-22</updated><authors><author><keyname>Samimi</keyname><forenames>Mathew K.</forenames></author><author><keyname>MacCartney,</keyname><forenames>George R.</forenames><suffix>Jr.</suffix></author><author><keyname>Sun</keyname><forenames>Shu</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>28 GHz Millimeter-Wave Ultrawideband Small-Scale Fading Models in
  Wireless Channels</title><categories>cs.IT math.IT</categories><comments>6 pages, 9 figures, to be published in the 2016 IEEE Vehicular
  Technology Conference (VTC2016-Spring), 15-18 May, 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents small-scale fading measurements for 28 GHz outdoor
millimeter-wave ultrawideband channels using directional horn antennas at the
transmitter and receiver. Power delay profiles were measured at half-wavelength
spatial increments over a local area (33 wavelengths) on a linear track in two
orthogonal receiver directions in a typical base-to-mobile scenario with fixed
transmitter and receiver antenna beam pointing directions. The voltage path
amplitudes are shown to follow a Rician distribution, with K-factor ranging
from 9 - 15 dB and 5 - 8 dB in line of sight (LOS) and non-line of sight (NLOS)
for a vertical-to-vertical co-polarized antenna scenario, respectively, and
from 3 - 7 dB in both LOS and NLOS vertical-to-horizontal cross-polarized
antenna scenario. The average spatial autocorrelation functions of individual
multipath components reveal that signal amplitudes reach a correlation of 0
after 2 and 5 wavelengths in LOS and NLOS co-polarized V-V antenna scenarios.
The models provided are useful for recreating path gain statistics of
millimeter-wave wideband channel impulse responses over local areas, for the
study of multi-element antenna simulations and channel estimation algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06939</identifier>
 <datestamp>2016-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06939</id><created>2015-11-21</created><updated>2016-02-17</updated><authors><author><keyname>Hidasi</keyname><forenames>Bal&#xe1;zs</forenames></author><author><keyname>Karatzoglou</keyname><forenames>Alexandros</forenames></author><author><keyname>Baltrunas</keyname><forenames>Linas</forenames></author><author><keyname>Tikk</keyname><forenames>Domonkos</forenames></author></authors><title>Session-based Recommendations with Recurrent Neural Networks</title><categories>cs.LG cs.IR cs.NE</categories><comments>Camera ready version (17th February, 2016)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply recurrent neural networks (RNN) on a new domain, namely recommender
systems. Real-life recommender systems often face the problem of having to base
recommendations only on short session-based data (e.g. a small sportsware
website) instead of long user histories (as in the case of Netflix). In this
situation the frequently praised matrix factorization approaches are not
accurate. This problem is usually overcome in practice by resorting to
item-to-item recommendations, i.e. recommending similar items. We argue that by
modeling the whole session, more accurate recommendations can be provided. We
therefore propose an RNN-based approach for session-based recommendations. Our
approach also considers practical aspects of the task and introduces several
modifications to classic RNNs such as a ranking loss function that make it more
viable for this specific problem. Experimental results on two data-sets show
marked improvements over widely used approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06940</identifier>
 <datestamp>2016-01-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06940</id><created>2015-11-21</created><updated>2016-01-27</updated><authors><author><keyname>Samimi</keyname><forenames>Mathew K.</forenames></author><author><keyname>Sun</keyname><forenames>Shu</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>MIMO Channel Modeling and Capacity Analysis for 5G Millimeter-Wave
  Wireless Systems</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures, accepted in the 10th European Conference on
  Antennas and Propagation (EuCAP'2016), April 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a 3-D statistical channel model of the impulse response
with small-scale spatially correlated random coefficients for multi-element
transmitter and receiver antenna arrays, derived using the physically-based
time cluster - spatial lobe (TCSL) clustering scheme. The small-scale
properties of multipath amplitudes are modeled based on 28 GHz outdoor
millimeter-wave small-scale local area channel measurements. The wideband
channel capacity is evaluated by considering measurement-based
Rician-distributed voltage amplitudes, and the spatial autocorrelation of
multipath amplitudes for each pair of transmitter and receiver antenna
elements. Results indicate that Rician channels may exhibit equal or possibly
greater capacity compared to Rayleigh channels, depending on the number of
antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06941</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06941</id><created>2015-11-21</created><updated>2016-02-15</updated><authors><author><keyname>Samimi</keyname><forenames>Mathew K.</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>Local Multipath Model Parameters for Generating 5G Millimeter-Wave
  3GPP-like Channel Impulse Response</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, accepted in the 10th European Conference on
  Antennas and Propagation (EuCAP'2016), April 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents 28 GHz and 73 GHz empirically-derived large-scale and
small-scale channel model parameters that characterize average temporal and
angular properties of multipaths. Omnidirectional azimuth scans at both the
transmitter and receiver used high gain directional antennas, from which global
3GPP modeling parameters for the mean global azimuth and zenith spreads of
arrival were found to be 22 degrees and 6.2 degrees at 28 GHz, and 37.1 degrees
and 3.8 degrees at 73 GHz, respectively, in non-line of sight (NLOS).
Small-scale spatial measurements at 28 GHz reveal a mean cross-polar ratio for
individual multipath components of 29.7 dB and 16.7 dB in line of sight and
NLOS, respectively. Small-scale parameters extracted using the KPowerMeans
algorithm yielded on average 5.3 and 4.6 clusters at 28 GHz and 73 GHz,
respectively, in NLOS. The time cluster - spatial lobe (TCSL) modeling approach
uses an alternative physically-based binning procedure and recreates 3GPP model
parameters to generate channel impulse responses, as well as new parameters
like the RMS lobe angular spreads useful in quantifying millimeter-wave
directionality. The TCSL algorithm faithfully reproduces first- and
second-order statistics of measured millimeter-wave channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06951</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06951</id><created>2015-11-21</created><authors><author><keyname>Smith</keyname><forenames>Leslie N.</forenames></author><author><keyname>Hand</keyname><forenames>Emily M.</forenames></author><author><keyname>Doster</keyname><forenames>Timothy</forenames></author></authors><title>Gradual DropIn of Layers to Train Very Deep Neural Networks</title><categories>cs.NE cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of dynamically growing a neural network during
training. In particular, an untrainable deep network starts as a trainable
shallow network and newly added layers are slowly, organically added during
training, thereby increasing the network's depth. This is accomplished by a new
layer, which we call DropIn. The DropIn layer starts by passing the output from
a previous layer (effectively skipping over the newly added layers), then
increasingly including units from the new layers for both feedforward and
backpropagation. We show that deep networks, which are untrainable with
conventional methods, will converge with DropIn layers interspersed in the
architecture. In addition, we demonstrate that DropIn provides regularization
during training in an analogous way as dropout. Experiments are described with
the MNIST dataset and various expanded LeNet architectures, CIFAR-10 dataset
with its architecture expanded from 3 to 11 layers, and on the ImageNet dataset
with the AlexNet architecture expanded to 13 layers and the VGG 16-layer
architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06954</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06954</id><created>2015-11-21</created><updated>2016-02-08</updated><authors><author><keyname>Borodin</keyname><forenames>Allan</forenames></author><author><keyname>Lev</keyname><forenames>Omer</forenames></author><author><keyname>Strangway</keyname><forenames>Tyrone</forenames></author></authors><title>Budgetary Effects on Pricing Equilibrium in Online Markets</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Following the work of Babaioff et al, we consider the pricing game with
strategic vendors and a single buyer, modeling a scenario in which multiple
competing vendors have very good knowledge of a buyer, as is common in online
markets. We add to this model the realistic assumption that the buyer has a
fixed budget and does not have unlimited funds. When the buyer's valuation
function is additive, we are able to completely characterize the different
possible pure Nash Equilibria (PNE) and in particular obtain a necessary and
sufficient condition for uniqueness. Furthermore, we characterize the market
clearing (or Walresian) equilibria for all submodular valuations.
  Surprisingly, for certain monotone submodular function valuations, we show
that the pure NE can exhibit some counterintuitive phenomena; namely, there is
a valuation such that the pricing will be market clearing and within budget if
the buyer does not reveal the budget but will result in a smaller set of
allocated items (and higher prices for items) if the buyer does reveal the
budget. It is also the case that the conditions that guarantee market clearing
in Babaioff et al for submodular functions are not necessarily market clearing
when there is a budget. Furthermore, with respect to social welfare, while
without budgets all equilibria are optimal (i.e. POA = POS = 1), we show that
with budgets the worst equilibrium may only achieve 1/(n-2) of the best
equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06960</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06960</id><created>2015-11-21</created><authors><author><keyname>Huang</keyname><forenames>Pengfei</forenames></author><author><keyname>Yaakobi</keyname><forenames>Eitan</forenames></author><author><keyname>Uchikawa</keyname><forenames>Hironori</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author></authors><title>Binary Linear Locally Repairable Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Locally repairable codes (LRCs) are a class of codes designed for the local
correction of erasures. They have received considerable attention in recent
years due to their applications in distributed storage. Most existing results
on LRCs do not explicitly take into consideration the field size $q$, i.e., the
size of the code alphabet. In particular, for the binary case, only a few
results are known.
  In this work, we present an upper bound on the minimum distance $d$ of linear
LRCs with availability, based on the work of Cadambe and Mazumdar. The bound
takes into account the code length $n$, dimension $k$, locality $r$,
availability $t$, and field size $q$. Then, we study binary linear LRCs in
three aspects. First, we focus on analyzing the locality of some classical
codes, i.e., cyclic codes and Reed-Muller codes, and their modified versions,
which are obtained by applying the operations of extend, shorten, expurgate,
augment, and lengthen. Next, we construct LRCs using phantom parity-check
symbols and multi-level tensor product structure, respectively. Compared to
other previous constructions of binary LRCs with fixed locality or minimum
distance, our construction is much more flexible in terms of code parameters,
and gives various families of high-rate LRCs, some of which are shown to be
optimal with respect to their minimum distance. Finally, availability of LRCs
is studied. We investigate the locality and availability properties of several
classes of one-step majority-logic decodable codes, including cyclic simplex
codes, cyclic difference-set codes, and $4$-cycle free regular low-density
parity-check (LDPC) codes. We also show the construction of a long LRC with
availability from a short one-step majority-logic decodable code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06961</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06961</id><created>2015-11-21</created><authors><author><keyname>Lee</keyname><forenames>Lisa Seung-Yeon</forenames></author></authors><title>On the Linear Algebraic Structure of Distributed Word Representations</title><categories>cs.CL cs.LG</categories><comments>55 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we leverage the linear algebraic structure of distributed word
representations to automatically extend knowledge bases and allow a machine to
learn new facts about the world. Our goal is to extract structured facts from
corpora in a simpler manner, without applying classifiers or patterns, and
using only the co-occurrence statistics of words. We demonstrate that the
linear algebraic structure of word embeddings can be used to reduce data
requirements for methods of learning facts. In particular, we demonstrate that
words belonging to a common category, or pairs of words satisfying a certain
relation, form a low-rank subspace in the projected space. We compute a basis
for this low-rank subspace using singular value decomposition (SVD), then use
this basis to discover new facts and to fit vectors for less frequent words
which we do not yet have vectors for.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06964</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06964</id><created>2015-11-21</created><updated>2016-01-18</updated><authors><author><keyname>Ororbia</keyname><forenames>Alexander G.</forenames><suffix>II</suffix></author><author><keyname>Giles</keyname><forenames>C. Lee</forenames></author><author><keyname>Reitter</keyname><forenames>David</forenames></author></authors><title>Online Semi-Supervised Learning with Deep Hybrid Boltzmann Machines and
  Denoising Autoencoders</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two novel deep hybrid architectures, the Deep Hybrid Boltzmann Machine and
the Deep Hybrid Denoising Auto-encoder, are proposed for handling
semi-supervised learning problems. The models combine experts that model
relevant distributions at different levels of abstraction to improve overall
predictive performance on discriminative tasks. Theoretical motivations and
algorithms for joint learning for each are presented. We apply the new models
to the domain of data-streams in work towards life-long learning. The proposed
architectures show improved performance compared to a pseudo-labeled, drop-out
rectifier network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06965</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06965</id><created>2015-11-21</created><authors><author><keyname>Darais</keyname><forenames>David</forenames></author><author><keyname>Van Horn</keyname><forenames>David</forenames></author></authors><title>Constructive Galois Connections: Taming the Galois Connection Framework
  for Mechanized Metatheory</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Galois connections are a foundational tool for structuring abstraction in
semantics and their use lies at the heart of the theory of abstract
interpretation. Yet, mechanization of Galois connections has remained limited
to certain restricted modes of use, preventing their fully general application
in mechanized metatheory and certified programming.
  This paper presents constructive Galois connections, a framework for Galois
connections that is effective both on paper and in proof assistants; is
complete with respect to the set of Galois connections with computational
content; and enables more general reasoning principles, including the
&quot;calculational&quot; style advocated by Cousot.
  Crucial to our technical approach is the addition of monadic structure to
Galois connections to control a &quot;specification effect.&quot; Effectful calculations
may reason classically, while pure calculations have extractable computational
content. Explicitly moving between the worlds of specification and
implementation is enabled by our metatheory.
  To validate our approach, we provide two case studies in mechanizing existing
proofs from the literature: one uses calculational abstract interpretation to
design a static analyzer, the other forms a semantic basis for gradual typing.
Both mechanized proofs closely follow their original paper-and-pencil
counterparts, employ reasoning principles not captured by previous
mechanization approaches, support the extraction of verified algorithms, and
are novel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06968</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06968</id><created>2015-11-22</created><authors><author><keyname>Prabhakar</keyname><forenames>Raghu</forenames></author><author><keyname>Koeplinger</keyname><forenames>David</forenames></author><author><keyname>Brown</keyname><forenames>Kevin</forenames></author><author><keyname>Lee</keyname><forenames>HyoukJoong</forenames></author><author><keyname>De Sa</keyname><forenames>Christopher</forenames></author><author><keyname>Kozyrakis</keyname><forenames>Christos</forenames></author><author><keyname>Olukotun</keyname><forenames>Kunle</forenames></author></authors><title>Generating Configurable Hardware from Parallel Patterns</title><categories>cs.DC cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years the computing landscape has seen an in- creasing shift
towards specialized accelerators. Field pro- grammable gate arrays (FPGAs) are
particularly promising as they offer significant performance and energy
improvements compared to CPUs for a wide class of applications and are far more
flexible than fixed-function ASICs. However, FPGAs are difficult to program.
Traditional programming models for reconfigurable logic use low-level hardware
description languages like Verilog and VHDL, which have none of the pro-
ductivity features of modern software development languages but produce very
efficient designs, and low-level software lan- guages like C and OpenCL coupled
with high-level synthesis (HLS) tools that typically produce designs that are
far less efficient. Functional languages with parallel patterns are a better
fit for hardware generation because they both provide high-level abstractions
to programmers with little experience in hard- ware design and avoid many of
the problems faced when gen- erating hardware from imperative languages. In
this paper, we identify two optimizations that are important when using par-
allel patterns to generate hardware: tiling and metapipelining. We present a
general representation of tiled parallel patterns, and provide rules for
automatically tiling patterns and gen- erating metapipelines. We demonstrate
experimentally that these optimizations result in speedups up to 40x on a set
of benchmarks from the data analytics domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06971</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06971</id><created>2015-11-22</created><authors><author><keyname>Al-Abbasi</keyname><forenames>Abubakr O.</forenames></author><author><keyname>Hamila</keyname><forenames>Ridha</forenames></author><author><keyname>Bajwa</keyname><forenames>Waheed U.</forenames></author><author><keyname>Al-Dhahir</keyname><forenames>Naofal</forenames></author></authors><title>A General Framework for the Design and Analysis of Sparse FIR Linear
  Equalizers</title><categories>cs.IT math.IT</categories><comments>7 pages, 4 figures, IEEE GlobalSIP'15 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complexity of linear finite-impulse-response (FIR) equalizers is proportional
to the square of the number of nonzero taps in the filter. This makes
equalization of channels with long impulse responses using either zero-forcing
or minimum mean square error (MMSE) filters computationally expensive. Sparse
equalization is a widely-used technique to solve this problem. In this paper, a
general framework is provided that transforms the problem of sparse linear
equalizers (LEs) design into the problem of sparsest-approximation of a vector
in different dictionaries. In addition, some possible choices of sparsifying
dictionaries in this framework are discussed. Furthermore, the worst-case
coherence of some of these dictionaries, which determines their sparsifying
strength, are analytically and/or numerically evaluated. Finally, the
usefulness of the proposed framework for the design of sparse FIR LEs is
validated through numerical experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06973</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06973</id><created>2015-11-22</created><authors><author><keyname>Wu</keyname><forenames>Qi</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Hengel</keyname><forenames>Anton van den</forenames></author><author><keyname>Dick</keyname><forenames>Anthony</forenames></author></authors><title>Ask Me Anything: Free-form Visual Question Answering Based on Knowledge
  from External Sources</title><categories>cs.CV</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for visual question answering which combines an internal
representation of the content of an image with information extracted from a
general knowledge base to answer a broad range of image-based questions. This
allows more complex questions to be answered using the predominant neural
network-based approach than has previously been possible. It particularly
allows questions to be asked about the contents of an image, even when the
image itself does not contain the whole answer. The method constructs a textual
representation of the semantic content of an image, and merges it with textual
information sourced from a knowledge base, to develop a deeper understanding of
the scene viewed. Priming a recurrent neural network with this combined
information, and the submitted question, leads to a very flexible visual
question answering approach. We are specifically able to answer questions posed
in natural language, that refer to information not contained in the image. We
demonstrate the effectiveness of our model on two publicly available datasets,
Toronto COCO-QA and MS COCO-VQA and show that it produces the best reported
results in both cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06975</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06975</id><created>2015-11-22</created><authors><author><keyname>Renjith</keyname><forenames>Shini</forenames></author></authors><title>An Integrated Framework to Recommend Personalized Retention Actions to
  Control B2C E-Commerce Customer Churn</title><categories>cs.IR cs.CY</categories><comments>6 pages, 7 figures, Published with International Journal of
  Engineering Trends and Technology (IJETT)</comments><journal-ref>IJETT, V27(3),152-157 September 2015. ISSN:2231-5381.
  www.ijettjournal.org</journal-ref><doi>10.14445/22315381/IJETT-V27P227</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering the level of competition prevailing in Business-to-Consumer (B2C)
E-Commerce domain and the huge investments required to attract new customers,
firms are now giving more focus to reduce their customer churn rate. Churn rate
is the ratio of customers who part away with the firm in a specific time
period. One of the best mechanism to retain current customers is to identify
any potential churn and respond fast to prevent it. Detecting early signs of a
potential churn, recognizing what the customer is looking for by the movement
and automating personalized win back campaigns are essential to sustain
business in this era of competition. E-Commerce firms normally possess large
volume of data pertaining to their existing customers like transaction history,
search history, periodicity of purchases, etc. Data mining techniques can be
applied to analyse customer behaviour and to predict the potential customer
attrition so that special marketing strategies can be adopted to retain them.
This paper proposes an integrated model that can predict customer churn and
also recommend personalized win back actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06982</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06982</id><created>2015-11-22</created><authors><author><keyname>Chow</keyname><forenames>Yin-Lam</forenames></author><author><keyname>Pavone</keyname><forenames>Marco</forenames></author><author><keyname>Sadler</keyname><forenames>Brian M.</forenames></author><author><keyname>Carpin</keyname><forenames>Stefano</forenames></author></authors><title>Trading Safety Versus Performance: Rapid Deployment of Robotic Swarms
  with Robust Performance Constraints</title><categories>cs.RO math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a stochastic deployment problem, where a robotic
swarm is tasked with the objective of positioning at least one robot at each of
a set of pre-assigned targets while meeting a temporal deadline. Travel times
and failure rates are stochastic but related, inasmuch as failure rates
increase with speed. To maximize chances of success while meeting the deadline,
a control strategy has therefore to balance safety and performance. Our
approach is to cast the problem within the theory of constrained Markov
Decision Processes, whereby we seek to compute policies that maximize the
probability of successful deployment while ensuring that the expected duration
of the task is bounded by a given deadline. To account for uncertainties in the
problem parameters, we consider a robust formulation and we propose efficient
solution algorithms, which are of independent interest. Numerical experiments
confirming our theoretical results are presented and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06984</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06984</id><created>2015-11-22</created><authors><author><keyname>Yeung</keyname><forenames>Serena</forenames></author><author><keyname>Russakovsky</keyname><forenames>Olga</forenames></author><author><keyname>Mori</keyname><forenames>Greg</forenames></author><author><keyname>Fei-Fei</keyname><forenames>Li</forenames></author></authors><title>End-to-end Learning of Action Detection from Frame Glimpses in Videos</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we introduce a fully end-to-end approach for action detection in
videos that learns to directly predict the temporal bounds of actions. Our
intuition is that the process of detecting actions is naturally one of
observation and refinement: observing moments in video, and refining hypotheses
about when an action is occurring. Based on this insight, we formulate our
model as a recurrent neural network-based agent that interacts with a video
over time. The agent observes video frames and decides both where to look next
and when to emit a prediction. Since backpropagation is not adequate in this
non-differentiable setting, we use REINFORCE to learn the agent's decision
policy. Our model achieves state-of-the-art results on the THUMOS'14 and
ActivityNet datasets while observing only a fraction (2% or less) of the video
frames.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06987</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06987</id><created>2015-11-22</created><authors><author><keyname>Eremeev</keyname><forenames>Anton V.</forenames></author></authors><title>Evolutionary algorithms</title><categories>cs.NE</categories><comments>Outline of lectures course &quot;Evolutionary Algorithms&quot; (in Russian)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This manuscript contains an outline of lectures course &quot;Evolutionary
Algorithms&quot; read by the author in Omsk State University n.a. F.M.Dostoevsky.
The course covers Canonic Genetic Algorithm and various other genetic
algorithms as well as evolutioanry algorithms in general. Some facts, such as
the Rotation Property of crossover, the Schemata Theorem, GA performance as a
local search and &quot;almost surely&quot; convergence of evolutionary algorithms are
given with complete proofs. The text is in Russian.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06988</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06988</id><created>2015-11-22</created><authors><author><keyname>Zheng</keyname><forenames>Haitian</forenames></author><author><keyname>Liu</keyname><forenames>Yebin</forenames></author><author><keyname>Ji</keyname><forenames>Mengqi</forenames></author><author><keyname>Wu</keyname><forenames>Feng</forenames></author><author><keyname>Fang</keyname><forenames>Lu</forenames></author></authors><title>Learning High-level Prior with Convolutional Neural Networks for
  Semantic Segmentation</title><categories>cs.CV</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a convolutional neural network that can fuse high-level
prior for semantic image segmentation. Motivated by humans' vision recognition
system, our key design is a three-layer generative structure consisting of
high-level coding, middle-level segmentation and low-level image to introduce
global prior for semantic segmentation. Based on this structure, we proposed a
generative model called conditional variational auto-encoder (CVAE) that can
build up the links behind these three layers. These important links include an
image encoder that extracts high level info from image, a segmentation encoder
that extracts high level info from segmentation, and a hybrid decoder that
outputs semantic segmentation from the high level prior and input image. We
theoretically derive the semantic segmentation as an optimization problem
parameterized by these links. Finally, the optimization problem enables us to
take advantage of state-of-the-art fully convolutional network structure for
the implementation of the above encoders and decoder. Experimental results on
several representative datasets demonstrate our supreme performance for
semantic segmentation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06995</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06995</id><created>2015-11-22</created><authors><author><keyname>Dragone</keyname><forenames>Paolo</forenames></author></authors><title>Non-Sentential Utterances in Dialogue: Experiments in Classification and
  Interpretation</title><categories>cs.CL cs.AI</categories><comments>Master thesis, 98 pages, ISBN: 9788887096057</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Non-sentential utterances (NSUs) are utterances that lack a complete
sentential form but whose meaning can be inferred from the dialogue context,
such as &quot;OK&quot;, &quot;where?&quot;, &quot;probably at his apartment&quot;. The interpretation of
non-sentential utterances is an important problem in computational linguistics
since they constitute a frequent phenomena in dialogue and they are
intrinsically context-dependent. The interpretation of NSUs is the task of
retrieving their full semantic content from their form and the dialogue
context. The first half of this thesis is devoted to the NSU classification
task. Our work builds upon Fern\'andez et al. (2007) which present a series of
machine-learning experiments on the classification of NSUs. We extended their
approach with a combination of new features and semi-supervised learning
techniques. The empirical results presented in this thesis show a modest but
significant improvement over the state-of-the-art classification performance.
The consecutive, yet independent, problem is how to infer an appropriate
semantic representation of such NSUs on the basis of the dialogue context.
Fern\'andez (2006) formalizes this task in terms of &quot;resolution rules&quot; built on
top of the Type Theory with Records (TTR). Our work is focused on the
reimplementation of the resolution rules from Fern\'andez (2006) with a
probabilistic account of the dialogue state. The probabilistic rules formalism
Lison (2014) is particularly suited for this task because, similarly to the
framework developed by Ginzburg (2012) and Fern\'andez (2006), it involves the
specification of update rules on the variables of the dialogue state to capture
the dynamics of the conversation. However, the probabilistic rules can also
encode probabilistic knowledge, thereby providing a principled account of
ambiguities in the NSU resolution process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.06996</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.06996</id><created>2015-11-22</created><authors><author><keyname>Forni</keyname><forenames>Fulvio</forenames></author><author><keyname>Mauroy</keyname><forenames>Alexandre</forenames></author><author><keyname>Sepulchre</keyname><forenames>Rodolphe</forenames></author></authors><title>Differential positivity characterizes one-dimensional normally
  hyperbolic attractors</title><categories>cs.SY math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper shows that normally hyperbolic one-dimensional compact attractors
of smooth dynamical systems are characterized by differential positivity, that
is, the pointwise infinitesimal contraction of a smooth cone field. The result
is analog to the characterization of zero-dimensional hyperbolic attractors by
differential stability, which is the pointwise infinitesimal contraction of a
Riemannian metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07001</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07001</id><created>2015-11-22</created><authors><author><keyname>Sparavigna</keyname><forenames>A. C.</forenames></author><author><keyname>Marazzato</keyname><forenames>R.</forenames></author></authors><title>Analysis of a Play by Means of CHAPLIN, the Characters and Places
  Interaction Network Software</title><categories>cs.CY cs.CL cs.SI</categories><journal-ref>International Journal of Sciences, 2015, 4(3):60-68</journal-ref><doi>10.18483/ijSci.662</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, we have developed a software able of gathering information on
social networks from written texts. This software, the CHAracters and PLaces
Interaction Network (CHAPLIN) tool, is implemented in Visual Basic. By means of
it, characters and places of a literary work can be extracted from a list of
raw words. The software interface helps users to select their names out of this
list. Setting some parameters, CHAPLIN creates a network where nodes represent
characters/places and edges give their interactions. Nodes and edges are
labelled by performances. In this paper, we propose to use CHAPLIN for the
analysis a William Shakespeare's play, the famous 'Tragedy of Hamlet, Prince of
Denmark'. Performances of characters in the play as a whole and in each act of
it are given by graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07004</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07004</id><created>2015-11-22</created><authors><author><keyname>Choi</keyname><forenames>Keunwoo</forenames></author><author><keyname>Fazekas</keyname><forenames>George</forenames></author><author><keyname>Sandler</keyname><forenames>Mark</forenames></author></authors><title>Understanding Music Playlists</title><categories>cs.MM cs.IR</categories><comments>International Conference on Machine Learning (ICML) 2015, Machine
  Learning for Music Discovery Workshop</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As music streaming services dominate the music industry, the playlist is
becoming an increasingly crucial element of music consumption. Con- sequently,
the music recommendation problem is often casted as a playlist generation prob-
lem. Better understanding of the playlist is there- fore necessary for
developing better playlist gen- eration algorithms. In this work, we analyse
two playlist datasets to investigate some com- monly assumed hypotheses about
playlists. Our findings indicate that deeper understanding of playlists is
needed to provide better prior infor- mation and improve machine learning
algorithms in the design of recommendation systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07008</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07008</id><created>2015-11-22</created><authors><author><keyname>Malt</keyname><forenames>Mikhail</forenames></author><author><keyname>Gentilucci</keyname><forenames>Marta</forenames></author></authors><title>Real Time Vowel Tremolo Detection Using Low Level Audio Descriptors</title><categories>cs.SD</categories><comments>6 pages, 6 figures, 2 tables, lab report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper resumes the results of a research conducted in a music production
situation Therefore, it is more a final lab report, a prospective methodology
then a scientific experience. The methodology we are presenting was developed
as an answer to a musical problem raised by the Italian composer Marta
Gentilucci. The problem was &quot;how to extract a temporal structure from a vowel
tremolo, on a tenuto (steady state) pitch.&quot; The musical goal was to apply, in a
compositional context the vowel tremolo time structure on a tenuto pitch chord,
as a transposition control.In this context we decide to follow, to explore the
potential of low-level MPEG7 audio descriptors to build event detection
functions. One of the main problems using low-level audio descriptors in audio
analysis is the redundancy of information among them. We describe an &quot;ad hoc&quot;
interactive methodology, based on side effect use of dimensionality reduction
by PCA, to choose a feature from a set of low-level audio descriptors, to be
used to detect a vowel tremolo rhythm. This methodology is supposed to be
interactive and easy enough to be used in a live creative context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07017</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07017</id><created>2015-11-22</created><authors><author><keyname>Singh</keyname><forenames>Sudhakar</forenames></author><author><keyname>Garg</keyname><forenames>Rakhi</forenames></author><author><keyname>Mishra</keyname><forenames>P. K.</forenames></author></authors><title>Performance Analysis of Apriori Algorithm with Different Data Structures
  on Hadoop Cluster</title><categories>cs.DC</categories><comments>2009-2015 International Journal of Computer Applications,
  FCS(Foundation of Computer Science)</comments><doi>10.5120/ijca2015906632</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mining frequent itemsets from massive datasets is always being a most
important problem of data mining. Apriori is the most popular and simplest
algorithm for frequent itemset mining. To enhance the efficiency and
scalability of Apriori, a number of algorithms have been proposed addressing
the design of efficient data structures, minimizing database scan and parallel
and distributed processing. MapReduce is the emerging parallel and distributed
technology to process big datasets on Hadoop Cluster. To mine big datasets it
is essential to re-design the data mining algorithm on this new paradigm. In
this paper, we implement three variations of Apriori algorithm using data
structures hash tree, trie and hash table trie i.e. trie with hash technique on
MapReduce paradigm. We emphasize and investigate the significance of these
three data structures for Apriori algorithm on Hadoop cluster, which has not
been given attention yet. Experiments are carried out on both real life and
synthetic datasets which shows that hash table trie data structures performs
far better than trie and hash tree in terms of execution time. Moreover the
performance in case of hash tree becomes worst.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07020</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07020</id><created>2015-11-22</created><authors><author><keyname>Straszak</keyname><forenames>Damian</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth K.</forenames></author></authors><title>On a Natural Dynamics for Linear Programming</title><categories>cs.DS math.DS math.OC physics.bio-ph</categories><acm-class>G.1.6; G.1.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study dynamics inspired by Physarum polycephalum (a slime
mold) for solving linear programs [NTY00, IJNT11, JZ12]. These dynamics are
arrived at by a local and mechanistic interpretation of the inner workings of
the slime mold and a global optimization perspective has been lacking even in
the simplest of instances. Our first result is an interpretation of the
dynamics as an optimization process. We show that Physarum dynamics can be seen
as a steepest-descent type algorithm on a certain Riemannian manifold.
Moreover, we prove that the trajectories of Physarum are in fact paths of
optimizers to a parametrized family of convex programs, in which the objective
is a linear cost function regularized by an entropy barrier. Subsequently, we
rigorously establish several important properties of solution curves of
Physarum. We prove global existence of such solutions and show that they have
limits, being optimal solutions of the underlying LP. Finally, we show that the
discretization of the Physarum dynamics is efficient for a class of linear
programs, which include unimodular constraint matrices. Thus, together, our
results shed some light on how nature might be solving instances of perhaps the
most complex problem in P: linear programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07023</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07023</id><created>2015-11-22</created><authors><author><keyname>Juneja</keyname><forenames>Prerna</forenames></author><author><keyname>Kundra</keyname><forenames>Divya</forenames></author><author><keyname>Sureka</keyname><forenames>Ashish</forenames></author></authors><title>Anvaya: An Algorithm and Case-Study on Improving the Goodness of
  Software Process Models generated by Mining Event-Log Data in Issue Tracking
  System</title><categories>cs.SE cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Issue Tracking Systems (ITS) such as Bugzilla can be viewed as Process Aware
Information Systems (PAIS) generating event-logs during the life-cycle of a bug
report. Process Mining consists of mining event logs generated from PAIS for
process model discovery, conformance and enhancement. We apply process map
discovery techniques to mine event trace data generated from ITS of open source
Firefox browser project to generate and study process models. Bug life-cycle
consists of diversity and variance. Therefore, the process models generated
from the event-logs are spaghetti-like with large number of edges,
inter-connections and nodes. Such models are complex to analyse and difficult
to comprehend by a process analyst. We improve the Goodness (fitness and
structural complexity) of the process models by splitting the event-log into
homogeneous subsets by clustering structurally similar traces. We adapt the
K-Medoid clustering algorithm with two different distance metrics: Longest
Common Subsequence (LCS) and Dynamic Time Warping (DTW). We evaluate the
goodness of the process models generated from the clusters using complexity and
fitness metrics. We study back-forth \&amp; self-loops, bug reopening, and
bottleneck in the clusters obtained and show that clustering enables better
analysis. We also propose an algorithm to automate the clustering process -the
algorithm takes as input the event log and returns the best cluster set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07031</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07031</id><created>2015-11-22</created><authors><author><keyname>Ghavami</keyname><forenames>Siavash</forenames></author><author><keyname>Adve</keyname><forenames>Raviraj</forenames></author><author><keyname>Lahouti</keyname><forenames>Farshad</forenames></author></authors><title>Information Rates of ASK-Based Molecular Communication in Fluid Media</title><categories>cs.IT math.IT</categories><comments>31 pages, 8 figures, Accepted for publication on IEEE Transactions on
  Molecular, Biological, and Multi-Scale Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the capacity of molecular communications in fluid media,
where the information is encoded in the number of transmitted molecules in a
time-slot (amplitude shift keying). The propagation of molecules is governed by
random Brownian motion and the communication is in general subject to
inter-symbol interference (ISI). We first consider the case where ISI is
negligible and analyze the capacity and the capacity per unit cost of the
resulting discrete memoryless molecular channel and the effect of possible
practical constraints, such as limitations on peak and/or average number of
transmitted molecules per transmission. In the case with a constrained peak
molecular emission, we show that as the time-slot duration increases, the input
distribution achieving the capacity per channel use transitions from binary
inputs to a discrete uniform distribution. In this paper, we also analyze the
impact of ISI. Crucially, we account for the correlation that ISI induces
between channel output symbols. We derive an upper bound and two lower bounds
on the capacity in this setting. Using the input distribution obtained by an
extended Blahut-Arimoto algorithm, we maximize the lower bounds. Our results
show that, over a wide range of parameter values, the bounds are close.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07033</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07033</id><created>2015-11-22</created><authors><author><keyname>Kent</keyname><forenames>Andrew M.</forenames></author><author><keyname>Kempe</keyname><forenames>David</forenames></author><author><keyname>Tobin-Hochstadt</keyname><forenames>Sam</forenames></author></authors><title>Occurrence Typing Modulo Theories</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new type system combining occurrence typing, previously used to
type check programs in dynamically-typed languages such as Racket, JavaScript,
and Ruby, with dependent refinement types. We demonstrate that the addition of
refinement types allows the integration of arbitrary solver-backed reasoning
about logical propositions from external theories. By building on occurrence
typing, we can add our enriched type system as an extension of Typed
Racket---adding dependency and refinement reuses the existing formalism while
increasing its expressiveness.
  Dependent refinement types allow Typed Racket programmers to express rich
type relationships, ranging from data structure invariants such as red-black
tree balance to preconditions such as vector bounds. Refinements allow
programmers to embed the propositions that occurrence typing in Typed Racket
already reasons about into their types. Further, extending occurrence typing to
refinements allows us to make the underlying formalism simpler and more
powerful.
  In addition to presenting the design of our system, we present a formal model
of the system, show how to integrate it with theories over both linear
arithmetic and bitvectors, and evaluate the system in the context of the full
Typed Racket implementation. Specifically, we take safe vector access as a case
study, and examine all vector accesses in a 56,000 line corpus of Typed Racket
programs. Our system is able to prove that 50% of these are safe with no new
annotation, and with a few annotations and modifications, we can capture close
to 80%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07035</identifier>
 <datestamp>2015-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07035</id><created>2015-11-22</created><updated>2015-12-04</updated><authors><author><keyname>Abdi&#x107;</keyname><forenames>Irman</forenames></author><author><keyname>Fridman</keyname><forenames>Lex</forenames></author><author><keyname>Marchi</keyname><forenames>Erik</forenames></author><author><keyname>Brown</keyname><forenames>Daniel E</forenames></author><author><keyname>Angell</keyname><forenames>William</forenames></author><author><keyname>Reimer</keyname><forenames>Bryan</forenames></author><author><keyname>Schuller</keyname><forenames>Bj&#xf6;rn</forenames></author></authors><title>Detecting Road Surface Wetness from Audio: A Deep Learning Approach</title><categories>cs.LG cs.NE cs.SD</categories><comments>Under review in IEEE Signal Processing Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a recurrent neural network architecture for automated road
surface wetness detection from audio of tire-surface interaction. The
robustness of our approach is evaluated on 785,826 bins of audio that span an
extensive range of vehicle speeds, noises from the environment, road surface
types, and pavement conditions including international roughness index (IRI)
values from 25 in/mi to 1400 in/mi. The training and evaluation of the model
are performed on different roads to minimize the impact of environmental and
other external factors on the accuracy of the classification. We achieve an
unweighted average recall (UAR) of 93.2% across all vehicle speeds including 0
mph. The classifier still works at 0 mph because the discriminating signal is
present in the sound of other vehicles driving by.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07038</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07038</id><created>2015-11-22</created><authors><author><keyname>Svensson</keyname><forenames>Ola</forenames></author><author><keyname>Tarnawski</keyname><forenames>Jakub</forenames></author><author><keyname>V&#xe9;gh</keyname><forenames>L&#xe1;szl&#xf3; A.</forenames></author></authors><title>Constant Factor Approximation for ATSP with Two Edge Weights</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a constant factor approximation algorithm for the Asymmetric
Traveling Salesman Problem on shortest path metrics of directed graphs with two
different edge weights. For the case of unit edge weights, the first constant
factor approximation was given recently in [Sve15]. This was accomplished by
introducing an easier problem called Local-Connectivity ATSP and showing that a
good solution to this problem can be used to obtain a constant factor
approximation for ATSP. In this paper, we solve Local-Connectivity ATSP for two
different edge weights. The solution is based on a flow decomposition theorem
for solutions of the Held-Karp relaxation, which may be of independent
interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07041</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07041</id><created>2015-11-22</created><updated>2015-11-26</updated><authors><author><keyname>Handa</keyname><forenames>Ankur</forenames></author><author><keyname>Patraucean</keyname><forenames>Viorica</forenames></author><author><keyname>Badrinarayanan</keyname><forenames>Vijay</forenames></author><author><keyname>Stent</keyname><forenames>Simon</forenames></author><author><keyname>Cipolla</keyname><forenames>Roberto</forenames></author></authors><title>SceneNet: Understanding Real World Indoor Scenes With Synthetic Data</title><categories>cs.CV</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Scene understanding is a prerequisite to many high level tasks for any
automated intelligent machine operating in real world environments. Recent
attempts with supervised learning have shown promise in this direction but also
highlighted the need for enormous quantity of supervised data --- performance
increases in proportion to the amount of data used. However, this quickly
becomes prohibitive when considering the manual labour needed to collect such
data. In this work, we focus our attention on depth based semantic per-pixel
labelling as a scene understanding problem and show the potential of computer
graphics to generate virtually unlimited labelled data from synthetic 3D
scenes. By carefully synthesizing training data with appropriate noise models
we show comparable performance to state-of-the-art RGBD systems on NYUv2
dataset despite using only depth data as input and set a benchmark on
depth-based segmentation on SUN RGB-D dataset. Additionally, we offer a route
to generating synthesized frame or video data, and understanding of different
factors influencing performance gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07053</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07053</id><created>2015-11-22</created><updated>2016-01-11</updated><authors><author><keyname>Visin</keyname><forenames>Francesco</forenames></author><author><keyname>Kastner</keyname><forenames>Kyle</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author><author><keyname>Matteucci</keyname><forenames>Matteo</forenames></author><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author></authors><title>ReSeg: A Recurrent Neural Network for Object Segmentation</title><categories>cs.CV cs.LG</categories><comments>Under review as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a structured prediction architecture for images centered around
deep recurrent neural networks. The proposed network, called ReSeg, is based on
the recently introduced ReNet model for object classification. We modify and
extend it to perform object segmentation, noting that the avoidance of pooling
can greatly simplify pixel-wise tasks for images. The ReSeg layer is composed
of four recurrent neural networks that sweep the image horizontally and
vertically in both directions, along with a final layer that expands the
prediction back to the original image size. ReSeg combines multiple ReSeg
layers with several possible input layers as well as a final layer which
expands the prediction back to the original image size, making it suitable for
a variety of structured prediction tasks. We evaluate ReSeg on the specific
task of object segmentation with three widely-used image segmentation datasets,
namely Weizmann Horse, Fashionista and Oxford Flower. The results suggest that
ReSeg can challenge the state of the art in object segmentation, and may have
further applications in structured prediction at large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07057</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07057</id><created>2015-11-22</created><updated>2016-02-22</updated><authors><author><keyname>MacCartney</keyname><forenames>George R.</forenames><suffix>Jr.</suffix></author><author><keyname>Deng</keyname><forenames>Sija</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>Indoor Office Plan Environment and Layout-Based MmWave Path Loss Models
  for 28 GHz and 73 GHz</title><categories>cs.IT math.IT</categories><comments>To be published in 2016 IEEE 83rd Vehicular Technology Conference
  Spring (VTC 2016-Spring), Nanjing, China, May 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents large-scale path loss models based on extensive
ultra-wideband millimeter-wave propagation measurements performed at 28 GHz and
73 GHz in three typical indoor office layouts -- namely: corridor, open-plan,
and closed-plan. A previous study combined all indoor layouts together, while
this study separates them for site-specific indoor large-scale path loss model
analysis. Measurements were conducted using a 400 megachips-per-second
broadband sliding correlator channel sounder with 800 MHz first null-to-null RF
bandwidth for 48 transmitter-receiver location combinations with distances
ranging 3.9 m to 45.9 m for both co- and cross-polarized antenna configurations
in line-of-sight and non-line-of-sight environments. Omnidirectional path loss
values were synthesized from over 14,000 directional power delay profiles and
were used to generate single-frequency and multi-frequency path loss models for
combined, co-, and cross-polarized antennas. Large-scale path loss models that
include a cross-polarization discrimination factor are provided for
cross-polarized antenna measurements. The results show the value of using the
close-in free space reference distance single and multi-frequency path loss
models, as they offer simplicity (less parameters) in path loss calculation and
prediction, without sacrificing accuracy. Moreover, the current 3GPP
floating-intercept path loss model only requires a simple and subtle
modification to convert to the close-in free space reference distance models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07063</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07063</id><created>2015-11-22</created><authors><author><keyname>Zhang</keyname><forenames>Ning</forenames></author><author><keyname>Shelhamer</keyname><forenames>Evan</forenames></author><author><keyname>Gao</keyname><forenames>Yang</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Fine-grained pose prediction, normalization, and recognition</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pose variation and subtle differences in appearance are key challenges to
fine-grained classification. While deep networks have markedly improved general
recognition, many approaches to fine-grained recognition rely on anchoring
networks to parts for better accuracy. Identifying parts to find correspondence
discounts pose variation so that features can be tuned to appearance. To this
end previous methods have examined how to find parts and extract
pose-normalized features. These methods have generally separated fine-grained
recognition into stages which first localize parts using hand-engineered and
coarsely-localized proposal features, and then separately learn deep
descriptors centered on inferred part positions. We unify these steps in an
end-to-end trainable network supervised by keypoint locations and class labels
that localizes parts by a fully convolutional network to focus the learning of
feature representations for the fine-grained classification task. Experiments
on the popular CUB200 dataset show that our method is state-of-the-art and
suggest a continuing role for strong supervision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07067</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07067</id><created>2015-11-22</created><authors><author><keyname>Kottur</keyname><forenames>Satwik</forenames></author><author><keyname>Vedantam</keyname><forenames>Ramakrishna</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author><author><keyname>Parikh</keyname><forenames>Devi</forenames></author></authors><title>Visual Word2Vec (vis-w2v): Learning Visually Grounded Word Embeddings
  Using Abstract Scenes</title><categories>cs.CV cs.CL</categories><comments>15 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a model to learn visually grounded word embeddings (vis-w2v) to
capture visual notions of semantic relatedness. While word embeddings trained
using text have been extremely successful, they cannot uncover notions of
semantic relatedness implicit in our visual world. For instance, visual
grounding can help us realize that concepts like eating and staring at are
related, since when people are eating something, they also tend to stare at the
food. Grounding a rich variety of relations like eating and stare at in vision
is a challenging task, despite recent progress in vision. We realize the visual
grounding for words depends on the semantics of our visual world, and not the
literal pixels. We thus use abstract scenes created from clipart to provide the
visual grounding. We find that the embeddings we learn capture fine-grained
visually grounded notions of semantic relatedness. We show improvements over
text only word embeddings (word2vec) on three tasks: common-sense assertion
classification, visual paraphrasing and text-based image retrieval. Our code
and datasets will be available online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07069</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07069</id><created>2015-11-22</created><updated>2016-03-02</updated><authors><author><keyname>Azadi</keyname><forenames>Samaneh</forenames></author><author><keyname>Feng</keyname><forenames>Jiashi</forenames></author><author><keyname>Jegelka</keyname><forenames>Stefanie</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Auxiliary Image Regularization for Deep CNNs with Noisy Labels</title><categories>cs.CV</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Precisely-labeled data sets with sufficient amount of samples are very
important for training deep convolutional neural networks (CNNs). However, many
of the available real-world data sets contain erroneously labeled samples and
those errors substantially hinder the learning of very accurate CNN models. In
this work, we consider the problem of training a deep CNN model for image
classification with mislabeled training samples - an issue that is common in
real image data sets with tags supplied by amateur users. To solve this
problem, we propose an auxiliary image regularization technique, optimized by
the stochastic Alternating Direction Method of Multipliers (ADMM) algorithm,
that automatically exploits the mutual context information among training
images and encourages the model to select reliable images to robustify the
learning process. Comprehensive experiments on benchmark data sets clearly
demonstrate our proposed regularized CNN model is resistant to label noise in
training data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07070</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07070</id><created>2015-11-22</created><authors><author><keyname>Backurs</keyname><forenames>Arturs</forenames></author><author><keyname>Indyk</keyname><forenames>Piotr</forenames></author></authors><title>Which Regular Expression Patterns are Hard to Match?</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regular expressions constitute a fundamental notion in formal language theory
and are frequently used in computer science to define search patterns. In
particular, regular expression matching is a widely used computational
primitive, employed in many programming languages and text processing
utilities. A classic algorithm for regular expression matching runs in $O(m n)$
time (where $m$ is the length of the pattern and $n$ is the length of the
text). This running time can be improved by a poly-logarithmic factor, but no
significantly faster solutions are known. At the same time, much faster
algorithms exist for various special cases of regular expressions, including
dictionary matching, wildcard matching, subset matching, etc.
  In this paper, we show that the complexity of regular expression matching can
be characterized based on its depth (when interpreted as a formula). Very
roughly, our results state that for expressions involving concatenation, OR and
Kleene plus, the following dichotomy holds:
  * Matching regular expressions of depth two (involving any combination of the
above operators) can be solved in near-linear time. In particular, this case
covers the aforementioned variants of regular expression matching amenable to
fast algorithms.
  * Matching regular expressions of depth three (involving any combination of
the above operators) that are not reducible to some depth-two expressions
cannot be solved in sub-quadratic time unless the Strong Exponential Time
Hypothesis (SETH) is false.
  For expressions involving concatenation, OR and Kleene star our results are
similar, with one notable exception: we show that pattern matching with depth
two regular expressions that are concatenations of Kleene stars is SETH-hard.
Otherwise the results are the same as described above, but with Kleene plus
replaced by Kleene star.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07076</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07076</id><created>2015-11-22</created><authors><author><keyname>Negrov</keyname><forenames>D. V.</forenames></author><author><keyname>Karandashev</keyname><forenames>I. M.</forenames></author><author><keyname>Shakirov</keyname><forenames>V. V.</forenames></author><author><keyname>Matveyev</keyname><forenames>Yu. A.</forenames></author><author><keyname>Dunin-Barkowski</keyname><forenames>W. L.</forenames></author><author><keyname>Zenkevich</keyname><forenames>A. V.</forenames></author></authors><title>A Plausible Memristor Implementation of Deep Learning Neural Networks</title><categories>cs.NE cs.ET</categories><comments>14 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A possible method for hardware implementation of multilayer neural networks
with the back-propagation learning algorithm employing memristor cross-bar
matrices for weight storage is modeled. The proposed approach offers an
efficient way to perform both learning and recognition operations. The solution
of several arising problems, such as the representation and multiplication of
signals as well as error propagation is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07077</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07077</id><created>2015-11-22</created><authors><author><keyname>Cevallos</keyname><forenames>Alfonso</forenames></author><author><keyname>Eisenbrand</keyname><forenames>Friedrich</forenames></author><author><keyname>Zenklusen</keyname><forenames>Rico</forenames></author></authors><title>Max-sum diversity via convex programming</title><categories>cs.DS cs.CG cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diversity maximization is an important concept in information retrieval,
computational geometry and operations research. Usually, it is a variant of the
following problem: Given a ground set, constraints, and a function $f(\cdot)$
that measures diversity of a subset, the task is to select a feasible subset
$S$ such that $f(S)$ is maximized. The \emph{sum-dispersion} function $f(S) =
\sum_{x,y \in S} d(x,y)$, which is the sum of the pairwise distances in $S$, is
in this context a prominent diversification measure. The corresponding
diversity maximization is the \emph{max-sum} or \emph{sum-sum diversification}.
Many recent results deal with the design of constant-factor approximation
algorithms of diversification problems involving sum-dispersion function under
a matroid constraint. In this paper, we present a PTAS for the max-sum
diversification problem under a matroid constraint for distances
$d(\cdot,\cdot)$ of \emph{negative type}. Distances of negative type are, for
example, metric distances stemming from the $\ell_2$ and $\ell_1$ norm, as well
as the cosine or spherical, or Jaccard distance which are popular similarity
metrics in web and image search.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07085</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07085</id><created>2015-11-22</created><authors><author><keyname>Malyshkin</keyname><forenames>Vladislav Gennadievich</forenames></author></authors><title>Multiple--Instance Learning: Christoffel Function Approach to
  Distribution Regression Problem</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two--step Christoffel function based solution is proposed to distribution
regression problem. On the first step, to model distribution of observations
inside a bag, build Christoffel function for each bag of observations. Then, on
the second step, build outcome variable Christoffel function, but use the bag's
Christoffel function value at given point as the weight for the bag's outcome.
The approach allows the result to be obtained in closed form and then to be
evaluated numerically. While most of existing approaches minimize some kind an
error between outcome and prediction, the proposed approach is conceptually
different, because it uses Christoffel function for knowledge representation,
what is conceptually equivalent working with probabilities only. To receive
possible outcomes and their probabilities Gauss quadrature for second--step
measure can be built, then the nodes give possible outcomes and normalized
weights -- outcome probabilities. A library providing numerically stable
polynomial basis for these calculations is available, what make the proposed
approach practical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07087</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07087</id><created>2015-11-22</created><authors><author><keyname>Malesevic</keyname><forenames>Branko</forenames></author><author><keyname>Jovovic</keyname><forenames>Ivana</forenames></author><author><keyname>Banjac</keyname><forenames>Bojan</forenames></author></authors><title>Visualization in teaching and learning mathematics in elementary,
  secondary and higher education</title><categories>cs.CY cs.SC</categories><journal-ref>Proceedings of International Conference on Engineering Graphics
  and Design, pp. 37-40, Timisoara, Romania, 13-15 june 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present our experience in using visualization in mathematics
education. The experience with our university courses: &quot;Computer tools in
matematics&quot; and &quot;Symbolic algebra&quot; provides the basis for mathematics teacher
education program http://vizuelizacija.etf.rs/. The program is intended for
elementary and high school teachers. The education program deals with modern
techniques of visualization by using technologies such as GeoGegebra, JAVA and
HTML.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07093</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07093</id><created>2015-11-22</created><authors><author><keyname>Arachchilage</keyname><forenames>Nalin Asanka Gamagedara</forenames></author><author><keyname>Tarhini</keyname><forenames>Ali</forenames></author><author><keyname>Love</keyname><forenames>Steve</forenames></author></authors><title>Designing a mobile game to thwarts malicious IT threats: A phishing
  threat avoidance perspective</title><categories>cs.CY cs.CR</categories><comments>9, International Journal for Infonomics (IJI), Volume 8 Issues 3/4,
  September/December 2015. arXiv admin note: text overlap with arXiv:1511.01622</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Phishing is an online identity theft, which aims to steal sensitive
information such as username, password and online banking details from victims.
To prevent this, phishing education needs to be considered. Game based
education is becoming more and more popular. This paper introduces a mobile
game prototype for the android platform based on a story, which simplifies and
exaggerates real life. The elements of a game design framework for avoiding
phishing attacks were used to address the game design issues and game design
principles were used as a set of guidelines for structuring and presenting
information. The overall mobile game design was aimed to enhance the user's
avoidance behaviour through motivation to protect themselves against phishing
threats. The prototype mobile game design was presented on MIT App Inventor
Emulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07100</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07100</id><created>2015-11-22</created><authors><author><keyname>Brimkov</keyname><forenames>Boris</forenames></author></authors><title>A reduction of the logspace shortest path problem to biconnected graphs</title><categories>cs.CC</categories><comments>9 pages</comments><msc-class>68Q25, 05C85</msc-class><acm-class>F.2.2; F.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we reduce the logspace shortest path problem to biconnected
graphs; in particular, we present a logspace shortest path algorithm for
general graphs which uses a logspace shortest path oracle for biconnected
graphs. We also present a linear time logspace shortest path algorithm for
graphs with bounded vertex degree and biconnected component size, which does
not rely on an oracle. The asymptotic time-space product of this algorithm is
the best possible among all shortest path algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07106</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07106</id><created>2015-11-22</created><authors><author><keyname>Salvato</keyname><forenames>Michael</forenames></author><author><keyname>Finman</keyname><forenames>Ross</forenames></author><author><keyname>Leonard</keyname><forenames>John</forenames></author></authors><title>Multi-Volume High Resolution RGB-D Mapping with Dynamic Volume Placement</title><categories>cs.RO cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel RGB-D mapping system for generating 3D maps over spatially
extended regions with higher resolution than current methods using multiple,
dynamically placed mapping volumes. Our method takes in RGB-D frames and
dynamically assigns multiple mapping volumes to the environment, exchanging
mapping volumes between the CPU and GPU. Mapping volumes are added or removed
as needed to allow for spatially extended, high resolution mapping. Our system
is designed to maximize the resolution possible for such volumetric methods,
while working on an unbounded space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07110</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07110</id><created>2015-11-22</created><authors><author><keyname>Xie</keyname><forenames>Pengtao</forenames></author><author><keyname>Deng</keyname><forenames>Yuntian</forenames></author><author><keyname>Xing</keyname><forenames>Eric</forenames></author></authors><title>On the Generalization Error Bounds of Neural Networks under
  Diversity-Inducing Mutual Angular Regularization</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently diversity-inducing regularization methods for latent variable models
(LVMs), which encourage the components in LVMs to be diverse, have been studied
to address several issues involved in latent variable modeling: (1) how to
capture long-tail patterns underlying data; (2) how to reduce model complexity
without sacrificing expressivity; (3) how to improve the interpretability of
learned patterns. While the effectiveness of diversity-inducing regularizers
such as the mutual angular regularizer has been demonstrated empirically, a
rigorous theoretical analysis of them is still missing. In this paper, we aim
to bridge this gap and analyze how the mutual angular regularizer (MAR) affects
the generalization performance of supervised LVMs. We use neural network (NN)
as a model instance to carry out the study and the analysis shows that
increasing the diversity of hidden units in NN would reduce estimation error
and increase approximation error. In addition to theoretical analysis, we also
present empirical study which demonstrates that the MAR can greatly improve the
performance of NN and the empirical observations are in accordance with the
theoretical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07111</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07111</id><created>2015-11-23</created><updated>2016-01-11</updated><authors><author><keyname>Tzeng</keyname><forenames>Eric</forenames></author><author><keyname>Devin</keyname><forenames>Coline</forenames></author><author><keyname>Hoffman</keyname><forenames>Judy</forenames></author><author><keyname>Finn</keyname><forenames>Chelsea</forenames></author><author><keyname>Peng</keyname><forenames>Xingchao</forenames></author><author><keyname>Levine</keyname><forenames>Sergey</forenames></author><author><keyname>Saenko</keyname><forenames>Kate</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Towards Adapting Deep Visuomotor Representations from Simulated to Real
  Environments</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of adapting robotic perception from simulated to
real-world environments. For many robotic control tasks, real training imagery
is expensive to obtain, but a large amount of synthetic data is easy to
generate through simulation. We propose a method that adapts representations
using a small number of paired synthetic and real views of the same
object/scene. Prior approaches to deep domain adaptation fail to exploit such
paired instance constraints. Our proposed model generalizes prior approaches
and combines a standard in-domain loss, a cross-domain adaptation loss, and a
contrastive loss explicitly designed to align pairs of images in feature space.
We evaluate our approach on robotic and object pose estimation and show that,
by exploiting the presence of synthetic-real image pairs, our model is able to
compensate for domain shift more effectively than standard adaptation
techniques. Our results serve as an initial step toward pretraining deep
visuomotor policies entirely in simulation, significantly reducing physical
demands when learning complex policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07118</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07118</id><created>2015-11-23</created><authors><author><keyname>Lee</keyname><forenames>Dong-Hyun</forenames></author></authors><title>Cascading Denoising Auto-Encoder as a Deep Directed Generative Model</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent work (Bengio et al., 2013) has shown howDenoising Auto-Encoders(DAE)
become gener-ative models as a density estimator. However,in practice, the
framework suffers from a mixingproblem in the MCMC sampling process and
nodirect method to estimate the test log-likelihood.We consider a directed
model with an stochas-tic identity mapping (simple corruption pro-cess) as an
inference model and a DAE as agenerative model. By cascading these mod-els, we
propose Cascading Denoising Auto-Encoders(CDAE) which can generate samples
ofdata distribution from tractable prior distributionunder the assumption that
probabilistic distribu-tion of corrupted data approaches tractable
priordistribution as the level of corruption increases.This work tries to
answer two questions. On theone hand, can deep directed models be success-fully
trained without intractable posterior infer-ence and difficult optimization of
very deep neu-ral networks in inference and generative mod-els? These are
unavoidable when recent suc-cessful directed model like VAE (Kingma &amp;Welling,
2014) is trained on complex dataset likereal images. On the other hand, can
DAEs getclean samples of data distribution from heavilycorrupted samples which
can be considered oftractable prior distribution far from data mani-fold?
so-called global denoising scheme.Our results show positive responses of
thesequestions and this work can provide fairly simpleframework for generative
models of very com-plex dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07122</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07122</id><created>2015-11-23</created><updated>2016-03-03</updated><authors><author><keyname>Yu</keyname><forenames>Fisher</forenames></author><author><keyname>Koltun</keyname><forenames>Vladlen</forenames></author></authors><title>Multi-Scale Context Aggregation by Dilated Convolutions</title><categories>cs.CV</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art models for semantic segmentation are based on adaptations of
convolutional networks that had originally been designed for image
classification. However, dense prediction and image classification are
structurally different. In this work, we develop a new convolutional network
module that is specifically designed for dense prediction. The presented module
uses dilated convolutions to systematically aggregate multi-scale contextual
information without losing resolution. The architecture is based on the fact
that dilated convolutions support exponential expansion of the receptive field
without loss of resolution or coverage. We show that the presented context
module increases the accuracy of state-of-the-art semantic segmentation
systems. In addition, we examine the adaptation of image classification
networks to dense prediction and show that simplifying the adapted network can
increase accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07125</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07125</id><created>2015-11-23</created><authors><author><keyname>Gallagher</keyname><forenames>Patrick W.</forenames></author><author><keyname>Tang</keyname><forenames>Shuai</forenames></author><author><keyname>Tu</keyname><forenames>Zhuowen</forenames></author></authors><title>What Happened to My Dog in That Network: Unraveling Top-down Generators
  in Convolutional Neural Networks</title><categories>cs.NE cs.CV cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Top-down information plays a central role in human perception, but plays
relatively little role in many current state-of-the-art deep networks, such as
Convolutional Neural Networks (CNNs). This work seeks to explore a path by
which top-down information can have a direct impact within current deep
networks. We explore this path by learning and using &quot;generators&quot; corresponding
to the network internal effects of three types of transformation (each a
restriction of a general affine transformation): rotation, scaling, and
translation. We demonstrate how these learned generators can be used to
transfer top-down information to novel settings, as mediated by the &quot;feature
flows&quot; that the transformations (and the associated generators) correspond to
inside the network. Specifically, we explore three aspects: 1) using generators
as part of a method for synthesizing transformed images --- given a previously
unseen image, produce versions of that image corresponding to one or more
specified transformations, 2) &quot;zero-shot learning&quot; --- when provided with a
feature flow corresponding to the effect of a transformation of unknown amount,
leverage learned generators as part of a method by which to perform an accurate
categorization of the amount of transformation, even for amounts never observed
during training, and 3) (inside-CNN) &quot;data augmentation&quot; --- improve the
classification performance of an existing network by using the learned
generators to directly provide additional training &quot;inside the CNN&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07130</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07130</id><created>2015-11-23</created><authors><author><keyname>Shah</keyname><forenames>Amar</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Parallel Predictive Entropy Search for Batch Global Optimization of
  Expensive Objective Functions</title><categories>cs.LG stat.ML</categories><comments>12 pages in Neural Information Processing Systems 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop parallel predictive entropy search (PPES), a novel algorithm for
Bayesian optimization of expensive black-box objective functions. At each
iteration, PPES aims to select a batch of points which will maximize the
information gain about the global maximizer of the objective. Well known
strategies exist for suggesting a single evaluation point based on previous
observations, while far fewer are known for selecting batches of points to
evaluate in parallel. The few batch selection schemes that have been studied
all resort to greedy methods to compute an optimal batch. To the best of our
knowledge, PPES is the first non-greedy batch Bayesian optimization strategy.
We demonstrate the benefit of this approach in optimization performance on both
synthetic and real world applications, including problems in machine learning,
rocket science and robotics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07131</identifier>
 <datestamp>2016-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07131</id><created>2015-11-23</created><updated>2016-01-26</updated><authors><author><keyname>Zhu</keyname><forenames>Jun</forenames></author><author><keyname>Chen</keyname><forenames>Xianjie</forenames></author><author><keyname>Yuille</keyname><forenames>Alan L.</forenames></author></authors><title>DeePM: A Deep Part-Based Model for Object Detection and Semantic Part
  Localization</title><categories>cs.CV</categories><comments>the final revision to ICLR 2016, in which some color errors in the
  figures are fixed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a deep part-based model (DeePM) for symbiotic
object detection and semantic part localization. For this purpose, we annotate
semantic parts for all 20 object categories on the PASCAL VOC 2012 dataset,
which provides information on object pose, occlusion, viewpoint and
functionality. DeePM is a latent graphical model based on the state-of-the-art
R-CNN framework, which learns an explicit representation of the object-part
configuration with flexible type sharing (e.g., a sideview horse head can be
shared by a fully-visible sideview horse and a highly truncated sideview horse
with head and neck only). For comparison, we also present an end-to-end
Object-Part (OP) R-CNN which learns an implicit feature representation for
jointly mapping an image ROI to the object and part bounding boxes. We evaluate
the proposed methods for both the object and part detection performance on
PASCAL VOC 2012, and show that DeePM consistently outperforms OP R-CNN in
detecting objects and parts. In addition, it obtains superior performance to
Fast and Faster R-CNNs in object detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07136</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07136</id><created>2015-11-23</created><authors><author><keyname>Anderson</keyname><forenames>Matthew</forenames></author><author><keyname>Forbes</keyname><forenames>Michael A.</forenames></author><author><keyname>Saptharishi</keyname><forenames>Ramprasad</forenames></author><author><keyname>Shpilka</keyname><forenames>Amir</forenames></author><author><keyname>Volk</keyname><forenames>Ben Lee</forenames></author></authors><title>Identity Testing and Lower Bounds for Read-$k$ Oblivious Algebraic
  Branching Programs</title><categories>cs.CC</categories><comments>33 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Read-$k$ oblivious algebraic branching programs are a natural generalization
of the well-studied model of read-once oblivious algebraic branching program
(ROABPs). In this work, we give an exponential lower bound of
$\exp(n/k^{O(k)})$ on the width of any read-$k$ oblivious ABP computing some
explicit multilinear polynomial $f$ that is computed by a polynomial size
depth-$3$ circuit. We also study the polynomial identity testing (PIT) problem
for this model and obtain a white-box subexponential-time PIT algorithm. The
algorithm runs in time $2^{\tilde{O}(n^{1-1/2^{k-1}})}$ and needs white box
access only to know the order in which the variables appear in the ABP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07147</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07147</id><created>2015-11-23</created><authors><author><keyname>Gupta</keyname><forenames>Rishi</forenames></author><author><keyname>Roughgarden</keyname><forenames>Tim</forenames></author></authors><title>A PAC Approach to Application-Specific Algorithm Selection</title><categories>cs.LG cs.DS</categories><comments>28 pages, 2 figures</comments><acm-class>I.2.6; F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The best algorithm for a computational problem generally depends on the
&quot;relevant inputs,&quot; a concept that depends on the application domain and often
defies formal articulation. While there is a large literature on empirical
approaches to selecting the best algorithm for a given application domain,
there has been surprisingly little theoretical analysis of the problem.
  This paper adapts concepts from statistical and online learning theory to
reason about application-specific algorithm selection. Our models capture
several state-of-the-art empirical and theoretical approaches to the problem,
ranging from self-improving algorithms to empirical performance models, and our
results identify conditions under which these approaches are guaranteed to
perform well. We present one framework that models algorithm selection as a
statistical learning problem, and our work here shows that dimension notions
from statistical learning theory, historically used to measure the complexity
of classes of binary- and real-valued functions, are relevant in a much broader
algorithmic context. We also study the online version of the algorithm
selection problem, and give possibility and impossibility results for the
existence of no-regret learning algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07148</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07148</id><created>2015-11-23</created><authors><author><keyname>Kraus</keyname><forenames>Naama</forenames></author><author><keyname>Carmel</keyname><forenames>David</forenames></author><author><keyname>Keidar</keyname><forenames>Idit</forenames></author><author><keyname>Orenbach</keyname><forenames>Meni</forenames></author></authors><title>NearBucket-LSH: Efficient Similarity Search in P2P Networks</title><categories>cs.DC cs.IR cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present NearBucket-LSH, an effective algorithm for similarity search in
large-scale distributed online social networks organized as peer-to-peer
overlays. As communication is a dominant consideration in distributed systems,
we focus on minimizing the network cost while guaranteeing good search quality.
Our algorithm is based on Locality Sensitive Hashing (LSH), which limits the
search to collections of objects, called buckets, that have a high probability
to be similar to the query. More specifically, NearBucket-LSH employs an LSH
extension that searches in near buckets, and improves search quality but also
significantly increases the network cost. We decrease the network cost by
considering the internals of both LSH and the P2P overlay, and harnessing their
properties to our needs. We show that our NearBucket-LSH increases search
quality for a given network cost compared to previous art. In many cases, the
search quality increases by more than 50%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07163</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07163</id><created>2015-11-23</created><authors><author><keyname>&#x10c;ern&#xfd;</keyname><forenames>Pavol</forenames></author><author><keyname>Clarke</keyname><forenames>Edmund M.</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Radhakrishna</keyname><forenames>Arjun</forenames></author><author><keyname>Ryzhyk</keyname><forenames>Leonid</forenames></author><author><keyname>Samanta</keyname><forenames>Roopsha</forenames></author><author><keyname>Tarrach</keyname><forenames>Thorsten</forenames></author></authors><title>Optimizing Solution Quality in Synchronization Synthesis</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a multithreaded program written assuming a friendly, non-preemptive
scheduler, the goal of synchronization synthesis is to automatically insert
synchronization primitives to ensure that the modified program behaves
correctly, even with a preemptive scheduler. In this work, we focus on the
quality of the synthesized solution: we aim to infer synchronization placements
that not only ensure correctness, but also meet some quantitative objectives
such as optimal program performance on a given computing platform.
  The key step that enables solution optimization is the construction of a set
of global constraints over synchronization placements such that each model of
the constraints set corresponds to a correctness-ensuring synchronization
placement. We extract the global constraints from generalizations of
counterexample traces and the control-flow graph of the program. The global
constraints enable us to choose from among the encoded synchronization
solutions using an objective function. We consider two types of objective
functions: ones that are solely dependent on the program (e.g., minimizing the
size of critical sections) and ones that are also dependent on the computing
platform. For the latter, given a program and a computing platform, we
construct a performance model based on measuring average contention for
critical sections and the average time taken to acquire and release a lock
under a given average contention.
  We empirically evaluated that our approach scales to typical module sizes of
many real world concurrent programs such as device drivers and multithreaded
servers, and that the performance predictions match reality. To the best of our
knowledge, this is the first comprehensive approach for optimizing the
placement of synthesized synchronization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07168</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07168</id><created>2015-11-23</created><authors><author><keyname>Bafghi</keyname><forenames>Hamid G.</forenames></author><author><keyname>Mirmohseni</keyname><forenames>Mahtab</forenames></author><author><keyname>Seyfe</keyname><forenames>Babak</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>On The Secrecy of the Cognitive Interference Channel with Partial
  Channel States</title><categories>cs.IT math.IT</categories><comments>31 pages, 3 figures, submitted to IEEE Transactions on Information
  Forensics and Security</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  The secrecy problem in the state-dependent cognitive interference channel is
considered in this paper. In our model, there are a primary and a secondary
(cognitive) transmitter-receiver pairs, in which the cognitive transmitter has
the message of the primary one as side information. In addition, the channel is
affected by a channel state sequence which is estimated partially at the
cognitive transmitter and the corresponding receiver. The cognitive transmitter
wishes to cooperate with the primary one, and it sends its individual message
which should be confidential at the primary receiver. The achievable
equivocation-rate regions for this channel are derived using two approaches:
the binning scheme coding, and superposition coding. Then the outer bounds on
the capacity are proposed and the results are extended to the Gaussian
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07174</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07174</id><created>2015-11-23</created><authors><author><keyname>Oancea</keyname><forenames>Bogdan</forenames></author><author><keyname>Andrei</keyname><forenames>Tudorel</forenames></author></authors><title>Developing a High Performance Software Library with MPI and CUDA for
  Matrix Computations</title><categories>cs.DC cs.MS</categories><comments>in Computational Methods for Social Sciences, VOL. I, ISSUE 2/2013</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Nowadays, the paradigm of parallel computing is changing. CUDA is now a
popular programming model for general purpose computations on GPUs and a great
number of applications were ported to CUDA obtaining speedups of orders of
magnitude comparing to optimized CPU implementations. Hybrid approaches that
combine the message passing model with the shared memory model for parallel
computing are a solution for very large applications. We considered a
heterogeneous cluster that combines the CPU and GPU computations using MPI and
CUDA for developing a high performance linear algebra library. Our library
deals with large linear systems solvers because they are a common problem in
the fields of science and engineering. Direct methods for computing the
solution of such systems can be very expensive due to high memory requirements
and computational cost. An efficient alternative are iterative methods which
computes only an approximation of the solution. In this paper we present an
implementation of a library that uses a hybrid model of computation using MPI
and CUDA implementing both direct and iterative linear systems solvers. Our
library implements LU and Cholesky factorization based solvers and some of the
non-stationary iterative methods using the MPI/CUDA combination. We compared
the performance of our MPI/CUDA implementation with classic programs written to
be run on a single CPU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07180</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07180</id><created>2015-11-23</created><authors><author><keyname>Dumitran</keyname><forenames>Marius</forenames></author><author><keyname>Gawrychowski</keyname><forenames>Pawe&#x142;</forenames></author><author><keyname>Manea</keyname><forenames>Florin</forenames></author></authors><title>Longest Gapped Repeats and Palindromes</title><categories>cs.DS</categories><comments>This is an extension of the conference papers &quot;Longest
  $\alpha$-Gapped Repeat and Palindrome&quot;, presented by the second and third
  authors at FCT 2015, and &quot;Longest Gapped Repeats and Palindromes&quot;, presented
  by the first and third authors at MFCS 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A gapped repeat (respectively, palindrome) occurring in a word $w$ is a
factor $uvu$ (respectively, $u^Rvu$) of $w$. In such a repeat (palindrome) $u$
is called the arm of the repeat (respectively, palindrome), while $v$ is called
the gap. We show how to compute efficiently, for every position $i$ of the word
$w$, the longest gapped repeat and palindrome occurring at that position,
provided that the length of the gap is subject to various types of
restrictions. That is, that for each position $i$ we compute the longest prefix
$u$ of $w[i..n]$ such that $uv$ (respectively, $u^Rv$) is a suffix of
$w[1..i-1]$ (defining thus a gapped repeat $uvu$ - respectively, palindrome
$u^Rvu$), and the length of $v$ is subject to the aforementioned restrictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07182</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07182</id><created>2015-11-23</created><authors><author><keyname>Thelwall</keyname><forenames>Mike</forenames></author><author><keyname>Sud</keyname><forenames>Pardeep</forenames></author></authors><title>National, disciplinary and temporal variations in the extent to which
  articles with more authors have more impact: Evidence from a geometric field
  normalised citation indicator</title><categories>cs.DL</categories><comments>Thelwall, M., &amp; Sud, P. (in press). National, disciplinary and
  temporal variations in the extent to which articles with more authors have
  more impact: Evidence from a geometric field normalised citation indicator.
  Journal of Informetrics</comments><journal-ref>Journal of Informetrics, 10(1), 48-61 (2016)</journal-ref><doi>10.1016/j.joi.2015.11.007</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The importance of collaboration in research is widely accepted, as is the
fact that articles with more authors tend to be more cited. Nevertheless,
although previous studies have investigated whether the apparent advantage of
collaboration varies by country, discipline, and number of co-authors, this
study introduces a more fine-grained method to identify differences: the
geometric Mean Normalized Citation Score (gMNCS). Based on comparisons between
disciplines, years and countries for two million journal articles, the average
citation impact of articles increases with the number of authors, even when
international collaboration is excluded. This apparent advantage of
collaboration varies substantially by discipline and country and changes a
little over time. Against the trend, however, in Russia solo articles have more
impact. Across the four broad disciplines examined, collaboration had by far
the strongest association with impact in the arts and humanities. Although
international comparisons are limited by the availability of systematic data
for author country affiliations, the new indicator is the most precise yet and
can give statistical evidence rather than estimates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07185</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07185</id><created>2015-11-23</created><authors><author><keyname>Costa</keyname><forenames>Pedro A. R. S.</forenames></author><author><keyname>Bai</keyname><forenames>Xiao</forenames></author><author><keyname>Ramos</keyname><forenames>Fernando M. V.</forenames></author><author><keyname>Correia</keyname><forenames>Miguel</forenames></author></authors><title>Medusa: An Efficient Cloud Fault-Tolerant MapReduce</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applications such as web search and social networking have been moving from
centralized to decentralized cloud architectures to improve their scalability.
MapReduce, a programming framework for processing large amounts of data using
thousands of machines in a single cloud, also needs to be scaled out to
multiple clouds to adapt to this evolution. The challenge of building a
multi-cloud distributed architecture is substantial. Notwithstanding, the
ability to deal with the new types of faults introduced by such setting, such
as the outage of a whole datacenter or an arbitrary fault caused by a malicious
cloud insider, increases the endeavor considerably.
  In this paper we propose Medusa, a platform that allows MapReduce
computations to scale out to multiple clouds and tolerate several types of
faults. Our solution fulfills four objectives. First, it is transparent to the
user, who writes her typical MapReduce application without modification.
Second, it does not require any modification to the widely used Hadoop
framework. Third, the proposed system goes well beyond the fault-tolerance
offered by MapReduce to tolerate arbitrary faults, cloud outages, and even
malicious faults caused by corrupt cloud insiders. Fourth, it achieves this
increased level of fault tolerance at reasonable cost. We performed an
extensive experimental evaluation in the ExoGENI testbed, demonstrating that
our solution significantly reduces execution time when compared to traditional
methods that achieve the same level of resilience.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07207</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07207</id><created>2015-11-23</created><authors><author><keyname>Oancea</keyname><forenames>Bogdan</forenames></author><author><keyname>Andrei</keyname><forenames>Tudorel</forenames></author><author><keyname>Dragoescu</keyname><forenames>Raluca Mariana</forenames></author></authors><title>Improving the performance of the linear systems solvers using CUDA</title><categories>cs.DC</categories><comments>in Proceedings of the Challenges of the Knowledge Society
  International Conference, 2012</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Parallel computing can offer an enormous advantage regarding the performance
for very large applications in almost any field: scientific computing, computer
vision, databases, data mining, and economics. GPUs are high performance
many-core processors that can obtain very high FLOP rates. Since the first idea
of using GPU for general purpose computing, things have evolved and now there
are several approaches to GPU programming: CUDA from NVIDIA and Stream from
AMD. CUDA is now a popular programming model for general purpose computations
on GPU for C/C++ programmers. A great number of applications were ported to
CUDA programming model and they obtain speedups of orders of magnitude
comparing to optimized CPU implementations. In this paper we present an
implementation of a library for solving linear systems using the CCUDA
framework. We present the results of performance tests and show that using GPU
one can obtain speedups of about of approximately 80 times comparing with a CPU
implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07209</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07209</id><created>2015-11-23</created><authors><author><keyname>Wang</keyname><forenames>Chao</forenames></author><author><keyname>Liemhetcharat</keyname><forenames>Somchaya</forenames></author><author><keyname>Low</keyname><forenames>Kian Hsiang</forenames></author></authors><title>Multi-Agent Continuous Transportation with Online Balanced Partitioning</title><categories>cs.MA cs.AI cs.RO</categories><comments>Submitted to AAMAS2016</comments><acm-class>I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of continuous transportation task to the context of
multi-agent systems. A continuous transportation task is one in which a
multi-agent team visits a number of fixed locations, picks up objects, and
delivers them to a final destination. The goal is to maximize the rate of
transportation while the objects are replenished over time. Examples of
problems that need continuous transportation are foraging, area sweeping, and
first/last mile problem. Previous approaches typically neglect the interference
and are highly dependent on communications among agents. Some also incorporate
an additional reconnaissance agent to gather information. In this paper, we
present a hybrid of centralized and distributed approaches that minimize the
interference and communications in the multi-agent team without the need for a
reconnaissance agent. We contribute two partitioning-transportation algorithms
inspired by existing algorithms, and contribute one novel online
partitioning-transportation algorithm with information gathering in the
multi-agent team. Our algorithms have been implemented and tested extensively
in the simulation. The results presented in this paper demonstrate the
effectiveness of our algorithms that outperform the existing algorithms, even
without any communications between the agents and without the presence of a
reconnaissance agent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07210</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07210</id><created>2015-11-23</created><authors><author><keyname>Saha</keyname><forenames>Suman</forenames></author><author><keyname>Ghrera</keyname><forenames>S. P.</forenames></author></authors><title>Nearest Neighbor search in Complex Network for Community Detection</title><categories>cs.SI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1508.06380</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Nearest neighbor search is a basic computational tool used extensively in
almost research domains of computer science specially when dealing with large
amount of data. However, the use of nearest neighbor search is restricted for
the purpose of algorithmic development by the existence of the notion of
nearness among the data points. The recent trend of research is on large,
complex networks and their structural analysis, where nodes represent entities
and edges represent any kind of relation between entities. Community detection
in complex network is an important problem of much interest. In general, a
community detection algorithm represents an objective function and captures the
communities by optimizing it to extract the interesting communities for the
user. In this article, we have studied the nearest neighbor search problem in
complex network via the development of a suitable notion of nearness.
Initially, we have studied and analyzed the exact nearest neighbor search using
metric tree on proposed metric space constructed from complex network. After,
the approximate nearest neighbor search problem is studied using locality
sensitive hashing. For evaluation of the proposed nearest neighbor search on
complex network we applied it in community detection problem. The results
obtained using our methods are very competitive with most of the well known
algorithms exists in the literature and this is verified on collection of real
networks. On the other-hand, it can be observed that time taken by our
algorithm is quite less compared to popular methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07211</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07211</id><created>2015-11-23</created><updated>2015-12-01</updated><authors><author><keyname>Singla</keyname><forenames>Adish</forenames></author><author><keyname>Tschiatschek</keyname><forenames>Sebastian</forenames></author><author><keyname>Krause</keyname><forenames>Andreas</forenames></author></authors><title>Noisy Submodular Maximization via Adaptive Sampling with Applications to
  Crowdsourced Image Collection Summarization</title><categories>cs.AI cs.LG stat.ML</categories><comments>Extended version of AAAI'16 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of maximizing an unknown submodular function that can
only be accessed via noisy evaluations. Our work is motivated by the task of
summarizing content, e.g., image collections, by leveraging users' feedback in
form of clicks or ratings. For summarization tasks with the goal of maximizing
coverage and diversity, submodular set functions are a natural choice. When the
underlying submodular function is unknown, users' feedback can provide noisy
evaluations of the function that we seek to maximize. We provide a generic
algorithm -- \submM{} -- for maximizing an unknown submodular function under
cardinality constraints. This algorithm makes use of a novel exploration module
-- \blbox{} -- that proposes good elements based on adaptively sampling noisy
function evaluations. \blbox{} is able to accommodate different kinds of
observation models such as value queries and pairwise comparisons. We provide
PAC-style guarantees on the quality and sampling cost of the solution obtained
by \submM{}. We demonstrate the effectiveness of our approach in an
interactive, crowdsourced image collection summarization application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07212</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07212</id><created>2015-11-23</created><authors><author><keyname>Zhu</keyname><forenames>Xiangyu</forenames></author><author><keyname>Lei</keyname><forenames>Zhen</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoming</forenames></author><author><keyname>Shi</keyname><forenames>Hailin</forenames></author><author><keyname>Li</keyname><forenames>Stan Z.</forenames></author></authors><title>Face Alignment Across Large Poses: A 3D Solution</title><categories>cs.CV</categories><comments>11 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Face alignment, which fits a face model to an image and extracts the semantic
meanings of facial pixels, has been an important topic in CV community.
However, most algorithms are designed for faces in small to medium poses (below
45 degree), lacking the ability to align faces in large poses up to 90 degree.
The challenges are three-fold: Firstly, the commonly used landmark-based face
model assumes that all the landmarks are visible and is therefore not suitable
for profile views. Secondly, the face appearance varies more dramatically
across large poses, ranging from frontal view to profile view. Thirdly,
labelling landmarks in large poses is extremely challenging since the invisible
landmarks have to be guessed. In this paper, we propose a solution to the three
problems in an new alignment framework, called 3D Dense Face Alignment (3DDFA),
in which a dense 3D face model is fitted to the image via convolutional neutral
network (CNN). We also propose a method to synthesize large-scale training
samples in profile views to solve the third problem of data labelling.
Experiments on the challenging AFLW database show that our approach achieves
significant improvements over state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07218</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07218</id><created>2015-11-23</created><authors><author><keyname>Han</keyname><forenames>Duo</forenames></author><author><keyname>Mo</keyname><forenames>Yilin</forenames></author><author><keyname>Xie</keyname><forenames>Lihua</forenames></author></authors><title>Convex Optimization Based State Estimation against Sparse Integrity
  Attacks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of robust estimation in the presence of integrity
attacks. There are m sensors monitoring the state and p of them are under
attack. The malicious measurements collected by the compromised sensors can be
manipulated arbitrarily by the attacker. The classical estimators such as the
least squares estimator may not provide a reliable estimate under the so-called
(p,m)-sparse attack. In this work, we are not restricting our efforts in
studying whether any specific estimator is resilient to the attack or not, but
instead we aim to present some generic sufficient and necessary conditions for
robustness by considering a general class of convex optimization based
estimators. The sufficient and necessary conditions are shown to be tight, with
a trivial gap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07233</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07233</id><created>2015-11-23</created><authors><author><keyname>Chan</keyname><forenames>Chin Hei</forenames></author><author><keyname>Xiong</keyname><forenames>Maosheng</forenames></author></authors><title>Construction of Unit-Memory MDS Convolutional Codes</title><categories>cs.IT math.IT</categories><msc-class>94B10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximum-distance separable (MDS) convolutional codes form an optimal family
of convolutional codes, the study of which is of great importance. There are
very few general algebraic constructions of MDS convolutional codes. In this
paper, we construct a large family of unit-memory MDS convolutional codes over
$\F$ with flexible parameters. Compared with previous works, the field size $q$
required to define these codes is much smaller. The construction also leads to
many new strongly-MDS convolutional codes, an important subclass of MDS
convolutional codes proposed and studied in \cite{GL2}. Many examples are
presented at the end of the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07236</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07236</id><created>2015-11-23</created><authors><author><keyname>Dai</keyname><forenames>Jincheng</forenames></author><author><keyname>Niu</keyname><forenames>Kai</forenames></author><author><keyname>Si</keyname><forenames>Zhongwei</forenames></author><author><keyname>Lin</keyname><forenames>Jiaru</forenames></author></authors><title>Evaluation and Optimization of Gaussian Approximation for Polar Codes</title><categories>cs.IT math.IT</categories><comments>Draft, 4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian approximation (GA) is widely used to construct polar codes. But when
the code length is sufficiently long, the subchannel selection inaccuracy due
to calculation error of conventional approximate GA (AGA), which uses
two-segment approximation function, will result in a catastrophic loss in
performance. In this paper, we propose a new metric, named
cumulative-logarithmic error (CLE), to evaluate the numeric error of subchannel
capacity calculation in log-domain. Further, we derive the upper bound of CLE
to simplify its calculation and find that the error of AGA will be amplified
exponentially with the increment of polarization levels. Guided by CLE bound,
we design new GA approximation function, which can efficiently reduce the
capacity calculation error. Numeric and simulation results show that
multi-segment AGA based on CLE bound is an efficient method to construct a
high-performance polar code with a long length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07237</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07237</id><created>2015-11-23</created><authors><author><keyname>Demeester</keyname><forenames>Thomas</forenames></author><author><keyname>Aly</keyname><forenames>Robin</forenames></author><author><keyname>Hiemstra</keyname><forenames>Djoerd</forenames></author><author><keyname>Nguyen</keyname><forenames>Dong</forenames></author><author><keyname>Develder</keyname><forenames>Chris</forenames></author></authors><title>Predicting Relevance based on Assessor Disagreement: Analysis and
  Practical Applications for Search Evaluation</title><categories>cs.IR</categories><comments>Accepted for publication in Springer Information Retrieval Journal,
  special issue on Information Retrieval Evaluation using Test Collections</comments><doi>10.1007/s10791-015-9275-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evaluation of search engines relies on assessments of search results for
selected test queries, from which we would ideally like to draw conclusions in
terms of relevance of the results for general (e.g., future, unknown) users. In
practice however, most evaluation scenarios only allow us to conclusively
determine the relevance towards the particular assessor that provided the
judgments. A factor that cannot be ignored when extending conclusions made from
assessors towards users, is the possible disagreement on relevance, assuming
that a single gold truth label does not exist. This paper presents and analyzes
the Predicted Relevance Model (PRM), which allows predicting a particular
result's relevance for a random user, based on an observed assessment and
knowledge on the average disagreement between assessors. With the PRM, existing
evaluation metrics designed to measure binary assessor relevance, can be
transformed into more robust and effectively graded measures that evaluate
relevance towards a random user. It also leads to a principled way of
quantifying multiple graded or categorical relevance levels for use as gains in
established graded relevance measures, such as normalized discounted cumulative
gain (nDCG), which nowadays often use heuristic and data-independent gain
values. Given a set of test topics with graded relevance judgments, the PRM
allows evaluating systems on different scenarios, such as their capability of
retrieving top results, or how well they are able to filter out non-relevant
ones. Its use in actual evaluation scenarios is illustrated on several
information retrieval test collections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07247</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07247</id><created>2015-11-23</created><updated>2016-02-26</updated><authors><author><keyname>Arandjelovi&#x107;</keyname><forenames>Relja</forenames></author><author><keyname>Gronat</keyname><forenames>Petr</forenames></author><author><keyname>Torii</keyname><forenames>Akihiko</forenames></author><author><keyname>Pajdla</keyname><forenames>Tomas</forenames></author><author><keyname>Sivic</keyname><forenames>Josef</forenames></author></authors><title>NetVLAD: CNN architecture for weakly supervised place recognition</title><categories>cs.CV cs.LG</categories><comments>- Added results on standard object/image retrieval benchmarks (tab.3)
  - Added comparison of NetVLAD with Max for same dimensionality (fig.6) -
  Added the Sum baseline - Added extra references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the problem of large scale visual place recognition, where the task
is to quickly and accurately recognize the location of a given query
photograph. We present the following three principal contributions. First, we
develop a convolutional neural network (CNN) architecture that is trainable in
an end-to-end manner directly for the place recognition task. The main
component of this architecture, NetVLAD, is a new generalized VLAD layer,
inspired by the &quot;Vector of Locally Aggregated Descriptors&quot; image representation
commonly used in image retrieval. The layer is readily pluggable into any CNN
architecture and amenable to training via backpropagation. Second, we develop a
training procedure, based on a new weakly supervised ranking loss, to learn
parameters of the architecture in an end-to-end manner from images depicting
the same places over time downloaded from Google Street View Time Machine.
Finally, we show that the proposed architecture obtains a large improvement in
performance over non-learnt image representations, significantly outperforms
off-the-shelf CNN descriptors on two challenging place recognition benchmarks,
and outperforms current state-of-the-art compact image representations on
standard image retrieval benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07249</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07249</id><created>2015-11-23</created><authors><author><keyname>Harutyunyan</keyname><forenames>Louisa</forenames></author></authors><title>On the total $(k,r)$-domination number of random graphs</title><categories>cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subset $S$ of a vertex set of a graph $G$ is a total $(k,r)$-dominating set
if every vertex $u \in V(G)$ is within distance $k$ of at least $r$ vertices in
$S$. The minimum cardinality among all total $(k,r)$-dominating sets of $G$ is
called the total $(k,r)$-domination number of $G$, denoted by
$\gamma^{t}_{(k,r)}(G)$. We previously gave an upper bound on
$\gamma^{t}_{(2,r)}(G(n,p))$ in random graphs with non-fixed $p \in (0,1)$. In
this paper we generalize this result to give an upper bound on
$\gamma^{t}_{(k,r)}(G(n,p))$ in random graphs with non-fixed $p \in (0,1)$ for
$k\geq 3$ as well as present an upper bound on $\gamma^{t}_{(k,r)}(G)$ in
graphs with large girth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07261</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07261</id><created>2015-11-23</created><authors><author><keyname>Bauer</keyname><forenames>Martin</forenames></author><author><keyname>Schornbaum</keyname><forenames>Florian</forenames></author><author><keyname>Godenschwager</keyname><forenames>Christian</forenames></author><author><keyname>Markl</keyname><forenames>Matthias</forenames></author><author><keyname>Anderl</keyname><forenames>Daniela</forenames></author><author><keyname>K&#xf6;stler</keyname><forenames>Harald</forenames></author><author><keyname>R&#xfc;de</keyname><forenames>Ulrich</forenames></author></authors><title>A Python Extension for the Massively Parallel Multiphysics Simulation
  Framework waLBerla</title><categories>cs.DC cs.MS</categories><doi>10.1080/17445760.2015.1118478</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a Python extension to the massively parallel HPC simulation
toolkit waLBerla. waLBerla is a framework for stencil based algorithms
operating on block-structured grids, with the main application field being
fluid simulations in complex geometries using the lattice Boltzmann method.
Careful performance engineering results in excellent node performance and good
scalability to over 400,000 cores. To increase the usability and flexibility of
the framework, a Python interface was developed. Python extensions are used at
all stages of the simulation pipeline: They simplify and automate scenario
setup, evaluation, and plotting. We show how our Python interface outperforms
the existing text-file-based configuration mechanism, providing features like
automatic nondimensionalization of physical quantities and handling of complex
parameter dependencies. Furthermore, Python is used to process and evaluate
results while the simulation is running, leading to smaller output files and
the possibility to adjust parameters dependent on the current simulation state.
C++ data structures are exported such that a seamless interfacing to other
numerical Python libraries is possible. The expressive power of Python and the
performance of C++ make development of efficient code with low time effort
possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07263</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07263</id><created>2015-11-23</created><authors><author><keyname>Cohen</keyname><forenames>Michael B.</forenames></author><author><keyname>Musco</keyname><forenames>Cameron</forenames></author><author><keyname>Musco</keyname><forenames>Christopher</forenames></author></authors><title>Ridge Leverage Scores for Low-Rank Approximation</title><categories>cs.DS cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often used as importance sampling probabilities, leverage scores have become
indispensable in randomized algorithms for linear algebra, optimization, graph
theory, and machine learning. A major body of work seeks to adapt these scores
to low-rank approximation problems. However, existing &quot;low-rank leverage
scores&quot; can be difficult to compute, often work for just a single application,
and are sensitive to matrix perturbations.
  We show how to avoid these issues by exploiting connections between low-rank
approximation and regularization. Specifically, we employ ridge leverage
scores, which are simply standard leverage scores computed with respect to an
$\ell_2$ regularized input. Importance sampling by these scores gives the first
unified solution to two of the most important low-rank sampling problems:
$(1+\epsilon)$ error column subset selection and $(1+\epsilon)$ error
projection-cost preservation.
  Moreover, ridge leverage scores satisfy a key monotonicity property that does
not hold for any prior low-rank leverage scores. Their resulting robustness
leads to two sought-after results in randomized linear algebra. 1) We give the
first input-sparsity time low-rank approximation algorithm based on iterative
column sampling, resolving an open question posed in [LMP13], [CLM+15], and
[AM15]. 2) We give the first single-pass streaming column subset selection
algorithm whose real-number space complexity has no dependence on stream
length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07267</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07267</id><created>2015-11-23</created><authors><author><keyname>Chu</keyname><forenames>Duc-Hiep</forenames></author><author><keyname>Jaffar</keyname><forenames>Joxan</forenames></author></authors><title>Local Reasoning with First-Class Heaps, and a New Frame Rule</title><categories>cs.PL</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Separation Logic (SL) brought an advance to program verification of data
structures by interpreting (recursively defined) predicates as implicit heaps,
and using a separating conjoin operator to construct heaps from disjoint
subheaps. While the Frame Rule of SL facilitated local reasoning in program
fragments, its restriction to disjoint subheaps means that any form of sharing
between predicates is problematic. With this as background motivation, we begin
with an assertion language in which subheaps may be explicitly defined within
predicates, and the effect of separation obtained by specifying that certain
heaps are disjoint. The strength of this base language is not just its
expressiveness, but it is amenable to symbolic execution and therefore
automatic program verification. In this paper, we extend this base language
with a new frame rule to accommodate subheaps and non-separating conjoining of
subheaps so as to provide compositional reasoning. This significantly extends
both the expressiveness and automatability of the base language. Finally we
demonstrate our framework to automatically prove two significant example
programs, one concerning a summary of a program fragments, and one exhibiting
structure sharing in data structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07271</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07271</id><created>2015-11-23</created><updated>2015-12-01</updated><authors><author><keyname>Sun</keyname><forenames>Shu</forenames></author><author><keyname>MacCartney</keyname><forenames>George R.</forenames><suffix>Jr.</suffix></author><author><keyname>Samimi</keyname><forenames>Mathew K.</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>Synthesizing Omnidirectional Antenna Patterns, Received Power and Path
  Loss from Directional Antennas for 5G Millimeter-Wave Communications</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Global Communications Conference (Globecom), Dec.
  2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Omnidirectional path loss models are vital for radiosystem design in wireless
communication systems, as they allow engineers to perform network simulations
for systems with arbitrary antenna patterns. At millimeter-wave frequencies,
channel measurements are frequently conducted using steerable highgain
directional antennas at both the transmitter and receiver to make up for the
significant increase in free space path loss at these frequencies compared to
traditional cellular systems that operate at lower frequencies. The
omnidirectional antenna pattern, and resulting omnidirectional received power
must therefore be synthesized from many unique pointing angles, where the
transmit and receive antennas are rotated over many different azimuth and
elevation planes. In this paper, the equivalent omnidirectional antenna pattern
and omnidirectional received power are synthesized by summing the received
powers from all measured unique pointing angles obtained at antenna halfpower
beamwidth step increments in the azimuth and elevation planes, and this method
is validated by demonstrating that the synthesized omnidirectional received
power and path loss are independent of antenna beamwidth, through theoretical
analyses and millimeter-wave propagation measurements using antennas with
different beamwidths. The method in this paper is shown to provide accurate
results while enhancing the measurement range substantially through the use of
directional antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07275</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07275</id><created>2015-11-23</created><updated>2015-11-23</updated><authors><author><keyname>Zaremba</keyname><forenames>Wojciech</forenames></author><author><keyname>Mikolov</keyname><forenames>Tomas</forenames></author><author><keyname>Joulin</keyname><forenames>Armand</forenames></author><author><keyname>Fergus</keyname><forenames>Rob</forenames></author></authors><title>Learning Simple Algorithms from Examples</title><categories>cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an approach for learning simple algorithms such as copying,
multi-digit addition and single digit multiplication directly from examples.
Our framework consists of a set of interfaces, accessed by a controller.
Typical interfaces are 1-D tapes or 2-D grids that hold the input and output
data. For the controller, we explore a range of neural network-based models
which vary in their ability to abstract the underlying algorithm from training
instances and generalize to test examples with many thousands of digits. The
controller is trained using $Q$-learning with several enhancements and we show
that the bottleneck is in the capabilities of the controller rather than in the
search incurred by $Q$-learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07289</identifier>
 <datestamp>2016-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07289</id><created>2015-11-23</created><updated>2016-02-22</updated><authors><author><keyname>Clevert</keyname><forenames>Djork-Arn&#xe9;</forenames></author><author><keyname>Unterthiner</keyname><forenames>Thomas</forenames></author><author><keyname>Hochreiter</keyname><forenames>Sepp</forenames></author></authors><title>Fast and Accurate Deep Network Learning by Exponential Linear Units
  (ELUs)</title><categories>cs.LG</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the &quot;exponential linear unit&quot; (ELU) which speeds up learning in
deep neural networks and leads to higher classification accuracies. Like
rectified linear units (ReLUs), leaky ReLUs (LReLUs) and parametrized ReLUs
(PReLUs), ELUs alleviate the vanishing gradient problem via the identity for
positive values. However, ELUs have improved learning characteristics compared
to the units with other activation functions. In contrast to ReLUs, ELUs have
negative values which allows them to push mean unit activations closer to zero
like batch normalization but with lower computational complexity. Mean shifts
toward zero speed up learning by bringing the normal gradient closer to the
unit natural gradient because of a reduced bias shift effect. While LReLUs and
PReLUs have negative values, too, they do not ensure a noise-robust
deactivation state. ELUs saturate to a negative value with smaller inputs and
thereby decrease the forward propagated variation and information. Therefore,
ELUs code the degree of presence of particular phenomena in the input, while
they do not quantitatively model the degree of their absence. In experiments,
ELUs lead not only to faster learning, but also to significantly better
generalization performance than ReLUs and LReLUs on networks with more than 5
layers. On CIFAR-100 ELUs networks significantly outperform ReLU networks with
batch normalization while batch normalization does not improve ELU networks.
ELU networks are among the top 10 reported CIFAR-10 results and yield the best
published result on CIFAR-100, without resorting to multi-view evaluation or
model averaging. On ImageNet, ELU networks considerably speed up learning
compared to a ReLU network with the same architecture, obtaining less than 10%
classification error for a single crop, single model network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07293</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07293</id><created>2015-11-23</created><authors><author><keyname>Lu</keyname><forenames>Zhaosong</forenames></author><author><keyname>Li</keyname><forenames>Xiaorui</forenames></author></authors><title>Sparse Recovery via Partial Regularization: Models, Theory and
  Algorithms</title><categories>math.OC cs.IT cs.LG math.IT stat.ME stat.ML</categories><comments>35 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of sparse recovery, it is known that most of existing
regularizers such as $\ell_1$ suffer from some bias incurred by some leading
entries (in magnitude) of the associated vector. To neutralize this bias, we
propose a class of models with partial regularizers for recovering a sparse
solution of a linear system. We show that every local minimizer of these models
is sufficiently sparse or the magnitude of all its nonzero entries is above a
uniform constant depending only on the data of the linear system. Moreover, for
a class of partial regularizers, any global minimizer of these models is a
sparsest solution to the linear system. We also establish some sufficient
conditions for local or global recovery of the sparsest solution to the linear
system, among which one of the conditions is weaker than the best known
restricted isometry property (RIP) condition for sparse recovery by $\ell_1$.
In addition, a first-order feasible augmented Lagrangian (FAL) method is
proposed for solving these models, in which each subproblem is solved by a
nonmonotone proximal gradient (NPG) method. Despite the complication of the
partial regularizers, we show that each proximal subproblem in NPG can be
solved as a certain number of one-dimensional optimization problems, which
usually have a closed-form solution. We also show that any accumulation point
of the sequence generated by FAL is a first-order stationary point of the
models. Numerical results on compressed sensing and sparse logistic regression
demonstrate that the proposed models substantially outperform the widely used
ones in the literature in terms of solution quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07299</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07299</id><created>2015-11-23</created><updated>2015-11-24</updated><authors><author><keyname>K&#xfc;bler</keyname><forenames>Thomas C.</forenames></author><author><keyname>Rittig</keyname><forenames>Tobias</forenames></author><author><keyname>Ungewiss</keyname><forenames>Judith</forenames></author><author><keyname>Krauss</keyname><forenames>Christina</forenames></author><author><keyname>Kasneci</keyname><forenames>Enkelejda</forenames></author></authors><title>Rendering refraction and reflection of eyeglasses for synthetic eye
  tracker images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While for the evaluation of robustness of eye tracking algorithms the use of
real-world data is essential, there are many applications where simulated,
synthetic eye images are of advantage. They can generate labelled ground-truth
data for appearance based gaze estimation algorithms or enable the development
of model based gaze estimation techniques by showing the influence on gaze
estimation error of different model factors that can then be simplified or
extended. We extend the generation of synthetic eye images by a simulation of
refraction and reflection for eyeglasses. On the one hand this allows for the
testing of pupil and glint detection algorithms under different illumination
and reflection conditions, on the other hand the error of gaze estimation
routines can be estimated in conjunction with different eyeglasses. We show how
a polynomial function fitting calibration performs equally well with and
without eyeglasses, and how a geometrical eye model behaves when exposed to
glasses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07303</identifier>
 <datestamp>2016-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07303</id><created>2015-11-23</created><updated>2016-01-15</updated><authors><author><keyname>Lenhart</keyname><forenames>William J.</forenames></author><author><keyname>Liotta</keyname><forenames>Giuseppe</forenames></author><author><keyname>Montecchiani</keyname><forenames>Fabrizio</forenames></author></authors><title>On Partitioning the Edges of 1-Plane Graphs</title><categories>cs.CG math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A 1-plane graph is a graph embedded in the plane such that each edge is
crossed at most once. A 1-plane graph is optimal if it has maximum edge
density. A red-blue edge coloring of an optimal 1-plane graph G partitions the
edge set of G into blue edges and red edges such that no two blue edges cross
each other and no two red edges cross each other. We prove the following: (i)
Every optimal 1-plane graph has a red-blue edge coloring such that the blue
subgraph is maximal planar while the red subgraph is K_4-free and has vertex
degree at most four; this bound on the vertex degree is worst-case optimal.
(ii) A red-blue edge coloring may not always induce a red forest of bounded
vertex degree. Applications of these results to graph augmentation and graph
drawing are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07305</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07305</id><created>2015-11-23</created><authors><author><keyname>Fenu</keyname><forenames>Caterina</forenames></author><author><keyname>Higham</keyname><forenames>Desmond J.</forenames></author></authors><title>Block Matrix Formulations for Evolving Networks</title><categories>cs.SI cs.NA physics.soc-ph</categories><comments>12 pages, 2 figures</comments><msc-class>05C50, 15A69</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many types of pairwise interaction take the form of a fixed set of nodes with
edges that appear and disappear over time. In the case of discrete-time
evolution, the resulting evolving network may be represented by a time-ordered
sequence of adjacency matrices. We consider here the issue of representing the
system as a single, higher dimensional block matrix, built from the individual
time-slices. We focus on the task of computing network centrality measures, and
present a particular block formulation that allows us to recover dynamic
centrality measures respecting time's arrow.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07311</identifier>
 <datestamp>2016-02-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07311</id><created>2015-11-23</created><updated>2016-02-23</updated><authors><author><keyname>Sun</keyname><forenames>Shu</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author><author><keyname>Thomas</keyname><forenames>Timothy A.</forenames></author><author><keyname>Ghosh</keyname><forenames>Amitava</forenames></author><author><keyname>Kovacs</keyname><forenames>Istvan Z.</forenames></author><author><keyname>Rodriguez</keyname><forenames>Ignacio</forenames></author><author><keyname>Koymen</keyname><forenames>Ozge</forenames></author><author><keyname>Partyka</keyname><forenames>Andrzej</forenames></author><author><keyname>Jarvelainen</keyname><forenames>Jan</forenames></author></authors><title>Propagation Path Loss Models for 5G Urban Micro- and Macro-Cellular
  Scenarios</title><categories>cs.IT math.IT</categories><comments>in 2016 IEEE 83rd Vehicular Technology Conference (VTC2016-Spring),
  May 2016, Nanjing, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents and compares two candidate large-scale propagation path
loss models, the alpha-beta-gamma (ABG) model and the close-in (CI) free space
reference distance model, for the design of fifth generation (5G) wireless
communication systems in urban micro- and macro-cellular scenarios. Comparisons
are made using the data obtained from 20 propagation measurement campaigns or
ray-tracing studies from 2 GHz to 73.5 GHz over distances ranging from 5 m to
1429 m. The results show that the one-parameter CI model has a very similar
goodness of fit (i.e., the shadow fading standard deviation) in both
line-of-sight and non-line-of-sight environments, while offering substantial
simplicity and more stable behavior across frequencies and distances, as
compared to the three-parameter ABG model. Additionally, the CI model needs
only one very subtle and simple modification to the existing 3GPP
floating-intercept path loss model (replacing a constant with a close-in free
space reference value) in order to provide greater simulation accuracy, more
simplicity, better repeatability across experiments, and higher stability
across a vast range of frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07312</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07312</id><created>2015-11-23</created><authors><author><keyname>Childers</keyname><forenames>J. T.</forenames></author><author><keyname>Uram</keyname><forenames>T. D.</forenames></author><author><keyname>LeCompte</keyname><forenames>T. J.</forenames></author><author><keyname>Papka</keyname><forenames>M. E.</forenames></author><author><keyname>Benjamin</keyname><forenames>D. P.</forenames></author></authors><title>Adapting the serial Alpgen event generator to simulate LHC collisions on
  millions of parallel threads</title><categories>hep-ph cs.DC physics.comp-ph</categories><comments>13 pages, 7 figures, publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the LHC moves to higher energies and luminosity, the demand for computing
resources increases accordingly and will soon outpace the growth of the
Worldwide LHC Computing Grid. To meet this greater demand, event generation
Monte Carlo was targeted for adaptation to run on Mira, the supercomputer at
the Argonne Leadership Computing Facility. Alpgen is a Monte Carlo event
generation application that is used by LHC experiments in the simulation of
collisions that take place in the Large Hadron Collider. This paper details the
process by which Alpgen was adapted from a single-processor serial-application
to a large-scale parallel-application and the performance that was achieved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07314</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07314</id><created>2015-11-23</created><authors><author><keyname>Hartinger</keyname><forenames>Tatiana Romina</forenames></author><author><keyname>Milani&#x10d;</keyname><forenames>Martin</forenames></author></authors><title>1-perfectly orientable graphs and graph products</title><categories>math.CO cs.DM</categories><msc-class>05C20, 05C76, 05C75</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph G is said to be 1-perfectly orientable (1-p.o. for short) if it
admits an orientation such that the out-neighborhood of every vertex is a
clique in G. The class of 1-p.o. graphs forms a common generalization of the
classes of chordal and circular arc graphs. Even though 1-p.o. graphs can be
recognized in polynomial time, no structural characterization of 1-p.o. graphs
is known. In this paper we consider the four standard graph products: the
Cartesian product, the strong product, the direct product, and the
lexicographic product. For each of them, we characterize when a nontrivial
product of two graphs is 1-p.o.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07316</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07316</id><created>2015-11-23</created><authors><author><keyname>Nassralla</keyname><forenames>Mohammad H.</forenames></author><author><keyname>Mansour</keyname><forenames>Mohammad M.</forenames></author><author><keyname>Jalloul</keyname><forenames>Louay M. A.</forenames></author></authors><title>A Low-Complexity Detection Algorithm for the Primary Synchronization
  Signal in LTE</title><categories>cs.IT math.IT</categories><comments>IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the challenging tasks in LTE baseband receiver design is
synchronization, which determines the symbol boundary and transmitted frame
start-time, and performs cell identification. Conventional algorithms are based
on correlation methods that involve a large number of multiplications and thus
lead to high receiver hardware complexity and power consumption. In this paper,
a hardware-efficient synchronization algorithm for frame timing based on
K-means clustering schemes is proposed. The algorithm reduces the complexity of
the primary synchronization signal for LTE from 24 complex-multiplications,
currently best known in the literature, to just 8. Simulation results
demonstrate that the proposed algorithm has negligible performance degradation
with reduced complexity relative to conventional techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07319</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07319</id><created>2015-11-13</created><authors><author><keyname>Provetti</keyname><forenames>Alessandro</forenames></author><author><keyname>Zucchellini</keyname><forenames>Andrea</forenames></author></authors><title>A Note on Flagg and Friedman's Epistemic and Intuitionistic Formal
  Systems</title><categories>cs.LO</categories><comments>Under evaluation by Annals of Pure and Applied Logic</comments><msc-class>03F55</msc-class><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report our findings on the properties of Flagg and Friedman's translation
from Epistemic into Intuitionistic logic, which was proposed as the basis of a
comprehensive proof method for the faithfulness of the Goodel translation. We
focus on the propositional case and raise the issue of the admissibility of the
translated necessitation rule. Then, we contribute to Flagg and Friedman's
program by giving an explicit proof of the soundness of their translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07337</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07337</id><created>2015-11-23</created><authors><author><keyname>Brea</keyname><forenames>Jorge</forenames></author><author><keyname>Burroni</keyname><forenames>Javier</forenames></author><author><keyname>Minnoni</keyname><forenames>Martin</forenames></author><author><keyname>Sarraute</keyname><forenames>Carlos</forenames></author></authors><title>Harnessing Mobile Phone Social Network Topology to Infer Users
  Demographic Attributes</title><categories>cs.SI physics.soc-ph</categories><journal-ref>Proceedings of the 8th Workshop on Social Network Mining and
  Analysis (SNAKDD 2014), New York City, USA, 24-27 August 2014, pp. 1-9</journal-ref><doi>10.1145/2659480.2659492</doi><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  We study the structure of the social graph of mobile phone users in the
country of Mexico, with a focus on demographic attributes of the users (more
specifically the users' age). We examine assortativity patterns in the graph,
and observe a strong age homophily in the communications preferences. We
propose a graph based algorithm for the prediction of the age of mobile phone
users. The algorithm exploits the topology of the mobile phone network,
together with a subset of known users ages (seeds), to infer the age of
remaining users. We provide the details of the methodology, and show
experimental results on a network GT with more than 70 million users. By
carefully examining the topological relations of the seeds to the rest of the
nodes in GT, we find topological metrics which have a direct influence on the
performance of the algorithm. In particular we characterize subsets of users
for which the accuracy of the algorithm is 62% when predicting between 4 age
categories (whereas a pure random guess would yield an accuracy of 25%). We
also show that we can use the probabilistic information computed by the
algorithm to further increase its inference power to 72% on a significant
subset of users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07338</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07338</id><created>2015-11-23</created><authors><author><keyname>Matthiesen</keyname><forenames>Bho</forenames></author><author><keyname>Jorswieck</keyname><forenames>Eduard A.</forenames></author></authors><title>Instantaneous Relaying for the 3-Way Relay Channel with Circular Message
  Exchanges</title><categories>cs.IT math.IT</categories><comments>In Proceedings of the Forty-Ninth Asilomar Conference on Signals,
  Systems, and Computers, Nov. 2015, Pacific Grove, CA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 3-user discrete memoryless multi-way relay channel with circular message
exchange and instantaneous relaying is investigated. We first show that this
channel is effectively a 3-user interference channel with receiver message side
information for every fixed (and instantaneous) relay mapping. Then, we extend
the Han-Kobayashi coding scheme to this channel. Finally, we apply these
results to Gaussian channels with amplify-and-forward relaying and present
numerical results showing the gain of the proposed scheme compared to the state
of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07340</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07340</id><created>2015-11-23</created><authors><author><keyname>Reeve</keyname><forenames>Henry W J</forenames></author><author><keyname>Brown</keyname><forenames>Gavin</forenames></author></authors><title>Modular Autoencoders for Ensemble Feature Extraction</title><categories>cs.LG</categories><comments>18 pages, 8 figures, to appear in a special issue of The Journal Of
  Machine Learning Research (vol.44, Dec 2015)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the concept of a Modular Autoencoder (MAE), capable of learning
a set of diverse but complementary representations from unlabelled data, that
can later be used for supervised tasks. The learning of the representations is
controlled by a trade off parameter, and we show on six benchmark datasets the
optimum lies between two extremes: a set of smaller, independent autoencoders
each with low capacity, versus a single monolithic encoding, outperforming an
appropriate baseline. In the present paper we explore the special case of
linear MAE, and derive an SVD-based algorithm which converges several orders of
magnitude faster than gradient descent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07345</identifier>
 <datestamp>2016-02-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07345</id><created>2015-11-23</created><updated>2016-02-23</updated><authors><author><keyname>Sun</keyname><forenames>Shu</forenames></author><author><keyname>MacCartney</keyname><forenames>George R.</forenames><suffix>Jr.</suffix></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author></authors><title>Millimeter-Wave Distance-Dependent Large-Scale Propagation Measurements
  and Path Loss Models for Outdoor and Indoor 5G Systems</title><categories>cs.IT math.IT</categories><comments>in the 10th European Conference on Antennas and Propagation, Davos,
  Switzerland, April 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents millimeter-wave propagation measurements for urban
micro-cellular and indoor office scenarios at 28 GHz and 73 GHz, and
investigates the corresponding path loss using five types of path loss models,
the singlefrequency floating-intercept (FI) model, single-frequency closein
(CI) free space reference distance model, multi-frequency alpha-beta-gamma
(ABG) model, multi-frequency CI model, and multi-frequency CI model with a
frequency-weighted path loss exponent (CIF), in both line-of-sight and
non-line-of-sight environments. Results show that the CI and CIF models provide
good estimation and exhibit stable behavior over frequencies and distances,
with a solid physical basis and less computational complexity when compared
with the FI and ABG models. Furthermore, path loss in outdoor scenarios shows
little dependence on frequency beyond the first meter of free space
propagation, whereas path loss tends to increase with frequency in addition to
the increased free space path loss in indoor environments. Therefore, the CI
model is suitable for outdoor environments over multiple frequencies, while the
CIF model is more appropriate for indoor modeling. This work shows that both
the CI and CIF models use fewer parameters and offer more convenient closedform
expressions suitable for analysis, without compromising model accuracy when
compared to current 3GPP and WINNER path loss models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07347</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07347</id><created>2015-11-23</created><authors><author><keyname>Zipser</keyname><forenames>Karl</forenames></author></authors><title>Node Specificity in Convolutional Deep Nets Depends on Receptive Field
  Position and Size</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In convolutional deep neural networks, receptive field (RF) size increases
with hierarchical depth. When RF size approaches full coverage of the input
image, different RF positions result in RFs with different specificity, as
portions of the RF fall out of the input space. This leads to a departure from
the convolutional concept of positional invariance and opens the possibility
for complex forms of context specificity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07349</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07349</id><created>2015-11-23</created><authors><author><keyname>Abbas</keyname><forenames>Hosny</forenames></author><author><keyname>Shaheen</keyname><forenames>Samir</forenames></author></authors><title>MOS-2: A Two-Dimension Space for Positioning MAS Organizational Models</title><categories>cs.MA</categories><comments>15 pages, 12 figures in International Journal of Engineering Research
  and General Science (ISSN 2091-2730)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increased complexity and dynamism of present and future Multi-Agent
Systems (MAS) enforce the need for considering both of their static
(design-time) and the dynamic (run-time) aspects. A type of balance between the
two aspects can definitely give better results related to system stability and
adaptivity. MAS organization is the research area that is concerned with these
issues and it is currently a very active and interesting research area.
Designing a MAS with an initial organization and giving it the ability to
dynamically reorganize to adapt the dynamic changes of its unpredictable and
uncertain environment, is the feasible way to survive and to run effectively.
Normally, MAS organization is tackled by what is called, MAS organizational
models, which are concerned with the description (formally or informally) of
the structural and dynamical aspects of agent organizations. This paper
proposes a two-dimension space, called MOS-2, for positioning and assessing MAS
organizational models based on two dimensions: their adopted engineering
viewpoint (agent-centered or organization-centered) as the vertical dimension
and the agents awareness/unawareness of the existence of the organizational
level as the horizontal dimension. The MOS-2 space is applied for positioning a
number of familiar organizational models. Its future trends and possible
improvements are highlighted. They include the following, (1) adding Time as a
dimension, (2) increasing the considered dimensions, (3) providing a
quantitative approach for positioning MAS organizational models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07353</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07353</id><created>2015-11-23</created><authors><author><keyname>Shaukat</keyname><forenames>Kamran</forenames></author><author><keyname>Masood</keyname><forenames>Nayyer</forenames></author><author><keyname>Shafaat</keyname><forenames>Ahmed Bin</forenames></author><author><keyname>Jabbar</keyname><forenames>Kamran</forenames></author><author><keyname>Shabbir</keyname><forenames>Hassan</forenames></author><author><keyname>Shabbir</keyname><forenames>Shakir</forenames></author></authors><title>Dengue Fever in Perspective of Clustering Algorithms</title><categories>cs.CY</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  Dengue fever is a disease which is transmitted and caused by Aedes Aegypti
mosquitos. Dengue has become a serious health issue in all over the world
especially in those countries who are situated in tropical or subtropical
regions because rain is an important factor for growth and increase in the
population of dengue transmitting mosquitos. For a long time, data mining
algorithms have been used by the scientists for the diagnosis and prognosis of
different diseases which includes dengue as well. This was a study to analyses
the attack of dengue fever in different areas of district Jhelum, Pakistan in
2011. As per our knowledge, we are unaware of any kind of research study in the
area of district Jhelum for diagnosis or analysis of dengue fever. According to
our information, we are the first one researching and analyzing dengue fever in
this specific area. Dataset was obtained from the office of Executive District
Officer EDO (health) District Jhelum. We applied DBSCAN algorithm for the
clustering of dengue fever. First we showed overall behavior of dengue in the
district Jhelum. Then we explained dengue fever at tehsil level with the help
of geographical pictures. After that we have elaborated comparison of different
clustering algorithms with the help of graphs based on our dataset. Those
algorithms include k-means, K-mediods, DBSCAN and OPTICS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07356</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07356</id><created>2015-11-23</created><authors><author><keyname>Honari</keyname><forenames>Sina</forenames></author><author><keyname>Yosinski</keyname><forenames>Jason</forenames></author><author><keyname>Vincent</keyname><forenames>Pascal</forenames></author><author><keyname>Pal</keyname><forenames>Christopher</forenames></author></authors><title>Recombinator Networks: Learning Coarse-to-Fine Feature Aggregation</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep neural networks with alternating convolutional, max-pooling and
decimation layers are widely used in state of the art architectures for
computer vision. Max-pooling purposefully discards precise spatial information
in order to create features that are more robust, and typically organized as
lower resolution spatial feature maps. On some tasks, such as whole-image
classification, max-pooling derived features are well suited; however, for
tasks requiring precise localization, such as pixel level prediction and
segmentation, max-pooling destroys exactly the information required to perform
well. Precise localization may be preserved by shallow convnets without pooling
but at the expense of robustness. Can we have our max-pooled multi-layered cake
and eat it too? Several papers have proposed summation and concatenation based
methods for combining upsampled coarse, abstract features with finer features
to produce robust pixel level predictions. Here we introduce another model ---
dubbed Recombinator Networks --- where coarse features inform finer features
early in their formation such that finer features can make use of several
layers of computation in deciding how to use coarse features. The model is
trained once, end-to-end and performs better than summation-based
architectures, reducing the error from the previous state of the art on two
facial keypoint datasets, AFW and AFLW, by 30% and beating the current
state-of-the-art on 300W without using extra data. We improve performance even
further by adding a denoising prediction model based on a novel convnet
formulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07357</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07357</id><created>2015-11-23</created><authors><author><keyname>Har-Peled</keyname><forenames>Sariel</forenames></author><author><keyname>Mahabadi</keyname><forenames>Sepideh</forenames></author></authors><title>Proximity in the Age of Distraction: Robust Approximate Nearest Neighbor
  Search</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new variant of the nearest neighbor search problem, which
allows for some coordinates of the dataset to be arbitrarily corrupted or
unknown. Formally, given a dataset of $n$ points $P=\{ x_1,\ldots, x_n\}$ in
high-dimensions, and a parameter $k$, the goal is to preprocess the dataset,
such that given a query point $q$, one can compute quickly a point $x \in P$,
such that the distance of the query to the point $x$ is minimized, when
ignoring the &quot;optimal&quot; $k$ coordinates. Note, that the coordinates being
ignored are a function of both the query point and the point returned.
  We present a general reduction from this problem to answering ANN queries,
which is similar in spirit to LSH (locality sensitive hashing) [IM98].
Specifically, we give a sampling technique which achieves a bi-criterion
approximation for this problem. If the distance to the nearest neighbor after
ignoring $k$ coordinates is $r$, the data-structure returns a point that is
within a distance of $O(r)$ after ignoring $O(k)$ coordinates. We also present
other applications and further extensions and refinements of the above result.
  The new data-structures are simple and (arguably) elegant, and should be
practical -- specifically, all bounds are polynomial in all relevant parameters
(including the dimension of the space, and the robustness parameter $k$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07361</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07361</id><created>2015-11-23</created><authors><author><keyname>Su</keyname><forenames>Guolong</forenames></author><author><keyname>Wei</keyname><forenames>Dennis</forenames></author><author><keyname>Varshney</keyname><forenames>Kush R.</forenames></author><author><keyname>Malioutov</keyname><forenames>Dmitry M.</forenames></author></authors><title>Interpretable Two-level Boolean Rule Learning for Classification</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes algorithms for learning two-level Boolean rules in
Conjunctive Normal Form (CNF, i.e. AND-of-ORs) or Disjunctive Normal Form (DNF,
i.e. OR-of-ANDs) as a type of human-interpretable classification model, aiming
for a favorable trade-off between the classification accuracy and the
simplicity of the rule. Two formulations are proposed. The first is an integer
program whose objective function is a combination of the total number of errors
and the total number of features used in the rule. We generalize a previously
proposed linear programming (LP) relaxation from one-level to two-level rules.
The second formulation replaces the 0-1 classification error with the Hamming
distance from the current two-level rule to the closest rule that correctly
classifies a sample. Based on this second formulation, block coordinate descent
and alternating minimization algorithms are developed. Experiments show that
the two-level rules can yield noticeably better performance than one-level
rules due to their dramatically larger modeling capacity, and the two
algorithms based on the Hamming distance formulation are generally superior to
the other two-level rule learning methods in our comparison. A proposed
approach to binarize any fractional values in the optimal solutions of LP
relaxations is also shown to be effective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07373</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07373</id><created>2015-11-23</created><authors><author><keyname>Arnborg</keyname><forenames>Stefan</forenames></author><author><keyname>Sj&#xf6;din</keyname><forenames>Gunnar</forenames></author></authors><title>What is the plausibility of probability?(revised 2003, 2015)</title><categories>cs.AI</categories><msc-class>62A01</msc-class><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  We present and examine a result related to uncertainty reasoning, namely that
a certain plausibility space of Cox's type can be uniquely embedded in a
minimal ordered field. This, although a purely mathematical result, can be
claimed to imply that every rational method to reason with uncertainty must be
based on sets of extended probability distributions, where extended probability
is standard probability extended with infinitesimals.
  This claim must be supported by some argumentation of non-mathematical type,
however, since pure mathematics does not tell us anything about the world. We
propose one such argumentation, and relate it to results from the literature of
uncertainty and statistics.
  In an added retrospective section we discuss some developments in the area
regarding countable additivity, partially ordered domains and robustness, and
philosophical stances on the Cox/Jaynes approach since 2003. We also show that
the most general partially ordered plausibility calculus embeddable in a ring
can be represented as a set of extended probability distributions or, in
algebraic terms, is a subdirect sum of ordered fields. In other words, the
robust Bayesian approach is universal. This result is exemplified by relating
Dempster-Shafer's evidence theory to robust Bayesian analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07374</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07374</id><created>2015-11-23</created><updated>2015-11-24</updated><authors><author><keyname>Sun</keyname><forenames>Shu</forenames></author><author><keyname>Thomas</keyname><forenames>Timothy A.</forenames></author><author><keyname>Rappaport</keyname><forenames>Theodore S.</forenames></author><author><keyname>Nguyen</keyname><forenames>Huan</forenames></author><author><keyname>Kovacs</keyname><forenames>Istvan Z.</forenames></author><author><keyname>Rodrigue</keyname><forenames>Ignacio</forenames></author></authors><title>Path Loss, Shadow Fading, and Line-Of-Sight Probability Models for 5G
  Urban Macro-Cellular Scenarios</title><categories>cs.IT math.IT</categories><comments>to appear in proceedings of IEEE Global Communications Conference
  Workshop, Dec. 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents key parameters including the line-of-sight (LOS)
probability, large-scale path loss, and shadow fading models for the design of
future fifth generation (5G) wireless communication systems in urban
macro-cellular (UMa) scenarios, using the data obtained from propagation
measurements at 38 GHz in Austin, US, and at 2, 10, 18, and 28 GHz in Aalborg,
Denmark. A comparison of different LOS probability models is performed for the
Aalborg environment. Alpha-betagamma and close-in reference distance path loss
models are studied in depth to show their value in channel modeling.
Additionally, both single-slope and dual-slope omnidirectional path loss models
are investigated to analyze and contrast their root-mean-square (RMS) errors on
measured path loss values. While the results show that the dual-slope
large-scale path loss model can slightly reduce RMS errors compared to its
singleslope counterpart in non-line-of-sight (NLOS) conditions, the improvement
is not significant enough to warrant adopting the dual-slope path loss model.
Furthermore, the shadow fading magnitude versus distance is explored, showing a
slight increasing trend in LOS and a decreasing trend in NLOS based on the
Aalborg data, but more measurements are necessary to gain a better knowledge of
the UMa channels at centimeter- and millimeter-wave frequency bands.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07376</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07376</id><created>2015-11-23</created><authors><author><keyname>Oskouei</keyname><forenames>Seyyed Salar Latifi</forenames></author><author><keyname>Golestani</keyname><forenames>Hossein</forenames></author><author><keyname>Kachuee</keyname><forenames>Mohamad</forenames></author><author><keyname>Hashemi</keyname><forenames>Matin</forenames></author><author><keyname>Mohammadzade</keyname><forenames>Hoda</forenames></author><author><keyname>Ghiasi</keyname><forenames>Soheil</forenames></author></authors><title>GPU-based Acceleration of Deep Convolutional Neural Networks on Mobile
  Platforms</title><categories>cs.DC cs.CV</categories><comments>This is a subtly improved version of a paper submitted to CVPR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile applications running on wearable devices and smartphones can greatly
benefit from accurate and scalable deep CNN-based machine learning algorithms.
While mobile CPU performance does not match the intensive computational
requirement of deep CNNs, the embedded GPU which already exists in many mobile
platforms can be leveraged for acceleration of CNN computations on the local
device and without the use of a cloud service. We present a GPU-based
accelerated deep CNN engine for mobile platforms with upto 60X speedup.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07386</identifier>
 <datestamp>2016-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07386</id><created>2015-11-23</created><updated>2016-01-22</updated><authors><author><keyname>Kokkinos</keyname><forenames>Iasonas</forenames></author></authors><title>Pushing the Boundaries of Boundary Detection using Deep Learning</title><categories>cs.CV cs.LG</categories><comments>The previous version reported large improvements w.r.t. the LPO
  region proposal baseline, which turned out to be due to a wrong computation
  for the baseline. The improvements are currently less important, and are
  omitted. We are sorry if the reported results caused any confusion. We have
  also integrated reviewer feedback regarding human performance on the BSD
  benchmark</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we show that adapting Deep Convolutional Neural Network training
to the task of boundary detection can result in substantial improvements over
the current state-of-the-art in boundary detection.
  Our contributions consist firstly in combining a careful design of the loss
for boundary detection training, a multi-resolution architecture and training
with external data to improve the detection accuracy of the current state of
the art. When measured on the standard Berkeley Segmentation Dataset, we
improve theoptimal dataset scale F-measure from 0.780 to 0.808 - while human
performance is at 0.803. We further improve performance to 0.813 by combining
deep learning with grouping, integrating the Normalized Cuts technique within a
deep network.
  We also examine the potential of our boundary detector in conjunction with
the task of semantic segmentation and demonstrate clear improvements over
state-of-the-art systems. Our detector is fully integrated in the popular Caffe
framework and processes a 320x420 image in less than a second.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07392</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07392</id><created>2015-11-23</created><authors><author><keyname>Olmos</keyname><forenames>Felipe</forenames><affiliation>CMAP</affiliation></author><author><keyname>Graham</keyname><forenames>Carl</forenames><affiliation>CMAP</affiliation></author><author><keyname>Simonian</keyname><forenames>Alain</forenames></author></authors><title>Cache Miss Estimation for Non-Stationary Request Processes</title><categories>math.PR cs.PF</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of the paper is to evaluate the miss probability of a Least Recently
Used (LRU) cache, when it is offered a non-stationary request process given by
a Poisson cluster point process. First, we construct a probability space using
Palm theory, describing how to consider a tagged document with respect to the
rest of the request process. This framework allows us to derive a general
integral formula for the expected number of misses of the tagged document.
Then, we consider the limit when the cache size and the arrival rate go to
infinity proportionally, and use the integral formula to derive an asymptotic
expansion of the miss probability in powers of the inverse of the cache size.
This enables us to quantify and improve the accuracy of the so-called Che
approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07394</identifier>
 <datestamp>2016-01-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07394</id><created>2015-11-23</created><updated>2016-01-10</updated><authors><author><keyname>Shih</keyname><forenames>Kevin J.</forenames></author><author><keyname>Singh</keyname><forenames>Saurabh</forenames></author><author><keyname>Hoiem</keyname><forenames>Derek</forenames></author></authors><title>Where To Look: Focus Regions for Visual Question Answering</title><categories>cs.CV</categories><comments>Submitted to CVPR2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method that learns to answer visual questions by selecting image
regions relevant to the text-based query. Our method exhibits significant
improvements in answering questions such as &quot;what color,&quot; where it is necessary
to evaluate a specific location, and &quot;what room,&quot; where it selectively
identifies informative image regions. Our model is tested on the VQA dataset
which is the largest human-annotated visual question answering dataset to our
knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07397</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07397</id><created>2015-11-23</created><authors><author><keyname>Farina</keyname><forenames>Gabriele</forenames></author><author><keyname>Gatti</keyname><forenames>Nicola</forenames></author></authors><title>Ad auctions and cascade model: GSP inefficiency and algorithms</title><categories>cs.GT</categories><comments>AAAI16, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of the best economic mechanism for Sponsored Search Auctions
(SSAs) is a central task in computational mechanism design/game theory. Two
open questions concern the adoption of user models more accurate than that one
currently used and the choice between Generalized Second Price auction (GSP)
and Vickrey-Clark-Groves mechanism (VCG). In this paper, we provide some
contributions to answer these questions. We study Price of Anarchy (PoA) and
Price of Stability (PoS) over social welfare and auctioneer's revenue of GSP
w.r.t. the VCG when the users follow the famous cascade model. Furthermore, we
provide exact, randomized, and approximate algorithms, showing that in
real-world settings (Yahoo! Webscope A3 dataset, 10 available slots) optimal
allocations can be found in less than 1s with up to 1000 ads, and can be
approximated in less than 20ms even with more than 1000 ads with an average
accuracy greater than 99%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07401</identifier>
 <datestamp>2016-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07401</id><created>2015-11-23</created><updated>2016-01-07</updated><authors><author><keyname>Sukhbaatar</keyname><forenames>Sainbayar</forenames></author><author><keyname>Szlam</keyname><forenames>Arthur</forenames></author><author><keyname>Synnaeve</keyname><forenames>Gabriel</forenames></author><author><keyname>Chintala</keyname><forenames>Soumith</forenames></author><author><keyname>Fergus</keyname><forenames>Rob</forenames></author></authors><title>MazeBase: A Sandbox for Learning from Games</title><categories>cs.LG cs.AI cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces MazeBase: an environment for simple 2D games, designed
as a sandbox for machine learning approaches to reasoning and planning. Within
it, we create 10 simple games embodying a range of algorithmic tasks (e.g.
if-then statements or set negation). A variety of neural models (fully
connected, convolutional network, memory network) are deployed via
reinforcement learning on these games, with and without a procedurally
generated curriculum. Despite the tasks' simplicity, the performance of the
models is far from optimal, suggesting directions for future development. We
also demonstrate the versatility of MazeBase by using it to emulate small
combat scenarios from StarCraft. Models trained on the MazeBase version can be
directly applied to StarCraft, where they consistently beat the in-game AI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07404</identifier>
 <datestamp>2016-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07404</id><created>2015-11-23</created><updated>2016-01-19</updated><authors><author><keyname>Fragkiadaki</keyname><forenames>Katerina</forenames></author><author><keyname>Agrawal</keyname><forenames>Pulkit</forenames></author><author><keyname>Levine</keyname><forenames>Sergey</forenames></author><author><keyname>Malik</keyname><forenames>Jitendra</forenames></author></authors><title>Learning Visual Predictive Models of Physics for Playing Billiards</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The ability to plan and execute goal specific actions in varied, unexpected
settings is a central requirement of intelligent agents. In this paper, we
explore how an agent can be equipped with an internal model of the dynamics of
the external world, and how it can use this model to plan novel actions by
running multiple internal simulations (&quot;visual imagination&quot;). Our models
directly process raw visual input, and use a novel object-centric prediction
formulation based on visual glimpses centered on objects (fixations) to enforce
translational invariance of the learned physical laws. The agent gathers
training data through random interaction with a collection of different
environments, and the resulting model can then be used to plan goal-directed
actions in novel environments that the agent has not seen before. We
demonstrate that our agent can accurately plan actions for playing a simulated
billiards game, which requires pushing a ball into a target position or into
collision with another ball.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07409</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07409</id><created>2015-11-23</created><authors><author><keyname>Xie</keyname><forenames>Saining</forenames></author><author><keyname>Huang</keyname><forenames>Xun</forenames></author><author><keyname>Tu</keyname><forenames>Zhuowen</forenames></author></authors><title>Convolutional Pseudo-Prior for Structured Labeling</title><categories>cs.CV cs.LG</categories><comments>Submission to ICLR 2016 conference. First two authors contributed
  equally to this work</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current practice in convolutional neural networks (CNN) remains largely
bottom-up and the role of top-down process in CNN for pattern analysis and
visual inference is not very clear. In this paper, we propose a new method for
structured labeling by developing convolutional pseudo-prior (ConvPP) on the
ground-truth labels. Our method has several interesting properties: (1)
compared with classical machine learning algorithms like CRFs and Structural
SVM, ConvPP automatically learns rich convolutional kernels to capture both
short- and long- range contexts; (2) compared with cascade classifiers like
Auto-Context, ConvPP avoids the iterative steps of learning a series of
discriminative classifiers and automatically learns contextual configurations;
(3) compared with recent efforts combing CNN models with CRFs and RNNs, ConvPP
learns convolution in the labeling space with much improved modeling capability
and less manual specification; (4) compared with Bayesian models like MRFs,
ConvPP capitalizes on the rich representation power of convolution by
automatically learning priors built on convolutional filters. We accomplish our
task using pseudo-likelihood approximation to the prior under a novel
fixed-point network structure that facilitates an end-to-end learning process.
We show state-of-the-art results on sequential labeling and image labeling
benchmarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07412</identifier>
 <datestamp>2015-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07412</id><created>2015-11-23</created><authors><author><keyname>Yang</keyname><forenames>Ger</forenames></author><author><keyname>Nikolova</keyname><forenames>Evdokia</forenames></author></authors><title>Approximation Algorithms for Route Planning with Nonlinear Objectives</title><categories>cs.DS</categories><comments>9 pages, 2 figures, main part of this paper is to be appear in
  AAAI'16</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider optimal route planning when the objective function is a general
nonlinear and non-monotonic function. Such an objective models user behavior
more accurately, for example, when a user is risk-averse, or the utility
function needs to capture a penalty for early arrival. It is known that as
nonlinearity arises, the problem becomes NP-hard and little is known about
computing optimal solutions when in addition there is no monotonicity
guarantee. We show that an approximately optimal non-simple path can be
efficiently computed under some natural constraints. In particular, we provide
a fully polynomial approximation scheme under hop constraints. Our
approximation algorithm can extend to run in pseudo-polynomial time under a
more general linear constraint that sometimes is useful. As a by-product, we
show that our algorithm can be applied to the problem of finding a path that is
most likely to be on time for a given deadline.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07423</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07423</id><created>2015-11-20</created><authors><author><keyname>Quang-Hung</keyname><forenames>Nguyen</forenames></author><author><keyname>Thoai</keyname><forenames>Nam</forenames></author></authors><title>Minimizing Total Busy Time for Energy-Aware Virtual Machine Allocation
  Problems</title><categories>cs.DC cs.PF</categories><comments>8 pages, Proceedings of the Sixth International Symposium on
  Information and Communication Technology. arXiv admin note: substantial text
  overlap with arXiv:1511.06825</comments><acm-class>C.2.4, C.4, D.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  This paper investigates the energy-aware virtual machine (VM) allocation
problems in clouds along characteristics: multiple resources, fixed interval
time and non-preemption of virtual machines. Many previous works have been
proposed to use a minimum number of physical machines, however, this is not
necessarily a good solution to minimize total energy consumption in the VM
placement with multiple resources, fixed interval time and non-preemption. We
observed that minimizing the sum of total busy time of all physical machines
implies minimizing total energy consumption of physical machines. In addition
to, if mapping of a VM onto physical machines have the same total busy time
then the best mapping has physical machine's remaining available resource
minimizing. Based on these observations, we proposed heuristic-based EM
algorithm to solve the energy-aware VM allocation with fixed starting time and
duration time. In addition, this work studies some heuristics for sorting the
list of virtual machines (e.g., sorting by the earliest starting time, or
latest finishing time, or the longest duration time first, etc.) to allocate
VM. We evaluate the EM using CloudSim toolkit and jobs log-traces in the
Feitelson's Parallel Workloads Archive. Simulation's results show that all of
EM-ST, EM-LFT and EM-LDTF algorithms could reduce total energy consumption
compared to state-of-the-art of power-aware VM allocation algorithms. (e.g.
Power-Aware Best-Fit Decreasing (PABFD) [7])).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07425</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07425</id><created>2015-11-21</created><updated>2016-01-02</updated><authors><author><keyname>Sabokrou</keyname><forenames>Mohammad</forenames></author><author><keyname>Fathy</keyname><forenames>Mahmood</forenames></author><author><keyname>Hosseini</keyname><forenames>Mojtaba</forenames></author></authors><title>Real-Time Anomalous Behavior Detection and Localization in Crowded
  Scenes</title><categories>cs.CV</categories><comments>This paper has been withdrawn by the author due to some error in
  experimental result. There are some mistakes</comments><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  In this paper, we propose an accurate and real-time anomaly detection and
localization in crowded scenes, and two descriptors for representing anomalous
behavior in video are proposed. We consider a video as being a set of cubic
patches. Based on the low likelihood of an anomaly occurrence, and the
redundancy of structures in normal patches in videos, two (global and local)
views are considered for modeling the video. Our algorithm has two components,
for (1) representing the patches using local and global descriptors, and for
(2) modeling the training patches using a new representation. We have two
Gaussian models for all training patches respect to global and local
descriptors. The local and global features are based on structure similarity
between adjacent patches and the features that are learned in an unsupervised
way. We propose a fusion strategy to combine the two descriptors as the output
of our system. Experimental results show that our algorithm performs like a
state-of-the-art method on several standard datasets, but even is more
time-efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07469</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07469</id><created>2015-11-23</created><authors><author><keyname>Li</keyname><forenames>Qunwei</forenames></author><author><keyname>Varshney</keyname><forenames>Pramod K.</forenames></author></authors><title>Resource Allocation and Outage Analysis for An Adaptive Cognitive
  Two-Way Relay Network</title><categories>cs.IT cs.NI math.IT</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, an adaptive two-way relay cooperation scheme is studied for
multiple-relay cognitive radio networks to improve the performance of secondary
transmissions. The power allocation scheme is derived to minimize the secondary
outage probability. We also provide best relay selection for the two-way relay
network using a max-min criterion. Exact closed-form expressions of secondary
outage probability are derived under a constraint on the quality of service of
primary transmissions in terms of the required primary outage probability. To
better understand the impact of primary user interference on secondary
transmissions, we further investigate the asymptotic behavior of the secondary
relay network when the primary signal-to-noise ratio goes to infinity,
including power allocation and outage probability. Simulation results are
provided to illustrate the performance of the proposed schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07471</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07471</id><created>2015-11-23</created><authors><author><keyname>Yu</keyname><forenames>Huizhen</forenames></author></authors><title>Weak Convergence Properties of Constrained Emphatic Temporal-difference
  Learning with Constant and Slowly Diminishing Stepsize</title><categories>cs.LG</categories><comments>53 pages</comments><msc-class>90C40, 62L20, 68W40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the emphatic temporal-difference (TD) algorithm, ETD($\lambda$),
for learning the value functions of stationary policies in a discounted, finite
state and action Markov decision process. The ETD($\lambda$) algorithm was
recently proposed by Sutton, Mahmood, and White to solve a long-standing
divergence problem of the standard TD algorithm when it is applied to
off-policy training, where data from an exploratory policy are used to evaluate
other policies of interest. The almost sure convergence of ETD($\lambda$) has
been proved in our recent work under general off-policy training conditions,
but for a narrow range of diminishing stepsize. In this paper we present
convergence results for constrained versions of ETD($\lambda$) with constant
stepsize and with diminishing stepsize from a broad range. Our results
characterize the asymptotic behavior of the trajectory of iterates produced by
those algorithms, and are derived by combining key properties of ETD($\lambda$)
with powerful convergence theorems from the weak convergence methods in
stochastic approximation theory. For the case of constant stepsize, in addition
to analyzing the behavior of the algorithms in the limit as the stepsize
parameter approaches zero, we also analyze their behavior for a fixed stepsize
and bound the deviations of their averaged iterates from the desired solution.
These results are obtained by exploiting the weak Feller property of the Markov
chains associated with the algorithms, and by using ergodic theorems for weak
Feller Markov chains, in conjunction with the convergence results we get from
the weak convergence methods. Besides ETD($\lambda$), our analysis also applies
to the off-policy TD($\lambda$) algorithm, when the divergence issue is avoided
by setting $\lambda$ sufficiently large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07480</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07480</id><created>2015-11-23</created><authors><author><keyname>Curticapean</keyname><forenames>Radu</forenames></author></authors><title>Parity Separation: A Scientifically Proven Method for Permanent Weight
  Loss</title><categories>cs.CC</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an edge-weighted graph G, let PerfMatch(G) denote the weighted sum over
all perfect matchings M in G, weighting each matching M by the product of
weights of edges in M. If G is unweighted, this plainly counts the perfect
matchings of G.
  In this paper, we introduce parity separation, a new method for reducing
PerfMatch to unweighted instances: For graphs G with edge-weights -1 and 1, we
construct two unweighted graphs G1 and G2 such that PerfMatch(G) =
PerfMatch(G1) - PerfMatch(G2). This yields a novel weight removal technique for
counting perfect matchings, in addition to those known from classical
#P-hardness proofs. We derive the following applications:
  1. An alternative #P-completeness proof for counting unweighted perfect
matchings.
  2. C=P-completeness for deciding whether two given unweighted graphs have the
same number of perfect matchings. To the best of our knowledge, this is the
first C=P-completeness result for the &quot;equality-testing version&quot; of any natural
counting problem that is not already #P-hard under parsimonious reductions.
  3. An alternative tight lower bound for counting unweighted perfect matchings
under the counting exponential-time hypothesis #ETH.
  Our technique is based upon matchgates and the Holant framework. To make our
#P-hardness proof self-contained, we also apply matchgates for an alternative
#P-hardness proof of PerfMatch on graphs with edge-weights -1 and 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07487</identifier>
 <datestamp>2016-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07487</id><created>2015-11-23</created><updated>2016-02-25</updated><authors><author><keyname>Zubiaga</keyname><forenames>Arkaitz</forenames></author><author><keyname>Liakata</keyname><forenames>Maria</forenames></author><author><keyname>Procter</keyname><forenames>Rob</forenames></author><author><keyname>Hoi</keyname><forenames>Geraldine Wong Sak</forenames></author><author><keyname>Tolmie</keyname><forenames>Peter</forenames></author></authors><title>Analysing How People Orient to and Spread Rumours in Social Media by
  Looking at Conversational Threads</title><categories>cs.SI</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  As breaking news unfolds people increasingly rely on social media to stay
abreast of the latest updates. The use of social media in such situations comes
with the caveat that new information being released piecemeal may encourage
rumours, many of which remain unverified long after their point of release.
Little is known, however, about the dynamics of the life cycle of a social
media rumour. In this paper we present a methodology that has enabled us to
collect, identify and annotate a dataset of 330 rumour threads (4,842 tweets)
associated with 9 newsworthy events. We analyse this dataset to understand how
users spread, support, or deny rumours that are later proven true or false, by
distinguishing two levels of status in a rumour life cycle i.e., before and
after its veracity status is resolved. The identification of rumours associated
with each event, as well as the tweet that resolved each rumour as true or
false, was performed by a team of journalists who tracked the events in real
time. Our study shows that rumours that are ultimately proven true tend to be
resolved faster than those that turn out to be false. Whilst one can readily
see users denying rumours once they have been debunked, users appear to be less
capable of distinguishing true from false rumours when their veracity remains
in question. In fact, we show that the prevalent tendency for users is to
support every unverified rumour. We also analyse the role of different types of
users, finding that highly reputable users such as news organisations endeavour
to post well-grounded statements, which appear to be certain and accompanied by
evidence. Nevertheless, these often prove to be unverified pieces of
information that give rise to false rumours. Our study reinforces the need for
developing robust machine learning techniques that can provide assistance for
assessing the veracity of rumours.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07488</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07488</id><created>2015-11-23</created><authors><author><keyname>Kim</keyname><forenames>John</forenames></author><author><keyname>Kopparty</keyname><forenames>Swastik</forenames></author></authors><title>Decoding Reed-Muller codes over product sets</title><categories>cs.CC cs.IT math.CO math.IT</categories><comments>25 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a polynomial time algorithm to decode multivariate polynomial codes
of degree $d$ up to half their minimum distance, when the evaluation points are
an arbitrary product set $S^m$, for every $d &lt; |S|$. Previously known
algorithms can achieve this only if the set $S$ has some very special algebraic
structure, or if the degree $d$ is significantly smaller than $|S|$. We also
give a near-linear time randomized algorithm, which is based on tools from
list-decoding, to decode these codes from nearly half their minimum distance,
provided $d &lt; (1-\epsilon)|S|$ for constant $\epsilon &gt; 0$.
  Our result gives an $m$-dimensional generalization of the well known decoding
algorithms for Reed-Solomon codes, and can be viewed as giving an algorithmic
version of the Schwartz-Zippel lemma.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07494</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07494</id><created>2015-11-23</created><authors><author><keyname>Byrka</keyname><forenames>Jaros&#x142;aw</forenames></author><author><keyname>Rybicki</keyname><forenames>Bartosz</forenames></author><author><keyname>Uniyal</keyname><forenames>Sumedha</forenames></author></authors><title>An approximation algorithm for Uniform Capacitated k-Median problem with
  1 + {\epsilon} capacity violation</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Capacitated k-Median problem, for which all the known constant
factor approximation algorithms violate either the number of facilities or the
capacities. While the standard LP-relaxation can only be used for algorithms
violating one of the two by a factor of at least two, Shi Li [SODA'15, SODA'16]
gave algorithms violating the number of facilities by a factor of 1+{\epsilon}
exploring properties of extended relaxations.
  In this paper we develop a constant factor approximation algorithm for
Uniform Capacitated k-Median violating only the capacities by a factor of
1+{\epsilon}. The algorithm is based on a configuration LP. Unlike in the
algorithms violating the number of facilities, we cannot simply open extra few
facilities at selected locations. Instead, our algorithm decides about the
facility openings in a carefully designed dependent rounding process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07497</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07497</id><created>2015-11-23</created><authors><author><keyname>Pathak</keyname><forenames>Deepak</forenames></author><author><keyname>Kr&#xe4;henb&#xfc;hl</keyname><forenames>Philipp</forenames></author><author><keyname>Yu</keyname><forenames>Stella X.</forenames></author><author><keyname>Darrell</keyname><forenames>Trevor</forenames></author></authors><title>Constrained Structured Regression with Convolutional Neural Networks</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Convolutional Neural Networks (CNNs) have recently emerged as the dominant
model in computer vision. If provided with enough training data, they predict
almost any visual quantity. In a discrete setting, such as classification, CNNs
are not only able to predict a label but often predict a confidence in the form
of a probability distribution over the output space. In continuous regression
tasks, such a probability estimate is often lacking. We present a regression
framework which models the output distribution of neural networks. This output
distribution allows us to infer the most likely labeling following a set of
physical or modeling constraints. These constraints capture the intricate
interplay between different input and output variables, and complement the
output of a CNN. However, they may not hold everywhere. Our setup further
allows to learn a confidence with which a constraint holds, in the form of a
distribution of the constrain satisfaction. We evaluate our approach on the
problem of intrinsic image decomposition, and show that constrained structured
regression significantly increases the state-of-the-art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07499</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07499</id><created>2015-11-23</created><authors><author><keyname>Park</keyname><forenames>Jeonghun</forenames></author><author><keyname>Lee</keyname><forenames>Namyoon</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>How Much Feedback is Required in Multi-Antenna Downlink Cellular
  Systems?</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a downlink cellular network where multi-antenna base stations
(BSs) transmit data to single-antenna users by using one of two linear
precoding methods with limited feedback: (i) maximum ratio transmission (MRT)
for serving a single user or (ii) zero forcing (ZF) for serving multiple users.
The BS and user locations are drawn from a Poisson point process, allowing
expressions for the signal- to-interference coverage probability and the
ergodic spectral efficiency to be derived as a function of system parameters
such as the number of BS antennas and feedback bits, and the pathloss exponent.
We find a tight lower bound on the optimum number of feedback bits to maximize
the net spectral efficiency, which captures the overall system gain by
considering both of downlink and uplink spectral efficiency using limited
feedback. Our main finding is that, when using MRT, the optimum number of
feedback bits scales linearly with the number of antennas, and logarithmically
with the channel coherence time. When using ZF, the feedback scales in the same
ways as MRT, but also linearly with the pathloss exponent. The derived results
provide system-level insights into the preferred channel codebook size by
averaging the effects of short-term fading and long-term pathloss.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07500</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07500</id><created>2015-11-23</created><authors><author><keyname>Strobel</keyname><forenames>Volker</forenames></author><author><keyname>Kirsch</keyname><forenames>Alexandra</forenames></author></authors><title>Planning in the Wild: Modeling Tools for PDDL</title><categories>cs.HC</categories><journal-ref>Strobel, Volker, and Alexandra Kirsch. &quot;Planning in the Wild:
  Modeling Tools for PDDL.&quot; KI 2014: Advances in Artificial Intelligence.
  Springer International Publishing, 2014. 273-284</journal-ref><doi>10.1007/978-3-319-11206-0_27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even though there are sophisticated AI planning algorithms, many integrated,
large-scale projects do not use planning. One reason seems to be the missing
support by engineering tools such as syntax highlighting and visualization. We
propose myPDDL - a modular toolbox for efficiently creating PDDL domains and
problems. To evaluate myPDDL, we compare it to existing knowledge engineering
tools for PDDL and experimentally assess its usefulness for novice PDDL users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07519</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07519</id><created>2015-11-23</created><authors><author><keyname>Elkhatib</keyname><forenames>Yehia</forenames></author><author><keyname>Tyson</keyname><forenames>Gareth</forenames></author><author><keyname>Sathiaseelan</keyname><forenames>Arjuna</forenames></author></authors><title>Does the Internet deserve everybody?</title><categories>cs.CY</categories><journal-ref>Proceedings of the 2015 ACM SIGCOMM Workshop on Ethics in
  Networked Systems Research</journal-ref><doi>10.1145/2793013.2793018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been a long standing tradition amongst developed nations of
influencing, both directly and indirectly, the activities of developing
economies. Behind this is one of a range of aims: building/improving living
standards, bettering the social status of recipient communities, etc. In some
cases, this has resulted in prosperous relations, yet often this has been seen
as the exploitation of a power position or a veneer for other activities (e.g.
to tap into new emerging markets). In this paper, we explore whether
initiatives to improve Internet connectivity in developing regions are always
ethical. We draw a list of issues that would aid in formulating Internet
initiatives that are ethical, effective, and sustainable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07521</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07521</id><created>2015-11-23</created><authors><author><keyname>Li</keyname><forenames>Zhuo</forenames></author><author><keyname>Liu</keyname><forenames>Lu</forenames></author><author><keyname>Dehghan</keyname><forenames>Sina</forenames></author><author><keyname>Chen</keyname><forenames>YangQuan</forenames></author><author><keyname>Xue</keyname><forenames>Dingyu</forenames></author></authors><title>A review and evaluation of numerical tools for fractional calculus and
  fractional order control</title><categories>cs.SY</categories><doi>10.1080/00207179.2015.1124290</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, as fractional calculus becomes more and more broadly used in
research across different academic disciplines, there are increasing demands
for the numerical tools for the computation of fractional
integration/differentiation, and the simulation of fractional order systems.
Time to time, being asked about which tool is suitable for a specific
application, the authors decide to carry out this survey to present
recapitulative information of the available tools in the literature, in hope of
benefiting researchers with different academic backgrounds. With this
motivation, the present article collects the scattered tools into a dashboard
view, briefly introduces their usage and algorithms, evaluates the accuracy,
compares the performance, and provides informative comments for selection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07527</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07527</id><created>2015-11-23</created><authors><author><keyname>Laarhoven</keyname><forenames>Thijs</forenames></author></authors><title>Tradeoffs for nearest neighbors on the sphere</title><categories>cs.DS cs.CG cs.IR</categories><comments>16 pages, 1 table, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider tradeoffs between the query and update complexities for the
(approximate) nearest neighbor problem on the sphere, extending the recent
spherical filters to sparse regimes and generalizing the scheme and analysis to
account for different tradeoffs. In a nutshell, for the sparse regime the
tradeoff between the query complexity $n^{\rho_q}$ and update complexity
$n^{\rho_u}$ for data sets of size $n$ is given by the following equation in
terms of the approximation factor $c$ and the exponents $\rho_q$ and $\rho_u$:
$$c^2\sqrt{\rho_q}+(c^2-1)\sqrt{\rho_u}=\sqrt{2c^2-1}.$$
  For small $c=1+\epsilon$, minimizing the time for updates leads to a linear
space complexity at the cost of a query time complexity $n^{1-4\epsilon^2}$.
Balancing the query and update costs leads to optimal complexities
$n^{1/(2c^2-1)}$, matching bounds from [Andoni-Razenshteyn, 2015] and [Dubiner,
IEEE-TIT'10] and matching the asymptotic complexities of [Andoni-Razenshteyn,
STOC'15] and [Andoni-Indyk-Laarhoven-Razenshteyn-Schmidt, NIPS'15]. A
subpolynomial query time complexity $n^{o(1)}$ can be achieved at the cost of a
space complexity of the order $n^{1/(4\epsilon^2)}$, matching the bound
$n^{\Omega(1/\epsilon^2)}$ of [Andoni-Indyk-Patrascu, FOCS'06] and
[Panigrahy-Talwar-Wieder, FOCS'10] and improving upon results of
[Indyk-Motwani, STOC'98] and [Kushilevitz-Ostrovsky-Rabani, STOC'98].
  For large $c$, minimizing the update complexity results in a query complexity
of $n^{2/c^2+O(1/c^4)}$, improving upon the related exponent for large $c$ of
[Kapralov, PODS'15] by a factor $2$, and matching the bound $n^{\Omega(1/c^2)}$
of [Panigrahy-Talwar-Wieder, FOCS'08]. Balancing the costs leads to optimal
complexities $n^{1/(2c^2-1)}$, while a minimum query time complexity can be
achieved with update complexity $n^{2/c^2+O(1/c^4)}$, improving upon the
previous best exponents of Kapralov by a factor $2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07528</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07528</id><created>2015-11-23</created><authors><author><keyname>Papernot</keyname><forenames>Nicolas</forenames></author><author><keyname>McDaniel</keyname><forenames>Patrick</forenames></author><author><keyname>Jha</keyname><forenames>Somesh</forenames></author><author><keyname>Fredrikson</keyname><forenames>Matt</forenames></author><author><keyname>Celik</keyname><forenames>Z. Berkay</forenames></author><author><keyname>Swami</keyname><forenames>Ananthram</forenames></author></authors><title>The Limitations of Deep Learning in Adversarial Settings</title><categories>cs.CR cs.LG cs.NE stat.ML</categories><comments>Accepted to the 1st IEEE European Symposium on Security &amp; Privacy,
  IEEE 2016. Saarbrucken, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deep learning takes advantage of large datasets and computationally efficient
training algorithms to outperform other approaches at various machine learning
tasks. However, imperfections in the training phase of deep neural networks
make them vulnerable to adversarial samples: inputs crafted by adversaries with
the intent of causing deep neural networks to misclassify. In this work, we
formalize the space of adversaries against deep neural networks (DNNs) and
introduce a novel class of algorithms to craft adversarial samples based on a
precise understanding of the mapping between inputs and outputs of DNNs. In an
application to computer vision, we show that our algorithms can reliably
produce samples correctly classified by human subjects but misclassified in
specific targets by a DNN with a 97% adversarial success rate while only
modifying on average 4.02% of the input features per sample. We then evaluate
the vulnerability of different sample classes to adversarial perturbations by
defining a hardness measure. Finally, we describe preliminary work outlining
defenses against adversarial samples by defining a predictive measure of
distance between a benign input and a target classification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07529</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07529</id><created>2015-11-23</created><authors><author><keyname>Whidden</keyname><forenames>Chris</forenames></author><author><keyname>Matsen</keyname><forenames>Frederick A.</forenames><suffix>IV</suffix></author></authors><title>Calculating the Unrooted Subtree Prune-and-Regraft Distance</title><categories>cs.DS q-bio.PE</categories><comments>37 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The subtree prune-and-regraft (SPR) distance metric is a fundamental way of
comparing evolutionary trees. It has wide-ranging applications, such as to
study lateral genetic transfer, viral recombination, and Markov chain Monte
Carlo phylogenetic inference. Although the rooted version of SPR distance can
be computed relatively efficiently between rooted trees using
fixed-parameter-tractable maximum agreement forest (MAF) algorithms, no MAF
formulation is known for the unrooted case. Correspondingly, previous
algorithms are unable to compute unrooted SPR distances larger than 7.
  In this paper, we substantially advance understanding of and computational
algorithms for the unrooted SPR distance. First we identify four properties of
minimal SPR paths, each of which suggests that no MAF formulation exists in the
unrooted case. We then prove the 2008 conjecture of Hickey et al. that chain
reduction preserves the unrooted SPR distance. This reduces the problem to a
linear size problem kernel, substantially improving on the previous best
quadratic size kernel. Then we introduce a new lower bound on the unrooted SPR
distance called the replug distance that is amenable to MAF methods, and give
an efficient fixed-parameter algorithm for calculating it. Finally, we develop
a &quot;progressive A*&quot; search algorithm using multiple heuristics, including the
TBR and replug distances, to exactly compute the unrooted SPR distance. Our
algorithm is nearly two orders of magnitude faster than previous methods on
small trees, and allows computation of unrooted SPR distances as large as 14 on
trees with 50 leaves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07531</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07531</id><created>2015-11-23</created><authors><author><keyname>Vettigli</keyname><forenames>Giuseppe</forenames></author><author><keyname>Ji</keyname><forenames>Mingyue</forenames></author><author><keyname>Tulino</keyname><forenames>Antonia M.</forenames></author><author><keyname>Llorca</keyname><forenames>Jaime</forenames></author><author><keyname>Festa</keyname><forenames>Paola</forenames></author></authors><title>An Efficient Coded Multicasting Scheme Preserving the Multiplicative
  Caching Gain</title><categories>cs.IT math.IT</categories><comments>6 pages, 7 figures, Published in Infocom CNTCV 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coded multicasting has been shown to be a promis- ing approach to
significantly improve the caching performance of content delivery networks with
multiple caches downstream of a common multicast link. However, achievable
schemes proposed to date have been shown to achieve the proved order-optimal
performance only in the asymptotic regime in which the number of packets per
requested item goes to infinity. In this paper, we first extend the asymptotic
analysis of the achievable scheme in [1], [2] to the case of heterogeneous
cache sizes and demand distributions, providing the best known upper bound on
the fundamental limiting performance when the number of packets goes to
infinity. We then show that the scheme achieving this upper bound quickly loses
its multiplicative caching gain for finite content packetization. To overcome
this limitation, we design a novel polynomial-time algorithm based on random
greedy graph- coloring that, while keeping the same finite content
packetization, recovers a significant part of the multiplicative caching gain.
Our results show that the order-optimal coded multicasting schemes proposed to
date, while useful in quantifying the fundamental limiting performance, must be
properly designed for practical regimes of finite packetization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07533</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07533</id><created>2015-11-23</created><authors><author><keyname>Lee</keyname><forenames>Seunghyun</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>Distributed Energy Beamforming with One-Bit Feedback</title><categories>cs.IT math.IT</categories><comments>submitted for possible conference publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy beamforming (EB) is a key technique for achieving efficient
radio-frequency (RF) transmission enabled wireless energy transfer (WET). By
optimally designing the waveforms from multiple energy transmitters (ETs) over
the wireless channels, they are constructively combined at the energy receiver
(ER) to achieve an EB gain that scales with the number of ETs. However, the
optimal design of transmit waveforms requires accurate channel state
information (CSI) at the ETs, which is challenging to obtain in practical WET
systems. In this paper, we propose a new channel training scheme to achieve
optimal EB gain in a distributed WET system, where multiple separated ETs
adjust their transmit phases to collaboratively send power to a single ER in an
iterative manner, based on one-bit feedback from the ER per training interval
which indicates the increase/decrease of the received power level from one
particular ET over two preassigned transmit phases. The proposed EB algorithm
can be efficiently implemented in practical WET systems even with a large
number of distributed ETs, and is analytically shown to converge quickly to the
optimal EB design as the number of feedback intervals per ET increases.
Numerical results are provided to evaluate the performance of the proposed
algorithm as compared to other distributed EB designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07535</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07535</id><created>2015-11-23</created><authors><author><keyname>Coons</keyname><forenames>Michael</forenames></author></authors><title>Regular sequences and the joint spectral radius</title><categories>math.CO cs.FL</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We classify the growth of a $k$-regular sequence based on information from
its $k$-kernel. In order to provide such a classification, we introduce the
notion of a growth exponent for $k$-regular sequences and show that this
exponent is equal to the joint spectral radius of any set of a special class of
matrices determined by the $k$-kernel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07536</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07536</id><created>2015-11-23</created><authors><author><keyname>Datta</keyname><forenames>Anupam</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Mitchell</keyname><forenames>John C.</forenames></author><author><keyname>Roy</keyname><forenames>Arnab</forenames></author><author><keyname>Sen</keyname><forenames>Shayak</forenames></author></authors><title>A Symbolic Logic with Concrete Bounds for Cryptographic Protocols</title><categories>cs.LO cs.CR</categories><acm-class>F.3.1; C.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a formal logic for quantitative reasoning about security
properties of network protocols. The system allows us to derive concrete
security bounds that can be used to choose key lengths and other security
parameters. We provide axioms for reasoning about digital signatures and random
nonces, with security properties based on the concrete security of signature
schemes and pseudorandom number generators (PRG). The formal logic supports
first-order reasoning and reasoning about protocol invariants, taking concrete
security bounds into account. Proofs constructed in our logic also provide
conventional asymptotic security guarantees because of the way that concrete
bounds accumulate in proofs. As an illustrative example, we use the formal
logic to prove an authentication property with concrete bounds of a
signature-based challenge-response protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07538</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07538</id><created>2015-11-23</created><authors><author><keyname>Roy</keyname><forenames>Ayan</forenames></author><author><keyname>Basu</keyname><forenames>Kaustuvi</forenames></author></authors><title>A Comparative Study of Statistical Learning and Adaptive Learning</title><categories>cs.CY</categories><comments>6 pages</comments><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  Numerous strategies have been adopted in order to make the process of
learning simple, efficient and within less amount of time.. Classroom learning
is slowly replaced by E-learning and M- learning. These techniques involve the
usage of computers, smart phones and tablets for the process of learning.
Learning from the internet has become popular among the e-learners where
learner tends to rely greatly upon information provided by the World Wide Web.
However, the e-learners have to go through a huge volume of data produced by
the first tier search engine, some of which are not suited to the interest of
the user. Various strategies, namely Statistical Learning and Adaptive
Learning, have been adopted to cater to the need of the user and produce data
best suited to the interest of the user. The authors have tried to present a
comparative study of Statistical Learning and Adaptive Learning based on
certain parameters, which arise from the characteristics of the learning
process. As a consequence of the comparative study, it has been concluded that
Adaptive learning is more efficient than Statistical learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07539</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07539</id><created>2015-11-23</created><authors><author><keyname>Ji</keyname><forenames>Mingyue</forenames></author><author><keyname>Shanmugam</keyname><forenames>Karthikeyan</forenames></author><author><keyname>Vettigli</keyname><forenames>Giuseppe</forenames></author><author><keyname>Llorca</keyname><forenames>Jaime</forenames></author><author><keyname>Tulino</keyname><forenames>Antonia M.</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>An Efficient Multiple-Groupcast Coded Multicasting Scheme for Finite
  Fractional Caching</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures, published in ICC 2015. arXiv admin note: text
  overlap with arXiv:1511.07531</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coded multicasting has been shown to improve the caching performance of
content delivery networks with multiple caches downstream of a common multicast
link. However, the schemes that have been shown to achieve order-optimal
perfor- mance require content items to be partitioned into a number of packets
that grows exponentially with the number of users [1]. In this paper, we first
extend the analysis of the achievable scheme in [2] to the case of
heterogeneous cache sizes and demand distribu- tions, providing an achievable
scheme and an upper bound on the limiting average performance when the number
of packets goes to infinity while the remaining system parameters are kept
constant. We then show how the scheme achieving this upper bound can very
quickly loose its multiplicative caching gain for finite content packetization.
To overcome this limitation, we design a novel polynomial-time algorithm based
on greedy local graph-coloring that, while keeping the same content
packetization, recovers a significant part of the multiplicative caching gain.
Our results show that the achievable schemes proposed to date to quantify the
limiting performance, must be properly designed for practical finite system
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07540</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07540</id><created>2015-11-23</created><updated>2015-12-01</updated><authors><author><keyname>Koczkodaj</keyname><forenames>W. W.</forenames></author></authors><title>Pairwise Comparisons Rating Scale Paradox</title><categories>cs.OH</categories><comments>12 pages, 3 figure, 1 table, progress report, (practically) ready for
  submission, call for cooperation, call for corrections of formerly published
  results (especially related to AHP) which may go into tens of thousands</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study demonstrates that incorrect data are entered into a pairwise
comparisons matrix for processing into weights for the data collected by a
rating scale. Unprocessed rating scale data lead to a paradox. A solution to
it, based on normalization, is proposed. This is an essential correction for
virtually all pairwise comparisons methods using rating scales. The
illustration of the relative error currently, taking place, is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07542</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07542</id><created>2015-11-23</created><authors><author><keyname>Ji</keyname><forenames>Mingyue</forenames></author><author><keyname>Tulino</keyname><forenames>Antonia</forenames></author><author><keyname>Llorca</keyname><forenames>Jaime</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Caching-Aided Coded Multicasting with Multiple Random Requests</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, published in ITW 2015. arXiv admin note: text
  overlap with arXiv:1402.4572</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of caching networks has received considerable attention in the
past few years. A particularly studied setting is the shared link caching
network, in which a single source with access to a file library communicates
with multiple users, each having the capability to store segments (packets) of
the library files, over a shared multicast link. Each user requests one file
from the library according to a common demand distribution and the server sends
a coded multicast message to satisfy all users at once. The problem consists of
finding the smallest possible average codeword length to satisfy such requests.
In this paper, we consider the generalization to the case where each user
places L &gt;= 1 independent requests according to the same common demand
distribution. We propose an achievable scheme based on random vector
(packetized) caching placement and multiple groupcast index coding, shown to be
order-optimal in the asymptotic regime in which the number of packets per file
B goes to infinity. We then show that the scalar (B = 1) version of the
proposed scheme can still preserve order-optimality when the number of per-user
requests L is large enough. Our results provide the first order-optimal
characterization of the shared link caching network with multiple random
requests, revealing the key effects of L on the performance of caching-aided
coded multicast schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07543</identifier>
 <datestamp>2016-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07543</id><created>2015-11-23</created><updated>2016-02-28</updated><authors><author><keyname>Li</keyname><forenames>Yixuan</forenames></author><author><keyname>Yosinski</keyname><forenames>Jason</forenames></author><author><keyname>Clune</keyname><forenames>Jeff</forenames></author><author><keyname>Lipson</keyname><forenames>Hod</forenames></author><author><keyname>Hopcroft</keyname><forenames>John</forenames></author></authors><title>Convergent Learning: Do different neural networks learn the same
  representations?</title><categories>cs.LG cs.NE</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent success in training deep neural networks have prompted active
investigation into the features learned on their intermediate layers. Such
research is difficult because it requires making sense of non-linear
computations performed by millions of parameters, but valuable because it
increases our ability to understand current models and create improved versions
of them. In this paper we investigate the extent to which neural networks
exhibit what we call convergent learning, which is when the representations
learned by multiple nets converge to a set of features which are either
individually similar between networks or where subsets of features span similar
low-dimensional spaces. We propose a specific method of probing
representations: training multiple networks and then comparing and contrasting
their individual, learned representations at the level of neurons or groups of
neurons. We begin research into this question using three techniques to
approximately align different neural networks on a feature level: a bipartite
matching approach that makes one-to-one assignments between neurons, a sparse
prediction approach that finds one-to-many mappings, and a spectral clustering
approach that finds many-to-many mappings. This initial investigation reveals a
few previously unknown properties of neural networks, and we argue that future
research into the question of convergent learning will yield many more. The
insights described here include (1) that some features are learned reliably in
multiple networks, yet other features are not consistently learned; (2) that
units learn to span low-dimensional subspaces and, while these subspaces are
common to multiple networks, the specific basis vectors learned are not; (3)
that the representation codes show evidence of being a mix between a local code
and slightly, but not fully, distributed codes across multiple units.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07544</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07544</id><created>2015-11-23</created><authors><author><keyname>Xu</keyname><forenames>Jinghong</forenames></author><author><keyname>Zhang</keyname><forenames>Lin</forenames></author><author><keyname>Ma</keyname><forenames>Baojun</forenames></author><author><keyname>Wu</keyname><forenames>Ye</forenames></author></authors><title>Impacts of suppressing guide on information spreading</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 6 figures,</comments><journal-ref>Physica A 444, 922(2016)</journal-ref><doi>10.1016/j.physa.2015.10.059</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is quite common that guides are introduced to suppress the information
spreading in modern society for different purposes. In this paper, an
agent-based model is established to quantitatively analyze the impacts of
suppressing guides on information spreading. We find that the spreading
threshold depends on the attractiveness of the information and the topology of
the social network with no suppressing guides at all. Usually, one would expect
that the existence of suppressing guides in the spreading procedure may result
in less diffusion of information within the overall network. However, we find
that sometimes the opposite is true: the manipulating nodes of suppressing
guides may lead to more extensive information spreading when there are
audiences with the reversal mind. These results can provide valuable
theoretical references to public opinion guidance on various information, e.g.,
rumor or news spreading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07545</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07545</id><created>2015-11-23</created><authors><author><keyname>Shi</keyname><forenames>Hailin</forenames></author><author><keyname>Zhu</keyname><forenames>Xiangyu</forenames></author><author><keyname>Liao</keyname><forenames>Shengcai</forenames></author><author><keyname>Lei</keyname><forenames>Zhen</forenames></author><author><keyname>Yang</keyname><forenames>Yang</forenames></author><author><keyname>Li</keyname><forenames>Stan Z.</forenames></author></authors><title>Constrained Deep Metric Learning for Person Re-identification</title><categories>cs.CV</categories><comments>11 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Person re-identification aims to re-identify the probe image from a given set
of images under different camera views. It is challenging due to large
variations of pose, illumination, occlusion and camera view. Since the
convolutional neural networks (CNN) have excellent capability of feature
extraction, certain deep learning methods have been recently applied in person
re-identification. However, in person re-identification, the deep networks
often suffer from the over-fitting problem. In this paper, we propose a novel
CNN-based method to learn a discriminative metric with good robustness to the
over-fitting problem in person re-identification. Firstly, a novel deep
architecture is built where the Mahalanobis metric is learned with a weight
constraint. This weight constraint is used to regularize the learning, so that
the learned metric has a better generalization ability. Secondly, we find that
the selection of intra-class sample pairs is crucial for learning but has
received little attention. To cope with the large intra-class variations in
pedestrian images, we propose a novel training strategy named moderate positive
mining to prevent the training process from over-fitting to the extreme samples
in intra-class pairs. Experiments show that our approach significantly
outperforms state-of-the-art methods on several benchmarks of person
re-identification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07549</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07549</id><created>2015-11-23</created><updated>2015-11-28</updated><authors><author><keyname>Krivulin</keyname><forenames>Nikolai</forenames></author></authors><title>Using tropical optimization to solve constrained minimax single-facility
  location problems with rectilinear distance</title><categories>math.OC cs.SY</categories><comments>24 pages, 2 figures</comments><msc-class>65K10 (Primary), 15A80, 90B85, 65K05, 90C48 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a constrained minimax single-facility location problem with
addends on the plane with rectilinear distance. The problem is first formulated
in a standard form, and then represented in terms of tropical mathematics as a
constrained optimization problem. We apply methods and results of tropical
optimization to obtain direct, explicit solutions to the optimization problem.
The results obtained are used to derive solutions of the location problem, and
of its special cases with reduced sets of constraints, in a closed form, ready
for immediate computation. Numerical solutions of example problems are given,
and graphical illustrations are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07551</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07551</id><created>2015-11-23</created><authors><author><keyname>Cao</keyname><forenames>Yanshuai</forenames></author><author><keyname>Fleet</keyname><forenames>David J.</forenames></author></authors><title>Transductive Log Opinion Pool of Gaussian Process Experts</title><categories>cs.LG stat.ML</categories><comments>Accepted at NIPS2015 Workshop on Nonparametric Methods for Large
  Scale Representation Learning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a framework for analyzing transductive combination of Gaussian
process (GP) experts, where independently trained GP experts are combined in a
way that depends on test point location, in order to scale GPs to big data. The
framework provides some theoretical justification for the generalized product
of GP experts (gPoE-GP) which was previously shown to work well in practice but
lacks theoretical basis. Based on the proposed framework, an improvement over
gPoE-GP is introduced and empirically validated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07556</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07556</id><created>2015-11-23</created><authors><author><keyname>Di</keyname><forenames>Xiaofei</forenames></author><author><keyname>Xiong</keyname><forenames>Ke</forenames></author><author><keyname>Fan</keyname><forenames>Pingyi</forenames></author><author><keyname>Yang</keyname><forenames>Hongchuan</forenames></author></authors><title>Simultaneous Wireless Information and Power Transfer in Cooperative
  Relay Networks with Rateless Codes</title><categories>cs.IT math.IT</categories><comments>31 pages,15 figures, submitted to IEEE Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the simultaneous wireless information and power
transfer (SWIPT) in cooperative relay networks, where a relay harvests energy
from the radio frequency (RF) signals transmitted by a source and then uses the
harvested energy to assist the information transmission from the source to its
destination. Both source and relay transmissions use rateless code, which
allows the destination to employ any of the two information receiving
strategies, i.e., the mutual information accumulation (IA) and the energy
accumulation (EA). The SWIPT-enabled relay employs three different SWIPT
receiver architectures, the ideal receiver and two practical receivers (i.e.,
the power splitting (PS) and the time switch (TS) receivers). Accordingly,
three relaying protocols, namely, ideal protocol, PS protocol and TS protocol,
are presented. In order to explore the system performance limits with these
three protocols, optimization problems are formulated to maximize their
achievable information rates. For the ideal protocol, explicit expressions of
the optimal solutions are derived. For the PS protocol, a linear-search
algorithm is designed to solve the non-convex problems. For the TS protocol,
two solving methods are presented. Numerical experiments are carried out to
validate our analysis and algorithms, which also show that, with the same SWIPT
receiver, the IA-based system outperforms the EA-based system, while with the
same information receiving strategy, PS protocol outperforms TS protocol.
Moreover, compared with conventional non-SWIPT and non-rateless-coded systems,
the proposed protocols exhibit considerable performance gains, especially in
relatively low signal-to-noise ratio (SNR) regime. Besides, the effects of the
source-destination direct link and the relay position on system performance are
also discussed, which provides insights on SWIPT-enabled relay systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07558</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07558</id><created>2015-11-23</created><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Gopi</keyname><forenames>Sivakanth</forenames></author></authors><title>Lower bounds for constant query affine-invariant LCCs and LTCs</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Affine-invariant codes are codes whose coordinates form a vector space over a
finite field and which are invariant under affine transformations of the
coordinate space. They form a natural, well-studied class of codes; they
include popular codes such as Reed-Muller and Reed-Solomon. A particularly
appealing feature of affine-invariant codes is that they seem well-suited to
admit local correctors and testers.
  In this work, we give lower bounds on the length of locally correctable and
locally testable affine-invariant codes with constant query complexity. We show
that if a code $\mathcal{C} \subset \Sigma^{\mathbb{K}^n}$ is an $r$-query
locally correctable code (LCC), where $\mathbb{K}$ is a finite field and
$\Sigma$ is a finite alphabet, then the number of codewords in $\mathcal{C}$ is
at most $\exp(O_{\mathbb{K}, r, |\Sigma|}(n^{r-1}))$. Also, we show that if
$\mathcal{C} \subset \Sigma^{\mathbb{K}^n}$ is an $r$-query locally testable
code (LTC), then the number of codewords in $\mathcal{C}$ is at most
$\exp(O_{\mathbb{K}, r, |\Sigma|}(n^{r-2}))$. The dependence on $n$ in these
bounds is tight for constant-query LCCs/LTCs, since Guo, Kopparty and Sudan
(ITCS `13) construct affine-invariant codes via lifting that have the same
asymptotic tradeoffs. Note that our result holds for non-linear codes, whereas
previously, Ben-Sasson and Sudan (RANDOM `11) assumed linearity to derive
similar results.
  Our analysis uses higher-order Fourier analysis. In particular, we show that
the codewords corresponding to an affine-invariant LCC/LTC must be far from
each other with respect to Gowers norm of an appropriate order. This then
allows us to bound the number of codewords, using known decomposition theorems
which approximate any bounded function in terms of a finite number of
low-degree non-classical polynomials, upto a small error in the Gowers norm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07559</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07559</id><created>2015-11-23</created><updated>2016-01-03</updated><authors><author><keyname>Chau</keyname><forenames>Chi-Kin</forenames></author><author><keyname>Zhang</keyname><forenames>Guanglin</forenames></author><author><keyname>Chen</keyname><forenames>Minghua</forenames></author></authors><title>Cost Minimizing Online Algorithms for Energy Storage Management with
  Worst-case Guarantee</title><categories>cs.DS math.OC</categories><comments>To appear in IEEE Transactions on Smart Grid</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fluctuations of electricity prices in demand response schemes and
intermittency of renewable energy supplies necessitate the adoption of energy
storage in microgrids. However, it is challenging to design effective real-time
energy storage management strategies that can deliver assured optimality,
without being hampered by the uncertainty of volatile electricity prices and
renewable energy supplies. This paper presents a simple effective online
algorithm for the charging and discharging decisions of energy storage that
minimizes the electricity cost in the presence of electricity price
fluctuations and renewable energy supplies, without relying on the future
information of prices, demands or renewable energy supplies. The proposed
algorithm is supported by a near-best worst-case guarantee (i.e., competitive
ratio), as compared to the offline optimal decisions based on full future
information. Furthermore, the algorithm can be adapted to take advantage of
limited future information, if available. By simulations on real-world data, it
is observed that the proposed algorithms can achieve satisfactory outcome in
practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07564</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07564</id><created>2015-11-23</created><authors><author><keyname>Lu</keyname><forenames>Yang</forenames></author><author><keyname>Xiong</keyname><forenames>Ke</forenames></author><author><keyname>Fan</keyname><forenames>Pingyi</forenames></author><author><keyname>Zhong</keyname><forenames>Zhangdui</forenames></author></authors><title>Deploying Multiple Antennas on High-speed Trains: Equidistant Strategy
  v.s. Fixed-Interval Strategy</title><categories>cs.IT math.IT</categories><comments>6 pages, 9 figures, submitted to IEEE Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deploying multiple antennas on high speed trains is an effective way to
enhance the information transmission performance for high speed railway (HSR)
wireless communication systems. However, how to efficiently deploy multiple
antennas on a train? This problem has not been studied yet. In this paper, we
shall investigate efficient antenna deployment strategies for HSR communication
systems where two multi-antenna deployment strategies, i.e., the equidistant
strategy and the fixed-interval strategy, are considered. To evaluate the
system performance, mobile service amount and outage time ratio are introduced.
Theoretical analysis and numerical results show that, when the length of the
train is not very large, for two-antenna case, by increasing the distance of
neighboring antennas in a reasonable region, the system performance can be
enhanced. It is also shown that the two strategies have much difference
performance behavior in terms of instantaneous channel capacity, and the
fixed-interval strategy may achieve much better performance than the
equidistant one in terms of service amount and outage time ratio when the
antenna number is much large.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07566</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07566</id><created>2015-11-23</created><authors><author><keyname>Xiong</keyname><forenames>Ke</forenames></author><author><keyname>Fan</keyname><forenames>Pingyi</forenames></author><author><keyname>Lu</keyname><forenames>Yang</forenames></author><author><keyname>Letaief</keyname><forenames>Khaled Ben</forenames></author></authors><title>Energy Efficiency with Proportional Rate Fairness in Multi-Relay OFDM
  Networks</title><categories>cs.IT math.IT</categories><comments>35 pages, 15 fihures, submitted to IEEE Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the energy efficiency (EE) in multiple relay aided
OFDM system, where decode-and-forward (DF) relay beamforming is employed to
help the information transmission. In order to explore the EE performance with
user fairness for such a system, we formulate an optimization problem to
maximize the EE by jointly considering several factors, the transmission mode
selection (DF relay beamforming or direct-link transmission), the helping relay
set selection, the subcarrier assignment and the power allocation at the source
and relays on subcarriers, under nonlinear proportional rate fairness
constraints, where both transmit power consumption and linearly rate-dependent
circuit power consumption are taken into account. To solve the non-convex
optimization problem, we propose a low-complexity scheme to approximate it.
Simulation results demonstrate its effectiveness. We also investigate the
effects of the circuit power consumption on system performances and observe
that with both the constant and the linearly rate-dependent circuit power
consumption, system EE grows with the increment of system average channel-to
noise ratio (CNR), but the growth rates show different behaviors. For the
constant circuit power consumption, system EE increasing rate is an increasing
function of the system average CNR, while for the linearly rate-dependent one,
system EE increasing rate is a decreasing function of the system average CNR.
This observation is very important which indicates that by deducing the circuit
dynamic power consumption per unit data rate, system EE can be greatly
enhanced. Besides, we also discuss the effects of the number of users and
subcarriers on the system EE performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07568</identifier>
 <datestamp>2016-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07568</id><created>2015-11-24</created><updated>2016-03-06</updated><authors><author><keyname>Akbar</keyname><forenames>Noman</forenames></author><author><keyname>Yang</keyname><forenames>Nan</forenames></author><author><keyname>Sadeghi</keyname><forenames>Parastoo</forenames></author><author><keyname>Kennedy</keyname><forenames>Rodney A.</forenames></author></authors><title>User Capacity Analysis and Pilot Design for Multi-Cell Multiuser Massive
  MIMO Networks</title><categories>cs.IT math.IT</categories><comments>Submitted for possible journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel pilot sequence design to mitigate pilot contamination in
multi-cell multiuser massive multiple-input multiple-output networks. Our
proposed design generates pilot sequences for all users in the multi-cell
network and devises power allocation at base stations (BSs) for downlink
transmission. The pilot sequences together with the power allocation ensure
that the user capacity of the network is achieved and the predefined
signal-to-interference-plus-noise ratio (SINR) requirements of all users are
met. To realize our design, we first derive new closed-form expressions for the
user capacity and the capacity region of the network. Built upon these
expressions, we then develop a new algorithm to obtain the required pilot
sequences and power allocation. We further determine the minimum number of
antennas required at BSs to achieve certain SINR requirements of all users.
Numerical results are presented to corroborate our analysis and to explicitly
examine the impact of key parameters, such as the pilot sequence length and the
total number of users, on the network performance. A pivotal conclusion is
reached that our design achieves a larger capacity region, supports a more
diverse range of SINR requirements, and needs a lower number of antennas at BSs
to fulfill the predefined SINR requirements than the existing designs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07569</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07569</id><created>2015-11-24</created><authors><author><keyname>Tang</keyname><forenames>Jiliang</forenames></author><author><keyname>Chang</keyname><forenames>Yi</forenames></author><author><keyname>Aggarwal</keyname><forenames>Charu</forenames></author><author><keyname>Liu</keyname><forenames>Huan</forenames></author></authors><title>A Survey of Signed Network Mining in Social Media</title><categories>cs.SI cs.AI physics.soc-ph</categories><comments>36 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real-world relations can be represented by signed networks with positive
and negative links, and signed network analysis has attracted increasing
attention from multiple disciplines. With the evolution of data from offline to
social media networks, signed network analysis has evolved from developing and
measuring theories to mining tasks. In this article, we present a review of
mining signed networks in social media and discuss some promising research
directions and new frontiers. We begin by giving basic concepts and unique
properties and principles of signed networks. Then we classify and review tasks
of signed network mining with representative algorithms. We also delineate some
tasks that have not been extensively studied with formal definitions and
research directions to expand the boundaries of signed network mining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07570</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07570</id><created>2015-11-24</created><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Xiong</keyname><forenames>Ke</forenames></author><author><keyname>Fan</keyname><forenames>Pingyi</forenames></author><author><keyname>Zhou</keyname><forenames>Xianwei</forenames></author></authors><title>Mobile Service-Based Cooperative Scheduling for High-Mobility Vehicular
  Networks</title><categories>cs.IT math.IT</categories><comments>11 pages, 10 figures, submitted to IEEE Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the downlink scheduling for relay-aided high-mobility
vehicular networks, where the vehicles with good vehicle-to-infrastructure
(V2I) links are employed as cooperative relay nodes to help the ones with poor
V2I links forward information via vehicle-to-vehicle (V2V) links. In existing
works, instantaneous achievable information rate was widely adopted to perform
the link scheduling, but it is not efficient for vehicular networks, especially
for high-mobility scenarios. Different from them, in this paper, we introduce
the mobile service to describe the mobile link capacity of vehicular networks
and then we propose a mobile service based relaying scheduling (MSRS) for high
mobility vehicular networks. In order to explore the system information
transmission performance limit, we formulate an optimization problem to
maximize the mobile service amount of MSRS by jointly scheduling the V2I and
V2V links. Since it is a combinational optimization problem which is too
complex to solve, we design an efficient algorithm with low-complexity for it,
where Sort-then-Select, Hungarian algorithm and Bisection search are employed.
Simulation results demonstrate that our proposed MSRS is able to achieve the
optimal results with an optimal approximation ratio larger than 96.5%. It is
also shown that our proposed MSRS is much more efficient for high-mobility
vehicular systems, which can improve the system average throughput with
increment of 3.63% compared with existing instantaneous achievable information
rate based scheduling method, and with 15% increment compared with traditional
non-cooperation scheduling method, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07571</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07571</id><created>2015-11-24</created><authors><author><keyname>Johnson</keyname><forenames>Justin</forenames></author><author><keyname>Karpathy</keyname><forenames>Andrej</forenames></author><author><keyname>Fei-Fei</keyname><forenames>Li</forenames></author></authors><title>DenseCap: Fully Convolutional Localization Networks for Dense Captioning</title><categories>cs.CV cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the dense captioning task, which requires a computer vision
system to both localize and describe salient regions in images in natural
language. The dense captioning task generalizes object detection when the
descriptions consist of a single word, and Image Captioning when one predicted
region covers the full image. To address the localization and description task
jointly we propose a Fully Convolutional Localization Network (FCLN)
architecture that processes an image with a single, efficient forward pass,
requires no external regions proposals, and can be trained end-to-end with a
single round of optimization. The architecture is composed of a Convolutional
Network, a novel dense localization layer, and Recurrent Neural Network
language model that generates the label sequences. We evaluate our network on
the Visual Genome dataset, which comprises 94,000 images and 4,100,000
region-grounded captions. We observe both speed and accuracy improvements over
baselines based on current state of the art approaches in both generation and
retrieval settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07573</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07573</id><created>2015-11-24</created><authors><author><keyname>Alotaibi</keyname><forenames>F.</forenames></author><author><keyname>Hosny</keyname><forenames>S.</forenames></author><author><keyname>Tadrous</keyname><forenames>J.</forenames></author><author><keyname>Gamal</keyname><forenames>H. El</forenames></author><author><keyname>Eryilmaz</keyname><forenames>A.</forenames></author></authors><title>Towards A Marketplace for Mobile Content: Dynamic Pricing and Proactive
  Caching</title><categories>cs.GT</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we investigate the profit maximization problem for a wireless
network carrier and the payment minimization for end-users. Motivated by recent
findings on proactive resource allocation, we focus on the scenario whereby
end-users who are equipped with device-to-device (D2D)communication can harness
predictable demand in proactive data contents caching and the possibility of
trading their proactive downloads to minimize their expected payments. The
carrier, on the other hand, utilizes a dynamic pricing scheme to differentiate
between off-peak and peak time prices and applies commissions on each trading
process to further maximize its profit. A novel marketplace that is based on
risk sharing between end-users is proposed where the tension between carrier
and end-users is formulated as a Stackelberg game. The existence and uniqueness
of the non-cooperative sub-game Nash equilibrium is shown. Furthermore, we
explore the equilibrium points for the case when the D2D is available and when
it is not available, and study the impact of the uncertainty of users future
demands on the system's performance. In particular, we compare the new
equilibrium with the baseline scenario of flat pricing. Despite end-users
connectivity with each other, the uncertainty of their future demands, and the
freshness of the pre-cached contents, we characterize a new equilibrium region
which yields to a win-win situation with respect to the baseline equilibrium.
We show that end-users activity patterns can be harnessed to maximize the
carrier's profit while minimizing the end-users expected payments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07578</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07578</id><created>2015-11-24</created><authors><author><keyname>Erturk</keyname><forenames>Emre</forenames></author><author><keyname>Iles</keyname><forenames>Howard Robert Edward</forenames></author></authors><title>Case Study on Cloud Based Library Software as a Service: Evaluating
  EZproxy</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a growing relationship between academic libraries and cloud
computing. Therefore, understanding the beginnings and the current use of cloud
base services in libraries is important. This will help understand the factors
that libraries should consider in the future. The purpose of this paper is to
better understand the future implementation of the cloud based software in
academic settings. Using cloud based, web based, and other remote services may
bring both advantages and disadvantages, some of which this paper will bring
out. First, a brief literature review of the academic literature, and a review
of available general-purpose cloud-based library products are conducted. Next,
a real-life scenario for a mid-sized New Zealand institution of higher
education is evaluated. This case involves moving from a locally hosted version
of EZproxy to a cloud based version with support from the vendor. As this
information system decision is an important one, this paper makes a
contribution to the available literature and can be informative for librarians.
In conclusion, academic libraries will gradually involve more pervasive use of
cloud based systems. The examples of important factors to be considered in
future decisions include timing and staffing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07605</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07605</id><created>2015-11-24</created><authors><author><keyname>Papadimitriou</keyname><forenames>Christos H.</forenames></author><author><keyname>Vishnoi</keyname><forenames>Nisheeth K.</forenames></author></authors><title>On the Computational Complexity of Limit Cycles in Dynamical Systems</title><categories>cs.CC cs.DS math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Poincare-Bendixson theorem for two-dimensional continuous
dynamical systems in compact domains from the point of view of computation,
seeking algorithms for finding the limit cycle promised by this classical
result. We start by considering a discrete analogue of this theorem and show
that both finding a point on a limit cycle, and determining if a given point is
on one, are PSPACE-complete.
  For the continuous version, we show that both problems are uncomputable in
the real complexity sense; i.e., their complexity is arbitrarily high.
Subsequently, we introduce a notion of an &quot;approximate cycle&quot; and prove an
&quot;approximate&quot; Poincar\'e-Bendixson theorem guaranteeing that some orbits come
very close to forming a cycle in the absence of approximate fixpoints;
surprisingly, it holds for all dimensions. The corresponding computational
problem defined in terms of arithmetic circuits is PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07607</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07607</id><created>2015-11-24</created><authors><author><keyname>Sharma</keyname><forenames>Rahul Anand</forenames></author><author><keyname>K</keyname><forenames>Pramod Sankar</forenames></author><author><keyname>Jawahar</keyname><forenames>CV</forenames></author></authors><title>Fine-Grain Annotation of Cricket Videos</title><categories>cs.MM cs.CL cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recognition of human activities is one of the key problems in video
understanding. Action recognition is challenging even for specific categories
of videos, such as sports, that contain only a small set of actions.
Interestingly, sports videos are accompanied by detailed commentaries available
online, which could be used to perform action annotation in a weakly-supervised
setting. For the specific case of Cricket videos, we address the challenge of
temporal segmentation and annotation of ctions with semantic descriptions. Our
solution consists of two stages. In the first stage, the video is segmented
into &quot;scenes&quot;, by utilizing the scene category information extracted from
text-commentary. The second stage consists of classifying video-shots as well
as the phrases in the textual description into various categories. The relevant
phrases are then suitably mapped to the video-shots. The novel aspect of this
work is the fine temporal scale at which semantic information is assigned to
the video. As a result of our approach, we enable retrieval of specific actions
that last only a few seconds, from several hours of video. This solution yields
a large number of labeled exemplars, with no manual effort, that could be used
by machine learning algorithms to learn complex actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07608</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07608</id><created>2015-11-24</created><authors><author><keyname>Kujala</keyname><forenames>Janne V.</forenames></author><author><keyname>Lukka</keyname><forenames>Tuomas J.</forenames></author><author><keyname>Holopainen</keyname><forenames>Harri</forenames></author></authors><title>Picking a Conveyor Clean by an Autonomously Learning Robot</title><categories>cs.RO cs.CV cs.LG</categories><comments>6 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a research picking prototype related to our company's industrial
waste sorting application. The goal of the prototype is to be as autonomous as
possible and it both calibrates itself and improves its picking with minimal
human intervention. The system learns to pick objects better based on a
feedback sensor in its gripper and uses machine learning to choosing the best
proposal from a random sample produced by simple hard-coded geometric models.
We show experimentally the system improving its picking autonomously by
measuring the pick success rate as function of time. We also show how this
system can pick a conveyor belt clean, depositing 70 out of 80 objects in a
difficult to manipulate pile of novel objects into the correct chute. We
discuss potential improvements and next steps in this direction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07611</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07611</id><created>2015-11-24</created><authors><author><keyname>Nanjappa</keyname><forenames>Ashwin</forenames></author><author><keyname>Cheng</keyname><forenames>Li</forenames></author><author><keyname>Gao</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Chi</forenames></author><author><keyname>Claridge-Chang</keyname><forenames>Adam</forenames></author><author><keyname>Bichler</keyname><forenames>Zoe</forenames></author></authors><title>Mouse Pose Estimation From Depth Images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on the challenging problem of efficient mouse 3D pose estimation
based on static images, and especially single depth images. We introduce an
approach to discriminatively train the split nodes of trees in random forest to
improve their performance on estimation of 3D joint positions of mouse. Our
algorithm is capable of working with different types of rodents and with
different types of depth cameras and imaging setups. In particular, it is
demonstrated in this paper that when a top-mounted depth camera is combined
with a bottom-mounted color camera, the final system is capable of delivering
full-body pose estimation including four limbs and the paws. Empirical
examinations on synthesized and real-world depth images confirm the
applicability of our approach on mouse pose estimation, as well as the closely
related task of part-based labeling of mouse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07616</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07616</id><created>2015-11-24</created><authors><author><keyname>Wu</keyname><forenames>Lingfei</forenames></author><author><keyname>Janssen</keyname><forenames>Marco A.</forenames></author></authors><title>Attention Dynamics in Collaborative Knowledge Creation</title><categories>physics.soc-ph cs.SI</categories><comments>11 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To uncover the mechanisms underlying the collaborative production of
knowledge, we investigate a very large online Question and Answer system that
includes the question asking and answering activities of millions of users over
five years. We created knowledge networks in which nodes are questions and
edges are the successive answering activities of users. We find that these
networks have two common properties: 1) the mitigation of degree inequality
among nodes; and 2) the assortative mixing of nodes. This means that, while the
system tends to reduce attention investment on old questions in order to supply
sufficient attention to new questions, it is not easy for novel knowledge be
integrated into the existing body of knowledge. We propose a mixing model to
combine preferential attachment and reversed preferential attachment processes
to model the evolution of knowledge networks and successfully reproduce the ob-
served patterns. Our mixing model is not only theoretically interesting but
also provide insights into the management of online communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07628</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07628</id><created>2015-11-24</created><authors><author><keyname>Wang</keyname><forenames>Changlong</forenames></author><author><keyname>Yue</keyname><forenames>Shigang</forenames></author><author><keyname>Peng</keyname><forenames>Jigen</forenames></author></authors><title>When is P such that l_0-minimization Equals to l_p-minimization</title><categories>cs.IT math.IT</categories><comments>16 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an analysis expression of p(A,b) such that the
unique solution to l_0-minimization also can be the unique solution to
l_p-minimization for any 0&lt;p&lt;p(A,b). Furthermore, the main contribution of this
paper isn't only the analysis expressed of such p^(A,b) but also its proof.
Finally, we display the results of two examples to confirm the validity of our
conclusions
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07637</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07637</id><created>2015-11-24</created><authors><author><keyname>Jeong</keyname><forenames>Seongah</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author><author><keyname>Haimovich</keyname><forenames>Alexander</forenames></author><author><keyname>Kang</keyname><forenames>Joonhyuk</forenames></author></authors><title>Positioning via Direct Localization in C-RAN Systems</title><categories>cs.IT math.IT</categories><comments>12 pages, 3 figures, submitted to IEEE Trans. Veh. Technol</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cloud Radio Access Network (C-RAN) is a prominent architecture for 5G
wireless cellular system which is based on the centralization of baseband
processing for multiple distributed radio units (RUs) at a control unit (CU).
In this correspondence, it is proposed to leverage the C-RAN architecture to
enable the implementation of direct, or one-step, localization of the position
of mobile devices from the received signals at distributed RUs. With ideal
connections between the CU and the RUs, direct localization is known to
outperform the traditional indirect, or two-step, localization, whereby the
source is located at a central node based on position-related measurements,
such as time of arrival (TOA), time difference of arrival (TDOA), angle of
arrival (AOA), or received signal strength (RSS), estimated at each RU
separately. In a C-RAN system, however, this may not be the case due to the
distortion caused by the quantization of the received signal at the RU needed
to cope with the capacity limitation of the fronthaul links connecting RUs and
CU. In this correspondence, the performance of direct localization is studied
for a C-RAN system by accounting for the effect of fronthaul quantization. The
analysis includes the derivation of Cramer-Rao Bound (CRB) on the squared
position error (SPE) of direct localization with quantized observations, as
well as the performance comparison of indirect localization and direct
localization with or without dithering via numerical results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07642</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07642</id><created>2015-11-24</created><updated>2015-11-25</updated><authors><author><keyname>Ashok</keyname><forenames>Pradeesha</forenames></author><author><keyname>Kolay</keyname><forenames>Sudeshna</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author></authors><title>Multivariate Complexity Analysis of Geometric {\sc Red Blue Set Cover}</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the parameterized complexity of GENERALIZED RED BLUE SET COVER
(Gen-RBSC), a generalization of the classic SET COVER problem and the more
recently studied RED BLUE SET COVER problem. Given a universe $U$ containing
$b$ blue elements and $r$ red elements, positive integers $k_\ell$ and $k_r$,
and a family $\F$ of $\ell$ sets over $U$, the \srbsc\ problem is to decide
whether there is a subfamily $\F'\subseteq \F$ of size at most $k_\ell$ that
covers all blue elements, but at most $k_r$ of the red elements. This
generalizes SET COVER and thus in full generality it is intractable in the
parameterized setting. In this paper, we study a geometric version of this
problem, called Gen-RBSC-lines, where the elements are points in the plane and
sets are defined by lines. We study this problem for an array of parameters,
namely, $k_\ell, k_r, r, b$, and $\ell$, and all possible combinations of them.
For all these cases, we either prove that the problem is W-hard or show that
the problem is fixed parameter tractable (FPT). In particular, on the
algorithmic side, our study shows that a combination of $k_\ell$ and $k_r$
gives rise to a nontrivial algorithm for Gen-RBSC-lines. On the hardness side,
we show that the problem is para-NP-hard when parameterized by $k_r$, and
W[1]-hard when parameterized by $k_\ell$. Finally, for the combination of
parameters for which Gen-RBSC-lines admits FPT algorithms, we ask for the
existence of polynomial kernels. We are able to provide a complete
kernelization dichotomy by either showing that the problem admits a polynomial
kernel or that it does not contain a polynomial kernel unless $\CoNP \subseteq
\NP/\mbox{poly}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07643</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07643</id><created>2015-11-24</created><authors><author><keyname>Ciotti</keyname><forenames>Valerio</forenames></author><author><keyname>Bonaventura</keyname><forenames>Moreno</forenames></author><author><keyname>Nicosia</keyname><forenames>Vincenzo</forenames></author><author><keyname>Panzarasa</keyname><forenames>Pietro</forenames></author><author><keyname>Latora</keyname><forenames>Vito</forenames></author></authors><title>Homophily and missing links in citation networks</title><categories>physics.soc-ph cs.DL cs.IR cs.SI</categories><comments>11 pages, 4 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Citation networks have been widely used to study the evolution of science
through the lenses of the underlying patterns of knowledge flows among academic
papers, authors, research sub-fields, and scientific journals. Here we focus on
citation networks to cast light on the salience of homophily, namely the
principle that similarity breeds connection, for knowledge transfer between
papers. To this end, we assess the degree to which citations tend to occur
between papers that are concerned with seemingly related topics or research
problems. Drawing on a large data set of articles published in the journals of
the American Physical Society between 1893 and 2009, we propose a novel method
for measuring the similarity between articles through the statistical
validation of the overlap between their bibliographies. Results suggest that
the probability of a citation made by one article to another is indeed an
increasing function of the similarity between the two articles. Our study also
enables us to uncover missing citations between pairs of highly related
articles, and may thus help identify barriers to effective knowledge flows. By
quantifying the proportion of missing citations, we conduct a comparative
assessment of distinct journals and research sub-fields in terms of their
ability to facilitate or impede the dissemination of knowledge. Findings
indicate that knowledge transfer seems to be more effectively facilitated by
journals of wide visibility, such as Physical Review Letters, than by
lower-impact ones. Our study has important implications for authors, editors
and reviewers of scientific journals, as well as public preprint repositories,
as it provides a procedure for recommending relevant yet missing references and
properly integrating bibliographies of papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07647</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07647</id><created>2015-11-24</created><authors><author><keyname>Jones</keyname><forenames>Jeff</forenames></author></authors><title>Exploiting Environmental Computation in a Multi-Agent Model of Slime
  Mould</title><categories>cs.ET</categories><comments>2014 ABBII International Symposium on Artificial, Biological and
  Bio-Inspired Intelligence, 27-28th September, Rhodes, Greece</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Very simple organisms, such as the single-celled amoeboid slime mould
Physarum polycephalum possess no neural tissue yet, despite this, are known to
exhibit complex biological and computational behaviour. Given such limited
resources, can environmental stimuli play a role in generating the complexity
of slime mould behaviour? We use a multi-agent collective model of slime mould
to explore a two-way mechanism where the collective behaviour is influenced by
simulated chemical concentration gradient fields and, in turn, this behaviour
alters the spatial pattern of the concentration gradients. This simple
mechanism yields complex behaviour amid the dynamically changing gradient
profiles and suggests how the apparently intelligent response of the slime
mould could possibly be due to outsourcing of computation to the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07651</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07651</id><created>2015-11-24</created><authors><author><keyname>Jones</keyname><forenames>Jeff Dale</forenames></author></authors><title>Material-based Non-neural Analogues of Lateral Inhibition: A Multi-agent
  Approach</title><categories>cs.ET</categories><comments>2014 - Adaptive Materials, Devices and Systems Towards Unconventional
  Computing and Robotics: Modeling and Implementation, 26th-27th September,
  Rhodes, Greece</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lateral Inhibition (LI) phenomena occur in a wide range of sensory modalities
and are most famously described in the human visual system. In LI the activity
of a stimulated neuron is itself excited and suppresses the activity of its
local neighbours via inhibitory connections, increasing the contrast between
spatial environmental stimuli. Simple or- ganisms, such as the single-celled
slime mould Physarum polycephalum possess no neural tissue yet, despite this,
are known to exhibit complex computational behaviour. Could simple organisms
such as slime mould approximate LI without recourse to neural tissue? We
describe a model whereby LI can emerge without explicit inhibitory wiring,
using only bulk transport effects. We use a multi-agent virtual material model
of slime mould to reproduce the characteristic contrast amplification response
of LI using excitation via attractant stimuli. Restoration of baseline activ-
ity occurs when the stimuli are removed. We also explore an opposite
counterpart behaviour, Lateral Activation (LA), using repellent stimuli. These
preliminary results suggest that simple organisms without neural tissue may
approximate sensory contrast enhancement using alternative analogues of LI and
suggests novel approaches towards generating collec- tive contrast enhancement
in distributed computing and robotic devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07654</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07654</id><created>2015-11-24</created><authors><author><keyname>Jones</keyname><forenames>Jeff</forenames></author></authors><title>Automated Guidance of Collective Movement in a Multi-Agent Model of
  Physarum polycephalum</title><categories>cs.ET</categories><comments>2015 - Automated Guidance of Collective Movement in a Multi-Agent
  Model of Physarum polycephalum, Multi-Agent Models on Swarm Behaviour, Swarm
  2015, 28-30 October, Kyoto, Japan</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collective movement occurs in living systems where the simple movements of
individual members of a pop- ulation are combined to generate movement of the
collective as a whole, displaying complex dynamics which cannot be found in the
component parts themselves. The plasmodium stage of slime mould Physarum
polycephalum displays complex amoeboid movement during its foraging and hazard
avoidance and its movement can be influenced by the spatial placement of
attractant and repellent stimuli. Slime mould is attractive to robotics due to
its simple component parts and the distributed nature of its control and
locomotion mechanisms. We investigate methods of automated guidance of a
multi-agent swarm collective along a pre-defined path to a goal location. We
demonstrate a closed-loop feedback mechanism using attractant and repellent
stimuli. We find that guidance by repellent stimuli (a light illumination mask)
provides faster and more accurate guidance than attractant sources, which
exhibit overshooting phenomena at path turns. The method allows traversal of
convoluted arenas with challenging obstacles and provides an insight into how
unconven- tional computing substrates may be hybridised with classical
computing methods to take advantage of the benefits of both approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07658</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07658</id><created>2015-11-24</created><authors><author><keyname>Li</keyname><forenames>Teng</forenames></author><author><keyname>Narayana</keyname><forenames>Vikram K.</forenames></author><author><keyname>El-Ghazawi</keyname><forenames>Tarek</forenames></author></authors><title>Efficient Resource Sharing Through GPU Virtualization on Accelerated
  High Performance Computing Systems</title><categories>cs.DC cs.PF</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The High Performance Computing (HPC) field is witnessing a widespread
adoption of Graphics Processing Units (GPUs) as co-processors for conventional
homogeneous clusters. The adoption of prevalent Single- Program Multiple-Data
(SPMD) programming paradigm for GPU-based parallel processing brings in the
challenge of resource underutilization, with the asymmetrical
processor/co-processor distribution. In other words, under SPMD, balanced
CPU/GPU distribution is required to ensure full resource utilization. In this
paper, we propose a GPU resource virtualization approach to allow underutilized
microprocessors to effi- ciently share the GPUs. We propose an efficient GPU
sharing scenario achieved through GPU virtualization and analyze the
performance potentials through execution models. We further present the
implementation details of the virtualization infrastructure, followed by the
experimental analyses. The results demonstrate considerable performance gains
with GPU virtualization. Furthermore, the proposed solution enables full
utilization of asymmetrical resources, through efficient GPU sharing among
microprocessors, while incurring low overhead due to the added virtualization
layer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07663</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07663</id><created>2015-11-24</created><updated>2016-02-09</updated><authors><author><keyname>Chakraborty</keyname><forenames>Supratik</forenames></author><author><keyname>Meel</keyname><forenames>Kuldeep S.</forenames></author><author><keyname>Mistry</keyname><forenames>Rakesh</forenames></author><author><keyname>Vardi</keyname><forenames>Moshe Y.</forenames></author></authors><title>Approximate Probabilistic Inference via Word-Level Counting</title><categories>cs.AI cs.LO</categories><comments>Full version of AAAI 2016 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hashing-based model counting has emerged as a promising approach for
large-scale probabilistic inference on graphical models. A key component of
these techniques is the use of xor-based 2-universal hash functions that
operate over Boolean domains. Many counting problems arising in probabilistic
inference are, however, naturally encoded over finite discrete domains.
Techniques based on bit-level (or Boolean) hash functions require these
problems to be propositionalized, making it impossible to leverage the
remarkable progress made in SMT (Satisfiability Modulo Theory) solvers that can
reason directly over words (or bit-vectors). In this work, we present the first
approximate model counter that uses word-level hashing functions, and can
directly leverage the power of sophisticated SMT solvers. Empirical evaluation
over an extensive suite of benchmarks demonstrates the promise of the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07677</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07677</id><created>2015-11-24</created><authors><author><keyname>Wohlbrandt</keyname><forenames>Attila</forenames></author><author><keyname>Weckm&#xfc;ller</keyname><forenames>Christian</forenames></author><author><keyname>Gu&#xe9;rin</keyname><forenames>S&#xe9;bastien</forenames></author></authors><title>A robust extension to the triple plane pressure mode matching method by
  filtering convective perturbations</title><categories>physics.flu-dyn cs.CE</categories><comments>Accepted 15-05-11 by International Journal of Aeroacoustics to be
  published in the special issue focusing on turbomachinery aeroacoustics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time-periodic CFD simulations are widely used to investigate turbomachinery
components. The triple-plane pressure mode matching method (TPP) developed by
Ovenden and Rienstra extracts the acoustic part in such simulations. Experience
shows that this method is subject to significant errors when the amplitude of
pseudo-sound is high compared to sound. Pseudo-sound are unsteady pressure
fluctuations with a convective character. The presented extension to the TPP
improves the splitting between acoustics and the rest of the unsteady flow
field. The method is simple: i) the acoustic eigenmodes are analytically
determined for a uniform mean flow as in the original TPP; ii) the suggested
model for convective pressure perturbations uses the convective wavenumber as
axial wavenumber and the same orthogonal radial shape functions as for the
acoustic modes. The reliability is demonstrated on the simulation data of a
low-pressure fan. As acoustic and convective perturbations are separated, the
accuracy of the results increases close to sources, allowing a reduction of the
computational costs by shortening the simulation domain. The extended method is
as robust as the original one--giving the same results for the acoustic modes
in absence of convective perturbations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07693</identifier>
 <datestamp>2016-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07693</id><created>2015-11-24</created><updated>2016-02-10</updated><authors><author><keyname>Szuba</keyname><forenames>Marek</forenames></author><author><keyname>Ameri</keyname><forenames>Parinaz</forenames></author><author><keyname>Grabowski</keyname><forenames>Udo</forenames></author><author><keyname>Meyer</keyname><forenames>J&#xf6;rg</forenames></author><author><keyname>Streit</keyname><forenames>Achim</forenames></author></authors><title>A Distributed System for Storing and Processing Data from
  Earth-observing Satellites: System Design and Performance Evaluation of the
  Visualisation Tool</title><categories>cs.DC</categories><comments>6 pages, 6 figures. To be published in the proceedings of the 16th
  IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid
  2016)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a distributed system for storage, processing, three-dimensional
visualisation and basic analysis of data from Earth-observing satellites. The
database and the server have been designed for high performance and
scalability, whereas the client is highly portable thanks to having been
designed as a HTML5- and WebGL-based Web application. The system is based on
the so-called MEAN stack, a modern replacement for LAMP which has steadily been
gaining traction among high-performance Web applications. We demonstrate the
performance of the system from the perspective of an user operating the client.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07702</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07702</id><created>2015-11-24</created><authors><author><keyname>Hu</keyname><forenames>Sha</forenames></author><author><keyname>Kroll</keyname><forenames>Harald</forenames></author><author><keyname>Huang</keyname><forenames>Qiuting</forenames></author><author><keyname>Rusek</keyname><forenames>Fredrik</forenames></author></authors><title>A Low-complexity Channel Shortening Receiver with Diversity Support for
  Evolved 2G Device</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The second generation (2G) cellular networks are the current workhorse for
machine-to-machine (M2M) communications. Diversity in 2G devices can be present
both in form of multiple receive branches and blind repetitions. In presence of
diversity, intersymbol interference (ISI) equalization and co-channel
interference (CCI) suppression are usually very complex. In this paper, we
consider the improvements for 2G devices with receive diversity. We derive a
low-complexity receiver based on a channel shortening filter, which allows to
sum up all diversity branches to a single stream after filtering while keeping
the full diversity gain. The summed up stream is subsequently processed by a
single stream Max-log-MAP (MLM) equalizer. The channel shortening filter is
designed to maximize the mutual information lower bound (MILB) with the
Ungerboeck detection model. Its filter coefficients can be obtained mainly by
means of discrete-Fourier transforms (DFTs). Compared with the state-of-art
homomorphic (HOM) filtering based channel shortener which cooperates with a
delayed-decision feedback MLM (DDF-MLM) equalizer, the proposed MILB channel
shortener has superior performance. Moreover, the equalization complexity, in
terms of real-valued multiplications, is decreased by a factor that equals the
number of diversity branches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07710</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07710</id><created>2015-11-24</created><authors><author><keyname>Nagaraja</keyname><forenames>Varun K.</forenames></author><author><keyname>Morariu</keyname><forenames>Vlad I.</forenames></author><author><keyname>Davis</keyname><forenames>Larry S.</forenames></author></authors><title>Searching for Objects using Structure in Indoor Scenes</title><categories>cs.CV cs.AI</categories><comments>Appeared in British Machine Vision Conference (BMVC) 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To identify the location of objects of a particular class, a passive computer
vision system generally processes all the regions in an image to finally output
few regions. However, we can use structure in the scene to search for objects
without processing the entire image. We propose a search technique that
sequentially processes image regions such that the regions that are more likely
to correspond to the query class object are explored earlier. We frame the
problem as a Markov decision process and use an imitation learning algorithm to
learn a search strategy. Since structure in the scene is essential for search,
we work with indoor scene images as they contain both unary scene context
information and object-object context in the scene. We perform experiments on
the NYU-depth v2 dataset and show that the unary scene context features alone
can achieve a significantly high average precision while processing only
20-25\% of the regions for classes like bed and sofa. By considering
object-object context along with the scene context features, the performance is
further improved for classes like counter, lamp, pillow and sofa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07714</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07714</id><created>2015-11-24</created><authors><author><keyname>Riedl</keyname><forenames>Mark O.</forenames></author></authors><title>A Python Engine for Teaching Artificial Intelligence in Games</title><categories>cs.CY</categories><acm-class>K.3.2; K.8.0; I.2.1; I.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer games play an important role in our society and motivate people to
learn computer science. Since artificial intelligence is integral to most
games, they can also be used to teach artificial intelligence. We introduce the
Game AI Game Engine (GAIGE), a Python game engine specifically designed to
teach about how AI is used in computer games. A progression of seven
assignments builds toward a complete, working Multi-User Battle Arena (MOBA)
game. We describe the engine, the assignments, and our experiences using it in
a class on Game Artificial Intelligence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07727</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07727</id><created>2015-11-24</created><updated>2015-11-26</updated><authors><author><keyname>Baydin</keyname><forenames>Atilim Gunes</forenames></author><author><keyname>Pearlmutter</keyname><forenames>Barak A.</forenames></author><author><keyname>Siskind</keyname><forenames>Jeffrey Mark</forenames></author></authors><title>DiffSharp: Automatic Differentiation Library</title><categories>cs.MS</categories><comments>5 pages, 1 figure, minor fixes, added coauthor</comments><msc-class>68T05, 68W30</msc-class><acm-class>I.2.6; G.1.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce DiffSharp, an automatic differentiation (AD)
library designed with machine learning in mind. AD is a family of techniques
that evaluate derivatives at machine precision with only a small constant
factor of overhead, by systematically applying the chain rule of calculus at
the elementary operator level. DiffSharp aims to make an extensive array of AD
techniques available, in convenient form, to the machine learning community.
These including arbitrary nesting of forward/reverse AD operations, AD with
linear algebra primitives, and a functional API that emphasizes the use of
higher-order functions and composition. The library exposes this functionality
through an API that provides gradients, Hessians, Jacobians, directional
derivatives, and matrix-free Hessian- and Jacobian-vector products. Bearing the
performance requirements of the latest machine learning techniques in mind, the
underlying computations are run through a high-performance BLAS/LAPACK backend,
using OpenBLAS by default. GPU support is currently being implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07729</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07729</id><created>2015-11-24</created><authors><author><keyname>Gilmer</keyname><forenames>Justin</forenames></author><author><keyname>Kouck&#xfd;</keyname><forenames>Michal</forenames></author><author><keyname>Saks</keyname><forenames>Michael</forenames></author></authors><title>A communication game related to the sensitivity conjecture</title><categories>cs.CC</categories><msc-class>68R05 (primary), 68Q01, 05D05 (secondary)</msc-class><acm-class>F.1.3; G.2.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the major outstanding foundational problems about boolean functions is
the sensitivity conjecture, which (in one of its many forms) asserts that the
degree of a boolean function (i.e. the minimum degree of a real polynomial that
interpolates the function) is bounded above by some fixed power of its
sensitivity (which is the maximum vertex degree of the graph defined on the
inputs where two inputs are adjacent if they differ in exactly one coordinate
and their function values are different). We propose an attack on the
sensitivity conjecture in terms of a novel two-player communication game. A
lower bound of the form $n^{\Omega(1)}$ on the cost of this game would imply
the sensitivity conjecture.
  To investigate the problem of bounding the cost of the game, three natural
(stronger) variants of the question are considered. For two of these variants,
protocols are presented that show that the hoped for lower bound does not hold.
These protocols satisfy a certain monotonicity property, and (in contrast to
the situation for the two variants) we show that the cost of any monotone
protocol satisfies a strong lower bound.
  There is an easy upper bound of $\sqrt{n}$ on the cost of the game. We also
improve slightly on this upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07732</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07732</id><created>2015-11-24</created><authors><author><keyname>Santini</keyname><forenames>Thiago</forenames></author><author><keyname>Fuhl</keyname><forenames>Wolfgang</forenames></author><author><keyname>K&#xfc;bler</keyname><forenames>Thomas</forenames></author><author><keyname>Kasneci</keyname><forenames>Enkelejda</forenames></author></authors><title>Bayesian Identification of Fixations, Saccades, and Smooth Pursuits</title><categories>cs.CV</categories><comments>8 pages</comments><acm-class>I.5.1; I.6.4; J.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smooth pursuit eye movements provide meaningful insights and information on
subject's behavior and health and may, in particular situations, disturb the
performance of typical fixation/saccade classification algorithms. Thus, an
automatic and efficient algorithm to identify these eye movements is paramount
for eye-tracking research involving dynamic stimuli. In this paper, we propose
the Bayesian Decision Theory Identification (I-BDT) algorithm, a novel
algorithm for ternary classification of eye movements that is able to reliably
separate fixations, saccades, and smooth pursuits in an online fashion, even
for low-resolution eye trackers. The proposed algorithm is evaluated on four
datasets with distinct mixtures of eye movements, including fixations,
saccades, as well as straight and circular smooth pursuits; data was collected
with a sample rate of 30 Hz from six subjects, totaling 24 evaluation datasets.
The algorithm exhibits high and consistent performance across all datasets and
movements relative to a manual annotation by a domain expert (recall: \mu =
91.42%, \sigma = 9.52%; precision: \mu = 95.60%, \sigma = 5.29%; specificity
\mu = 95.41%, \sigma = 7.02%) and displays a significant improvement when
compared to I-VDT, an state-of-the-art algorithm (recall: \mu = 87.67%, \sigma
= 14.73%; precision: \mu = 89.57%, \sigma = 8.05%; specificity \mu = 92.10%,
\sigma = 11.21%). For algorithm implementation and annotated datasets, please
contact the first author.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07741</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07741</id><created>2015-11-24</created><authors><author><keyname>Georgiadis</keyname><forenames>Loukas</forenames></author><author><keyname>Tarjan</keyname><forenames>Robert E.</forenames></author></authors><title>A Note on Fault Tolerant Reachability for Directed Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we describe an application of low-high orders in fault-tolerant
network design. Baswana et al. [DISC 2015] study the following reachability
problem. We are given a flow graph $G = (V, A)$ with start vertex $s$, and a
spanning tree $T =(V, A_T)$ rooted at $s$. We call a set of arcs $A'$ valid if
the subgraph $G' = (V, A_T \cup A')$ of $G$ has the same dominators as $G$. The
goal is to find a valid set of minimum size. Baswana et al. gave an $O(m
\log{n})$-time algorithm to compute a minimum-size valid set in $O(m \log{n})$
time, where $n = |V|$ and $m = |A|$. Here we provide a simple $O(m)$-time
algorithm that uses the dominator tree $D$ of $G$ and a low-high order of it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07763</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07763</id><created>2015-11-24</created><authors><author><keyname>Gidaris</keyname><forenames>Spyros</forenames></author><author><keyname>Komodakis</keyname><forenames>Nikos</forenames></author></authors><title>LocNet: Improving Localization Accuracy for Object Detection</title><categories>cs.CV cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel object localization methodology with the purpose of
boosting the localization accuracy of state-of-the-art object detection
systems. Our model, given a search region, aims at returning the bounding box
of an object of interest inside this region. To accomplish its goal, it relies
on assigning conditional probabilities to each row and column of this region,
where these probabilities provide useful information regarding the location of
the boundaries of the object inside the search region and allow the accurate
inference of the object bounding box under a simple probabilistic framework.
  For implementing our localization model, we make use of a convolutional
neural network architecture that is properly adapted for this task, called
LocNet. We show experimentally that LocNet achieves a very significant
improvement on the mAP for high IoU thresholds on PASCAL VOC2007 test set and
that it can be very easily coupled with recent state-of-the-art object
detection systems, helping them to boost their performance. Furthermore, it
sets a new state-of-the-art on PASCAL VOC2012 test set achieving mAP of 74.8%.
Finally, we demonstrate that our detection approach can achieve high detection
accuracy even when it is given as input a set of sliding windows, thus proving
that it is independent of bounding box proposal methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07788</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07788</id><created>2015-11-24</created><authors><author><keyname>Marasek</keyname><forenames>Krzysztof</forenames></author><author><keyname>Brocki</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Korzinek</keyname><forenames>Danijel</forenames></author><author><keyname>Wo&#x142;k</keyname><forenames>Krzysztof</forenames></author><author><keyname>Gubrynowicz</keyname><forenames>Ryszard</forenames></author></authors><title>Spoken Language Translation for Polish</title><categories>cs.CL</categories><comments>Marasek K., Wo{\l}k K., Korzinek D., Brocki {\L}., Spoken Language
  Translation for Polish, Proceedings of Forum Acuscticum 2014, Krak\'ow. arXiv
  admin note: substantial text overlap with arXiv:1509.08909</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spoken language translation (SLT) is becoming more important in the
increasingly globalized world, both from a social and economic point of view.
It is one of the major challenges for automatic speech recognition (ASR) and
machine translation (MT), driving intense research activities in these areas.
While past research in SLT, due to technology limitations, dealt mostly with
speech recorded under controlled conditions, today's major challenge is the
translation of spoken language as it can be found in real life. Considered
application scenarios range from portable translators for tourists, lectures
and presentations translation, to broadcast news and shows with live
captioning. We would like to present PJIIT's experiences in the SLT gained from
the Eu-Bridge 7th framework project and the U-Star consortium activities for
the Polish/English language pair. Presented research concentrates on ASR
adaptation for Polish (state-of-the-art acoustic models: DBN-BLSTM training,
Kaldi: LDA+MLLT+SAT+MMI), language modeling for ASR &amp; MT (text normalization,
RNN-based LMs, n-gram model domain interpolation) and statistical translation
techniques (hierarchical models, factored translation models, automatic casing
and punctuation, comparable and bilingual corpora preparation). While results
for the well-defined domains (phrases for travelers, parliament speeches,
medical documentation, movie subtitling) are very encouraging, less defined
domains (presentation, lectures) still form a challenge. Our progress in the
IWSLT TED task (MT only) will be presented, as well as current progress in the
Polish ASR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07792</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07792</id><created>2015-11-24</created><authors><author><keyname>Dubrova</keyname><forenames>Elena</forenames></author><author><keyname>N&#xe4;slund</keyname><forenames>Mats</forenames></author><author><keyname>Carlsson</keyname><forenames>Gunnar</forenames></author><author><keyname>Fornehed</keyname><forenames>John</forenames></author><author><keyname>Smeets</keyname><forenames>Ben</forenames></author></authors><title>Two Countermeasures Against Hardware Trojans Exploiting Non-Zero
  Aliasing Probability of BIST</title><categories>cs.CR</categories><comments>16 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The threat of hardware Trojans has been widely recognized by academia,
industry, and government agencies. A Trojan can compromise security of a system
in spite of cryptographic protection. The damage caused by a Trojan may not be
limited to a business or reputation, but could have a severe impact on public
safety, national economy, or national security. An extremely stealthy way of
implementing hardware Trojans has been presented by Becker et al. at CHES'2012.
Their work have shown that it is possible to inject a Trojan in a random number
generator compliant with FIPS 140-2 and NIST SP800-90 standards by exploiting
non-zero aliasing probability of Logic Built-In-Self-Test (LBIST). In this
paper, we present two methods for modifying LBIST to prevent such an attack.
The first method makes test patterns dependent on a configurable key which is
programed into a chip after the manufacturing stage. The second method uses a
remote test management system which can execute LBIST using a different set of
test patterns at each test cycle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07803</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07803</id><created>2015-11-24</created><authors><author><keyname>Khoreva</keyname><forenames>Anna</forenames></author><author><keyname>Benenson</keyname><forenames>Rodrigo</forenames></author><author><keyname>Omran</keyname><forenames>Mohamed</forenames></author><author><keyname>Hein</keyname><forenames>Matthias</forenames></author><author><keyname>Schiele</keyname><forenames>Bernt</forenames></author></authors><title>Weakly Supervised Object Boundaries</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  State-of-the-art learning based boundary detection methods require extensive
training data. Since labelling object boundaries is one of the most expensive
types of annotations, there is a need to relax the requirement to carefully
annotate images to make both the training more affordable and to extend the
amount of training data. In this paper we propose a technique to generate
weakly supervised annotations and show that bounding box annotations alone
suffice to reach high-quality object boundaries without using any
object-specific boundary annotations. With the proposed weak supervision
techniques we achieve the top performance on the object boundary detection
task, outperforming by a large margin the current fully supervised
state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07826</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07826</id><created>2015-11-24</created><updated>2015-12-01</updated><authors><author><keyname>Bansal</keyname><forenames>Nikhil</forenames></author><author><keyname>Srinivasan</keyname><forenames>Aravind</forenames></author><author><keyname>Svensson</keyname><forenames>Ola</forenames></author></authors><title>Lift-and-Round to Improve Weighted Completion Time on Unrelated Machines</title><categories>cs.DS</categories><comments>21 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of scheduling jobs on unrelated machines so as to
minimize the sum of weighted completion times. Our main result is a
$(3/2-c)$-approximation algorithm for some fixed $c&gt;0$, improving upon the
long-standing bound of 3/2 (independently due to Skutella, Journal of the ACM,
2001, and Sethuraman &amp; Squillante, SODA, 1999). To do this, we first introduce
a new lift-and-project based SDP relaxation for the problem. This is necessary
as the previous convex programming relaxations have an integrality gap of
$3/2$. Second, we give a new general bipartite-rounding procedure that produces
an assignment with certain strong negative correlation properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07829</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07829</id><created>2015-11-24</created><authors><author><keyname>Liu</keyname><forenames>Jingbo</forenames></author><author><keyname>Cuff</keyname><forenames>Paul</forenames></author><author><keyname>Verd&#xfa;</keyname><forenames>Sergio</forenames></author></authors><title>$E_{\gamma}$-Resolvability</title><categories>cs.IT math.IT</categories><comments>54 pages, 4 figures, presented in part at 2015 IEEE International
  Symposium on Information Theory (ISIT)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conventional channel resolvability refers to the minimum rate needed for
an input process to approximate an output distribution of a channel in total
variation distance. In this paper we study $E_{\gamma}$-resolvability, which
replaces total variation distance by the more general $E_{\gamma}$ distance. A
general one-shot achievability bound for the precision of such an approximation
is developed. We show that in the asymptotic setting where $\gamma=\exp(nE)$, a
(nonnegative) randomness rate above $\inf_{Q_{\sf U}: D(Q_{\sf X}\|{{\pi}}_{\sf
X})\le E} \{D(Q_{\sf X}\|{{\pi}}_{\sf X})+I(Q_{\sf U},Q_{\sf X|U})-E\}$ is
necessary and sufficient to approximate the output distribution ${{\pi}}_{\sf
X}^{\otimes n}$ using the channel $Q_{\sf X|U}^{\otimes n}$, where $Q_{\sf
U}\to Q_{\sf X|U}\to Q_{\sf X}$. Moreover, by developing simple bounds relating
$E_{\gamma}$ and other distance measures, we are able to determine the exact
linear growth rate of the approximation errors measured in relative entropy and
smooth R\'{e}nyi divergences for a fixed-input randomness rate. The new
resolvability result is then used to derive 1) a one-shot upper bound on the
probability of excess distortion in lossy compression, which is exponentially
tight in the i.i.d.~setting, 2) a one-shot version of the mutual covering
lemma, and 3) a lower bound on the size of the eavesdropper list to include the
actual message and a lower bound on the eavesdropper false-alarm probability in
the wiretap channel problem, which is (asymptotically) ensemble-tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07837</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07837</id><created>2015-11-24</created><updated>2016-02-12</updated><authors><author><keyname>Lu</keyname><forenames>Zhaosong</forenames></author><author><keyname>Chen</keyname><forenames>Xiaojun</forenames></author></authors><title>Generalized Conjugate Gradient Methods for $\ell_1$ Regularized Convex
  Quadratic Programming with Finite Convergence</title><categories>math.OC cs.LG math.NA stat.CO stat.ML</categories><comments>36 pages, 2 tables</comments><msc-class>65C60, 65K05, 65Y20, 90C06, 90C20, 90C25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The conjugate gradient (CG) method is an efficient iterative method for
solving large-scale strongly convex quadratic programming (QP). In this paper
we propose some generalized CG (GCG) methods for solving the
$\ell_1$-regularized (possibly not strongly) convex QP that terminate at an
optimal solution in a finite number of iterations. At each iteration, our
methods first identify a face of an orthant and then either perform an exact
line search along the direction of the negative projected minimum-norm
subgradient of the objective function or execute a CG subroutine that conducts
a sequence of CG iterations until a CG iterate crosses the boundary of this
face or an approximate minimizer of over this face or a subface is found. We
determine which type of step should be taken by comparing the magnitude of some
components of the minimum-norm subgradient of the objective function to that of
its rest components. Our analysis on finite convergence of these methods makes
use of an error bound result and some key properties of the aforementioned
exact line search and the CG subroutine. We also show that the proposed methods
are capable of finding an approximate solution of the problem by allowing some
inexactness on the execution of the CG subroutine. The overall arithmetic
operation cost of our GCG methods for finding an $\epsilon$-optimal solution
depends on $\epsilon$ in $O(\log(1/\epsilon))$, which is superior to the
accelerated proximal gradient method [2,23] that depends on $\epsilon$ in
$O(1/\sqrt{\epsilon})$. In addition, our GCG methods can be extended
straightforwardly to solve box-constrained convex QP with finite convergence.
Numerical results demonstrate that our methods are very favorable for solving
ill-conditioned problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07838</identifier>
 <datestamp>2016-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07838</id><created>2015-11-24</created><updated>2016-02-09</updated><authors><author><keyname>Almahairi</keyname><forenames>Amjad</forenames></author><author><keyname>Ballas</keyname><forenames>Nicolas</forenames></author><author><keyname>Cooijmans</keyname><forenames>Tim</forenames></author><author><keyname>Zheng</keyname><forenames>Yin</forenames></author><author><keyname>Larochelle</keyname><forenames>Hugo</forenames></author><author><keyname>Courville</keyname><forenames>Aaron</forenames></author></authors><title>Dynamic Capacity Networks</title><categories>cs.LG cs.NE</categories><comments>ICML 2016 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the Dynamic Capacity Network (DCN), a neural network that can
adaptively assign its capacity across different portions of the input data.
This is achieved by combining modules of two types: low-capacity sub-networks
and high-capacity sub-networks. The low-capacity sub-networks are applied
across most of the input, but also provide a guide to select a few portions of
the input on which to apply the high-capacity sub-networks. The selection is
made using a novel gradient-based attention mechanism, that efficiently
identifies the modules and input features for which the DCN's output is most
sensitive and to which we should devote more capacity. We focus our empirical
evaluation on the cluttered MNIST and SVHN image datasets. Our findings
indicate that DCNs are able to drastically reduce the number of computations,
compared to traditional convolutional neural networks, while maintaining
similar performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07845</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07845</id><created>2015-11-24</created><updated>2015-11-24</updated><authors><author><keyname>Tulsiani</keyname><forenames>Shubham</forenames></author><author><keyname>Kar</keyname><forenames>Abhishek</forenames></author><author><keyname>Huang</keyname><forenames>Qixing</forenames></author><author><keyname>Carreira</keyname><forenames>Jo&#xe3;o</forenames></author><author><keyname>Malik</keyname><forenames>Jitendra</forenames></author></authors><title>Shape and Symmetry Induction for 3D Objects</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Actions as simple as grasping an object or navigating around it require a
rich understanding of that object's 3D shape from a given viewpoint. In this
paper we repurpose powerful learning machinery, originally developed for object
classification, to discover image cues relevant for recovering the 3D shape of
potentially unfamiliar objects. We cast the problem as one of local prediction
of surface normals and global detection of 3D reflection symmetry planes, which
open the door for extrapolating occluded surfaces from visible ones. We
demonstrate that our method is able to recover accurate 3D shape information
for classes of objects it was not trained on, in both synthetic and real
images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07846</identifier>
 <datestamp>2016-03-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07846</id><created>2015-11-24</created><updated>2016-03-06</updated><authors><author><keyname>Fegaras</keyname><forenames>Leonidas</forenames></author></authors><title>Incremental Query Processing on Big Data Streams</title><categories>cs.DB cs.DC</categories><comments>Extended version of a paper submitted to a journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses online query processing for large-scale, incremental
data analysis on a distributed stream processing engine (DSPE). Our goal is to
convert any SQL-like query to an incremental DSPE program automatically. In
contrast to other approaches, we derive incremental programs that return
accurate results, not approximate answers. This is accomplished by retaining a
minimal state during the query evaluation lifetime and by using incremental
evaluation techniques to return an accurate snapshot answer at each time
interval that depends on the current state and the latest batches of data. Our
methods can handle many forms of queries on nested data collections, including
iterative and nested queries, group-by with aggregation, and equi-joins.
Finally, we report on a prototype implementation of our framework, called MRQL
Streaming, running on top of Spark and we experimentally validate the
effectiveness of our methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07847</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07847</id><created>2015-11-24</created><updated>2015-11-25</updated><authors><author><keyname>Darmann</keyname><forenames>Andreas</forenames></author><author><keyname>Pferschy</keyname><forenames>Ulrich</forenames></author><author><keyname>Schauer</keyname><forenames>Joachim</forenames></author></authors><title>The Shortest Connection Game</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce Shortest Connection Game, a two-player game played on a directed
graph with edge costs. Given two designated vertices in which they start, the
players take turns in choosing edges emanating from the vertex they are
currently located at. In this way, each of the players forms a path that
origins from its respective starting vertex. The game ends as soon as the two
paths meet, i.e., a connection between the players is established. Each player
has to carry the cost of its chosen edges and thus aims at minimizing its own
total cost.
  In this work we analyze the computational complexity of Shortest Connection
Game. On the negative side, the game turns out to be computationally hard even
on restricted graph classes such as bipartite, acyclic and cactus graphs. On
the positive side, we can give a polynomial time algorithm for cactus graphs
when the game is restricted to simple paths.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07860</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07860</id><created>2015-11-24</created><authors><author><keyname>Kane</keyname><forenames>Daniel M.</forenames></author><author><keyname>Williams</keyname><forenames>Ryan</forenames></author></authors><title>Super-Linear Gate and Super-Quadratic Wire Lower Bounds for Depth-Two
  and Depth-Three Threshold Circuits</title><categories>cs.CC cs.NE</categories><msc-class>68Q17</msc-class><acm-class>C.1.3; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to formally understand the power of neural computing, we first need
to crack the frontier of threshold circuits with two and three layers, a regime
that has been surprisingly intractable to analyze. We prove the first
super-linear gate lower bounds and the first super-quadratic wire lower bounds
for depth-two linear threshold circuits with arbitrary weights, and depth-three
majority circuits computing an explicit function.
  $\bullet$ We prove that for all $\epsilon\gg \sqrt{\log(n)/n}$, the
linear-time computable Andreev's function cannot be computed on a
$(1/2+\epsilon)$-fraction of $n$-bit inputs by depth-two linear threshold
circuits of $o(\epsilon^3 n^{3/2}/\log^3 n)$ gates, nor can it be computed with
$o(\epsilon^{3} n^{5/2}/\log^{7/2} n)$ wires. This establishes an average-case
``size hierarchy'' for threshold circuits, as Andreev's function is computable
by uniform depth-two circuits of $o(n^3)$ linear threshold gates, and by
uniform depth-three circuits of $O(n)$ majority gates.
  $\bullet$ We present a new function in $P$ based on small-biased sets, which
we prove cannot be computed by a majority vote of depth-two linear threshold
circuits with $o(n^{3/2}/\log^3 n)$ gates, nor with $o(n^{5/2}/\log^{7/2}n)$
wires.
  $\bullet$ We give tight average-case (gate and wire) complexity results for
computing PARITY with depth-two threshold circuits; the answer turns out to be
the same as for depth-two majority circuits.
  The key is a new random restriction lemma for linear threshold functions. Our
main analytical tool is the Littlewood-Offord Lemma from additive
combinatorics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07865</identifier>
 <datestamp>2015-11-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07865</id><created>2015-11-24</created><authors><author><keyname>Komendantskaya</keyname><forenames>Ekaterina</forenames></author><author><keyname>Johann</keyname><forenames>Patricia</forenames></author></authors><title>Structural Resolution: a Framework for Coinductive Proof Search and
  Proof Construction in Horn Clause Logic</title><categories>cs.LO</categories><comments>Submitted</comments><acm-class>F.3.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logic programming (LP) is a programming language based on first-order Horn
clause logic that uses SLD-resolution as a semi-decision procedure. Finite
SLD-computations are inductively sound and complete with respect to least
Herbrand models of logic programs. Dually, the corecursive approach to
SLD-resolution views infinite SLD-computations as successively approximating
infinite terms contained in programs' greatest complete Herbrand models.
State-of-the-art algorithms implementing corecursion in LP are based on loop
detection. However, such algorithms support inference of logical entailment
only for rational terms, and they do not account for the important property of
productivity in infinite SLD-computations. Loop detection thus lags behind
coinductive methods in interactive theorem proving (ITP) and term-rewriting
systems (TRS).
  Structural resolution is a newly proposed alternative to SLD-resolution that
makes it possible to define and semi-decide a notion of productivity
appropriate to LP. In this paper we show that productivity supports the
development of a new coinductive proof principle for LP that semi-decides
logical entailment by observing finite fragments of resolution computations for
productive programs. This severs the dependence of coinductive proof on term
rationality, and puts coinductive methods in LP on par with productivity-based
observational approaches to coinduction in ITP and TRS. We prove soundness of
structural resolution relative to Herbrand model semantics for productive
inductive, coinductive, and mixed inductive-coinductive logic programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07888</identifier>
 <datestamp>2016-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07888</id><created>2015-11-24</created><updated>2016-02-02</updated><authors><author><keyname>Briat</keyname><forenames>Corentin</forenames></author><author><keyname>Khammash</keyname><forenames>Mustafa</forenames></author></authors><title>Interval peak-to-peak observers for continuous- and discrete-time
  systems with persistent inputs and delays</title><categories>math.OC cs.SY</categories><comments>10 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the design of optimal peak-to-peak controllers/observers for linear
systems is known to be a difficult problem, this problem becomes interestingly
much easier in the context of interval observers because of the positive nature
of the error dynamics. Indeed, by exploiting several recent results on positive
systems, we propose a novel and non-conservative approach formulated in terms
of tractable finite-dimensional linear programs for designing a class of
interval observers achieving minimum peak-to-peak gain. The optimal observer is
notably shown to be uniform over the set of all possible mappings between
observation errors and their weighted versions, which parallels a recent result
on the stabilization of linear positive systems. Results pertaining on the
interval observation of time-delay and discrete-time systems are then obtained
as a direct application of the proposed method, emphasizing then its
versatility. Several examples on the interval observation of linear and
nonlinear systems are finally given for illustration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07889</identifier>
 <datestamp>2015-12-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07889</id><created>2015-11-24</created><updated>2015-12-17</updated><authors><author><keyname>L&#xe9;onard</keyname><forenames>Nicholas</forenames></author><author><keyname>Waghmare</keyname><forenames>Sagar</forenames></author><author><keyname>Wang</keyname><forenames>Yang</forenames></author><author><keyname>Kim</keyname><forenames>Jin-Hwa</forenames></author></authors><title>rnn : Recurrent Library for Torch</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rnn package provides components for implementing a wide range of
Recurrent Neural Networks. It is built withing the framework of the Torch
distribution for use with the nn package. The components have evolved from 3
iterations, each adding to the flexibility and capability of the package. All
component modules inherit either the AbstractRecurrent or AbstractSequencer
classes. Strong unit testing, continued backwards compatibility and access to
supporting material are the principles followed during its development. The
package is compared against existing implementations of two published papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07893</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07893</id><created>2015-11-24</created><authors><author><keyname>Goering</keyname><forenames>Max</forenames></author><author><keyname>Sahneh</keyname><forenames>Faryad Darabi</forenames></author><author><keyname>Albin</keyname><forenames>Nathan</forenames></author><author><keyname>Scoglio</keyname><forenames>Caterina</forenames></author><author><keyname>Poggi-Corradini</keyname><forenames>Pietro</forenames></author></authors><title>Numerical Investigation of Metrics for Epidemic Processes on Graphs</title><categories>physics.soc-ph cs.SI math.PR</categories><comments>6 pages, 1 figure, 3 tables, In Proceedings of 2015 Asilomar
  Conference on Signals, Systems, and Computers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This study develops the epidemic hitting time (EHT) metric on graphs
measuring the expected time an epidemic starting at node $a$ in a fully
susceptible network takes to propagate and reach node $b$. An associated EHT
centrality measure is then compared to degree, betweenness, spectral, and
effective resistance centrality measures through exhaustive numerical
simulations on several real-world network data-sets. We find two surprising
observations: first, EHT centrality is highly correlated with effective
resistance centrality; second, the EHT centrality measure is much more
delocalized compared to degree and spectral centrality, highlighting the role
of peripheral nodes in epidemic spreading on graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07896</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07896</id><created>2015-11-24</created><authors><author><keyname>Karwa</keyname><forenames>Vishesh</forenames></author><author><keyname>Kifer</keyname><forenames>Dan</forenames></author><author><keyname>Slavkovi&#x107;</keyname><forenames>Aleksandra B.</forenames></author></authors><title>Private Posterior distributions from Variational approximations</title><categories>stat.ML cs.CR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy preserving mechanisms such as differential privacy inject additional
randomness in the form of noise in the data, beyond the sampling mechanism.
Ignoring this additional noise can lead to inaccurate and invalid inferences.
In this paper, we incorporate the privacy mechanism explicitly into the
likelihood function by treating the original data as missing, with an end goal
of estimating posterior distributions over model parameters. This leads to a
principled way of performing valid statistical inference using private data,
however, the corresponding likelihoods are intractable. In this paper, we
derive fast and accurate variational approximations to tackle such intractable
likelihoods that arise due to privacy. We focus on estimating posterior
distributions of parameters of the naive Bayes log-linear model, where the
sufficient statistics of this model are shared using a differentially private
interface. Using a simulation study, we show that the posterior approximations
outperform the naive method of ignoring the noise addition mechanism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07902</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07902</id><created>2015-11-24</created><authors><author><keyname>Ying</keyname><forenames>Bicheng</forenames></author><author><keyname>Sayed</keyname><forenames>Ali H.</forenames></author></authors><title>Performance Limits of Online Stochastic Sub-Gradient Learning</title><categories>stat.ML cs.LG cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work examines the performance of stochastic sub-gradient learning
strategies under weaker conditions than usually considered in the literature.
The conditions are shown to be automatically satisfied by several important
cases of interest including the construction of SVM, LASSO, and Total-Variation
denoising formulations. In comparison, these problems do not satisfy the
traditional assumptions and, therefore, conclusions derived based on these
earlier assumptions are not directly applicable to these problems. The analysis
establishes that stochastic sub-gradient strategies can attain exponential
convergence rates, as opposed to sub-linear rates. The analysis also
establishes that these strategies can approach the optimal solution within
$O(\mu)$, for sufficiently small step-sizes, where constant step-sizes are used
to enable continuous adaptation and learning. A realizable
exponential-weighting procedure is proposed to smooth the intermediate iterates
by the sub-gradient procedure and to guarantee the established performance
bounds in terms of convergence rate and mean-square-error performance. Both
single-agent and multi-agent scenarios are studied, where the latter case
assumes that a collection of agents are interconnected by a topology and can
only interact locally with their neighbors. The theoretical conclusions are
illustrated by several examples and simulations, including comparisons with the
FISTA procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07903</identifier>
 <datestamp>2015-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07903</id><created>2015-11-24</created><updated>2015-12-24</updated><authors><author><keyname>AlAmmouri</keyname><forenames>Ahmad</forenames></author><author><keyname>ElSawy</keyname><forenames>Hesham</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Flexible Design for $\alpha$-Duplex Communications in Multi-Tier
  Cellular Networks</title><categories>cs.IT math.IT math.ST stat.TH</categories><comments>Submitted to Tcom. arXiv admin note: substantial text overlap with
  arXiv:1511.00207</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Backward compatibility is an essential ingredient for the success of new
technologies. In the context of in-band full-duplex (FD) communication, FD base
stations (BSs) should support half-duplex (HD) UEs without sacrificing the
foreseen FD gains. This paper presents flexible and tractable modeling
framework for multi-tier cellular networks with FD-BSs and HD-UEs. The
presented model is based on stochastic geometry and accounts for the intrinsic
vulnerability of uplink transmissions. To this end, we propose location-aware
and fine-grained duplexing design, which allows partial overlap between uplink
and downlink spectrum, to maximize the network transmission rate. The results
show that FD-UEs are not necessarily required to harvest rate gains from
FD-BSs. In particular, the results show that adding FD-UEs to FD-BSs offers a
maximum of 8% rate gain over FD-BSs and HD-UEs case, which is a marginal gain
compared to the burden required to implement FD transceivers at the UEs' side.
To this end, we shed light on practical scenarios where HD-UEs operation with
FD-BSs outperforms the operation when both the BSs and UEs are FD. Finally, we
propose a location dependent mixed FD/HD strategy for the UEs that efficiently
operates FD cellular networks when the UEs' FD receivers have different
efficiencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07907</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07907</id><created>2015-11-24</created><updated>2015-11-27</updated><authors><author><keyname>Yuan</keyname><forenames>Wei</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Zhang</keyname><forenames>Ying Jun</forenames></author></authors><title>Competitive Charging Station Pricing for Plug-in Electric Vehicles</title><categories>cs.GT cs.SY math.OC</categories><comments>15 pages, 21 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of charging station pricing and plug-in
electric vehicles (PEVs) station selection. When a PEV needs to be charged, it
selects a charging station by considering the charging prices, waiting times,
and travel distances. Each charging station optimizes its charging price based
on the prediction of the PEVs' charging station selection decisions and the
other station's pricing decision, in order to maximize its profit. To obtain
insights of such a highly coupled system, we consider a one-dimensional system
with two competing charging stations and Poisson arriving PEVs. We propose a
multi-leader-multi-follower Stackelberg game model, in which the charging
stations (leaders) announce their charging prices in Stage I, and the PEVs
(followers) make their charging station selections in Stage II. We show that
there always exists a unique charging station selection equilibrium in Stage
II, and such equilibrium depends on the charging stations' service capacities
and the price difference between them. We then characterize the sufficient
conditions for the existence and uniqueness of the pricing equilibrium in Stage
I. We also develop a low complexity algorithm that efficiently computes the
pricing equilibrium and the subgame perfect equilibrium of the two-stage
Stackelberg game.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07910</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07910</id><created>2015-11-24</created><authors><author><keyname>RezazadehReyhani</keyname><forenames>Ahmad</forenames></author><author><keyname>Farhang-Boroujeny</keyname><forenames>Behrouz</forenames></author></authors><title>Asynchronous Performance of Circularly Pulse-Shaped Waveforms for 5G</title><categories>cs.IT math.IT</categories><comments>6 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fifth generation of wireless networks (5G) necessitates the use of
waveforms with loose constraints on synchronization in multiuser scenarios.
Also, carrier aggregation, as a way to better utilize the spectrum in 5G, needs
a waveform with low out-of-band (OOB) emission. Generalized frequency division
multiplexing (GFDM) and circular filter bank multicarrier (C-FBMC) are two
candidate waveforms that fulfill these requirements. Both GFDM and C-FBMC
operate based on circular convolution, and use cyclic prefix to combat channel
response. In this paper, we develop an analytical technique for examining the
OOB emission and multiuser interference (MUI) in circularly shaped waveforms,
like GFDM and C-FBMC. To stay focused, the study in this paper is limited to
C-FBMC modulation. However, the approach we take is trivially extendable to
other waveforms as well. We derive equations that quantify OOB emission and
MUI. Our analysis allows us to identify the source of OOB emission and MUI.
This leads us to quantify the methods proposed by other researchers to decrease
OOB emission and MUI. Moreover, we quantify the impact of signal windowing at
the transmitter and receiver in reducing OOB emission and MUI, respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07915</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07915</id><created>2015-11-24</created><authors><author><keyname>Whiting</keyname><forenames>James G. H.</forenames></author><author><keyname>Mayne</keyname><forenames>Richard</forenames></author><author><keyname>Moody</keyname><forenames>Nadine</forenames></author><author><keyname>Costello</keyname><forenames>Ben de Lacy</forenames></author><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Practical circuits with Physarum Wires</title><categories>cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Purpose: Protoplasmic tubes of Physarum polycephalum, also know as Physarum
Wires (PW), have been previously suggested as novel bio- electronic components.
Until recently, practical examples of electronic circuits using PWs have been
limited. These PWs have been shown to be self repairing, offering significant
advantage over traditional electronic components. This article documents work
performed to produce practical circuits using PWs. Method: We have demonstrated
through manufacture and testing of hybrid circuits that PWs can be used to
produce a variety of practical electronic circuits. A purality of different
applications of PWs have been tested to show the universality of PWs in
analogue and digital electronics. Results: Voltage dividers can be produced
using a pair of PWs in series with an output voltage accurate to within 12%.
PWs can also transmit analogue and digital data with a frequency of up to 19
kHz, which with the addition of a buffer, can drive high current circuits. We
have demonstrated that PWs can last approximately two months, a 4 fold increase
on previous literature. Protoplasmic tubes can be modified with the addition of
conductive or magnetic nano-particles to provide changes in functionality.
Conclusion This work has documented novel macro-scale data transmission through
biological material; it has advanced the field of bio-electronics by providing
a cheap and easy to grow conducting bio-material which may be used in future
hybrid electronic technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07916</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07916</id><created>2015-11-24</created><authors><author><keyname>Cho</keyname><forenames>Kyunghyun</forenames></author></authors><title>Natural Language Understanding with Distributed Representation</title><categories>cs.CL stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a lecture note for the course DS-GA 3001 &lt;Natural Language
Understanding with Distributed Representation&gt; at the Center for Data Science ,
New York University in Fall, 2015. As the name of the course suggests, this
lecture note introduces readers to a neural network based approach to natural
language understanding/processing. In order to make it as self-contained as
possible, I spend much time on describing basics of machine learning and neural
networks, only after which how they are used for natural languages is
introduced. On the language front, I almost solely focus on language modelling
and machine translation, two of which I personally find most fascinating and
most fundamental to natural language understanding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07917</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07917</id><created>2015-11-24</created><authors><author><keyname>Vu</keyname><forenames>Tuan-Hung</forenames></author><author><keyname>Osokin</keyname><forenames>Anton</forenames></author><author><keyname>Laptev</keyname><forenames>Ivan</forenames></author></authors><title>Context-aware CNNs for person head detection</title><categories>cs.CV cs.LG</categories><comments>To appear in International Conference on Computer Vision (ICCV), 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Person detection is a key problem for many computer vision tasks. While face
detection has reached maturity, detecting people under a full variation of
camera view-points, human poses, lighting conditions and occlusions is still a
difficult challenge. In this work we focus on detecting human heads in natural
scenes. Starting from the recent local R-CNN object detector, we extend it with
two types of contextual cues. First, we leverage person-scene relations and
propose a Global CNN model trained to predict positions and scales of heads
directly from the full image. Second, we explicitly model pairwise relations
among objects and train a Pairwise CNN model using a structured-output
surrogate loss. The Local, Global and Pairwise models are combined into a joint
CNN framework. To train and test our full model, we introduce a large dataset
composed of 369,846 human heads annotated in 224,740 movie frames. We evaluate
our method and demonstrate improvements of person head detection against
several recent baselines in three datasets. We also show improvements of the
detection speed provided by our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07922</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07922</id><created>2015-11-24</created><updated>2016-01-28</updated><authors><author><keyname>Zhang</keyname><forenames>Yi</forenames></author></authors><title>Contraction of Ore Ideals with Applications</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ore operators form a common algebraic abstraction of linear ordinary
differential and recurrence equations. Given an Ore operator $L$ with
polynomial coefficients in $x$, it generates a left ideal $I$ in the Ore
algebra over the field $\mathbf{k}(x)$ of rational functions. We present an
algorithm for computing a basis of the contraction ideal of $I$ in the Ore
algebra over the ring $R[x]$ of polynomials, where $R$ may be either
$\mathbf{k}$ or a domain with $\mathbf{k}$ as its fraction field. This
algorithm is based on recent work on desingularization for Ore operators by
Chen, Jaroschek, Kauers and Singer. Using a basis of the contraction ideal, we
compute a completely desingularized operator for $L$ whose leading coefficient
not only has minimal degree in $x$ but also has minimal content. Completely
desingularized operators have interesting applications such as certifying
integer sequences and checking special cases of a conjecture of Krattenthaler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07927</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07927</id><created>2015-11-24</created><authors><author><keyname>Sun</keyname><forenames>Hong</forenames></author><author><keyname>Sang</keyname><forenames>Cheng-Wei</forenames></author><author><keyname>Liu</keyname><forenames>Chen-Guang</forenames></author></authors><title>Principal Basis Analysis in Sparse Representation</title><categories>cs.CV</categories><comments>The text propose a Principal Basis Analysis in Sparse Representation
  and apply the principal basis analysis to image denoising corrupted by
  Gaussian and non-Gaussian noises, showing better performances than some
  reference methods at suppressing strong noise and at preserving signal
  details;including 8 pages, 4 figures prepared using pdf according to the
  instructions to Authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces a new signal analysis method, which can be
interpreted as a principal component analysis in sparse decomposition of the
signal. The method, called principal basis analysis, is based on a novel
criterion: reproducibility of component which is an intrinsic characteristic of
regularity in natural signals. We show how to measure reproducibility. Then we
present the principal basis analysis method, which chooses, in a sparse
representation of the signal, the components optimizing the reproducibility
degree to build the so-called principal basis. With this principal basis, we
show that the underlying signal pattern could be effectively extracted from
corrupted data. As illustration, we apply the principal basis analysis to image
denoising corrupted by Gaussian and non-Gaussian noises, showing better
performances than some reference methods at suppressing strong noise and at
preserving signal details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07932</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07932</id><created>2015-11-24</created><authors><author><keyname>Ji</keyname><forenames>Weixing</forenames></author><author><keyname>Liu</keyname><forenames>Qinghui</forenames></author><author><keyname>Wang</keyname><forenames>Guizhen</forenames></author><author><keyname>Shen</keyname><forenames>ZhuoJia</forenames></author></authors><title>Embedding of Hypercube into Cylinder</title><categories>cs.GR</categories><comments>11 pages, 2 figures</comments><acm-class>G.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Task mapping in modern high performance parallel computers can be modeled as
a graph embedding problem, which simulates the mapping as embedding one graph
into another and try to find the minimum wirelength for the mapping. Though
embedding problems have been considered for several regular graphs, such as
hypercubes into grids, binary trees into grids, et al, it is still an open
problem for hypercubes into cylinders. In this paper, we consider the problem
of embedding hypercubes into cylinders to minimize the wirelength. We obtain
the exact wirelength formula of embedding hypercube $Q^r$ into cylinder
$C_{2^3}\times P_{2^{r-3}}$ with $r\ge3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07938</identifier>
 <datestamp>2016-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07938</id><created>2015-11-24</created><updated>2016-01-19</updated><authors><author><keyname>Razavian</keyname><forenames>Narges</forenames></author><author><keyname>Sontag</keyname><forenames>David</forenames></author></authors><title>Temporal Convolutional Neural Networks for Diagnosis from Lab Tests</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Early diagnosis of treatable diseases is essential for improving healthcare,
and many diseases' onsets are predictable from annual lab tests and their
temporal trends. We introduce a multi-resolution convolutional neural network
for early detection of multiple diseases from irregularly measured sparse lab
values. Our novel architecture takes as input both an imputed version of the
data and a binary observation matrix. For imputing the temporal sparse
observations, we develop a flexible, fast to train method for differentiable
multivariate kernel regression. Our experiments on data from 298K individuals
over 8 years, 18 common lab measurements, and 171 diseases show that the
temporal signatures learned via convolution are significantly more predictive
than baselines commonly used for early disease diagnosis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07940</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07940</id><created>2015-11-24</created><authors><author><keyname>Wang</keyname><forenames>Li</forenames></author><author><keyname>Liu</keyname><forenames>Ting</forenames></author><author><keyname>Wang</keyname><forenames>Gang</forenames></author><author><keyname>Chan</keyname><forenames>Kap Luk</forenames></author><author><keyname>Yang</keyname><forenames>Qingxiong</forenames></author></authors><title>Video Tracking Using Learned Hierarchical Features</title><categories>cs.CV</categories><comments>12 pages, 7 figures</comments><journal-ref>IEEE Transactions on Image Processing, vol. 24, no. 4, April 2015</journal-ref><doi>10.1109/TIP.2015.2403231</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an approach to learn hierarchical features for
visual object tracking. First, we offline learn features robust to diverse
motion patterns from auxiliary video sequences. The hierarchical features are
learned via a two-layer convolutional neural network. Embedding the temporal
slowness constraint in the stacked architecture makes the learned features
robust to complicated motion transformations, which is important for visual
object tracking. Then, given a target video sequence, we propose a domain
adaptation module to online adapt the pre-learned features according to the
specific target object. The adaptation is conducted in both layers of the deep
feature learning module so as to include appearance information of the specific
target object. As a result, the learned hierarchical features can be robust to
both complicated motion transformations and appearance changes of target
objects. We integrate our feature learning algorithm into three tracking
methods. Experimental results demonstrate that significant improvement can be
achieved using our learned hierarchical features, especially on video sequences
with complicated motion transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07948</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07948</id><created>2015-11-24</created><authors><author><keyname>Zhang</keyname><forenames>Yuchen</forenames></author><author><keyname>Lee</keyname><forenames>Jason D.</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author><author><keyname>Jordan</keyname><forenames>Michael I.</forenames></author></authors><title>Learning Halfspaces and Neural Networks with Random Initialization</title><categories>cs.LG</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study non-convex empirical risk minimization for learning halfspaces and
neural networks. For loss functions that are $L$-Lipschitz continuous, we
present algorithms to learn halfspaces and multi-layer neural networks that
achieve arbitrarily small excess risk $\epsilon&gt;0$. The time complexity is
polynomial in the input dimension $d$ and the sample size $n$, but exponential
in the quantity $(L/\epsilon^2)\log(L/\epsilon)$. These algorithms run multiple
rounds of random initialization followed by arbitrary optimization steps. We
further show that if the data is separable by some neural network with constant
margin $\gamma&gt;0$, then there is a polynomial-time algorithm for learning a
neural network that separates the training data with margin $\Omega(\gamma)$.
As a consequence, the algorithm achieves arbitrary generalization error
$\epsilon&gt;0$ with ${\rm poly}(d,1/\epsilon)$ sample and time complexity. We
establish the same learnability result when the labels are randomly flipped
with probability $\eta&lt;1/2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07949</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07949</id><created>2015-11-25</created><authors><author><keyname>Prabhakaran</keyname><forenames>Manoj M.</forenames></author><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author></authors><title>R\'enyi Information Complexity and an Information Theoretic
  Characterization of the Partition Bound</title><categories>cs.CC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new information-theoretic complexity measure $IC_\infty$ for
2-party functions which is a lower-bound on communication complexity, and has
the two leading lower-bounds on communication complexity as its natural
relaxations: (external) information complexity ($IC$) and logarithm of
partition complexity ($\text{prt}$) which have so far appeared conceptually
quite different from each other. $IC_\infty$ is an external information
complexity based on R\'enyi mutual information of order infinity. In the
definition of $IC_\infty$, relaxing the order of R\'enyi mutual information
from infinity to 1 yields $IC$, while $\log \text{prt}$ is obtained by
replacing protocol transcripts with what we term &quot;pseudotranscripts,&quot; which
omits the interactive nature of a protocol, but only requires that the
probability of any transcript given the inputs $x$ and $y$ to the two parties,
factorizes into two terms which depend on $x$ and $y$ separately. Further
understanding $IC_\infty$ might have consequences for important direct-sum
problems in communication complexity, as it lies between communication
complexity and information complexity.
  We also show that applying both the above relaxations simultaneously to
$IC_\infty$ gives a complexity measure that is lower-bounded by the (log of)
relaxed partition complexity, a complexity measure introduced by Kerenidis et
al. (FOCS 2012). We obtain a sharper connection between (external) information
complexity and relaxed partition complexity than Kerenidis et al., using an
arguably more direct proof.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07951</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07951</id><created>2015-11-25</created><authors><author><keyname>Premachandran</keyname><forenames>Vittal</forenames></author><author><keyname>Bonev</keyname><forenames>Boyan</forenames></author><author><keyname>Yuille</keyname><forenames>Alan L.</forenames></author></authors><title>PASCAL Boundaries: A Class-Agnostic Semantic Boundary Dataset</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the boundary detection task motivated by the
ambiguities in current definition of edge detection. To this end, we generate a
large database consisting of more than 10k images (which is 20x bigger than
existing edge detection databases) along with ground truth boundaries between
459 semantic classes including both foreground objects and different types of
background, and call it the PASCAL Boundaries dataset, which will be released
to the community. In addition, we propose a novel deep network-based
multi-scale semantic boundary detector and name it Multi-scale Deep Semantic
Boundary Detector (M-DSBD). We provide baselines using models that were trained
on edge detection and show that they transfer reasonably to the task of
boundary detection. Finally, we point to various important research problems
that this dataset can be used for.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07953</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07953</id><created>2015-11-25</created><authors><author><keyname>Garg</keyname><forenames>Amit</forenames></author><author><keyname>Noyola</keyname><forenames>Jonathan</forenames></author><author><keyname>Verma</keyname><forenames>Romil</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author><author><keyname>Jami</keyname><forenames>Aditya</forenames></author></authors><title>Exploring Correlation between Labels to improve Multi-Label
  Classification</title><categories>cs.LG cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper attempts multi-label classification by extending the idea of
independent binary classification models for each output label, and exploring
how the inherent correlation between output labels can be used to improve
predictions. Logistic Regression, Naive Bayes, Random Forest, and SVM models
were constructed, with SVM giving the best results: an improvement of 12.9\%
over binary models was achieved for hold out cross validation by augmenting
with pairwise correlation probabilities of the labels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07961</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07961</id><created>2015-11-25</created><authors><author><keyname>He</keyname><forenames>Jiazhen</forenames></author><author><keyname>Rubinstein</keyname><forenames>Benjamin I. P.</forenames></author><author><keyname>Bailey</keyname><forenames>James</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Milligan</keyname><forenames>Sandra</forenames></author><author><keyname>Chan</keyname><forenames>Jeffrey</forenames></author></authors><title>MOOCs Meet Measurement Theory: A Topic-Modelling Approach</title><categories>cs.LG cs.CY</categories><comments>12 pages, 9 figures; accepted into AAAI'2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper adapts topic models to the psychometric testing of MOOC students
based on their online forum postings. Measurement theory from education and
psychology provides statistical models for quantifying a person's attainment of
intangible attributes such as attitudes, abilities or intelligence. Such models
infer latent skill levels by relating them to individuals' observed responses
on a series of items such as quiz questions. The set of items can be used to
measure a latent skill if individuals' responses on them conform to a Guttman
scale. Such well-scaled items differentiate between individuals and inferred
levels span the entire range from most basic to the advanced. In practice,
education researchers manually devise items (quiz questions) while optimising
well-scaled conformance. Due to the costly nature and expert requirements of
this process, psychometric testing has found limited use in everyday teaching.
We aim to develop usable measurement models for highly-instrumented MOOC
delivery platforms, by using participation in automatically-extracted online
forum topics as items. The challenge is to formalise the Guttman scale
educational constraint and incorporate it into topic models. To favour topics
that automatically conform to a Guttman scale, we introduce a novel
regularisation into non-negative matrix factorisation-based topic modelling. We
demonstrate the suitability of our approach with both quantitative experiments
on three Coursera MOOCs, and with a qualitative survey of topic
interpretability on two MOOCs by domain expert interviews.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07962</identifier>
 <datestamp>2016-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07962</id><created>2015-11-25</created><authors><author><keyname>Schossau</keyname><forenames>Jory</forenames></author><author><keyname>Adami</keyname><forenames>Christoph</forenames></author><author><keyname>Hintze</keyname><forenames>Arend</forenames></author></authors><title>Information-theoretic neuro-correlates boost evolution of cognitive
  systems</title><categories>q-bio.NC cs.IT math.IT nlin.AO q-bio.PE</categories><comments>26 pages, 6 figures plus 3 Suppl. figures (included). To appear in
  special issue &quot;Information Theoretic Incentives for Cognitive Systems&quot; of
  journal &quot;Entropy&quot;</comments><journal-ref>Entropy 18 (2016) 6</journal-ref><doi>10.3390/e18010006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genetic Algorithms (GA) are a powerful set of tools for search and
optimization that mimic the process of natural selection, and have been used
successfully in a wide variety of problems, including evolving neural networks
to solve cognitive tasks. Despite their success, GAs sometimes fail to locate
the highest peaks of the fitness landscape, in particular if the landscape is
rugged and contains multiple peaks. Reaching distant and higher peaks is
difficult because valleys need to be crossed, in a process that (at least
temporarily) runs against the fitness maximization objective. Here we propose
and test a number of information-theoretic (as well as network-based) measures
that can be used in conjunction with a fitness maximization objective
(so-called ``neuro-correlates&quot;) to evolve neural controllers for two widely
different tasks: a behavioral task that requires information integration, and a
cognitive task that requires memory and logic. We find that judiciously chosen
neuro-correlates can significantly aid GAs to find the highest peaks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07963</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07963</id><created>2015-11-25</created><authors><author><keyname>Legchekova</keyname><forenames>Elena</forenames></author><author><keyname>Titov</keyname><forenames>Oleg</forenames></author></authors><title>Calculate distance to object in the area where car, using video analysis</title><categories>cs.CV</categories><comments>5 pages, in Russian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The method of using video cameras installed on the car, to calculate the
distance to the object in its area of movement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07972</identifier>
 <datestamp>2016-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07972</id><created>2015-11-25</created><updated>2016-01-25</updated><authors><author><keyname>Tresp</keyname><forenames>Volker</forenames></author><author><keyname>Esteban</keyname><forenames>Crist&#xf3;bal</forenames></author><author><keyname>Yang</keyname><forenames>Yinchong</forenames></author><author><keyname>Baier</keyname><forenames>Stephan</forenames></author><author><keyname>Krompa&#xdf;</keyname><forenames>Denis</forenames></author></authors><title>Learning with Memory Embeddings</title><categories>cs.AI cs.CL cs.LG</categories><comments>14 pages, NIPS 2015 Workshop on Nonparametric Methods for Large Scale
  Representation Learning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Embedding learning, a.k.a. representation learning, has been shown to be able
to model large-scale semantic knowledge graphs. A key concept is a mapping of
the knowledge graph to a tensor representation whose entries are predicted by
models using latent representations of generalized entities. Latent variable
models are well suited to deal with the high dimensionality and sparsity of
typical knowledge graphs. In recent publications the embedding models were
extended to also consider temporal evolutions, temporal patterns and
subsymbolic representations. In this paper we map embedding models to various
cognitive memory functions. We postulate several hypotheses. A first hypothesis
that arises out off this work is that mutual information exchange can be
achieved by a sharing or a coupling of distributed latent representations of
entities across different memory functions (unique-representation hypothesis).
Secondly, the sequential sampling hypothesis states that retrieval and question
answering is achieved by a sequentially sampling of latent representations of
entities. Thirdly, the functional memory hypothesis states that memory
operations are implemented as functions on the latent representations. A fourth
hypothesis is that a latent representation for time t, which captures all
events that are happening at time t, is a bridge between sensory input and
episodic memory (temporal-representation hypothesis). A fifth hypothesis is
that the decoding of sensory input is constrained in that it must lead to a
semantic explanation for the sensory data (emerging semantics hypothesis).
Sixth, the attention hypothesis states that only sensory information that is
novel is stored in episodic memory. Finally, the semantic-attractor learning
hypothesis can be the basis for learning in cognitive memory systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07983</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07983</id><created>2015-11-25</created><authors><author><keyname>Li</keyname><forenames>Teng</forenames></author><author><keyname>Narayana</keyname><forenames>Vikram K.</forenames></author><author><keyname>El-Ghazawi</keyname><forenames>Tarek</forenames></author></authors><title>Reordering GPU Kernel Launches to Enable Efficient Concurrent Execution</title><categories>cs.DC cs.DS</categories><comments>2 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Contemporary GPUs allow concurrent execution of small computational kernels
in order to prevent idling of GPU resources. Despite the potential concurrency
between independent kernels, the order in which kernels are issued to the GPU
will significantly influence the application performance. A technique for
deriving suitable kernel launch orders is therefore presented, with the aim of
reducing the total execution time. Experimental results indicate that the
proposed method yields solutions that are well above the 90 percentile mark in
the design space of all possible permutations of the kernel launch sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.07992</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.07992</id><created>2015-11-25</created><authors><author><keyname>Feng</keyname><forenames>Keqin</forenames></author><author><keyname>Jin</keyname><forenames>Lingfei</forenames></author><author><keyname>Xing</keyname><forenames>Chaoping</forenames></author><author><keyname>Yuan</keyname><forenames>Chen</forenames></author></authors><title>Multipartite entangled states, symmetric matrices and error-correcting
  codes</title><categories>cs.IT math.IT quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A pure quantum state is called $k$-uniform if all its reductions to $k$-qudit
are maximally mixed. We investigate the general constructions of $k$-uniform
pure quantum states of $n$ subsystems with $d$ levels. We provide one
construction via symmetric matrices and the second one through classical
error-correcting codes. There are three main results arising from our
constructions. Firstly, we show that for any given even $n\ge 2$, there always
exists an $n/2$-uniform $n$-qudit quantum state of level $p$ for sufficiently
large prime $p$. Secondly, both constructions show that their exist $k$-uniform
$n$-qudit pure quantum states such that $k$ is proportional to $n$, i.e.,
$k=\Omega(n)$ although the construction from symmetric matrices outperforms the
one by error-correcting codes. Thirdly, our symmetric matrix construction
provides a positive answer to the open question in \cite{DA} on whether there
exists $3$-uniform $n$-qudit pure quantum state for all $n\ge 8$. In fact, we
can further prove that, for every $k$, there exists a constant $M_k$ such that
there exists a $k$-uniform $n$-qudit quantum state for all $n\ge M_k$. In
addition, by using concatenation of algebraic geometry codes, we give an
explicit construction of $k$-uniform quantum state when $k$ tends to infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08020</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08020</id><created>2015-11-25</created><authors><author><keyname>Naghibi</keyname><forenames>Farshad</forenames></author><author><keyname>Oechtering</keyname><forenames>Tobias J.</forenames></author><author><keyname>Skoglund</keyname><forenames>Mikael</forenames></author></authors><title>Authentication With a Guessing Adversary</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure, revised IEEE WIFS 2015 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the authentication problem where a candidate
measurement presented by an unidentified user is compared to a previously
stored measurement of the legitimate user, the enrollment, with respect to a
certain distortion criteria for authentication. An adversary wishes to
impersonate the legitimate user by guessing the enrollment until the system
authenticates him. For this setting, we study the minimum number of required
guesses (on average) by the adversary for a successful impersonation attack and
find the complete characterization of the asymptotic exponent of this metric,
referred to as the deception exponent. Our result is a direct application of
the results of the Guessing problem by Arikan and Merhav [19]. Paralleling the
work in [19] we also extend this result to the case where the adversary may
have access to additional side information correlated to the enrollment data.
The paper is a revised version of a submission to IEEE WIFS 2015, with the
referencing to the paper [19] clarified compared with the conference version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08032</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08032</id><created>2015-11-25</created><authors><author><keyname>Tzelepis</keyname><forenames>Christos</forenames></author><author><keyname>Galanopoulos</keyname><forenames>Damianos</forenames></author><author><keyname>Mezaris</keyname><forenames>Vasileios</forenames></author><author><keyname>Patras</keyname><forenames>Ioannis</forenames></author></authors><title>Learning to detect video events from zero or very few video examples</title><categories>cs.LG cs.CV</categories><comments>Image and Vision Computing Journal, Elsevier, 2015, accepted for
  publication</comments><journal-ref>Image and Vision Computing Journal, Elsevier, 2015</journal-ref><doi>10.1016/j.imavis.2015.09.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we deal with the problem of high-level event detection in video.
Specifically, we study the challenging problems of i) learning to detect video
events from solely a textual description of the event, without using any
positive video examples, and ii) additionally exploiting very few positive
training samples together with a small number of ``related'' videos. For
learning only from an event's textual description, we first identify a general
learning framework and then study the impact of different design choices for
various stages of this framework. For additionally learning from example
videos, when true positive training samples are scarce, we employ an extension
of the Support Vector Machine that allows us to exploit ``related'' event
videos by automatically introducing different weights for subsets of the videos
in the overall training set. Experimental evaluations performed on the
large-scale TRECVID MED 2014 video dataset provide insight on the effectiveness
of the proposed methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08049</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08049</id><created>2015-11-25</created><authors><author><keyname>Keshishzadeh</keyname><forenames>Sarmen</forenames></author><author><keyname>Mooij</keyname><forenames>Arjan J.</forenames></author><author><keyname>Hooman</keyname><forenames>Jozef</forenames></author></authors><title>Industrial Experiences with a Formal DSL Semantics to Check Correctness
  of DSL Transformations</title><categories>cs.SE cs.LO cs.PL</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  A domain specific language (DSL) abstracts from implementation details and is
aligned with the way domain experts reason about a software component. The
development of DSLs is usually centered around a grammar and transformations
that generate implementation code or analysis models. The semantics of the
language is often defined implicitly and in terms of a transformation to
implementation code. In the presence of multiple transformations from the DSL,
the consistency of the generated artifacts with respect to the semantics of the
DSL is a relevant issue. We show that a formal semantics is essential for
checking the consistency between the generated artifacts. We exploit the formal
semantics in an industrial project and use formal techniques based on
equivalence checking and model-based testing for consistency checking. We
report about our experience with this approach in an industrial development
project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08054</identifier>
 <datestamp>2016-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08054</id><created>2015-11-25</created><updated>2016-03-07</updated><authors><author><keyname>Fiorini</keyname><forenames>Samuel</forenames></author><author><keyname>Huynh</keyname><forenames>Tony</forenames></author><author><keyname>Joret</keyname><forenames>Gwena&#xeb;l</forenames></author><author><keyname>Varvitsiotis</keyname><forenames>Antonios</forenames></author></authors><title>The excluded minors for isometric realizability in the plane</title><categories>math.MG cs.DM math.CO</categories><comments>14 pages, 5 figures</comments><msc-class>05C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G$ be a graph and $p \in [1, \infty]$. The parameter $f_p(G)$ is the
least integer $k$ such that for all $m$ and all vectors $(r_v)_{v \in V(G)}
\subseteq \mathbb{R}^m$, there exist vectors $(q_v)_{v \in V(G)} \subseteq
\mathbb{R}^k$ satisfying $$\|r_v-r_w\|_p=\|q_v-q_w\|_p, \ \text{ for all }\
vw\in E(G).$$ It is easy to check that $f_p(G)$ is always finite and that it is
minor monotone. By the graph minor theorem of Robertson and Seymour, there are
a finite number of excluded minors for the property $f_p(G) \leq k$.
  In this paper, we determine the complete set of excluded minors for
$f_\infty(G) \leq 2$. The two excluded minors are the wheel on $5$ vertices and
the graph obtained by gluing two copies of $K_4$ along an edge and then
deleting that edge. Due to an isometry between the corresponding metric spaces,
this also characterizes the graphs $G$ with $f_1(G) \leq 2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08058</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08058</id><created>2015-11-25</created><authors><author><keyname>Cao</keyname><forenames>Jiale</forenames></author><author><keyname>Pang</keyname><forenames>Yanwei</forenames></author><author><keyname>Li</keyname><forenames>Xuelong</forenames></author></authors><title>Pedestrian Detection Inspired by Appearance Constancy and Shape Symmetry</title><categories>cs.CV</categories><comments>9 pages,17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discrimination and simplicity of features are very important for
effective and efficient pedestrian detection. However, most state-of-the-art
methods are unable to achieve good tradeoff between accuracy and efficiency.
Inspired by some simple inherent attributes of pedestrians (i.e., appearance
constancy and shape symmetry), we propose two new types of non-neighboring
features (NNF): side-inner difference features (SIDF) and symmetrical
similarity features (SSF). SIDF can characterize the difference between the
background and pedestrian and the difference between the pedestrian contour and
its inner part. SSF can capture the symmetrical similarity of pedestrian shape.
However, it's difficult for neighboring features to have such above
characterization abilities. Finally, we propose to combine both non-neighboring
and neighboring features for pedestrian detection. It's found that
non-neighboring features can further decrease the average miss rate by 4.44%.
Experimental results on INRIA and Caltech pedestrian datasets demonstrate the
effectiveness and efficiency of the proposed method. Compared to the
state-of-the-art methods without using CNN, our method achieves the best
detection performance on Caltech, outperforming the second best method (i.e.,
Checkboards) by 1.63%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08060</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08060</id><created>2015-11-25</created><authors><author><keyname>Hughes</keyname><forenames>David. P.</forenames></author><author><keyname>Salathe</keyname><forenames>Marcel</forenames></author></authors><title>An open access repository of images on plant health to enable the
  development of mobile disease diagnostics through machine learning and
  crowdsourcing</title><categories>cs.CY</categories><comments>11, 1 Figure, 1 table</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  Human society needs to increase food production by an estimated 70% by 2050
to feed an expected population size that is predicted to be over 9 billion
people. Currently infectious diseases reduce the potential yield by an average
of 40% with many farmers in the developing world experiencing yield losses as
high as 100%. Infectious diseases of crops are not new and historic examples
such as the Irish Potato Famine of 1845-49 demonstrate this. But what is new is
the widespread distribution of smartphones among crop growers around the world
with an expected 5 billion smartphones by 2020. This offers the potential of
turning the smartphone into a valuable tool for diverse communities growing
food. One potential application is the development of mobile disease
diagnostics through machine learning and crowdsourcing. Computer vision and
machine learning have shown their potential to automatically classify images.
To do this for plant diseases requires a training set that facilitates the
development of the algorithms. Here we announce the release of &gt;50,000 expertly
curated images on healthy and infected leaves of crops plants through the
existing platform www.PlantVillage.org. We describe both the data and the
platform. These data are the beginning of an on-going, crowdsourcing effort to
enable computer vision approaches to help solve the problem of yield losses in
crop plants due to infectious diseases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08062</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08062</id><created>2015-11-25</created><authors><author><keyname>Xu</keyname><forenames>Chen</forenames></author><author><keyname>Lin</keyname><forenames>Zhouchen</forenames></author><author><keyname>Zhao</keyname><forenames>Zhenyu</forenames></author><author><keyname>Zha</keyname><forenames>Hongbin</forenames></author></authors><title>Relaxed Majorization-Minimization for Non-smooth and Non-convex
  Optimization</title><categories>math.OC cs.LG cs.NA</categories><comments>AAAI16</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new majorization-minimization (MM) method for non-smooth and
non-convex programs, which is general enough to include the existing MM
methods. Besides the local majorization condition, we only require that the
difference between the directional derivatives of the objective function and
its surrogate function vanishes when the number of iterations approaches
infinity, which is a very weak condition. So our method can use a surrogate
function that directly approximates the non-smooth objective function. In
comparison, all the existing MM methods construct the surrogate function by
approximating the smooth component of the objective function. We apply our
relaxed MM methods to the robust matrix factorization (RMF) problem with
different regularizations, where our locally majorant algorithm shows
advantages over the state-of-the-art approaches for RMF. This is the first
algorithm for RMF ensuring, without extra assumptions, that any limit point of
the iterates is a stationary point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08063</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08063</id><created>2015-11-25</created><authors><author><keyname>Mineraud</keyname><forenames>Julien</forenames></author><author><keyname>Tarkoma</keyname><forenames>Sasu</forenames></author></authors><title>Toward interoperability for the Internet of Things with meta-hubs</title><categories>cs.SE</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet of Things (IoT) envisions that objects may be connected to the
Internet, producing and consuming data in real-time. Today, numerous middleware
platforms are available to facilitate the communication with these objects.
Unfortunately, the interoperability of these platforms is very limited because
it requires to &quot;manually&quot; connect the services proposed by each platform. One
key design goal for our contribution is not to build yet another middleware,
but rather to augment the functionalities of existing systems via an extension
to support their integration into a network of heterogeneous IoT hubs. The
extension includes a RESTful API to manipulate the basic component of our
extension, the IoT feeds. The IoT feeds allow the platform's owner to
dynamically marshal the IoT features connected to the platform, as well as the
data that they produce. Furthermore, the feeds enable the owner to manage and
control the data flows before connecting them to his applications.
Subsequently, these feeds may also be published to meta-hubs in order to expose
them to third parties. We evaluated an implementation our extension for Android
systems to show the feasibility of managing the data flows using the RESTful
API on this platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08066</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08066</id><created>2015-11-25</created><authors><author><keyname>Brandstadt</keyname><forenames>Andreas</forenames></author><author><keyname>Mosca</keyname><forenames>Raffaele</forenames></author></authors><title>Maximum Weight Independent Sets for ($P_7$,Triangle)-Free Graphs in
  Polynomial Time</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Maximum Weight Independent Set (MWIS) problem on finite undirected graphs
with vertex weights asks for a set of pairwise nonadjacent vertices of maximum
weight sum. MWIS is one of the most investigated and most important algorithmic
graph problems; it is well known to be NP-complete, and it remains NP-complete
even under various strong restrictions such as for triangle-free graphs. Its
complexity was an open problem for $P_k$-free graphs, $k \ge 5$. Recently,
Lokshtanov, Vatshelle, and Villanger proved that MWIS can be solved in
polynomial time for $P_5$-free graphs, and Lokshtanov, Pilipczuk, and van
Leeuwen proved that MWIS can be solved in quasi-polynomial time for $P_6$-free
graphs. It still remains an open problem whether MWIS can be solved in
polynomial time for $P_k$-free graphs, $k \geq 6$ or in quasi-polynomial time
for $P_k$-free graphs, $k \geq 7$. Some characterizations of $P_k$-free graphs
and some progress are known in the literature but so far did not solve the
problem. In this paper, we show that MWIS can be solved in polynomial time for
($P_7$,triangle)-free graphs. This extends the corresponding result for
($P_6$,triangle)-free graphs and may provide some progress in the study of MWIS
for $P_7$-free graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08073</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08073</id><created>2015-11-25</created><authors><author><keyname>Cath&#xe1;in</keyname><forenames>Padraig &#xd3;</forenames></author></authors><title>Remark on a result of Constantine</title><categories>math.CO cs.IT math.IT</categories><comments>1 page</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short note we construct codes of length $4n$ with $8n+8$ codewords
and minimum distance $2n-2$ whenever $4n+4$ is the order of a Hadamard matrix.
This generalises work of Constantine who obtained a similar result in the
special case that $n$ is a prime power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08078</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08078</id><created>2015-11-25</created><authors><author><keyname>Srirama</keyname><forenames>Satish Narayana</forenames></author><author><keyname>Jakovits</keyname><forenames>Pelle</forenames></author><author><keyname>Ivani&#x161;t&#x161;ev</keyname><forenames>Vladislav</forenames></author></authors><title>Desktop to Cloud Migration of Scientific Computing Experiments</title><categories>cs.DC</categories><comments>28 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scientific computing applications usually need huge amounts of computational
power. The cloud provides interesting high-performance computing solutions,
with its promise of virtually infinite resources on demand. However, migrating
scientific computing problems to clouds and the re-creation of software
environment on the vendor-supplied OS and cloud instances is often a laborious
task. It is also assumed that the scientist who is performing the experiments
has significant knowledge of computer science, cloud computing and the
migration procedure, which is often not true. Considering these obstacles, we
have designed a tool suite that migrates the complete software environment
directly to the cloud. The developed desktop-to-cloud-migration (D2CM) tool
supports transformation and migration of virtual machine images, reusable
deployment description and life-cycle management for applications to be hosted
on Amazon Cloud or compatible infrastructure such as Eucalyptus. The paper also
presents an electrochemical case study and computational experiments targeted
at designing modern supercapacitors. These experiments have extensively used
the tool in drawing domain specific results. Detailed analysis of the case
showed that D2CM tool not only simplifies the migration procedure for the
scientists, but also helps them in optimizing the calculations and compute
clusters, by providing them a new dimension -- cost-to-value of computational
experiments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08082</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08082</id><created>2015-11-25</created><authors><author><keyname>Bakhshali</keyname><forenames>Ali</forenames></author><author><keyname>Chan</keyname><forenames>Wai-Yip</forenames></author><author><keyname>Blosten</keyname><forenames>Steven D.</forenames></author><author><keyname>Cao</keyname><forenames>Yu</forenames></author></authors><title>QoE Optimization of Video Multicast with Heterogeneous Channels and
  Playback Requirements</title><categories>cs.IT cs.MM cs.NI math.IT</categories><comments>29 pages, 5 tables, 11 figures, to appear in EURASIP Journal on
  Wireless Communications and Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an application-layer forward error correction (AL-FEC) code rate
allocation scheme to maximize the quality of experience (QoE) of a video
multicast. The allocation dynamically assigns multicast clients to the quality
layers of a scalable video bitstream, based on their heterogeneous channel
qualities and video playback capabilities. Normalized mean opinion score (NMOS)
is employed to value the client's quality of experience across various possible
adaptations of a multilayer video, coded using mixed spatial-temporal-amplitude
scalability. The scheme provides assurance of reception of the video layers
using fountain coding and effectively allocates coding rates across the layers
to maximize a multicast utility measure. An advantageous feature of the
proposed scheme is that the complexity of the optimization is independent of
the number of clients. Additionally, a convex formulation is proposed that
attains close to the best performance and offers a reliable alternative when
further reduction in computational complexity is desired. The optimization is
extended to perform suppression of QoE fluctuations for clients with marginal
channel qualities. The scheme offers a means to trade-off service utility for
the entire multicast group and clients with the worst channels. According to
the simulation results, the proposed optimization framework is robust against
source rate variations and limited amount of client feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08084</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08084</id><created>2015-11-25</created><authors><author><keyname>Kang</keyname><forenames>Jinkyu</forenames><affiliation>Shitz</affiliation></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Kang</keyname><forenames>Joonhyuk</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Layered Downlink Precoding for C-RAN Systems with Full Dimensional MIMO</title><categories>cs.IT math.IT</categories><comments>29 pages, 12 figures, Submitted to IEEE Transactions on Vehicular
  Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The implementation of a Cloud Radio Access Network (C-RAN) with Full
Dimensional (FD)-MIMO is faced with the challenge of controlling the fronthaul
overhead for the transmission of baseband signals as the number of horizontal
and vertical antennas grows larger. This work proposes to leverage the special
low-rank structure of FD-MIMO channel, which is characterized by a
time-invariant elevation component and a time-varying azimuth component, by
means of a layered precoding approach, so as to reduce the fronthaul overhead.
According to this scheme, separate precoding matrices are applied for the
azimuth and elevation channel components, with different rates of adaptation to
the channel variations and correspondingly different impacts on the fronthaul
capacity. Moreover, we consider two different Central Unit (CU) - Radio Unit
(RU) functional splits at the physical layer, namely the conventional C-RAN
implementation and an alternative one in which coding and precoding are
performed at the RUs. Via numerical results, it is shown that the layered
schemes significantly outperform conventional non-layered schemes, especially
in the regime of low fronthaul capacity and large number of vertical antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08088</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08088</id><created>2015-11-25</created><updated>2016-02-01</updated><authors><author><keyname>Bornmann</keyname><forenames>Lutz</forenames></author><author><keyname>Haunschild</keyname><forenames>Robin</forenames></author></authors><title>Relative Citation Ratio (RCR): An empirical attempt to study a new
  field-normalized bibliometric indicator</title><categories>cs.DL</categories><comments>Accepted for publication in the Journal of the Association for
  Information Science and Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Hutchins, Yuan, M., and Santangelo (2015) proposed the Relative Citation
Ratio (RCR) as a new field-normalized impact indicator. This study investigates
the RCR by correlating it on the level of single publications with established
field-normalized indicators and assessments of the publications by peers. We
find that the RCR correlates highly with established field-normalized
indicators, but the correlation between RCR and peer assessments is only low to
medium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08096</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08096</id><created>2015-11-25</created><authors><author><keyname>Mongeon</keyname><forenames>Philippe</forenames></author><author><keyname>Paul-Hus</keyname><forenames>Adele</forenames></author></authors><title>The Journal Coverage of Web of Science and Scopus: a Comparative
  Analysis</title><categories>cs.DL</categories><comments>Accepted for publication in Scientometrics. 17 pages, 6 Figures, 4
  Tables</comments><doi>10.1007/s11192-015-1765-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bibliometric methods are used in multiple fields for a variety of purposes,
namely for research evaluation. Most bibliometric analyses have in common their
data sources: Thomson Reuters' Web of Science (WoS) and Elsevier's Scopus. This
research compares the journal coverage of both databases in terms of fields,
countries and languages, using Ulrich's extensive periodical directory as a
base for comparison. Results indicate that the use of either WoS or Scopus for
research evaluation may introduces biases that favor Natural Sciences and
Engineering as well as Biomedical Research to the detriment of Social Sciences
and Arts and Humanities. Similarly, English-language journals are
overrepresented to the detriment of other languages. While both databases share
these biases, their coverage differs substantially. As a consequence, the
results of bibliometric analyses may vary depending on the database used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08099</identifier>
 <datestamp>2015-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08099</id><created>2015-11-25</created><authors><author><keyname>Cuay&#xe1;huitl</keyname><forenames>Heriberto</forenames></author><author><keyname>Keizer</keyname><forenames>Simon</forenames></author><author><keyname>Lemon</keyname><forenames>Oliver</forenames></author></authors><title>Strategic Dialogue Management via Deep Reinforcement Learning</title><categories>cs.AI cs.LG</categories><comments>NIPS'15 Workshop on Deep Reinforcement Learning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificially intelligent agents equipped with strategic skills that can
negotiate during their interactions with other natural or artificial agents are
still underdeveloped. This paper describes a successful application of Deep
Reinforcement Learning (DRL) for training intelligent agents with strategic
conversational skills, in a situated dialogue setting. Previous studies have
modelled the behaviour of strategic agents using supervised learning and
traditional reinforcement learning techniques, the latter using tabular
representations or learning with linear function approximation. In this study,
we apply DRL with a high-dimensional state space to the strategic board game of
Settlers of Catan---where players can offer resources in exchange for others
and they can also reply to offers made by other players. Our experimental
results report that the DRL-based learnt policies significantly outperformed
several baselines including random, rule-based, and supervised-based
behaviours. The DRL-based policy has a 53% win rate versus 3 automated players
(`bots'), whereas a supervised player trained on a dialogue corpus in this
setting achieved only 27%, versus the same 3 bots. This result supports the
claim that DRL is a promising framework for training dialogue systems, and
strategic agents with negotiation abilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08101</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08101</id><created>2015-11-25</created><updated>2016-01-18</updated><authors><author><keyname>Calderini</keyname><forenames>Marco</forenames></author><author><keyname>Sala</keyname><forenames>Massimilano</forenames></author><author><keyname>Villa</keyname><forenames>Irene</forenames></author></authors><title>A note on APN permutations in even dimension</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  APN permutations in even dimension are vectorial Boolean functions that play
a special role in the design of block ciphers. We study their properties,
providing some general results and some applications to the low-dimension
cases. In particular, we prove that none of their components can be quadratic.
If the permutation is a cubic then we prove the existence of a component having
a large number of balanced derivatives. Using these restrictions, we obtain the
first theoretical proof of the non-existence of APN permutations in dimension
4. Moreover, we derive some contraints on APN permutations in dimension 6.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08113</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08113</id><created>2015-11-25</created><authors><author><keyname>B&#xfc;rgisser</keyname><forenames>Peter</forenames></author></authors><title>Permanent versus determinant, obstructions, and Kronecker coefficients</title><categories>cs.CC</categories><comments>Survey, 17 pages, 1 figure</comments><msc-class>68Q17, 20C30, 05E10, 14L24</msc-class><acm-class>F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an introduction to some of the recent ideas that go under the name
``geometric complexity theory''. We first sketch the proof of the known upper
and lower bounds for the determinantal complexity of the permanent. We then
introduce the concept of a representation theoretic obstruction, which has
close links to algebraic combinatorics, and we explain some of the insights
gained so far. In particular, we address very recent insights on the complexity
of testing the positivity of Kronecker coefficients. We also briefly discuss
the related asymptotic version of this question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08114</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08114</id><created>2015-11-25</created><authors><author><keyname>Kuperman</keyname><forenames>Greg</forenames></author><author><keyname>Sun</keyname><forenames>Jun</forenames></author><author><keyname>Cheng</keyname><forenames>Bow-Nan</forenames></author><author><keyname>Deutsch</keyname><forenames>Patricia</forenames></author><author><keyname>Narula-Tam</keyname><forenames>Aradhana</forenames></author></authors><title>Group Centric Networking: A New Approach for Wireless Multi-Hop
  Networking to Enable the Internet of Things</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a new networking architecture called Group
Centric Networking (GCN), which is designed to support the large number of
devices expected with the emergence of the Internet of Things. GCN is designed
to enable these devices to operate collaboratively in a highly efficient and
resilient fashion, while not sacrificing their ability to communicate with one
another. We do a full protocol implementation of GCN in NS3, and demonstrate
that GCN utilizes up to an order of magnitude fewer network resources than
traditional wireless networking schemes, while providing high connectivity and
reliability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08118</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08118</id><created>2015-11-25</created><authors><author><keyname>Zuki&#x107;</keyname><forenames>D&#x17e;enan</forenames></author><author><keyname>Finet</keyname><forenames>Julien</forenames></author><author><keyname>Wilson</keyname><forenames>Emmanuel</forenames></author><author><keyname>Banovac</keyname><forenames>Filip</forenames></author><author><keyname>Esposito</keyname><forenames>Giuseppe</forenames></author><author><keyname>Cleary</keyname><forenames>Kevin</forenames></author><author><keyname>Enquobahrie</keyname><forenames>Andinet</forenames></author></authors><title>SlicerPET: A workflow based software module for PET/CT guided needle
  biopsy</title><categories>cs.GR</categories><acm-class>I.4.9</acm-class><doi>10.1007/s11548-015-1213-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Biopsy is commonly used to confirm cancer diagnosis when radiologically
indicated. Given the ability of PET to localize malignancies in heterogeneous
tumors and tumors that do not have a CT correlate, PET/CT guided biopsy may
improve the diagnostic yield of biopsies. To facilitate PET/CT guided needle
biopsy, we developed a workflow that allows us to bring PET image guidance into
the interventional CT suite. In this abstract, we present SlicerPET, a
user-friendly workflow based module developed using open source software
libraries to guide needle biopsy in the interventional suite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08119</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08119</id><created>2015-11-25</created><updated>2015-11-28</updated><authors><author><keyname>Arnab</keyname><forenames>Anurag</forenames></author><author><keyname>Jayasumana</keyname><forenames>Sadeep</forenames></author><author><keyname>Zheng</keyname><forenames>Shuai</forenames></author><author><keyname>Torr</keyname><forenames>Philip</forenames></author></authors><title>Higher Order Potentials in End-to-End Trainable Conditional Random
  Fields</title><categories>cs.CV</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We tackle the problem of semantic segmentation using deep learning
techniques. Most semantic segmentation systems include a Conditional Random
Field (CRF) model to produce a structured output that is consistent with visual
features of the image. With recent advances in deep learning, it is becoming
increasingly common to perform CRF inference within a deep neural network to
facilitate joint learning of the CRF with a pixel-wise Convolutional Neural
Network (CNN) classifier.
  While basic CRFs use only unary and pairwise potentials, it has been shown
that the addition of higher order potentials defined on cliques with more than
two nodes can result in a better segmentation outcome. In this paper, we show
that two types of higher order potential, namely, object detection based
potentials and superpixel based potentials, can be included in a CRF embedded
within a deep network. We design these higher order potentials to allow
inference with the efficient and differentiable mean-field algorithm, making it
possible to implement our CRF model as a stack of layers in a deep network. As
a result, all parameters of our richer CRF model can be jointly learned with a
CNN classifier during the end-to-end training of the entire network. We find
significant improvement in the results with the introduction of these trainable
higher order potentials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08130</identifier>
 <datestamp>2016-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08130</id><created>2015-11-25</created><updated>2016-02-26</updated><authors><author><keyname>Mikolov</keyname><forenames>Tomas</forenames></author><author><keyname>Joulin</keyname><forenames>Armand</forenames></author><author><keyname>Baroni</keyname><forenames>Marco</forenames></author></authors><title>A Roadmap towards Machine Intelligence</title><categories>cs.AI cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The development of intelligent machines is one of the biggest unsolved
challenges in computer science. In this paper, we propose some fundamental
properties these machines should have, focusing in particular on communication
and learning. We discuss a simple environment that could be used to
incrementally teach a machine the basics of natural-language-based
communication, as a prerequisite to more complex interaction with human users.
We also present some conjectures on the sort of algorithms the machine should
support in order to profitably learn from the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08131</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08131</id><created>2015-11-25</created><authors><author><keyname>Romero</keyname><forenames>Adriana</forenames></author><author><keyname>Gatta</keyname><forenames>Carlo</forenames></author><author><keyname>Camps-Valls</keyname><forenames>Gustau</forenames></author></authors><title>Unsupervised Deep Feature Extraction for Remote Sensing Image
  Classification</title><categories>cs.CV</categories><journal-ref>IEEE Transactions on Geoscience and Remote Sensing, Volume:PP ,
  Issue: 99, 2015</journal-ref><doi>10.1109/TGRS.2015.2478379</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the use of single layer and deep convolutional networks
for remote sensing data analysis. Direct application to multi- and
hyper-spectral imagery of supervised (shallow or deep) convolutional networks
is very challenging given the high input data dimensionality and the relatively
small amount of available labeled data. Therefore, we propose the use of greedy
layer-wise unsupervised pre-training coupled with a highly efficient algorithm
for unsupervised learning of sparse features. The algorithm is rooted on sparse
representations and enforces both population and lifetime sparsity of the
extracted features, simultaneously. We successfully illustrate the expressive
power of the extracted representations in several scenarios: classification of
aerial scenes, as well as land-use classification in very high resolution
(VHR), or land-cover classification from multi- and hyper-spectral images. The
proposed algorithm clearly outperforms standard Principal Component Analysis
(PCA) and its kernel counterpart (kPCA), as well as current state-of-the-art
algorithms of aerial classification, while being extremely computationally
efficient at learning representations of data. Results show that single layer
convolutional networks can extract powerful discriminative features only when
the receptive field accounts for neighboring pixels, and are preferred when the
classification requires high resolution and detailed results. However, deep
architectures significantly outperform single layers variants, capturing
increasing levels of abstraction and complexity throughout the feature
hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08136</identifier>
 <datestamp>2016-01-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08136</id><created>2015-11-25</created><updated>2016-01-18</updated><authors><author><keyname>Wang</keyname><forenames>Yisen</forenames></author><author><keyname>Song</keyname><forenames>Chaobing</forenames></author><author><keyname>Xia</keyname><forenames>Shu-Tao</forenames></author></authors><title>Unifying Decision Trees Split Criteria Using Tsallis Entropy</title><categories>stat.ML cs.AI cs.LG</categories><comments>6 pages, 2 figures, the paper is under consideration at Pattern
  Recognition Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The construction of efficient and effective decision trees remains a key
topic in machine learning because of their simplicity and flexibility. A lot of
heuristic algorithms have been proposed to construct near-optimal decision
trees. ID3, C4.5 and CART are classical decision tree algorithms and the split
criteria they used are Shannon entropy, Gain Ratio and Gini index respectively.
All the split criteria seem to be independent, actually, they can be unified in
a Tsallis entropy framework. Tsallis entropy is a generalization of Shannon
entropy and provides a new approach to enhance decision trees' performance with
an adjustable parameter $q$. In this paper, a Tsallis Entropy Criterion (TEC)
algorithm is proposed to unify Shannon entropy, Gain Ratio and Gini index,
which generalizes the split criteria of decision trees. More importantly, we
reveal the relations between Tsallis entropy with different $q$ and other split
criteria. Experimental results on UCI data sets indicate that the TEC algorithm
achieves statistically significant improvement over the classical algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08141</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08141</id><created>2015-11-25</created><authors><author><keyname>Menon</keyname><forenames>Vijay</forenames></author><author><keyname>Larson</keyname><forenames>Kate</forenames></author></authors><title>Reinstating Combinatorial Protections for Manipulation and Bribery in
  Single-Peaked and Nearly Single-Peaked Electorates</title><categories>cs.GT cs.MA</categories><comments>28 pages; A shorter version of this paper will appear at the 30th
  AAAI Conference on Artificial Intelligence (AAAI-16)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Understanding when and how computational complexity can be used to protect
elections against different manipulative actions has been a highly active
research area over the past two decades. A recent body of work, however, has
shown that many of the NP-hardness shields, previously obtained, vanish when
the electorate has single-peaked or nearly single-peaked preferences. In light
of these results, we investigate whether it is possible to reimpose NP-hardness
shields for such electorates by allowing the voters to specify partial
preferences instead of insisting they cast complete ballots. In particular, we
show that in single-peaked and nearly single-peaked electorates, if voters are
allowed to submit top-truncated ballots, then the complexity of manipulation
and bribery for many voting rules increases from being in P to being
NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08143</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08143</id><created>2015-11-25</created><authors><author><keyname>Joshi</keyname><forenames>Gauri</forenames></author><author><keyname>Kochman</keyname><forenames>Yuval</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>On Throughput-Smoothness Trade-offs in Streaming Communication</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlike traditional file transfer where only total delay matters, streaming
applications impose delay constraints on each packet and require them to be in
order. To achieve fast in-order packet decoding, we have to compromise on the
throughput. We study this trade-off between throughput and smoothness in packet
decoding. We first consider a point-to-point streaming and analyze how the
trade-off is affected by the frequency of block-wise feedback, whereby the
source receives full channel state feedback at periodic intervals. We show that
frequent feedback can drastically improve the throughput-smoothness trade-off.
Then we consider the problem of multicasting a packet stream to two users. For
both point-to-point and multicast streaming, we propose a spectrum of coding
schemes that span different throughput-smoothness tradeoffs. One can choose an
appropriate coding scheme from these, depending upon the delay-sensitivity and
bandwidth limitations of the application. This work introduces a novel style of
analysis using renewal processes and Markov chains to analyze coding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08152</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08152</id><created>2015-11-25</created><authors><author><keyname>Lee</keyname><forenames>Jon</forenames></author><author><keyname>Nagarajan</keyname><forenames>Viswanath</forenames></author><author><keyname>Shen</keyname><forenames>Xiangkun</forenames></author></authors><title>Max-Cut under Graph Constraints</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An instance of the graph-constrained max-cut (GCMC) problem consists of (i)
an undirected graph G and (ii) edge-weights on a complete undirected graph on
the same vertex set. The objective is to find a subset of vertices satisfying
some graph-based constraint in G that maximizes the total weight of edges in
the cut. The types of graph constraints we can handle include independent set,
vertex cover, dominating set and connectivity. Our main results are for the
case when G is a graph with bounded treewidth, where we obtain a
0.5-approximation algorithm. Our algorithm uses an LP relaxation based on the
Sherali-Adams hierarchy. It can handle any graph constraint for which there is
a (certain type of) dynamic program that exactly optimizes linear objectives.
Using known decomposition results, these imply essentially the same
approximation ratio for GCMC under constraints such as independent set,
dominating set and connectivity on a planar graph G (more generally for
bounded-genus or excluded-minor graphs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08158</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08158</id><created>2015-11-25</created><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>Zhuo</keyname><forenames>Hankz Hankui</forenames></author><author><keyname>Kambhampati</keyname><forenames>Subbarao</forenames></author></authors><title>Plan Explainability and Predictability for Cobots</title><categories>cs.AI cs.RO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robots are becoming pervasive in human populated environments. A desirable
capability of these robots (cobots) is to respond to goal-oriented commands by
autonomously constructing plans. However, such autonomy can add significant
cognitive load and even potentially introduce safety risks to the humans when
robots choose their plans unexpectedly. As a result, for cobots to be more
helpful, one important requirement is for them to synthesize plans that do not
{\it surprise} the humans. While there are previous works that studied socially
acceptable robots which discuss ``natural ways'' for cobots to interact with
humans, there still lacks a general solution, especially for cobots that can
construct their own plans. In this paper, we introduce the notions of plan {\it
explainability} and {\it predictability}. To compute these measures, first, we
postulate that humans understand robot plans by associating high level tasks
with robot actions, which can be considered as a labeling process. We learn the
labeling scheme of humans for robot plans from training examples using
conditional random fields (CRFs). Then, we use the learned model to label a new
plan to compute its explainability and predictability. These measures can be
used by cobots to proactively choose plans, or directly incorporated into the
planning process to generate plans that are more explainable and predictable.
We provide an evaluation on a synthetic dataset to demonstrate the
effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08166</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08166</id><created>2015-11-25</created><authors><author><keyname>Basu</keyname><forenames>Chandrayee</forenames></author><author><keyname>Rowe</keyname><forenames>Anthony</forenames></author></authors><title>Tracking Motion and Proxemics using Thermal-sensor Array</title><categories>cs.CV</categories><comments>6 pages, 6 figures, Machine Learning for Signal Processing Class
  project</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indoor tracking has all-pervasive applications beyond mere surveillance, for
example in education, health monitoring, marketing, energy management and so
on. Image and video based tracking systems are intrusive. Thermal array sensors
on the other hand can provide coarse-grained tracking while preserving privacy
of the subjects. The goal of the project is to facilitate motion detection and
group proxemics modeling using an 8 x 8 infrared sensor array. Each of the 8 x
8 pixels is a temperature reading in Fahrenheit. We refer to each 8 x 8 matrix
as a scene. We collected approximately 902 scenes with different configurations
of human groups and different walking directions. We infer direction of motion
of a subject across a set of scenes as left-to-right, right-to-left, up-to-down
and down-to-up using cross-correlation analysis. We used features from
connected component analysis of each background subtracted scene and performed
Support Vector Machine classification to estimate number of instances of human
subjects in the scene.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08167</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08167</id><created>2015-11-24</created><authors><author><keyname>Ucar</keyname><forenames>I&#xf1;aki</forenames></author><author><keyname>Azcorra</keyname><forenames>Arturo</forenames></author></authors><title>Deseeding Energy Consumption of Network Stacks</title><categories>cs.NI cs.PF</categories><comments>10 pages, 12 figures</comments><acm-class>C.2.2; C.4</acm-class><doi>10.1109/RTSI.2015.7325085</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regular works on energy efficiency strategies for wireless communications are
based on classical energy models that account for the wireless card only.
Nevertheless, there is a non-negligible energy toll called &quot;cross-factor&quot; that
encompasses the energy drained while a frame crosses the network stack of an
OS.
  This paper addresses the challenge of deepen into the roots of the
cross-factor, deseed its components and analyse its causes. Energy issues are
critical for IoT devices. Thus, this paper conceives and validates a new
comprehensive framework that enables us to measure a wide range of wireless
devices, as well as multiple devices synchronously. We also present a rigorous
methodology to perform whole-device energy measurements in laptops, a more
generic and suitable device to perform energy debugging. Finally, and using
this framework, we provide a collection of measurements and insights that
deepens our understanding of the cross-factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08177</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08177</id><created>2015-11-25</created><authors><author><keyname>Gupta</keyname><forenames>Saurabh</forenames></author><author><keyname>Hariharan</keyname><forenames>Bharath</forenames></author><author><keyname>Malik</keyname><forenames>Jitendra</forenames></author></authors><title>Exploring Person Context and Local Scene Context for Object Detection</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore two ways of using context for object detection. The
first model focusses on people and the objects they commonly interact with,
such as fashion and sports accessories. The second model considers more general
object detection and uses the spatial relationships between objects and between
objects and scenes. Our models are able to capture precise spatial
relationships between the context and the object of interest, and make
effective use of the appearance of the contextual region. On the newly released
COCO dataset, our models provide relative improvements of up to 5% over
CNN-based state-of-the-art detectors, with the gains concentrated on hard cases
such as small objects (10% relative improvement).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08178</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08178</id><created>2015-11-24</created><authors><author><keyname>Trawi&#x144;ski</keyname><forenames>Krzysztof</forenames></author><author><keyname>Chica</keyname><forenames>Manuel</forenames></author><author><keyname>Pancho</keyname><forenames>David P.</forenames></author><author><keyname>Damas</keyname><forenames>Sergio</forenames></author><author><keyname>Cord&#xf3;n</keyname><forenames>Oscar</forenames></author></authors><title>moGrams: a network-based methodology for visualizing the set of
  non-dominated solutions in multiobjective optimization</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An appropriate visualization of multiobjective non-dominated solutions is a
valuable asset for decision making. Although there are methods for visualizing
the solutions in the design space, they do not provide any information about
their relationship. In this work, we propose a novel methodology that allows
the visualization of the non-dominated solutions in the design space and their
relationships by means of a network. The nodes represent the solutions in the
objective space, while the edges show the relationships between the solutions
in the design space. Our proposal (called moGrams) thus provides a joint
visualization of both objective and design spaces. It aims at helping the
decision maker to get more understanding of the problem so that (s)he can
choose the more appropriate final solution. moGrams can be applied to any
multicriteria problem in which the solutions are related by a similarity
metric. Besides, the decision maker interaction is facilitated by modifying the
network based on the current preferences to obtain a clearer view. An
exhaustive experimental study is performed using three multiobjective problems
in order to show both the usefulness and versatility of moGrams. The results
exhibit interesting characteristics of our methodology for visualizing and
analyzing solutions of multiobjective problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08179</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08179</id><created>2015-11-25</created><authors><author><keyname>Angulo</keyname><forenames>Gustavo</forenames></author><author><keyname>Van Vyve</keyname><forenames>Mathieu</forenames></author></authors><title>Fixed-charge transportation problems on trees</title><categories>math.OC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a class of fixed-charge transportation problems over graphs. We
show that this problem is strongly NP-hard, but solvable in pseudo-polynomial
time over trees using dynamic programming. We also show that the LP formulation
associated to the dynamic program can be obtained from extended formulations of
single-node flow polytopes. Given these results, we present a unary
expansion-based formulation for general graphs that is computationally
advantageous when compared to a standard formulation, even if its LP relaxation
is not stronger.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08189</identifier>
 <datestamp>2015-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08189</id><created>2015-11-25</created><authors><author><keyname>Allender</keyname><forenames>Eric</forenames></author><author><keyname>Grochow</keyname><forenames>Joshua A.</forenames></author><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author></authors><title>Graph Isomorphism and Circuit Size</title><categories>cs.CC</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the Graph Automorphism problem is ZPP-reducible to MKTP, the
problem of minimizing time-bounded Kolmogorov complexity. MKTP has previously
been studied in connection with the Minimum Circuit Size Problem (MCSP) and is
often viewed as essentially a different encoding of MCSP. All prior reductions
to MCSP have applied equally well to MKTP, and vice-versa, and all such
reductions have relied on the fact that functions computable in polynomial time
can be inverted with high probability relative to MCSP and MKTP. Our reduction
uses a different approach, and consequently yields the first example of a
problem -- other than MKTP itself -- that is in ZPP^MKTP but that is not known
to lie in NP intersect coNP. We also show that this approach can be used to
provide a reduction of the Graph Isomorphism problem to MKTP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08198</identifier>
 <datestamp>2016-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08198</id><created>2015-11-25</created><updated>2016-03-04</updated><authors><author><keyname>Wieting</keyname><forenames>John</forenames></author><author><keyname>Bansal</keyname><forenames>Mohit</forenames></author><author><keyname>Gimpel</keyname><forenames>Kevin</forenames></author><author><keyname>Livescu</keyname><forenames>Karen</forenames></author></authors><title>Towards Universal Paraphrastic Sentence Embeddings</title><categories>cs.CL cs.LG</categories><comments>Published as a conference paper at ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of learning general-purpose, paraphrastic sentence
embeddings based on supervision from the Paraphrase Database (Ganitkevitch et
al., 2013). We compare six compositional architectures, evaluating them on
annotated textual similarity datasets drawn both from the same distribution as
the training data and from a wide range of other domains. We find that the most
complex architectures, such as long short-term memory (LSTM) recurrent neural
networks, perform best on the in-domain data. However, in out-of-domain
scenarios, simple architectures such as word averaging vastly outperform LSTMs.
Our simplest averaging model is even competitive with systems tuned for the
particular tasks while also being extremely efficient and easy to use.
  In order to better understand how these architectures compare, we conduct
further experiments on three supervised NLP tasks: sentence similarity,
entailment, and sentiment classification. We again find that the word averaging
models perform well for sentence similarity and entailment, outperforming
LSTMs. However, on sentiment classification, we find that the LSTM performs
very strongly-even recording new state-of-the-art performance on the Stanford
Sentiment Treebank.
  We then demonstrate how to combine our pretrained sentence embeddings with
these supervised tasks, using them both as a prior and as a black box feature
extractor. This leads to performance rivaling the state of the art on the SICK
similarity and entailment tasks. We release all of our resources to the
research community with the hope that they can serve as the new baseline for
further work on universal sentence embeddings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08205</identifier>
 <datestamp>2016-02-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08205</id><created>2015-11-25</created><updated>2016-02-03</updated><authors><author><keyname>Itzhakov</keyname><forenames>Avraham</forenames></author><author><keyname>Codish</keyname><forenames>Michael</forenames></author></authors><title>Breaking Symmetries in Graph Search with Canonizing Sets</title><categories>cs.AI cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many complex combinatorial problems which involve searching for an
undirected graph satisfying given constraints. Such problems are often highly
challenging because of the large number of isomorphic representations of their
solutions. This paper introduces effective and compact, complete symmetry
breaking constraints for small graph search. Enumerating with these symmetry
breaks generates all and only non-isomorphic solutions. For small search
problems, with up to $10$ vertices, we compute instance independent symmetry
breaking constraints. For small search problems with a larger number of
vertices we demonstrate the computation of instance dependent constraints which
are complete. We illustrate the application of complete symmetry breaking
constraints to extend two known sequences from the OEIS related to graph
enumeration. We also demonstrate the application of a generalization of our
approach to fully-interchangeable matrix search problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08228</identifier>
 <datestamp>2016-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08228</id><created>2015-11-25</created><updated>2016-01-06</updated><authors><author><keyname>Kaiser</keyname><forenames>&#x141;ukasz</forenames></author><author><keyname>Sutskever</keyname><forenames>Ilya</forenames></author></authors><title>Neural GPUs Learn Algorithms</title><categories>cs.LG cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning an algorithm from examples is a fundamental problem that has been
widely studied. Recently it has been addressed using neural networks, in
particular by Neural Turing Machines (NTMs). These are fully differentiable
computers that use backpropagation to learn their own programming. Despite
their appeal NTMs have a weakness that is caused by their sequential nature:
they are not parallel and are are hard to train due to their large depth when
unfolded.
  We present a neural network architecture to address this problem: the Neural
GPU. It is based on a type of convolutional gated recurrent unit and, like the
NTM, is computationally universal. Unlike the NTM, the Neural GPU is highly
parallel which makes it easier to train and efficient to run.
  An essential property of algorithms is their ability to handle inputs of
arbitrary size. We show that the Neural GPU can be trained on short instances
of an algorithmic task and successfully generalize to long instances. We
verified it on a number of tasks including long addition and long
multiplication of numbers represented in binary. We train the Neural GPU on
numbers with upto 20 bits and observe no errors whatsoever while testing it,
even on much longer numbers.
  To achieve these results we introduce a technique for training deep recurrent
networks: parameter sharing relaxation. We also found a small amount of dropout
and gradient noise to have a large positive effect on learning and
generalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08232</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08232</id><created>2015-11-25</created><authors><author><keyname>Wang</keyname><forenames>Cheng</forenames></author><author><keyname>Delporte-Gallet</keyname><forenames>Carole</forenames></author><author><keyname>Fauconnier</keyname><forenames>Hugues</forenames></author><author><keyname>Guerraoui</keyname><forenames>Rachid</forenames></author><author><keyname>Kermarrec</keyname><forenames>Anne-Marie</forenames></author></authors><title>Beyond One Third Byzantine Failures</title><categories>cs.DC</categories><license>http://creativecommons.org/licenses/by/4.0/</license><abstract>  The Byzantine agreement problem requires a set of $n$ processes to agree on a
value sent by a transmitter, despite a subset of $b$ processes behaving in an
arbitrary, i.e. Byzantine, manner and sending corrupted messages to all
processes in the system. It is well known that the problem has a solution in a
(an eventually) synchronous message passing distributed system iff the number
of processes in the Byzantine subset is less than one third of the total number
of processes, i.e. iff $n &gt; 3b+1$. The rest of the processes are expected to be
correct: they should never deviate from the algorithm assigned to them and send
corrupted messages. But what if they still do?
  We show in this paper that it is possible to solve Byzantine agreement even
if, beyond the $ b$ ($&lt; n/3 $) Byzantine processes, some of the other processes
also send corrupted messages, as long as they do not send them to all. More
specifically, we generalize the classical Byzantine model and consider that
Byzantine failures might be partial. In each communication step, some of the
processes might send corrupted messages to a subset of the processes. This
subset of processes - to which corrupted messages might be sent - could change
over time. We compute the exact number of processes that can commit such
faults, besides those that commit classical Byzantine failures, while still
solving Byzantine agreement. We present a corresponding Byzantine agreement
algorithm and prove its optimality by giving resilience and complexity bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08238</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08238</id><created>2015-11-25</created><authors><author><keyname>Hannak</keyname><forenames>Gabor</forenames></author><author><keyname>Mayer</keyname><forenames>Martin</forenames></author><author><keyname>Matz</keyname><forenames>Gerald</forenames></author><author><keyname>Goertz</keyname><forenames>Norbert</forenames></author></authors><title>An Approach to Complex Bayesian-optimal Approximate Message Passing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we aim to solve the compressed sensing problem for the case of a
complex unknown vector by utilizing the Bayesian-optimal structured signal
approximate message passing (BOSSAMP) algorithm on the jointly sparse real and
imaginary parts of the unknown. By introducing a latent activity variable,
BOSSAMP separates the tasks of activity detection and value estimation to
overcome the problem of detecting different supports in the real and imaginary
parts. We complement the recovery algorithm by two novel support detection
schemes that utilize the updated auxiliary variables of BOSSAMP. Simulations
show the superiority of our proposed method against approximate message passing
(AMP) and its Bayesian-optimal sibling (BAMP), both in mean squared error and
support detection performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08245</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08245</id><created>2015-11-25</created><authors><author><keyname>Moran</keyname><forenames>Shay</forenames></author><author><keyname>Rashtchian</keyname><forenames>Cyrus</forenames></author></authors><title>Shattered Sets and the Hilbert Function</title><categories>math.CO cs.CC cs.DM</categories><comments>19 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study complexity measures on subsets of the boolean hypercube and exhibit
connections between algebra (the Hilbert function) and combinatorics (VC
theory). These connections yield results in both directions. Our main
complexity-theoretic result proves that most linear program feasibility
problems cannot be computed by polynomial-sized constant-depth circuits.
Moreover, our result applies to a stronger regime in which the hyperplanes are
fixed and only the directions of the inequalities are given as input to the
circuit. We derive this result by proving that a rich class of extremal
functions in VC theory cannot be approximated by low-degree polynomials. We
also present applications of algebra to combinatorics. We provide a new
algebraic proof of the Sandwich Theorem, which is a generalization of the
well-known Sauer-Perles-Shelah Lemma. Finally, we prove a structural result
about downward-closed sets, related to the Chv\'{a}tal conjecture in extremal
combinatorics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08250</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08250</id><created>2015-11-25</created><authors><author><keyname>Romera-Paredes</keyname><forenames>Bernardino</forenames></author><author><keyname>Torr</keyname><forenames>Philip H. S.</forenames></author></authors><title>Recurrent Instance Segmentation</title><categories>cs.CV cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instance segmentation is the problem of detecting and delineating each object
of interest appearing in an image. Current instance segmentation approaches
consist of ensembles of modules that are trained independently of each other,
thus missing learning opportunities. Here we propose a new instance
segmentation paradigm consisting in an end-to-end method that learns how to
segment instances sequentially. The model is based on a recurrent neural
network that sequentially finds objects and their segmentations one at a time.
This net is provided with a spatial memory that keeps track of what pixels have
been explained and allows handling occlusion. In order to train the model we
designed a new principled loss function that accurately represents the
properties of the instance segmentation problem. In the experiments carried out
we found that our method outperforms all $5$ state of the art approaches on the
Plant Phenotyping dataset.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08253</identifier>
 <datestamp>2016-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08253</id><created>2015-11-25</created><authors><author><keyname>Bhaskar</keyname><forenames>Mihir K.</forenames></author><author><keyname>Hadfield</keyname><forenames>Stuart</forenames></author><author><keyname>Papageorgiou</keyname><forenames>Anargyros</forenames></author><author><keyname>Petras</keyname><forenames>Iasonas</forenames></author></authors><title>Quantum Algorithms and Circuits for Scientific Computing</title><categories>quant-ph cs.NA</categories><comments>43 pages, 11 figures</comments><journal-ref>Quantum Information and Computation. 16, no. 3&amp;4 (2016): 0197-0236</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum algorithms for scientific computing require modules implementing
fundamental functions, such as the square root, the logarithm, and others. We
require algorithms that have a well-controlled numerical error, that are
uniformly scalable and reversible (unitary), and that can be implemented
efficiently. We present quantum algorithms and circuits for computing the
square root, the natural logarithm, and arbitrary fractional powers. We provide
performance guarantees in terms of their worst-case accuracy and cost. We
further illustrate their performance by providing tests comparing them to the
respective floating point implementations found in widely used numerical
software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08256</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08256</id><created>2015-11-25</created><authors><author><keyname>Zhu</keyname><forenames>Kun</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author></authors><title>Virtualization of 5G Cellular Networks as a Hierarchical Combinatorial
  Auction</title><categories>cs.GT cs.NI</categories><comments>IEEE Transactions on Mobile Computing, under submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Virtualization has been seen as one of the main evolution trends in the
forthcoming fifth generation (5G) cellular networks which enables the
decoupling of infrastructure from the services it provides. In this case, the
roles of infrastructure providers (InPs) and mobile virtual network operators
(MVNOs) can be logically separated and the resources (e.g., subchannels, power,
and antennas) of a base station owned by an InP can be transparently shared by
multiple MVNOs, while each MVNO virtually owns the entire BS. Naturally, the
issue of resource allocation arises. In particular, the InP is required to
abstract the physical resources into isolated slices for each MVNO who then
allocates the resources within the slice to its subscribed users. In this
paper, we aim to address this two-level hierarchical resource allocation
problem while satisfying the requirements of efficient resource allocation,
strict inter-slice isolation, and the ability of intra-slice customization. To
this end, we design a hierarchical combinatorial auction mechanism, based on
which a truthful and sub-efficient resource allocation framework is provided.
Specifically, winner determination problems (WDPs) are formulated for the InP
and MVNOs, and computationally tractable algorithms are proposed to solve these
WDPs. Also, pricing schemes are designed to ensure incentive compatibility. The
designed mechanism can achieve social efficiency in each level even if each
party involved acts selfishly. Numerical results show the effectiveness of the
proposed scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08264</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08264</id><created>2015-11-24</created><authors><author><keyname>Gospodarczyk</keyname><forenames>Przemys&#x142;aw</forenames></author><author><keyname>Wo&#x17a;ny</keyname><forenames>Pawe&#x142;</forenames></author></authors><title>A new property of dual bases and its application</title><categories>math.NA cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a new property of dual bases. Let there be given
a dual basis $D_{n+1}$ for a basis $B_{n+1} :=
\left\{b_0,b_1,\ldots,b_{n+1}\right\}$ of the linear space $\mathcal{B}_{n+1}
:= \mbox{span}\,B_{n+1}$ with an inner product $\left&lt;\cdot,\cdot\right&gt;$. A
dual basis $D_n$ for the basis $B_n := B_{n+1} \setminus
\left\{b_{n+1}\right\}$ of the linear space $\mathcal{B}_{n} :=
\mbox{span}\,B_n$ with respect to the same inner product can be computed
quickly using a new formula connecting the dual functions from $D_{n+1}$ and
$D_n$. The presented algorithm, along with the methods given in (P. Wo\'zny,
Journal of Computational and Applied Mathematics 260 (2014), 301--311), can be
used to solve efficiently the problem of degree reduction of B\'ezier curves
with box constraints, which has been proposed recently in (P. Gospodarczyk,
Computer-Aided Design 62 (2015), 143--151).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08270</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08270</id><created>2015-11-25</created><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Gadekar</keyname><forenames>Ameet</forenames></author><author><keyname>Ghoshal</keyname><forenames>Suprovat</forenames></author><author><keyname>Saket</keyname><forenames>Rishi</forenames></author></authors><title>On the hardness of learning sparse parities</title><categories>cs.CC cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work investigates the hardness of computing sparse solutions to systems
of linear equations over F_2. Consider the k-EvenSet problem: given a
homogeneous system of linear equations over F_2 on n variables, decide if there
exists a nonzero solution of Hamming weight at most k (i.e. a k-sparse
solution). While there is a simple O(n^{k/2})-time algorithm for it,
establishing fixed parameter intractability for k-EvenSet has been a notorious
open problem. Towards this goal, we show that unless k-Clique can be solved in
n^{o(k)} time, k-EvenSet has no poly(n)2^{o(sqrt{k})} time algorithm and no
polynomial time algorithm when k = (log n)^{2+eta} for any eta &gt; 0.
  Our work also shows that the non-homogeneous generalization of the problem --
which we call k-VectorSum -- is W[1]-hard on instances where the number of
equations is O(k log n), improving on previous reductions which produced
Omega(n) equations. We also show that for any constant eps &gt; 0, given a system
of O(exp(O(k))log n) linear equations, it is W[1]-hard to decide if there is a
k-sparse linear form satisfying all the equations or if every function on at
most k-variables (k-junta) satisfies at most (1/2 + eps)-fraction of the
equations. In the setting of computational learning, this shows hardness of
approximate non-proper learning of k-parities. In a similar vein, we use the
hardness of k-EvenSet to show that that for any constant d, unless k-Clique can
be solved in n^{o(k)} time there is no poly(m, n)2^{o(sqrt{k}) time algorithm
to decide whether a given set of m points in F_2^n satisfies: (i) there exists
a non-trivial k-sparse homogeneous linear form evaluating to 0 on all the
points, or (ii) any non-trivial degree d polynomial P supported on at most k
variables evaluates to zero on approx. Pr_{F_2^n}[P(z) = 0] fraction of the
points i.e., P is fooled by the set of points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08277</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08277</id><created>2015-11-25</created><authors><author><keyname>Wan</keyname><forenames>Shengxian</forenames></author><author><keyname>Lan</keyname><forenames>Yanyan</forenames></author><author><keyname>Guo</keyname><forenames>Jiafeng</forenames></author><author><keyname>Xu</keyname><forenames>Jun</forenames></author><author><keyname>Pang</keyname><forenames>Liang</forenames></author><author><keyname>Cheng</keyname><forenames>Xueqi</forenames></author></authors><title>A Deep Architecture for Semantic Matching with Multiple Positional
  Sentence Representations</title><categories>cs.AI cs.CL cs.NE</categories><comments>Accepted by AAAI-2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching natural language sentences is central for many applications such as
information retrieval and question answering. Existing deep models rely on a
single sentence representation or multiple granularity representations for
matching. However, such methods cannot well capture the contextualized local
information in the matching process. To tackle this problem, we present a new
deep architecture to match two sentences with multiple positional sentence
representations. Specifically, each positional sentence representation is a
sentence representation at this position, generated by a bidirectional long
short term memory (Bi-LSTM). The matching score is finally produced by
aggregating interactions between these different positional sentence
representations, through $k$-Max pooling and a multi-layer perceptron. Our
model has several advantages: (1) By using Bi-LSTM, rich context of the whole
sentence is leveraged to capture the contextualized local information in each
positional sentence representation; (2) By matching with multiple positional
sentence representations, it is flexible to aggregate different important
contextualized local information in a sentence to support the matching; (3)
Experiments on different tasks such as question answering and sentence
completion demonstrate the superiority of our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08280</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08280</id><created>2015-11-25</created><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Kalinowski</keyname><forenames>Thomas</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author><author><keyname>Xia</keyname><forenames>Lirong</forenames></author></authors><title>Welfare of Sequential Allocation Mechanisms for Indivisible Goods</title><categories>cs.AI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential allocation is a simple and attractive mechanism for the allocation
of indivisible goods. Agents take turns, according to a policy, to pick items.
Sequential allocation is guaranteed to return an allocation which is efficient
but may not have an optimal social welfare. We consider therefore the relation
between welfare and efficiency. We study the (computational) questions of what
welfare is possible or necessary depending on the choice of policy. We also
consider a novel control problem in which the chair chooses a policy to improve
social welfare.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08283</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08283</id><created>2015-11-25</created><authors><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author></authors><title>A tight lower bound for Vertex Planarization on graphs of bounded
  treewidth</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Vertex Planarization problem one asks to delete the minimum possible
number of vertices from an input graph to obtain a planar graph. The
parameterized complexity of this problem, parameterized by the solution size
(the number of deleted vertices) has recently attracted significant attention.
The state-of-the-art algorithm of Jansen, Lokshtanov, and Saurabh [SODA 2014]
runs in time $2^{O(k \log k)} \cdot n$ on $n$-vertex graph with a solution of
size $k$. It remains open if one can obtain a single-exponential dependency on
$k$ in the running time bound.
  One of the core technical contributions of the work of Jansen, Lokshtanov,
and Saurabh is an algorithm that solves a weighted variant of Vertex
Planarization in time $2^{O(w \log w)} \cdot n$ on graphs of treewidth $w$. In
this short note we prove that the running time of this routine is tight under
the Exponential Time Hypothesis, even in unweighted graphs and when
parameterizing by treedepth. Consequently, it is unlikely that a potential
single-exponential algorithm for Vertex Planarization parameterized by the
solution size can be obtained by merely improving upon the aforementioned
bounded treewidth subroutine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08290</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08290</id><created>2015-11-25</created><authors><author><keyname>Shafique</keyname><forenames>Taniya</forenames></author><author><keyname>Muhammad</keyname><forenames>Zia</forenames></author><author><keyname>Han</keyname><forenames>Huy-Dung</forenames></author></authors><title>Cross-layer Chase Combining with Selective Retransmission, Analysis and
  Throughput Optimization for OFDM Systems</title><categories>cs.IT cs.PF math.IT</categories><comments>arXiv admin note: text overlap with arXiv:1503.05819</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present bandwidth efficient retransmission method employong
selective retransmission approach at modulation layer under orthogonal
frequency division multiplexing (OFDM) signaling. Our proposed cross-layer
design embeds a selective retransmission sublayer in physical layer (PHY) that
targets retransmission of information symbols transmitted over poor quality
OFDM sub-carriers. Most of the times, few errors in decoded bit stream result
in packet failure at medium access control (MAC) layer. The unnecessary
retransmission of good quality information symbols of a failed packet has
detrimental effect on overall throughput of transceiver. We propose a
cross-layer Chase combining with selective retransmission (CCSR) method by
blending Chase combining at MAC layer and selective retransmission in PHY. The
selective retransmission in PHY targets the poor quality information symbols
prior to decoding, which results into lower hybrid automatic repeat reQuest
(HARQ) retransmissions at MAC layer. We also present tight bit-error rate (BER)
upper bound and tight throughput lower bound for CCSR method. In order to
maximize throughput of the proposed method, we formulate optimization problem
with respect to the amount of information to be retransmitted in selective
retransmission. The simulation results demonstrate significant throughput gain
of the proposed CCSR method as compared to conventional Chase combining method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08299</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08299</id><created>2015-11-26</created><authors><author><keyname>Long</keyname><forenames>Matthew</forenames></author><author><keyname>Jami</keyname><forenames>Aditya</forenames></author><author><keyname>Saxena</keyname><forenames>Ashutosh</forenames></author></authors><title>Hierarchical classification of e-commerce related social media</title><categories>cs.SI cs.CL cs.IR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we attempt to classify tweets into root categories of the
Amazon browse node hierarchy using a set of tweets with browse node ID labels,
a much larger set of tweets without labels, and a set of Amazon reviews.
Examining twitter data presents unique challenges in that the samples are short
(under 140 characters) and often contain misspellings or abbreviations that are
trivial for a human to decipher but difficult for a computer to parse. A
variety of query and document expansion techniques are implemented in an effort
to improve information retrieval to modest success.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08303</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08303</id><created>2015-11-26</created><authors><author><keyname>Kontogiannis</keyname><forenames>Spyros</forenames></author><author><keyname>Michalopoulos</keyname><forenames>George</forenames></author><author><keyname>Papastavrou</keyname><forenames>Georgia</forenames></author><author><keyname>Paraskevopoulos</keyname><forenames>Andreas</forenames></author><author><keyname>Wagner</keyname><forenames>Dorothea</forenames></author><author><keyname>Zaroliagis</keyname><forenames>Christos</forenames></author></authors><title>Engineering Oracles for Time-Dependent Road Networks</title><categories>cs.DS</categories><comments>In ALENEX 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We implement and experimentally evaluate landmark-based oracles for min-cost
paths in large-scale time-dependent road networks. We exploit parallelism and
lossless compression, combined with a novel travel-time approximation
technique, to severely reduce preprocessing space and time. We significantly
improve the FLAT oracle, improving the previous query time by $30\%$ and
doubling the Dijkstra-rank speedup. We also implement and experimentally
evaluate a novel oracle (HORN), based on a landmark hierarchy, achieving even
better performance wrt to FLAT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08307</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08307</id><created>2015-11-26</created><authors><author><keyname>Kuramitsu</keyname><forenames>Kimio</forenames></author></authors><title>Nez: practical open grammar language</title><categories>cs.PL</categories><comments>unpublished draft work (11 pages)</comments><acm-class>D.3.1; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nez is a PEG(Parsing Expressing Grammar)-based open grammar language that
allows us to describe complex syntax constructs without action code. Since open
grammars are declarative and free from a host programming language of parsers,
software engineering tools and other parser applications can reuse once-defined
grammars across programming languages.
  A key challenge to achieve practical open grammars is the expressiveness of
syntax constructs and the resulting parser performance, as the traditional
action code approach has provided very pragmatic solutions to these two issues.
In Nez, we extend the symbol-based state management to recognize
context-sensitive language syntax, which often appears in major programming
languages. In addition, the Abstract Syntax Tree constructor allows us to make
flexible tree structures, including the left-associative pair of trees. Due to
these extensions, we have demonstrated that Nez can parse not all but many
grammars.
  Nez can generate various types of parsers since all Nez operations are
independent of a specific parser language. To highlight this feature, we have
implemented Nez with dynamic parsing, which allows users to integrate a Nez
parser as a parser library that loads a grammar at runtime. To achieve its
practical performance, Nez operators are assembled into low-level virtual
machine instructions, including automated state modifications when
backtracking, transactional controls of AST construction, and efficient
memoization in packrat parsing. We demonstrate that Nez dynamic parsers achieve
very competitive performance compared to existing efficient parser generators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08308</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08308</id><created>2015-11-26</created><authors><author><keyname>Chiu</keyname><forenames>Jason P. C.</forenames></author><author><keyname>Nichols</keyname><forenames>Eric</forenames></author></authors><title>Named Entity Recognition with Bidirectional LSTM-CNNs</title><categories>cs.CL cs.LG cs.NE</categories><msc-class>68T50</msc-class><acm-class>I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Named entity recognition is a challenging task that has traditionally
required large amounts of knowledge in the form of feature engineering and
lexicons to achieve high performance. In this paper, we present a novel neural
network architecture that automatically detects word- and character-level
features using a hybrid bidirectional LSTM and CNN architecture, eliminating
the need for most feature engineering. We also propose a novel method of
encoding partial lexicon matches in neural networks and compare it to existing
exact match approaches. Extensive evaluation shows that, given only tokenized
text, publicly available word vectors, and an automatically constructed lexicon
from open sources, our system is able to surpass the reported state-of-the-art
on the OntoNotes 5.0 dataset by 2.35 F1 points and achieves competitive results
on the CoNLL 2003 dataset, rivaling systems that employ heavy feature
engineering, proprietary lexicons, and rich entity linking information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08310</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08310</id><created>2015-11-26</created><updated>2015-12-01</updated><authors><author><keyname>Singh</keyname><forenames>Mayank</forenames></author><author><keyname>Sarkar</keyname><forenames>Rajdeep</forenames></author><author><keyname>Goyal</keyname><forenames>Pawan</forenames></author><author><keyname>Mukherjee</keyname><forenames>Animesh</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Soumen</forenames></author></authors><title>Sic Transit Gloria Manuscriptum: Two Views of the Aggregate Fate of
  Ancient Papers</title><categories>cs.DL cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When PageRank began to be used for ranking in Web search, a concern soon
arose that older pages have an inherent --- and potentially unfair ---
advantage over emerging pages of high quality, because they have had more time
to acquire hyperlink citations. Algorithms were then proposed to compensate for
this effect. Curiously, in bibliometry, the opposite concern has often been
raised: that a growing body of recent papers crowds out older papers, resulting
in a collective amnesia in research communities, which potentially leads to
reinventions, redundancies, and missed opportunities to connect ideas. A recent
paper by Verstak et al. reported experiments on Google Scholar data, which
seemed to refute the amnesia, or aging, hypothesis. They claimed that more
recently written papers have a larger fraction of outbound citations targeting
papers that are older by a fixed number of years, indicating that ancient
papers are alive and well-loved and increasingly easily found, thanks in part
to Google Scholar. In this paper we show that the full picture is considerably
more nuanced. Specifically, the fate of a fixed sample of papers, as they age,
is rather different from what Verstak et al.'s study suggests: there is clear
and steady abandonment in favor of citations to newer papers. The two
apparently contradictory views are reconciled by the realization that, as time
passes, the number of papers older than a fixed number of years grows rapidly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08324</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08324</id><created>2015-11-26</created><authors><author><keyname>Guo</keyname><forenames>Xiujia</forenames></author><author><keyname>Chen</keyname><forenames>Haibo</forenames></author><author><keyname>Liu</keyname><forenames>Xuqin</forenames></author><author><keyname>Xu</keyname><forenames>Xiangyu</forenames></author><author><keyname>Chen</keyname><forenames>Zhong</forenames></author></authors><title>The Scale-free Network of Passwords : Visualization and Estimation of
  Empirical Passwords</title><categories>cs.CR</categories><comments>9 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a novel vision of large scale of empirical password
sets available and improve the understanding of passwords by revealing their
interconnections and considering the security on a level of the whole password
set instead of one single password level. Through the visualization of Yahoo,
Phpbb, 12306, etc. we, for the first time, show what the spatial structure of
empirical password sets are like and take the community and clustering patterns
of the passwords into account to shed lights on the definition of popularity of
a password based on their frequency and degree separately. Furthermore, we
propose a model of statistical guessing attack from the perspective of the
data's topological space, which provide an explanation of the &quot;cracking curve&quot;.
We also give a lower bound of the minimum size of the dictionary needed to
compromise arbitrary ratio of any given password set by proving that it is
equivalent to the minimum dominating set problem, which is a NP-complete
problem. Hence the minimal dictionary problem is also NP-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08327</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08327</id><created>2015-11-26</created><authors><author><keyname>Genuer</keyname><forenames>Robin</forenames><affiliation>ISPED,SISTM</affiliation></author><author><keyname>Poggi</keyname><forenames>Jean-Michel</forenames><affiliation>UPD5,LM-Orsay</affiliation></author><author><keyname>Tuleau-Malot</keyname><forenames>Christine</forenames><affiliation>JAD</affiliation></author><author><keyname>Villa-Vialaneix</keyname><forenames>Nathalie</forenames><affiliation>MIAT INRA</affiliation></author></authors><title>Random Forests for Big Data</title><categories>stat.ML cs.LG</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Big Data is one of the major challenges of statistical science and has
numerous consequences from algorithmic and theoretical viewpoints. Big Data
always involve massive data but they also often include data streams and data
heterogeneity. Recently some statistical methods have been adapted to process
Big Data, like linear regression models, clustering methods and bootstrapping
schemes. Based on decision trees combined with aggregation and bootstrap ideas,
random forests were introduced by Breiman in 2001. They are a powerful
nonparametric statistical method allowing to consider in a single and versatile
framework regression problems, as well as two-class and multi-class
classification problems. Focusing on classification problems, this paper
reviews available proposals about random forests in parallel environments as
well as about online random forests. Then, we formulate various remarks for
random forests in the Big Data context. Finally, we experiment three variants
involving subsampling, Big Data-bootstrap and MapReduce respectively, on two
massive datasets (15 and 120 millions of observations), a simulated one as well
as real world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08331</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08331</id><created>2015-11-26</created><authors><author><keyname>Zhang</keyname><forenames>Jianhui</forenames></author></authors><title>Value of Information Aware Opportunistic Duty Cycling in Solar
  Harvesting Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The energy-harvested Wireless Sensor Networks (WSNs) may operate perpetually
with the extra energy supply from ambient natural energy, such as solar energy.
Nevertheless, the harvested energy is still limited so it's not able to support
the perpetual network operation with full duty cycle. To achieve the perpetual
network operation and process the data with high importance, measured by Value
of Information (VoI), the network has to operate under partial duty cycle and
to improve the efficiency to consume the harvested energy. The challenging
problem is how to deal with the stochastic feature of the natural energy and
the variable data VoI. We consider the energy consumption during storing and
the diversity of the data process including sampling, transmitting and
receiving, which consume different power levels. The problem is then mapped as
the budget-dynamic Multi-Arm Bandit (MAB) problem by treating the energy as the
budget and the data process as arm pulling. This paper proposes an
Opportunistic Duty Cycling (ODC) scheme to improve the energy efficiency while
satisfying the perpetual network operation. ODC chooses the proper
opportunities to store the harvested energy or to spend it on the data process
based on the historical information of the energy harvesting and the VoI of the
processed data. With this scheme, each sensor node need only estimate the
ambient natural energy in short term so as to reduce the computation and the
storage for the historical information. It also can distributively adjust its
own duty cycle according to its local historical information. This paper also
conducts the extensive analysis on the performance of our scheme ODC, and the
theoretical results validate the regret, which is the difference between the
optimal scheme and ours. Our experimental results also manifest the promising
performance of ODC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08334</identifier>
 <datestamp>2016-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08334</id><created>2015-11-26</created><updated>2016-01-29</updated><authors><author><keyname>Bruy&#xe8;re</keyname><forenames>V&#xe9;ronique</forenames></author><author><keyname>Hautem</keyname><forenames>Quentin</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author></authors><title>On the complexity of heterogeneous multidimensional quantitative games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study two-player zero-sum turn-based games played on a
finite multidimensional weighted graph. In recent papers all dimensions use the
same measure, whereas here we allow to combine different measures. Such
heterogeneous multidimensional quantitative games provide a general and natural
model for the study of reactive system synthesis. We focus on classical
measures like the Inf, Sup, LimInf, and LimSup of the weights seen along the
play, as well as on the window mean-payoff (WMP) measure. This new measure is a
natural strengthening of the mean-payoff measure. We allow objectives defined
as Boolean combinations of heterogeneous constraints. While multidimensional
games with Boolean combinations of mean-payoff constraints are undecidable, we
show that the problem becomes EXPTIME-complete for DNF/CNF Boolean combinations
of heterogeneous measures taken among {WMP, Inf, Sup, LimInf, LimSup} and that
exponential memory strategies are sufficient for both players to win. We
provide a detailed study of the complexity and the memory requirements when the
Boolean combination of the measures is replaced by an intersection.
EXPTIME-completeness and exponential memory strategies still hold for the
intersection of measures in {WMP, Inf, Sup, LimInf, LimSup}, and we get
PSPACE-completeness when WMP measure is no longer considered. To avoid
EXPTIME-or PSPACE-hardness, we impose at most one occurrence of WMP measure and
fix the number of Sup measures, and we propose several refinements (on the
number of occurrences of the other measures) for which we get polynomial
algorithms and lower memory requirements. For all the considered classes of
games, we also study parameterized complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08336</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08336</id><created>2015-11-26</created><authors><author><keyname>Shao</keyname><forenames>Wenqin</forenames></author><author><keyname>Devienne</keyname><forenames>Francois</forenames></author><author><keyname>Iannone</keyname><forenames>Luigi</forenames></author><author><keyname>Rougier</keyname><forenames>Jean-Louis</forenames></author></authors><title>On the use of BGP communities for fine-grained inbound traffic
  engineering</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the context of Border Gateway Protocol (BGP), inbound inter-domain traffic
engineering (TE) remains a difficult problem without panacea. Each of
previously investigated method solves a part of the problem. In this study, we
try to complement the map by exploring the use of BGP communities. With BGP
community based polices enabled in transit provider networks, we are able to
manipulate incoming traffic for stub Autonomous System (AS) in a finer
granularity than known techniques by customizing the AS-paths perceived by
remote networks. We analyze the constraints using this technique, along with
its effectiveness and granularity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08342</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08342</id><created>2015-11-26</created><updated>2015-11-30</updated><authors><author><keyname>Zhou</keyname><forenames>Tianqing</forenames></author><author><keyname>Huang</keyname><forenames>Yongming</forenames></author><author><keyname>Yang</keyname><forenames>Luxi</forenames></author></authors><title>Energy-Efficient User Association with Open Loop Power Control for
  Uplink Heterogeneous Cellular Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy reduction for wireless systems becomes more and more important due to
its impact on the operation cost and global carbon footprint. In this paper, we
investigate three kinds of energy-efficient association schemes under open loop
power control for uplink heterogeneous cellular networks, which are formulated
as a whole energy efficiency maximization problem, a sum energy efficiency
maximization problem and a utility maximization problem respectively. The third
case takes account of load balancing level and user's fairness in the
energy-efficient association. Considering that the first problem is in a
fractional mixed-integer form, we introduce an energy efficiency parameter to
convert it into a parametric subtractive form, and then design an effective
iterative algorithm to achieve the optimal solutions. As for the third problem,
we first introduce a dual variable to decouple the constraint and then develop
a distributed algorithm using dual decomposition. In addition, we also give the
convergence proof for the proposed algorithms. In order to confirm the
effectiveness of energy-efficient user association algorithms, we introduce
other association rules for comparison, and investigate the influences of
different parameters on the association performance of these association rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08343</identifier>
 <datestamp>2016-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08343</id><created>2015-11-26</created><updated>2016-02-11</updated><authors><author><keyname>Hwang</keyname><forenames>Yunseong</forenames></author><author><keyname>Tong</keyname><forenames>Anh</forenames></author><author><keyname>Choi</keyname><forenames>Jaesik</forenames></author></authors><title>The Automatic Statistician: A Relational Perspective</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian Processes (GPs) provide a general and analytically tractable way of
modeling complex time-varying, nonparametric functions. The Automatic Bayesian
Covariance Discovery (ABCD) system constructs natural-language description of
time-series data by treating unknown time-series data nonparametrically using
GP with a composite covariance kernel function. Unfortunately, learning a
composite covariance kernel with a single time-series data set often results in
less informative kernel that may not give qualitative, distinctive descriptions
of data. We address this challenge by proposing two relational kernel learning
methods which can model multiple time-series data sets by finding common,
shared causes of changes. We show that the relational kernel learning methods
find more accurate models for regression problems on several real-world data
sets; US stock data, US house price index data and currency exchange rate data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08344</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08344</id><created>2015-11-26</created><authors><author><keyname>Shao</keyname><forenames>Wenqin</forenames></author><author><keyname>Iannone</keyname><forenames>Luigi</forenames></author><author><keyname>Rougier</keyname><forenames>Jean-Louis</forenames></author><author><keyname>Devienne</keyname><forenames>Francois</forenames></author><author><keyname>Viste</keyname><forenames>Mateusz</forenames></author></authors><title>Scalable BGP Prefix Selection for Effective Inter-domain Traffic
  Engineering</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inter-domain Traffic Engineering for multi-homed networks faces a scalability
challenge, as the size of BGP routing table continue to grow. In this context,
the choice of the best path must be made potentially for each destination
prefix, requiring all available paths to be characterised (e.g., through
measurements) and compared with each other. Fortunately, it is well-known that
a few number of prefixes carry the larger part of the traffic. As a natural
consequence, to engineer large volume of traffic only few prefixes need to be
managed. Yet, traffic characteristics of a given prefix can greatly vary over
time, and little is known on the dynamism of traffic at this aggregation level,
including predicting the set of the most significant prefixes in the near
future. %based on past observations. Sophisticated prediction methods won't
scale in such context. In this paper, we study the relationship between prefix
volume, stability, and predictability, based on recent traffic traces from nine
different networks. Three simple and resource-efficient methods to select the
prefixes associated with the most important foreseeable traffic volume are then
proposed. Such proposed methods allow to select sets of prefixes with both
excellent representativeness (volume coverage) and stability in time, for which
the best routes are identified. The analysis carried out confirm the potential
benefits of a route decision engine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08350</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08350</id><created>2015-11-26</created><authors><author><keyname>Kemmar</keyname><forenames>Amina</forenames></author><author><keyname>Loudni</keyname><forenames>Samir</forenames></author><author><keyname>Lebbah</keyname><forenames>Yahia</forenames></author><author><keyname>Boizumault</keyname><forenames>Patrice</forenames></author><author><keyname>Charnois</keyname><forenames>Thierry</forenames></author></authors><title>A global Constraint for mining Sequential Patterns with GAP constraint</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential pattern mining (SPM) under gap constraint is a challenging task.
Many efficient specialized methods have been developed but they are all
suffering from a lack of genericity. The Constraint Programming (CP) approaches
are not so effective because of the size of their encodings. In[7], we have
proposed the global constraint Prefix-Projection for SPM which remedies to this
drawback. However, this global constraint cannot be directly extended to
support gap constraint. In this paper, we propose the global constraint GAP-SEQ
enabling to handle SPM with or without gap constraint. GAP-SEQ relies on the
principle of right pattern extensions. Experiments show that our approach
clearly outperforms both CP approaches and the state-of-the-art cSpade method
on large datasets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08355</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08355</id><created>2015-11-26</created><authors><author><keyname>Yu</keyname><forenames>Jihong</forenames></author><author><keyname>Chen</keyname><forenames>Lin</forenames></author></authors><title>From Static to Dynamic Tag Population Estimation: An Extended Kalman
  Filter Perspective</title><categories>cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tag population estimation has recently attracted significant research
attention due to its paramount importance on a variety of radio frequency
identification (RFID) applications. However, most, if not all, of existing
estimation mechanisms are proposed for the static case where tag population
remains constant during the estimation process, thus leaving the more
challenging dynamic case unaddressed, despite the fundamental importance of the
latter case on both theoretical analysis and practical application. In order to
bridge this gap, %based on \textit{dynamic framed-slotted ALOHA} (DFSA)
protocol, we devote this paper to designing a generic framework of stable and
accurate tag population estimation schemes based on Kalman filter for both
static and dynamic RFID systems. %The objective is to devise estimation schemes
and analyze the boundedness of estimation error. Technically, we first model
the dynamics of RFID systems as discrete stochastic processes and leverage the
techniques in extended Kalman filter (EKF) and cumulative sum control chart
(CUSUM) to estimate tag population for both static and dynamic systems. By
employing Lyapunov drift analysis, we mathematically characterise the
performance of the proposed framework in terms of estimation accuracy and
convergence speed by deriving the closed-form conditions on the design
parameters under which our scheme can stabilise around the real population size
with bounded relative estimation error that tends to zero with exponential
convergence rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08366</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08366</id><created>2015-11-26</created><authors><author><keyname>Kapanova</keyname><forenames>K. G.</forenames></author><author><keyname>Dimov</keyname><forenames>I.</forenames></author><author><keyname>Sellier</keyname><forenames>J. M.</forenames></author></authors><title>On randomization of neural networks as a form of post-learning strategy</title><categories>cs.NE</categories><comments>15 pages, 26 figures</comments><doi>10.1007/s00500-015-1949-1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today artificial neural networks are applied in various fields - engineering,
data analysis, robotics. While they represent a successful tool for a variety
of relevant applications, mathematically speaking they are still far from being
conclusive. In particular, they suffer from being unable to find the best
configuration possible during the training process (local minimum problem). In
this paper, we focus on this issue and suggest a simple, but effective,
post-learning strategy to allow the search for improved set of weights at a
relatively small extra computational cost. Therefore, we introduce a novel
technique based on analogy with quantum effects occurring in nature as a way to
improve (and sometimes overcome) this problem. Several numerical experiments
are presented to validate the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08367</identifier>
 <datestamp>2016-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08367</id><created>2015-11-26</created><authors><author><keyname>Berche</keyname><forenames>Bertrand</forenames></author><author><keyname>Holovatch</keyname><forenames>Yurij</forenames></author><author><keyname>Kenna</keyname><forenames>Ralph</forenames></author><author><keyname>Mryglod</keyname><forenames>Olesya</forenames></author></authors><title>Academic research groups: evaluation of their quality and quality of
  their evaluation</title><categories>physics.soc-ph cs.DL</categories><comments>Presented at the International Conference on Computer Simulation in
  Physics and Beyond in Moscow, 2015. The Proceedings will appear in Journal of
  Physics: Conference Series (JPCS)</comments><doi>10.1088/1742-6596/681/1/012004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, evaluation of the quality of academic research has become an
increasingly important and influential business. It determines, often to a
large extent, the amount of research funding flowing into universities and
similar institutes from governmental agencies and it impacts upon academic
careers. Policy makers are becoming increasingly reliant upon, and influenced
by, the outcomes of such evaluations. In response, university managers are
increasingly attracted to simple indicators as guides to the dynamics of the
positions of their various institutions in league tables. However, these league
tables are frequently drawn up by inexpert bodies such as newspapers and
magazines, using rather arbitrary measures and criteria. Terms such as
&quot;critical mass' and &quot;metrics&quot; are often bandied about without proper
understanding of what they actually mean. Rather than accepting the rise and
fall of universities, departments and individuals on a turbulent sea of
arbitrary measures, we suggest it is incumbent upon the scientific community
itself to clarify their nature. Here we report on recent attempts to do that by
properly defining critical mass and showing how group size influences research
quality. We also examine currently predominant metrics and show that these fail
as reliable indicators of group research quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08386</identifier>
 <datestamp>2016-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08386</id><created>2015-11-26</created><updated>2016-02-06</updated><authors><author><keyname>Bagan</keyname><forenames>Guillaume</forenames></author><author><keyname>Bonifati</keyname><forenames>Angela</forenames></author><author><keyname>Ciucanu</keyname><forenames>Radu</forenames></author><author><keyname>Fletcher</keyname><forenames>George H. L.</forenames></author><author><keyname>Lemay</keyname><forenames>Aur&#xe9;lien</forenames></author><author><keyname>Advokaat</keyname><forenames>Nicky</forenames></author></authors><title>gMark: Controlling Workload Diversity in Benchmarking Graph Databases</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Massive graph data sets are pervasive in contemporary application domains.
Hence, graph database systems are becoming increasingly important. In the study
of these systems, it is vital that the research community has shared
benchmarking solutions for the generation of database instances and query
workloads having predictable and controllable properties. Similarly to TPC
benchmarks for relational databases, benchmarks for graph databases have been
important drivers for the Semantic Web and graph data management communities.
In this paper, we present the design and engineering principles of gMark, a
domain- and query language-independent graph benchmark exhibiting flexible
schema and workload chokepoints. A core contribution of gMark is its ability to
target and control the diversity of properties of both the generated graph
instances and the generated query workloads coupled to these instances. A
further novelty is the support of recursive regular path queries, a fundamental
graph query paradigm. We illustrate the flexibility and practical usability of
gMark by showcasing the framework's capabilities in generating high quality
graphs and workloads, and its ability to encode user-defined schemas across a
variety of application domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08396</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08396</id><created>2015-11-26</created><updated>2015-12-02</updated><authors><author><keyname>Vorel</keyname><forenames>Vojt&#x11b;ch</forenames></author></authors><title>On Basic Properties of Jumping Finite Automata</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We complete the initial study of jumping finite automata, which was started
in a former article of Meduna and Zemek \citep{athMED1}. The open questions
about basic closure properties are solved. Besides this, we correct erroneous
results presented in the article. Finally, we point out important relations
between jumping finite automata and some other models studied in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08399</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08399</id><created>2015-11-26</created><authors><author><keyname>Labb&#xe9;</keyname><forenames>S&#xe9;bastien</forenames></author></authors><title>$3$-dimensional Continued Fraction Algorithms Cheat Sheets</title><categories>math.DS cs.FL</categories><comments>9 pages, 66 figures, landscape orientation</comments><msc-class>11J70, 37A45, 52C35, 68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multidimensional Continued Fraction Algorithms are generalizations of the
Euclid algorithm and find iteratively the gcd of two or more numbers. They are
defined as linear applications on some subcone of $\mathbb{R}^d$. We consider
multidimensional continued fraction algorithms that acts symmetrically on the
positive cone $\mathbb{R}^d_+$ for $d=3$. We include well-known and old ones
(Poincar\'e, Brun, Selmer, Fully Subtractive) and new ones
(Arnoux-Rauzy-Poincar\'e, Reverse, Cassaigne).
  For each algorithm, one page (called cheat sheet) gathers a handful of
informations most of them generated with the open source software Sage with the
optional Sage package \texttt{slabbe-0.2.spkg}. The information includes the
$n$-cylinders, density function of an absolutely continuous invariant measure,
domain of the natural extension, lyapunov exponents as well as data regarding
combinatorics on words, symbolic dynamics and digital geometry, that is,
associated substitutions, generated $S$-adic systems, factor complexity,
discrepancy, dual substitutions and generation of digital planes.
  The document ends with a table of comparison of Lyapunov exponents and gives
the code allowing to reproduce any of the results or figures appearing in these
cheat sheets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08400</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08400</id><created>2015-11-26</created><updated>2016-03-02</updated><authors><author><keyname>Krueger</keyname><forenames>David</forenames></author><author><keyname>Memisevic</keyname><forenames>Roland</forenames></author></authors><title>Regularizing RNNs by Stabilizing Activations</title><categories>cs.NE cs.CL cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We stabilize the activations of Recurrent Neural Networks (RNNs) by
penalizing the squared distance between successive hidden states' norms. This
penalty term is an effective regularizer for RNNs including LSTMs and IRNNs,
improving performance on character-level language modelling and phoneme
recognition, and outperforming weight noise and dropout. We set state of the
art (17.5% PER) for an RNN on the TIMIT phoneme recognition task, without using
beam-search. With this penalty term, IRNN can achieve similar performance to
LSTM on language modelling, although adding the penalty term to the LSTM
results in superior performance. Our penalty term also prevents the exponential
growth of IRNN's activations outside of their training horizon, allowing them
to generalize to much longer sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08403</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08403</id><created>2015-11-26</created><updated>2015-12-02</updated><authors><author><keyname>Schaudt</keyname><forenames>Oliver</forenames></author><author><keyname>Weil</keyname><forenames>Vera</forenames></author></authors><title>On bounding the difference between the maximum degree and the chromatic
  number by a constant</title><categories>cs.DM math.CO</categories><comments>11 pages, 3 figures</comments><msc-class>05C15, 05C17, 05C69, 05C75</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For every $k \in \mathbb{N}_0$, we consider graphs $G$ where for every
induced subgraph $H$ of $G$, $\Delta(H) \leq \chi(H) -1 + k$ holds, where
$\Delta(H)$ is the maximum degree and $\chi(H)$ is the chromatic number of the
subgraph $H$. Let us call this family of graphs~$\varUpsilon_k$. We give a
finite forbidden induced subgraph characterization of $\varUpsilon_k$ for every
$k$.
  We compare these results with those given in On bounding the difference
between the maximum degree and the clique number, Graphs and Combinatorics
31(5): 1689-1702 (2015), where we studied the graphs in which for any induced
subgraph $H$, $\Delta(H) \leq \omega(H) -1 + k$ holds, where $\omega(H)$
denotes the clique number of a graph.
  In particular, we introduce the class of neighborhood perfect graphs, that
is, those graphs where the neighborhood of every vertex is perfect. We find a
nice characterization of this graph class in terms of $\varOmega_k$ and
$\varUpsilon_k$: We prove that a graph $G$ is a neighborhood perfect graph if
and only if for every induced subgraph $H$ of $G$, $H \in \varUpsilon_k$ if and
only if $H \in \varOmega_k$ for all $k \in \mathbb{N}_0$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08405</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08405</id><created>2015-11-26</created><authors><author><keyname>Kwon</keyname><forenames>Joon</forenames></author><author><keyname>Perchet</keyname><forenames>Vianney</forenames></author></authors><title>Gains and Losses are Fundamentally Different in Regret Minimization: The
  Sparse Case</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate that, in the classical non-stochastic regret minimization
problem with $d$ decisions, gains and losses to be respectively maximized or
minimized are fundamentally different. Indeed, by considering the additional
sparsity assumption (at each stage, at most $s$ decisions incur a nonzero
outcome), we derive optimal regret bounds of different orders. Specifically,
with gains, we obtain an optimal regret guarantee after $T$ stages of order
$\sqrt{T\log s}$, so the classical dependency in the dimension is replaced by
the sparsity size. With losses, we provide matching upper and lower bounds of
order $\sqrt{Ts\log(d)/d}$, which is decreasing in $d$. Eventually, we also
study the bandit setting, and obtain an upper bound of order $\sqrt{Ts\log
(d/s)}$ when outcomes are losses. This bound is proven to be optimal up to the
logarithmic factor $\sqrt{\log(d/s)}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08407</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08407</id><created>2015-11-26</created><updated>2015-12-18</updated><authors><author><keyname>Tian</keyname><forenames>Ran</forenames></author><author><keyname>Okazaki</keyname><forenames>Naoaki</forenames></author><author><keyname>Inui</keyname><forenames>Kentaro</forenames></author></authors><title>The Mechanism of Additive Composition</title><categories>cs.CL cs.LG</categories><comments>Submitted to Journal of Machine Learning Research; Under Review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove an upper bound for the bias of additive composition (Foltz et al.,
1998; Landauer and Dutnais, 1997; Mitchell and Lapata, 2010), a widely used
method for computing meanings of phrases by averaging the vector
representations of their constituent words. The result endorses additive
composition as a reasonable operation for calculating meanings of phrases,
which is the first theoretical analysis on compositional frameworks from a
machine learning point of view. The theory also suggests ways to improve
additive compositionality, including: transforming entries of distributional
word vectors by a function that meets a specific condition, constructing a
novel type of vector representations to make additive composition sensitive to
word order, and utilizing singular value decomposition to train word vectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08410</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08410</id><created>2015-11-26</created><authors><author><keyname>Chialina</keyname><forenames>Silvano</forenames></author><author><keyname>Cicuttin</keyname><forenames>Matteo</forenames></author><author><keyname>Codecasa</keyname><forenames>Lorenzo</forenames></author><author><keyname>Solari</keyname><forenames>Giovanni</forenames></author><author><keyname>Specogna</keyname><forenames>Ruben</forenames></author><author><keyname>Trevisan</keyname><forenames>Francesco</forenames></author></authors><title>Modeling of anechoich chambers with equivalent materials and equivalent
  sources</title><categories>cs.CE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Numerical simulation of anechoic chambers is a hot topic since it can provide
useful data about the performance of the EMC site. However, the mathematical
nature of the problem, the physical dimensions of the simulated sites and the
frequency ranges pose nontrivial challenges to the simulation. Computational
requirements in particular will quickly become unmanageable if adequate
techniques are not employed. In this work we describe a novel approach, based
on equivalent elements, that enables the simulation of large chambers with
modest computational resources. The method is then validated against real
measurement results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08411</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08411</id><created>2015-11-26</created><authors><author><keyname>Bayomi</keyname><forenames>Mostafa</forenames></author><author><keyname>Levacher</keyname><forenames>Killian</forenames></author><author><keyname>Ghorab</keyname><forenames>M. Rami</forenames></author><author><keyname>Lawless</keyname><forenames>S&#xe9;amus</forenames></author></authors><title>OntoSeg: a Novel Approach to Text Segmentation using Ontological
  Similarity</title><categories>cs.CL</categories><comments>10 pages, IEEE ICDMW 2015 (SENTIRE Workshop)</comments><doi>10.1109/ICDMW.2015.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Text segmentation (TS) aims at dividing long text into coherent segments
which reflect the subtopic structure of the text. It is beneficial to many
natural language processing tasks, such as Information Retrieval (IR) and
document summarisation. Current approaches to text segmentation are similar in
that they all use word-frequency metrics to measure the similarity between two
regions of text, so that a document is segmented based on the lexical cohesion
between its words. Various NLP tasks are now moving towards the semantic web
and ontologies, such as ontology-based IR systems, to capture the
conceptualizations associated with user needs and contents. Text segmentation
based on lexical cohesion between words is hence not sufficient anymore for
such tasks. This paper proposes OntoSeg, a novel approach to text segmentation
based on the ontological similarity between text blocks. The proposed method
uses ontological similarity to explore conceptual relations between text
segments and a Hierarchical Agglomerative Clustering (HAC) algorithm to
represent the text as a tree-like hierarchy that is conceptually structured.
The rich structure of the created tree further allows the segmentation of text
in a linear fashion at various levels of granularity. The proposed method was
evaluated on a wellknown dataset, and the results show that using ontological
similarity in text segmentation is very promising. Also we enhance the proposed
method by combining ontological similarity with lexical similarity and the
results show an enhancement of the segmentation quality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08412</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08412</id><created>2015-11-26</created><updated>2015-12-01</updated><authors><author><keyname>Botoeva</keyname><forenames>Elena</forenames></author><author><keyname>Calvanese</keyname><forenames>Diego</forenames></author><author><keyname>Santarelli</keyname><forenames>Valerio</forenames></author><author><keyname>Savo</keyname><forenames>Domenico Fabio</forenames></author><author><keyname>Solimando</keyname><forenames>Alessandro</forenames></author><author><keyname>Xiao</keyname><forenames>Guohui</forenames></author></authors><title>Beyond OWL 2 QL in OBDA: Rewritings and Approximations (Extended
  Version)</title><categories>cs.AI</categories><comments>The extended version of the AAAI 2016 paper &quot;Beyond OWL 2 QL in OBDA:
  Rewritings and Approximations&quot; by Elena Botoeva, Diego Calvanese, Valerio
  Santarelli, Domenico Fabio Savo, Alessandro Solimando,and Guohui Xiao</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ontology-based data access (OBDA) is a novel paradigm facilitating access to
relational data, realized by linking data sources to an ontology by means of
declarative mappings. DL-Lite_R, which is the logic underpinning the W3C
ontology language OWL 2 QL and the current language of choice for OBDA, has
been designed with the goal of delegating query answering to the underlying
database engine, and thus is restricted in expressive power. E.g., it does not
allow one to express disjunctive information, and any form of recursion on the
data. The aim of this paper is to overcome these limitations of DL-Lite_R, and
extend OBDA to more expressive ontology languages, while still leveraging the
underlying relational technology for query answering. We achieve this by
relying on two well-known mechanisms, namely conservative rewriting and
approximation, but significantly extend their practical impact by bringing into
the picture the mapping, an essential component of OBDA. Specifically, we
develop techniques to rewrite OBDA specifications with an expressive ontology
to &quot;equivalent&quot; ones with a DL-Lite_R ontology, if possible, and to approximate
them otherwise. We do so by exploiting the high expressive power of the mapping
layer to capture part of the domain semantics of rich ontology languages. We
have implemented our techniques in the prototype system OntoProx, making use of
the state-of-the-art OBDA system Ontop and the query answering system Clipper,
and we have shown their feasibility and effectiveness with experiments on
synthetic and real-world data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08413</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08413</id><created>2015-11-26</created><authors><author><keyname>Puchinger</keyname><forenames>Sven</forenames></author><author><keyname>M&#xfc;elich</keyname><forenames>Sven</forenames></author><author><keyname>Ishak</keyname><forenames>Karim</forenames></author><author><keyname>Bossert</keyname><forenames>Martin</forenames></author></authors><title>Code-Based Cryptosystems Using Generalized Concatenated Codes</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to Springer Proceedings in Mathematics &amp; Statistics,
  special issue devoted to the conference Application of Computer Algebra (ACA)
  2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The security of public-key cryptosystems is mostly based on number theoretic
problems like factorization and the discrete logarithm. There exists an
algorithm which solves these problems in polynomial time using a quantum
computer. Hence, these cryptosystems will be broken as soon as quantum
computers emerge. Code-based cryptography is an alternative which resists
quantum computers since its security is based on an NP-complete problem, namely
decoding of random linear codes. The McEliece cryptosystem is the most
prominent scheme to realize code-based cryptography. Many codeclasses were
proposed for the McEliece cryptosystem, but most of them are broken by now.
Sendrier suggested to use ordinary concatenated codes, however, he also
presented an attack on such codes. This work investigates generalized
concatenated codes to be used in the McEliece cryptosystem. We examine the
application of Sendrier's attack on generalized concatenated codes and present
alternative methods for both partly finding the code structure and recovering
the plaintext from a cryptogram. Further, we discuss modifications of the
cryptosystem making it resistant against these attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08414</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08414</id><created>2015-11-26</created><authors><author><keyname>Matsumura</keyname><forenames>Tetsuro</forenames></author><author><keyname>Kuramitsu</keyname><forenames>Kimio</forenames></author></authors><title>A declarative extension of parsing expression grammars for recognizing
  most programming languages</title><categories>cs.PL</categories><comments>To appear in Journal of Information Processing, 24(2), 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Parsing Expression Grammars are a popular foundation for describing syntax.
Unfortunately, several syntax of programming languages are still hard to
recognize with pure PEGs. Notorious cases appears: typedef-defined names in
C/C++, indentation-based code layout in Python, and HERE document in many
scripting languages. To recognize such PEG-hard syntax, we have addressed a
declarative extension to PEGs. The &quot;declarative&quot; extension means no programmed
semantic actions, which are traditionally used to realize the extended parsing
behavior. Nez is our extended PEG language, including symbol tables and
conditional parsing. This paper demonstrates that the use of Nez Extensions can
realize many practical programming languages, such as C, C\#, Ruby, and Python,
which involve PEG-hard syntax.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08416</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08416</id><created>2015-11-26</created><authors><author><keyname>Kim</keyname><forenames>Michael P.</forenames></author><author><keyname>Suksompong</keyname><forenames>Warut</forenames></author><author><keyname>Williams</keyname><forenames>Virginia Vassilevska</forenames></author></authors><title>Who Can Win a Single-Elimination Tournament?</title><categories>cs.GT</categories><comments>To appear in the 30th AAAI Conference on Artificial Intelligence,
  2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A single-elimination (SE) tournament is a popular way to select a winner in
both sports competitions and in elections. A natural and well-studied question
is the tournament fixing problem (TFP): given the set of all pairwise match
outcomes, can a tournament organizer rig an SE tournament by adjusting the
initial seeding so that their favorite player wins? We prove new sufficient
conditions on the pairwise match outcome information and the favorite player,
under which there is guaranteed to be a seeding where the player wins the
tournament. Our results greatly generalize previous results. We also
investigate the relationship between the set of players that can win an SE
tournament under some seeding (so called SE winners) and other traditional
tournament solutions. In addition, we generalize and strengthen prior work on
probabilistic models for generating tournaments. For instance, we show that
\emph{every} player in an $n$ player tournament generated by the Condorcet
Random Model will be an SE winner even when the noise is as small as possible,
$p=\Theta(\ln n/n)$; prior work only had such results for $p\geq
\Omega(\sqrt{\ln n/n})$. We also establish new results for significantly more
general generative models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08417</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08417</id><created>2015-11-26</created><authors><author><keyname>Cao</keyname><forenames>Ziqiang</forenames></author><author><keyname>Chen</keyname><forenames>Chengyao</forenames></author><author><keyname>Li</keyname><forenames>Wenjie</forenames></author><author><keyname>Li</keyname><forenames>Sujian</forenames></author><author><keyname>Wei</keyname><forenames>Furu</forenames></author><author><keyname>Zhou</keyname><forenames>Ming</forenames></author></authors><title>TGSum: Build Tweet Guided Multi-Document Summarization Dataset</title><categories>cs.IR cs.CL</categories><comments>7 pages, 1 figure in AAAI 2016</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  The development of summarization research has been significantly hampered by
the costly acquisition of reference summaries. This paper proposes an effective
way to automatically collect large scales of news-related multi-document
summaries with reference to social media's reactions. We utilize two types of
social labels in tweets, i.e., hashtags and hyper-links. Hashtags are used to
cluster documents into different topic sets. Also, a tweet with a hyper-link
often highlights certain key points of the corresponding document. We
synthesize a linked document cluster to form a reference summary which can
cover most key points. To this aim, we adopt the ROUGE metrics to measure the
coverage ratio, and develop an Integer Linear Programming solution to discover
the sentence set reaching the upper bound of ROUGE. Since we allow summary
sentences to be selected from both documents and high-quality tweets, the
generated reference summaries could be abstractive. Both informativeness and
readability of the collected summaries are verified by manual judgment. In
addition, we train a Support Vector Regression summarizer on DUC generic
multi-document summarization benchmarks. With the collected data as extra
training resource, the performance of the summarizer improves a lot on all the
test sets. We release this dataset for further research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08418</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08418</id><created>2015-11-26</created><authors><author><keyname>Oliver</keyname><forenames>Maria</forenames></author><author><keyname>Haro</keyname><forenames>Gloria</forenames></author><author><keyname>Dimiccoli</keyname><forenames>Mariella</forenames></author><author><keyname>Mazin</keyname><forenames>Baptiste</forenames></author><author><keyname>Ballester</keyname><forenames>Coloma</forenames></author></authors><title>A Computational Model for Amodal Completion</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a computational model to recover the most likely
interpretation of the 3D scene structure from a planar image, where some
objects may occlude others. The estimated scene interpretation is obtained by
integrating some global and local cues and provides both the complete
disoccluded objects that form the scene and their ordering according to depth.
Our method first computes several distal scenes which are compatible with the
proximal planar image. To compute these different hypothesized scenes, we
propose a perceptually inspired object disocclusion method, which works by
minimizing the Euler's elastica as well as by incorporating the relatability of
partially occluded contours and the convexity of the disoccluded objects. Then,
to estimate the preferred scene we rely on a Bayesian model and define
probabilities taking into account the global complexity of the objects in the
hypothesized scenes as well as the effort of bringing these objects in their
relative position in the planar image, which is also measured by an Euler's
elastica-based quantity. The model is illustrated with numerical experiments
on, both, synthetic and real images showing the ability of our model to
reconstruct the occluded objects and the preferred perceptual order among them.
We also present results on images of the Berkeley dataset with provided
figure-ground ground-truth labeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08431</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08431</id><created>2015-11-26</created><updated>2015-12-07</updated><authors><author><keyname>Fici</keyname><forenames>Gabriele</forenames></author><author><keyname>Kociumaka</keyname><forenames>Tomasz</forenames></author><author><keyname>Radoszewski</keyname><forenames>Jakub</forenames></author><author><keyname>Rytter</keyname><forenames>Wojciech</forenames></author><author><keyname>Wale&#x144;</keyname><forenames>Tomasz</forenames></author></authors><title>On the Greedy Algorithm for the Shortest Common Superstring Problem with
  Reversals</title><categories>cs.DS</categories><comments>Published in Information Processing Letters</comments><doi>10.1016/j.ipl.2015.11.015</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a variation of the classical Shortest Common Superstring (SCS)
problem in which a shortest superstring of a finite set of strings $S$ is
sought containing as a factor every string of $S$ or its reversal. We call this
problem Shortest Common Superstring with Reversals (SCS-R). This problem has
been introduced by Jiang et al., who designed a greedy-like algorithm with
length approximation ratio $4$. In this paper, we show that a natural
adaptation of the classical greedy algorithm for SCS has (optimal) compression
ratio $\frac12$, i.e., the sum of the overlaps in the output string is at least
half the sum of the overlaps in an optimal solution. We also provide a
linear-time implementation of our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08435</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08435</id><created>2015-11-26</created><authors><author><keyname>Zhu</keyname><forenames>Jingge</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>Typical sumsets of linear codes</title><categories>cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given two identical linear codes $\mathcal C$ over $\mathbb F_q$ of length
$n$, we independently pick one codeword from each codebook uniformly at random.
A $\textit{sumset}$ is formed by adding these two codewords entry-wise as
integer vectors and a sumset is called $\textit{typical}$, if the sum falls
inside this set with high probability. We ask the question: how large is the
typical sumset for most codes? In this paper we characterize the asymptotic
size of such typical sumset. We show that when the rate $R$ of the linear code
is below a certain threshold $D$, the typical sumset size is roughly $|\mathcal
C|^2=2^{2nR}$ for most codes while when $R$ is above this threshold, most codes
have a typical sumset whose size is roughly $|\mathcal C|\cdot
2^{nD}=2^{n(R+D)}$ due to the linear structure of the codes. The threshold $D$
depends solely on the alphabet size $q$ and takes value in $[1/2, \log
\sqrt{e})$. More generally, we completely characterize the asymptotic size of
typical sumsets of two nested linear codes $\mathcal C_1, \mathcal C_2$ with
different rates. As an application of the result, we study the communication
problem where the integer sum of two codewords is to be decoded through a
general two-user multiple-access channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08446</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08446</id><created>2015-11-26</created><authors><author><keyname>Ghodrati</keyname><forenames>Amir</forenames></author><author><keyname>Jia</keyname><forenames>Xu</forenames></author><author><keyname>Pedersoli</keyname><forenames>Marco</forenames></author><author><keyname>Tuytelaars</keyname><forenames>Tinne</forenames></author></authors><title>Towards Automatic Image Editing: Learning to See another You</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning the distribution of images in order to generate new samples is a
challenging task due to the high dimensionality of the data and the highly
non-linear relations that are involved. Nevertheless, some promising results
have been reported in the literature recently,building on deep network
architectures. In this work, we zoom in on a specific type of image generation:
given an image and knowing the category of objects it belongs to (e.g. faces),
our goal is to generate a similar and plausible image, but with some altered
attributes. This is particularly challenging, as the model needs to learn to
disentangle the effect of each attribute and to apply a desired attribute
change to a given input image, while keeping the other attributes and overall
object appearance intact. To this end, we learn a convolutional network, where
the desired attribute information is encoded then merged with the encoded image
at feature map level. We show promising results, both qualitatively as well as
quantitatively, in the context of a retrieval experiment, on two face datasets
(MultiPie and CAS-PEAL-R1).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08447</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08447</id><created>2015-11-26</created><authors><author><keyname>Dongol</keyname><forenames>Brijesh</forenames></author><author><keyname>Hierons</keyname><forenames>Robert M.</forenames></author></authors><title>Decidability and Complexity for Quiescent Consistency and its Variations</title><categories>cs.LO cs.DC cs.DS cs.FL</categories><acm-class>D.2.4; D.3.1; F.3.1; H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quiescent consistency is a notion of correctness for a concurrent object that
gives meaning to the object's behaviours in quiescent states, i.e., states in
which none of the object's operations are being executed. Correctness of an
implementation object is defined in terms of a corresponding abstract
specification. This gives rise to two important verification questions:
membership (checking whether a behaviour of the implementation is allowed by
the specification) and correctness (checking whether all behaviours of the
implementation are allowed by the specification). In this paper, we show that
the membership problem for quiescent consistency is NP-complete and that the
correctness problem is decidable, but coNP-hard and in EXPSPACE. For both
problems, we consider restricted versions of quiescent consistency by assuming
an upper limit on the number of events between two quiescent points. Here, we
show that the membership problem is in PTIME, whereas correctness is in PSPACE.
  Quiescent consistency does not guarantee sequential consistency, i.e., it
allows operation calls by the same process to be reordered when mapping to an
abstract specification. Therefore, we also consider quiescent sequential
consistency, which strengthens quiescent consistency with an additional
sequential consistency condition. We show that the unrestricted versions of
membership and correctness are NP-complete and undecidable, respectively. When
by placing a limit on the number of events between two quiescent points,
membership is in PTIME, while correctness is in PSPACE. Finally, we consider a
version of quiescent sequential consistency that places an upper limit on the
number of processes for every run of the implementation, and show that the
membership problem for quiescent sequential consistency with this restriction
is in PTIME.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08456</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08456</id><created>2015-11-26</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Chmelik</keyname><forenames>Martin</forenames></author><author><keyname>Davies</keyname><forenames>Jessica</forenames></author></authors><title>A Symbolic SAT-based Algorithm for Almost-sure Reachability with Small
  Strategies in POMDPs</title><categories>cs.AI</categories><comments>Full version of &quot;A Symbolic SAT-based Algorithm for Almost-sure
  Reachability with Small Strategies in POMDPs&quot; AAAI 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  POMDPs are standard models for probabilistic planning problems, where an
agent interacts with an uncertain environment. We study the problem of
almost-sure reachability, where given a set of target states, the question is
to decide whether there is a policy to ensure that the target set is reached
with probability 1 (almost-surely). While in general the problem is
EXPTIME-complete, in many practical cases policies with a small amount of
memory suffice. Moreover, the existing solution to the problem is explicit,
which first requires to construct explicitly an exponential reduction to a
belief-support MDP. In this work, we first study the existence of
observation-stationary strategies, which is NP-complete, and then small-memory
strategies. We present a symbolic algorithm by an efficient encoding to SAT and
using a SAT solver for the problem. We report experimental results
demonstrating the scalability of our symbolic (SAT-based) approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08458</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08458</id><created>2015-11-26</created><updated>2015-12-02</updated><authors><author><keyname>O'Shea</keyname><forenames>Keiron</forenames></author><author><keyname>Nash</keyname><forenames>Ryan</forenames></author></authors><title>An Introduction to Convolutional Neural Networks</title><categories>cs.NE cs.CV cs.LG</categories><comments>10 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The field of machine learning has taken a dramatic twist in recent times,
with the rise of the Artificial Neural Network (ANN). These biologically
inspired computational models are able to far exceed the performance of
previous forms of artificial intelligence in common machine learning tasks. One
of the most impressive forms of ANN architecture is that of the Convolutional
Neural Network (CNN). CNNs are primarily used to solve difficult image-driven
pattern recognition tasks and with their precise yet simple architecture,
offers a simplified method of getting started with ANNs.
  This document provides a brief introduction to CNNs, discussing recently
published papers and newly formed techniques in developing these brilliantly
fantastic image recognition models. This introduction assumes you are familiar
with the fundamentals of ANNs and machine learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08464</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08464</id><created>2015-11-26</created><authors><author><keyname>Nevelsteen</keyname><forenames>Kim J. L.</forenames></author></authors><title>'Virtual World', Defined from a Technological Perspective, and Applied
  to Video Games, Mixed Reality and the Metaverse</title><categories>cs.HC cs.CY</categories><comments>36 pages, 2 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/4.0/</license><abstract>  There is no generally accepted definition for a virtual world, with many
complimentary terms and acronyms having emerged implying a virtual world.
Advances in systems architecture techniques such as, host migration between
instances, mobile ad-hoc networking, and distributed computing, bring in to
question whether those architectures can actually support a virtual world.
Without a concrete definition, controversy ensues and it is problematic to
design an architecture for a virtual world. Several researchers provided a
definition but aspects of each definition are still problematic and simply can
not be applied to contemporary technologies. The approach of this article is to
sample technologies using grounded theory, and obtain a definition for a
`virtual world' that is directly applicable to technology. The obtained
definition is compared with related work and used to classify advanced
technologies, such as: a pseudo-persistent video game, a MANet, Virtual and
Mixed Reality, and the Metaverse. The results of this article include: a break
down of which properties set apart the various technologies; a definition that
is validated by comparing it with other definitions; an ontology showing the
relation of the different complimentary terms and acronyms; and, the usage of
pseudo-persistence to categories those technologies which only mimic
persistence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08474</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08474</id><created>2015-11-26</created><authors><author><keyname>Monemi</keyname><forenames>Mehdi</forenames></author><author><keyname>Rasti</keyname><forenames>Mehdi</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author></authors><title>On Characterization of Feasible Interference Regions in Cognitive Radio
  Networks</title><categories>cs.NI</categories><comments>IEEE Transactions on Communications, under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the state-of-the-art interference management schemes for underlay CRNs, it
is considered that all PUs are protected if the cognitive interference for each
primary receiving-point is lower than a maximum threshold, the so called
interference temperature limit (ITL) for the corresponding receiving-point.
This is assumed to be fixed and independent of ITL values for other primary
receiving-points, which corresponds to a box-like FCIR. In this paper, we
characterize the FCIR for {\em uplink} transmissions in cellular CRNs and for
direct transmissions in ad-hoc CRNs. We show that the FCIR is in fact a
polyhedron (i.e., the maximum feasible cognitive interference threshold for
each primary receiving-point is not a constant, and it depends on that for the
other primary receiving-points). Therefore, in practical interference
management algorithms, it is not proper to consider a constant and independent
ITL value for each of the primary receiving-points. This finding would
significantly affect the design of practical interference management schemes
for CRNs. To demonstrate this, based on the characterized FCIR, we propose two
power control algorithms to find the maximum number of admitted SUs and the
maximum aggregate throughput of the SUs in infeasible and feasible CRNs,
respectively. For two distinct objectives, our proposed interference management
schemes outperform the existing ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08476</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08476</id><created>2015-11-26</created><authors><author><keyname>Monemi</keyname><forenames>Mehdi</forenames></author><author><keyname>Rasti</keyname><forenames>Mehdi</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author></authors><title>Low-Complexity SINR Feasibility Checking and Joint Power and Admission
  Control in Prioritized Multi-tier Cellular Networks</title><categories>cs.NI cs.IT math.IT</categories><comments>IEEE Transactions on Wireless Communications, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next generation cellular networks will consist of multiple tiers of cells and
users associated with different network tiers may have different priorities
(e.g., macrocell-picocell-femtocell networks with macro tier prioritized over
pico tier, which is again prioritized over femto tier). Designing efficient
joint power and admission control (JPAC) algorithms for such networks under a
co-channel deployment (i.e., underlay) scenario is of significant importance.
Feasibility checking of a given target signal-to-noise-plus-interference ratio
(SINR) vector is generally the most significant contributor to the complexity
of JPAC algorithms in single/multi-tier underlay cellular networks. This is
generally accomplished through iterative strategies whose complexity is either
unpredictable or of O(M^3), when the well-known relationship between the SINR
vector and the power vector is used, where $M$ is the number of users/links. In
this paper, we derive a novel relationship between a given SINR vector and its
corresponding uplink/downlink power vector based on which the feasibility
checking can be performed with a complexity of O(B^3+M B), where B is the
number of base stations. This is significantly less compared to O(M^3) in many
cellular wireless networks since the number of base stations is generally much
lower than the number of users/links in such networks. The developed novel
relationship between the SINR and power vector not only substantially reduces
the complexity of designing JPAC algorithms, but also provides insights into
developing efficient but low-complexity power update strategies for prioritized
multi-tier cellular networks. We propose two such algorithms and through
simulations, we show that our proposed algorithms outperform the existing ones
in prioritized cellular networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08478</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08478</id><created>2015-11-26</created><authors><author><keyname>Rey-Otero</keyname><forenames>Ives</forenames></author><author><keyname>Morel</keyname><forenames>Jean-Michel</forenames></author><author><keyname>Delbracio</keyname><forenames>Mauricio</forenames></author></authors><title>An analysis of the factors affecting keypoint stability in scale-space</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The most popular image matching algorithm SIFT, introduced by D. Lowe a
decade ago, has proven to be sufficiently scale invariant to be used in
numerous applications. In practice, however, scale invariance may be weakened
by various sources of error inherent to the SIFT implementation affecting the
stability and accuracy of keypoint detection. The density of the sampling of
the Gaussian scale-space and the level of blur in the input image are two of
these sources. This article presents a numerical analysis of their impact on
the extracted keypoints stability. Such an analysis has both methodological and
practical implications, on how to compare feature detectors and on how to
improve SIFT. We show that even with a significantly oversampled scale-space
numerical errors prevent from achieving perfect stability. Usual strategies to
filter out unstable detections are shown to be inefficient. We also prove that
the effect of the error in the assumption on the initial blur is asymmetric and
that the method is strongly degraded in presence of aliasing or without a
correct assumption on the camera blur.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08486</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08486</id><created>2015-11-26</created><authors><author><keyname>Xie</keyname><forenames>Pengtao</forenames></author><author><keyname>Kim</keyname><forenames>Jin Kyu</forenames></author><author><keyname>Zhou</keyname><forenames>Yi</forenames></author><author><keyname>Ho</keyname><forenames>Qirong</forenames></author><author><keyname>Kumar</keyname><forenames>Abhimanu</forenames></author><author><keyname>Yu</keyname><forenames>Yaoliang</forenames></author><author><keyname>Xing</keyname><forenames>Eric</forenames></author></authors><title>Distributed Machine Learning via Sufficient Factor Broadcasting</title><categories>cs.LG cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matrix-parametrized models, including multiclass logistic regression and
sparse coding, are used in machine learning (ML) applications ranging from
computer vision to computational biology. When these models are applied to
large-scale ML problems starting at millions of samples and tens of thousands
of classes, their parameter matrix can grow at an unexpected rate, resulting in
high parameter synchronization costs that greatly slow down distributed
learning. To address this issue, we propose a Sufficient Factor Broadcasting
(SFB) computation model for efficient distributed learning of a large family of
matrix-parameterized models, which share the following property: the parameter
update computed on each data sample is a rank-1 matrix, i.e., the outer product
of two &quot;sufficient factors&quot; (SFs). By broadcasting the SFs among worker
machines and reconstructing the update matrices locally at each worker, SFB
improves communication efficiency --- communication costs are linear in the
parameter matrix's dimensions, rather than quadratic --- without affecting
computational correctness. We present a theoretical convergence analysis of
SFB, and empirically corroborate its efficiency on four different
matrix-parametrized ML models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08488</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08488</id><created>2015-11-26</created><authors><author><keyname>Plajner</keyname><forenames>Martin</forenames></author><author><keyname>Vomlel</keyname><forenames>Ji&#x159;&#xed;</forenames></author></authors><title>Bayesian Network Models for Adaptive Testing</title><categories>cs.AI</categories><comments>12th Annual Bayesian Modelling Applications Workshop, Amsterdam,
  Netherlands, (July 2015). 10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computerized adaptive testing (CAT) is an interesting and promising approach
to testing human abilities. In our research we use Bayesian networks to create
a model of tested humans. We collected data from paper tests performed with
grammar school students. In this article we first provide the summary of data
used for our experiments. We propose several different Bayesian networks, which
we tested and compared by cross-validation. Interesting results were obtained
and are discussed in the paper. The analysis has brought a clearer view on the
model selection problem. Future research is outlined in the concluding part of
the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08494</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08494</id><created>2015-11-26</created><authors><author><keyname>Loreti</keyname><forenames>Paola</forenames></author><author><keyname>Vellucci</keyname><forenames>Pierluigi</forenames></author></authors><title>Perturbed Sinc Bases with Application to Time Jittering in Digital Audio
  Processes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we apply some results obtained for &quot;perturbed&quot; Whittaker's
cardinal series, $\sum_{k\in\mathbb Z} a_k \operatorname{sinc}(t-\lambda_k)$,
to problem of signal reconstruction in a Digital Audio Processes, where we
consider ideal bandlimited interpolation and the variability of
$\{\lambda_k\}_{k\in\mathbb Z}$ models sampling clock jitter effects. Results
applied in this work concern a stability theorem, by previous work, and a
generalization of the Parseval's identity for perturbed Whittaker's cardinal
series, here introduced for the first time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08495</identifier>
 <datestamp>2016-02-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08495</id><created>2015-11-26</created><updated>2016-02-03</updated><authors><author><keyname>Gehring</keyname><forenames>Clement</forenames></author><author><keyname>Pan</keyname><forenames>Yangchen</forenames></author><author><keyname>White</keyname><forenames>Martha</forenames></author></authors><title>Incremental Truncated LSTD</title><categories>cs.LG cs.AI</categories><comments>Under review for IJCAI 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Balancing between computational efficiency and sample efficiency is an
important goal in reinforcement learning. Temporal difference (TD) learning
algorithms stochastically update the value function, with a linear time
complexity in the number of features, whereas least-squares temporal difference
(LSTD) algorithms are sample efficient but can be quadratic in the number of
features. In this work, we develop an efficient incremental low-rank
LSTD({\lambda}) algorithm that progresses towards the goal of better balancing
computation and sample efficiency. The algorithm reduces the computation and
storage complexity to the number of features times the chosen rank parameter
while summarizing past samples efficiently to nearly obtain the sample
complexity of LSTD. We derive a simulation bound on the solution given by
truncated low-rank approximation, illustrating a bias- variance trade-off
dependent on the choice of rank. We demonstrate that the algorithm effectively
balances computational complexity and sample efficiency for policy evaluation
in a benchmark task and a high-dimensional energy allocation domain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08497</identifier>
 <datestamp>2016-02-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08497</id><created>2015-11-26</created><updated>2016-02-13</updated><authors><author><keyname>Raghothaman</keyname><forenames>Mukund</forenames></author><author><keyname>Wei</keyname><forenames>Yi</forenames></author><author><keyname>Hamadi</keyname><forenames>Youssef</forenames></author></authors><title>SWIM: Synthesizing What I Mean</title><categories>cs.SE</categories><comments>Final draft of paper to be presented at ICSE 2016</comments><doi>10.1145/2884781.2884808</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Modern programming frameworks come with large libraries, with diverse
applications such as for matching regular expressions, parsing XML files and
sending email. Programmers often use search engines such as Google and Bing to
learn about existing APIs. In this paper, we describe SWIM, a tool which
suggests code snippets given API-related natural language queries such as
&quot;generate md5 hash code&quot;.
  We translate user queries into the APIs of interest using clickthrough data
from the Bing search engine. Then, based on patterns learned from open-source
code repositories, we synthesize idiomatic code describing the use of these
APIs. We introduce \emph{structured call sequences} to capture API-usage
patterns. Structured call sequences are a generalized form of method call
sequences, with if-branches and while-loops to represent conditional and
repeated API usage patterns, and are simple to extract and amenable to
synthesis.
  We evaluated SWIM with 30 common C# API-related queries received by Bing. For
70% of the queries, the first suggested snippet was a relevant solution, and a
relevant solution was present in the top 10 results for all benchmarked
queries. The online portion of the workflow is also very responsive, at an
average of 1.5 seconds per snippet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08498</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08498</id><created>2015-11-26</created><authors><author><keyname>Li</keyname><forenames>Ke</forenames></author><author><keyname>Hariharan</keyname><forenames>Bharath</forenames></author><author><keyname>Malik</keyname><forenames>Jitendra</forenames></author></authors><title>Iterative Instance Segmentation</title><categories>cs.CV cs.LG</categories><comments>11 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing methods for pixel-wise labelling tasks generally disregard the
underlying structure of labellings and so the resulting predictions may be
visually implausible. While incorporating structure into the model should
improve prediction quality, doing so is challenging - manually specifying the
form of structural constraints may be impractical and inference often becomes
intractable even if structural constraints are given. We sidestep this problem
by reducing structured prediction to a sequence of unconstrained prediction
problems and demonstrate that this approach is capable of automatically
discovering priors on shape, contiguity of region predictions and smoothness of
region contours from data without any a priori specification. On the instance
segmentation task, this method outperforms the state-of-the-art, achieving a
mean AP^r of 63.7% at 50% overlap and 42.2% at 70% overlap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08507</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08507</id><created>2015-11-26</created><authors><author><keyname>Wendzel</keyname><forenames>Steffen</forenames></author><author><keyname>Palmer</keyname><forenames>Carolin</forenames></author></authors><title>Creativity in Mind: Evaluating and Maintaining Advances in Network
  Steganographic Research</title><categories>cs.MM cs.CR cs.CY</categories><comments>to appear in Journal of Universal Computer Science (J.UCS)</comments><acm-class>D.2.11; D.4.6; K.6.5; K.7.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The research discipline of network steganography deals with the hiding of
information within network transmissions, e.g. to transfer illicit information
in networks with Internet censorship. The last decades of research on network
steganography led to more than hundred techniques for hiding data in network
transmissions. However, previous research has shown that most of these hiding
techniques are either based on the same idea or introduce limited novelty,
enabling the application of existing countermeasures. In this paper, we provide
a link between the field of creativity and network steganographic research. We
propose a framework and a metric to help evaluating the creativity bound to a
given hiding technique. This way, we support two sides of the scientific peer
review process as both authors and reviewers can use our framework to analyze
the novelty and applicability of hiding techniques. At the same time, we
contribute to a uniform terminology in network steganography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08512</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08512</id><created>2015-11-26</created><authors><author><keyname>Lieto</keyname><forenames>Antonio</forenames></author></authors><title>Some Epistemological Problems with the Knowledge Level in Cognitive
  Architectures</title><categories>cs.AI</categories><comments>5 pages in Proceedings of AISC 2015, 12th Italian Conference on
  Cognitive Science, Genoa, 10-12 December 2015, Italy</comments><acm-class>I.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article addresses an open problem in the area of cognitive systems and
architectures: namely the problem of handling (in terms of processing and
reasoning capabilities) complex knowledge structures that can be at least
plausibly comparable, both in terms of size and of typology of the encoded
information, to the knowledge that humans process daily for executing everyday
activities. Handling a huge amount of knowledge, and selectively retrieve it
ac- cording to the needs emerging in different situational scenarios, is an
important aspect of human intelligence. For this task, in fact, humans adopt a
wide range of heuristics (Gigerenzer and Todd) due to their bounded rationality
(Simon, 1957). In this perspective, one of the re- quirements that should be
considered for the design, the realization and the evaluation of intelligent
cognitively inspired systems should be represented by their ability of
heuristically identify and retrieve, from the general knowledge stored in their
artificial Long Term Memory (LTM), that one which is synthetically and
contextually relevant. This require- ment, however, is often neglected.
Currently, artificial cognitive systems and architectures are not able, de
facto, to deal with complex knowledge structures that can be even slightly
comparable to the knowledge heuris- tically managed by humans. In this paper I
will argue that this is not only a technological problem but also an
epistemological one and I will briefly sketch a proposal for a possible
solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08522</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08522</id><created>2015-11-26</created><authors><author><keyname>Sukhwani</keyname><forenames>Mohak</forenames></author><author><keyname>Jawahar</keyname><forenames>C. V.</forenames></author></authors><title>TennisVid2Text: Fine-grained Descriptions for Domain Specific Videos</title><categories>cs.CV</categories><comments>BMVC 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automatically describing videos has ever been fascinating. In this work, we
attempt to describe videos from a specific domain - broadcast videos of lawn
tennis matches. Given a video shot from a tennis match, we intend to generate a
textual commentary similar to what a human expert would write on a sports
website. Unlike many recent works that focus on generating short captions, we
are interested in generating semantically richer descriptions. This demands a
detailed low-level analysis of the video content, specially the actions and
interactions among subjects. We address this by limiting our domain to the game
of lawn tennis. Rich descriptions are generated by leveraging a large corpus of
human created descriptions harvested from Internet. We evaluate our method on a
newly created tennis video data set. Extensive analysis demonstrate that our
approach addresses both semantic correctness as well as readability aspects
involved in the task.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08528</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08528</id><created>2015-11-26</created><authors><author><keyname>Melgaard</keyname><forenames>Christopher</forenames></author><author><keyname>Gu</keyname><forenames>Ming</forenames></author></authors><title>Gaussian Elimination with Randomized Complete Pivoting</title><categories>math.NA cs.NA stat.CO</categories><comments>5 figures, 33 pages</comments><msc-class>60, 65</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Gaussian elimination with partial pivoting (GEPP) has long been among the
most widely used methods for computing the LU factorization of a given matrix.
However, this method is also known to fail for matrices that induce large
element growth during the factorization process. In this paper, we propose a
new scheme, Gaussian elimination with randomized complete pivoting (GERCP) for
the efficient and reliable LU factorization of a given matrix. GERCP satisfies
GECP (Gaussian elimination with complete pivoting) style element growth bounds
with high probability, yet costs only marginally higher than GEPP. Our
numerical experimental results strongly suggest that GERCP is as reliable as
GECP and as efficient as GEPP for computing the LU factorization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08531</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08531</id><created>2015-11-26</created><authors><author><keyname>Paisitkriangkrai</keyname><forenames>Sakrapee</forenames></author><author><keyname>Wu</keyname><forenames>Lin</forenames></author><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Hengel</keyname><forenames>Anton van den</forenames></author></authors><title>Structured learning of metric ensembles with application to person
  re-identification</title><categories>cs.CV</categories><comments>18 pages. Extended version of &quot;Learning to Rank in Person
  Re-Identification With Metric Ensembles&quot;, at
  http://www.cv-foundation.org/openaccess/content_cvpr_2015/html/Paisitkriangkrai_Learning_to_Rank_2015_CVPR_paper.html</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Matching individuals across non-overlapping camera networks, known as person
re-identification, is a fundamentally challenging problem due to the large
visual appearance changes caused by variations of viewpoints, lighting, and
occlusion. Approaches in literature can be categoried into two streams: The
first stream is to develop reliable features against realistic conditions by
combining several visual features in a pre-defined way; the second stream is to
learn a metric from training data to ensure strong inter-class differences and
intra-class similarities. However, seeking an optimal combination of visual
features which is generic yet adaptive to different benchmarks is a unsoved
problem, and metric learning models easily get over-fitted due to the scarcity
of training data in person re-identification. In this paper, we propose two
effective structured learning based approaches which explore the adaptive
effects of visual features in recognizing persons in different benchmark data
sets. Our framework is built on the basis of multiple low-level visual features
with an optimal ensemble of their metrics. We formulate two optimization
algorithms, CMCtriplet and CMCstruct, which directly optimize evaluation
measures commonly used in person re-identification, also known as the
Cumulative Matching Characteristic (CMC) curve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08538</identifier>
 <datestamp>2015-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08538</id><created>2015-11-26</created><updated>2015-12-10</updated><authors><author><keyname>Warsi</keyname><forenames>Naqueeb Ahmad</forenames></author></authors><title>Simple one-shot bounds for various source coding problems using smooth
  Renyi quantities</title><categories>cs.IT math.IT quant-ph</categories><comments>Accepted for publication at Problems of Information Transmission. To
  appear in the January issue of the journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of source compression under three different scenarios
in the one-shot (non- asymptotic) regime. To be specific, we prove one-shot
achievability and converse bounds on the coding rates for distributed source
coding, source coding with coded side information available at the decoder and
source coding under maximum distortion criterion. The one-shot bounds obtained
are in terms of smooth max Renyi entropy and smooth max Renyi divergence. Our
results are powerful enough to yield the results that are known for these
problems in the asymptotic regime both in the i.i.d. (independent and
identically distributed) and non-i.i.d. settings
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08540</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08540</id><created>2015-11-26</created><authors><author><keyname>Zhao</keyname><forenames>Tianchu</forenames></author><author><keyname>Zhou</keyname><forenames>Sheng</forenames></author><author><keyname>Guo</keyname><forenames>Xueying</forenames></author><author><keyname>Zhao</keyname><forenames>Yun</forenames></author><author><keyname>Niu</keyname><forenames>Zhisheng</forenames></author></authors><title>A Cooperative Scheduling Scheme of Local Cloud and Internet Cloud for
  Delay-Aware Mobile Cloud Computing</title><categories>cs.NI cs.DC</categories><comments>6 pages, 7 figures, accepted by GlobeCom'15 Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the proliferation of mobile applications, Mobile Cloud Computing (MCC)
has been proposed to help mobile devices save energy and improve computation
performance. To further improve the quality of service (QoS) of MCC, cloud
servers can be deployed locally so that the latency is decreased. However, the
computational resource of the local cloud is generally limited. In this paper,
we design a threshold-based policy to improve the QoS of MCC by cooperation of
the local cloud and Internet cloud resources, which takes the advantages of low
latency of the local cloud and abundant computational resources of the Internet
cloud simultaneously. This policy also applies a priority queue in terms of
delay requirements of applications. The optimal thresholds depending on the
traffic load is obtained via a proposed algorithm. Numerical results show that
the QoS can be greatly enhanced with the assistance of Internet cloud when the
local cloud is overloaded. Better QoS is achieved if the local cloud order
tasks according to their delay requirements, where delay-sensitive applications
are executed ahead of delay-tolerant applications. Moreover, the optimal
thresholds of the policy have a sound impact on the QoS of the system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08541</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08541</id><created>2015-11-26</created><authors><author><keyname>Cheng</keyname><forenames>Cheng</forenames></author><author><keyname>Jiang</keyname><forenames>Yingchun</forenames></author><author><keyname>Sun</keyname><forenames>Qiyu</forenames></author></authors><title>Spatially Distributed Sampling and Reconstruction</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A spatially distributed system contains a large amount of agents with limited
sensing, data processing, and communication capabilities. Recent technological
advances have opened up possibilities to deploy spatially distributed systems
for signal sampling and reconstruction. In this paper, we introduce a graph
structure for a distributed sampling and reconstruction system by coupling
agents in a spatially distributed system with innovative positions of signals.
A fundamental problem in sampling theory is the robustness of signal
reconstruction in the presence of sampling noises. For a distributed sampling
and reconstruction system, the robustness could be reduced to the stability of
its sensing matrix. In a traditional centralized sampling and reconstruction
system, the stability of the sensing matrix could be verified by its central
processor, but the above procedure is infeasible in a distributed sampling and
reconstruction system as it is decentralized. In this paper, we split a
distributed sampling and reconstruction system into a family of overlapping
smaller subsystems, and we show that the stability of the sensing matrix holds
if and only if its quasi-restrictions to those subsystems have uniform
stability. This new stability criterion could be pivotal for the design of a
robust distributed sampling and reconstruction system against supplement,
replacement and impairment of agents, as we only need to check the uniform
stability of affected subsystems. In this paper, we also propose an
exponentially convergent distributed algorithm for signal reconstruction, that
provides a suboptimal approximation to the original signal in the presence of
bounded sampling noises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08547</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08547</id><created>2015-11-26</created><authors><author><keyname>Druinsky</keyname><forenames>Alex</forenames></author><author><keyname>Carlebach</keyname><forenames>Eyal</forenames></author><author><keyname>Toledo</keyname><forenames>Sivan</forenames></author></authors><title>Wilkinson's Inertia-Revealing Factorization and Its Application to
  Sparse Matrices</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new inertia-revealing factorization for sparse matrices. The
factorization scheme and the method for extracting the inertia from it were
proposed in the 1960s for dense, banded, or tridiagonal matrices, but they have
been abandoned in favor of faster methods. We show that this scheme can be
applied to any sparse matrix and that the fill in the factorization is bounded
by the fill in the sparse QR factorization of the same matrix (but is usually
much smaller). We present experimental results, studying the method's numerical
stability and performance. Our implementation of the method is somewhat naive,
but still demonstrates its potential.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08551</identifier>
 <datestamp>2015-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08551</id><created>2015-11-26</created><updated>2015-12-05</updated><authors><author><keyname>Yi</keyname><forenames>Xinyang</forenames></author><author><keyname>Caramanis</keyname><forenames>Constantine</forenames></author></authors><title>Regularized EM Algorithms: A Unified Framework and Statistical
  Guarantees</title><categories>cs.LG stat.ML</categories><comments>53 pages, 3 figures. A shorter version appears in NIPS 2015</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Latent variable models are a fundamental modeling tool in machine learning
applications, but they present significant computational and analytical
challenges. The popular EM algorithm and its variants, is a much used
algorithmic tool; yet our rigorous understanding of its performance is highly
incomplete. Recently, work in Balakrishnan et al. (2014) has demonstrated that
for an important class of problems, EM exhibits linear local convergence. In
the high-dimensional setting, however, the M-step may not be well defined. We
address precisely this setting through a unified treatment using
regularization. While regularization for high-dimensional problems is by now
well understood, the iterative EM algorithm requires a careful balancing of
making progress towards the solution while identifying the right structure
(e.g., sparsity or low-rank). In particular, regularizing the M-step using the
state-of-the-art high-dimensional prescriptions (e.g., Wainwright (2014)) is
not guaranteed to provide this balance. Our algorithm and analysis are linked
in a way that reveals the balance between optimization and statistical errors.
We specialize our general framework to sparse gaussian mixture models,
high-dimensional mixed regression, and regression with missing variables,
obtaining statistical guarantees for each of these examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08552</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08552</id><created>2015-11-26</created><authors><author><keyname>Bun</keyname><forenames>Mark</forenames></author><author><keyname>Nissim</keyname><forenames>Kobbi</forenames></author><author><keyname>Stemmer</keyname><forenames>Uri</forenames></author></authors><title>Simultaneous Private Learning of Multiple Concepts</title><categories>cs.DS cs.CR cs.LG</categories><comments>29 pages. To appear in ITCS '16</comments><doi>10.1145/2840728.2840747</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the direct-sum problem in the context of differentially
private PAC learning: What is the sample complexity of solving $k$ learning
tasks simultaneously under differential privacy, and how does this cost compare
to that of solving $k$ learning tasks without privacy? In our setting, an
individual example consists of a domain element $x$ labeled by $k$ unknown
concepts $(c_1,\ldots,c_k)$. The goal of a multi-learner is to output $k$
hypotheses $(h_1,\ldots,h_k)$ that generalize the input examples.
  Without concern for privacy, the sample complexity needed to simultaneously
learn $k$ concepts is essentially the same as needed for learning a single
concept. Under differential privacy, the basic strategy of learning each
hypothesis independently yields sample complexity that grows polynomially with
$k$. For some concept classes, we give multi-learners that require fewer
samples than the basic strategy. Unfortunately, however, we also give lower
bounds showing that even for very simple concept classes, the sample cost of
private multi-learning must grow polynomially in $k$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08572</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08572</id><created>2015-11-27</created><updated>2015-11-30</updated><authors><author><keyname>Beck</keyname><forenames>Ekkehard</forenames></author><author><keyname>Armbruster</keyname><forenames>Benjamin</forenames></author></authors><title>Elementary proof of convergence to the mean-field model for the SIR
  process</title><categories>math.DS cs.SI math.PR q-bio.PE</categories><comments>20 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The susceptible-infected-recovered (SIR) model has been used extensively to
model disease spread and other processes. Despite the widespread usage of this
ordinary differential equation (ODE) based model which represents the
mean-field approximation of the underlying stochastic SIR process on contact
networks, only few rigorous approaches exist and these use complex semigroup
and martingale techniques to prove that the expected fraction of the
susceptible and infected nodes of the stochastic SIR process on a complete
graph converges as the number of nodes increases to the solution of the
mean-field ODE model. Extending the elementary proof of convergence for the SIS
process introduced by Armbruster and Beck (2015) to the SIR process, we show
convergence in mean-square using only a system of three ODEs, simple
probabilistic inequalities, and basic ODE theory. Our approach can also be
generalized to many other types of compartmental models (e.g.,
susceptible-infected-recovered-susceptible (SIRS)) which are linear ODEs with
the addition of quadratic terms for the number of new infections similar to the
SI term in the SIR model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08574</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08574</id><created>2015-11-27</created><authors><author><keyname>Klimenko</keyname><forenames>Dimitri</forenames></author><author><keyname>Kurniawati</keyname><forenames>Hanna</forenames></author><author><keyname>Gallagher</keyname><forenames>Marcus</forenames></author></authors><title>A Stochastic Process Model of Classical Search</title><categories>cs.AI</categories><comments>Submitted to ICAPS 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among classical search algorithms with the same heuristic information, with
sufficient memory A* is essentially as fast as possible in finding a proven
optimal solution. However, in many situations optimal solutions are simply
infeasible, and thus search algorithms that trade solution quality for speed
are desirable. In this paper, we formalize the process of classical search as a
metalevel decision problem, the Abstract Search MDP. For any given optimization
criterion, this establishes a well-defined notion of the best possible
behaviour for a search algorithm and offers a theoretical approach to the
design of algorithms for that criterion. We proceed to approximately solve a
version of the Abstract Search MDP for anytime algorithms and thus derive a
novel search algorithm, Search by Maximizing the Incremental Rate of
Improvement (SMIRI). SMIRI is shown to outperform current state-of-the-art
anytime search algorithms on a parametrized stochastic tree model for most of
the tested parameter values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08575</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08575</id><created>2015-11-27</created><authors><author><keyname>Mukhopadhyay</keyname><forenames>Samrat</forenames></author><author><keyname>Satpathi</keyname><forenames>Siddhartha</forenames></author><author><keyname>Chakraborty</keyname><forenames>Mrityunjoy</forenames></author></authors><title>Sparse Signal Recovery Using gOMP Assisted mOLS</title><categories>cs.IT math.IT stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Because of fast convergence in finite number of steps and low computational
complexity, signal recovery from compressed measurements using greedy
algorithms have generated a large amount of interest in recent years. Among
these greedy algorithms OMP is well studied and recently its generalization,
gOMP, have also drawn attention. On the other hand OLS and its generalization
mOLS have been studied in recent years because of their potential advantages in
signal recovery guarantee compared to OMP or gOMP. But OLS and mOLS have the
shortcomings of high computational complexity. In this paper we propose a new
algorithm which uses gOMP to preselect a N length set out of which mOLS selects
its L best coefficients. We have shown that our new algorithm, named gOMPamOLS,
is guaranteed to reconstruct a K sparse signals perfectly from compressed
measurements if the restricted isometry constant satisfies
$\delta_{LK+N}&lt;\frac{\sqrt{L}}{\sqrt{L}+\sqrt{K+L}}$ . Moreover experimental
results indicate that gOMPamOLS is robust under sensing matrix with correlated
dictionary in terms of signal reconstruction and is much faster than OLS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08585</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08585</id><created>2015-11-27</created><authors><author><keyname>Li</keyname><forenames>Tianyi</forenames></author><author><keyname>Dong</keyname><forenames>Min</forenames></author></authors><title>Real-Time Residential-Side Joint Energy Storage Management and Load
  Scheduling with Renewable Integration</title><categories>cs.SY</categories><comments>Submitted to IEEE Transactions on Smart Grid</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider joint energy storage management and load scheduling at a
residential site with integrated renewable generation. We aim at optimizing the
load scheduling and energy storage control simultaneously in order to minimize
the overall system cost within a finite time period. Besides assuming unknown
arbitrary dynamics of renewable source, loads, and electricity pricing
information and incorporating battery operational costs, we model the load in
terms of individual tasks with their own intensities, requested service
durations, and maximum and average delay constraints. To tackle this finite
time horizon stochastic problem, we propose a real-time scheduling and storage
solution by applying a sequence of modification and transformation to employ
Lyapunov optimization technique that otherwise is not directly applicable. We
show that in our proposed algorithm, the joint scheduling and energy storage
control can be separated and sequentially determined, and both scheduling and
energy control decisions have close-form solutions for simple implementation.
Through analysis, we show that our proposed real-time algorithm has a bounded
performance guarantee from the optimal T-slot look-ahead solution and is
asymptotically equivalent to it as the battery capacity and time period go to
infinity. The effectiveness of joint energy storage control and load scheduling
by our proposed algorithm is demonstrated through simulation as compared with
alternative algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08587</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08587</id><created>2015-11-27</created><authors><author><keyname>Sharma</keyname><forenames>Shubham</forenames></author><author><keyname>Sridhar</keyname><forenames>Aditya</forenames></author><author><keyname>Krishnia</keyname><forenames>Jai Prakash</forenames></author></authors><title>Self-Healing Audio System</title><categories>cs.NI</categories><comments>Accepted at IEEE sponsored International Conference on Computer
  Communication and Informatics,2016. It will be published in IEEE Xplore
  Digital library after paper presentation</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Installed sound applications typically involve a large number of audio
processors, amplifiers and speaker systems spread across the venue. They could
be spatially distributed at the venue across different rack rooms and floors.
These systems are commissioned and configured by sound engineers using software
application(s). This is essentially a one-time activity, following which, the
audio systems run independently. Detection of faults and reconfiguration of any
audio device(s) that fail(s) is a time-consuming operation. This disruption in
the audio system can affect the entire audio chain and affect the usability of
the venue in question. In this paper, we provide an overview of an audio system
that detects the replacement for any faulty audio device(s) in the network and
re-purposes the same to restore the configuration to last working point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08589</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08589</id><created>2015-11-27</created><authors><author><keyname>Narayanan</keyname><forenames>Chandrashekar Lakshmi</forenames></author><author><keyname>Maity</keyname><forenames>Raj Kumar</forenames></author><author><keyname>Bhatnagar</keyname><forenames>Shalabh</forenames></author></authors><title>Shaping Proto-Value Functions via Rewards</title><categories>cs.AI cs.LG</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In this paper, we combine task-dependent reward shaping and task-independent
proto-value functions to obtain reward dependent proto-value functions (RPVFs).
In constructing the RPVFs we are making use of the immediate rewards which are
available during the sampling phase but are not used in the PVF construction.
We show via experiments that learning with an RPVF based representation is
better than learning with just reward shaping or PVFs. In particular, when the
state space is symmetrical and the rewards are asymmetrical, the RPVF capture
the asymmetry better than the PVFs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08591</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08591</id><created>2015-11-27</created><authors><author><keyname>Rass</keyname><forenames>Stefan</forenames></author></authors><title>On Game-Theoretic Risk Management (Part Two) - Algorithms to Compute
  Nash-Equilibria in Games with Distributions as Payoffs</title><categories>q-fin.EC cs.GT math.ST q-fin.RM stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The game-theoretic risk management framework put forth in the precursor work
&quot;Towards a Theory of Games with Payoffs that are Probability-Distributions&quot;
(arXiv:1506.07368 [q-fin.EC]) is herein extended by algorithmic details on how
to compute equilibria in games where the payoffs are probability distributions.
Our approach is &quot;data driven&quot; in the sense that we assume empirical data
(measurements, simulation, etc.) to be available that can be compiled into
distribution models, which are suitable for efficient decisions about
preferences, and setting up and solving games using these as payoffs. While
preferences among distributions turn out to be quite simple if nonparametric
methods (kernel density estimates) are used, computing Nash-equilibria in games
using such models is discovered as inefficient (if not impossible). In fact, we
give a counterexample in which fictitious play fails to converge for the
(specifically unfortunate) choice of payoff distributions in the game, and
introduce a suitable tail approximation of the payoff densities to tackle the
issue. The overall procedure is essentially a modified version of fictitious
play, and is herein described for standard and multicriteria games, to
iteratively deliver an (approximate) Nash-equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08592</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08592</id><created>2015-11-27</created><authors><author><keyname>Biedl</keyname><forenames>Therese</forenames></author><author><keyname>Liotta</keyname><forenames>Giuseppe</forenames></author><author><keyname>Montecchiani</keyname><forenames>Fabrizio</forenames></author></authors><title>On Visibility Representations of Non-planar Graphs</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A rectangle visibility representation (RVR) of a graph consists of an
assignment of axis-aligned rectangles to vertices such that for every edge
there exists a horizontal or vertical line of sight between the rectangles
assigned to its endpoints. Testing whether a graph has an RVR is known to be
NP-hard. In this paper, we study the problem of finding an RVR under the
assumption that an embedding in the plane of the input graph is fixed and we
are looking for an RVR that reflects this embedding. We show that in this case
the problem can be solved in polynomial time for general embedded graphs and in
linear time for 1-plane graphs (i.e., embedded graphs having at most one
crossing per edge). The linear time algorithm uses a precise list of forbidden
configurations, which extends the set known for straight-line drawings of
1-plane graphs. These forbidden configurations can be tested for in linear
time, and so in linear time we can test whether a 1-plane graph has an RVR and
either compute such a representation or report a negative witness. Finally, we
discuss some extensions of our study to the case when the embedding is not
fixed but the RVR can have at most one crossing per edge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08598</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08598</id><created>2015-11-27</created><authors><author><keyname>&#x10c;un&#xe1;t</keyname><forenames>Vladim&#xed;r</forenames></author></authors><title>Predecessor problem on smooth distributions</title><categories>cs.DS</categories><comments>6 pages, to be submitted to Information Processing Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We follow a research thread studying the predecessor problem on &quot;smooth&quot;
distribution families. We propose a conceptually simpler solution utilizing
well-known results from much better studied variant of the problem that assumes
nothing about the input. As a side effect, we are able to extend the range of
handled input distributions for the most studied case needing expected
$\mathcal O(\log \log n)$ time, and we provide better insight into why the
related methods are faster on smooth inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08599</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08599</id><created>2015-11-27</created><authors><author><keyname>Wang</keyname><forenames>Hanyu</forenames></author><author><keyname>Qi</keyname><forenames>Miao</forenames></author><author><keyname>Wang</keyname><forenames>Bo</forenames></author></authors><title>Study of Memristor-based Oscillatory Neural Networks using PPV modeling</title><categories>cs.ET</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memristor-based oscillator is becoming promising thanks to its inherent NDR
(Negative Differential Region) property and compact circuit structure. This
paves the way to the large scale oscillatory neural network (ONN) and the
realization of pattern recognition based on its global synchronization.
However, the simulation of large scale ONN encounters the problem of long
simulation time because of the large number of oscillators. Here we propose a
highly efficient method to abstract the phase sensitivity characteristic of the
memristor-based oscillator, i.e., its PPV (Perturbation Projection Vector),
which allows reducing considerably the complexity of ONN simulation, and
speeding up the simulation more than 2000 times. Our study also reveals the
impact of the circuit parameters on the pattern recognition accuracy and the
robustness against the frequency mismatch.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08605</identifier>
 <datestamp>2015-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08605</id><created>2015-11-27</created><updated>2015-12-22</updated><authors><author><keyname>Courcelle</keyname><forenames>Bruno</forenames><affiliation>LaBRI</affiliation></author></authors><title>Fly-automata for checking MSO 2 graph properties</title><categories>cs.LO</categories><comments>Submitted for publication in December 2015</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A more descriptive but too long title would be : Constructing fly-automata to
check properties of graphs of bounded tree-width expressed by monadic
second-order formulas written with edge quantifications. Such properties are
called MSO2 in short. Fly-automata (FA) run bottom-up on terms denoting graphs
and compute &quot;on the fly&quot; the necessary states and transitions instead of
looking into huge, actually unimplementable tables. In previous works, we have
constructed FA that process terms denoting graphs of bounded clique-width, in
order to check their monadic second-order (MSO) properties (expressed by
formulas without edge quan-tifications). Here, we adapt these FA to incidence
graphs, so that they can check MSO2 properties of graphs of bounded tree-width.
This is possible because: (1) an MSO2 property of a graph is nothing but an MSO
property of its incidence graph and (2) the clique-width of the incidence graph
of a graph is linearly bounded in terms of its tree-width. Our constructions
are actually implementable and usable. We detail concrete constructions of
automata in this perspective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08610</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08610</id><created>2015-11-27</created><authors><author><keyname>Ding</keyname><forenames>Zhiguo</forenames></author><author><keyname>Liu</keyname><forenames>Yuanwei</forenames></author><author><keyname>Choi</keyname><forenames>Jinho</forenames></author><author><keyname>Sun</keyname><forenames>Qi</forenames></author><author><keyname>Elkashlan</keyname><forenames>Maged</forenames></author><author><keyname>I</keyname><forenames>Chih-Lin</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Application of Non-orthogonal Multiple Access in LTE and 5G Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As the latest member of the multiple access family, non-orthogonal multiple
access (NOMA) has been recently proposed for 3GPP Long Term Evolution (LTE) and
envisioned to be an essential component of 5th generation (5G) mobile networks.
The key feature of NOMA is to serve multiple users at the same
time/frequency/code, but with different power levels, which yields a
significant spectral efficiency gain over conventional orthogonal MA. This
article provides a systematic treatment of this newly emerging technology, from
its combination with multiple-input multiple-output (MIMO) technologies, to
cooperative NOMA, as well as the interplay between NOMA and cognitive radio.
This article also reviews the state of the art in the standardization
activities concerning the implementation of NOMA in LTE and 5G networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08628</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08628</id><created>2015-11-27</created><authors><author><keyname>Bernstein</keyname><forenames>Andrey</forenames></author><author><keyname>Bouman</keyname><forenames>Niek J.</forenames></author><author><keyname>Boudec</keyname><forenames>Jean-Yves Le</forenames></author></authors><title>Design of Resource Agents with Guaranteed Tracking Properties for
  Real-Time Control of Electrical Grids</title><categories>math.OC cs.MA</categories><comments>16 pages, double-column format</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We target the problem of controlling electrical microgrids with little
inertia in real time. We consider a central controller and a number of
resources, where each resource is either a load, a generator, or a combination
thereof, like a battery. The controller periodically computes power setpoints
for the resources based on the estimated state of the grid and an overall
objective, and subject to safety constraints. Each resource is augmented with a
resource agent that a) implements the setpoint requests sent by the controller
on the resource, and b) translates device-specific information about the
resource into a device-independent representation and transmits this to the
controller.
  We focus on the resource agents and their impact on the overall system's
behavior. Intuitively, for the system to converge to the objective, the
resource agents should be obedient to the requests from the controller, in the
sense that the actually implemented setpoint should be close to the requested
setpoint, at least on average. This can be important especially when a
controller that performs continuous optimization is used (for the sake of
performance) to control discrete resources (which have a discrete set of
implementable setpoints).
  We formalize obedience by defining the notion of $c$-bounded
accumulated-error. We then demonstrate its usefulness, by presenting
theoretical results (for a simple scenario) and simulation results (for a more
realistic setting) that indicate that, if all resource agents in the system
have bounded accumulated-error, the closed-loop system converges on average to
the objective. Finally, we show how to design resource agents that provably
have bounded accumulated-error for various types of resources, such as
resources with uncertainty (e.g., PV panels) and resources with a discrete set
of implementable setpoints (e.g., on-off heating systems).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08629</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08629</id><created>2015-11-27</created><updated>2015-11-30</updated><authors><author><keyname>Zhou</keyname><forenames>Chunting</forenames></author><author><keyname>Sun</keyname><forenames>Chonglin</forenames></author><author><keyname>Liu</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Lau</keyname><forenames>Francis C. M.</forenames></author></authors><title>Category Enhanced Word Embedding</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed word representations have been demonstrated to be effective in
capturing semantic and syntactic regularities. Unsupervised representation
learning from large unlabeled corpora can learn similar representations for
those words that present similar co-occurrence statistics. Besides local
occurrence statistics, global topical information is also important knowledge
that may help discriminate a word from another. In this paper, we incorporate
category information of documents in the learning of word representations and
to learn the proposed models in a document-wise manner. Our models outperform
several state-of-the-art models in word analogy and word similarity tasks.
Moreover, we evaluate the learned word vectors on sentiment analysis and text
classification tasks, which shows the superiority of our learned word vectors.
We also learn high-quality category embeddings that reflect topical meanings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08630</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08630</id><created>2015-11-27</created><updated>2015-11-30</updated><authors><author><keyname>Zhou</keyname><forenames>Chunting</forenames></author><author><keyname>Sun</keyname><forenames>Chonglin</forenames></author><author><keyname>Liu</keyname><forenames>Zhiyuan</forenames></author><author><keyname>Lau</keyname><forenames>Francis C. M.</forenames></author></authors><title>A C-LSTM Neural Network for Text Classification</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neural network models have been demonstrated to be capable of achieving
remarkable performance in sentence and document modeling. Convolutional neural
network (CNN) and recurrent neural network (RNN) are two mainstream
architectures for such modeling tasks, which adopt totally different ways of
understanding natural languages. In this work, we combine the strengths of both
architectures and propose a novel and unified model called C-LSTM for sentence
representation and text classification. C-LSTM utilizes CNN to extract a
sequence of higher-level phrase representations, and are fed into a long
short-term memory recurrent neural network (LSTM) to obtain the sentence
representation. C-LSTM is able to capture both local features of phrases as
well as global and temporal sentence semantics. We evaluate the proposed
architecture on sentiment classification and question classification tasks. The
experimental results show that the C-LSTM outperforms both CNN and LSTM and can
achieve excellent performance on these tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08631</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08631</id><created>2015-11-27</created><authors><author><keyname>Samarakoon</keyname><forenames>Sumudu</forenames></author><author><keyname>Bennis</keyname><forenames>Mehdi</forenames></author><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Latva-aho</keyname><forenames>Matti</forenames></author></authors><title>Dynamic Clustering and ON/OFF Strategies for Wireless Small Cell
  Networks</title><categories>cs.NI cs.GT cs.IT math.IT</categories><comments>15 pages, 6 figures, 1 table, journal</comments><doi>10.1109/TWC.2015.2499182</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel cluster-based approach for maximizing the energy
efficiency of wireless small cell networks is proposed. A dynamic mechanism is
proposed to group locally-coupled small cell base stations (SBSs) into clusters
based on location and traffic load. Within each formed cluster, SBSs coordinate
their transmission parameters to minimize a cost function which captures the
tradeoffs between energy efficiency and flow level performance, while
satisfying their users' quality-of-service requirements. Due to the lack of
inter-cluster communications, clusters compete with one another in order to
improve the overall network's energy efficiency. This inter-cluster competition
is formulated as a noncooperative game between clusters that seek to minimize
their respective cost functions. To solve this game, a distributed learning
algorithm is proposed using which clusters autonomously choose their optimal
transmission strategies based on local information. It is shown that the
proposed algorithm converges to a stationary mixed-strategy distribution which
constitutes an epsilon-coarse correlated equilibrium for the studied game.
Simulation results show that the proposed approach yields significant
performance gains reaching up to 36% of reduced energy expenditures and up to
41% of reduced fractional transfer time compared to conventional approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08635</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08635</id><created>2015-11-27</created><authors><author><keyname>Delporte</keyname><forenames>Baptiste</forenames></author><author><keyname>Rigamonti</keyname><forenames>Roberto</forenames></author><author><keyname>Dassatti</keyname><forenames>Alberto</forenames></author></authors><title>HPA: An Opportunistic Approach to Embedded Energy Efficiency</title><categories>cs.PF</categories><comments>8 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reducing energy consumption is a challenge that is faced on a daily basis by
teams from the High-Performance Computing as well as the Embedded domain. This
issue is mostly attacked from an hardware perspective, by devising
architectures that put energy efficiency as a primary target, often at the cost
of processing power. Lately, computing platforms have become more and more
heterogeneous, but the exploitation of these additional capabilities is so
complex from the application developer's perspective that they are left unused
most of the time, resulting therefore in a supplemental waste of energy rather
than in faster processing times.
  In this paper we present a transparent, on-the-fly optimization scheme that
allows a generic application to automatically exploit the available computing
units to partition its computational load. We have called our approach
Heterogeneous Platform Accelerator (HPA). The idea is to use profiling to
automatically select a computing-intensive candidate for acceleration, and then
distribute the computations to the different units by off-loading blocks of
code to them.
  Using an NVIDIA Jetson TK1 board, we demonstrate that not only HPA results in
faster processing speed, but also in a considerable reduction in the total
energy absorbed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08642</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08642</id><created>2015-11-27</created><authors><author><keyname>Vorel</keyname><forenames>Vojt&#x11b;ch</forenames></author></authors><title>Two Results on Discontinuous Input Processing</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  First, we show that universality and other properties of general jumping
finite automata are undecidable, which answers a question asked by Meduna and
Zemek in 2012. Second, we close the study raised by \v{C}erno and Mr\'{a}z in
2010 by proving that clearing restarting automata using contexts of size two
can accept binary non-context-free languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08644</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08644</id><created>2015-11-27</created><authors><author><keyname>Kurpisz</keyname><forenames>Adam</forenames></author><author><keyname>Lepp&#xe4;nen</keyname><forenames>Samuli</forenames></author><author><keyname>Mastrolilli</keyname><forenames>Monaldo</forenames></author></authors><title>A Lasserre Lower Bound for the Min-Sum Single Machine Scheduling Problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Min-sum single machine scheduling problem (denoted 1||sum f_j)
generalizes a large number of sequencing problems. The first constant
approximation guarantees have been obtained only recently and are based on
natural time-indexed LP relaxations strengthened with the so called
Knapsack-Cover inequalities (see Bansal and Pruhs, Cheung and Shmoys and the
recent 4+\epsilon-approximation by Mestre and Verschae). These relaxations have
an integrality gap of 2, since the Min-knapsack problem is a special case. No
APX-hardness result is known and it is still conceivable that there exists a
PTAS. Interestingly, the Lasserre hierarchy relaxation, when the objective
function is incorporated as a constraint, reduces the integrality gap for the
Min-knapsack problem to 1+\epsilon.
  In this paper we study the complexity of the Min-sum single machine
scheduling problem under algorithms from the Lasserre hierarchy. We prove the
first lower bound for this model by showing that the integrality gap is
unbounded at level \Omega(\sqrt{n}) even for a variant of the problem that is
solvable in O(n log n) time by the Moore-Hodgson algorithm, namely Min-number
of tardy jobs. We consider a natural formulation that incorporates the
objective function as a constraint and prove the result by partially
diagonalizing the matrix associated with the relaxation and exploiting this
characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08647</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08647</id><created>2015-11-27</created><authors><author><keyname>Chitnis</keyname><forenames>Rajesh</forenames></author><author><keyname>Kamma</keyname><forenames>Lior</forenames></author><author><keyname>Krauthgamer</keyname><forenames>Robert</forenames></author></authors><title>Tight Bounds for Gomory-Hu-like Cut Counting</title><categories>cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By a classical result of Gomory and Hu (1961), in every edge-weighted graph
$G=(V,E,w)$, the minimum $st$-cut values, when ranging over all $s,t\in V$,
take at most $|V|-1$ distinct values. That is, these $\binom{|V|}{2}$ instances
exhibit redundancy factor $\Omega(|V|)$. They further showed how to construct
from $G$ a tree $(V,E',w')$ that stores all minimum $st$-cut values. Motivated
by this result, we obtain tight bounds for the redundancy factor of several
generalizations of the minimum $st$-cut problem.
  1. Group-Cut: Consider the minimum $(A,B)$-cut, ranging over all subsets
$A,B\subseteq V$ of given sizes $|A|=\alpha$ and $|B|=\beta$. The redundancy
factor is $\Omega_{\alpha,\beta}(|V|)$.
  2. Multiway-Cut: Consider the minimum cut separating every two vertices of
$S\subseteq V$, ranging over all subsets of a given size $|S|=k$. The
redundancy factor is $\Omega_{k}(|V|)$.
  3. Multicut: Consider the minimum cut separating every demand-pair in
$D\subseteq V\times V$, ranging over collections of $|D|=k$ demand pairs. The
redundancy factor is $\Omega_{k}(|V|^k)$. This result is a bit surprising, as
the redundancy factor is much larger than in the first two problems.
  A natural application of these bounds is to construct small data structures
that stores all relevant cut values, like the Gomory-Hu tree. We initiate this
direction by giving some upper and lower bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08672</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08672</id><created>2015-11-27</created><authors><author><keyname>Bensmail</keyname><forenames>Julien</forenames></author><author><keyname>Nandi</keyname><forenames>Soumen</forenames></author><author><keyname>Sen</keyname><forenames>Sagnik</forenames></author></authors><title>On oriented cliques with respect to push operation</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To push a vertex $v$ of a directed graph $\overrightarrow{G}$ is to change
the orientations of all the arcs incident with $v$. An oriented graph is a
directed graph without any cycle of length at most 2. An oriented clique is an
oriented graph whose non-adjacent vertices are connected by a directed 2-path.
A push clique is an oriented clique that remains an oriented clique even if one
pushes any set of vertices of it. We show that it is NP-complete to decide if
an undirected graph is underlying graph of a push clique or not. We also prove
that a planar push clique can have at most 8 vertices. We also provide an
exhaustive list of minimal (with respect to spanning subgraph inclusion) planar
push cliques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08678</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08678</id><created>2015-11-27</created><authors><author><keyname>Meijer</keyname><forenames>Jeroen</forenames></author><author><keyname>van de Pol</keyname><forenames>Jaco</forenames></author></authors><title>Bandwidth and Wavefront Reduction for Static Variable Ordering in
  Symbolic Model Checking</title><categories>cs.SE cs.LO</categories><comments>preprint</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate the applicability of bandwidth and wavefront reduction
algorithms to static variable ordering. In symbolic model checking event
locality plays a major role in time and memory usage. For example, in Petri
nets event locality can be captured by dependency matrices, where nonzero
entries indicate whether a transition modifies a place. The quality of event
locality has been expressed as a metric called (weighted) event span. The
bandwidth of a matrix is a metric indicating the distance of nonzero elements
to the diagonal. Wavefront is a metric indicating the degree of nonzeros on one
end of the diagonal of the matrix. Bandwidth and wavefront are well studied
metrics used in sparse matrix solvers.
  In this work we prove that span is limited by twice the bandwidth of a
matrix. This observation makes bandwidth reduction algorithms useful for
obtaining good variable orders. One major issue we address is that the
reduction algorithms can only be applied on symmetric matrices, while the
dependency matrices are asymmetric. We show that the Sloan algorithm executed
on the total graph of the adjacency graph gives the best variable orders.
Practically, we demonstrate that our work allows to call standard sparse matrix
operations in Boost and ViennaCL, computing very good static variable orders in
milliseconds. Future work is promising, because a whole new spectrum of more
off-the-shelf algorithms, including metaheuristic ones, become available for
variable ordering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08681</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08681</id><created>2015-11-27</created><authors><author><keyname>Tossou</keyname><forenames>Aristide</forenames></author><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author></authors><title>Algorithms for Differentially Private Multi-Armed Bandits</title><categories>stat.ML cs.CR cs.LG</categories><proxy>ccsd</proxy><journal-ref>AAAI 2016, Feb 2016, Phoenix, Arizona, United States</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present differentially private algorithms for the stochastic Multi-Armed
Bandit (MAB) problem. This is a problem for applications such as adaptive
clinical trials, experiment design, and user-targeted advertising where private
information is connected to individual rewards. Our major contribution is to
show that there exist $(\epsilon, \delta)$ differentially private variants of
Upper Confidence Bound algorithms which have optimal regret, $O(\epsilon^{-1} +
\log T)$. This is a significant improvement over previous results, which only
achieve poly-log regret $O(\epsilon^{-2} \log^{2} T)$, because of our use of a
novel interval-based mechanism. We also substantially improve the bounds of
previous family of algorithms which use a continual release mechanism.
Experiments clearly validate our theoretical bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08682</identifier>
 <datestamp>2015-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08682</id><created>2015-11-27</created><updated>2015-12-02</updated><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Iraids</keyname><forenames>J&#x101;nis</forenames></author><author><keyname>Kokainis</keyname><forenames>Martins</forenames></author><author><keyname>Smotrovs</keyname><forenames>Juris</forenames></author></authors><title>Polynomials, Quantum Query Complexity, and Grothendieck's Inequality</title><categories>quant-ph cs.CC</categories><comments>31 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show an equivalence between 1-query quantum algorithms and representations
by degree-2 polynomials. Namely, a partial Boolean function $f$ is computable
by a 1-query quantum algorithm with error bounded by $\epsilon&lt;1/2$ iff $f$ can
be approximated by a degree-2 polynomial with error bounded by $\epsilon'&lt;1/2$.
This result holds for two different notions of approximation by a polynomial:
the standard definition of Nisan and Szegedy and the approximation by
block-multilinear polynomials recently introduced by Aaronson and Ambainis
(STOC'2015, arxiv:1411.5729).
  We also show two results for polynomials of higher degree. First, there is a
total Boolean function which requires $\tilde{\Omega}(n)$ quantum queries but
can be represented by a block-multilinear polynomial of degree
$\tilde{O}(\sqrt{n})$. Thus, in the general case (for an arbitrary number of
queries), block-multilinear polynomials are not equivalent to quantum
algorithms.
  Second, for any constant degree $k$, the two notions of approximation by a
polynomial (the standard and the block-multilinear) are equivalent. As a
consequence, we solve an open problem of Aaronson and Ambainis, showing that
one can estimate the value of any bounded degree-$k$ polynomial $p:\{0, 1\}^n
\rightarrow [-1, 1]$ with $O(n^{1-\frac{1}{2k}})$ queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08689</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08689</id><created>2015-11-27</created><authors><author><keyname>Prasad</keyname><forenames>K. N. R. Surya Vara</forenames></author><author><keyname>Hossain</keyname><forenames>Ekram</forenames></author><author><keyname>Bhargava</keyname><forenames>Vijay K.</forenames></author></authors><title>Energy Efficiency in Massive MIMO-Based 5G Networks: Opportunities and
  Challenges</title><categories>cs.NI cs.IT math.IT</categories><comments>IEEE Wireless Communications, under review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As we make progress towards the era of fifth generation (5G) communication
networks, energy efficiency (EE) becomes an important design criterion because
it guarantees sustainable evolution. In this regard, the massive multiple-input
multiple-output (MIMO) technology, where the base stations (BSs) are equipped
with a large number of antennas so as to achieve multiple orders of spectral
and energy efficiency gains, will be a key technology enabler for 5G. In this
article, we present a comprehensive discussion on state-of-the-art techniques
which further enhance the EE gains offered by massive MIMO (MM). We begin with
an overview of MM systems and discuss how realistic power consumption models
can be developed for these systems. Thereby, we discuss and identify few
shortcomings of some of the most prominent EE-maximization techniques present
in the current literature. Then, we discuss &quot;hybrid MM systems&quot; operating in a
5G architecture, where MM operates in conjunction with other potential
technology enablers, such as millimetre wave, heterogenous networks, and energy
harvesting networks. Multiple opportunities and challenges arise in such a 5G
architecture because these technologies benefit mutually from each other and
their coexistence introduces several new constraints on the design of
energy-efficient systems. Despite clear evidence that hybrid MM systems can
achieve significantly higher EE gains than conventional MM systems, several
open research problems continue to roadblock system designers from fully
harnessing the EE gains offered by hybrid MM systems. Our discussions lead to
the conclusion that hybrid MM systems offer a sustainable evolution towards 5G
networks and are therefore an important research topic for future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08700</identifier>
 <datestamp>2016-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08700</id><created>2015-11-27</created><authors><author><keyname>Simmons</keyname><forenames>David E.</forenames></author><author><keyname>Coon</keyname><forenames>Justin P.</forenames></author></authors><title>Distortion Limited Amplify-and-forward Relay Networks and the
  $\epsilon$-critical Phase Transition</title><categories>cs.IT math.IT</categories><comments>Draft submission to IEEE Transactions on Vehicular Technology</comments><doi>10.1109/TIT.2016.2527682</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study amplify-and-forward (AF) relay networks operating with source and
relay nonlinear amplifier distortion, where distortion dominates noise. The
log-log decay of the outage probability with the source/relay transmit powers
is shown to be (asymptotically) $0$ for fixed-gain (FG) and $1$ for
variable-gain (VG) if distortion occurs at the relay; if distortion occurs only
at the source, this decay will be $1$ for both. To give further insight to
this, we define the network to be $\epsilon_S$-$\epsilon_R$-distorted when
$\epsilon_\beta=N_0/\eta_\beta$ ($N_0$ the noise power, $\eta_\beta$ the
non-linear distortion power at node $\beta\in\{S,R\}$, i.e., the source or
relay). Through this definition, an $\epsilon$-critical signal-to-noise plus
distortion ratio (SNDR) threshold (a threshold emerging for small
$\min\{\epsilon_\beta\}$) is revealed for both forwarding schemes. We show that
crossing this threshold in distortion limited regions will cause a phase
transition in the network's outage probability. Our results reveal that, for
distortion limited networks, small reductions in the required end-to-end
transmission rate can have significant reductions in the network's outage
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08707</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08707</id><created>2015-11-27</created><authors><author><keyname>Tejaswi</keyname><forenames>Tripti Tanaya</forenames></author><author><keyname>Azharuddin</keyname><forenames>Md</forenames></author><author><keyname>Jana</keyname><forenames>P. K.</forenames></author></authors><title>A GA based approach for task scheduling in multi-cloud environment</title><categories>cs.DC</categories><license>http://creativecommons.org/publicdomain/zero/1.0/</license><abstract>  In multi-cloud environment, task scheduling has attracted a lot of attention
due to NP-Complete nature of the problem. Moreover, it is very challenging due
to heterogeneity of the cloud resources with varying capacities and
functionalities. Therefore, minimizing the makespan for task scheduling is a
challenging issue. In this paper, we propose a genetic algorithm (GA) based
approach for solving task scheduling problem. The algorithm is described with
innovative idea of fitness function derivation and mutation. The proposed
algorithm is exposed to rigorous testing using various benchmark datasets and
its performance is evaluated in terms of total makespan.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08712</identifier>
 <datestamp>2016-01-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08712</id><created>2015-11-27</created><updated>2016-01-14</updated><authors><author><keyname>Fenner</keyname><forenames>Trevor</forenames></author><author><keyname>Levene</keyname><forenames>Mark</forenames></author><author><keyname>Loizou</keyname><forenames>George</forenames></author></authors><title>A stochastic evolutionary model generating a mixture of exponential
  distributions</title><categories>physics.soc-ph cs.SI</categories><comments>14 pages. arXiv admin note: substantial text overlap with
  arXiv:1502.07558</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent interest in human dynamics has stimulated the investigation of the
stochastic processes that explain human behaviour in various contexts, such as
mobile phone networks and social media. In this paper, we extend the stochastic
urn-based model proposed in \cite{FENN15} so that it can generate mixture
models,in particular, a mixture of exponential distributions. The model is
designed to capture the dynamics of survival analysis, traditionally employed
in clinical trials, reliability analysis in engineering, and more recently in
the analysis of large data sets recording human dynamics. The mixture modelling
approach, which is relatively simple and well understood, is very effective in
capturing heterogeneity in data. We provide empirical evidence for the validity
of the model, using a data set of popular search engine queries collected over
a period of 114 months. We show that the survival function of these queries is
closely matched by the exponential mixture solution for our model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08714</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08714</id><created>2015-11-27</created><authors><author><keyname>Gao</keyname><forenames>Zhen</forenames></author><author><keyname>Dai</keyname><forenames>Linglong</forenames></author><author><keyname>Wang</keyname><forenames>Zhaocheng</forenames></author></authors><title>Structured Compressive Sensing Based Superimposed Pilot Design in
  Downlink Large-Scale MIMO Systems</title><categories>cs.IT math.IT</categories><comments>2 pages, 2 figures.
  http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=6836737&amp;tag=1</comments><journal-ref>Electronics Letters, vol. 50, no. 12 pp. 896-898, Jun. 2014</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large-scale multiple-input multiple-output (MIMO) with high spectrum and
energy efficiency is a very promising key technology for future 5G wireless
communications. For large-scale MIMO systems, accurate channel state
information (CSI) acquisition is a challenging problem, especially when each
user has to distinguish and estimate numerous channels coming from a large
number of transmit antennas in the downlink. Unlike the conventional orthogonal
pilots whose pilot overhead prohibitively increases with the number of transmit
antennas, we propose a spectrum-efficient superimposed pilot design for
downlink large-scale MIMO scenarios, where frequency-domain pilots of different
transmit antennas occupy the completely same subcarriers in the freqency
domain. Meanwhile, spatial-temporal common sparsity of large-scale MIMO
channels motivates us to exploit the emerging theory of structured compressive
sensing (CS) for reliable MIMO channel estimation, which is realized by the
proposed structured subspace pursuit (SSP) algorithm to simultaneously recover
multiple channels with low pilot overhead. Simulation results demonstrate that
the proposed scheme performs well and can approach the performance bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08715</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08715</id><created>2015-11-27</created><authors><author><keyname>Gao</keyname><forenames>Zhen</forenames></author><author><keyname>Dai</keyname><forenames>Linglong</forenames></author><author><keyname>Wang</keyname><forenames>Zhaocheng</forenames></author><author><keyname>Chen</keyname><forenames>Sheng</forenames></author><author><keyname>Hanzo</keyname><forenames>Lajos</forenames></author></authors><title>Compressive Sensing Based Multi-User Detector for the Large-Scale
  SM-MIMO Uplink</title><categories>cs.IT math.IT</categories><comments>7 pages, 4 figures, to appear in IEEE Transactions on Vehicular
  Technology. http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7331321</comments><doi>10.1109/TVT.2015.2501460</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conventional spatial modulation (SM) is typically considered for transmission
in the downlink of small-scale MIMO systems, where a single one of a set of
antenna elements (AEs) is activated for implicitly conveying extra bits. By
contrast, inspired by the compelling benefits of large-scale MIMO (LS- MIMO)
systems, here we propose a LS-SM-MIMO scheme for the uplink (UL), where each
user having multiple AEs but only a single radio frequency (RF) chain invokes
SM for increasing the UL-throughput. At the same time, by relying on hundreds
of AEs but a small number of RF chains, the base station (BS) can
simultaneously serve multiple users whilst reducing the power consumption. Due
to the large number of AEs of the UL-users and the comparably small number of
RF chains at the BS, the UL multi-user signal detection becomes a challenging
large-scale under-determined problem. To solve this problem, we propose a joint
SM transmission scheme and a carefully designed structured compressive sensing
(SCS)-based multi-user detector (MUD) to be used at the users and BS,
respectively. Additionally, the cyclic- prefix single-carrier (CPSC) is used to
combat the multipath channels, and a simple receive AE selection is used for
the improved performance over correlated Rayleigh-fading MIMO channels. We
demonstrate that the aggregate SM signal consisting of SM signals of multiple
UL-users in one CPSC block appears the distributed sparsity. Moreover, due to
the joint SM transmission scheme, aggregate SM signals in the same transmission
group exhibit the group sparsity. By exploiting these intrinsically sparse
features, the proposed SCS-based MUD can reliably detect the resultant SM
signals with low complexity. Simulation results demonstrate that the proposed
SCS-based MUD achieves a better signal detection performance than its
counterparts even with higher UL-throughtput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08723</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08723</id><created>2015-11-27</created><authors><author><keyname>Amarilli</keyname><forenames>Antoine</forenames></author><author><keyname>Bourhis</keyname><forenames>Pierre</forenames></author><author><keyname>Senellart</keyname><forenames>Pierre</forenames></author></authors><title>Provenance Circuits for Trees and Treelike Instances (Extended Version)</title><categories>cs.DB cs.LO</categories><comments>48 pages. Presented at ICALP'15</comments><license>http://creativecommons.org/licenses/by-sa/4.0/</license><abstract>  Query evaluation in monadic second-order logic (MSO) is tractable on trees
and treelike instances, even though it is hard for arbitrary instances. This
tractability result has been extended to several tasks related to query
evaluation, such as counting query results [3] or performing query evaluation
on probabilistic trees [10]. These are two examples of the more general problem
of computing augmented query output, that is referred to as provenance. This
article presents a provenance framework for trees and treelike instances, by
describing a linear-time construction of a circuit provenance representation
for MSO queries. We show how this provenance can be connected to the usual
definitions of semiring provenance on relational instances [20], even though we
compute it in an unusual way, using tree automata; we do so via intrinsic
definitions of provenance for general semirings, independent of the operational
details of query evaluation. We show applications of this provenance to capture
existing counting and probabilistic results on trees and treelike instances,
and give novel consequences for probability evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08724</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08724</id><created>2015-11-27</created><updated>2016-01-05</updated><authors><author><keyname>Ameloot</keyname><forenames>Tom J.</forenames></author><author><keyname>Bussche</keyname><forenames>Jan Van den</forenames></author></authors><title>On the convergence of cycle detection for navigational reinforcement
  learning</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a reinforcement learning framework where agents have to navigate
from start states to goal states. We prove convergence of a cycle-detection
learning algorithm on a class of tasks that we call reducible. Reducible tasks
have an acyclic solution. We also syntactically characterize the form of the
final policy. This characterization can be used to precisely detect the
convergence point in a simulation. Our result demonstrates that even simple
algorithms can be successful in learning a large class of nontrivial tasks. In
addition, our framework is elementary in the sense that we only use basic
concepts to formally prove convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08739</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08739</id><created>2015-11-25</created><authors><author><keyname>Chandrashekar</keyname><forenames>Praveen</forenames></author><author><keyname>Zenk</keyname><forenames>Markus</forenames></author></authors><title>Well-balanced nodal discontinuous Galerkin method for Euler equations
  with gravity</title><categories>physics.comp-ph cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a well-balanced nodal discontinuous Galerkin (DG) scheme for
compressible Euler equations with gravity. The DG scheme makes use of
discontinuous Lagrange basis functions supported at Gauss-Lobatto-Legendre
(GLL) nodes together with GLL quadrature using the same nodes. The
well-balanced property is achieved by a specific form of source term
discretization that depends on the nature of the hydrostatic solution, together
with the GLL nodes for quadrature of the source term. The scheme is able to
preserve isothermal and polytropic stationary solutions upto machine precision
on any mesh composed of quadrilateral cells and for any gravitational
potential. It is applied on several examples to demonstrate its well-balanced
property and the improved resolution of small perturbations around the
stationary solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08742</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08742</id><created>2015-11-27</created><authors><author><keyname>Thangaraj</keyname><forenames>Andrew</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author><author><keyname>Bocherer</keyname><forenames>Georg</forenames></author></authors><title>Capacity Bounds for Discrete-Time, Amplitude-Constrained, Additive White
  Gaussian Noise Channels</title><categories>cs.IT math.IT</categories><comments>10 pages, part of this paper was presented at the IEEE International
  Symposium on Information Theory (ISIT) 2015, Hong Kong</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity-achieving input distribution of the discrete-time, additive
white Gaussian noise (AWGN) channel with an amplitude constraint is discrete
and seems difficult to characterize explicitly. A dual capacity expression is
used to derive analytic capacity upper bounds for scalar and vector AWGN
channels. The scalar bound improves on McKellips' bound and is within 0.1 bits
of capacity for all signal-to-noise ratios (SNRs). The two-dimensional bound is
within 0.15 bits of capacity provably up to 4.5 dB, and numerical evidence
suggests a similar gap for all SNRs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08745</identifier>
 <datestamp>2015-12-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08745</id><created>2015-11-27</created><updated>2015-12-10</updated><authors><author><keyname>Li</keyname><forenames>Nan</forenames></author><author><keyname>Rasmussen</keyname><forenames>Lars K.</forenames></author><author><keyname>Xiao</keyname><forenames>Ming</forenames></author></authors><title>Cooperative Communication Using Network Coding</title><categories>cs.IT math.IT</categories><comments>32 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a cognitive radio network scenario where a primary transmitter
and a secondary transmitter, respectively, communicate a message to their
respective primary receiver and secondary receiver over a packet-based wireless
link, using a joint automatic-repeat-request (ARQ) error control scheme. The
secondary transmitter assists in the retransmission of the primary message,
which improves the primary performance, and is granted limited access to the
transmission resources. Conventional ARQ, as well as two network-coding schemes
are investigated for application in the retransmission phase; namely the static
network-coding (SNC) scheme and the adaptive network-coding (ANC) scheme. For
each scheme we analyze the transmission process by investigating the
distribution of the number of transmission attempts and approximate it by
normal distributions. Considering both the cases of an adaptive frame size and
a truncated frame size, we derive analytical results on packet throughput and
infer that the ANC scheme outperforms the SNC scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08746</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08746</id><created>2015-11-27</created><authors><author><keyname>Choi</keyname><forenames>Jun Won</forenames></author><author><keyname>Shim</keyname><forenames>Byonghyo</forenames></author><author><keyname>Ding</keyname><forenames>Yacong</forenames></author><author><keyname>Rao</keyname><forenames>Bhaskar</forenames></author><author><keyname>Kim</keyname><forenames>Dong In</forenames></author></authors><title>Compressed Sensing for Wireless Communications : A Few Tips and Tricks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As a paradigm to recover the sparse signal from a small set of linear
measurements, compressed sensing (CS) has generated a great deal of interest in
recent years. In order to apply the CS techniques to wireless communication
systems, there are a number of things to consider. However, it is not easy to
find simple and easy answers to those issues in research papers. The main
purpose of this paper is to provide key premises and useful tips that wireless
communication researchers need to know when designing CS-based wireless
systems. These include promise and limitation of CS technique, subtle points
that one should pay attention to, and discussion of wireless applications that
CS technique can be applied to. The purpose of this paper is to provide
essentials and useful tips that non-expert in the CS field needs to be aware
of. Our hope is that this paper will provide better understanding on the
promises and limitations of CS techniques to wireless communication
researchers. Our hope is that this article will be a useful guide for wireless
communication researchers to grasp the gist of CS techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08748</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08748</id><created>2015-11-27</created><authors><author><keyname>Devanur</keyname><forenames>Nikhil</forenames></author><author><keyname>Garg</keyname><forenames>Jugal</forenames></author><author><keyname>Mehta</keyname><forenames>Ruta</forenames></author><author><keyname>Vazirani</keyname><forenames>Vijay V.</forenames></author><author><keyname>Yazdanbod</keyname><forenames>Sadra</forenames></author></authors><title>A Market for Scheduling, with Applications to Cloud Computing</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a market for allocating and scheduling resources to agents who
have specified budgets and need to complete specific tasks. Two important
aspects required in this market are: (1) agents need specific amounts of each
resource to complete their tasks, and (2) agents would like to complete their
tasks as soon as possible. In incorporating these aspects, we arrive at a model
that deviates substantially from market models studied so far in economics and
theoretical computer science. Indeed, all known techniques developed to compute
equilibria in markets in the last decade and half seem not to apply here.
  We give a polynomial time algorithm for computing an equilibrium using a new
technique that is somewhat reminiscent of the \emph{ironing} procedure used in
the characterization of optimal auctions by Myerson. This is inspite of the
fact that the set of equilibrium prices could be non-convex; in fact it could
have &quot;holes&quot;. Our market model is motivated by the cloud computing marketplace.
Even though this market is already huge and is projected to grow at a massive
rate, it is currently run in an ad hoc manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08749</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08749</id><created>2015-11-27</created><authors><author><keyname>T&#xf6;r&#xf6;k</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Murase</keyname><forenames>Yohsuke</forenames></author><author><keyname>Jo</keyname><forenames>Hang-Hyun</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author></authors><title>What does Big Data tell? Sampling the social network by communication
  channels</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Big Data has become the primary source of understanding the structure and
dynamics of the society at large scale. The network of social interactions can
be considered as a multiplex, where each layer corresponds to one communication
channel and the aggregate of all them constitutes the entire social network.
However, usually one has information only about one of the channels, which
should be considered as a sample of the whole. Here we show by simulations and
analytical methods that this sampling may lead to bias. For example, while it
is expected that the degree distribution of the whole social network has a
maximum at a value larger than one, we get with reasonable assumptions about
the sampling process a monotonously decreasing distribution as observed in
empirical studies of single channel data. Also we find, that assortativity may
occur or get strengthened due to the sampling process. We analyze the
far-reaching consequences of our findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08756</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08756</id><created>2015-11-27</created><updated>2015-11-30</updated><authors><author><keyname>Pessl</keyname><forenames>Peter</forenames></author><author><keyname>Gruss</keyname><forenames>Daniel</forenames></author><author><keyname>Maurice</keyname><forenames>Cl&#xe9;mentine</forenames></author><author><keyname>Schwarz</keyname><forenames>Michael</forenames></author><author><keyname>Mangard</keyname><forenames>Stefan</forenames></author></authors><title>Reverse Engineering Intel DRAM Addressing and Exploitation</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a method to reverse engineer DRAM addressing
functions based on a physical bus probing. Second, we present an automatic and
generic method to reverse engineer DRAM addressing functions merely from
performing a timing attack. This timing attack can be performed on any system
without privileges and even in virtual machines to derive information about the
mapping to physical DRAM channels, ranks and banks. We reversed the complex
adressing functions on a diverse set of Intel processors and DRAM
configurations. Our work enables side-channel attacks and covert channels based
on inner-bank row conflicts and overlaps. Thus, our attack does not exploit the
CPU as a shared resource, but only the DRAM that might even be shared across
multiple CPUs. We demonstrate the power of such attacks by implementing a high
speed covert channel that achieves transmission rates of up to 1.5Mb/s, which
is three orders of magnitude faster than current covert channels on main
memory. Finally, we show how our results can be used to increase the efficiency
of the Rowhammer attack significantly by reducing the search space by a factor
of up to 16384.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08762</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08762</id><created>2015-11-27</created><authors><author><keyname>De Bie</keyname><forenames>Tijl</forenames></author><author><keyname>Lijffijt</keyname><forenames>Jefrey</forenames></author><author><keyname>Santos-Rodriguez</keyname><forenames>Raul</forenames></author><author><keyname>Kang</keyname><forenames>Bo</forenames></author></authors><title>Informative Data Projections: A Framework and Two Examples</title><categories>cs.LG cs.IR math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Methods for Projection Pursuit aim to facilitate the visual exploration of
high-dimensional data by identifying interesting low-dimensional projections. A
major challenge is the design of a suitable quality metric of projections,
commonly referred to as the projection index, to be maximized by the Projection
Pursuit algorithm. In this paper, we introduce a new information-theoretic
strategy for tackling this problem, based on quantifying the amount of
information the projection conveys to a user given their prior beliefs about
the data. The resulting projection index is a subjective quantity, explicitly
dependent on the intended user. As a useful illustration, we developed this
idea for two particular kinds of prior beliefs. The first kind leads to PCA
(Principal Component Analysis), shining new light on when PCA is (not)
appropriate. The second kind leads to a novel projection index, the
maximization of which can be regarded as a robust variant of PCA. We show how
this projection index, though non-convex, can be effectively maximized using a
modified power method as well as using a semidefinite programming relaxation.
The usefulness of this new projection index is demonstrated in comparative
empirical experiments against PCA and a popular Projection Pursuit method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08769</identifier>
 <datestamp>2016-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08769</id><created>2015-11-27</created><updated>2016-01-04</updated><authors><author><keyname>Javanmard</keyname><forenames>Adel</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Ricci-Tersenghi</keyname><forenames>Federico</forenames></author></authors><title>Phase Transitions in Semidefinite Relaxations</title><categories>cond-mat.stat-mech cs.DM cs.IT math.IT</categories><comments>71 pages, 24 pdf figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Statistical inference problems arising within signal processing, data mining,
and machine learning naturally give rise to hard combinatorial optimization
problems. These problems become intractable when the dimensionality of the data
is large, as is often the case for modern datasets. A popular idea is to
construct convex relaxations of these combinatorial problems, which can be
solved efficiently for large scale datasets.
  Semidefinite programming (SDP) relaxations are among the most powerful
methods in this family, and are surprisingly well-suited for a broad range of
problems where data take the form of matrices or graphs. It has been observed
several times that, when the `statistical noise' is small enough, SDP
relaxations correctly detect the underlying combinatorial structures.
  In this paper we develop asymptotic predictions for several `detection
thresholds,' as well as for the estimation error above these thresholds. We
study some classical SDP relaxations for statistical problems motivated by
graph synchronization and community detection in networks. We map these
optimization problems to statistical mechanics models with vector spins, and
use non-rigorous techniques from statistical mechanics to characterize the
corresponding phase transitions. Our results clarify the effectiveness of SDP
relaxations in solving high-dimensional statistical problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08774</identifier>
 <datestamp>2015-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08774</id><created>2015-11-27</created><updated>2015-12-13</updated><authors><author><keyname>Yu</keyname><forenames>Xiangyao</forenames></author><author><keyname>Liu</keyname><forenames>Hongzhe</forenames></author><author><keyname>Zou</keyname><forenames>Ethan</forenames></author><author><keyname>Devadas</keyname><forenames>Srinivas</forenames></author></authors><title>Tardis 2.0: An Optimized Time Traveling Coherence Protocol</title><categories>cs.AR</categories><comments>13 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The scalability of cache coherence protocols is a significant challenge in
multicore and other distributed shared memory systems. Traditional snoopy and
directory-based coherence protocols are difficult to scale up to many-core
systems because of the overhead of broadcasting and storing sharers for each
cacheline. Tardis, a recently proposed coherence protocol, shows potential in
solving the scalability problem, since it only requires O(logN) storage per
cacheline for an N-core system and needs no broadcasting support.
  The original Tardis protocol, however, only supports the sequential
consistency memory model. This limits its applicability in real systems since
most processors today implement relaxed consistency models like Total Store
Order (TSO). Tardis also incurs large network traffic overhead on some
benchmarks due to an excessive number of renew messages. Furthermore, the
original Tardis protocol has suboptimal performance when the program uses
spinning to communicate between threads.
  In this paper, we address these downsides of Tardis protocol and make it
significantly more practical. Specifically, we discuss the architectural,
memory system and protocol changes required in order to implement TSO
consistency model on Tardis, and prove that the modified protocol satisfies
TSO. We also propose optimizations for better leasing policies and to handle
program spinning. Evaluated on 20 benchmarks, optimized Tardis at 64 (256)
cores can achieve average performance improvement of 15.8% (8.4%) compared to
the baseline Tardis and 1% (3.4%) compared to the baseline directory protocol.
Our optimizations also reduce the average network traffic by 4.3% (6.1%)
compared to the baseline directory protocol. On this set of benchmarks,
optimized Tardis improves on a fullmap directory protocol in the metrics of
energy, performance and storage, while being simpler to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08779</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08779</id><created>2015-11-27</created><authors><author><keyname>Tampuu</keyname><forenames>Ardi</forenames></author><author><keyname>Matiisen</keyname><forenames>Tambet</forenames></author><author><keyname>Kodelja</keyname><forenames>Dorian</forenames></author><author><keyname>Kuzovkin</keyname><forenames>Ilya</forenames></author><author><keyname>Korjus</keyname><forenames>Kristjan</forenames></author><author><keyname>Aru</keyname><forenames>Juhan</forenames></author><author><keyname>Aru</keyname><forenames>Jaan</forenames></author><author><keyname>Vicente</keyname><forenames>Raul</forenames></author></authors><title>Multiagent Cooperation and Competition with Deep Reinforcement Learning</title><categories>cs.AI cs.LG q-bio.NC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiagent systems appear in most social, economical, and political
situations. In the present work we extend the Deep Q-Learning Network
architecture proposed by Google DeepMind to multiagent environments and
investigate how two agents controlled by independent Deep Q-Networks interact
in the classic videogame Pong. By manipulating the classical rewarding scheme
of Pong we demonstrate how competitive and collaborative behaviors emerge.
Competitive agents learn to play and score efficiently. Agents trained under
collaborative rewarding schemes find an optimal strategy to keep the ball in
the game as long as possible. We also describe the progression from competitive
to collaborative behavior. The present work demonstrates that Deep Q-Networks
can become a practical tool for studying the decentralized learning of
multiagent systems living in highly complex environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08791</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08791</id><created>2015-11-27</created><authors><author><keyname>Arzani</keyname><forenames>Behnaz</forenames></author><author><keyname>Gurney</keyname><forenames>Alexander</forenames></author><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Han</keyname><forenames>Xianglong</forenames></author><author><keyname>Guerin</keyname><forenames>Roch</forenames></author><author><keyname>Loo</keyname><forenames>Boon Thau</forenames></author></authors><title>FixRoute: A Unified Logic and Numerical Tool for Provably Safe Internet
  Traffic Engineering</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of networks that use the Internet Protocol is sensitive to
precise configuration of many low-level parameters on each network device.
These settings govern the action of dynamic routing protocols, which direct the
flow of traffic; in order to ensure that these dynamic protocols all converge
to produce some 'optimal' flow, each parameter must be set correctly. Multiple
conflicting optimization objectives, nondeterminism, and the need to reason
about different failure scenarios make the task particularly complicated.
  We present a fast and flexible approach for the analysis of a number of such
management tasks presented in the context of BGP routing. The idea is to
combine {\em logical} satisfiability criteria with traditional {\em numerical}
optimization, to reach a desired traffic flow outcome subject to given
constraints on the routing process. The method can then be used to probe
parameter sensitivity, trade-offs in the selection of optimization goals,
resilience to failure, and so forth. The theory is underpinned by a rigorous
abstraction of the convergence of distributed asynchronous message-passing
protocols, and is therefore generalizable to other scenarios. Our resulting
hybrid engine is faster than either purely logical or purely numeric
alternatives, making it potentially feasible for interactive production use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08795</identifier>
 <datestamp>2015-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08795</id><created>2015-11-27</created><authors><author><keyname>Miller</keyname><forenames>Keith B.</forenames></author><author><keyname>Brandon</keyname><forenames>Eric R.</forenames></author></authors><title>Improving Network Monitoring and Security via Visualization</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet networks are handling increasing volume of traffic than ever before.
This data is mainly associated to sensitive, distributed, and multimedia
applications. In the past years, much attention has been paid to the way
network infrastructure must be designed and developed in order to handle the
challenges of delivering high quality services for applications such as VoIP
and streaming video.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08800</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08800</id><created>2015-11-27</created><authors><author><keyname>Li</keyname><forenames>Hong-Wei</forenames></author><author><keyname>Yang</keyname><forenames>Li</forenames></author></authors><title>Quantum differential cryptanalysis to the block ciphers</title><categories>quant-ph cs.CR</categories><comments>11 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential cryptanalysis is one of the most popular methods in attacking
block ciphers. However, there still some limitations in traditional
differential cryptanalysis. On the other hand, researches of quantum algorithms
have made great progress nowadays. This paper proposes two methods to apply
quantum algorithms in differential cryptanalysis, and analysis their
efficiencies and success probabilities. One method is using quantum algorithm
in the high probability differential finding period for every S-Box. The second
method is taking the encryption as a whole, using quantum algorithm in this
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08827</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08827</id><created>2015-11-27</created><authors><author><keyname>Raza</keyname><forenames>Arif</forenames></author><author><keyname>Capretz</keyname><forenames>Luiz Fernando</forenames></author><author><keyname>Ahmed</keyname><forenames>Faheem</forenames></author></authors><title>Maintenance Support in Open Source Software Projects</title><categories>cs.SE</categories><doi>10.1109/ICDIM.2013.6694005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Easy and mostly free access to the internet has resulted in the growing use
of open source software (OSS). However, it is a common perception that closed
proprietary software is still superior in areas such as software maintenance
and management. The research model of this study establishes a relationship
between maintenance issues (such as user requests and error handling) and
support provided by open source software through project forums, mailing lists
and trackers. To conduct this research, we have used a dataset consisting of
120 open source software projects, covering a wide range of categories. The
results of the study show that project forums and mailing lists play a
significant role in addressing user requests in open source software. However
according to the empirical investigation, it has been explored that trackers
are used as an effective medium for error reporting as well as user requests.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08839</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08839</id><created>2015-11-27</created><authors><author><keyname>Darwish</keyname><forenames>Marwan</forenames></author><author><keyname>Ouda</keyname><forenames>Abdelkader</forenames></author><author><keyname>Capretz</keyname><forenames>Luiz Fernando</forenames></author></authors><title>Cloud-based DDoS Attacks and Defenses</title><categories>cs.CR</categories><journal-ref>IEEE International Conference on Information Society (i-Society
  2013), pp. 67-71, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Safety and reliability are important in the cloud computing environment. This
is especially true today as distributed denial-of-service (DDoS) attacks
constitute one of the largest threats faced by Internet users and cloud
computing services. DDoS attacks target the resources of these services,
lowering their ability to provide optimum usage of the network infrastructure.
Due to the nature of cloud computing, the methodologies for preventing or
stopping DDoS attacks are quite different compared to those used in traditional
networks. In this paper, we investigate the effect of DDoS attacks on cloud
resources and recommend practical defense mechanisms against different types of
DDoS attacks in the cloud environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08840</identifier>
 <datestamp>2015-12-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08840</id><created>2015-11-27</created><authors><author><keyname>Alrasheedi</keyname><forenames>Muasaad</forenames></author><author><keyname>Capretz</keyname><forenames>Luiz Fernando</forenames></author></authors><title>Applying CMM Towards an m-Learning Context</title><categories>cs.CY</categories><journal-ref>IEEE International Conference on Information Society (i-Society
  2013), pp. 146-151, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the era of m-Learning, it is found that educational institutions have onus
of incorporating the latest technological innovations that can be accepted and
understood widely. While investigating the important theme of fast-paced
development of emerging technologies in mobile communications, it is important
to recognize the extent influence of these innovations using which society can
communicate, learn, access information, and, additionally, interact. In
addition, the usage of mobile technology in higher education needs not only the
pervasive nature of the technology but also its disruptive nature that offers
several challenges while incorporation in the area of teaching and learning.
Therefore, recently, higher education institutions are looking at various ways
of implementing m-Learning strategies, in order to offer solutions, which, in
turn, can standardize the process of education and, additionally, replace those
traditional didactic courses, focusing on m-Learning endless benefits. Some of
the benefits are: the process of learning itself could be self-paced, whereas
information could be easier accessed, adding to independent, discovery-oriented
learning that becomes more engaging. Applying CMM successfully to design
effective incorporation strategies of m-Learning, this research targets
formulation of such a maturity model by which the process of m-Learning can be
more effective and efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08841</identifier>
 <datestamp>2016-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08841</id><created>2015-11-27</created><updated>2016-02-18</updated><authors><author><keyname>Gajarsk&#xfd;</keyname><forenames>Jakub</forenames></author><author><keyname>Hlin&#x11b;n&#xfd;</keyname><forenames>Petr</forenames></author><author><keyname>Tiwary</keyname><forenames>Hans Raj</forenames></author></authors><title>Parameterized Extension Complexity of Independent Set and Related
  Problems</title><categories>cs.CC</categories><comments>12 pages</comments><acm-class>G.1.6; G.2.2; F.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $G$ be a graph on $n$ vertices and $STAB_k(G)$ be the convex hull of
characteristic vectors of its independent sets of size at most $k$. It is known
that optimizing over $STAB_k(G)$ is $W[1]$-hard and is $FPT$ tractable for
graphs of bounded expansion. We show analogous results for the extension
complexity of $STAB_k(G)$. In particular, we show that when $G$ is a graph from
a class of bounded expansion then $xc(STAB_k(G))\leqslant O(f(k)\cdot n)$ for
some function $f$ (depending only on the class). This result can be extended in
a simple way to a wide range of similarly defined graph polytopes. In case of
general graphs we show that there is \emph{no function} $f$ such that, for all
natural numbers $k$ and for all graphs on $n$ vertices, the extension
complexity of $STAB_k(G)$ is at most $f(k)\cdot n^{O(1)}.$
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1511.08842</identifier>
 <datestamp>2015-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1511.08842</id><created>2015-11-27</created><authors><author><keyname>Ravishankar</keyname><forenames>Saiprasad</forenames></author><author><keyname>Nadakuditi</keyname><forenames>Raj Rao</forenames></author><author><keyname>Fessler</keyname><forenames>Jeffrey A.</forenames></author></authors><title>Efficient Sum of Outer Products Dictionary Learning (SOUP-DIL) - The
  $\ell_0$ Method</title><categories>cs.LG</categories><comments>A short version of this work [arXiv:1511.06333] has also been
  submitted to ICLR 2016</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sparsity of natural signals and images in a transform domain or
dictionary has been extensively exploited in several applications such as
compression, denoising and inverse problems. More recently, data-driven
adaptation of synthesis dictionaries has shown promise in many applications
compared to fixed or analytical dictionary models. However, dictionary learning
problems are typically non-convex and NP-hard, and the usual alternating
minimization approaches for these problems are often computationally expensive,
with the computations dominated by the NP-hard synthesis sparse coding step. In
this work, we investigate an efficient method for $\ell_{0}$ &quot;norm&quot;-based
dictionary learning by first approximating the training data set with a sum of
sparse rank-one matrices and then using a block coordinate descent approach to
estimate the unknowns. The proposed block coordinate descent algorithm involves
efficient closed-form solutions. In particular, the sparse coding step involves
a simple form of thresholding. We provide a convergence analysis for the
proposed block coordinate descent approach. Our numerical experiments show the
promising performance and significant speed-ups provided by our method over the
classical K-SVD scheme in sparse signal representation and image denoising.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="87000" completeListSize="102538">1122234|88001</resumptionToken>
</ListRecords>
</OAI-PMH>
