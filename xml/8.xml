<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:39:50Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|7001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1084</identifier>
 <datestamp>2009-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1084</id><created>2009-04-07</created><authors><author><keyname>Mawussi</keyname><forenames>Kwamiwi</forenames><affiliation>LURPA</affiliation></author><author><keyname>Lavernhe</keyname><forenames>Sylvain</forenames><affiliation>LURPA</affiliation></author><author><keyname>Lartigue</keyname><forenames>Claire</forenames><affiliation>LURPA</affiliation></author></authors><title>Usinage de poches en UGV - Aide au choix de strat\'egies</title><categories>cs.OH</categories><proxy>ccsd hal-00373733</proxy><journal-ref>Revue Internationale de CFAO et d'informatique graphique 18, 3
  (2003) 337-349</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper deals with associating the optimal machining strategy to a given
pocket geometry, within the context of High-Speed Machining (HSM) of
aeronautical pockets. First we define different classes of pocket features
according to geometrical criteria. Following, we propose a method allowing to
associate a set of capable tools to the features. Each capable tool defines a
machined zone with a specific geometry. The last part of the paper is thus
dedicated to associate the optimal machining strategy to a given geometry
within the context of HSM. Results highlight that analyses must be conducted in
a dynamical as well as a geometrical viewpoint. In particular, it becomes
necessary to integrate dynamical specifities associated to the behavior of the
couple machine/NC unit in the tool path calculation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1110</identifier>
 <datestamp>2009-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1110</id><created>2009-04-07</created><authors><author><keyname>Nowak</keyname><forenames>David</forenames></author></authors><title>On formal verification of arithmetic-based cryptographic primitives</title><categories>cs.CR cs.LO</categories><comments>13 pages</comments><journal-ref>In Information Security and Cryptology - ICISC 2008, 11th
  International Conference, Seoul, Korea, December 3-5, 2008, Proceedings,
  volume 5461 of Lecture Notes in Computer Science, pages 368-382, Springer</journal-ref><doi>10.1007/978-3-642-00730-9_23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cryptographic primitives are fundamental for information security: they are
used as basic components for cryptographic protocols or public-key
cryptosystems. In many cases, their security proofs consist in showing that
they are reducible to computationally hard problems. Those reductions can be
subtle and tedious, and thus not easily checkable. On top of the proof
assistant Coq, we had implemented in previous work a toolbox for writing and
checking game-based security proofs of cryptographic primitives. In this paper
we describe its extension with number-theoretic capabilities so that it is now
possible to write and check arithmetic-based cryptographic primitives in our
toolbox. We illustrate our work by machine checking the game-based proofs of
unpredictability of the pseudo-random bit generator of Blum, Blum and Shub, and
semantic security of the public-key cryptographic scheme of Goldwasser and
Micali.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1113</identifier>
 <datestamp>2009-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1113</id><created>2009-04-07</created><updated>2009-08-07</updated><authors><author><keyname>Arthur</keyname><forenames>David</forenames></author><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author><author><keyname>R&#xf6;glin</keyname><forenames>Heiko</forenames></author></authors><title>k-Means has Polynomial Smoothed Complexity</title><categories>cs.DS cs.CC cs.CG</categories><comments>Full version of FOCS 2009 paper. The argument has been improved and
  the restriction to at least three dimensions could be dropped</comments><acm-class>F.2.2; I.5.3; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The k-means method is one of the most widely used clustering algorithms,
drawing its popularity from its speed in practice. Recently, however, it was
shown to have exponential worst-case running time. In order to close the gap
between practical performance and theoretical analysis, the k-means method has
been studied in the model of smoothed analysis. But even the smoothed analyses
so far are unsatisfactory as the bounds are still super-polynomial in the
number n of data points.
  In this paper, we settle the smoothed running time of the k-means method. We
show that the smoothed number of iterations is bounded by a polynomial in n and
1/\sigma, where \sigma is the standard deviation of the Gaussian perturbations.
This means that if an arbitrary input data set is randomly perturbed, then the
k-means method will run in expected polynomial time on that input set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1144</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1144</id><created>2009-04-07</created><authors><author><keyname>Sanudo</keyname><forenames>Jaime</forenames></author><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author></authors><title>Alternative evaluation of statistical indicators in atoms: the
  non-relativistic and relativistic cases</title><categories>nlin.AO cs.IT math.IT physics.atom-ph</categories><comments>8 pages, 4 figures</comments><doi>10.1016/j.physleta.2009.05.030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, the calculation of a statistical measure of complexity and the
Fisher-Shannon information is performed for all the atoms in the periodic
table. Non-relativistic and relativistic cases are considered. We follow the
method suggested in [C.P. Panos, N.S. Nikolaidis, K. Ch. Chatzisavvas, C.C.
Tsouros, arXiv:0812.3963v1] that uses the fractional occupation probabilities
of electrons in atomic orbitals, instead of the continuous electronic wave
functions. For the order of shell filling in the relativistic case, we take
into account the effect due to electronic spin-orbit interaction. The
increasing of both magnitudes, the statistical complexity and the
Fisher-Shannon information, with the atomic number $Z$ is observed. The shell
structure and the irregular shell filling is well displayed by the
Fisher-Shannon information in the relativistic case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1149</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1149</id><created>2009-04-07</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>Chaitin \Omega numbers and halting problems</title><categories>math.LO cs.CC cs.IT math.IT</categories><comments>17 pages, LaTeX2e, no figures. This is an earlier full version of the
  paper that will appear in the Proceedings of Computability in Europe 2009,
  Heidelberg, Germany, July 19 - 24, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Chaitin [G. J. Chaitin, J. Assoc. Comput. Mach., vol.22, pp.329-340, 1975]
introduced \Omega number as a concrete example of random real. The real \Omega
is defined as the probability that an optimal computer halts, where the optimal
computer is a universal decoding algorithm used to define the notion of
program-size complexity. Chaitin showed \Omega to be random by discovering the
property that the first n bits of the base-two expansion of \Omega solve the
halting problem of the optimal computer for all binary inputs of length at most
n. In the present paper we investigate this property from various aspects. We
consider the relative computational power between the base-two expansion of
\Omega and the halting problem by imposing the restriction to finite size on
both the problems. It is known that the base-two expansion of \Omega and the
halting problem are Turing equivalent. We thus consider an elaboration of the
Turing equivalence in a certain manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1150</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1150</id><created>2009-04-07</created><updated>2012-07-28</updated><authors><author><keyname>Huang</keyname><forenames>Xiujie</forenames></author><author><keyname>Kavcic</keyname><forenames>Aleksandar</forenames></author><author><keyname>Ma</keyname><forenames>Xiao</forenames></author></authors><title>Upper Bounds on the Capacities of Noncontrollable Finite-State Channels
  with/without Feedback</title><categories>cs.IT cs.SY math.IT math.OC</categories><comments>15 pages, Two columns, 6 figures; appears in IEEE Transaction on
  Information Theory</comments><report-no>CLN: 9-255</report-no><acm-class>H.1.1; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Noncontrollable finite-state channels (FSCs) are FSCs in which the channel
inputs have no influence on the channel states, i.e., the channel states evolve
freely. Since single-letter formulae for the channel capacities are rarely
available for general noncontrollable FSCs, computable bounds are usually
utilized to numerically bound the capacities. In this paper, we take the
delayed channel state as part of the channel input and then define the {\em
directed information rate} from the new channel input (including the source and
the delayed channel state) sequence to the channel output sequence. With this
technique, we derive a series of upper bounds on the capacities of
noncontrollable FSCs with/without feedback. These upper bounds can be achieved
by conditional Markov sources and computed by solving an average reward per
stage stochastic control problem (ARSCP) with a compact state space and a
compact action space. By showing that the ARSCP has a uniformly continuous
reward function, we transform the original ARSCP into a finite-state and
finite-action ARSCP that can be solved by a value iteration method. Under a
mild assumption, the value iteration algorithm is convergent and delivers a
near-optimal stationary policy and a numerical upper bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1186</identifier>
 <datestamp>2009-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1186</id><created>2009-04-07</created><authors><author><keyname>Grohmann</keyname><forenames>Bjoern</forenames></author></authors><title>A New Key-Agreement-Protocol</title><categories>cs.CR</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new 4-pass Key-Agreement Protocol is presented. The security of the
protocol mainly relies on the existence of a (polynomial-computable)
One-Way-Function and the supposed computational hardness of solving a specific
system of equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1193</identifier>
 <datestamp>2009-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1193</id><created>2009-04-07</created><authors><author><keyname>Maleki</keyname><forenames>Arian</forenames></author></authors><title>Coherence Analysis of Iterative Thresholding Algorithms</title><categories>cs.IT math.IT</categories><comments>6 pages, o figures, partially submitted to Signale Processing Letter</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a recent surge of interest in developing algorithms for finding
sparse solutions of underdetermined systems of linear equations $y = \Phi x$.
In many applications, extremely large problem sizes are envisioned, with at
least tens of thousands of equations and hundreds of thousands of unknowns. For
such problem sizes, low computational complexity is paramount. The best studied
$\ell_1$ minimization algorithm is not fast enough to fulfill this need.
Iterative thresholding algorithms have been proposed to address this problem.
In this paper we want to analyze two of these algorithms theoretically, and
give sufficient conditions under which they recover the sparsest solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1227</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1227</id><created>2009-04-07</created><authors><author><keyname>Goyal</keyname><forenames>Navin</forenames></author><author><keyname>Rademacher</keyname><forenames>Luis</forenames></author></authors><title>Learning convex bodies is hard</title><categories>cs.LG cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that learning a convex body in $\RR^d$, given random samples from the
body, requires $2^{\Omega(\sqrt{d/\eps})}$ samples. By learning a convex body
we mean finding a set having at most $\eps$ relative symmetric difference with
the input body. To prove the lower bound we construct a hard to learn family of
convex bodies. Our construction of this family is very simple and based on
error correcting codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1229</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1229</id><created>2009-04-07</created><authors><author><keyname>Pikhurko</keyname><forenames>Oleg</forenames></author></authors><title>Finding an Unknown Acyclic Orientation of a Given Graph</title><categories>math.CO cs.IT math.IT</categories><comments>12 pages</comments><msc-class>68P10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let c(G) be the smallest number of edges we have to test in order to
determine an unknown acyclic orientation of the given graph G in the worst
case. For example, if G is the complete graph on n vertices, then c(G) is the
smallest number of comparisons needed to sort n numbers.
  We prove that c(G)\le (1/4+o(1))n^2 for any graph G on n vertices, answering
in the affirmative a question of Aigner, Triesch, and Tuza [Discrete
Mathematics, 144 (1995) 3-10]. Also, we show that, for every e&gt;0, it is NP-hard
to approximate the parameter c(G) within a multiplicative factor 74/73-e.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1234</identifier>
 <datestamp>2011-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1234</id><created>2009-04-07</created><updated>2010-04-22</updated><authors><author><keyname>Herrera</keyname><forenames>Mark</forenames></author><author><keyname>Roberts</keyname><forenames>David C.</forenames></author><author><keyname>Gulbahce</keyname><forenames>Natali</forenames></author></authors><title>Mapping the evolution of scientific fields</title><categories>physics.soc-ph cs.DL cs.IR</categories><comments>v3: re-ran analysis with new noise parameter choice; 10 pages for
  main paper; 11 pages for suppl. info</comments><journal-ref>PLoS ONE 5(5): e10355. 2010</journal-ref><doi>10.1371/journal.pone.0010355</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite the apparent cross-disciplinary interactions among scientific fields,
a formal description of their evolution is lacking. Here we describe a novel
approach to study the dynamics and evolution of scientific fields using a
network-based analysis. We build an idea network consisting of American
Physical Society Physics and Astronomy Classification Scheme (PACS) numbers as
nodes representing scientific concepts. Two PACS numbers are linked if there
exist publications that reference them simultaneously. We locate scientific
fields using a community finding algorithm, and describe the time evolution of
these fields over the course of 1985-2006. The communities we identify map to
known scientific fields, and their age depends on their size and activity. We
expect our approach to quantifying the evolution of ideas to be relevant for
making predictions about the future of science and thus help to guide its
development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1242</identifier>
 <datestamp>2010-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1242</id><created>2009-04-07</created><updated>2010-04-29</updated><authors><author><keyname>Ning</keyname><forenames>Kang</forenames></author><author><keyname>Leong</keyname><forenames>Hon Wai</forenames></author></authors><title>The Distribution and Deposition Algorithm for Multiple Sequences Sets</title><categories>cs.DS cs.DC cs.DM</categories><comments>15 pages, 7 figures, extended version of conference paper presented
  on GIW 2006, revised version accepted by Journal of Combinatorial
  Optimization.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequences set is a mathematical model used in many applications. As the
number of the sequences becomes larger, single sequence set model is not
appropriate for the rapidly increasing problem sizes. For example, more and
more text processing applications separate a single big text file into multiple
files before processing. For these applications, the underline mathematical
model is multiple sequences sets (MSS). Though there is increasing use of MSS,
there is little research on how to process MSS efficiently. To process multiple
sequences sets, sequences are first distributed to different sets, and then
sequences for each set are processed. Deriving effective algorithm for MSS
processing is both interesting and challenging. In this paper, we have defined
the cost functions and performance ratio for analysis of the quality of
synthesis sequences. Based on these, the problem of Process of Multiple
Sequences Sets (PMSS) is formulated. We have first proposed two greedy
algorithms for the PMSS problem, which are based on generalization of
algorithms for single sequences set. Then based on the analysis of the
characteristics of multiple sequences sets, we have proposed the Distribution
and Deposition (DDA) algorithm and DDA* algorithm for PMSS problem. In DDA
algorithm, the sequences are first distributed to multiple sets according to
their alphabet contents; then sequences in each set are deposited by the
deposition algorithm. The DDA* algorithm differs from the DDA algorithm in that
the DDA* algorithm distributes sequences by clustering based on sequence
profiles. Experiments show that DDA and DDA* always output results with smaller
costs than other algorithms, and DDA* outperforms DDA in most instances. The
DDA and DDA* algorithms are also efficient both in time and space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1243</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1243</id><created>2009-04-08</created><authors><author><keyname>Bruno</keyname><forenames>Raffaele</forenames></author><author><keyname>Conan</keyname><forenames>Vania</forenames></author><author><keyname>Rousseau</keyname><forenames>Stephane</forenames></author></authors><title>Maximizing the number of accepted flows in TDMA-based wireless ad hoc
  networks is APX-complete</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Full exploitation of the bandwidth resources of Wireless Networks is
challenging because of the sharing of the radio medium among neighboring nodes.
Practical algorithms and distributed schemes that tries to optimising the use
of the network radio resources. In this technical report we present the proof
that maximising the network capacity is is an APX Complete problem (not
approximable within 1/(1 - 2^(-k)) - eps for eps &gt; 0).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1258</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1258</id><created>2009-04-07</created><updated>2009-04-13</updated><authors><author><keyname>Niu</keyname><forenames>Jinzhong</forenames></author><author><keyname>Parsons</keyname><forenames>Simon</forenames></author></authors><title>An Investigation Report on Auction Mechanism Design</title><categories>cs.AI cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Auctions are markets with strict regulations governing the information
available to traders in the market and the possible actions they can take.
Since well designed auctions achieve desirable economic outcomes, they have
been widely used in solving real-world optimization problems, and in
structuring stock or futures exchanges. Auctions also provide a very valuable
testing-ground for economic theory, and they play an important role in
computer-based control systems.
  Auction mechanism design aims to manipulate the rules of an auction in order
to achieve specific goals. Economists traditionally use mathematical methods,
mainly game theory, to analyze auctions and design new auction forms. However,
due to the high complexity of auctions, the mathematical models are typically
simplified to obtain results, and this makes it difficult to apply results
derived from such models to market environments in the real world. As a result,
researchers are turning to empirical approaches.
  This report aims to survey the theoretical and empirical approaches to
designing auction mechanisms and trading strategies with more weights on
empirical ones, and build the foundation for further research in the field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1281</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1281</id><created>2009-04-08</created><updated>2009-09-24</updated><authors><author><keyname>Kleiner</keyname><forenames>Marius</forenames></author><author><keyname>Rimoldi</keyname><forenames>Bixio</forenames></author></authors><title>Asymptotically Optimal Joint Source-Channel Coding with Minimal Delay</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, final version accepted at IEEE Globecom 2009
  (Communication Theory Symposium)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and analyze a joint source-channel coding strategy for the
transmission of a Gaussian source across a Gaussian channel in n channel uses
per source symbol. Among all such strategies, our scheme has the following
properties: i) the resulting mean-squared error scales optimally with the
signal-to-noise ratio, and ii) the scheme is easy to implement and the incurred
delay is minimal, in the sense that a single source symbol is encoded at a
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1284</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1284</id><created>2009-04-08</created><authors><author><keyname>Inuma</keyname><forenames>Manabu</forenames></author><author><keyname>Otsuka</keyname><forenames>Akira</forenames></author><author><keyname>Imai</keyname><forenames>Hideki</forenames></author></authors><title>Theoretical framework for constructing matching algorithms in biometric
  authentication systems</title><categories>cs.CR cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a theoretical framework to construct matching
algorithms for any biometric authentication systems. Conventional matching
algorithms are not necessarily secure against strong intentional impersonation
attacks such as wolf attacks. The wolf attack is an attempt to impersonate a
genuine user by presenting a &quot;wolf&quot; to a biometric authentication system
without the knowledge of a genuine user's biometric sample. A wolf is a sample
which can be accepted as a match with multiple templates. The wolf attack
probability (WAP) is the maximum success probability of the wolf attack, which
was proposed by Une, Otsuka, Imai as a measure for evaluating security of
biometric authentication systems. We present a principle for construction of
secure matching algorithms against the wolf attack for any biometric
authentication systems. The ideal matching algorithm determines a threshold for
each input value depending on the entropy of the probability distribution of
the (Hamming) distances. Then we show that if the information about the
probability distribution for each input value is perfectly given, then our
matching algorithm is secure against the wolf attack. Our generalized matching
algorithm gives a theoretical framework to construct secure matching
algorithms. How lower WAP is achievable depends on how accurately the entropy
is estimated. Then there is a trade-off between the efficiency and the
achievable WAP. Almost every conventional matching algorithm employs a fixed
threshold and hence it can be regarded as an efficient but insecure instance of
our theoretical framework. Daugman's IrisCode recognition algorithm proposed
can also be regarded as a non-optimal instance of our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1289</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1289</id><created>2009-04-08</created><authors><author><keyname>Choudhury</keyname><forenames>Monojit</forenames></author><author><keyname>Mukherjee</keyname><forenames>Animesh</forenames></author><author><keyname>Basu</keyname><forenames>Anupam</forenames></author><author><keyname>Ganguly</keyname><forenames>Niloy</forenames></author><author><keyname>Garg</keyname><forenames>Ashish</forenames></author><author><keyname>Jalan</keyname><forenames>Vaibhav</forenames></author></authors><title>Language Diversity across the Consonant Inventories: A Study in the
  Framework of Complex Networks</title><categories>cs.CL physics.comp-ph physics.soc-ph</categories><comments>In EACL 2009 Workshop on Cognitive Aspects of Computational Language
  Acquisition</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  n this paper, we attempt to explain the emergence of the linguistic diversity
that exists across the consonant inventories of some of the major language
families of the world through a complex network based growth model. There is
only a single parameter for this model that is meant to introduce a small
amount of randomness in the otherwise preferential attachment based growth
process. The experiments with this model parameter indicates that the choice of
consonants among the languages within a family are far more preferential than
it is across the families. The implications of this result are twofold -- (a)
there is an innate preference of the speakers towards acquiring certain
linguistic structures over others and (b) shared ancestry propels the stronger
preferential connection between the languages within a family than across them.
Furthermore, our observations indicate that this parameter might bear a
correlation with the period of existence of the language families under
investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1296</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1296</id><created>2009-04-08</created><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>On the perfect matching index of bridgeless cubic graphs</title><categories>cs.DM</categories><proxy>ccsd hal-00374313</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If $G$ is a bridgeless cubic graph, Fulkerson conjectured that we can find 6
perfect matchings $M_1,...,M_6$ of $G$ with the property that every edge of $G$
is contained in exactly two of them and Berge conjectured that its edge set can
be covered by 5 perfect matchings. We define $\tau(G)$ as the least number of
perfect matchings allowing to cover the edge set of a bridgeless cubic graph
and we study this parameter. The set of graphs with perfect matching index 4
seems interesting and we give some informations on this class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1299</identifier>
 <datestamp>2010-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1299</id><created>2009-04-08</created><authors><author><keyname>Riede</keyname><forenames>Moritz</forenames></author><author><keyname>Schueppel</keyname><forenames>Rico</forenames></author><author><keyname>Sylvester-Hvid</keyname><forenames>Kristian O.</forenames></author><author><keyname>Kuehne</keyname><forenames>Martin</forenames></author><author><keyname>Roettger</keyname><forenames>Michael C.</forenames></author><author><keyname>Zimmermann</keyname><forenames>Klaus</forenames></author><author><keyname>Liehr</keyname><forenames>Andreas W.</forenames></author></authors><title>On the Communication of Scientific Results: The Full-Metadata Format</title><categories>cs.DL cs.IR physics.comp-ph physics.ins-det</categories><report-no>SI20090302a</report-no><journal-ref>Comput.Phys.Commun.181:651-662,2010</journal-ref><doi>10.1016/j.cpc.2009.11.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a scientific format for text-based data files,
which facilitates storing and communicating tabular data sets. The so-called
Full-Metadata Format builds on the widely used INI-standard and is based on
four principles: readable self-documentation, flexible structure, fail-safe
compatibility, and searchability. As a consequence, all metadata required to
interpret the tabular data are stored in the same file, allowing for the
automated generation of publication-ready tables and graphs and the semantic
searchability of data file collections. The Full-Metadata Format is introduced
on the basis of three comprehensive examples. The complete format and syntax is
given in the appendix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1302</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1302</id><created>2009-04-08</created><authors><author><keyname>Kreutzer</keyname><forenames>Stephan</forenames></author></authors><title>On the Parameterised Intractability of Monadic Second-Order Logic</title><categories>cs.LO cs.CC</categories><comments>23 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of Courcelle's celebrated results states that if C is a class of graphs
of bounded tree-width, then model-checking for monadic second order logic is
fixed-parameter tractable on C by linear time parameterised algorithms. An
immediate question is whether this is best possible or whether the result can
be extended to classes of unbounded tree-width.
  In this paper we show that in terms of tree-width, the theorem can not be
extended much further. More specifically, we show that if C is a class of
graphs which is closed under colourings and satisfies certain constructibility
conditions such that the tree-width of C is not bounded by log^{16}(n) then
MSO_2-model checking is not fixed-parameter tractable unless the satisfiability
problem SAT for propositional logic can be solved in sub-exponential time. If
the tree-width of C is not poly-logarithmically bounded, then MSO_2-model
checking is not fixed-parameter tractable unless all problems in the
polynomial-time hierarchy, and hence in particular all problems in NP, can be
solved in sub-exponential time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1313</identifier>
 <datestamp>2009-04-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1313</id><created>2009-04-08</created><authors><author><keyname>Zhang</keyname><forenames>Hao</forenames></author><author><keyname>Li</keyname><forenames>Gang</forenames></author><author><keyname>Meng</keyname><forenames>Huadong</forenames></author></authors><title>A Class of Novel STAP Algorithms Using Sparse Recovery Technique</title><categories>cs.IT math.IT</categories><comments>8 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of novel STAP algorithms based on sparse recovery technique were
presented. Intrinsic sparsity of distribution of clutter and target energy on
spatial-frequency plane was exploited from the viewpoint of compressed sensing.
The original sample data and distribution of target and clutter energy was
connected by a ill-posed linear algebraic equation and popular $L_1$
optimization method could be utilized to search for its solution with sparse
characteristic. Several new filtering algorithm acting on this solution were
designed to clean clutter component on spatial-frequency plane effectively for
detecting invisible targets buried in clutter. The method above is called
CS-STAP in general. CS-STAP showed their advantage compared with conventional
STAP technique, such as SMI, in two ways: Firstly, the resolution of CS-STAP on
estimation for distribution of clutter and target energy is ultra-high such
that clutter energy might be annihilated almost completely by carefully tuned
filter. Output SCR of CS-STAP algorithms is far superior to the requirement of
detection; Secondly, a much smaller size of training sample support compared
with SMI method is requested for CS-STAP method. Even with only one snapshot
(from target range cell) could CS-STAP method be able to reveal the existence
of target clearly. CS-STAP method display its great potential to be used in
heterogeneous situation. Experimental result on dataset from mountaintop
program has provided the evidence for our assertion on CS-STAP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1331</identifier>
 <datestamp>2011-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1331</id><created>2009-04-08</created><updated>2010-03-28</updated><authors><author><keyname>Ghorpade</keyname><forenames>Sudhir R.</forenames></author><author><keyname>Hasan</keyname><forenames>Sartaj Ul</forenames></author><author><keyname>Kumari</keyname><forenames>Meena</forenames></author></authors><title>Primitive Polynomials, Singer Cycles, and Word-Oriented Linear Feedback
  Shift Registers</title><categories>math.CO cs.IT math.IT</categories><comments>Version 2 with some minor changes; to appear in Designs, Codes and
  Cryptography.</comments><msc-class>11T06, 11T31, 20G40, 94A60</msc-class><journal-ref>Designs, Codes and Cryptography, Vol. 58, No. 2 (2011), pp.
  123-134</journal-ref><doi>10.1007/s10623-010-9387-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using the structure of Singer cycles in general linear groups, we prove that
a conjecture of Zeng, Han and He (2007) holds in the affirmative in a special
case, and outline a plausible approach to prove it in the general case. This
conjecture is about the number of primitive $\sigma$-LFSRs of a given order
over a finite field, and it generalizes a known formula for the number of
primitive LFSRs, which, in turn, is the number of primitive polynomials of a
given degree over a finite field. Moreover, this conjecture is intimately
related to an open question of Niederreiter (1995) on the enumeration of
splitting subspaces of a given dimension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1366</identifier>
 <datestamp>2010-12-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1366</id><created>2009-04-08</created><updated>2010-12-15</updated><authors><author><keyname>Li</keyname><forenames>Jian</forenames></author><author><keyname>Saha</keyname><forenames>Barna</forenames></author><author><keyname>Deshpande</keyname><forenames>Amol</forenames></author></authors><title>A Unified Approach to Ranking in Probabilistic Databases</title><categories>cs.DB cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dramatic growth in the number of application domains that naturally
generate probabilistic, uncertain data has resulted in a need for efficiently
supporting complex querying and decision-making over such data. In this paper,
we present a unified approach to ranking and top-k query processing in
probabilistic databases by viewing it as a multi-criteria optimization problem,
and by deriving a set of features that capture the key properties of a
probabilistic dataset that dictate the ranked result. We contend that a single,
specific ranking function may not suffice for probabilistic databases, and we
instead propose two parameterized ranking functions, called PRF-w and PRF-e,
that generalize or can approximate many of the previously proposed ranking
functions. We present novel generating functions-based algorithms for
efficiently ranking large datasets according to these ranking functions, even
if the datasets exhibit complex correlations modeled using probabilistic
and/xor trees or Markov networks. We further propose that the parameters of the
ranking function be learned from user preferences, and we develop an approach
to learn those parameters. Finally, we present a comprehensive experimental
study that illustrates the effectiveness of our parameterized ranking
functions, especially PRF-e, at approximating other ranking functions and the
scalability of our proposed algorithms for exact or approximate ranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1369</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1369</id><created>2009-04-08</created><updated>2009-07-29</updated><authors><author><keyname>Paredes</keyname><forenames>Javier M.</forenames></author><author><keyname>Khalaj</keyname><forenames>Babak H.</forenames></author><author><keyname>Gershman</keyname><forenames>Alex B.</forenames></author></authors><title>Cooperative Transmission for Wireless Relay Networks Using Limited
  Feedback</title><categories>cs.IT math.IT</categories><comments>V1: 27 pages, 1 column, 6 figures. Submitted to IEEE Transactions on
  Signal Processing, February 2, 2009. V2: 30 pages, 1 column, 8 figures.
  Revised version submitted to IEEE Transactions on Signal Processing, July 23,
  2009</comments><doi>10.1109/TSP.2010.2046079</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To achieve the available performance gains in half-duplex wireless relay
networks, several cooperative schemes have been earlier proposed using either
distributed space-time coding or distributed beamforming for the transmitter
without and with channel state information (CSI), respectively. However, these
schemes typically have rather high implementation and/or decoding complexities,
especially when the number of relays is high. In this paper, we propose a
simple low-rate feedback-based approach to achieve maximum diversity with a low
decoding and implementation complexity. To further improve the performance of
the proposed scheme, the knowledge of the second-order channel statistics is
exploited to design long-term power loading through maximizing the receiver
signal-to-noise ratio (SNR) with appropriate constraints. This maximization
problem is approximated by a convex feasibility problem whose solution is shown
to be close to the optimal one in terms of the error probability. Subsequently,
to provide robustness against feedback errors and further decrease the feedback
rate, an extended version of the distributed Alamouti code is proposed. It is
also shown that our scheme can be generalized to the differential transmission
case, where it can be applied to wireless relay networks with no CSI available
at the receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1409</identifier>
 <datestamp>2009-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1409</id><created>2009-04-07</created><updated>2009-07-09</updated><authors><author><keyname>Shirani-Mehr</keyname><forenames>Hooman</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>MIMO Downlink Scheduling with Non-Perfect Channel State Knowledge</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Downlink scheduling schemes are well-known and widely investigated under the
assumption that the channel state is perfectly known to the scheduler. In the
multiuser MIMO (broadcast) case, downlink scheduling in the presence of
non-perfect channel state information (CSI) is only scantly treated. In this
paper we provide a general framework that addresses the problem systematically.
Also, we illuminate the key role played by the channel state prediction error:
our scheme treats in a fundamentally different way users with small channel
prediction error (&quot;predictable&quot; users) and users with large channel prediction
error (&quot;non-predictable&quot; users), and can be interpreted as a near-optimal
opportunistic time-sharing strategy between MIMO downlink beamforming to
predictable users and space-time coding to nonpredictable users. Our results,
based on a realistic MIMO channel model used in 3GPP standardization, show that
the proposed algorithms can significantly outperform a conventional
&quot;mismatched&quot; scheduling scheme that treats the available CSI as if it was
perfect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1435</identifier>
 <datestamp>2009-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1435</id><created>2009-04-08</created><authors><author><keyname>Kintali</keyname><forenames>Shiva</forenames></author><author><keyname>Poplawski</keyname><forenames>Laura J.</forenames></author><author><keyname>Rajaraman</keyname><forenames>Rajmohan</forenames></author><author><keyname>Sundaram</keyname><forenames>Ravi</forenames></author><author><keyname>Teng</keyname><forenames>Shang-Hua</forenames></author></authors><title>Reducibility Among Fractional Stability Problems</title><categories>cs.CC cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we resolve the computational complexity of a number of
outstanding open problems with practical applications. Here is the list of
problems we show to be PPAD-complete, along with the domains of practical
significance: Fractional Stable Paths Problem (FSPP) [21] - Internet routing;
Core of Balanced Games [41] - Economics and Game theory; Scarf's Lemma [41] -
Combinatorics; Hypergraph Matching [1]- Social Choice and Preference Systems;
Fractional Bounded Budget Connection Games (FBBC) [30] - Social networks; and
Strong Fractional Kernel [2]- Graph Theory. In fact, we show that no fully
polynomial-time approximation schemes exist (unless PPAD is in FP).
  This paper is entirely a series of reductions that build in nontrivial ways
on the framework established in previous work. In the course of deriving these
reductions, we created two new concepts - preference games and personalized
equilibria. The entire set of new reductions can be presented as a lattice with
the above problems sandwiched between preference games (at the &quot;easy&quot; end) and
personalized equilibria (at the &quot;hard&quot; end). Our completeness results extend to
natural approximate versions of most of these problems. On a technical note, we
wish to highlight our novel &quot;continuous-to-discrete&quot; reduction from exact
personalized equilibria to approximate personalized equilibria using a linear
program augmented with an exponential number of &quot;min&quot; constraints of a specific
form. In addition to enhancing our repertoire of PPAD-complete problems, we
expect the concepts and techniques in this paper to find future use in
algorithmic game theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1439</identifier>
 <datestamp>2010-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1439</id><created>2009-04-08</created><authors><author><keyname>Chen</keyname><forenames>Chaomei</forenames><affiliation>Drexel University</affiliation><affiliation>Dalian University of Technology</affiliation></author><author><keyname>Chen</keyname><forenames>Yue</forenames><affiliation>Dalian University of Technology</affiliation></author><author><keyname>Horowitz</keyname><forenames>Mark</forenames><affiliation>Drexel University</affiliation></author><author><keyname>Hou</keyname><forenames>Haiyan</forenames><affiliation>Dalian University of Technology</affiliation></author><author><keyname>Liu</keyname><forenames>Zeyuan</forenames><affiliation>Dalian University of Technology</affiliation></author><author><keyname>Pellegrino</keyname><forenames>Don</forenames><affiliation>Drexel University</affiliation></author></authors><title>Towards an explanatory and computational theory of scientific discovery</title><categories>cs.GL cs.CY</categories><comments>32 pages, 6 figures. Journal of Informetirics, 2009, volume 3 (in
  press)</comments><journal-ref>Journal of Informetirics, 3(2009), 191-209</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an explanatory and computational theory of transformative
discoveries in science. The theory is derived from a recurring theme found in a
diverse range of scientific change, scientific discovery, and knowledge
diffusion theories in philosophy of science, sociology of science, social
network analysis, and information science. The theory extends the concept of
structural holes from social networks to a broader range of associative
networks found in science studies, especially including networks that reflect
underlying intellectual structures such as co-citation networks and
collaboration networks. The central premise is that connecting otherwise
disparate patches of knowledge is a valuable mechanism of creative thinking in
general and transformative scientific discovery in particular.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1444</identifier>
 <datestamp>2010-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1444</id><created>2009-04-08</created><authors><author><keyname>Ganti</keyname><forenames>Radha Krishna</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Spatial and Temporal Correlation of the Interference in ALOHA Ad Hoc
  Networks</title><categories>cs.IT cs.NI math.IT math.PR</categories><doi>10.1109/LCOMM.2009.090837</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference is a main limiting factor of the performance of a wireless ad
hoc network. The temporal and the spatial correlation of the interference makes
the outages correlated temporally (important for retransmissions) and spatially
correlated (important for routing). In this letter we quantify the temporal and
spatial correlation of the interference in a wireless ad hoc network whose
nodes are distributed as a Poisson point process on the plane when ALOHA is
used as the multiple-access scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1446</identifier>
 <datestamp>2009-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1446</id><created>2009-04-08</created><authors><author><keyname>Yu</keyname><forenames>Yaming</forenames></author><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author></authors><title>Concavity of entropy under thinning</title><categories>cs.IT math.IT</categories><comments>To be presented at ISIT09</comments><journal-ref>IEEE International Symposium on Information Theory, June 28
  2009-July 3, 2009, pp. 144 -- 148</journal-ref><doi>10.1109/ISIT.2009.5205880</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building on the recent work of Johnson (2007) and Yu (2008), we prove that
entropy is a concave function with respect to the thinning operation T_a. That
is, if X and Y are independent random variables on Z_+ with ultra-log-concave
probability mass functions, then H(T_a X+T_{1-a} Y)&gt;= a H(X)+(1-a)H(Y), 0 &lt;= a
&lt;= 1, where H denotes the discrete entropy. This is a discrete analogue of the
inequality (h denotes the differential entropy) h(sqrt(a) X + sqrt{1-a} Y)&gt;= a
h(X)+(1-a) h(Y), 0 &lt;= a &lt;= 1, which holds for continuous X and Y with finite
variances and is equivalent to Shannon's entropy power inequality. As a
consequence we establish a special case of a conjecture of Shepp and Olkin
(1981).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1488</identifier>
 <datestamp>2009-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1488</id><created>2009-04-09</created><authors><author><keyname>Ranzato</keyname><forenames>Francesco</forenames></author><author><keyname>Tapparo</keyname><forenames>Francesco</forenames></author></authors><title>Computing Stuttering Simulations</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stuttering bisimulation is a well-known behavioral equivalence that preserves
CTL-X, namely CTL without the next-time operator X. Correspondingly, the
stuttering simulation preorder induces a coarser behavioral equivalence that
preserves the existential fragment ECTL-{X,G}, namely ECTL without the
next-time X and globally G operators. While stuttering bisimulation equivalence
can be computed by the well-known Groote and Vaandrager's [1990] algorithm, to
the best of our knowledge, no algorithm for computing the stuttering simulation
preorder and equivalence is available. This paper presents such an algorithm
for finite state systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1529</identifier>
 <datestamp>2009-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1529</id><created>2009-04-09</created><authors><author><keyname>Santocanale</keyname><forenames>Luigi</forenames><affiliation>LIF</affiliation></author><author><keyname>Cockett</keyname><forenames>Robin</forenames></author></authors><title>On the word problem for SP-categories, and the properties of two-way
  communication</title><categories>cs.LO math.CT math.LO</categories><proxy>ccsd hal-00374654</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The word problem for categories with free products and coproducts (sums),
SP-categories, is directly related to the problem of determining the
equivalence of certain processes. Indeed, the maps in these categories may be
directly interpreted as processes which communicate by two-way channels. The
maps of an SP-category may also be viewed as a proof theory for a simple logic
with a game theoretic intepretation. The cut-elimination procedure for this
logic determines equality only up to certain permuting conversions. As the
equality classes under these permuting conversions are finite, it is easy to
see that equality between cut-free terms (even in the presence of the additive
units) is decidable. Unfortunately, this does not yield a tractable decision
algorithm as these equivalence classes can contain exponentially many terms.
However, the rather special properties of these free categories -- and, thus,
of two-way communication -- allow one to devise a tractable algorithm for
equality. We show that, restricted to cut-free terms s,t : X --&gt; A, the
decision procedure runs in time polynomial on |X||A|, the product of the sizes
of the domain and codomain type.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1534</identifier>
 <datestamp>2014-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1534</id><created>2009-04-09</created><authors><author><keyname>Zhang</keyname><forenames>Jianfeng</forenames><affiliation>INRIA Rocquencourt, CEREMADE</affiliation></author><author><keyname>Chavent</keyname><forenames>Guy</forenames><affiliation>INRIA Rocquencourt, CEREMADE</affiliation></author><author><keyname>Jaffr&#xe9;</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Estimating nonlinearities in twophase flow in porous media</title><categories>cs.NA math.AP physics.class-ph</categories><proxy>ccsd inria-00374754</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to analyze numerically inverse problems several techniques based on
linear and nonlinear stability analysis are presented. These techniques are
illustrated on the problem of estimating mobilities and capillary pressure in
one-dimensional two-phase displacements in porous media that are performed in
laboratories. This is an example of the problem of estimating nonlinear
coefficients in a system of nonlinear partial differential equations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1538</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1538</id><created>2009-04-09</created><updated>2012-04-03</updated><authors><author><keyname>Floor</keyname><forenames>Paal Anders</forenames></author><author><keyname>Ramstad</keyname><forenames>Tor A.</forenames></author></authors><title>Shannon-Kotel'nikov Mappings for Analog Point-to-Point Communications</title><categories>cs.IT math.IT</categories><comments>11 page revision submitted to IEEE transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper an approach to joint source-channel coding (JSCC), named
Shannon-Kotel'nikov mappings (S-K mappings), is presented. S-K mappings are
(piecewise) continuous, direct source-to-channel mappings operating directly on
amplitude continuous, discrete time signals. These mappings include several
existing JSCC schemes. There exist many interesting approaches to analog and
semi-analog JSCC in the literature that provide both excellent performance as
well as robustness to variations in noise level. However, no common theory
describing their behavior on a general basis exists at the moment.
  The objective of this paper is to introduce a general theoretical framework
for analysis of analog (and semi-analog) mappings. This framework will enable
calculation of distortion when applying such schemes on point-to-point links,
reveal more about their fundamental nature, and provide conditions indicating
how such mappings should be constructed in order to perform well at low and
arbitrary complexity and delay. Since this problem is very difficult we are not
attempting to provide a complete theory at this stage, but rather establish a
starting point from which future research can be developed. The paper considers
memoryless sources with an arbitrary continuous unimodal density function and
memoryless Gaussian channels. Most results are valid for good channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1579</identifier>
 <datestamp>2009-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1579</id><created>2009-04-09</created><authors><author><keyname>Zhdanov</keyname><forenames>Fedor</forenames></author><author><keyname>Vovk</keyname><forenames>Vladimir</forenames></author><author><keyname>Burford</keyname><forenames>Brian</forenames></author><author><keyname>Devetyarov</keyname><forenames>Dmitry</forenames></author><author><keyname>Nouretdinov</keyname><forenames>Ilia</forenames></author><author><keyname>Gammerman</keyname><forenames>Alex</forenames></author></authors><title>Online prediction of ovarian cancer</title><categories>cs.AI cs.LG</categories><comments>11 pages, 4 figures, uses llncs.cls</comments><acm-class>I.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we apply computer learning methods to diagnosing ovarian cancer
using the level of the standard biomarker CA125 in conjunction with information
provided by mass-spectrometry. We are working with a new data set collected
over a period of 7 years. Using the level of CA125 and mass-spectrometry peaks,
our algorithm gives probability predictions for the disease. To estimate
classification accuracy we convert probability predictions into strict
predictions. Our algorithm makes fewer errors than almost any linear
combination of the CA125 level and one peak's intensity (taken on the log
scale). To check the power of our algorithm we use it to test the hypothesis
that CA125 and the peaks do not contain useful information for the prediction
of the disease at a particular time before the diagnosis. Our algorithm
produces $p$-values that are better than those produced by the algorithm that
has been previously applied to this data set. Our conclusion is that the
proposed algorithm is more reliable for prediction on new data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1613</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1613</id><created>2009-04-09</created><authors><author><keyname>Myronenko</keyname><forenames>Andriy</forenames></author><author><keyname>Song</keyname><forenames>Xubo</forenames></author></authors><title>On the closed-form solution of the rotation matrix arising in computer
  vision problems</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show the closed-form solution to the maximization of trace(A'R), where A
is given and R is unknown rotation matrix. This problem occurs in many computer
vision tasks involving optimal rotation matrix estimation. The solution has
been continuously reinvented in different fields as part of specific problems.
We summarize the historical evolution of the problem and present the general
proof of the solution. We contribute to the proof by considering the degenerate
cases of A and discuss the uniqueness of R.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1616</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1616</id><created>2009-04-09</created><authors><author><keyname>Meza</keyname><forenames>Juan</forenames></author><author><keyname>Campbell</keyname><forenames>Scott</forenames></author><author><keyname>Bailey</keyname><forenames>David</forenames></author></authors><title>Mathematical and Statistical Opportunities in Cyber Security</title><categories>cs.CR</categories><report-no>LBNL-1667E</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The role of mathematics in a complex system such as the Internet has yet to
be deeply explored. In this paper, we summarize some of the important and
pressing problems in cyber security from the viewpoint of open science
environments. We start by posing the question &quot;What fundamental problems exist
within cyber security research that can be helped by advanced mathematics and
statistics?&quot; Our first and most important assumption is that access to
real-world data is necessary to understand large and complex systems like the
Internet. Our second assumption is that many proposed cyber security solutions
could critically damage both the openness and the productivity of scientific
research. After examining a range of cyber security problems, we come to the
conclusion that the field of cyber security poses a rich set of new and
exciting research opportunities for the mathematical and statistical sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1629</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1629</id><created>2009-04-09</created><authors><author><keyname>Yamazaki</keyname><forenames>Yoichi</forenames></author><author><keyname>Dong</keyname><forenames>Fangyan</forenames></author><author><keyname>Masuda</keyname><forenames>Yuta</forenames></author><author><keyname>Uehara</keyname><forenames>Yukiko</forenames></author><author><keyname>Kormushev</keyname><forenames>Petar</forenames></author><author><keyname>Vu</keyname><forenames>Hai An</forenames></author><author><keyname>Le</keyname><forenames>Phuc Quang</forenames></author><author><keyname>Hirota</keyname><forenames>Kaoru</forenames></author></authors><title>Fuzzy inference based mentality estimation for eye robot agent</title><categories>cs.RO cs.AI cs.HC</categories><comments>2 pages, in Japanese</comments><journal-ref>Proceedings of 23rd Fuzzy System Symposium (FSS 2007), pp.
  387-388, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Household robots need to communicate with human beings in a friendly fashion.
To achieve better understanding of displayed information, an importance and a
certainty of the information should be communicated together with the main
information. The proposed intent expression system aims to convey this
additional information using an eye robot. The eye motions are represented as
states in a pleasure-arousal space model. Change of the model state is
calculated by fuzzy inference according to the importance and certainty of the
displayed information. This change influences the arousal-sleep coordinate in
the space which corresponds to activeness in communication. The eye robot
provides a basic interface for the mascot robot system which is an easy to
understand information terminal for home environments in a humatronics society.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1630</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1630</id><created>2009-04-09</created><updated>2011-07-20</updated><authors><author><keyname>Sterling</keyname><forenames>Aaron</forenames></author></authors><title>Self-Assembly of a Statistically Self-Similar Fractal</title><categories>cs.CC cs.DS cs.OH</categories><comments>I am withdrawing all work I would like to polish before resubmitting,
  including this paper. Several typos fixed</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We demonstrate existence of a tile assembly system that self-assembles the
statistically self-similar Sierpinski Triangle in the Winfree-Rothemund Tile
Assembly Model. This appears to be the first paper that considers self-assembly
of a random fractal, instead of a deterministic fractal or a finite, bounded
shape. Our technical contributions include a way to remember, and use,
unboundedly-long prefixes of an infinite coding sequence at each stage of
fractal construction; a tile assembly mechanism for nested recursion; and a
definition of &quot;almost-everywhere local determinism,&quot; to describe a tileset
whose assembly is locally determined, conditional upon a zeta-dimension zero
set of (infinitely many) &quot;input&quot; tiles. This last is similar to the definition
of randomized computation for Turing machines, in which an algorithm is
deterministic relative to an oracle sequence of coin flips that provides advice
but does not itself compute. Keywords: tile self-assembly, statistically
self-similar Sierpinski Triangle.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1631</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1631</id><created>2009-04-09</created><authors><author><keyname>Yamazaki</keyname><forenames>Yoichi</forenames></author><author><keyname>Dong</keyname><forenames>Fangyan</forenames></author><author><keyname>Masuda</keyname><forenames>Yuta</forenames></author><author><keyname>Uehara</keyname><forenames>Yukiko</forenames></author><author><keyname>Kormushev</keyname><forenames>Petar</forenames></author><author><keyname>Vu</keyname><forenames>Hai An</forenames></author><author><keyname>Le</keyname><forenames>Phuc Quang</forenames></author><author><keyname>Hirota</keyname><forenames>Kaoru</forenames></author></authors><title>Intent expression using eye robot for mascot robot system</title><categories>cs.RO cs.AI cs.HC</categories><comments>5 pages</comments><journal-ref>8th International Symposium on Advanced Intelligent Systems
  (ISIS2007), pp. 576-580, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An intent expression system using eye robots is proposed for a mascot robot
system from a viewpoint of humatronics. The eye robot aims at providing a basic
interface method for an information terminal robot system. To achieve better
understanding of the displayed information, the importance and the degree of
certainty of the information should be communicated along with the main
content. The proposed intent expression system aims at conveying this
additional information using the eye robot system. Eye motions are represented
as the states in a pleasure-arousal space model. Changes in the model state are
calculated by fuzzy inference according to the importance and degree of
certainty of the displayed information. These changes influence the
arousal-sleep coordinates in the space that corresponds to levels of liveliness
during communication. The eye robot provides a basic interface for the mascot
robot system that is easy to be understood as an information terminal for home
environments in a humatronics society.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1645</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1645</id><created>2009-04-10</created><updated>2009-04-15</updated><authors><author><keyname>Chauve</keyname><forenames>Cedric</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Ouangraoua</keyname><forenames>A&#xef;da</forenames><affiliation>LaBRI</affiliation></author></authors><title>A 3-approximation algorithm for computing a parsimonious first
  speciation in the gene duplication model</title><categories>cs.DM cs.DS q-bio.QM</categories><proxy>ccsd hal-00374851</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following problem: from a given set of gene families trees on
a set of genomes, find a first speciation, that splits these genomes into two
subsets, that minimizes the number of gene duplications that happened before
this speciation. We call this problem the Minimum Duplication Bipartition
Problem. Using a generalization of the Minimum Edge-Cut Problem, known as
Submodular Function Minimization, we propose a polynomial time and space
3-approximation algorithm for the Minimum Duplication Bipartition Problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1672</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1672</id><created>2009-04-10</created><authors><author><keyname>Vennekens</keyname><forenames>Joost</forenames></author><author><keyname>Denecker</keyname><forenames>Marc</forenames></author><author><keyname>Bruynooghe</keyname><forenames>Maurice</forenames></author></authors><title>CP-logic: A Language of Causal Probabilistic Events and Its Relation to
  Logic Programming</title><categories>cs.AI cs.LO</categories><comments>To be published in Theory and Practice of Logic Programming (TPLP)</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This papers develops a logical language for representing probabilistic causal
laws. Our interest in such a language is twofold. First, it can be motivated as
a fundamental study of the representation of causal knowledge. Causality has an
inherent dynamic aspect, which has been studied at the semantical level by
Shafer in his framework of probability trees. In such a dynamic context, where
the evolution of a domain over time is considered, the idea of a causal law as
something which guides this evolution is quite natural. In our formalization, a
set of probabilistic causal laws can be used to represent a class of
probability trees in a concise, flexible and modular way. In this way, our work
extends Shafer's by offering a convenient logical representation for his
semantical objects.
  Second, this language also has relevance for the area of probabilistic logic
programming. In particular, we prove that the formal semantics of a theory in
our language can be equivalently defined as a probability distribution over the
well-founded models of certain logic programs, rendering it formally quite
similar to existing languages such as ICL or PRISM. Because we can motivate and
explain our language in a completely self-contained way as a representation of
probabilistic causal laws, this provides a new way of explaining the intuitions
behind such probabilistic logic programs: we can say precisely which knowledge
such a program expresses, in terms that are equally understandable by a
non-logician. Moreover, we also obtain an additional piece of knowledge
representation methodology for probabilistic logic programs, by showing how
they can express probabilistic causal laws.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1692</identifier>
 <datestamp>2010-02-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1692</id><created>2009-04-10</created><updated>2010-02-22</updated><authors><author><keyname>Goldenberg</keyname><forenames>Idan</forenames></author><author><keyname>Burshtein</keyname><forenames>David</forenames></author></authors><title>Error Bounds for Repeat-Accumulate Codes Decoded via Linear Programming</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine regular and irregular repeat-accumulate (RA) codes with repetition
degrees which are all even. For these codes and with a particular choice of an
interleaver, we give an upper bound on the decoding error probability of a
linear-programming based decoder which is an inverse polynomial in the block
length. Our bound is valid for any memoryless, binary-input, output-symmetric
(MBIOS) channel. This result generalizes the bound derived by Feldman et al.,
which was for regular RA(2) codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1696</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1696</id><created>2009-04-10</created><authors><author><keyname>Belkhir</keyname><forenames>Walid</forenames></author></authors><title>Undirected Graphs of Entanglement 3</title><categories>cs.GT cs.DM</categories><comments>33 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entanglement is a complexity measure of digraphs that origins in fixed-point
logics. Its combinatorial purpose is to measure the nested depth of cycles in
digraphs. We address the problem of characterizing the structure of graphs of
entanglement at most $k$. Only partial results are known so far: digraphs for
$k=1$, and undirected graphs for $k=2$. In this paper we investigate the
structure of undirected graphs for $k=3$. Our main tool is the so-called
\emph{Tutte's decomposition} of 2-connected graphs into cycles and 3-connected
components into a tree-like fashion. We shall give necessary conditions on
Tutte's tree to be a tree decomposition of a 2-connected graph of entanglement
3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1700</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1700</id><created>2009-04-10</created><updated>2009-06-09</updated><authors><author><keyname>Sinton</keyname><forenames>Antoine</forenames></author></authors><title>Recovering the state sequence of hidden Markov models using mean-field
  approximations</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.LG</categories><comments>43 pages, 41 figures</comments><doi>10.1088/1742-5468/2009/07/P07026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inferring the sequence of states from observations is one of the most
fundamental problems in Hidden Markov Models. In statistical physics language,
this problem is equivalent to computing the marginals of a one-dimensional
model with a random external field. While this task can be accomplished through
transfer matrix methods, it becomes quickly intractable when the underlying
state space is large.
  This paper develops several low-complexity approximate algorithms to address
this inference problem when the state space becomes large. The new algorithms
are based on various mean-field approximations of the transfer matrix. Their
performances are studied in detail on a simple realistic model for DNA
pyrosequencing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1701</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1701</id><created>2009-04-10</created><authors><author><keyname>Belkhir</keyname><forenames>Walid</forenames></author></authors><title>The Star Height Hierarchy Vs. The Variable Hierarchy</title><categories>cs.LO cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The star height hierarchy (resp. the variable hierarchy) results in
classifying $\mu$-terms into classes according to the nested depth of fixed
point operators (resp. to the number of bound variables). We prove, under some
assumptions, that the variable hierarchy is a proper refinement of the star
height hierarchy. We mean that the non collapse of the variable hierarchy
implies the non collapse of the star height hierarchy. The proof relies on the
combinatorial characterization of the two hierarchies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1703</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1703</id><created>2009-04-10</created><authors><author><keyname>Belkhir</keyname><forenames>Walid</forenames></author></authors><title>Closure Under Minors of Undirected Entanglement</title><categories>cs.DM cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Entanglement is a digraph complexity measure that origins in fixed-point
theory. Its purpose is to count the nested depth of cycles in digraphs.
  In this paper we prove that the class of undirected graphs of entanglement at
most $k$, for arbitrary fixed $k \in \mathbb{N}$, is closed under taking
minors. Our proof relies on the game theoretic characterization of entanglement
in terms of Robber and Cops games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1705</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1705</id><created>2009-04-10</created><authors><author><keyname>Bampis</keyname><forenames>Evripidis</forenames></author><author><keyname>Kononov</keyname><forenames>Alexander</forenames></author><author><keyname>Lucarelli</keyname><forenames>Giorgio</forenames></author><author><keyname>Milis</keyname><forenames>Ioannis</forenames></author></authors><title>Bounded Max-Colorings of Graphs</title><categories>cs.DS</categories><comments>13 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a bounded max-coloring of a vertex/edge weighted graph, each color class
is of cardinality at most $b$ and of weight equal to the weight of the heaviest
vertex/edge in this class. The bounded max-vertex/edge-coloring problems ask
for such a coloring minimizing the sum of all color classes' weights.
  In this paper we present complexity results and approximation algorithms for
those problems on general graphs, bipartite graphs and trees. We first show
that both problems are polynomial for trees, when the number of colors is
fixed, and $H_b$ approximable for general graphs, when the bound $b$ is fixed.
For the bounded max-vertex-coloring problem, we show a 17/11-approximation
algorithm for bipartite graphs, a PTAS for trees as well as for bipartite
graphs when $b$ is fixed. For unit weights, we show that the known 4/3 lower
bound for bipartite graphs is tight by providing a simple 4/3 approximation
algorithm. For the bounded max-edge-coloring problem, we prove approximation
factors of $3-2/\sqrt{2b}$, for general graphs, $\min\{e, 3-2/\sqrt{b}\}$, for
bipartite graphs, and 2, for trees. Furthermore, we show that this problem is
NP-complete even for trees. This is the first complexity result for
max-coloring problems on trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1712</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1712</id><created>2009-04-10</created><updated>2010-08-04</updated><authors><author><keyname>Ait-Idir</keyname><forenames>Tarik</forenames></author><author><keyname>Chafnaji</keyname><forenames>Houda</forenames></author><author><keyname>Saoudi</keyname><forenames>Samir</forenames></author></authors><title>Turbo Packet Combining for Broadband Space-Time BICM Hybrid-ARQ Systems
  with Co-Channel Interference</title><categories>cs.IT math.IT</categories><comments>12 pages, 7 figures, and 2 tables</comments><journal-ref>IEEE Transactions on Wireless Communications, vol. 9, no. 5, pp.
  1686-1697, May 2010</journal-ref><doi>10.1109/TWC.2010.05.090441</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, efficient turbo packet combining for single carrier (SC)
broadband multiple-input--multiple-output (MIMO) hybrid--automatic repeat
request (ARQ) transmission with unknown co-channel interference (CCI) is
studied. We propose a new frequency domain soft minimum mean square error
(MMSE)-based signal level combining technique where received signals and
channel frequency responses (CFR)s corresponding to all retransmissions are
used to decode the data packet. We provide a recursive implementation algorithm
for the introduced scheme, and show that both its computational complexity and
memory requirements are quite insensitive to the ARQ delay, i.e., maximum
number of ARQ rounds. Furthermore, we analyze the asymptotic performance, and
show that under a sum-rank condition on the CCI MIMO ARQ channel, the proposed
packet combining scheme is not interference-limited. Simulation results are
provided to demonstrate the gains offered by the proposed technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1729</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1729</id><created>2009-04-10</created><authors><author><keyname>Murugesan</keyname><forenames>Sugumar</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>Joint Opportunistic Scheduling in Multi-Cellular Systems</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of multiuser scheduling with partial channel
information in a multi-cell environment. The scheduling problem is formulated
jointly with the ARQ based channel learning process and the intercell
interference mitigating cell breathing protocol. The optimal joint scheduling
policy under various system constraints is established. The general problem is
posed as a generalized Restless Multiarmed Bandit process and the notion of
indexability is studied. We conjecture, with numerical support, that the
multicell multiuser scheduling problem is indexable and obtain a partial
structure of the index policy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1730</identifier>
 <datestamp>2009-04-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1730</id><created>2009-04-10</created><authors><author><keyname>Sundararajan</keyname><forenames>Jay Kumar</forenames></author><author><keyname>Shah</keyname><forenames>Devavrat</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author></authors><title>Feedback-based online network coding</title><categories>cs.NI cs.IT math.IT</categories><comments>27 pages, 7 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current approaches to the practical implementation of network coding are
batch-based, and often do not use feedback, except possibly to signal
completion of a file download. In this paper, the various benefits of using
feedback in a network coded system are studied. It is shown that network coding
can be performed in a completely online manner, without the need for batches or
generations, and that such online operation does not affect the throughput.
Although these ideas are presented in a single-hop packet erasure broadcast
setting, they naturally extend to more general lossy networks which employ
network coding in the presence of feedback. The impact of feedback on queue
size at the sender and decoding delay at the receivers is studied. Strategies
for adaptive coding based on feedback are presented, with the goal of
minimizing the queue size and delay. The asymptotic behavior of these metrics
is characterized, in the limit of the traffic load approaching capacity.
Different notions of decoding delay are considered, including an
order-sensitive notion which assumes that packets are useful only when
delivered in order. Our work may be viewed as a natural extension of Automatic
Repeat reQuest (ARQ) schemes to coded networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1752</identifier>
 <datestamp>2012-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1752</id><created>2009-04-11</created><updated>2012-01-03</updated><authors><author><keyname>Cassaigne</keyname><forenames>Julien</forenames></author><author><keyname>Nicolas</keyname><forenames>Francois</forenames></author></authors><title>On polynomial growth functions of D0L-systems</title><categories>cs.DM cs.FL</categories><comments>Not intended to be published</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to prove that every polynomial function that maps
the natural integers to the positive integers is the growth function of some
D0L-system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1754</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1754</id><created>2009-04-10</created><authors><author><keyname>Murugesan</keyname><forenames>Sugumar</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>Opportunistic Multiuser Scheduling in a Three State Markov-modeled
  Downlink</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the downlink of a cellular system and address the problem of
multiuser scheduling with partial channel information. In our setting, the
channel of each user is modeled by a three-state Markov chain. The scheduler
indirectly estimates the channel via accumulated Automatic Repeat Request (ARQ)
feedback from the scheduled users and uses this information in future
scheduling decisions. Using a Partially Observable Markov Decision Process
(POMDP), we formulate a throughput maximization problem that is an extension of
our previous work where the channels were modeled using two states. We recall
the greedy policy that was shown to be optimal and easy to implement in the two
state case and study the implementation structure of the greedy policy in the
considered downlink. We classify the system into two types based on the channel
statistics and obtain round robin structures for the greedy policy for each
system type. We obtain performance bounds for the downlink system using these
structures and study the conditions under which the greedy policy is optimal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1783</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1783</id><created>2009-04-11</created><updated>2009-08-10</updated><authors><author><keyname>Bagnara</keyname><forenames>Roberto</forenames></author><author><keyname>Hill</keyname><forenames>Patricia M.</forenames></author><author><keyname>Zaffanella</keyname><forenames>Enea</forenames></author></authors><title>Exact Join Detection for Convex Polyhedra and Other Numerical
  Abstractions</title><categories>cs.CG</categories><comments>36 pages, 4 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Deciding whether the union of two convex polyhedra is itself a convex
polyhedron is a basic problem in polyhedral computations; having important
applications in the field of constrained control and in the synthesis,
analysis, verification and optimization of hardware and software systems. In
such application fields though, general convex polyhedra are just one among
many, so-called, numerical abstractions, which range from restricted families
of (not necessarily closed) convex polyhedra to non-convex geometrical objects.
We thus tackle the problem from an abstract point of view: for a wide range of
numerical abstractions that can be modeled as bounded join-semilattices --that
is, partial orders where any finite set of elements has a least upper bound--,
we show necessary and sufficient conditions for the equivalence between the
lattice-theoretic join and the set-theoretic union. For the case of closed
convex polyhedra --which, as far as we know, is the only one already studied in
the literature-- we improve upon the state-of-the-art by providing a new
algorithm with a better worst-case complexity. The results and algorithms
presented for the other numerical abstractions are new to this paper. All the
algorithms have been implemented, experimentally validated, and made available
in the Parma Polyhedra Library.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1812</identifier>
 <datestamp>2010-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1812</id><created>2009-04-11</created><updated>2010-01-04</updated><authors><author><keyname>Zhang</keyname><forenames>Wei</forenames></author><author><keyname>Xu</keyname><forenames>Tianyi</forenames></author><author><keyname>Xia</keyname><forenames>Xiang-Gen</forenames></author></authors><title>Two Designs of Space-Time Block Codes Achieving Full Diversity with
  Partial Interference Cancellation Group Decoding</title><categories>cs.IT math.IT</categories><comments>41 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A partial interference cancellation (PIC) group decoding based space-time
block code (STBC) design criterion was recently proposed by Guo and Xia, where
the decoding complexity and the code rate trade-off is dealt when the full
diversity is achieved. In this paper, two designs of STBC are proposed for any
number of transmit antennas that can obtain full diversity when a PIC group
decoding (with a particular grouping scheme) is applied at receiver. With the
PIC group decoding and an appropriate grouping scheme for the decoding, the
proposed STBC are shown to obtain the same diversity gain as the ML decoding,
but have a low decoding complexity. The first proposed STBC is designed with
multiple diagonal layers and it can obtain the full diversity for two-layer
design with the PIC group decoding and the rate is up to 2 symbols per channel
use. But with PIC-SIC group decoding, the first proposed STBC can obtain full
diversity for any number of layers and the rate can be full. The second
proposed STBC can obtain full diversity and a rate up to 9/4 with the PIC group
decoding. Some code design examples are given and simulation results show that
the newly proposed STBC can well address the rate-performance-complexity
tradeoff of the MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1840</identifier>
 <datestamp>2013-12-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1840</id><created>2009-04-12</created><authors><author><keyname>Khan</keyname><forenames>Usman A.</forenames></author><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Higher Dimensional Consensus: Learning in Large-Scale Networks</title><categories>cs.IT cs.DC math.IT math.OC</categories><comments>30 pages, 4 figures Submitted for journal publication</comments><journal-ref>U. A. Khan, S. Kar, and J. M. F. Moura, &quot;Higher dimensional
  consensus: Learning in large-scale networks,&quot; IEEE Transactions on Signal
  Processing, vol. 58, no. 5, pp. 2836-2849, May 2010</journal-ref><doi>10.1109/TSP.2010.2042482</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents higher dimension consensus (HDC) for large-scale networks.
HDC generalizes the well-known average-consensus algorithm. It divides the
nodes of the large-scale network into anchors and sensors. Anchors are nodes
whose states are fixed over the HDC iterations, whereas sensors are nodes that
update their states as a linear combination of the neighboring states. Under
appropriate conditions, we show that the sensor states converge to a linear
combination of the anchor states. Through the concept of anchors, HDC captures
in a unified framework several interesting network tasks, including distributed
sensor localization, leader-follower, distributed Jacobi to solve linear
systems of algebraic equations, and, of course, average-consensus. In many
network applications, it is of interest to learn the weights of the distributed
linear algorithm so that the sensors converge to a desired state. We term this
inverse problem the HDC learning problem. We pose learning in HDC as a
constrained non-convex optimization problem, which we cast in the framework of
multi-objective optimization (MOP) and to which we apply Pareto optimality. We
prove analytically relevant properties of the MOP solutions and of the Pareto
front from which we derive the solution to learning in HDC. Finally, the paper
shows how the MOP approach resolves interesting tradeoffs (speed of convergence
versus quality of the final state) arising in learning in HDC in resource
constrained networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1888</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1888</id><created>2009-04-12</created><authors><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>On Fodor on Darwin on Evolution</title><categories>cs.NE cs.LG</categories><comments>21</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Jerry Fodor argues that Darwin was wrong about &quot;natural selection&quot; because
(1) it is only a tautology rather than a scientific law that can support
counterfactuals (&quot;If X had happened, Y would have happened&quot;) and because (2)
only minds can select. Hence Darwin's analogy with &quot;artificial selection&quot; by
animal breeders was misleading and evolutionary explanation is nothing but
post-hoc historical narrative. I argue that Darwin was right on all counts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1889</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1889</id><created>2009-04-12</created><authors><author><keyname>Harnad</keyname><forenames>Stevan</forenames></author></authors><title>First Person Singular</title><categories>cs.OH</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brian Rotman argues that (one) &quot;mind&quot; and (one) &quot;god&quot; are only conceivable,
literally, because of (alphabetic) literacy, which allowed us to designate each
of these ghosts as an incorporeal, speaker-independent &quot;I&quot; (or, in the case of
infinity, a notional agent that goes on counting forever). I argue that to have
a mind is to have the capacity to feel. No one can be sure which organisms
feel, hence have minds, but it seems likely that one-celled organisms and
plants do not, whereas animals do. So minds originated before humans and before
language --hence, a fortiori, before writing, whether alphabetic or
ideographic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1892</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1892</id><created>2009-04-12</created><authors><author><keyname>Philosof</keyname><forenames>Tal</forenames></author><author><keyname>Zamir</keyname><forenames>Ram</forenames></author><author><keyname>Erez</keyname><forenames>Uri</forenames></author><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author></authors><title>Lattice Strategies for the Dirty Multiple Access Channel</title><categories>cs.IT math.IT</categories><comments>42 pages, 14 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generalization of the Gaussian dirty-paper problem to a multiple access
setup is considered. There are two additive interference signals, one known to
each transmitter but none to the receiver. The rates achievable using Costa's
strategies (i.e. by a random binning scheme induced by Costa's auxiliary random
variables) vanish in the limit when the interference signals are strong. In
contrast, it is shown that lattice strategies (&quot;lattice precoding&quot;) can achieve
positive rates independent of the interferences, and in fact in some cases -
which depend on the noise variance and power constraints - they are optimal. In
particular, lattice strategies are optimal in the limit of high SNR. It is also
shown that the gap between the achievable rate region and the capacity region
is at most 0.167 bit. Thus, the dirty MAC is another instance of a network
setup, like the Korner-Marton modulo-two sum problem, where linear coding is
potentially better than random binning. Lattice transmission schemes and
conditions for optimality for the asymmetric case, where there is only one
interference which is known to one of the users (who serves as a &quot;helper&quot; to
the other user), and for the &quot;common interference&quot; case are also derived. In
the former case the gap between the helper achievable rate and its capacity is
at most 0.085 bit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1897</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1897</id><created>2009-04-12</created><updated>2010-01-22</updated><authors><author><keyname>Yang</keyname><forenames>Shenghao</forenames></author><author><keyname>Yeung</keyname><forenames>Raymond W.</forenames></author><author><keyname>Ngai</keyname><forenames>Chi-Kin</forenames></author></authors><title>Refined Coding Bounds and Code Constructions for Coherent Network Error
  Correction</title><categories>cs.IT math.IT</categories><comments>32 pages</comments><journal-ref>IEEE-J-IT 57 (2011) 1409 - 1424</journal-ref><doi>10.1109/TIT.2011.2106930</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Coherent network error correction is the error-control problem in network
coding with the knowledge of the network codes at the source and sink nodes.
With respect to a given set of local encoding kernels defining a linear network
code, we obtain refined versions of the Hamming bound, the Singleton bound and
the Gilbert-Varshamov bound for coherent network error correction. Similar to
its classical counterpart, this refined Singleton bound is tight for linear
network codes. The tightness of this refined bound is shown by two construction
algorithms of linear network codes achieving this bound. These two algorithms
illustrate different design methods: one makes use of existing network coding
algorithms for error-free transmission and the other makes use of classical
error-correcting codes. The implication of the tightness of the refined
Singleton bound is that the sink nodes with higher maximum flow values can have
higher error correction capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1902</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1902</id><created>2009-04-13</created><authors><author><keyname>Grumbach</keyname><forenames>Stephane</forenames><affiliation>INRIA Liama</affiliation></author><author><keyname>Wu</keyname><forenames>Zhilin</forenames><affiliation>CASIA Liama</affiliation></author></authors><title>On Distributed Model Checking of MSO on Graphs</title><categories>cs.LO cs.DC</categories><comments>30 pages, 4 figures, llncs.cls,llncsdoc.sty</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider distributed model-checking of Monadic Second-Order logic (MSO) on
graphs which constitute the topology of communication networks. The graph is
thus both the structure being checked and the system on which the distributed
computation is performed. We prove that MSO can be distributively model-checked
with only a constant number of messages sent over each link for planar networks
with bounded diameter, as well as for networks with bounded degree and bounded
tree-length. The distributed algorithms rely on nontrivial transformations of
linear time sequential algorithms for tree decompositions of bounded tree-width
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1907</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1907</id><created>2009-04-13</created><authors><author><keyname>Chen</keyname><forenames>Qi</forenames></author><author><keyname>He</keyname><forenames>Chen</forenames></author><author><keyname>Jiang</keyname><forenames>Lingge</forenames></author><author><keyname>Wang</keyname><forenames>Qingchuan</forenames></author></authors><title>Average Entropy Functions</title><categories>cs.IT cs.RO math.IT</categories><comments>accepted by ISIT2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The closure of the set of entropy functions associated with n discrete
variables, Gammar*n, is a convex cone in (2n-1)- dimensional space, but its
full characterization remains an open problem. In this paper, we map Gammar*n
to an n-dimensional region Phi*n by averaging the joint entropies with the same
number of variables, and show that the simpler Phi*n can be characterized
solely by the Shannon-type information inequalities
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1910</identifier>
 <datestamp>2013-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1910</id><created>2009-04-13</created><updated>2013-11-03</updated><authors><author><keyname>Suksmono</keyname><forenames>Andriyan Bayu</forenames></author></authors><title>Compressive Sampling with Known Spectral Energy Density</title><categories>cs.IT cs.CE math.FA math.IT</categories><comments>Proc. of Int. Conf. on Rural ICT 2009</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  A method to improve l1 performance of the CS (Compressive Sampling) for
A-scan SFCW-GPR (Stepped Frequency Continuous Wave-Ground Penetrating Radar)
signals with known spectral energy density is proposed. Instead of random
sampling, the proposed method selects the location of samples to follow the
distribution of the spectral energy. Samples collected from three different
measurement methods; the uniform sampling, random sampling, and energy
equipartition sampling, are used to reconstruct a given monocycle signal whose
spectral energy density is known. Objective performance evaluation in term of
PSNR (Peak Signal to Noise Ratio) indicates empirically that the CS
reconstruction of random sampling outperform the uniform sampling, while the
energy equipartition sampling outperforms both of them. These results suggest
that similar performance improvement can be achieved for the compressive SFCW
(Stepped Frequency Continuous Wave) radar, allowing even higher acquisition
speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1915</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1915</id><created>2009-04-13</created><authors><author><keyname>Grumbach</keyname><forenames>Stephane</forenames><affiliation>INRIA Liama</affiliation></author><author><keyname>Wu</keyname><forenames>Zhilin</forenames><affiliation>CASIA Liama</affiliation></author></authors><title>Logical locality entails frugal distributed computation over graphs</title><categories>cs.LO cs.DC</categories><comments>31 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  First-order logic is known to have limited expressive power over finite
structures. It enjoys in particular the locality property, which states that
first-order formulae cannot have a global view of a structure. This limitation
ensures on their low sequential computational complexity. We show that the
locality impacts as well on their distributed computational complexity. We use
first-order formulae to describe the properties of finite connected graphs,
which are the topology of communication networks, on which the first-order
formulae are also evaluated. We show that over bounded degree networks and
planar networks, first-order properties can be frugally evaluated, that is,
with only a bounded number of messages, of size logarithmic in the number of
nodes, sent over each link. Moreover, we show that the result carries over for
the extension of first-order logic with unary counting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1920</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1920</id><created>2009-04-13</created><authors><author><keyname>Wu</keyname><forenames>Zhilin</forenames><affiliation>CASIA Liama</affiliation></author><author><keyname>Grumbach</keyname><forenames>Stephane</forenames><affiliation>INRIA Liama</affiliation></author></authors><title>Feasibility of Motion Planning on Acyclic and Strongly Connected
  Directed Graphs</title><categories>cs.DM cs.DS</categories><comments>19 pages, 9 figures, algorithm2e.sty</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motion planning is a fundamental problem of robotics with applications in
many areas of computer science and beyond. Its restriction to graphs has been
investigated in the literature for it allows to concentrate on the
combinatorial problem abstracting from geometric considerations. In this paper,
we consider motion planning over directed graphs, which are of interest for
asymmetric communication networks. Directed graphs generalize undirected
graphs, while introducing a new source of complexity to the motion planning
problem: moves are not reversible. We first consider the class of acyclic
directed graphs and show that the feasibility can be solved in time linear in
the product of the number of vertices and the number of arcs. We then turn to
strongly connected directed graphs. We first prove a structural theorem for
decomposing strongly connected directed graphs into strongly biconnected
components.Based on the structural decomposition, we give an algorithm for the
feasibility of motion planning on strongly connected directed graphs, and show
that it can also be decided in time linear in the product of the number of
vertices and the number of arcs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1923</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1923</id><created>2009-04-13</created><updated>2010-06-21</updated><authors><author><keyname>Limouzy</keyname><forenames>Vincent</forenames></author></authors><title>Seidel Minor, Permutation Graphs and Combinatorial Properties</title><categories>cs.DM</categories><comments>submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A permutation graph is an intersection graph of segments lying between two
parallel lines. A Seidel complementation of a finite graph at one of it vertex
$v$ consists to complement the edges between the neighborhood and the
non-neighborhood of $v$. Two graphs are Seidel complement equivalent if one can
be obtained from the other by a successive application of Seidel
complementation.
  In this paper we introduce the new concept of Seidel complementation and
Seidel minor, we then show that this operation preserves cographs and the
structure of modular decomposition. The main contribution of this paper is to
provide a new and succinct characterization of permutation graphs i.e. A graph
is a permutation graph \Iff it does not contain the following graphs: $C_5$,
$C_7$, $XF_{6}^{2}$, $XF_{5}^{2n+3}$, $C_{2n}, n\geqslant6$ and their
complement as Seidel minor. In addition we provide a $O(n+m)$-time algorithm to
output one of the forbidden Seidel minor if the graph is not a permutation
graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1931</identifier>
 <datestamp>2009-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1931</id><created>2009-04-13</created><authors><author><keyname>Griffith</keyname><forenames>Obi L.</forenames></author><author><keyname>Gao</keyname><forenames>Byron J.</forenames></author><author><keyname>Bilenky</keyname><forenames>Mikhail</forenames></author><author><keyname>Prichyna</keyname><forenames>Yuliya</forenames></author><author><keyname>Ester</keyname><forenames>Martin</forenames></author><author><keyname>Jones</keyname><forenames>Steven J. M.</forenames></author></authors><title>KiWi: A Scalable Subspace Clustering Algorithm for Gene Expression
  Analysis</title><categories>cs.DB cs.AI q-bio.GN</categories><comments>International Conference on Bioinformatics and Biomedical Engineering
  (iCBBE), 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Subspace clustering has gained increasing popularity in the analysis of gene
expression data. Among subspace cluster models, the recently introduced
order-preserving sub-matrix (OPSM) has demonstrated high promise. An OPSM,
essentially a pattern-based subspace cluster, is a subset of rows and columns
in a data matrix for which all the rows induce the same linear ordering of
columns. Existing OPSM discovery methods do not scale well to increasingly
large expression datasets. In particular, twig clusters having few genes and
many experiments incur explosive computational costs and are completely pruned
off by existing methods. However, it is of particular interest to determine
small groups of genes that are tightly coregulated across many conditions. In
this paper, we present KiWi, an OPSM subspace clustering algorithm that is
scalable to massive datasets, capable of discovering twig clusters and
identifying negative as well as positive correlations. We extensively validate
KiWi using relevant biological datasets and show that KiWi correctly assigns
redundant probes to the same cluster, groups experiments with common clinical
annotations, differentiates real promoter sequences from negative control
sequences, and shows good association with cis-regulatory motif predictions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1956</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1956</id><created>2009-04-13</created><updated>2009-08-18</updated><authors><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Calderbank</keyname><forenames>A. Robert</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Ergodic Layered Erasure One-Sided Interference Channels</title><categories>cs.IT math.IT</categories><comments>in Proc. IEEE Information Theory Workshop, Taormina, Sicily, Oct 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sum capacity of a class of layered erasure one-sided interference
channels is developed under the assumption of no channel state information at
the transmitters. Outer bounds are presented for this model and are shown to be
tight for the following sub-classes: i) weak, ii) strong (mix of strong but not
very strong (SnVS) and very strong (VS)), iii) ergodic very strong (mix of
strong and weak), and (iv) a sub-class of mixed interference (mix of SnVS and
weak). Each sub-class is uniquely defined by the fading statistics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.1989</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.1989</id><created>2009-04-13</created><authors><author><keyname>Zhang</keyname><forenames>Zi-Ke</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Personalized Recommendation via Integrated Diffusion on User-Item-Tag
  Tripartite Graphs</title><categories>cs.IR</categories><comments>12 pages, 6 figures, 2 tables</comments><journal-ref>Physica A 389 (2010) 179-186</journal-ref><doi>10.1016/j.physa.2009.08.036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Personalized recommender systems are confronting great challenges of
accuracy, diversification and novelty, especially when the data set is sparse
and lacks accessorial information, such as user profiles, item attributes and
explicit ratings. Collaborative tags contain rich information about
personalized preferences and item contents, and are therefore potential to help
in providing better recommendations. In this paper, we propose a recommendation
algorithm based on an integrated diffusion on user-item-tag tripartite graphs.
We use three benchmark data sets, Del.icio.us, MovieLens and BibSonomy, to
evaluate our algorithm. Experimental results demonstrate that the usage of tag
information can significantly improve accuracy, diversification and novelty of
recommendations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2012</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2012</id><created>2009-04-13</created><authors><author><keyname>Spivak</keyname><forenames>David I.</forenames></author></authors><title>Simplicial Databases</title><categories>cs.DB cs.IR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we define a category DB, called the category of simplicial
databases, whose objects are databases and whose morphisms are data-preserving
maps. Along the way we give a precise formulation of the category of relational
databases, and prove that it is a full subcategory of DB. We also prove that
limits and colimits always exist in DB and that they correspond to queries such
as select, join, union, etc.
  One feature of our construction is that the schema of a simplicial database
has a natural geometric structure: an underlying simplicial set. The geometry
of a schema is a way of keeping track of relationships between distinct tables,
and can be thought of as a system of foreign keys. The shape of a schema is
generally intuitive (e.g. the schema for round-trip flights is a circle
consisting of an edge from $A$ to $B$ and an edge from $B$ to $A$), and as
such, may be useful for analyzing data.
  We give several applications of our approach, as well as possible advantages
it has over the relational model. We also indicate some directions for further
research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2018</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2018</id><created>2009-04-14</created><updated>2009-06-11</updated><authors><author><keyname>Xie</keyname><forenames>J.</forenames></author><author><keyname>Jiang</keyname><forenames>Y.</forenames></author></authors><title>Stochastic Service Guarantee Analysis Based on Time-Domain Models</title><categories>cs.NI cs.PF</categories><comments>Accepted by 17th Annual Meeting of the IEEE/ACM International
  Symposium on Modelling, Analysis and Simulation of Computer and
  Telecommunication Systems. This version fixed Lemma 2 &amp;3 and Theorem 3 and
  also corrected some typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochastic network calculus is a theory for stochastic service guarantee
analysis of computer communication networks. In the current stochastic network
calculus literature, its traffic and server models are typically based on the
cumulative amount of traffic and cumulative amount of service respectively.
However, there are network scenarios where the applicability of such models is
limited, and hence new ways of modeling traffic and service are needed to
address this limitation. This paper presents time-domain models and results for
stochastic network calculus. Particularly, we define traffic models, which are
based on probabilistic lower-bounds on cumulative packet inter-arrival time,
and server models, which are based on probabilistic upper-bounds on cumulative
packet service time. In addition, examples demonstrating the use of the
proposed time-domain models are provided. On the basis of the proposed models,
the five basic properties of stochastic network calculus are also proved, which
implies broad applicability of the proposed time-domain approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2022</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2022</id><created>2009-04-13</created><authors><author><keyname>Smarandache</keyname><forenames>Roxana</forenames></author><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>Absdet-Pseudo-Codewords and Perm-Pseudo-Codewords: Definitions and
  Properties</title><categories>cs.IT cs.DM math.IT</categories><journal-ref>Proc. IEEE Int. Symp. Information Theory, Seoul, Korea, June 28 -
  July 3, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linear-programming decoding performance of a binary linear code crucially
depends on the structure of the fundamental cone of the parity-check matrix
that describes the code. Towards a better understanding of fundamental cones
and the vectors therein, we introduce the notion of absdet-pseudo-codewords and
perm-pseudo-codewords: we give the definitions, we discuss some simple
examples, and we list some of their properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2023</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2023</id><created>2009-04-13</created><authors><author><keyname>Grohmann</keyname><forenames>Bjoern</forenames></author></authors><title>A new Protocol for 1-2 Oblivious Transfer</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new protocol for 1-2 (String) Oblivious Transfer is proposed. The protocol
uses 5 rounds of message exchange.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2027</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2027</id><created>2009-04-13</created><authors><author><keyname>Nelson</keyname><forenames>Jelani</forenames></author><author><keyname>Woodruff</keyname><forenames>David P.</forenames></author></authors><title>A Near-Optimal Algorithm for L1-Difference</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give the first L_1-sketching algorithm for integer vectors which produces
nearly optimal sized sketches in nearly linear time. This answers the first
open problem in the list of open problems from the 2006 IITK Workshop on
Algorithms for Data Streams. Specifically, suppose Alice receives a vector x in
{-M,...,M}^n and Bob receives y in {-M,...,M}^n, and the two parties share
randomness. Each party must output a short sketch of their vector such that a
third party can later quickly recover a (1 +/- eps)-approximation to ||x-y||_1
with 2/3 probability given only the sketches. We give a sketching algorithm
which produces O(eps^{-2}log(1/eps)log(nM))-bit sketches in O(n*log^2(nM))
time, independent of eps. The previous best known sketching algorithm for L_1
is due to [Feigenbaum et al., SICOMP 2002], which achieved the optimal sketch
length of O(eps^{-2}log(nM)) bits but had a running time of O(n*log(nM)/eps^2).
Notice that our running time is near-linear for every eps, whereas for
sufficiently small values of eps, the running time of the previous algorithm
can be as large as quadratic. Like their algorithm, our sketching procedure
also yields a small-space, one-pass streaming algorithm which works even if the
entries of x,y are given in arbitrary order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2028</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2028</id><created>2009-04-14</created><updated>2009-04-15</updated><authors><author><keyname>Chen</keyname><forenames>Tao</forenames></author><author><keyname>Zhang</keyname><forenames>Honggang</forenames></author><author><keyname>Katz</keyname><forenames>Marcos</forenames></author></authors><title>Cloud Networking Formation in CogMesh Environment</title><categories>cs.NI</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As radio spectrum usage paradigm moving from the traditional command and
control allocation scheme to the open spectrum allocation scheme, wireless
networks meet new opportunities and challenges. In this article we introduce
the concept of cognitive wireless mesh (CogMesh) networks and address the
unique problem in such a network. CogMesh is a self-organized distributed
network architecture combining cognitive technologies with the mesh structure
in order to provide a uniform service platform over a wide range of networks.
It is based on dynamic spectrum access (DSA) and featured by self-organization,
self-configuration and self-healing. The unique problem in CogMesh is the
common control channel problem, which is caused by the opportunistic spectrum
sharing nature of secondary users (SU) in the network. More precisely, since
the channels of SUs are fluctuating according to the radio environment, it is
difficult to find always available global common control channels. This puts a
significant challenge on the network design. We develop the control cloud based
control channel selection and cluster based network formation techniques to
tackle this problem. Moreover, we show in this article that the swarm
intelligence is a good candidate to deal with the control channel problem in
CogMesh. Since the study of cognitive wireless networks (CWN) is still in its
early phase, the ideas provided in this article act as a catalyst to inspire
new solutions in this field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2037</identifier>
 <datestamp>2010-01-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2037</id><created>2009-04-13</created><updated>2010-01-06</updated><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Li</keyname><forenames>Hanxi</forenames></author></authors><title>Boosting through Optimization of Margin Distributions</title><categories>cs.LG cs.CV</categories><comments>9 pages. To publish/Published in IEEE Transactions on Neural
  Networks, 21(7), July 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boosting has attracted much research attention in the past decade. The
success of boosting algorithms may be interpreted in terms of the margin
theory. Recently it has been shown that generalization error of classifiers can
be obtained by explicitly taking the margin distribution of the training data
into account. Most of the current boosting algorithms in practice usually
optimizes a convex loss function and do not make use of the margin
distribution. In this work we design a new boosting algorithm, termed
margin-distribution boosting (MDBoost), which directly maximizes the average
margin and minimizes the margin variance simultaneously. This way the margin
distribution is optimized. A totally-corrective optimization algorithm based on
column generation is proposed to implement MDBoost. Experiments on UCI datasets
show that MDBoost outperforms AdaBoost and LPBoost in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2051</identifier>
 <datestamp>2011-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2051</id><created>2009-04-14</created><authors><author><keyname>Berg</keyname><forenames>Ewout van den</forenames></author><author><keyname>Friedlander</keyname><forenames>Michael P.</forenames></author></authors><title>Joint-sparse recovery from multiple measurements</title><categories>cs.IT math.IT</categories><comments>19 pages, 9 figures</comments><report-no>University of British Columbia, Department of Computer Science Tech.
  Rep. 2009-07</report-no><journal-ref>IEEE Trans. Info. Theory, 56(5):2516-2527, 2010</journal-ref><doi>10.1109/TIT.2010.2043876</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The joint-sparse recovery problem aims to recover, from sets of compressed
measurements, unknown sparse matrices with nonzero entries restricted to a
subset of rows. This is an extension of the single-measurement-vector (SMV)
problem widely studied in compressed sensing. We analyze the recovery
properties for two types of recovery algorithms. First, we show that recovery
using sum-of-norm minimization cannot exceed the uniform recovery rate of
sequential SMV using $\ell_1$ minimization, and that there are problems that
can be solved with one approach but not with the other. Second, we analyze the
performance of the ReMBo algorithm [M. Mishali and Y. Eldar, IEEE Trans. Sig.
Proc., 56 (2008)] in combination with $\ell_1$ minimization, and show how
recovery improves as more measurements are taken. From this analysis it follows
that having more measurements than number of nonzero rows does not improve the
potential theoretical recovery rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2058</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2058</id><created>2009-04-14</created><authors><author><keyname>Saha</keyname><forenames>Chandan</forenames></author><author><keyname>Saptharishi</keyname><forenames>Ramprasad</forenames></author><author><keyname>Saxena</keyname><forenames>Nitin</forenames></author></authors><title>The Power of Depth 2 Circuits over Algebras</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of polynomial identity testing (PIT) for depth 2
arithmetic circuits over matrix algebra. We show that identity testing of depth
3 (Sigma-Pi-Sigma) arithmetic circuits over a field F is polynomial time
equivalent to identity testing of depth 2 (Pi-Sigma) arithmetic circuits over
U_2(F), the algebra of upper-triangular 2 x 2 matrices with entries from F.
Such a connection is a bit surprising since we also show that, as computational
models, Pi-Sigma circuits over U_2(F) are strictly `weaker' than Sigma-Pi-Sigma
circuits over F.
  The equivalence further shows that PIT of depth 3 arithmetic circuits reduces
to PIT of width-2 planar commutative Algebraic Branching Programs (ABP). Thus,
identity testing for commutative ABPs is interesting even in the case of
width-2.
  Further, we give a deterministic polynomial time identity testing algorithm
for a Pi-Sigma circuit over any constant dimensional commutative algebra over
F. While over commutative algebras of polynomial dimension, identity testing is
at least as hard as that of Sigma-Pi-Sigma circuits over F.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2060</identifier>
 <datestamp>2013-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2060</id><created>2009-04-14</created><updated>2012-07-14</updated><authors><author><keyname>Cao</keyname><forenames>Zhigang</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoguang</forenames></author></authors><title>Complementary cooperation, minimal winning coalitions, and power indices</title><categories>cs.GT</categories><comments>60 pages</comments><journal-ref>Theoretical Computer Science, 470 (2013) 53-92</journal-ref><doi>10.1016/j.tcs.2012.11.033</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new simple game, which is referred to as the complementary
weighted multiple majority game (C-WMMG for short). C-WMMG models a basic
cooperation rule, the complementary cooperation rule, and can be taken as a
sister model of the famous weighted majority game (WMG for short). In this
paper, we concentrate on the two dimensional C-WMMG. An interesting property of
this case is that there are at most $n+1$ minimal winning coalitions (MWC for
short), and they can be enumerated in time $O(n\log n)$, where $n$ is the
number of players. This property guarantees that the two dimensional C-WMMG is
more handleable than WMG. In particular, we prove that the main power indices,
i.e. the Shapley-Shubik index, the Penrose-Banzhaf index, the Holler-Packel
index, and the Deegan-Packel index, are all polynomially computable. To make a
comparison with WMG, we know that it may have exponentially many MWCs, and none
of the four power indices is polynomially computable (unless P=NP). Still for
the two dimensional case, we show that local monotonicity holds for all of the
four power indices. In WMG, this property is possessed by the Shapley-Shubik
index and the Penrose-Banzhaf index, but not by the Holler-Packel index or the
Deegan-Packel index. Since our model fits very well the cooperation and
competition in team sports, we hope that it can be potentially applied in
measuring the values of players in team sports, say help people give more
objective ranking of NBA players and select MVPs, and consequently bring new
insights into contest theory and the more general field of sports economics. It
may also provide some interesting enlightenments into the design of
non-additive voting mechanisms. Last but not least, the threshold version of
C-WMMG is a generalization of WMG, and natural variants of it are closely
related with the famous airport game and the stable marriage/roommates problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2061</identifier>
 <datestamp>2011-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2061</id><created>2009-04-14</created><updated>2009-07-20</updated><authors><author><keyname>Cao</keyname><forenames>Zhigang</forenames></author><author><keyname>Yang</keyname><forenames>Xiaoguang</forenames></author></authors><title>Selfish Bin Covering</title><categories>cs.GT</categories><comments>16 pages</comments><journal-ref>Theoretical Computer Science, 412, 2011, 7049-7058</journal-ref><doi>10.1016/j.tcs.2011.09.017</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the selfish bin covering problem, which is greatly
related both to the bin covering problem, and to the weighted majority game.
What we mainly concern is how much the lack of coordination harms the social
welfare. Besides the standard PoA and PoS, which are based on Nash equilibrium,
we also take into account the strong Nash equilibrium, and several other new
equilibria. For each equilibrium, the corresponding PoA and PoS are given, and
the problems of computing an arbitrary equilibrium, as well as approximating
the best one, are also considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2076</identifier>
 <datestamp>2010-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2076</id><created>2009-04-14</created><updated>2009-06-09</updated><authors><author><keyname>Amadio</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author></authors><title>On stratified regions</title><categories>cs.LO</categories><proxy>ccsd hal-00375232</proxy><journal-ref>Programming Languages and Systems, 7th Asian Symposium, APLAS
  2009, Cor\'ee, R\'epublique De (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Type and effect systems are a tool to analyse statically the behaviour of
programs with effects. We present a proof based on the so called reducibility
candidates that a suitable stratification of the type and effect system entails
the termination of the typable programs. The proof technique covers a simply
typed, multi-threaded, call-by-value lambda-calculus, equipped with a variety
of scheduling (preemptive, cooperative) and interaction mechanisms (references,
channels, signals).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2096</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2096</id><created>2009-04-14</created><authors><author><keyname>Domingues</keyname><forenames>Christophe</forenames><affiliation>IBISC</affiliation></author><author><keyname>Otmane</keyname><forenames>Samir</forenames><affiliation>IBISC</affiliation></author><author><keyname>Davesne</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>IBISC</affiliation></author><author><keyname>Mallem</keyname><forenames>Malik</forenames><affiliation>IBISC</affiliation></author></authors><title>A Distributed Software Architecture for Collaborative Teleoperation
  based on a VR Platform and Web Application Interoperability</title><categories>cs.HC cs.GR cs.MM cs.RO</categories><proxy>ccsd hal-00344873</proxy><journal-ref>18th International Conference on Artificial Reality and
  Telexistence (ACM ICAT 2008), Yokohama : Japon (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Augmented Reality and Virtual Reality can provide to a Human Operator (HO) a
real help to complete complex tasks, such as robot teleoperation and
cooperative teleassistance. Using appropriate augmentations, the HO can
interact faster, safer and easier with the remote real world. In this paper, we
present an extension of an existing distributed software and network
architecture for collaborative teleoperation based on networked human-scaled
mixed reality and mobile platform. The first teleoperation system was composed
by a VR application and a Web application. However the 2 systems cannot be used
together and it is impossible to control a distant robot simultaneously. Our
goal is to update the teleoperation system to permit a heterogeneous
collaborative teleoperation between the 2 platforms. An important feature of
this interface is based on different Mobile platforms to control one or many
robots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2115</identifier>
 <datestamp>2011-04-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2115</id><created>2009-04-14</created><updated>2011-04-07</updated><authors><author><keyname>Aloupis</keyname><forenames>G.</forenames></author><author><keyname>Cardinal</keyname><forenames>J.</forenames></author><author><keyname>Collette</keyname><forenames>S.</forenames></author><author><keyname>Imahori</keyname><forenames>S.</forenames></author><author><keyname>Korman</keyname><forenames>M.</forenames></author><author><keyname>Langerman</keyname><forenames>S.</forenames></author><author><keyname>Schwartz</keyname><forenames>O.</forenames></author><author><keyname>Smorodinsky</keyname><forenames>S.</forenames></author><author><keyname>Taslakian</keyname><forenames>P.</forenames></author></authors><title>Colorful Strips</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a planar point set and an integer $k$, we wish to color the points with
$k$ colors so that any axis-aligned strip containing enough points contains all
colors. The goal is to bound the necessary size of such a strip, as a function
of $k$. We show that if the strip size is at least $2k{-}1$, such a coloring
can always be found. We prove that the size of the strip is also bounded in any
fixed number of dimensions. In contrast to the planar case, we show that
deciding whether a 3D point set can be 2-colored so that any strip containing
at least three points contains both colors is NP-complete.
  We also consider the problem of coloring a given set of axis-aligned strips,
so that any sufficiently covered point in the plane is covered by $k$ colors.
We show that in $d$ dimensions the required coverage is at most $d(k{-}1)+1$.
  Lower bounds are given for the two problems. This complements recent
impossibility results on decomposition of strip coverings with arbitrary
orientations. Finally, we study a variant where strips are replaced by wedges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2129</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2129</id><created>2009-04-14</created><authors><author><keyname>Mchedlidze</keyname><forenames>Tamara</forenames></author><author><keyname>Symvonis</keyname><forenames>Antonios</forenames></author></authors><title>Crossing-Optimal Acyclic HP-Completion for Outerplanar st-Digraphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an embedded planar acyclic digraph G, we define the problem of acyclic
hamiltonian path completion with crossing minimization (Acyclic-HPCCM) to be
the problem of determining a hamiltonian path completion set of edges such
that, when these edges are embedded on G, they create the smallest possible
number of edge crossings and turn G to a hamiltonian acyclic digraph. Our
results include: 1. We provide a characterization under which a planar
st-digraph G is hamiltonian. 2. For an outerplanar st-digraph G, we define the
st-polygon decomposition of G and, based on its properties, we develop a
linear-time algorithm that solves the Acyclic-HPCCM problem. 3. For the class
of planar st-digraphs, we establish an equivalence between the Acyclic-HPCCM
problem and the problem of determining an upward 2-page topological book
embedding with minimum number of spine crossings. We infer (based on this
equivalence) for the class of outerplanar st-digraphs an upward topological
2-page book embedding with minimum number of spine crossings. To the best of
our knowledge, it is the first time that edge-crossing minimization is studied
in conjunction with the acyclic hamiltonian completion problem and the first
time that an optimal algorithm with respect to spine crossing minimization is
presented for upward topological book embeddings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2136</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2136</id><created>2009-04-14</created><authors><author><keyname>Est&#xe9;vez-Mart&#xed;n</keyname><forenames>S.</forenames></author><author><keyname>Hortal&#xe1;-Gonz&#xe1;lez</keyname><forenames>T.</forenames></author><author><keyname>Rodr&#xed;guez-Artalejo</keyname></author><author><keyname>del Vado-V&#xed;rseda</keyname><forenames>R.</forenames></author><author><keyname>S&#xe1;enz-P&#xe9;rez</keyname><forenames>F.</forenames></author><author><keyname>Fern&#xe1;ndez</keyname><forenames>A. J.</forenames></author></authors><title>On the Cooperation of the Constraint Domains H, R and FD in CFLP</title><categories>cs.PL cs.SC</categories><comments>113 pages, 5 figures, 18 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a computational model for the cooperation of constraint
domains and an implementation for a particular case of practical importance.
The computational model supports declarative programming with lazy and possibly
higher-order functions, predicates, and the cooperation of different constraint
domains equipped with their respective solvers, relying on a so-called
Constraint Functional Logic Programming (CFLP) scheme. The implementation has
been developed on top of the CFLP system TOY, supporting the cooperation of the
three domains H, R and FD, which supply equality and disequality constraints
over symbolic terms, arithmetic constraints over the real numbers, and finite
domain constraints over the integers, respectively. The computational model has
been proved sound and complete w.r.t. the declarative semantics provided by the
$CFLP$ scheme, while the implemented system has been tested with a set of
benchmarks and shown to behave quite efficiently in comparison to the closest
related approach we are aware of.
  To appear in Theory and Practice of Logic Programming (TPLP)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2160</identifier>
 <datestamp>2009-04-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2160</id><created>2009-04-14</created><authors><author><keyname>Patnaik</keyname><forenames>Debprakash</forenames></author><author><keyname>Laxman</keyname><forenames>Srivatsan</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Naren</forenames></author></authors><title>Inferring Dynamic Bayesian Networks using Frequent Episode Mining</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivation: Several different threads of research have been proposed for
modeling and mining temporal data. On the one hand, approaches such as dynamic
Bayesian networks (DBNs) provide a formal probabilistic basis to model
relationships between time-indexed random variables but these models are
intractable to learn in the general case. On the other, algorithms such as
frequent episode mining are scalable to large datasets but do not exhibit the
rigorous probabilistic interpretations that are the mainstay of the graphical
models literature.
  Results: We present a unification of these two seemingly diverse threads of
research, by demonstrating how dynamic (discrete) Bayesian networks can be
inferred from the results of frequent episode mining. This helps bridge the
modeling emphasis of the former with the counting emphasis of the latter.
First, we show how, under reasonable assumptions on data characteristics and on
influences of random variables, the optimal DBN structure can be computed using
a greedy, local, algorithm. Next, we connect the optimality of the DBN
structure with the notion of fixed-delay episodes and their counts of distinct
occurrences. Finally, to demonstrate the practical feasibility of our approach,
we focus on a specific (but broadly applicable) class of networks, called
excitatory networks, and show how the search for the optimal DBN structure can
be conducted using just information from frequent episodes. Application on
datasets gathered from mathematical models of spiking neurons as well as real
neuroscience datasets are presented.
  Availability: Algorithmic implementations, simulator codebases, and datasets
are available from our website at http://neural-code.cs.vt.edu/dbn
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2203</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2203</id><created>2009-04-14</created><updated>2009-12-03</updated><authors><author><keyname>Pirwani</keyname><forenames>Imran A.</forenames><affiliation>Department of Computing Science, University of Alberta, Edmonton, Canada</affiliation></author><author><keyname>Salavatipour</keyname><forenames>Mohammad R.</forenames><affiliation>Department of Computing Science, University of Alberta, Edmonton, Canada</affiliation></author></authors><title>A Weakly-Robust PTAS for Minimum Clique Partition in Unit Disk Graphs</title><categories>cs.CG cs.DC cs.DM cs.DS</categories><comments>21 pages, 9 figures</comments><acm-class>G.2.2; F.2.2</acm-class><doi>10.1007/978-3-642-13731-0_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of partitioning the set of vertices of a given unit
disk graph (UDG) into a minimum number of cliques. The problem is NP-hard and
various constant factor approximations are known, with the current best ratio
of 3. Our main result is a {\em weakly robust} polynomial time approximation
scheme (PTAS) for UDGs expressed with edge-lengths, it either (i) computes a
clique partition or (ii) gives a certificate that the graph is not a UDG; for
the case (i) that it computes a clique partition, we show that it is guaranteed
to be within $(1+\eps)$ ratio of the optimum if the input is UDG; however if
the input is not a UDG it either computes a clique partition as in case (i)
with no guarantee on the quality of the clique partition or detects that it is
not a UDG. Noting that recognition of UDG's is NP-hard even if we are given
edge lengths, our PTAS is a weakly-robust algorithm. Our algorithm can be
transformed into an $O(\frac{\log^* n}{\eps^{O(1)}})$ time distributed PTAS.
  We consider a weighted version of the clique partition problem on vertex
weighted UDGs that generalizes the problem. We note some key distinctions with
the unweighted version, where ideas useful in obtaining a PTAS breakdown. Yet,
surprisingly, it admits a $(2+\eps)$-approximation algorithm for the weighted
case where the graph is expressed, say, as an adjacency matrix. This improves
on the best known 8-approximation for the {\em unweighted} case for UDGs
expressed in standard form.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2237</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2237</id><created>2009-04-15</created><authors><author><keyname>Luo</keyname><forenames>Jinquan</forenames></author></authors><title>On Binary Cyclic Codes with Five Nonzero Weights</title><categories>cs.IT cs.DM math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $q=2^n$, $0\leq k\leq n-1$, $n/\gcd(n,k)$ be odd and $k\neq n/3, 2n/3$.
In this paper the value distribution of following exponential sums
\[\sum\limits_{x\in \bF_q}(-1)^{\mathrm{Tr}_1^n(\alpha x^{2^{2k}+1}+\beta
x^{2^k+1}+\ga x)}\quad(\alpha,\beta,\ga\in \bF_{q})\] is determined. As an
application, the weight distribution of the binary cyclic code $\cC$, with
parity-check polynomial $h_1(x)h_2(x)h_3(x)$ where $h_1(x)$, $h_2(x)$ and
$h_3(x)$ are the minimal polynomials of $\pi^{-1}$, $\pi^{-(2^k+1)}$ and
$\pi^{-(2^{2k}+1)}$ respectively for a primitive element $\pi$ of $\bF_q$, is
also determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2257</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2257</id><created>2009-04-15</created><authors><author><keyname>Honkala</keyname><forenames>Juha</forenames></author></authors><title>The equality problem for infinite words generated by primitive morphisms</title><categories>cs.FL</categories><comments>Preliminary version of a paper to appear in Information and
  Computation</comments><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the equality problem for infinite words obtained by iterating
morphisms. In particular, we give a practical algorithm to decide whether or
not two words generated by primitive morphisms are equal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2290</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2290</id><created>2009-04-15</created><authors><author><keyname>Chettibi</keyname><forenames>Saloua</forenames></author></authors><title>A Comprehensive study of a New Multipath Energy Aware Routing Protocol
  for Mobile Ad-hoc Networks</title><categories>cs.NI</categories><proxy>ccsd hal-00375517</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximizing network lifetime is a very challenging issue in routing protocol
design for Mobile Ad-hoc NETworks (MANETs), since mobile nodes are powered by
limited-capacity batteries. Furthermore, replacing or recharging batteries is
often impossible in critical environments (e.g. battlefields, disaster areas,
etc.) The proposed MEA-DSR (Multipath Energy-Aware on Demand Source Routing)
protocol uses a load distribution policy in order to maximize network lifetime.
The simulation results have shown the efficiency of the proposed protocol in
comparison to DSR routing protocol in many difficult scenarios
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2302</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2302</id><created>2009-04-15</created><authors><author><keyname>Zhou</keyname><forenames>Chan</forenames></author><author><keyname>Wunder</keyname><forenames>Gerhard</forenames></author></authors><title>A Fundamental Characterization of Stability in Broadcast Queueing
  Systems</title><categories>cs.NI cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Stability with respect to a given scheduling policy has become an important
issue for wireless communication systems, but it is hard to prove in particular
scenarios. In this paper two simple conditions for stability in broadcast
channels are derived, which are easy to check. Heuristically, the conditions
imply that if the queue length in the system becomes large, the rate allocation
is always the solution of a weighted sum rate maximization problem.
Furthermore, the change of the weight factors between two time slots becomes
smaller and the weight factors of the users, whose queues are bounded while the
other queues expand, tend to zero. Then it is shown that for any mean arrival
rate vector inside the ergodic achievable rate region the system is stable in
the strong sense when the given scheduling policy complies with the conditions.
In this case the policy is so-called throughput-optimal. Subsequently, some
results on the necessity of the presented conditions are provided. Finally, in
several application examples it is shown that the results in the paper provide
a convenient way to verify the throughput-optimal policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2306</identifier>
 <datestamp>2010-03-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2306</id><created>2009-04-15</created><updated>2010-03-09</updated><authors><author><keyname>Chang</keyname><forenames>Ching-Lueh</forenames></author><author><keyname>Lyuu</keyname><forenames>Yuh-Dauh</forenames></author></authors><title>On irreversible dynamic monopolies in general graphs</title><categories>cs.DM cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the following coloring process in a simple directed graph $G(V,E)$
with positive indegrees. Initially, a set $S$ of vertices are white, whereas
all the others are black. Thereafter, a black vertex is colored white whenever
more than half of its in-neighbors are white. The coloring process ends when no
additional vertices can be colored white. If all vertices end up white, we call
$S$ an irreversible dynamic monopoly (or dynamo for short) under the
strict-majority scenario. An irreversible dynamo under the simple-majority
scenario is defined similarly except that a black vertex is colored white when
at least half of its in-neighbors are white. We derive upper bounds of
$(2/3)\,|\,V\,|$ and $|\,V\,|/2$ on the minimum sizes of irreversible dynamos
under the strict and the simple-majority scenarios, respectively. For the
special case when $G$ is an undirected connected graph, we prove the existence
of an irreversible dynamo with size at most $\lceil |\,V\,|/2 \rceil$ under the
strict-majority scenario. Let $\epsilon&gt;0$ be any constant. We also show that,
unless $\text{NP}\subseteq \text{TIME}(n^{O(\ln \ln n)}),$ no polynomial-time,
$((1/2-\epsilon)\ln |\,V\,|)$-approximation algorithms exist for finding the
minimum irreversible dynamo under either the strict or the simple-majority
scenario. The inapproximability results hold even for bipartite graphs with
diameter at most 8.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2310</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2310</id><created>2009-04-15</created><authors><author><keyname>Berman</keyname><forenames>Piotr</forenames></author><author><keyname>Karpinski</keyname><forenames>Marek</forenames></author><author><keyname>Lingas</keyname><forenames>Andrzej</forenames></author></authors><title>Exact and Approximation Algorithms for Geometric and Capacitated Set
  Cover Problems with Applications</title><categories>cs.CC cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  First, we study geometric variants of the standard set cover motivated by
assignment of directional antenna and shipping with deadlines, providing the
first known polynomial-time exact solutions. Next, we consider the following
general capacitated set cover problem. There is given a set of elements with
real weights and a family S of sets of elements. One can use a set if it is a
subset of one of the sets on our lists and the sum of weights is at most one.
The goal is to cover all the elements with the allowed sets.&lt;br&gt;We show that
any polynomial-time algorithm that approximates the un-capacitated version of
the set cover problem with ratio r can be converted to an approximation
algorithm for the capacitated version with ratio r + 1.357.In particular, the
composition of these two results yields a polynomial-time approximation
algorithm for the problem of covering a set of customers represented by a
weighted n-point set with a minimum number of antennas of variable angular
range and fixed capacity with ratio 2.357. Finally, we provide a PTAS for the
dual problem where the number of sets (e.g., antennas) to use is fixed and the
task is to minimize the maximum set load, in case the sets correspond to line
intervals or arcs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2311</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2311</id><created>2009-04-15</created><updated>2009-04-30</updated><authors><author><keyname>Weissman</keyname><forenames>Tsachy</forenames></author><author><keyname>Permuter</keyname><forenames>Haim H.</forenames></author></authors><title>Source Coding with a Side Information &quot;Vending Machine&quot;</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study source coding in the presence of side information, when the system
can take actions that affect the availability, quality, or nature of the side
information. We begin by extending the Wyner-Ziv problem of source coding with
decoder side information to the case where the decoder is allowed to choose
actions affecting the side information. We then consider the setting where
actions are taken by the encoder, based on its observation of the source.
Actions may have costs that are commensurate with the quality of the side
information they yield, and an overall per-symbol cost constraint may be
imposed. We characterize the achievable tradeoffs between rate, distortion, and
cost in some of these problem settings. Among our findings is the fact that
even in the absence of a cost constraint, greedily choosing the action
associated with the `best' side information is, in general, sub-optimal. A few
examples are worked out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2320</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2320</id><created>2009-04-15</created><authors><author><keyname>Abdallah</keyname><forenames>Sherief</forenames></author></authors><title>Why Global Performance is a Poor Metric for Verifying Convergence of
  Multi-agent Learning</title><categories>cs.MA cs.LG</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Experimental verification has been the method of choice for verifying the
stability of a multi-agent reinforcement learning (MARL) algorithm as the
number of agents grows and theoretical analysis becomes prohibitively complex.
For cooperative agents, where the ultimate goal is to optimize some global
metric, the stability is usually verified by observing the evolution of the
global performance metric over time. If the global metric improves and
eventually stabilizes, it is considered a reasonable verification of the
system's stability.
  The main contribution of this note is establishing the need for better
experimental frameworks and measures to assess the stability of large-scale
adaptive cooperative systems. We show an experimental case study where the
stability of the global performance metric can be rather deceiving, hiding an
underlying instability in the system that later leads to a significant drop in
performance. We then propose an alternative metric that relies on agents' local
policies and show, experimentally, that our proposed metric is more effective
(than the traditional global performance metric) in exposing the instability of
MARL algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2323</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2323</id><created>2009-04-15</created><authors><author><keyname>Schneider</keyname><forenames>Carsten</forenames></author></authors><title>A Symbolic Summation Approach to Find Optimal Nested Sum Representations</title><categories>cs.SC math.CO math.NT</categories><comments>To appear in Clay Mathematics Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following problem: Given a nested sum expression, find a sum
representation such that the nested depth is minimal. We obtain a symbolic
summation framework that solves this problem for sums defined, e.g., over
hypergeometric, $q$-hypergeometric or mixed hypergeometric expressions.
Recently, our methods have found applications in quantum field theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2340</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2340</id><created>2009-04-15</created><updated>2009-06-22</updated><authors><author><keyname>Cacciagrano</keyname><forenames>D.</forenames></author><author><keyname>Corradini</keyname><forenames>F.</forenames></author><author><keyname>Palamidessi</keyname><forenames>C.</forenames></author></authors><title>Explicit fairness in testing semantics</title><categories>cs.LO</categories><comments>27 pages, 1 figure, appeared in LMCS</comments><acm-class>F.1.2; D.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (June 22,
  2009) lmcs:1134</journal-ref><doi>10.2168/LMCS-5(2:15)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate fair computations in the pi-calculus. Following
Costa and Stirling's approach for CCS-like languages, we consider a method to
label process actions in order to filter out unfair computations. We contrast
the existing fair-testing notion with those that naturally arise by imposing
weak and strong fairness. This comparison provides insight about the
expressiveness of the various `fair' testing semantics and about their
discriminating power.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2375</identifier>
 <datestamp>2009-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2375</id><created>2009-04-15</created><authors><author><keyname>Manada</keyname><forenames>Akiko</forenames></author><author><keyname>Kashyap</keyname><forenames>Navin</forenames></author></authors><title>The Zeta Function of a Periodic-Finite-Type Shift</title><categories>cs.IT math.IT</categories><comments>To appear in Proceedings of the 2009 IEEE International Symposium on
  Information Theory (ISIT'09); 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The class of periodic-finite-type shifts (PFT's) is a class of sofic shifts
that strictly includes the class of shifts of finite type (SFT's), and the zeta
function of a PFT is a generating function for the number of periodic sequences
in the shift. In this paper, we derive a useful formula for the zeta function
of a PFT. This formula allows the zeta function of a PFT to be computed more
efficiently than the specialization of a formula known for a generic sofic
shift
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2385</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2385</id><created>2009-04-15</created><updated>2009-04-15</updated><authors><author><keyname>Milius</keyname><forenames>Stefan</forenames></author><author><keyname>Moss</keyname><forenames>Lawrence S.</forenames></author></authors><title>The Category Theoretic Solution of Recursive Program Schemes</title><categories>cs.LO math.CT</categories><comments>this version includes the corrections from the corrigendum in
  Theoret. Comput. Sci. 403 (2008), 409-415</comments><journal-ref>Theoret. Comput. Sci. 366 (2006), 3-59</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides a general account of the notion of recursive program
schemes, studying both uninterpreted and interpreted solutions. It can be
regarded as the category-theoretic version of the classical area of algebraic
semantics. The overall assumptions needed are small indeed: working only in
categories with &quot;enough final coalgebras&quot; we show how to formulate, solve, and
study recursive program schemes. Our general theory is algebraic and so avoids
using ordered, or metric structures. Our work generalizes the previous
approaches which do use this extra structure by isolating the key concepts
needed to study substitution in infinite trees, including second-order
substitution. As special cases of our interpreted solutions we obtain the usual
denotational semantics using complete partial orders, and the one using
complete metric spaces. Our theory also encompasses implicitly defined objects
which are not usually taken to be related to recursive program schemes. For
example, the classical Cantor two-thirds set falls out as an interpreted
solution (in our sense) of a recursive program scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2389</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2389</id><created>2009-04-15</created><authors><author><keyname>Serrano</keyname><forenames>M. Angeles</forenames></author><author><keyname>Boguna</keyname><forenames>Marian</forenames></author><author><keyname>Vespignani</keyname><forenames>Alessandro</forenames></author></authors><title>Extracting the multiscale backbone of complex weighted networks</title><categories>physics.soc-ph cond-mat.dis-nn cs.NI</categories><journal-ref>Proc. Natl. Acad. Sci. USA 106, 6483-6488 (2009)</journal-ref><doi>10.1073/pnas.0808904106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large number of complex systems find a natural abstraction in the form of
weighted networks whose nodes represent the elements of the system and the
weighted edges identify the presence of an interaction and its relative
strength. In recent years, the study of an increasing number of large scale
networks has highlighted the statistical heterogeneity of their interaction
pattern, with degree and weight distributions which vary over many orders of
magnitude. These features, along with the large number of elements and links,
make the extraction of the truly relevant connections forming the network's
backbone a very challenging problem. More specifically, coarse-graining
approaches and filtering techniques are at struggle with the multiscale nature
of large scale systems. Here we define a filtering method that offers a
practical procedure to extract the relevant connection backbone in complex
multiscale networks, preserving the edges that represent statistical
significant deviations with respect to a null model for the local assignment of
weights to edges. An important aspect of the method is that it does not
belittle small-scale interactions and operates at all scales defined by the
weight distribution. We apply our method to real world network instances and
compare the obtained results with alternative backbone extraction techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2400</identifier>
 <datestamp>2009-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2400</id><created>2009-04-16</created><authors><author><keyname>Briest</keyname><forenames>Patrick</forenames></author><author><keyname>Chawla</keyname><forenames>Shuchi</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Weinberg</keyname><forenames>S. Matthew</forenames></author></authors><title>Pricing Randomized Allocations</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized mechanisms, which map a set of bids to a probability distribution
over outcomes rather than a single outcome, are an important but ill-understood
area of computational mechanism design. We investigate the role of randomized
outcomes (henceforth, &quot;lotteries&quot;) in the context of a fundamental and
archetypical multi-parameter mechanism design problem: selling heterogeneous
items to unit-demand bidders. To what extent can a seller improve her revenue
by pricing lotteries rather than items, and does this modification of the
problem affect its computational tractability? Our results show that the
answers to these questions hinge on whether consumers can purchase only one
lottery (the buy-one model) or purchase any set of lotteries and receive an
independent sample from each (the buy-many model). In the buy-one model, there
is a polynomial-time algorithm to compute the revenue-maximizing envy-free
prices (thus overcoming the inapproximability of the corresponding item pricing
problem) and the revenue of the optimal lottery system can exceed the revenue
of the optimal item pricing by an unbounded factor as long as the number of
item types exceeds 4. In the buy-many model with n item types, the profit
achieved by lottery pricing can exceed item pricing by a factor of O(log n) but
not more, and optimal lottery pricing cannot be approximated within a factor of
O(n^eps) for some eps&gt;0, unless NP has subexponential-time randomized
algorithms. Our lower bounds rely on a mixture of geometric and algebraic
techniques, whereas the upper bounds use a novel rounding scheme to transform a
mechanism with randomized outcomes into one with deterministic outcomes while
losing only a bounded amount of revenue.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2401</identifier>
 <datestamp>2009-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2401</id><created>2009-04-15</created><authors><author><keyname>Yazdi</keyname><forenames>S. M. Sadegh Tabatabaei</forenames></author><author><keyname>Savari</keyname><forenames>Serap A.</forenames></author></authors><title>A Combinatorial Study of Linear Deterministic Relay Networks</title><categories>cs.IT math.IT</categories><comments>24 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the last few years the so--called &quot;linear deterministic&quot; model of relay
channels has gained popularity as a means of studying the flow of information
over wireless communication networks, and this approach generalizes the model
of wireline networks which is standard in network optimization. There is recent
work extending the celebrated max--flow/min--cut theorem to the capacity of a
unicast session over a linear deterministic relay network which is modeled by a
layered directed graph. This result was first proved by a random coding scheme
over large blocks of transmitted signals. We demonstrate the same result with a
simple, deterministic, polynomial--time algorithm which takes as input a single
transmitted signal instead of a long block of signals. Our capacity-achieving
transmission scheme for a two--layer network requires the extension of a
one--dimensional Rado--Hall transversal theorem on the independent subsets of
rows of a row--partitioned matrix into a two--dimensional variation for block
matrices. To generalize our approach to larger networks we use the
submodularity of the capacity of a cut for our model and show that our complete
transmission scheme can be obtained by solving a linear program over the
intersection of two polymatroids. We prove that our transmission scheme can
achieve the max-flow/min-cut capacity by applying a theorem of Edmonds about
such linear programs. We use standard submodular function minimization
techniques as part of our polynomial--time algorithm to construct our
capacity-achieving transmission scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2441</identifier>
 <datestamp>2009-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2441</id><created>2009-04-16</created><authors><author><keyname>Jacobsen</keyname><forenames>Rasmus</forenames></author><author><keyname>Nielsen</keyname><forenames>Karsten Fyhn</forenames></author><author><keyname>Popovski</keyname><forenames>Petar</forenames></author><author><keyname>Larsen</keyname><forenames>Torben</forenames></author></authors><title>Reliable Identification of RFID Tags Using Multiple Independent Reader
  Sessions</title><categories>cs.IT math.IT</categories><comments>Presented at IEEE RFID 2009 Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Radio Frequency Identification (RFID) systems are gaining momentum in various
applications of logistics, inventory, etc. A generic problem in such systems is
to ensure that the RFID readers can reliably read a set of RFID tags, such that
the probability of missing tags stays below an acceptable value. A tag may be
missing (left unread) due to errors in the communication link towards the
reader e.g. due to obstacles in the radio path. The present paper proposes
techniques that use multiple reader sessions, during which the system of
readers obtains a running estimate of the probability to have at least one tag
missing. Based on such an estimate, it is decided whether an additional reader
session is required. Two methods are proposed, they rely on the statistical
independence of the tag reading errors across different reader sessions, which
is a plausible assumption when e.g. each reader session is executed on
different readers. The first method uses statistical relationships that are
valid when the reader sessions are independent. The second method is obtained
by modifying an existing capture-recapture estimator. The results show that,
when the reader sessions are independent, the proposed mechanisms provide a
good approximation to the probability of missing tags, such that the number of
reader sessions made, meets the target specification. If the assumption of
independence is violated, the estimators are still useful, but they should be
corrected by a margin of additional reader sessions to ensure that the target
probability of missing tags is met.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2448</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2448</id><created>2009-04-16</created><authors><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author><author><keyname>Valiente</keyname><forenames>Gabriel</forenames></author></authors><title>All that Glisters is not Galled</title><categories>cs.DM cs.CE q-bio.PE</categories><comments>13 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Galled trees, evolutionary networks with isolated reticulation cycles, have
appeared under several slightly different definitions in the literature. In
this paper we establish the actual relationships between the main four such
alternative definitions: namely, the original galled trees, level-1 networks,
nested networks with nesting depth 1, and evolutionary networks with
arc-disjoint reticulation cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2452</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2452</id><created>2009-04-16</created><updated>2009-12-17</updated><authors><author><keyname>Mezzarobba</keyname><forenames>Marc</forenames></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames></author></authors><title>Effective Bounds for P-Recursive Sequences</title><categories>cs.SC</categories><comments>26 pages</comments><doi>10.1016/j.jsc.2010.06.024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm that takes as input a complex sequence $(u_n)$ given
by a linear recurrence relation with polynomial coefficients along with initial
values, and outputs a simple explicit upper bound $(v_n)$ such that $|u_n| \leq
v_n$ for all $n$. Generically, the bound is tight, in the sense that its
asymptotic behaviour matches that of $u_n$. We discuss applications to the
evaluation of power series with guaranteed precision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2457</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2457</id><created>2009-04-16</created><authors><author><keyname>Jeandel</keyname><forenames>Emmanuel</forenames><affiliation>LIF</affiliation></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames><affiliation>LM-Savoie</affiliation></author></authors><title>Subshifts, Languages and Logic</title><categories>cs.DM cs.LO</categories><proxy>ccsd hal-00375816</proxy><journal-ref>13th International Conference on Developments in Language Theory,
  Stuttgart : Allemagne (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the Monadic Second Order (MSO) Hierarchy over in?nite pictures, that
is tilings. We give a characterization of existential MSO in terms of tilings
and projections of tilings. Conversely, we characterise logic fragments
corresponding to various classes of in?nite pictures (subshifts of ?nite type,
so?c subshifts).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2477</identifier>
 <datestamp>2009-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2477</id><created>2009-04-16</created><authors><author><keyname>Harremo&#xeb;s</keyname><forenames>Peter</forenames></author></authors><title>Joint Range of R\'enyi Entropies</title><categories>cs.IT math.IT math.PR</categories><msc-class>94A17; 62B10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exact range of the joined values of several R\'{e}nyi entropies is
determined. The method is based on topology with special emphasis on the
orientation of the objects studied. Like in the case when only two orders of
R\'{e}nyi entropies are studied one can parametrize upper and lower bounds but
an explicit formula for a tight upper or lower bound cannot be given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2482</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2482</id><created>2009-04-16</created><authors><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author><author><keyname>Rosnes</keyname><forenames>Eirik</forenames></author></authors><title>Good Concatenated Code Ensembles for the Binary Erasure Channel</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Journal on Selected Areas in Communications,
  special issue on Capacity Approaching Codes</comments><journal-ref>IEEE J. Select. Areas Commun., vol. 27, no. 6, pp. 928-943, Aug.
  2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we give good concatenated code ensembles for the binary erasure
channel (BEC). In particular, we consider repeat multiple-accumulate (RMA) code
ensembles formed by the serial concatenation of a repetition code with multiple
accumulators, and the hybrid concatenated code (HCC) ensembles recently
introduced by Koller et al. (5th Int. Symp. on Turbo Codes &amp; Rel. Topics,
Lausanne, Switzerland) consisting of an outer multiple parallel concatenated
code serially concatenated with an inner accumulator. We introduce stopping
sets for iterative constituent code oriented decoding using maximum a
posteriori erasure correction in the constituent codes. We then analyze the
asymptotic stopping set distribution for RMA and HCC ensembles and show that
their stopping distance hmin, defined as the size of the smallest nonempty
stopping set, asymptotically grows linearly with the block length. Thus, these
code ensembles are good for the BEC. It is shown that for RMA code ensembles,
contrary to the asymptotic minimum distance dmin, whose growth rate coefficient
increases with the number of accumulate codes, the hmin growth rate coefficient
diminishes with the number of accumulators. We also consider random puncturing
of RMA code ensembles and show that for sufficiently high code rates, the
asymptotic hmin does not grow linearly with the block length, contrary to the
asymptotic dmin, whose growth rate coefficient approaches the Gilbert-Varshamov
bound as the rate increases. Finally, we give iterative decoding thresholds for
the different code ensembles to compare the convergence properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2511</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2511</id><created>2009-04-16</created><updated>2009-09-11</updated><authors><author><keyname>Br&#xe1;zdil</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Bro&#x17e;ek</keyname><forenames>V&#xe1;clav</forenames></author><author><keyname>Etessami</keyname><forenames>Kousha</forenames></author><author><keyname>Ku&#x10d;era</keyname><forenames>Anton&#xed;n</forenames></author><author><keyname>Wojtczak</keyname><forenames>Dominik</forenames></author></authors><title>One-Counter Markov Decision Processes</title><categories>cs.GT cs.FL</categories><comments>Updated preliminary version, submitted to SODA2010</comments><acm-class>G.3; F.1.1; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the computational complexity of central analysis problems for
One-Counter Markov Decision Processes (OC-MDPs), a class of finitely-presented,
countable-state MDPs. OC-MDPs are equivalent to a controlled extension of
(discrete-time) Quasi-Birth-Death processes (QBDs), a stochastic model studied
heavily in queueing theory and applied probability. They can thus be viewed as
a natural ``adversarial'' version of a classic stochastic model. Alternatively,
they can also be viewed as a natural probabilistic/controlled extension of
classic one-counter automata. OC-MDPs also subsume (as a very restricted
special case) a recently studied MDP model called ``solvency games'' that model
a risk-averse gambling scenario. Basic computational questions about these
models include ``termination'' questions and ``limit'' questions, such as the
following: does the controller have a ``strategy'' (or ``policy'') to ensure
that the counter (which may for example count the number of jobs in the queue)
will hit value 0 (the empty queue) almost surely (a.s.)? Or that it will have
infinite limsup value, a.s.? Or, that it will hit value 0 in selected terminal
states, a.s.? Or, in case these are not satisfied a.s., compute the maximum
(supremum) such probability over all strategies. We provide new upper and lower
bounds on the complexity of such problems. For some of them we present a
polynomial-time algorithm, whereas for others we show PSPACE- or BH-hardness
and give an EXPTIME upper bound. Our upper bounds combine techniques from the
theory of MDP reward models, the theory of random walks, and a variety of
automata-theoretic methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2521</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2521</id><created>2009-04-16</created><updated>2009-06-02</updated><authors><author><keyname>Madelaine</keyname><forenames>Florent R.</forenames></author></authors><title>Universal Structures and the logic of Forbidden Patterns</title><categories>cs.LO cs.DM</categories><comments>25 pages, 3 figures, extended version of conference papers at CSR'06
  and CSL'06</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (June 2,
  2009) lmcs:1237</journal-ref><doi>10.2168/LMCS-5(2:13)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Forbidden Patterns Problems (FPPs) are a proper generalisation of Constraint
Satisfaction Problems (CSPs). However, we show that when the input is connected
and belongs to a class which has low tree-depth decomposition (e.g. structure
of bounded degree, proper minor closed class and more generally class of
bounded expansion) any FPP becomes a CSP. This result can also be rephrased in
terms of expressiveness of the logic MMSNP, introduced by Feder and Vardi in
relation with CSPs. Our proof generalises that of a recent paper by Nesetril
and Ossona de Mendez. Note that our result holds in the general setting of
problems over arbitrary relational structures (not just for graphs).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2540</identifier>
 <datestamp>2010-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2540</id><created>2009-04-16</created><updated>2010-09-30</updated><authors><author><keyname>Benford</keyname><forenames>David H. Wolpert Gregory</forenames></author></authors><title>What does Newcomb's paradox teach us?</title><categories>cs.GT</categories><comments>Revised version with analysis extended and clarified; 22 pages, 1
  table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In Newcomb's paradox you choose to receive either the contents of a
particular closed box, or the contents of both that closed box and another one.
Before you choose though, an antagonist uses a prediction algorithm to deduce
your choice, and fills the two boxes based on that deduction. Newcomb's paradox
is that game theory's expected utility and dominance principles appear to
provide conflicting recommendations for what you should choose. A recent
extension of game theory provides a powerful tool for resolving paradoxes
concerning human choice, which formulates such paradoxes in terms of Bayes
nets. Here we apply this to ol to Newcomb's scenario. We show that the
conflicting recommendations in Newcomb's scenario use different Bayes nets to
relate your choice and the algorithm's prediction. These two Bayes nets are
incompatible. This resolves the paradox: the reason there appears to be two
conflicting recommendations is that the specification of the underlying Bayes
net is open to two, conflicting interpretations. We then show that the accuracy
of the prediction algorithm in Newcomb's paradox, the focus of much previous
work, is irrelevant. We similarly show that the utility functions of you and
the antagonist are irrelevant. We end by showing that Newcomb's paradox is
time-reversal invariant; both the paradox and its resolution are unchanged if
the algorithm makes its `prediction' \emph{after} you make your choice rather
than before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2541</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2541</id><created>2009-04-16</created><updated>2009-05-15</updated><authors><author><keyname>Gebauer</keyname><forenames>Heidi</forenames></author></authors><title>Disproof of the Neighborhood Conjecture with Implications to SAT</title><categories>cs.GT</categories><comments>12 pages, 1 figure</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a Maker/Breaker game described by Beck. As a result we disprove a
conjecture of Beck on positional games, establish a connection between this
game and SAT and construct an unsatisfiable k-CNF formula with few occurrences
per variable, thereby improving a previous result by Hoory and Szeider and
showing that the bound obtained from the Lovasz Local Lemma is tight up to a
constant factor. The Maker/Breaker game we study is as follows. Maker and
Breaker take turns in choosing vertices from a given n-uniform hypergraph F,
with Maker going first. Maker's goal is to completely occupy a hyperedge and
Breaker tries to avoid this. Beck conjectures that if the maximum neighborhood
size of F is at most 2^(n-1) then Breaker has a winning strategy. We disprove
this conjecture by establishing an n-uniform hypergraph with maximum
neighborhood size 3*2^(n - 3) where Maker has a winning strategy. Moreover, we
show how to construct an n-uniform hypergraph with maximum degree (2^(n-1))/n
where maker has a winning strategy. Finally, we establish a connection between
SAT and the Maker/Breaker game we study. We can use this connection to derive
new results in SAT. Kratochvil, Savicky and Tuza showed that for every k &gt;= 3
there is an integer f(k) such that every (k,f(k))-formula is satisfiable, but
(k,f(k) + 1)-SAT is already NP-complete (it is not known whether f(k) is
computable). Kratochvil, Savicky and Tuza also gave the best known lower bound
f(k) = Omega(2^k/k), which is a consequence of the Lovasz Local Lemma. We prove
that, in fact, f(k) = Theta(2^k/k), improving upon the best known upper bound
O((log k) * 2^k/k) by Hoory and Szeider.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2550</identifier>
 <datestamp>2012-10-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2550</id><created>2009-04-16</created><authors><author><keyname>Maheshwari</keyname><forenames>Anil</forenames></author><author><keyname>Wuhrer</keyname><forenames>Stefanie</forenames></author></authors><title>Geodesic Paths On 3D Surfaces: Survey and Open Problems</title><categories>cs.CG</categories><journal-ref>Extended version in: Computational Geometry - Theory and
  Applications, 44(9):486-498, 2011</journal-ref><doi>10.1016/j.comgeo.2011.05.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This survey gives a brief overview of theoretically and practically relevant
algorithms to compute geodesic paths and distances on three-dimensional
surfaces. The survey focuses on polyhedral three-dimensional surfaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2576</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2576</id><created>2009-04-16</created><authors><author><keyname>Adamaszek</keyname><forenames>Anna</forenames></author><author><keyname>Czumaj</keyname><forenames>Artur</forenames></author><author><keyname>Lingas</keyname><forenames>Andrzej</forenames></author></authors><title>PTAS for k-tour cover problem on the plane for moderately large values
  of k</title><categories>cs.DS</categories><comments>11 pages, 2 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let P be a set of n points in the Euclidean plane and let O be the origin
point in the plane. In the k-tour cover problem (called frequently the
capacitated vehicle routing problem), the goal is to minimize the total length
of tours that cover all points in P, such that each tour starts and ends in O
and covers at most k points from P.
  The k-tour cover problem is known to be NP-hard. It is also known to admit
constant factor approximation algorithms for all values of k and even a
polynomial-time approximation scheme (PTAS) for small values of k, i.e.,
k=O(log n / log log n).
  We significantly enlarge the set of values of k for which a PTAS is provable.
We present a new PTAS for all values of k &lt;= 2^{log^{\delta}n}, where \delta =
\delta(\epsilon). The main technical result proved in the paper is a novel
reduction of the k-tour cover problem with a set of n points to a small set of
instances of the problem, each with O((k/\epsilon)^O(1)) points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2584</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2584</id><created>2009-04-16</created><authors><author><keyname>Lizcano</keyname><forenames>J. A. Manzano</forenames></author><author><keyname>Florez</keyname><forenames>S. A. Jaramillo</forenames></author></authors><title>New technologies for high speed computer networks: a wavelet approach</title><categories>cs.NI</categories><comments>in spanish, 13 pages, associated research in
  http://www.airenatural.com; Published in Revista AIELEC de la Universidad
  Pontificia Bolivariana. 2001</comments><acm-class>C.2.1; B.4.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Indoor multpropagation channel is modeled by the Kaiser electromagnetic
wavelet. A method for channel characterization is proposed by modeling all the
reflections of indoor propagation in a kernel function instead of its impulse
response. This lead us to consider a fractal modulation scheme in which Kaiser
wavelets substitute the traditional sinusoidal carrier.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2585</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2585</id><created>2009-04-16</created><authors><author><keyname>Djeumou</keyname><forenames>Brice</forenames></author><author><keyname>Belmega</keyname><forenames>Elena Veronica</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author></authors><title>Interference Relay Channels - Part I: Transmission Rates</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the performance of a system composed of two interfering
point-to-point links where the transmitters can exploit a common relay to
improve their individual transmission rate. When the relay uses the
amplify-and-forward protocol we prove that it is not always optimal (in some
sense defined later on) to exploit all the relay transmit power and derive the
corresponding optimal amplification factor. For the case of the
decode-and-forward protocol, already investigated in [1], we show that this
protocol, through the cooperation degree between each transmitter and the
relay, is the only one that naturally introduces a game between the
transmitters. For the estimate-and-forward protocol, we derive two rate regions
for the general case of discrete interference relay channels (IRCs) and
specialize these results to obtain the Gaussian case; these regions correspond
to two compression schemes at the relay, having different resolution levels.
These schemes are compared analytically in some special cases. All the results
mentioned are illustrated by simulations, given in this part, and exploited to
study power allocation games in multi-band IRCs in the second part of this
two-part paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2587</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2587</id><created>2009-04-16</created><updated>2010-11-20</updated><authors><author><keyname>Belmega</keyname><forenames>Elena Veronica</forenames></author><author><keyname>Djeumou</keyname><forenames>Brice</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author></authors><title>Interference Relay Channels - Part II: Power Allocation Games</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the first part of this paper we have derived achievable transmission rates
for the (single-band) interference relay channel (IRC) when the relay
implements either the amplify-and-forward, decode-and-forward or
estimate-and-forward protocol. Here, we consider wireless networks that can be
modeled by a multi-band IRC. We tackle the existence issue of Nash equilibria
(NE) in these networks where each information source is assumed to selfishly
allocate its power between the available bands in order to maximize its
individual transmission rate. Interestingly, it is possible to show that the
three power allocation (PA) games (corresponding to the three protocols
assumed) under investigation are concave, which guarantees the existence of a
pure NE after Rosen [3]. Then, as the relay can also optimize several
parameters e.g., its position and transmit power, it is further considered as
the leader of a Stackelberg game where the information sources are the
followers. Our theoretical analysis is illustrated by simulations giving more
insights on the addressed issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2595</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2595</id><created>2009-04-16</created><authors><author><keyname>Levene</keyname><forenames>Mark</forenames></author><author><keyname>Fenner</keyname><forenames>Trevor</forenames></author></authors><title>A Methodology for Learning Players' Styles from Game Records</title><categories>cs.AI cs.LG</categories><comments>15 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a preliminary investigation into learning a Chess player's style
from game records. The method is based on attempting to learn features of a
player's individual evaluation function using the method of temporal
differences, with the aid of a conventional Chess engine architecture. Some
encouraging results were obtained in learning the styles of two recent Chess
world champions, and we report on our attempt to use the learnt styles to
discriminate between the players from game records by trying to detect who was
playing white and who was playing black. We also discuss some limitations of
our approach and propose possible directions for future research. The method we
have presented may also be applicable to other strategic games, and may even be
generalisable to other domains where sequences of agents' actions are recorded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2623</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2623</id><created>2009-04-16</created><updated>2009-06-04</updated><authors><author><keyname>Petterson</keyname><forenames>James</forenames></author><author><keyname>Caetano</keyname><forenames>Tiberio</forenames></author><author><keyname>McAuley</keyname><forenames>Julian</forenames></author><author><keyname>Yu</keyname><forenames>Jin</forenames></author></authors><title>Exponential Family Graph Matching and Ranking</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for learning max-weight matching predictors in bipartite
graphs. The method consists of performing maximum a posteriori estimation in
exponential families with sufficient statistics that encode permutations and
data features. Although inference is in general hard, we show that for one very
relevant application - web page ranking - exact inference is efficient. For
general model instances, an appropriate sampler is readily available. Contrary
to existing max-margin matching models, our approach is statistically
consistent and, in addition, experiments with increasing sample sizes indicate
superior improvement over such models. We apply the method to graph matching in
computer vision as well as to a standard benchmark dataset for learning web
page ranking, in which we obtain state-of-the-art results, in particular
improving on max-margin variants. The drawback of this method with respect to
max-margin alternatives is its runtime for large graphs, which is comparatively
high.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2638</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2638</id><created>2009-04-17</created><updated>2013-05-28</updated><authors><author><keyname>Bloem</keyname><forenames>Roderick</forenames></author><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author><author><keyname>Jobstmann</keyname><forenames>Barbara</forenames></author></authors><title>Better Quality in Synthesis through Quantitative Objectives</title><categories>cs.LO cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most specification languages express only qualitative constraints.
  However, among two implementations that satisfy a given specification, one
may be preferred to another. For example, if a specification asks that every
request is followed by a response, one may prefer an implementation that
generates responses quickly but does not generate unnecessary responses. We use
quantitative properties to measure the &quot;goodness&quot; of an implementation. Using
games with corresponding quantitative objectives, we can synthesize &quot;optimal&quot;
implementations, which are preferred among the set of possible implementations
that satisfy a given specification. In particular, we show how automata with
lexicographic mean-payoff conditions can be used to express many interesting
quantitative properties for reactive systems. In this framework, the synthesis
of optimal implementations requires the solution of lexicographic mean-payoff
games (for safety requirements), and the solution of games with both
lexicographic mean-payoff and parity objectives (for liveness requirements). We
present algorithms for solving both kinds of novel graph games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2658</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2658</id><created>2009-04-17</created><authors><author><keyname>Daligault</keyname><forenames>Jean</forenames></author><author><keyname>Thomasse</keyname><forenames>Stephan</forenames></author></authors><title>On Finding Directed Trees with Many Leaves</title><categories>cs.DM</categories><comments>Submitted to ESA 09, 13 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Rooted Maximum Leaf Outbranching problem consists in finding a spanning
directed tree rooted at some prescribed vertex of a digraph with the maximum
number of leaves. Its parameterized version asks if there exists such a tree
with at least $k$ leaves. We use the notion of $s-t$ numbering to exhibit
combinatorial bounds on the existence of spanning directed trees with many
leaves. These combinatorial bounds allow us to produce a constant factor
approximation algorithm for finding directed trees with many leaves, whereas
the best known approximation algorithm has a $\sqrt{OPT}$-factor. We also show
that Rooted Maximum Leaf Outbranching admits a quadratic kernel, improving over
the cubic kernel given by Fernau et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2675</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2675</id><created>2009-04-17</created><updated>2010-12-23</updated><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames><affiliation>Universit&#xe0; di Bologna</affiliation></author><author><keyname>Hofmann</keyname><forenames>Martin</forenames><affiliation>LMU, Munchen</affiliation></author></authors><title>Bounded Linear Logic, Revisited</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 6, Issue 4 (December
  18, 2010) lmcs:1064</journal-ref><doi>10.2168/LMCS-6(4:7)2010</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present QBAL, an extension of Girard, Scedrov and Scott's bounded linear
logic. The main novelty of the system is the possibility of quantifying over
resource variables. This generalization makes bounded linear logic considerably
more flexible, while preserving soundness and completeness for polynomial time.
In particular, we provide compositional embeddings of Leivant's RRW and
Hofmann's LFPL into QBAL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2695</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2695</id><created>2009-04-17</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Zhang</keyname><forenames>Wenji</forenames></author><author><keyname>Li</keyname><forenames>Fang</forenames></author></authors><title>Compressive Diffraction Tomography for Weakly Scattering</title><categories>cs.CE cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  An appealing requirement from the well-known diffraction tomography (DT)
exists for success reconstruction from few-view and limited-angle data.
Inspired by the well-known compressive sensing (CS), the accurate
super-resolution reconstruction from highly sparse data for the weakly scatters
has been investigated in this paper. To realize the compressive data
measurement, in particular, to obtain the super-resolution reconstruction with
highly sparse data, the compressive system which is realized by surrounding the
probed obstacles by the random media has been proposed and empirically studied.
Several interesting conclusions have been drawn: (a) if the desired resolution
is within the range from to, the K-sparse N-unknowns imaging can be obtained
exactly bymeasurements, which is comparable to the required number of
measurement by the Gaussian random matrix in the literatures of compressive
sensing. (b) With incorporating the random media which is used to enforce the
multi-path effect of wave propagation, the resulting measurement matrix is
incoherence with wavelet matrix, in other words, when the probed obstacles are
sparse with the framework of wavelet, the required number of measurements for
successful reconstruction is similar as above. (c) If the expected resolution
is lower than, the required number of measurements of proposed compressive
system is almost identical to the case of free space. (d) There is also a
requirement to make the tradeoff between the imaging resolutions and the number
of measurements. In addition, by the introduction of complex Gaussian variable
the kind of fast sparse Bayesian algorithm has been slightly modified to deal
with the complex-valued optimization with sparse constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2712</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2712</id><created>2009-04-17</created><authors><author><keyname>Xiao</keyname><forenames>Mingyu</forenames></author></authors><title>New Branching Rules: Improvements on Independent Set and Vertex Cover in
  Sparse Graphs</title><categories>cs.DS cs.DM</categories><comments>The paper was presented at the 2nd annual meeting of asian
  association for algorithms and computation (AAAC 2009), April 11-12, 2009,
  Hangzhou, China</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an $O^*(1.0919^n)$-time algorithm for finding a maximum
independent set in an $n$-vertex graph with degree bounded by 3, which improves
the previously known algorithm of running time $O^*(1.0977^n)$ by Bourgeois,
Escoffier and Paschos [IWPEC 2008]. We also present an $O^*(1.1923^k)$-time
algorithm to decide if a graph with degree bounded by 3 has a vertex cover of
size $k$, which improves the previously known algorithm of running time
$O^*(1.1939^k)$ by Chen, Kanj and Xia [ISAAC 2003].
  Two new branching techniques, \emph{branching on a bottle} and
\emph{branching on a 4-cycle}, are introduced, which help us to design simple
and fast algorithms for the maximum independent set and minimum vertex cover
problems and avoid tedious branching rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2716</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2716</id><created>2009-04-17</created><authors><author><keyname>Magnien</keyname><forenames>Clemence</forenames><affiliation>LIP6</affiliation></author><author><keyname>Ouedraogo</keyname><forenames>Frederic</forenames><affiliation>LIP6</affiliation><affiliation>LTIC</affiliation></author><author><keyname>Valadon</keyname><forenames>Guillaume</forenames><affiliation>LIP6</affiliation></author><author><keyname>Latapy</keyname><forenames>Matthieu</forenames><affiliation>LIP6</affiliation></author></authors><title>Fast dynamics in Internet topology: preliminary observations and
  explanations</title><categories>cs.NI</categories><comments>Fourth International Conference on Internet Monitoring and Protection
  (ICIMP 2009), May 24-28, 2009, Venice, Italy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  By focusing on what can be observed by running traceroute-like measurements
at a high frequency from a single monitor to a fixed destination set, we show
that the observed view of the topology is constantly evolving at a pace much
higher than expected. Repeated measurements discover new IP addresses at a
constant rate, for long period of times (up to several months). In order to
provide explanations, we study this phenomenon both at the IP, and at the
Autonomous System levels. We show that this renewal of IP addresses is
partially caused by a BGP routing dynamics, altering paths between existing
ASes. Furthermore, we conjecture that an intra AS routing dynamics is another
cause of this phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2722</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2722</id><created>2009-04-17</created><authors><author><keyname>Kim</keyname><forenames>MinJi</forenames></author><author><keyname>Lima</keyname><forenames>Lu&#xed;sa</forenames></author><author><keyname>Zhao</keyname><forenames>Fang</forenames></author><author><keyname>Barros</keyname><forenames>Joao</forenames></author><author><keyname>Medard</keyname><forenames>Muriel</forenames></author><author><keyname>Koetter</keyname><forenames>Ralf</forenames></author><author><keyname>Kalker</keyname><forenames>Ton</forenames></author><author><keyname>Han</keyname><forenames>Keesook</forenames></author></authors><title>On Counteracting Byzantine Attacks in Network Coded Peer-to-Peer
  Networks</title><categories>cs.NI cs.CR</categories><comments>26 pages, 9 figures, Submitted to IEEE Journal on Selected Areas in
  Communications (JSAC) &quot;Mission Critical Networking&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random linear network coding can be used in peer-to-peer networks to increase
the efficiency of content distribution and distributed storage. However, these
systems are particularly susceptible to Byzantine attacks. We quantify the
impact of Byzantine attacks on the coded system by evaluating the probability
that a receiver node fails to correctly recover a file. We show that even for a
small probability of attack, the system fails with overwhelming probability. We
then propose a novel signature scheme that allows packet-level Byzantine
detection. This scheme allows one-hop containment of the contamination, and
saves bandwidth by allowing nodes to detect and drop the contaminated packets.
We compare the net cost of our signature scheme with various other Byzantine
schemes, and show that when the probability of Byzantine attacks is high, our
scheme is the most bandwidth efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2728</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2728</id><created>2009-04-17</created><authors><author><keyname>Magnien</keyname><forenames>Clemence</forenames><affiliation>LIP6</affiliation></author><author><keyname>Latapy</keyname><forenames>Matthieu</forenames><affiliation>LIP6</affiliation></author><author><keyname>Habib</keyname><forenames>Michel</forenames><affiliation>LIAFA</affiliation></author></authors><title>Fast Computation of Empirically Tight Bounds for the Diameter of Massive
  Graphs</title><categories>cs.DS</categories><comments>ACM Journal of Experimental Algorithmics (JEA), 13, 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The diameter of a graph is among its most basic parameters. Since a few
years, it moreover became a key issue to compute it for massive graphs in the
context of complex network analysis. However, known algorithms, including the
ones producing approximate values, have too high a time and/or space complexity
to be used in such cases. We propose here a new approach relying on very simple
and fast algorithms that compute (upper and lower) bounds for the diameter. We
show empirically that, on various real-world cases representative of complex
networks studied in the literature, the obtained bounds are very tight (and
even equal in some cases). This leads to rigorous and very accurate estimations
of the actual diameter in cases which were previously untractable in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2733</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2733</id><created>2009-04-17</created><authors><author><keyname>Viger</keyname><forenames>Fabien</forenames><affiliation>LIP6</affiliation></author><author><keyname>Augustin</keyname><forenames>Brice</forenames><affiliation>LIP6</affiliation></author><author><keyname>Cuvellier</keyname><forenames>Xavier</forenames><affiliation>LIP6</affiliation></author><author><keyname>Magnien</keyname><forenames>Clemence</forenames><affiliation>LIP6</affiliation></author><author><keyname>Latapy</keyname><forenames>Matthieu</forenames><affiliation>LIP6</affiliation></author><author><keyname>Friedman</keyname><forenames>Timur</forenames><affiliation>LIP6</affiliation></author><author><keyname>Teixeira</keyname><forenames>Renata</forenames><affiliation>LIP6</affiliation></author></authors><title>Detection, Understanding, and Prevention of Traceroute Measurement
  Artifacts</title><categories>cs.NI</categories><comments>Computer Networks 52-5 (2008), pp. 998-1018. Extended abstract
  published in the proceedings of the 6-th Internet Measurement Conference
  IMC'06, 2006, Rio de Janeiro, Brazil</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traceroute is widely used: from the diagnosis of network problems to the
assemblage of internet maps. Unfortu- nately, there are a number of problems
with traceroute methodology, which lead to the inference of erroneous routes.
This paper studies particular structures arising in nearly all traceroute
measurements. We characterize them as &quot;loops&quot;, &quot;cycles&quot;, and &quot;diamonds&quot;. We
iden- tify load balancing as a possible cause for the appear- ance of false
loops, cycles and diamonds, i.e., artifacts that do not represent the internet
topology. We pro- vide a new publicly-available traceroute, called Paris
traceroute, which, by controlling the packet header con- tents, provides a
truer picture of the actual routes that packets follow. We performed
measurements, from the perspective of a single source tracing towards multiple
destinations, and Paris traceroute allowed us to show that many of the
particular structures we observe are indeed traceroute measurement artifacts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2751</identifier>
 <datestamp>2009-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2751</id><created>2009-04-17</created><authors><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Restrepo</keyname><forenames>Ricardo</forenames></author><author><keyname>Tetali</keyname><forenames>Prasad</forenames></author></authors><title>Reconstruction and Clustering in Random Constraint Satisfaction Problems</title><categories>cs.DM</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random instances of Constraint Satisfaction Problems (CSP's) appear to be
hard for all known algorithms, when the number of constraints per variable lies
in a certain interval. Contributing to the general understanding of the
structure of the solution space of a CSP in the satisfiable regime, we
formulate a set of natural technical conditions on a large family of (random)
CSP's, and prove bounds on three most interesting thresholds for the density of
such an ensemble: namely, the satisfiability threshold, the threshold for
clustering of the solution space, and the threshold for an appropriate
reconstruction problem on the CSP's. The bounds become asymptoticlally tight as
the number of degrees of freedom in each clause diverges. The families are
general enough to include commonly studied problems such as, random instances
of Not-All-Equal-SAT, k-XOR formulae, hypergraph 2-coloring, and graph
k-coloring. An important new ingredient is a condition involving the Fourier
expansion of clauses, which characterizes the class of problems with a similar
threshold structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2759</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2759</id><created>2009-04-17</created><authors><author><keyname>Reichardt</keyname><forenames>Ben W.</forenames></author></authors><title>Span programs and quantum query complexity: The general adversary bound
  is nearly tight for every boolean function</title><categories>quant-ph cs.CC</categories><comments>70 pages, 2 figures</comments><journal-ref>Extended abstract in Proc. 50th IEEE Symp. on Foundations of
  Computer Science (FOCS), 2009, pages 544-551</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The general adversary bound is a semi-definite program (SDP) that
lower-bounds the quantum query complexity of a function. We turn this lower
bound into an upper bound, by giving a quantum walk algorithm based on the dual
SDP that has query complexity at most the general adversary bound, up to a
logarithmic factor.
  In more detail, the proof has two steps, each based on &quot;span programs,&quot; a
certain linear-algebraic model of computation. First, we give an SDP that
outputs for any boolean function a span program computing it that has optimal
&quot;witness size.&quot; The optimal witness size is shown to coincide with the general
adversary lower bound. Second, we give a quantum algorithm for evaluating span
programs with only a logarithmic query overhead on the witness size.
  The first result is motivated by a quantum algorithm for evaluating composed
span programs. The algorithm is known to be optimal for evaluating a large
class of formulas. The allowed gates include all constant-size functions for
which there is an optimal span program. So far, good span programs have been
found in an ad hoc manner, and the SDP automates this procedure. Surprisingly,
the SDP's value equals the general adversary bound. A corollary is an optimal
quantum algorithm for evaluating &quot;balanced&quot; formulas over any finite boolean
gate set. The second result extends span programs' applicability beyond the
formula evaluation problem.
  A strong universality result for span programs follows. A good quantum query
algorithm for a problem implies a good span program, and vice versa. Although
nearly tight, this equivalence is nontrivial. Span programs are a promising
model for developing more quantum algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2761</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2761</id><created>2009-04-17</created><authors><author><keyname>Chyzak</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Kauers</keyname><forenames>Manuel</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>A Non-Holonomic Systems Approach to Special Function Identities</title><categories>cs.SC</categories><proxy>ccsd inria-00376526</proxy><doi>10.1145/1576702.1576720</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend Zeilberger's approach to special function identities to cases that
are not holonomic. The method of creative telescoping is thus applied to
definite sums or integrals involving Stirling or Bernoulli numbers, incomplete
Gamma function or polylogarithms, which are not covered by the holonomic
framework. The basic idea is to take into account the dimension of appropriate
ideals in Ore algebras. This unifies several earlier extensions and provides
algorithms for summation and integration in classes that had not been
accessible to computer algebra before.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2769</identifier>
 <datestamp>2009-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2769</id><created>2009-04-17</created><updated>2009-05-10</updated><authors><author><keyname>Awasthi</keyname><forenames>Amit K</forenames></author><author><keyname>Chaudhary</keyname><forenames>Sanjay</forenames></author></authors><title>Non Homogeneous Poisson Process Model based Optimal Modular Software
  Testing using Fault Tolerance</title><categories>cs.SE</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In software development process we come across various modules. Which raise
the idea of priority of the different modules of a software so that important
modules are tested on preference. This approach is desirable because it is not
possible to test each module regressively due to time and cost constraints.
This paper discuss on some parameters, required to prioritize several modules
of a software and provides measure of optimal time and cost for testing based
on non homogeneous Poisson process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2785</identifier>
 <datestamp>2009-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2785</id><created>2009-04-17</created><authors><author><keyname>Kral</keyname><forenames>Daniel</forenames></author></authors><title>Decomposition width - a new width parameter for matroids</title><categories>cs.DM cs.DS</categories><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new width parameter for matroids called decomposition width
and prove that every matroid property expressible in the monadic second order
logic can be computed in linear time for matroids with bounded decomposition
width if their decomposition is given. Since decompositions of small width for
our new notion can be computed in polynomial time for matroids of bounded
branch-width represented over finite fields, our results include recent
algorithmic results of Hlineny [J. Combin. Theory Ser. B 96 (2006), 325-351] in
this area and extend his results to matroids not necessarily representable over
finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2827</identifier>
 <datestamp>2011-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2827</id><created>2009-04-18</created><updated>2011-10-13</updated><authors><author><keyname>Vishnevksaya</keyname><forenames>Elena S.</forenames></author></authors><title>Principle of development</title><categories>cs.AI</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, science have a powerful tool for the description of reality - the
numbers. However, the concept of number was not immediately, lets try to trace
the evolution of the concept. The numbers emerged as the need for accurate
estimates of the amount in order to permit a comparison of some objects. So if
you see to it how many times a day a person uses the numbers and compare, it
becomes evident that the comparison is used much more frequently. However, the
comparison is not possible without two opposite basic standards. Thus, to
introduce the concept of comparison, must have two opposing standards, in turn,
the operation of comparison is necessary to introduce the concept of number.
Arguably, the scientific description of reality is impossible without the
concept of opposites.
  In this paper analyzes the concept of opposites, as the basis for the
introduction of the principle of development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2861</identifier>
 <datestamp>2009-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2861</id><created>2009-04-18</created><authors><author><keyname>Fedorenko</keyname><forenames>Sergei V.</forenames></author></authors><title>A simple algorithm for decoding both errors and erasures of Reed-Solomon
  codes</title><categories>cs.IT math.IT</categories><comments>Comments: 6 pages. Proceedings of the Workshop &quot;Coding Theory Days in
  St. Petersburg&quot;, Russia, October 2008. pp.18-21</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A simple algorithm for decoding both errors and erasures of Reed-Solomon
codes is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2863</identifier>
 <datestamp>2009-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2863</id><created>2009-04-18</created><authors><author><keyname>Barooah</keyname><forenames>Prabir</forenames></author><author><keyname>Hespanha</keyname><forenames>Joao P.</forenames></author></authors><title>Error Scaling Laws for Linear Optimal Estimation from Relative
  Measurements</title><categories>cs.IT math.IT</categories><comments>15 pages, submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of estimating vector-valued variables from noisy
&quot;relative&quot; measurements. This problem arises in several sensor network
applications. The measurement model can be expressed in terms of a graph, whose
nodes correspond to the variables and edges to noisy measurements of the
difference between two variables. We take an arbitrary variable as the
reference and consider the optimal (minimum variance) linear unbiased estimate
of the remaining variables.
  We investigate how the error in the optimal linear unbiased estimate of a
node variable grows with the distance of the node to the reference node. We
establish a classification of graphs, namely, dense or sparse in Rd,1&lt;= d &lt;=3,
that determines how the linear unbiased optimal estimation error of a node
grows with its distance from the reference node. In particular, if a graph is
dense in 1,2, or 3D, then a node variable's estimation error is upper bounded
by a linear, logarithmic, or bounded function of distance from the reference,
respectively. Corresponding lower bounds are obtained if the graph is sparse in
1, 2 and 3D.
  Our results also show that naive measures of graph density, such as node
degree, are inadequate predictors of the estimation error. Being true for the
optimal linear unbiased estimate, these scaling laws determine
algorithm-independent limits on the estimation accuracy achievable in large
graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2894</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2894</id><created>2009-04-19</created><authors><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Weil</keyname><forenames>Pascal</forenames><affiliation>LaBRI</affiliation></author></authors><title>On FO2 quantifier alternation over words</title><categories>cs.LO</categories><proxy>ccsd hal-00376640</proxy><journal-ref>Mathematical Foundations of Computer Science 2009, slovaque,
  R\'epublique (2009)</journal-ref><doi>10.1007/978-3-642-03816-7_44</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that each level of the quantifier alternation hierarchy within
FO^2[&lt;] -- the 2-variable fragment of the first order logic of order on words
-- is a variety of languages. We then use the notion of condensed rankers, a
refinement of the rankers defined by Weis and Immerman, to produce a decidable
hierarchy of varieties which is interwoven with the quantifier alternation
hierarchy -- and conjecturally equal to it. It follows that the latter
hierarchy is decidable within one unit: given a formula alpha in FO^2[&lt;], one
can effectively compute an integer m such that alpha is equivalent to a formula
with at most m+1 alternating blocks of quantifiers, but not to a formula with
only m-1 blocks. This is a much more precise result than what is known about
the quantifier alternation hierarchy within FO[&lt;], where no decidability result
is known beyond the very first levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2921</identifier>
 <datestamp>2009-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2921</id><created>2009-04-19</created><authors><author><keyname>Mohsenian-Rad</keyname><forenames>Amir-Hamed</forenames></author><author><keyname>Huang</keyname><forenames>Jianwei</forenames></author><author><keyname>Wong</keyname><forenames>Vincent W. S.</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Inter-Session Network Coding with Strategic Users: A Game-Theoretic
  Analysis of Network Coding</title><categories>cs.IT math.IT</categories><comments>50 pages. To be presented at ICC 2009. Submitted to IEEE Transactions
  on IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A common assumption in the existing network coding literature is that the
users are cooperative and non-selfish. However, this assumption can be violated
in practice. In this paper, we analyze inter-session network coding in a wired
network using game theory. We assume selfish users acting strategically to
maximize their own utility, leading to a resource allocation game among users.
In particular, we study the well-known butterfly network topology where a
bottleneck link is shared by several network coding and routing flows. We prove
the existence of a Nash equilibrium for a wide range of utility functions. We
show that the number of Nash equilibria can be large (even infinite) for
certain choices of system parameters. This is in sharp contrast to a similar
game setting with traditional packet forwarding where the Nash equilibrium is
always unique. We then characterize the worst-case efficiency bounds, i.e., the
Price-of-Anarchy (PoA), compared to an optimal and cooperative network design.
We show that by using a novel discriminatory pricing scheme which charges
encoded and forwarded packets differently, we can improve the PoA. However,
regardless of the discriminatory pricing scheme being used, the PoA is still
worse than for the case when network coding is not applied. This implies that,
although inter-session network coding can improve performance compared to
ordinary routing, it is significantly more sensitive to users' strategic
behaviour. For example, in a butterfly network where the side links have zero
cost, the efficiency can be as low as 25%. If the side links have non-zero
cost, then the efficiency can further reduce to only 20%. These results
generalize the well-known result of guaranteed 67% worst-case efficiency for
traditional packet forwarding networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2953</identifier>
 <datestamp>2009-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2953</id><created>2009-04-20</created><authors><author><keyname>Kebair</keyname><forenames>Fahem</forenames></author><author><keyname>Serin</keyname><forenames>Frederic</forenames></author></authors><title>Towards an Intelligent System for Risk Prevention and Management</title><categories>cs.AI cs.MA</categories><comments>11 pages</comments><journal-ref>Proceedings of the 5th International ISCRAM Conference. 526-535,
  Washington, DC, USA May 2008</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Making a decision in a changeable and dynamic environment is an arduous task
owing to the lack of information, their uncertainties and the unawareness of
planners about the future evolution of incidents. The use of a decision support
system is an efficient solution of this issue. Such a system can help emergency
planners and responders to detect possible emergencies, as well as to suggest
and evaluate possible courses of action to deal with the emergency. We are
interested in our work to the modeling of a monitoring preventive and emergency
management system, wherein we stress the generic aspect. In this paper we
propose an agent-based architecture of this system and we describe a first step
of our approach which is the modeling of information and their representation
using a multiagent system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2954</identifier>
 <datestamp>2009-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2954</id><created>2009-04-20</created><authors><author><keyname>Kebair</keyname><forenames>Fahem</forenames></author><author><keyname>Serin</keyname><forenames>Frederic</forenames></author></authors><title>Agent-Based Decision Support System to Prevent and Manage Risk
  Situations</title><categories>cs.AI cs.MA</categories><comments>5 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The topic of risk prevention and emergency response has become a key social
and political concern. One approach to address this challenge is to develop
Decision Support Systems (DSS) that can help emergency planners and responders
to detect emergencies, as well as to suggest possible course of actions to deal
with the emergency. Our research work comes in this framework and aims to
develop a DSS that must be generic as much as possible and independent from the
case study.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.2955</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.2955</id><created>2009-04-20</created><updated>2009-04-27</updated><authors><author><keyname>David</keyname><forenames>Ren&#xe9;</forenames><affiliation>LAMA</affiliation></author></authors><title>A short proof that adding some permutation rules to beta preserves SN</title><categories>math.LO cs.LO</categories><proxy>ccsd hal-00376711</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I show that, if a term is $SN$ for $\beta$, it remains $SN$ when some
permutation rules are added.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3036</identifier>
 <datestamp>2015-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3036</id><created>2009-04-20</created><updated>2015-03-02</updated><authors><author><keyname>Hewitt</keyname><forenames>Carl</forenames></author></authors><title>Inconsistency Robustness in Logic Programs</title><categories>cs.LO</categories><comments>Limits of Classical Logic</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inconsistency robustness is &quot;information system performance in the face of
continually pervasive inconsistencies.&quot; A fundamental principle of
Inconsistency Robustness is to make contradictions explicit so that arguments
for and against propositions can be formalized. This paper explores the role of
Inconsistency Robustness in the history and theory of Logic Programs.
  Robert Kowalski put forward a bold thesis: &quot;Looking back on our early
discoveries, I value most the discovery that computation could be subsumed by
deduction.&quot; However, mathematical logic cannot always infer computational steps
because computational systems make use of arbitration for determining which
message is processed next by a recipient that is sent multiple messages
concurrently. Since reception orders are in general indeterminate, they cannot
be inferred from prior information by mathematical logic alone. Therefore
mathematical logic cannot in general implement computation.
  Over the course of history, the term &quot;Functional Program&quot; has grown more
precise and technical as the field has matured. &quot;Logic Program&quot; should be on a
similar trajectory. Accordingly, &quot;Logic Program&quot; should have a general precise
characterization. In the fall of 1972, different characterizations of Logic
Programs that have continued to this day:
  * A Logic Program uses Horn-Clause syntax for forward and backward chaining
  * Each computational step (according to Actor Model) of a Logic Program is
deductively inferred (e.g. in Direct Logic).
  The above examples are illustrative of how issues of inconsistency robustness
have repeatedly arisen in Logic Programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3060</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3060</id><created>2009-04-20</created><authors><author><keyname>Hu</keyname><forenames>Heping</forenames></author><author><keyname>Zhang</keyname><forenames>Yingyu</forenames></author><author><keyname>Lu</keyname><forenames>Zhengding</forenames></author></authors><title>An efficient quantum search engine on unsorted database</title><categories>cs.DB cs.DS</categories><comments>7 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding one or more desired items out of an
unsorted database. Patel has shown that if the database permits quantum
queries, then mere digitization is sufficient for efficient search for one
desired item. The algorithm, called factorized quantum search algorithm,
presented by him can locate the desired item in an unsorted database using
$O(log_{4}N)$ queries to factorized oracles. But the algorithm requires that
all the property values must be distinct from each other. In this paper, we
discuss how to make a database satisfy the requirements, and present a quantum
search engine based on the algorithm. Our goal is achieved by introducing
auxiliary files for the property values that are not distinct, and converting
every complex query request into a sequence of calls to factorized quantum
search algorithm. The query complexity of our algorithm is $O(P*Q*M*log_{4}N)$,
where P is the number of the potential simple query requests in the complex
query request, Q is the maximum number of calls to the factorized quantum
search algorithm of the simple queries, M is the number of the auxiliary files
for the property on which our algorithm are searching for desired items. This
implies that to manage an unsorted database on an actual quantum computer is
possible and efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3062</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3062</id><created>2009-04-20</created><updated>2009-08-24</updated><authors><author><keyname>Csuros</keyname><forenames>Miklos</forenames></author></authors><title>Approximate counting with a floating-point counter</title><categories>cs.DS</categories><comments>Updated content (fixed errors in the previous version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memory becomes a limiting factor in contemporary applications, such as
analyses of the Webgraph and molecular sequences, when many objects need to be
counted simultaneously. Robert Morris [Communications of the ACM, 21:840--842,
1978] proposed a probabilistic technique for approximate counting that is
extremely space-efficient. The basic idea is to increment a counter containing
the value $X$ with probability $2^{-X}$. As a result, the counter contains an
approximation of $\lg n$ after $n$ probabilistic updates stored in $\lg\lg n$
bits. Here we revisit the original idea of Morris, and introduce a binary
floating-point counter that uses a $d$-bit significand in conjunction with a
binary exponent. The counter yields a simple formula for an unbiased estimation
of $n$ with a standard deviation of about $0.6\cdot n2^{-d/2}$, and uses
$d+\lg\lg n$ bits.
  We analyze the floating-point counter's performance in a general framework
that applies to any probabilistic counter, and derive practical formulas to
assess its accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3063</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3063</id><created>2009-04-20</created><authors><author><keyname>Fernandes</keyname><forenames>C. M.</forenames></author><author><keyname>Merelo</keyname><forenames>J. J.</forenames></author><author><keyname>Rosa</keyname><forenames>A. C.</forenames></author></authors><title>Using Dissortative Mating Genetic Algorithms to Track the Extrema of
  Dynamic Deceptive Functions</title><categories>cs.NE</categories><comments>Technical report complementing Carlos Fernandes' PhD</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Traditional Genetic Algorithms (GAs) mating schemes select individuals for
crossover independently of their genotypic or phenotypic similarities. In
Nature, this behaviour is known as random mating. However, non-random schemes -
in which individuals mate according to their kinship or likeness - are more
common in natural systems. Previous studies indicate that, when applied to GAs,
negative assortative mating (a specific type of non-random mating, also known
as dissortative mating) may improve their performance (on both speed and
reliability) in a wide range of problems. Dissortative mating maintains the
genetic diversity at a higher level during the run, and that fact is frequently
observed as an explanation for dissortative GAs ability to escape local optima
traps. Dynamic problems, due to their specificities, demand special care when
tuning a GA, because diversity plays an even more crucial role than it does
when tackling static ones. This paper investigates the behaviour of
dissortative mating GAs, namely the recently proposed Adaptive Dissortative
Mating GA (ADMGA), on dynamic trap functions. ADMGA selects parents according
to their Hamming distance, via a self-adjustable threshold value. The method,
by keeping population diversity during the run, provides an effective means to
deal with dynamic problems. Tests conducted with deceptive and nearly deceptive
trap functions indicate that ADMGA is able to outperform other GAs, some
specifically designed for tracking moving extrema, on a wide range of tests,
being particularly effective when speed of change is not very fast. When
comparing the algorithm to a previously proposed dissortative GA, results show
that performance is equivalent on the majority of the experiments, but ADMGA
performs better when solving the hardest instances of the test set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3074</identifier>
 <datestamp>2009-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3074</id><created>2009-04-20</created><authors><author><keyname>Popov</keyname><forenames>Michael A.</forenames></author></authors><title>P vs NP Problem in the field anthropology</title><categories>cs.OH</categories><acm-class>K.4.3</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  An attempt of a new kind of complexity anthropology is considered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3087</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3087</id><created>2009-04-20</created><updated>2013-07-22</updated><authors><author><keyname>Casteigts</keyname><forenames>Arnaud</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Chaumette</keyname><forenames>Serge</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Guinand</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LITIS</affiliation></author><author><keyname>Pign&#xe9;</keyname><forenames>Yoann</forenames><affiliation>LITIS</affiliation></author></authors><title>Distributed Maintenance of Anytime Available Spanning Trees in Dynamic
  Networks</title><categories>cs.DC cs.NI</categories><comments>Distributed Maintenance of Anytime Available Spanning Trees in
  Dynamic Networks, Poland (2013)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the problem of building and maintaining distributed spanning trees
in highly dynamic networks, in which topological events can occur at any time
and any rate, and no stable periods can be assumed. In these harsh
environments, we strive to preserve some properties such as cycle-freeness or
the existence of a root in each tree, in order to make it possible to keep
using the trees uninterruptedly (to a possible extent). Our algorithm operates
at a coarse-grain level, using atomic pairwise interactions in a way akin to
recent population protocol models. The algorithm relies on a perpetual
alternation of \emph{topology-induced splittings} and \emph{computation-induced
mergings} of a forest of spanning trees. Each tree in the forest hosts exactly
one token (also called root) that performs a random walk {\em inside} the tree,
switching parent-child relationships as it crosses edges. When two tokens are
located on both sides of a same edge, their trees are merged upon this edge and
one token disappears. Whenever an edge that belongs to a tree disappears, its
child endpoint regenerates a new token instantly. The main features of this
approach is that both \emph{merging} and \emph{splitting} are purely localized
phenomenons. In this paper, we present and motivate the algorithm, and we prove
its correctness in arbitrary dynamic networks. Then we discuss several
implementation choices around this general principle. Preliminary results
regarding its analysis are also discussed, in particular an analytical
expression of the expected merging time for two given trees in a static
context.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3093</identifier>
 <datestamp>2009-04-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3093</id><created>2009-04-20</created><authors><author><keyname>Bj&#xf6;rklund</keyname><forenames>Andreas</forenames></author><author><keyname>Husfeldt</keyname><forenames>Thore</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author></authors><title>Counting Paths and Packings in Halves</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that one can count $k$-edge paths in an $n$-vertex graph and
$m$-set $k$-packings on an $n$-element universe, respectively, in time ${n
\choose k/2}$ and ${n \choose mk/2}$, up to a factor polynomial in $n$, $k$,
and $m$; in polynomial space, the bounds hold if multiplied by $3^{k/2}$ or
$5^{mk/2}$, respectively. These are implications of a more general result:
given two set families on an $n$-element universe, one can count the disjoint
pairs of sets in the Cartesian product of the two families with $\nO(n \ell)$
basic operations, where $\ell$ is the number of members in the two families and
their subsets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3116</identifier>
 <datestamp>2011-03-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3116</id><created>2009-04-20</created><updated>2011-03-18</updated><authors><author><keyname>Musatov</keyname><forenames>Daniil</forenames></author><author><keyname>Romashchenko</keyname><forenames>Andrei</forenames></author><author><keyname>Shen</keyname><forenames>Alexander</forenames></author></authors><title>Variations on Muchnik's Conditional Complexity Theorem</title><categories>cs.CC</categories><comments>24 pages, 1 figure, presented at CSR2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Muchnik's theorem about simple conditional descriptions states that for all
strings $a$ and $b$ there exists a short program $p$ transforming $a$ to $b$
that has the least possible length and is simple conditional on $b$. In this
paper we present two new proofs of this theorem. The first one is based on the
on-line matching algorithm for bipartite graphs. The second one, based on
extractors, can be generalized to prove a version of Muchnik's theorem for
space-bounded Kolmogorov complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3148</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3148</id><created>2009-04-20</created><authors><author><keyname>Chen</keyname><forenames>Hao</forenames></author></authors><title>CRT-Based High Speed Parallel Architecture for Long BCH Encoding</title><categories>cs.AR cs.IT math.IT</categories><comments>3 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BCH (Bose-Chaudhuri-Hocquenghen) error correcting codes ([1]-[2]) are now
widely used in communication systems and digital technology. Direct LFSR(linear
feedback shifted register)-based encoding of a long BCH code suffers from
serial-in and serial-out limitation and large fanout effect of some XOR gates.
This makes the LFSR-based encoders of long BCH codes cannot keep up with the
data transmission speed in some applications. Several parallel long parallel
encoders for long cyclic codes have been proposed in [3]-[8]. The technique for
eliminating the large fanout effect by J-unfolding method and some algebraic
manipulation was presented in [7] and [8] . In this paper we propose a
CRT(Chinese Remainder Theorem)-based parallel architecture for long BCH
encoding. Our novel technique can be used to eliminate the fanout bottleneck.
The only restriction on the speed of long BCH encoding of our CRT-based
architecture is $log_2N$, where $N$ is the length of the BCH code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3151</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3151</id><created>2009-04-20</created><authors><author><keyname>Uno</keyname><forenames>Takeaki</forenames></author><author><keyname>Sugiyama</keyname><forenames>Masashi</forenames></author><author><keyname>Tsuda</keyname><forenames>Koji</forenames></author></authors><title>Efficient Construction of Neighborhood Graphs by the Multiple Sorting
  Method</title><categories>cs.DS cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Neighborhood graphs are gaining popularity as a concise data representation
in machine learning. However, naive graph construction by pairwise distance
calculation takes $O(n^2)$ runtime for $n$ data points and this is
prohibitively slow for millions of data points. For strings of equal length,
the multiple sorting method (Uno, 2008) can construct an $\epsilon$-neighbor
graph in $O(n+m)$ time, where $m$ is the number of $\epsilon$-neighbor pairs in
the data. To introduce this remarkably efficient algorithm to continuous
domains such as images, signals and texts, we employ a random projection method
to convert vectors to strings. Theoretical results are presented to elucidate
the trade-off between approximation quality and computation time. Empirical
results show the efficiency of our method in comparison to fast nearest
neighbor alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3157</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3157</id><created>2009-04-20</created><authors><author><keyname>Grumbach</keyname><forenames>Stephane</forenames><affiliation>INRIA Liama</affiliation></author><author><keyname>Wang</keyname><forenames>Fang</forenames><affiliation>ISCAS Sklcs</affiliation></author><author><keyname>Wu</keyname><forenames>Zhilin</forenames><affiliation>CASIA Liama</affiliation></author></authors><title>On the distributed evaluation of recursive queries over graphs</title><categories>cs.LO cs.DC</categories><comments>28 pages, 0 figures, NOTERE 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logical formalisms such as first-order logic (FO) and fixpoint logic (FP) are
well suited to express in a declarative manner fundamental graph
functionalities required in distributed systems. We show that these logics
constitute good abstractions for programming distributed systems as a whole,
since they can be evaluated in a fully distributed manner with reasonable
complexity upper-bounds. We first prove that FO and FP can be evaluated with a
polynomial number of messages of logarithmic size. We then show that the
(global) logical formulas can be translated into rule programs describing the
local behavior of the nodes of the distributed system, which compute equivalent
results. Finally, we introduce local fragments of these logics, which preserve
as much as possible the locality of their distributed computation, while
offering a rich expressive power for networking functionalities. We prove that
they admit tighter upper-bounds with bounded number of messages of bounded
size. Finally, we show that the semantics and the complexity of the local
fragments are preserved over locally consistent networks as well as anonymous
networks, thus showing the robustness of the proposed local logical formalisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3165</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3165</id><created>2009-04-21</created><authors><author><keyname>Tse</keyname><forenames>David</forenames></author><author><keyname>Yates</keyname><forenames>Roy</forenames></author></authors><title>Fading Broadcast Channels with State Information at the Receivers</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Despite considerable progress on the information-theoretic broadcast channel,
the capacity region of fading broadcast channels with channel state known at
the receivers but unknown at the transmitter remains unresolved. We address
this subject by introducing a layered erasure broadcast channel model in which
each component channel has a state that specifies the received signal levels in
an instance of a deterministic binary expansion channel. We find the capacity
region of this class of broadcast channels. The capacity achieving strategy
assigns each signal level to the user that derives the maximum expected rate
from that level. The outer bound is based on a channel enhancement that creates
a degraded broadcast channel for which the capacity region is known. This same
approach is then used to find inner and outer bounds to the capacity region of
fading Gaussian broadcast channels. The achievability scheme employs a
superposition of binary inputs. For intermittent AWGN channels and for Rayleigh
fading channels, the achievable rates are observed to be with 1-2 bits of the
outer bound at high SNR. We also prove that the achievable rate region is
within 6.386 bits/s/Hz of the capacity region for all fading AWGN broadcast
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3169</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3169</id><created>2009-04-21</created><authors><author><keyname>Durr</keyname><forenames>Christoph</forenames></author><author><keyname>Guinez</keyname><forenames>Flavio</forenames></author><author><keyname>Matamala</keyname><forenames>Martin</forenames></author></authors><title>Reconstructing 3-colored grids from horizontal and vertical projections
  is NP-hard</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of coloring a grid using k colors with the
restriction that in each row and each column has an specific number of cells of
each color. In an already classical result, Ryser obtained a necessary and
sufficient condition for the existence of such a coloring when two colors are
considered. This characterization yields a linear time algorithm for
constructing such a coloring when it exists. Gardner et al. showed that for
k&gt;=7 the problem is NP-hard. Afterward Chrobak and Durr improved this result,
by proving that it remains NP-hard for k&gt;=4. We solve the gap by showing that
for 3 colors the problem is already NP-hard. Besides we also give some results
on tiling tomography problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3183</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3183</id><created>2009-04-21</created><authors><author><keyname>Kuivinen</keyname><forenames>Fredrik</forenames></author></authors><title>On the Complexity of Submodular Function Minimisation on Diamonds</title><categories>cs.DS cs.CC</categories><comments>31 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $(L; \sqcap, \sqcup)$ be a finite lattice and let $n$ be a positive
integer. A function $f : L^n \to \mathbb{R}$ is said to be submodular if
$f(\tup{a} \sqcap \tup{b}) + f(\tup{a} \sqcup \tup{b}) \leq f(\tup{a}) +
f(\tup{b})$ for all $\tup{a}, \tup{b} \in L^n$. In this paper we study
submodular functions when $L$ is a diamond. Given oracle access to $f$ we are
interested in finding $\tup{x} \in L^n$ such that $f(\tup{x}) = \min_{\tup{y}
\in L^n} f(\tup{y})$ as efficiently as possible.
  We establish a min--max theorem, which states that the minimum of the
submodular function is equal to the maximum of a certain function defined over
a certain polyhedron; and a good characterisation of the minimisation problem,
i.e., we show that given an oracle for computing a submodular $f : L^n \to
\mathbb{Z}$ and an integer $m$ such that $\min_{\tup{x} \in L^n} f(\tup{x}) =
m$, there is a proof of this fact which can be verified in time polynomial in
$n$ and $\max_{\tup{t} \in L^n} \log |f(\tup{t})|$; and a pseudo-polynomial
time algorithm for the minimisation problem, i.e., given an oracle for
computing a submodular $f : L^n \to \mathbb{Z}$ one can find $\min_{\tup{t} \in
L^n} f(\tup{t})$ in time bounded by a polynomial in $n$ and $\max_{\tup{t} \in
L^n} |f(\tup{t})|$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3215</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3215</id><created>2009-04-21</created><authors><author><keyname>Allali</keyname><forenames>Oussama</forenames><affiliation>LIP6</affiliation></author><author><keyname>Latapy</keyname><forenames>Matthieu</forenames><affiliation>LIP6</affiliation></author><author><keyname>Magnien</keyname><forenames>Clemence</forenames><affiliation>LIP6</affiliation></author></authors><title>Measurement of eDonkey Activity with Distributed Honeypots</title><categories>cs.NI</categories><comments>Hot-P2P Sixth International Workshop on Hot Topics in Peer-to-Peer
  Systems (Hot-P2P 2009), May 29, 2009, Rome, Italy</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collecting information about user activity in peer-to-peer systems is a key
but challenging task. We describe here a distributed platform for doing so on
the eDonkey network, relying on a group of honeypot peers which claim to have
certain files and log queries they receive for these files. We then conduct
some measurements with typical scenarios and use the obtained data to analyze
the impact of key parameters like measurement duration, number of honeypots
involved, and number of advertised files. This illustrates both the possible
uses of our measurement system, and the kind of data one may collect using it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3222</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3222</id><created>2009-04-21</created><authors><author><keyname>Tarissan</keyname><forenames>Fabien</forenames><affiliation>ISC</affiliation></author><author><keyname>Latapy</keyname><forenames>Matthieu</forenames><affiliation>LIP6</affiliation></author><author><keyname>Prieur</keyname><forenames>Christophe</forenames><affiliation>LIAFA</affiliation></author></authors><title>Efficient Measurement of Complex Networks Using Link Queries</title><categories>cs.NI</categories><comments>Proceedings of the IEEE International Workshop on Network Science For
  Communication Networks (NetSciCom'09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex networks are at the core of an intense research activity. However, in
most cases, intricate and costly measurement procedures are needed to explore
their structure. In some cases, these measurements rely on link queries: given
two nodes, it is possible to test the existence of a link between them. These
tests may be costly, and thus minimizing their number while maximizing the
number of discovered links is a key issue. This paper studies this problem: we
observe that properties classically observed on real-world complex networks
give hints for their efficient measurement; we derive simple principles and
several measurement strategies based on this, and experimentally evaluate their
efficiency on real-world cases. In order to do so, we introduce methods to
evaluate the efficiency of strategies. We also explore the bias that different
measurement strategies may induce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3243</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3243</id><created>2009-04-21</created><authors><author><keyname>Oriol</keyname><forenames>Manuel</forenames></author></authors><title>The Business of Selling Electronic Documents</title><categories>cs.GL cs.GT</categories><comments>6 pages</comments><acm-class>K.4.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The music industry has huge troubles adapting to the new technologies. As
many pointed out, when copying music is essentially free and socially accepted
it becomes increasingly tempting for users to infringe copyrights and copy
music from one person to another. The answer of the music industry is to outlaw
a majority of citizens. This article describes how the music industry should
reinvent itself and adapt to a world where the network is ubiquitous and
exchanging information is essentially free. It relies on adapting prices to the
demand and lower costs of electronic documents in a dramatic way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3251</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3251</id><created>2009-04-21</created><authors><author><keyname>Bj&#xf6;rklund</keyname><forenames>Andreas</forenames></author><author><keyname>Husfeldt</keyname><forenames>Thore</forenames></author><author><keyname>Kaski</keyname><forenames>Petteri</forenames></author><author><keyname>Koivisto</keyname><forenames>Mikko</forenames></author></authors><title>On evaluation of permanents</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the time and space complexity of matrix permanents over rings and
semirings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3273</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3273</id><created>2009-04-21</created><updated>2009-05-14</updated><authors><author><keyname>Hamel</keyname><forenames>John S.</forenames></author></authors><title>A Thermodynamic Turing Machine: Artificial Molecular Computing Using
  Classical Reversible Logic Switching Networks</title><categories>cs.CC quant-ph</categories><comments>Version 2 eliminates two erroneous figures (4 and 5 in version 1) and
  adds a new section containing circuit examples of how to implement Hadamard
  transforms in one step for Deutsch, Bernstein Vazirani and Simon problems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses how to implement certain classes of quantum computer
algorithms using classical discrete switching networks that are amenable to
implementation in main stream CMOS transistor IC technology. The methods differ
from other classical approaches in that asynchronous feedback is exploited in
classical transistor reversible logic circuits to implement the Hadamard
transform in one simultaneous step over all qubits as in a true quantum
computer. The Simon problem is used as an example. The method is used to
provide an order n execution speed method for the Gaussian elimination step in
the Simon problem. The approach is referred to as a Thermodynamic Turing
Machine in that it behaves like an artificial molecule where solutions to a
problem are found by evolving the classical circuits from one thermodynamic
equilibrium state to another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3310</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3310</id><created>2009-04-21</created><authors><author><keyname>Bashir</keyname><forenames>Shariq</forenames></author><author><keyname>Baig</keyname><forenames>Abdul Rauf</forenames></author></authors><title>FastLMFI: An Efficient Approach for Local Maximal Patterns Propagation
  and Maximal Patterns Superset Checking</title><categories>cs.DB cs.AI cs.DS</categories><comments>8 Pages, In the proceedings of 4th ACS/IEEE International Conference
  on Computer Systems and Applications 2006, March 8, 2006, Dubai/Sharjah, UAE,
  2006, Page(s) 452-459</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximal frequent patterns superset checking plays an important role in the
efficient mining of complete Maximal Frequent Itemsets (MFI) and maximal search
space pruning. In this paper we present a new indexing approach, FastLMFI for
local maximal frequent patterns (itemset) propagation and maximal patterns
superset checking. Experimental results on different sparse and dense datasets
show that our work is better than the previous well known progressive focusing
technique. We have also integrated our superset checking approach with an
existing state of the art maximal itemsets algorithm Mafia, and compare our
results with current best maximal itemsets algorithms afopt-max and FP
(zhu)-max. Our results outperform afopt-max and FP (zhu)-max on dense (chess
and mushroom) datasets on almost all support thresholds, which shows the
effectiveness of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3312</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3312</id><created>2009-04-21</created><authors><author><keyname>Bashir</keyname><forenames>Shariq</forenames></author><author><keyname>Baig</keyname><forenames>Abdul Rauf</forenames></author></authors><title>HybridMiner: Mining Maximal Frequent Itemsets Using Hybrid Database
  Representation Approach</title><categories>cs.DB cs.AI cs.DS</categories><comments>8 Pages In the proceedings of 9th IEEE-INMIC 2005, Karachi, Pakistan,
  2005</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel hybrid (arraybased layout and vertical
bitmap layout) database representation approach for mining complete Maximal
Frequent Itemset (MFI) on sparse and large datasets. Our work is novel in terms
of scalability, item search order and two horizontal and vertical projection
techniques. We also present a maximal algorithm using this hybrid database
representation approach. Different experimental results on real and sparse
benchmark datasets show that our approach is better than previous state of art
maximal algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3316</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3316</id><created>2009-04-21</created><authors><author><keyname>Bashir</keyname><forenames>Shariq</forenames></author><author><keyname>Baig</keyname><forenames>Abdul Rauf</forenames></author></authors><title>Ramp: Fast Frequent Itemset Mining with Efficient Bit-Vector Projection
  Technique</title><categories>cs.DB cs.AI cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mining frequent itemset using bit-vector representation approach is very
efficient for dense type datasets, but highly inefficient for sparse datasets
due to lack of any efficient bit-vector projection technique. In this paper we
present a novel efficient bit-vector projection technique, for sparse and dense
datasets. To check the efficiency of our bit-vector projection technique, we
present a new frequent itemset mining algorithm Ramp (Real Algorithm for Mining
Patterns) build upon our bit-vector projection technique. The performance of
the Ramp is compared with the current best (all, maximal and closed) frequent
itemset mining algorithms on benchmark datasets. Different experimental results
on sparse and dense datasets show that mining frequent itemset using Ramp is
faster than the current best algorithms, which show the effectiveness of our
bit-vector projection idea. We also present a new local maximal frequent
itemsets propagation and maximal itemset superset checking approach FastLMFI,
build upon our PBR bit-vector projection technique. Our different computational
experiments suggest that itemset maximality checking using FastLMFI is fast and
efficient than a previous will known progressive focusing approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3319</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3319</id><created>2009-04-21</created><authors><author><keyname>Bashir</keyname><forenames>Shariq</forenames></author><author><keyname>Jan</keyname><forenames>Zahoor</forenames></author><author><keyname>Baig</keyname><forenames>Abdul Rauf</forenames></author></authors><title>Fast Algorithms for Mining Interesting Frequent Itemsets without Minimum
  Support</title><categories>cs.DB cs.AI cs.DS</categories><comments>25 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Real world datasets are sparse, dirty and contain hundreds of items. In such
situations, discovering interesting rules (results) using traditional frequent
itemset mining approach by specifying a user defined input support threshold is
not appropriate. Since without any domain knowledge, setting support threshold
small or large can output nothing or a large number of redundant uninteresting
results. Recently a novel approach of mining only N-most/Top-K interesting
frequent itemsets has been proposed, which discovers the top N interesting
results without specifying any user defined support threshold. However, mining
interesting frequent itemsets without minimum support threshold are more costly
in terms of itemset search space exploration and processing cost. Thereby, the
efficiency of their mining highly depends upon three main factors (1) Database
representation approach used for itemset frequency counting, (2) Projection of
relevant transactions to lower level nodes of search space and (3) Algorithm
implementation technique. Therefore, to improve the efficiency of mining
process, in this paper we present two novel algorithms called (N-MostMiner and
Top-K-Miner) using the bit-vector representation approach which is very
efficient in terms of itemset frequency counting and transactions projection.
In addition to this, several efficient implementation techniques of N-MostMiner
and Top-K-Miner are also present which we experienced in our implementation.
Our experimental results on benchmark datasets suggest that the NMostMiner and
Top-K-Miner are very efficient in terms of processing time as compared to
current best algorithms BOMO and TFP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3320</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3320</id><created>2009-04-21</created><authors><author><keyname>Bashir</keyname><forenames>Shariq</forenames></author><author><keyname>Razzaq</keyname><forenames>Saad</forenames></author><author><keyname>Maqbool</keyname><forenames>Umer</forenames></author><author><keyname>Tahir</keyname><forenames>Sonya</forenames></author><author><keyname>Baig</keyname><forenames>Abdul Rauf</forenames></author></authors><title>Using Association Rules for Better Treatment of Missing Values</title><categories>cs.DB cs.AI cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quality of training data for knowledge discovery in databases (KDD) and
data mining depends upon many factors, but handling missing values is
considered to be a crucial factor in overall data quality. Today real world
datasets contains missing values due to human, operational error, hardware
malfunctioning and many other factors. The quality of knowledge extracted,
learning and decision problems depend directly upon the quality of training
data. By considering the importance of handling missing values in KDD and data
mining tasks, in this paper we propose a novel Hybrid Missing values Imputation
Technique (HMiT) using association rules mining and hybrid combination of
k-nearest neighbor approach. To check the effectiveness of our HMiT missing
values imputation technique, we also perform detail experimental results on
real world datasets. Our results suggest that the HMiT technique is not only
better in term of accuracy but it also take less processing time as compared to
current best missing values imputation technique based on k-nearest neighbor
approach, which shows the effectiveness of our missing values imputation
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3321</identifier>
 <datestamp>2009-04-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3321</id><created>2009-04-21</created><authors><author><keyname>Bashir</keyname><forenames>Shariq</forenames></author><author><keyname>Razzaq</keyname><forenames>Saad</forenames></author><author><keyname>Maqbool</keyname><forenames>Umer</forenames></author><author><keyname>Tahir</keyname><forenames>Sonya</forenames></author><author><keyname>Baig</keyname><forenames>Abdul Rauf</forenames></author></authors><title>Introducing Partial Matching Approach in Association Rules for Better
  Treatment of Missing Values</title><categories>cs.DB cs.AI cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Handling missing values in training datasets for constructing learning models
or extracting useful information is considered to be an important research task
in data mining and knowledge discovery in databases. In recent years, lot of
techniques are proposed for imputing missing values by considering attribute
relationships with missing value observation and other observations of training
dataset. The main deficiency of such techniques is that, they depend upon
single approach and do not combine multiple approaches, that why they are less
accurate. To improve the accuracy of missing values imputation, in this paper
we introduce a novel partial matching concept in association rules mining,
which shows better results as compared to full matching concept that we
described in our previous work. Our imputation technique combines the partial
matching concept in association rules with k-nearest neighbor approach. Since
this is a hybrid technique, therefore its accuracy is much better than as
compared to those techniques which depend upon single approach. To check the
efficiency of our technique, we also provide detail experimental results on
number of benchmark datasets which show better results as compared to previous
approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3325</identifier>
 <datestamp>2010-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3325</id><created>2009-04-21</created><updated>2009-06-08</updated><authors><author><keyname>Ummels</keyname><forenames>Michael</forenames></author><author><keyname>Wojtczak</keyname><forenames>Dominik</forenames></author></authors><title>Decision Problems for Nash Equilibria in Stochastic Games</title><categories>cs.GT cs.LO</categories><comments>22 pages, revised version</comments><report-no>EDI-INF-RR-1325</report-no><doi>10.1007/978-3-642-04027-6_37</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the computational complexity of finding Nash equilibria in
stochastic multiplayer games with $\omega$-regular objectives. While the
existence of an equilibrium whose payoff falls into a certain interval may be
undecidable, we single out several decidable restrictions of the problem.
First, restricting the search space to stationary, or pure stationary,
equilibria results in problems that are typically contained in PSPACE and NP,
respectively. Second, we show that the existence of an equilibrium with a
binary payoff (i.e. an equilibrium where each player either wins or loses with
probability 1) is decidable. We also establish that the existence of a Nash
equilibrium with a certain binary payoff entails the existence of an
equilibrium with the same payoff in pure, finite-state strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3340</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3340</id><created>2009-04-21</created><authors><author><keyname>Gioran</keyname><forenames>Chris</forenames></author><author><keyname>Kontoyiannis</keyname><forenames>Ioannis</forenames></author></authors><title>Lossy Compression in Near-Linear Time via Efficient Random Codebooks and
  Databases</title><categories>cs.IT math.IT</categories><comments>23 pages, four figures, four tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The compression-complexity trade-off of lossy compression algorithms that are
based on a random codebook or a random database is examined. Motivated, in
part, by recent results of Gupta-Verd\'{u}-Weissman (GVW) and their underlying
connections with the pattern-matching scheme of Kontoyiannis' lossy Lempel-Ziv
algorithm, we introduce a non-universal version of the lossy Lempel-Ziv method
(termed LLZ). The optimality of LLZ for memoryless sources is established, and
its performance is compared to that of the GVW divide-and-conquer approach.
Experimental results indicate that the GVW approach often yields better
compression than LLZ, but at the price of much higher memory requirements. To
combine the advantages of both, we introduce a hybrid algorithm (HYB) that
utilizes both the divide-and-conquer idea of GVW and the single-database
structure of LLZ. It is proved that HYB shares with GVW the exact same
rate-distortion performance and implementation complexity, while, like LLZ,
requiring less memory, by a factor which may become unbounded, depending on the
choice or the relevant design parameters. Experimental results are also
presented, illustrating the performance of all three methods on data generated
by simple discrete memoryless sources. In particular, the HYB algorithm is
shown to outperform existing schemes for the compression of some simple
discrete sources with respect to the Hamming distortion criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3351</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3351</id><created>2009-04-21</created><authors><author><keyname>Fozunbal</keyname><forenames>Majid</forenames></author></authors><title>A Subsequence-Histogram Method for Generic Vocabulary Recognition over
  Deletion Channels</title><categories>cs.IT cs.DS math.IT stat.AP</categories><comments>5 pages, International Symposium on Information Theory (ISIT) 2009</comments><report-no>HP Labs Technical Report HPL-2009-2</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of recognizing a vocabulary--a collection of words
(sequences) over a finite alphabet--from a potential subsequence of one of its
words. We assume the given subsequence is received through a deletion channel
as a result of transmission of a random word from one of the two generic
underlying vocabularies. An exact maximum a posterior (MAP) solution for this
problem counts the number of ways a given subsequence can be derived from
particular subsets of candidate vocabularies, requiring exponential time or
space.
  We present a polynomial approximation algorithm for this problem. The
algorithm makes no prior assumption about the rules and patterns governing the
structure of vocabularies. Instead, through off-line processing of
vocabularies, it extracts data regarding regularity patterns in the
subsequences of each vocabulary. In the recognition phase, the algorithm just
uses this data, called subsequence-histogram, to decide in favor of one of the
vocabularies. We provide examples to demonstrate the performance of the
algorithm and show that it can achieve the same performance as MAP in some
situations.
  Potential applications include bioinformatics, storage systems, and search
engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3352</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3352</id><created>2009-04-21</created><authors><author><keyname>Szita</keyname><forenames>Istvan</forenames></author><author><keyname>Lorincz</keyname><forenames>Andras</forenames></author></authors><title>Optimistic Initialization and Greediness Lead to Polynomial Time
  Learning in Factored MDPs - Extended Version</title><categories>cs.AI cs.LG</categories><comments>This paper is the extended version of a similarly named paper
  appearing in ICML'09, containing the rigorous proofs of the main theorem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an algorithm for polynomial-time reinforcement
learning in factored Markov decision processes (FMDPs). The factored optimistic
initial model (FOIM) algorithm, maintains an empirical model of the FMDP in a
conventional way, and always follows a greedy policy with respect to its model.
The only trick of the algorithm is that the model is initialized
optimistically. We prove that with suitable initialization (i) FOIM converges
to the fixed point of approximate value iteration (AVI); (ii) the number of
steps when the agent makes non-near-optimal decisions (with respect to the
solution of AVI) is polynomial in all relevant quantities; (iii) the per-step
costs of the algorithm are also polynomial. To our best knowledge, FOIM is the
first algorithm with these properties. This extended version contains the
rigorous proofs of the main theorem. A version of this paper appeared in
ICML'09.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3356</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3356</id><created>2009-04-21</created><updated>2009-10-13</updated><authors><author><keyname>Freund</keyname><forenames>Yoav</forenames></author></authors><title>A method for Hedging in continuous time</title><categories>cs.IT cs.AI math.IT math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method for hedging in continuous time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3366</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3366</id><created>2009-04-21</created><authors><author><keyname>Daley</keyname><forenames>Mark</forenames></author><author><keyname>Domaratzki</keyname><forenames>Michael</forenames></author><author><keyname>Salomaa</keyname><forenames>Kai</forenames></author></authors><title>State complexity of orthogonal catenation</title><categories>cs.FL</categories><comments>DCFS 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A language $L$ is the orthogonal catenation of languages $L_1$ and $L_2$ if
every word of $L$ can be written in a unique way as a catenation of a word in
$L_1$ and a word in $L_2$. We establish a tight bound for the state complexity
of orthogonal catenation of regular languages. The bound is smaller than the
bound for arbitrary catenation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3395</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3395</id><created>2009-04-22</created><authors><author><keyname>Ricci-Tersenghi</keyname><forenames>Federico</forenames></author><author><keyname>Semerjian</keyname><forenames>Guilhem</forenames></author></authors><title>On the cavity method for decimated random constraint satisfaction
  problems and the analysis of belief propagation guided decimation algorithms</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.DM</categories><comments>32 pages, 24 figures</comments><journal-ref>J Stat. Mech. P09001 (2009)</journal-ref><doi>10.1088/1742-5468/2009/09/P09001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a version of the cavity method for diluted mean-field spin
models that allows the computation of thermodynamic quantities similar to the
Franz-Parisi quenched potential in sparse random graph models. This method is
developed in the particular case of partially decimated random constraint
satisfaction problems. This allows to develop a theoretical understanding of a
class of algorithms for solving constraint satisfaction problems, in which
elementary degrees of freedom are sequentially assigned according to the
results of a message passing procedure (belief-propagation). We confront this
theoretical analysis to the results of extensive numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3420</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3420</id><created>2009-04-22</created><authors><author><keyname>Lal</keyname><forenames>Sunder</forenames></author><author><keyname>Verma</keyname><forenames>Vandani</forenames></author></authors><title>Identity Based Strong Designated Verifier Parallel Multi-Proxy Signature
  Scheme</title><categories>cs.CR</categories><comments>6 pages, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new identity based strong designated verifier parallel
multi-proxy signature scheme. Multi-Proxy signatures allow the original signer
to delegate his signing power to a group of proxy signers. In our scheme, the
designated verifier can only validate proxy signatures created by a group of
proxy signer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3422</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3422</id><created>2009-04-22</created><authors><author><keyname>Lal</keyname><forenames>Sunder</forenames></author><author><keyname>Verma</keyname><forenames>Vandani</forenames></author></authors><title>Some Proxy Signature and Designated verifier Signature Schemes over
  Braid Groups</title><categories>cs.CR</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Braids groups provide an alternative to number theoretic public cryptography
and can be implemented quite efficiently. The paper proposes five signature
schemes: Proxy Signature, Designated Verifier, Bi-Designated Verifier,
Designated Verifier Proxy Signature And Bi-Designated Verifier Proxy Signature
scheme based on braid groups. We also discuss the security aspects of each of
the proposed schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3444</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3444</id><created>2009-04-22</created><authors><author><keyname>Gupta</keyname><forenames>Bhupendra</forenames><affiliation>Indian Institute of Information Technology-DM-Jabalpur</affiliation></author></authors><title>Comment to &quot;Coverage by Randomly Deployed Wireless Sensor Networks&quot;</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is a correction paper on &quot;P.J. Wan and C.W. Yi, &quot;Coverage by Randomly
Deployed Wireless Sensor Networks&quot;, IEEE Transaction On Information Theory,
vol.52, No.6, June 2006.&quot;
  In the above paper, Lemma (4), on page 2659 play the key role for deriving
the main results in the paper. The statement as well as the proof of Lemma (4),
page $2659,$ is not correct. We have given the correct version of Lemma. This
change in Lemma leads a drastic change in all the result derived in the above
paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3458</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3458</id><created>2009-04-22</created><authors><author><keyname>Sivadasan</keyname><forenames>Praveen</forenames></author><author><keyname>Lal</keyname><forenames>P Sojan</forenames></author></authors><title>JConstHide: A Framework for Java Source Code Constant Hiding</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software obfuscation or obscuring a software is an approach to defeat the
practice of reverse engineering a software for using its functionality
illegally in the development of another software. Java applications are more
amenable to reverse engineering and re-engineering attacks through methods such
as decompilation because Java class files store the program in a semi complied
form called byte codes. The existing obfuscation systems obfuscate the Java
class files. Obfuscated source code produce obfuscated byte codes and hence two
level obfuscation (source code and byte code level) of the program makes it
more resilient to reverse engineering attacks . But source code obfuscation is
much more difficult due to richer set of programming constructs and the scope
of the different variables used in the program and only very little progress
has been made on this front. We in this paper are proposing a framework named
JConstHide for hiding constants, especially integers in the java source codes,
to defeat reverse engineering through decompilation. To the best of our
knowledge, no data hiding software are available for java source code constant
hiding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3469</identifier>
 <datestamp>2011-02-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3469</id><created>2009-04-22</created><updated>2010-05-01</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames></author></authors><title>Toggling operators in computability logic</title><categories>cs.LO cs.AI math.LO</categories><msc-class>03B47, 03F50, 03B70, 68Q10, 68T27, 68T30, 91A05</msc-class><acm-class>F.1.1; F.1.2</acm-class><journal-ref>Theoretical Computer Science 412 (2011), pp. 971-1004</journal-ref><doi>10.1016/j.tcs.2010.11.037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computability logic (CL) (see http://www.cis.upenn.edu/~giorgi/cl.html ) is a
research program for redeveloping logic as a formal theory of computability, as
opposed to the formal theory of truth which it has more traditionally been.
Formulas in CL stand for interactive computational problems, seen as games
between a machine and its environment; logical operators represent operations
on such entities; and &quot;truth&quot; is understood as existence of an effective
solution. The formalism of CL is open-ended, and may undergo series of
extensions as the studies of the subject advance. So far three -- parallel,
sequential and choice -- sorts of conjunction and disjunction have been
studied. The present paper adds one more natural kind to this collection,
termed toggling. The toggling operations can be characterized as lenient
versions of choice operations where choices are retractable, being allowed to
be reconsidered any finite number of times. This way, they model
trial-and-error style decision steps in interactive computation. The main
technical result of this paper is constructing a sound and complete
axiomatization for the propositional fragment of computability logic whose
vocabulary, together with negation, includes all four -- parallel, toggling,
sequential and choice -- kinds of conjunction and disjunction. Along with
toggling conjunction and disjunction, the paper also introduces the toggling
versions of quantifiers and recurrence operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3501</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3501</id><created>2009-04-22</created><authors><author><keyname>Bhattacharya</keyname><forenames>Sayan</forenames></author><author><keyname>Conitzer</keyname><forenames>Vincent</forenames></author><author><keyname>Munagala</keyname><forenames>Kamesh</forenames></author><author><keyname>Xia</keyname><forenames>Lirong</forenames></author></authors><title>Incentive Compatible Budget Elicitation in Multi-unit Auctions</title><categories>cs.GT cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the problem of designing incentive compatible
auctions for multiple (homogeneous) units of a good, when bidders have private
valuations and private budget constraints. When only the valuations are private
and the budgets are public, Dobzinski {\em et al} show that the {\em adaptive
clinching} auction is the unique incentive-compatible auction achieving
Pareto-optimality. They further show thatthere is no deterministic
Pareto-optimal auction with private budgets. Our main contribution is to show
the following Budget Monotonicity property of this auction: When there is only
one infinitely divisible good, a bidder cannot improve her utility by reporting
a budget smaller than the truth. This implies that a randomized modification to
the adaptive clinching auction is incentive compatible and Pareto-optimal with
private budgets.
  The Budget Monotonicity property also implies other improved results in this
context. For revenue maximization, the same auction improves the best-known
competitive ratio due to Abrams by a factor of 4, and asymptotically approaches
the performance of the optimal single-price auction.
  Finally, we consider the problem of revenue maximization (or social welfare)
in a Bayesian setting. We allow the bidders have public size constraints (on
the amount of good they are willing to buy) in addition to private budget
constraints. We show a simple poly-time computable 5.83-approximation to the
optimal Bayesian incentive compatible mechanism, that is implementable in
dominant strategies. Our technique again crucially needs the ability to prevent
bidders from over-reporting budgets via randomization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3503</identifier>
 <datestamp>2009-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3503</id><created>2009-04-22</created><updated>2009-08-09</updated><authors><author><keyname>Cicalese</keyname><forenames>Ferdinando</forenames></author><author><keyname>Jacobs</keyname><forenames>Tobias</forenames></author><author><keyname>Laber</keyname><forenames>Eduardo</forenames></author><author><keyname>Molinaro</keyname><forenames>Marco</forenames></author></authors><title>On the Complexity of Searching in Trees: Average-case Minimization</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on the average-case analysis: A function w : V -&gt; Z+ is given which
defines the likelihood for a node to be the one marked, and we want the
strategy that minimizes the expected number of queries. Prior to this paper,
very little was known about this natural question and the complexity of the
problem had remained so far an open question.
  We close this question and prove that the above tree search problem is
NP-complete even for the class of trees with diameter at most 4. This results
in a complete characterization of the complexity of the problem with respect to
the diameter size. In fact, for diameter not larger than 3 the problem can be
shown to be polynomially solvable using a dynamic programming approach.
  In addition we prove that the problem is NP-complete even for the class of
trees of maximum degree at most 16. To the best of our knowledge, the only
known result in this direction is that the tree search problem is solvable in
O(|V| log|V|) time for trees with degree at most 2 (paths).
  We match the above complexity results with a tight algorithmic analysis. We
first show that a natural greedy algorithm attains a 2-approximation.
Furthermore, for the bounded degree instances, we show that any optimal
strategy (i.e., one that minimizes the expected number of queries) performs at
most O(\Delta(T) (log |V| + log w(T))) queries in the worst case, where w(T) is
the sum of the likelihoods of the nodes of T and \Delta(T) is the maximum
degree of T. We combine this result with a non-trivial exponential time
algorithm to provide an FPTAS for trees with bounded degree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3525</identifier>
 <datestamp>2009-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3525</id><created>2009-04-22</created><authors><author><keyname>Monniaux</keyname><forenames>David</forenames><affiliation>VERIMAG - Imag</affiliation></author></authors><title>On using floating-point computations to help an exact linear arithmetic
  decision procedure</title><categories>cs.LO cs.NA</categories><proxy>ccsd hal-00354112</proxy><acm-class>F.4.1; G.1.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the decision problem for quantifier-free formulas whose atoms are
linear inequalities interpreted over the reals or rationals. This problem may
be decided using satisfiability modulo theory (SMT), using a mixture of a SAT
solver and a simplex-based decision procedure for conjunctions.
State-of-the-art SMT solvers use simplex implementations over rational numbers,
which perform well for typical problems arising from model-checking and program
analysis (sparse inequalities, small coefficients) but are slow for other
applications (denser problems, larger coefficients). We propose a simple
preprocessing phase that can be adapted on existing SMT solvers and that may be
optionally triggered. Despite using floating-point computations, our method is
sound and complete - it merely affects efficiency. We implemented the method
and provide benchmarks showing that this change brings a naive and slow
decision procedure (&quot;textbook simplex&quot; with rational numbers) up to the
efficiency of recent SMT solvers, over test cases arising from model-checking,
and makes it definitely faster than state-of-the-art SMT solvers on dense
examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3528</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3528</id><created>2009-04-22</created><updated>2009-04-28</updated><authors><author><keyname>Lescanne</keyname><forenames>Pierre</forenames><affiliation>LIP</affiliation></author></authors><title>Deconstruction of Infinite Extensive Games using coinduction</title><categories>cs.GT cs.LO</categories><comments>19 p</comments><proxy>ccsd ensl-00376141</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite objects and more specifically finite games are formalized using
induction, whereas infinite objects are formalized using coinduction. In this
article, after an introduction to the concept of coinduction, we revisit on
infinite (discrete) extensive games the basic notions of game theory. Among
others, we introduce a definition of Nash equilibrium and a notion of subgame
perfect equilibrium for infinite games. We use those concepts to analyze well
known infinite games, like the dollar auction game and the centipede game and
we show that human behaviors that are often considered as illogic are perfectly
rational, if one admits that human agents reason coinductively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3552</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3552</id><created>2009-04-23</created><authors><author><keyname>Nicolae</keyname><forenames>Papin</forenames></author><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author></authors><title>Internet: Romania vs. Europe</title><categories>cs.OH</categories><comments>14 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 153-166</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents various access ways to Internet for home users, both for
those who are low consumers (consumed time online or traffic monthly value), or
large consumers (unlimited connection). The main purpose of the work consists
in making a comparison between the situation of the Internet in Romania and
other countries in Europe such as Hungary (more western than Romania, so a
little more developed, still an Eastern country comparing to the more developed
countries in Western Europe and others well developed such as England, Italy,
France, and to those in development such as Poland, and at the periphery of
Europe such as Ukraine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3588</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3588</id><created>2009-04-22</created><authors><author><keyname>Xia</keyname><forenames>Bican</forenames></author><author><keyname>Zhang</keyname><forenames>Zhihai</forenames></author></authors><title>Termination of Linear Programs with Nonlinear Constraints</title><categories>cs.LO</categories><comments>17pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tiwari proved that termination of linear programs (loops with linear loop
conditions and updates) over the reals is decidable through Jordan forms and
eigenvectors computation. Braverman proved that it is also decidable over the
integers. In this paper, we consider the termination of loops with polynomial
loop conditions and linear updates over the reals and integers. First, we prove
that the termination of such loops over the integers is undecidable. Second,
with an assumption, we provide an complete algorithm to decide the termination
of a class of such programs over the reals. Our method is similar to that of
Tiwari in spirit but uses different techniques. Finally, we conjecture that the
termination of linear programs with polynomial loop conditions over the reals
is undecidable in general by %constructing a loop and reducing the problem to
another decision problem related to number theory and ergodic theory, which we
guess undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3607</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3607</id><created>2009-04-23</created><authors><author><keyname>Safilian</keyname><forenames>Ali Akbar</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author></authors><title>Relation between the Usual Order and the Enumeration Orders of Elements
  of r.e. Sets</title><categories>cs.FL cs.CC math.LO</categories><comments>15 pages; submitted to Mathematical Logic Quarterly</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have compared r.e. sets based on their enumeration orders
with Turing machines. Accordingly, we have defined novel concept uniformity for
Turing machines and r.e. sets and have studied some relationships between
uniformity and both one-reducibility and Turing reducibility. Furthermore, we
have defined type-2 uniformity concept and studied r.e. sets and Turing
machines based on this concept. In the end, we have introduced a new structure
called Turing Output Binary Search Tree that helps us lighten some ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3611</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3611</id><created>2009-04-23</created><authors><author><keyname>Huc</keyname><forenames>Florian</forenames></author><author><keyname>Jarry</keyname><forenames>Aubin</forenames></author></authors><title>VRAC: Virtual Raw Anchor Coordinates Routing in Sensor Networks --
  Concepts and Experimental Protocol</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to make full use of geographic routing techniques developed for
large scale networks, nodes must be localized. However, localization and
virtual localization techniques in sensor networks are dependent either on
expensive and sometimes unavailable hardware (e.g. GPS) or on sophisticated
localization calculus (e.g. triangulation) which are both error-prone and with
a costly overhead.
  Instead of localizing nodes in a traditional 2-dimensional space, we intend
to use directly the raw distance to a set of anchors to route messages in the
multi-dimensional space. This should enable us to use any geographic routing
protocol in a robust and efficient manner in a very large range of scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3612</identifier>
 <datestamp>2010-05-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3612</id><created>2009-04-23</created><authors><author><keyname>Neumann</keyname><forenames>Florentin</forenames></author><author><keyname>Reichenberger</keyname><forenames>Andrea</forenames></author><author><keyname>Ziegler</keyname><forenames>Martin</forenames></author></authors><title>Variations of the Turing Test in the Age of Internet and Virtual Reality</title><categories>cs.AI cs.HC</categories><acm-class>H.5.1; I.2.0</acm-class><journal-ref>pp.355-362 in Proc. 32nd Annual Conference on Artificial
  Intelligence (KI2009), Springer LNCS/LNAI vol.5803</journal-ref><doi>10.1007/978-3-642-04617-9_45</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Inspired by Hofstadter's Coffee-House Conversation (1982) and by the science
fiction short story SAM by Schattschneider (1988), we propose and discuss
criteria for non-mechanical intelligence. Firstly, we emphasize the practical
need for such tests in view of massively multiuser online role-playing games
(MMORPGs) and virtual reality systems like Second Life. Secondly, we
demonstrate Second Life as a useful framework for implementing (some iterations
of) that test.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3629</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3629</id><created>2009-04-23</created><updated>2009-06-22</updated><authors><author><keyname>Codat</keyname><forenames>Diana Sophia</forenames></author></authors><title>Les technologies de l'information et de la communication au niveau
  mondial et en Roumanie dans les dernieres annees</title><categories>cs.OH</categories><comments>10 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 21-30</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The level of development of the electronic communication market and of the
information technology, the indicators regarding the penetration of Internet
and the level of penetration of the connections in wide band, the integration
degree of the Tic application in the business area are crucial for the
development of an informational society and for the creation of a society based
on knowledge. Though the levels are still reduced their positive evolution
reflects the attenuation of the gaps by Romania, comparatively to other
countries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3631</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3631</id><created>2009-04-23</created><authors><author><keyname>Despi</keyname><forenames>Ioan</forenames></author><author><keyname>Luca</keyname><forenames>Lucian</forenames></author></authors><title>On the Ambiguity of Commercial Open Source</title><categories>cs.OH</categories><comments>10 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 31-40</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open source and commercial applications used to be two separate worlds. The
former was the work of amateurs who had little interest in making a profit,
while the latter was only profit oriented and was produced by big companies.
Nowadays open source is a threat and an opportunity to serious businesses of
all kinds, generating good profits while delivering low costs products to
customers. The competition between commercial and open source software has
impacted the industry and the society as a whole. But in the last years, the
markets for commercial and open source software are converging rapidly and it
is interesting to resume and discuss the implications of this new paradigm,
taking into account arguments pro and against it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3633</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3633</id><created>2009-04-23</created><authors><author><keyname>Fortis</keyname><forenames>Alexandra</forenames></author></authors><title>Business Process Modeling Notation - An Overview</title><categories>cs.SE</categories><comments>10 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 41-50</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BPMN represents an industrial standard created to offer a common and user
friendly notation to all the participants to a business process. The present
paper aims to briefly present the main features of this notation as well as an
interpretation of some of the main patterns characterizing a business process
modeled by the working fluxes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3634</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3634</id><created>2009-04-23</created><authors><author><keyname>Fortis</keyname><forenames>Florin</forenames></author><author><keyname>Fortis</keyname><forenames>Alexandra</forenames></author></authors><title>Tailored business solutions by workflow technologies</title><categories>cs.SE</categories><comments>12 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 51-62</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  VISP (Virtual Internet Service Provider) is an IST-STREP project, which is
conducting research in the field of these new technologies, targeted to
telecom/ISP companies. One of the first tasks of the VISP project is to
identify the most appropriate technologies in order to construct the VISP
platform. This paper presents the most significant results in the field of
choreography and orchestration, two key domains that must accompany process
modeling in the construction of a workflow environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3638</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3638</id><created>2009-04-23</created><authors><author><keyname>Gotsulenko</keyname><forenames>Vladimir</forenames></author><author><keyname>Gaponova</keyname><forenames>Lyudmila</forenames></author></authors><title>On one method of boundary value problem regularization by passage to the
  limit</title><categories>cs.NA</categories><comments>6 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 63-68</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For one class of boundary value problem depending on small parameter for
which numerical methods for their solution are actually inapplicable, procedure
of limiting problem acquisition which is much easier and which solution as much
as close to the initial solution is described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3642</identifier>
 <datestamp>2009-11-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3642</id><created>2009-04-23</created><authors><author><keyname>Haddadi</keyname><forenames>Farzan</forenames></author><author><keyname>Nayebi</keyname><forenames>Mohammad Mahdi</forenames></author><author><keyname>Aref</keyname><forenames>Mohammad Reza</forenames></author></authors><title>Direction-of-Arrival Estimation for Temporally Correlated Narrowband
  Signals</title><categories>cs.IT math.IT</categories><comments>IEEE Transactions on Signal Processing, vol. 57, pp. 600-609, Feb.
  2009</comments><doi>10.1109/TSP.2008.2008220</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  signal direction-of-arrival estimation using an array of sensors has been the
subject of intensive research and development during the last two decades.
Efforts have been directed to both, better solutions for the general data model
and to develop more realistic models. So far, many authors have assumed the
data to be iid samples of a multivariate statistical model. Although this
assumption reduces the complexity of the model, it may not be true in certain
situations where signals show temporal correlation. Some results are available
on the temporally correlated signal model in the literature. The temporally
correlated stochastic Cramer-Rao bound (CRB) has been calculated and an
instrumental variable-based method called IV-SSF is introduced. Also, it has
been shown that temporally correlated CRB is lower bounded by the deterministic
CRB. In this paper, we show that temporally correlated CRB is also upper
bounded by the stochastic iid CRB. We investigate the effect of temporal
correlation of the signals on the best achievable performance. We also show
that the IV-SSF method is not efficient and based on an analysis of the CRB,
propose a variation in the method which boosts its performance. Simulation
results show the improved performance of the proposed method in terms of lower
bias and error variance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3648</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3648</id><created>2009-04-23</created><authors><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author><author><keyname>Titu</keyname><forenames>Mihai</forenames></author></authors><title>Computer Aided Optimization of the Unconventional Processing</title><categories>cs.SE</categories><comments>6 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 85-90</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The unconventional technologies, currently applied at a certain category of
materials, difficult to be processed through usual techniques, have undergone
during the last 60 years all the stages, since their discovery to their use on
a large scale. They are based on elementary mechanisms which run the processing
through classic methods, yet, they use in addition the interconnections of
these methods. This leads to a plus in performance by increasing the outcomes
precision, reducing the processing time, increasing the quality of the finite
product, etc. This performance can be much increased by using the computer and
a software product in assisting the human operator in the processing by an
unconventional method such as; the electric or electro-chemical erosion, the
complex electric-electro-chemical erosion, the processing by a laser fascicle
and so on. The present work presents such an application based on a data base
combining the previous experimental results, which proposes a method of
optimization of the outcomes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3650</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3650</id><created>2009-04-23</created><authors><author><keyname>Lacrama</keyname><forenames>Dan L.</forenames></author><author><keyname>Snep</keyname><forenames>Ioan</forenames></author></authors><title>The use of invariant moments in hand-written character recognition</title><categories>cs.NE</categories><comments>12 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 91-102</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to present the implementation of a Radial Basis
Function neural network with built-in knowledge to recognize hand-written
characters. The neural network includes in its architecture gates controlled by
an attraction/repulsion system of coefficients. These coefficients are derived
from a preprocessing stage which groups the characters according to their
ascendant, central, or descendent components. The neural network is trained
using data from invariant moment functions. Results are compared with those
obtained using a K nearest neighbor method on the same moment data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3664</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3664</id><created>2009-04-23</created><authors><author><keyname>Shashua</keyname><forenames>Amnon</forenames></author></authors><title>Introduction to Machine Learning: Class Notes 67577</title><categories>cs.LG</categories><comments>109 pages, class notes of Machine Learning course given at the Hebrew
  University of Jerusalem</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Introduction to Machine learning covering Statistical Inference (Bayes, EM,
ML/MaxEnt duality), algebraic and spectral methods (PCA, LDA, CCA, Clustering),
and PAC learning (the Formal model, VC dimension, Double Sampling theorem).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3667</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3667</id><created>2009-04-23</created><authors><author><keyname>Munteanu</keyname><forenames>Alin</forenames></author><author><keyname>Sofran</keyname><forenames>Cristina Ofelia</forenames></author></authors><title>Considerations upon the Machine Learning Technologies</title><categories>cs.LG cs.AI</categories><comments>6 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 133-138</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial intelligence offers superior techniques and methods by which
problems from diverse domains may find an optimal solution. The Machine
Learning technologies refer to the domain of artificial intelligence aiming to
develop the techniques allowing the computers to &quot;learn&quot;. Some systems based on
Machine Learning technologies tend to eliminate the necessity of the human
intelligence while the others adopt a man-machine collaborative approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3669</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3669</id><created>2009-04-23</created><authors><author><keyname>Munteanu</keyname><forenames>Alin</forenames></author><author><keyname>Sofran</keyname><forenames>Cristina Ofelia</forenames></author></authors><title>Collaborative systems and multiagent systems</title><categories>cs.MA</categories><comments>6 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 139-144</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents some basic elements regarding the domain of the
collaborative systems, a domain of maximum actuality and also the multiagent
systems, developed as a result of a sound study on the one-agent systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3677</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3677</id><created>2009-04-23</created><updated>2009-04-29</updated><authors><author><keyname>Mitra</keyname><forenames>Arindam</forenames></author></authors><title>Quantum theory can be collectively verified</title><categories>cs.OH</categories><comments>Pdf, 8 pages, content unchanged</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  No theory of physics has been collectively scientifically verified in an
experiment so far. It is pointed out that probabilistic structure of quantum
theory can be collectively scientifically verified in an experiment. It is also
argued that experimentalist point of view quantum theory is a complete theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3693</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3693</id><created>2009-04-23</created><authors><author><keyname>Cotosman</keyname><forenames>Dieter Penteliuc</forenames></author></authors><title>The Multimedia Product - between Design and Information, Design and
  Utility and Design and Entertainment</title><categories>cs.MM</categories><comments>28 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 167-194</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates the possible coherent and effective alternatives to
solve the problems related to the communication needs of any multimedia
product. In essence, the presentation will focus on identifying the issues and
principles governing three types of the design - in fact, the multimedia design
in a broader sense - namely the information design - precisely aiming at ways
of organization and presentation of information in a useful and significant
form, the graphical user interface design, whose sub-domain consists of the
information displayed on the monitor screen and of interactivity between user,
computer and electronic devices, meaning, in fact, everything the user sees,
touches, hears and all the elements with which he interacts, the graphic
design, whose main concern is to create an aesthetic layout arrangement (from
the visual and perceptive) information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3694</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3694</id><created>2009-04-23</created><authors><author><keyname>Penteliuc-Cotosman</keyname><forenames>Dieter</forenames></author></authors><title>The new multimedia educational technologies, used in open and distance
  learning</title><categories>cs.MM</categories><comments>10 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 195-204</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews and refers to the latest telematics technology that has
turned the open system learning and helped it to become an institutional
alternative to the face-to-face traditional one. Most technologies, briefly
presented here, will be implemented in the &quot;ARTeFACt&quot; project - telematic
system for vocational education system of open system learning, system which
will be officially launched at the end of 2006, in the institutional offer of
the Faculty of Arts of the University West of Timisoara. The scientific
coordination of the doctoral project &quot;ARTeFACt&quot; is done by Mr. Prof. Dr. Eng.
Savi G. George, representing the Department of Mechatronics Faculty of
Mechanical Engineering from the University &quot;Politehnica&quot; of Timisoara, Romania
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3698</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3698</id><created>2009-04-23</created><authors><author><keyname>Rasenack</keyname><forenames>Rolf Andreas</forenames></author><author><keyname>Wolke</keyname><forenames>Karsten</forenames></author><author><keyname>Yermashov</keyname><forenames>Kostyantyn</forenames></author><author><keyname>Siemsen</keyname><forenames>Karl Hayo</forenames></author></authors><title>Semantic Linkage of Control Systems</title><categories>cs.SE</categories><comments>8 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 205-212</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Control systems are sets of interconnected hardware and software components
which regulate the behaviour of processes. The software of modern control
systems rises for some years by requirements regarding the flexibility and
functionality. Thus the force of innovation grows on enterprises, since ever
newer products in ever shorter time intervals must be made available.
Associated hereby is the crucial shortening of the product life cycle, whose
effects show up in reduced care of the software and the spares inventory. The
aim, the concept presented here and developed in a modeling environment, is
proved and ensures a minimum functionality of software components. Replacing
software components of a control system verified for functionality by a
framework at run-time and if necessary the software conditions will become
adapted. Quintessential point of this implementation is the usage of an
abstract syntax tree. Within its hierarchical structure meta information is
attached to nodes and processed by the framework. With the development of the
concept for semantic proving of software components the lifetime of
software-based products is increased.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3701</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3701</id><created>2009-04-23</created><authors><author><keyname>Er&#xe9;t&#xe9;o</keyname><forenames>Guillaume</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Gandon</keyname><forenames>Fabien</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Corby</keyname><forenames>Olivier</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Buffa</keyname><forenames>Michel</forenames></author></authors><title>Semantic Social Network Analysis</title><categories>cs.AI</categories><comments>published in Web Science (2009)</comments><proxy>ccsd inria-00378174</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social Network Analysis (SNA) tries to understand and exploit the key
features of social networks in order to manage their life cycle and predict
their evolution. Increasingly popular web 2.0 sites are forming huge social
network. Classical methods from social network analysis (SNA) have been applied
to such online networks. In this paper, we propose leveraging semantic web
technologies to merge and exploit the best features of each domain. We present
how to facilitate and enhance the analysis of online social networks,
exploiting the power of semantic social network analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3711</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3711</id><created>2009-04-23</created><authors><author><keyname>Timis</keyname><forenames>Mihai</forenames></author></authors><title>Output Width Signal Control In Asynchronous Digital Systems Using
  External Clock Signal</title><categories>cs.OH</categories><comments>6 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 237-242</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In present paper, I propose a method for resolving the timing delays for
output signals from an asynchronous sequential system. It will be used an
example of an asynchronous sequential system that will set up an output signal
when an input signal will be set up. The width of the output signal depends on
the input signal width, and in this case it is very short. There are many
synthesis methods, like using a RC group system, a monostable system in design
of the asynchronous digital system or using an external clock signal, CK. In
this paper will be used an external clock signal, CK.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3714</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3714</id><created>2009-04-23</created><authors><author><keyname>Timis</keyname><forenames>Mihai</forenames></author></authors><title>Output Width Signal Control In Asynchronous Digital Systems Using
  Monostable Circuits</title><categories>cs.OH</categories><comments>6 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 243-248</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In present paper, I propose a method for resolving the timing delays for
output signals from an asynchronous sequential system. It will be used an
example of an asynchronous sequential system that will set up an output signal
when an input signal will be set up. The width of the output signal depends on
the input signal width, and in this case it is very short. There are many
synthesis methods, like using a RC group system, a monostable system in design
of the asynchronous digital system or using an external clock signal, CK. In
this paper will be used a monostable circuit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3715</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3715</id><created>2009-04-23</created><authors><author><keyname>Vultur</keyname><forenames>Radu</forenames></author></authors><title>Mesh</title><categories>cs.OH</categories><comments>6 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 261-266</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Whether you just want to take a peek of a remote computer status, or you want
to install the latest version of a software on several workstations, you can do
all of this from your computer. The networks are growing, the time spent
administering the workstations increases and the number of repetitive tasks is
going sky high. But here comes MESH to take that load off your shoulders. And
because of SMS commands you can take this &quot;command center&quot; wherever you will
go. Just connect a GSM phone to the computer (using a cable, IrDA or Bluetooth)
and lock/restart/shutdown computers from your LAN with the push of a cell phone
button. You can even create your own SMS commands. This is MESH - the network
administrator's Swiss knife
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3716</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3716</id><created>2009-04-23</created><authors><author><keyname>Wolke</keyname><forenames>Karsten</forenames></author><author><keyname>Yermashov</keyname><forenames>K.</forenames></author><author><keyname>Siemsen</keyname><forenames>K. H.</forenames></author><author><keyname>Rasenack</keyname><forenames>Rolf Andreas</forenames></author></authors><title>Failover of Software Services with State Replication</title><categories>cs.SE</categories><comments>10 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 267-276</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing systems are becoming more and more complex and assuming more and
more responsibilities in all sectors of human activity. Applications do not run
locally on a single computer any more. A lot of today's applications are built
as distributed system; with services on different computers communicating with
each other. Distributed systems arise everywhere. The Internet is one of the
best-known distributed systems and used by nearly everyone today. It is obvious
that we are more and more dependent on computer services. Many people expect to
be able to buy things like clothing or electronic equipment even at night on
the Internet. Computers are expected to be operational and available 7 days a
week, 24 hours a day. Downtime, even for maintenance, is no longer acceptable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3718</identifier>
 <datestamp>2009-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3718</id><created>2009-04-23</created><authors><author><keyname>Yermashov</keyname><forenames>K.</forenames></author><author><keyname>Siemsen</keyname><forenames>K. H.</forenames></author><author><keyname>Wolke</keyname><forenames>K.</forenames></author><author><keyname>Rasenack</keyname><forenames>R. A.</forenames></author></authors><title>Architecture of the Neurath Basic Model View Controller</title><categories>cs.SE</categories><comments>6 pages,exposed on 1st &quot;European Conference on Computer Sciences &amp;
  Applications&quot; - XA2006, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series IV (2006), 277-282</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea of the Neurath Basic Model View Controller (NBMVC) appeared during
the discussion of the design of domain-specific modeling tools based on the
Neurath Modeling Language [Yer06]. The NBMVC is the core of the modeling
process within the modeling environment. It reduces complexity out of the
design process by providing domain-specific interfaces between the developer
and the model. These interfaces help to organize and manipulate the model. The
organization includes, for example, a layer with visual components to drop them
in and filter them out. The control routines includes, for example, model
transformations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3741</identifier>
 <datestamp>2015-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3741</id><created>2009-04-23</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Spiro</keyname><forenames>Emma S.</forenames></author></authors><title>The h-Index of a Graph and its Application to Dynamic Subgraph
  Statistics</title><categories>cs.DS</categories><comments>To appear at Algorithms and Data Structures Symposium, Banff, Canada,
  August 2009. 18 pages, 4 figures. Includes six pages of appendices that will
  not be included in the conference proceedings version</comments><acm-class>F.2.2</acm-class><journal-ref>J. Graph Algorithms &amp; Applications 16(2): 543-567, 2012</journal-ref><doi>10.7155/jgaa.00273</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a data structure that maintains the number of triangles in a
dynamic undirected graph, subject to insertions and deletions of edges and of
degree-zero vertices. More generally it can be used to maintain the number of
copies of each possible three-vertex subgraph in time O(h) per update, where h
is the h-index of the graph, the maximum number such that the graph contains
$h$ vertices of degree at least h. We also show how to maintain the h-index
itself, and a collection of h high-degree vertices in the graph, in constant
time per update. Our data structure has applications in social network analysis
using the exponential random graph model (ERGM); its bound of O(h) time per
edge is never worse than the Theta(sqrt m) time per edge necessary to list all
triangles in a static graph, and is strictly better for graphs obeying a power
law degree distribution. In order to better understand the behavior of the
h-index statistic and its implications for the performance of our algorithms,
we also study the behavior of the h-index on a set of 136 real-world networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3756</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3756</id><created>2009-04-23</created><updated>2009-05-12</updated><authors><author><keyname>Du</keyname><forenames>Wenliang</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Lueker</keyname><forenames>George S.</forenames></author></authors><title>On the Approximability of Geometric and Geographic Generalization and
  the Min-Max Bin Covering Problem</title><categories>cs.DS</categories><comments>18 pages. Expanded version of paper appearing in 2009 Algorithms and
  Data Structures Symposium (formerly WADS)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of abstracting a table of data about individuals so that
no selection query can identify fewer than k individuals. We show that it is
impossible to achieve arbitrarily good polynomial-time approximations for a
number of natural variations of the generalization technique, unless P = NP,
even when the table has only a single quasi-identifying attribute that
represents a geographic or unordered attribute:
  Zip-codes: nodes of a planar graph generalized into connected subgraphs
  GPS coordinates: points in R2 generalized into non-overlapping rectangles
  Unordered data: text labels that can be grouped arbitrarily. In addition to
impossibility results, we provide approximation algorithms for these difficult
single-attribute generalization problems, which, of course, apply to
multiple-attribute instances with one that is quasi-identifying. We show
theoretically and experimentally that our approximation algorithms can come
reasonably close to optimal solutions. Incidentally, the generalization problem
for unordered data can be viewed as a novel type of bin packing
problem--min-max bin covering--which may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3761</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3761</id><created>2009-04-24</created><updated>2009-06-30</updated><authors><author><keyname>Tsourakakis</keyname><forenames>Charalampos E.</forenames></author><author><keyname>Kolountzakis</keyname><forenames>Mihail N.</forenames></author><author><keyname>Miller</keyname><forenames>Gary L.</forenames></author></authors><title>Approximate Triangle Counting</title><categories>cs.DS cs.DM</categories><comments>1) 16 pages, 2 figures, under submission 2) Removed the erroneous
  random projection part. Thanks to Ioannis Koutis for pointing out the error.
  3) Added experimental session</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Triangle counting is an important problem in graph mining. Clustering
coefficients of vertices and the transitivity ratio of the graph are two
metrics often used in complex network analysis. Furthermore, triangles have
been used successfully in several real-world applications. However, exact
triangle counting is an expensive computation. In this paper we present the
analysis of a practical sampling algorithm for counting triangles in graphs.
Our analysis yields optimal values for the sampling rate, thus resulting in
tremendous speedups ranging from \emph{2800}x to \emph{70000}x when applied to
real-world networks. At the same time the accuracy of the estimation is
excellent.
  Our contributions include experimentation on graphs with several millions of
nodes and edges, where we show how practical our proposed method is. Finally,
our algorithm's implementation is a part of the \pegasus library (Code and
datasets are available at (http://www.cs.cmu.edu/~ctsourak/).) a Peta-Graph
Mining library implemented in Hadoop, the open source version of Mapreduce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3778</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3778</id><created>2009-04-23</created><authors><author><keyname>Timo</keyname><forenames>Roy</forenames></author><author><keyname>Blackmore</keyname><forenames>Kim</forenames></author><author><keyname>Hanlen</keyname><forenames>Leif</forenames></author></authors><title>Word-Valued Sources: an Ergodic Theorem, an AEP and the Conservation of
  Entropy</title><categories>cs.IT math.IT</categories><comments>21 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A word-valued source $\mathbf{Y} = Y_1,Y_2,...$ is discrete random process
that is formed by sequentially encoding the symbols of a random process
$\mathbf{X} = X_1,X_2,...$ with codewords from a codebook $\mathscr{C}$. These
processes appear frequently in information theory (in particular, in the
analysis of source-coding algorithms), so it is of interest to give conditions
on $\mathbf{X}$ and $\mathscr{C}$ for which $\mathbf{Y}$ will satisfy an
ergodic theorem and possess an Asymptotic Equipartition Property (AEP). In this
correspondence, we prove the following: (1) if $\mathbf{X}$ is asymptotically
mean stationary, then $\mathbf{Y}$ will satisfy a pointwise ergodic theorem and
possess an AEP; and, (2) if the codebook $\mathscr{C}$ is prefix-free, then the
entropy rate of $\mathbf{Y}$ is equal to the entropy rate of $\mathbf{X}$
normalized by the average codeword length.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3780</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3780</id><created>2009-04-23</created><authors><author><keyname>Needell</keyname><forenames>Deanna</forenames></author></authors><title>Noisy Signal Recovery via Iterative Reweighted L1-Minimization</title><categories>math.NA cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing has shown that it is possible to reconstruct sparse high
dimensional signals from few linear measurements. In many cases, the solution
can be obtained by solving an L1-minimization problem, and this method is
accurate even in the presence of noise. Recent a modified version of this
method, reweighted L1-minimization, has been suggested. Although no provable
results have yet been attained, empirical studies have suggested the reweighted
version outperforms the standard method. Here we analyze the reweighted
L1-minimization method in the noisy case, and provide provable results showing
an improvement in the error bound over the standard bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3789</identifier>
 <datestamp>2009-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3789</id><created>2009-04-23</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author></authors><title>Formally Specifying and Proving Operational Aspects of Forensic Lucid in
  Isabelle</title><categories>cs.LO cs.CR cs.PL</categories><comments>23 pages, 3 listings, 3 figures, 1 table, 1 Appendix with theorems,
  pp. 76--98. TPHOLs 2008 Emerging Trends Proceedings, August 18-21, Montreal,
  Canada. Editors: Otmane Ait Mohamed and Cesar Munoz and Sofiene Tahar. The
  individual paper's PDF is at
  http://users.encs.concordia.ca/~tphols08/TPHOLs2008/ET/76-98.pdf</comments><report-no>2008-1-Ait Mohamed</report-no><acm-class>D.3.1; D.3.2; D.3.3; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Forensic Lucid intensional programming language has been proposed for
intensional cyberforensic analysis. In large part, the language is based on
various predecessor and codecessor Lucid dialects bound by the higher-order
intensional logic (HOIL) that is behind them. This work formally specifies the
operational aspects of the Forensic Lucid language and compiles a theory of its
constructs using Isabelle, a proof assistant system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3797</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3797</id><created>2009-04-24</created><updated>2009-04-27</updated><authors><author><keyname>Smith</keyname><forenames>Reginald D.</forenames></author></authors><title>Internet Traffic Periodicities and Oscillations: A Brief Review</title><categories>cs.NI</categories><comments>10 pages 2 figures; submitted to Computer Networks</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Internet traffic displays many persistent periodicities (oscillations) on a
large range of time scales. This paper describes the measurement methodology to
detect Internet traffic periodicities and also describes the main periodicities
in Internet traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3808</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3808</id><created>2009-04-24</created><updated>2009-04-24</updated><authors><author><keyname>Bao</keyname><forenames>Forrest Sheng</forenames></author><author><keyname>Gao</keyname><forenames>Jue-Ming</forenames></author><author><keyname>Hu</keyname><forenames>Jing</forenames></author><author><keyname>Lie</keyname><forenames>Donald Y. -C.</forenames></author><author><keyname>Zhang</keyname><forenames>Yuanlin</forenames></author><author><keyname>Oommen</keyname><forenames>K. J.</forenames></author></authors><title>Automated Epilepsy Diagnosis Using Interictal Scalp EEG</title><categories>cs.AI cs.CV</categories><comments>5 pages, 4 figures, 3 tables, based on our IEEE ICTAI'08 paper,
  submitted to IEEE EMBC'09</comments><acm-class>I.5.4; I.2.1</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Approximately over 50 million people worldwide suffer from epilepsy.
Traditional diagnosis of epilepsy relies on tedious visual screening by highly
trained clinicians from lengthy EEG recording that contains the presence of
seizure (ictal) activities. Nowadays, there are many automatic systems that can
recognize seizure-related EEG signals to help the diagnosis. However, it is
very costly and inconvenient to obtain long-term EEG data with seizure
activities, especially in areas short of medical resources. We demonstrate in
this paper that we can use the interictal scalp EEG data, which is much easier
to collect than the ictal data, to automatically diagnose whether a person is
epileptic. In our automated EEG recognition system, we extract three classes of
features from the EEG data and build Probabilistic Neural Networks (PNNs) fed
with these features. We optimize the feature extraction parameters and combine
these PNNs through a voting mechanism. As a result, our system achieves an
impressive 94.07% accuracy, which is very close to reported human recognition
accuracy by experienced medical professionals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3827</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3827</id><created>2009-04-24</created><authors><author><keyname>Valibouze</keyname><forenames>Annick</forenames><affiliation>LSTA, Lip6</affiliation></author></authors><title>La R\'esolvante de Lagrange et ses Applications</title><categories>cs.SC</categories><comments>26 pages</comments><proxy>ccsd hal-00376921</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the changes of representations of a group are used in order to
describe its action as algebraic Galois group of an univariate polynomial on
the roots of factors of any Lagrange resolvent. By this way, the Galois group
of resolvent factors are pre-determinated. In follows, different applications
are exposed; in particular, some classical results of algebraic Galois theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3894</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3894</id><created>2009-04-24</created><updated>2009-04-30</updated><authors><author><keyname>B&#xfc;hler</keyname><forenames>J.</forenames></author><author><keyname>Wunder</keyname><forenames>G.</forenames></author></authors><title>On Capacity Computation for the Two-User Binary Multiple-Access Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, IEEE International Symposium on Information Theory (ISIT)
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with the problem of computing the boundary of the capacity
region for the memoryless two-user binary-input binary-output multiple-access
channel ((2,2;2)-MAC), or equivalently, the computation of input probability
distributions maximizing weighted sum-rate. This is equivalent to solving a
difficult nonconvex optimization problem. For a restricted class of
(2,2;2)-MACs and weight vectors, it is shown that, depending on an ordering
property of the channel matrix, the optimal solution is located on the
boundary, or the objective function has at most one stationary point in the
interior of the domain. For this, the problem is reduced to a pseudoconcave
one-dimensional optimization and the single-user problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3898</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3898</id><created>2009-04-24</created><updated>2009-04-25</updated><authors><author><keyname>Fouz</keyname><forenames>Mahmoud</forenames></author><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author><author><keyname>Manthey</keyname><forenames>Bodo</forenames></author><author><keyname>Jahromi</keyname><forenames>Nima Zeini</forenames></author></authors><title>On Smoothed Analysis of Quicksort and Hoare's Find</title><categories>cs.DS</categories><comments>To be presented at the 15th Int. Computing and Combinatorics
  Conference (COCOON 2009)</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a smoothed analysis of Hoare's find algorithm and we revisit the
smoothed analysis of quicksort.
  Hoare's find algorithm - often called quickselect - is an easy-to-implement
algorithm for finding the k-th smallest element of a sequence. While the
worst-case number of comparisons that Hoare's find needs is quadratic, the
average-case number is linear. We analyze what happens between these two
extremes by providing a smoothed analysis of the algorithm in terms of two
different perturbation models: additive noise and partial permutations.
  Moreover, we provide lower bounds for the smoothed number of comparisons of
quicksort and Hoare's find for the median-of-three pivot rule, which usually
yields faster algorithms than always selecting the first element: The pivot is
the median of the first, middle, and last element of the sequence. We show that
median-of-three does not yield a significant improvement over the classic rule:
the lower bounds for the classic rule carry over to median-of-three.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3912</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3912</id><created>2009-04-24</created><updated>2009-05-14</updated><authors><author><keyname>Ferraro</keyname><forenames>Frank</forenames></author><author><keyname>Hall</keyname><forenames>Garrett</forenames></author><author><keyname>Wood</keyname><forenames>Andrew</forenames></author></authors><title>Refutation of Aslam's Proof that NP = P</title><categories>cs.CC</categories><comments>13 pages, 2 figures, a response to Aslam's paper (arXiv:0812.1385v11)
  and the underlying arguments (arXiv:0812.1385v9). Very minor content changes
  and typos fixed</comments><acm-class>F.2.0; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aslam presents an algorithm he claims will count the number of perfect
matchings in any incomplete bipartite graph with an algorithm in the
function-computing version of NC, which is itself a subset of FP. Counting
perfect matchings is known to be #P-complete; therefore if Aslam's algorithm is
correct, then NP=P. However, we show that Aslam's algorithm does not correctly
count the number of perfect matchings and offer an incomplete bipartite graph
as a concrete counter-example.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3927</identifier>
 <datestamp>2009-04-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3927</id><created>2009-04-24</created><authors><author><keyname>Richardson</keyname><forenames>Andrew Keenan</forenames></author><author><keyname>Brown</keyname><forenames>Cole Arthur</forenames></author></authors><title>A Critique of &quot;Solving the P/NP Problem Under Intrinsic Uncertainty&quot;,
  arXiv:0811.0463</title><categories>cs.CC</categories><comments>7 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Although whether P equals NP is an important, open problem in computer
science, and although Jaeger's 2008 paper, &quot;Solving the P/NP Problem Under
Intrinsic Uncertainty&quot; (arXiv:0811.0463) presents an attempt at tackling the
problem by discussing the possibility that all computation is uncertain to some
degree, there are a number of logical oversights present in that paper which
preclude it from serious consideration toward having resolved P-versus-NP.
There are several differences between the model of computation presented in
Jaeger's paper and the standard model, as well as several bold assumptions that
are not well supported in Jaeger's paper or in the literature. In addition, we
find several omissions of rigorous proof that ultimately weaken this paper to a
point where it cannot be considered a candidate solution to the P-versus-NP
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3941</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3941</id><created>2009-04-24</created><authors><author><keyname>Dutta</keyname><forenames>Sagarmoy</forenames></author><author><keyname>Kurur</keyname><forenames>Piyush P</forenames></author></authors><title>Representating groups on graphs</title><categories>cs.CC</categories><comments>13 pages, 2 figures</comments><doi>10.1007/978-3-642-03816-7_26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we formulate and study the problem of representing groups on
graphs. We show that with respect to polynomial time turing reducibility, both
abelian and solvable group representability are all equivalent to graph
isomorphism, even when the group is presented as a permutation group via
generators. On the other hand, the representability problem for general groups
on trees is equivalent to checking, given a group $G$ and $n$, whether a
nontrivial homomorphism from $G$ to $S_n$ exists. There does not seem to be a
polynomial time algorithm for this problem, in spite of the fact that tree
isomorphism has polynomial time algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3944</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3944</id><created>2009-04-24</created><authors><author><keyname>Ward</keyname><forenames>Christopher O.</forenames></author></authors><title>Better Global Polynomial Approximation for Image Rectification</title><categories>cs.CV cs.RO</categories><doi>10.2316/Journal.205.2008.3.205-4669</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When using images to locate objects, there is the problem of correcting for
distortion and misalignment in the images. An elegant way of solving this
problem is to generate an error correcting function that maps points in an
image to their corrected locations. We generate such a function by fitting a
polynomial to a set of sample points. The objective is to identify a polynomial
that passes &quot;sufficiently close&quot; to these points with &quot;good&quot; approximation of
intermediate points. In the past, it has been difficult to achieve good global
polynomial approximation using only sample points. We report on the development
of a global polynomial approximation algorithm for solving this problem. Key
Words: Polynomial approximation, interpolation, image rectification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.3953</identifier>
 <datestamp>2010-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.3953</id><created>2009-04-24</created><updated>2010-02-21</updated><authors><author><keyname>Marek</keyname><forenames>V. W.</forenames></author><author><keyname>Remmel</keyname><forenames>J. B.</forenames></author></authors><title>Guarded resolution for answer set programming</title><categories>cs.AI</categories><comments>13 pages, some results added. Accepted for publication at TPLP</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a variant of resolution rule of proof and show that it is
complete for stable semantics of logic programs. We show applications of this
result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4006</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4006</id><created>2009-04-26</created><authors><author><keyname>Rajesh</keyname><forenames>R.</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author><author><keyname>Varshenya</keyname><forenames>V. K.</forenames></author></authors><title>Joint Source-Channel Coding on a Multiple Access Channel with Side
  Information</title><categories>cs.IT math.IT</categories><comments>29 pages, 3 figures. Submitted to IEEE Trans. Information theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of transmission of several distributed correlated
sources over a multiple access channel (MAC) with side information at the
sources and the decoder. Source-channel separation does not hold for this
channel. Sufficient conditions are provided for transmission of sources with a
given distortion. The source and/or the channel could have continuous alphabets
(thus Gaussian sources and Gaussian MACs are special cases). Various previous
results are obtained as special cases. We also provide several good joint
source-channel coding schemes for discrete sources and discrete/continuous
alphabet channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4010</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4010</id><created>2009-04-27</created><authors><author><keyname>Timme</keyname><forenames>Marc</forenames></author><author><keyname>van Bussel</keyname><forenames>Frank</forenames></author><author><keyname>Fliegner</keyname><forenames>Denny</forenames></author><author><keyname>Stolzenberg</keyname><forenames>Sebastian</forenames></author></authors><title>Counting Complex Disordered States by Efficient Pattern Matching:
  Chromatic Polynomials and Potts Partition Functions</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.SC math.CO</categories><comments>7 pages, 4 figures</comments><journal-ref>New J. Phys. 11:023001 (2009); freely available online</journal-ref><doi>10.1088/1367-2630/11/2/023001</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Counting problems, determining the number of possible states of a large
system under certain constraints, play an important role in many areas of
science. They naturally arise for complex disordered systems in physics and
chemistry, in mathematical graph theory, and in computer science. Counting
problems, however, are among the hardest problems to access computationally.
Here, we suggest a novel method to access a benchmark counting problem, finding
chromatic polynomials of graphs. We develop a vertex-oriented symbolic pattern
matching algorithm that exploits the equivalence between the chromatic
polynomial and the zero-temperature partition function of the Potts
antiferromagnet on the same graph. Implementing this bottom-up algorithm using
appropriate computer algebra, the new method outperforms standard top-down
methods by several orders of magnitude, already for moderately sized graphs. As
a first application, we compute chromatic polynomials of samples of the simple
cubic lattice, for the first time computationally accessing three-dimensional
lattices of physical relevance. The method offers straightforward
generalizations to several other counting problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4030</identifier>
 <datestamp>2010-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4030</id><created>2009-04-27</created><updated>2010-04-02</updated><authors><author><keyname>Yao</keyname><forenames>Yong</forenames></author></authors><title>Successive Difference Substitution Based on Column Stochastic Matrix and
  Mechanical Decision for Positive Semi-definite Forms</title><categories>cs.SC</categories><comments>LaTeX; 18 pages</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory part of this paper is sketched as follows. Based on column
stochastic average matrix $T_n$ selected as a basic substitution matrix, the
method of advanced successive difference substitution is established. Then, a
set of necessary and sufficient conditions for deciding positive semi-definite
form on $\R^n_+$ is derived from this method. And furthermore, it is proved
that the sequence of SDS sets of a positive definite form is positively
terminating.
  Worked out according to these results, the Maple program TSDS3 not only
automatically proves the polynomial inequalities, but also outputs counter
examples for the false. Sometimes TSDS3 does not halt, but it is very useful by
experimenting on so many examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4041</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4041</id><created>2009-04-26</created><authors><author><keyname>Luo</keyname><forenames>Jie</forenames></author><author><keyname>Nascimento</keyname><forenames>Mario A.</forenames></author></authors><title>Content-Based Sub-Image Retrieval with Relevance Feedback</title><categories>cs.DB cs.IR</categories><comments>A preliminary version of this paper appeared in the Proceedings of
  the 1st ACM International Workshop on Multimedia Databases, p. 63-69. 2003</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The typical content-based image retrieval problem is to find images within a
database that are similar to a given query image. This paper presents a
solution to a different problem, namely that of content based sub-image
retrieval, i.e., finding images from a database that contains another image.
Note that this is different from finding a region in a (segmented) image that
is similar to another image region given as a query. We present a technique for
CBsIR that explores relevance feedback, i.e., the user's input on intermediary
results, in order to improve retrieval efficiency. Upon modeling images as a
set of overlapping and recursive tiles, we use a tile re-weighting scheme that
assigns penalties to each tile of the database images and updates the tile
penalties for all relevant images retrieved at each iteration using both the
relevant and irrelevant images identified by the user. Each tile is modeled by
means of its color content using a compact but very efficient method which can,
indirectly, capture some notion of texture as well, despite the fact that only
color information is maintained. Performance evaluation on a largely
heterogeneous dataset of over 10,000 images shows that the system can achieve a
stable average recall value of 70% within the top 20 retrieved (and presented)
images after only 5 iterations, with each such iteration taking about 2 seconds
on an off-the-shelf desktop computer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4048</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4048</id><created>2009-04-26</created><authors><author><keyname>Chettibi</keyname><forenames>Saloua</forenames></author></authors><title>Un protocole de routage \`a basse consommation d'\'energie pour les
  MANETs</title><categories>cs.NI</categories><proxy>ccsd hal-00375519</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maximizing network lifetime is a very challenging issue in routing protocol
design for Mobile Ad-hoc NETworks (MANETs), since mobile nodes are powered by
limited-capacity batteries. Furthermore, replacing or recharging batteries is
often impossible in critical environments (e.g. battlefields, disaster areas,
etc.). Energy consumption was considered for a long time equivalent to
bandwidth consumption. However, recent works have shown that &quot;energy&quot; and
&quot;bandwidth&quot; are substantially different metrics. Moreover, it was found that
traditional routing policies such as &quot;the shortest path&quot; one can have a
negative impact on energy consumption balance. Therefore, several new
approaches have been proposed addressing energy efficiency explicitly. Our work
is related to energy efficient routing for MANETs' problem. The proposed
MEA-DSR (Multipath Energy-Aware on Demand Source Routing) protocol is based on
a load sharing strategy between mobile nodes in order to maximize network
lifetime. To achieve this goal, we used multipath routing; nodes' residual
energies and paths length were also considered when making routing decisions.
Simulation results have shown the efficiency of the proposed protocol under
difficult scenarios characterised by high mobility, high density and important
traffic load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4057</identifier>
 <datestamp>2009-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4057</id><created>2009-04-26</created><updated>2009-10-27</updated><authors><author><keyname>Kong</keyname><forenames>Zhenning</forenames></author><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Soljanin</keyname><forenames>Emina</forenames></author></authors><title>Decentralized Coding Algorithms for Distributed Storage in Wireless
  Sensor Networks</title><categories>cs.IT cs.DS cs.NI math.IT</categories><comments>Accepted for publication in IEEE JSAC, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider large-scale wireless sensor networks with $n$ nodes, out of which
k are in possession, (e.g., have sensed or collected in some other way) k
information packets. In the scenarios in which network nodes are vulnerable
because of, for example, limited energy or a hostile environment, it is
desirable to disseminate the acquired information throughout the network so
that each of the n nodes stores one (possibly coded) packet so that the
original k source packets can be recovered, locally and in a computationally
simple way from any k(1 + \epsilon) nodes for some small \epsilon &gt; 0. We
develop decentralized Fountain codes based algorithms to solve this problem.
Unlike all previously developed schemes, our algorithms are truly distributed,
that is, nodes do not know n, k or connectivity in the network, except in their
own neighborhoods, and they do not maintain any routing tables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4058</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4058</id><created>2009-04-26</created><authors><author><keyname>Arnold</keyname><forenames>Jeff</forenames></author><author><keyname>Abbott</keyname><forenames>Tim</forenames></author><author><keyname>Daher</keyname><forenames>Waseem</forenames></author><author><keyname>Price</keyname><forenames>Gregory</forenames></author><author><keyname>Elhage</keyname><forenames>Nelson</forenames></author><author><keyname>Thomas</keyname><forenames>Geoffrey</forenames></author><author><keyname>Kaseorg</keyname><forenames>Anders</forenames></author></authors><title>Security impact ratings considered harmful</title><categories>cs.CR</categories><comments>HotOS 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we question the common practice of assigning security impact
ratings to OS updates. Specifically, we present evidence that ranking updates
by their perceived security importance, in order to defer applying some
updates, exposes systems to significant risk.
  We argue that OS vendors and security groups should not focus on security
updates to the detriment of other updates, but should instead seek update
technologies that make it feasible to distribute updates for all disclosed OS
bugs in a timely manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4061</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4061</id><created>2009-04-27</created><authors><author><keyname>Chan</keyname><forenames>Agnes</forenames></author><author><keyname>Rajaraman</keyname><forenames>Rajmohan</forenames></author><author><keyname>Sun</keyname><forenames>Zhifeng</forenames></author><author><keyname>Zhu</keyname><forenames>Feng</forenames></author></authors><title>Approximation Algorithms for Key Management in Secure Multicast</title><categories>cs.DS</categories><comments>COCOON 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many data dissemination and publish-subscribe systems that guarantee the
privacy and authenticity of the participants rely on symmetric key
cryptography. An important problem in such a system is to maintain the shared
group key as the group membership changes. We consider the problem of
determining a key hierarchy that minimizes the average communication cost of an
update, given update frequencies of the group members and an edge-weighted
undirected graph that captures routing costs. We first present a
polynomial-time approximation scheme for minimizing the average number of
multicast messages needed for an update. We next show that when routing costs
are considered, the problem is NP-hard even when the underlying routing network
is a tree network or even when every group member has the same update
frequency. Our main result is a polynomial time constant-factor approximation
algorithm for the general case where the routing network is an arbitrary
weighted graph and group members have nonuniform update frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4064</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4064</id><created>2009-04-26</created><updated>2010-02-03</updated><authors><author><keyname>Emiris</keyname><forenames>Ioannis Z.</forenames></author><author><keyname>Mantzaflaris</keyname><forenames>Angelos</forenames></author></authors><title>Multihomogeneous Resultant Formulae for Systems with Scaled Support</title><categories>cs.SC math.AG</categories><comments>28 pages, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constructive methods for matrices of multihomogeneous (or multigraded)
resultants for unmixed systems have been studied by Weyman, Zelevinsky,
Sturmfels, Dickenstein and Emiris. We generalize these constructions to mixed
systems, whose Newton polytopes are scaled copies of one polytope, thus taking
a step towards systems with arbitrary supports. First, we specify matrices
whose determinant equals the resultant and characterize the systems that admit
such formulae. Bezout-type determinantal formulae do not exist, but we describe
all possible Sylvester-type and hybrid formulae. We establish tight bounds for
all corresponding degree vectors, and specify domains that will surely contain
such vectors; the latter are new even for the unmixed case. Second, we make use
of multiplication tables and strong duality theory to specify resultant
matrices explicitly, for a general scaled system, thus including unmixed
systems. The encountered matrices are classified; these include a new type of
Sylvester-type matrix as well as Bezout-type matrices, known as partial
Bezoutians. Our public-domain Maple implementation includes efficient storage
of complexes in memory, and construction of resultant matrices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4073</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4073</id><created>2009-04-26</created><authors><author><keyname>Ghernaouti-Helie</keyname><forenames>Solange</forenames></author><author><keyname>Tashi</keyname><forenames>Igli</forenames></author><author><keyname>Laenger</keyname><forenames>Thomas</forenames></author><author><keyname>Monyk</keyname><forenames>Christian</forenames></author></authors><title>SECOQC Business White Paper</title><categories>quant-ph cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In contemporary cryptographic systems, secret keys are usually exchanged by
means of methods, which suffer from mathematical and technology inherent
drawbacks. That could lead to unnoticed complete compromise of cryptographic
systems, without a chance of control by its legitimate owners. Therefore a need
for innovative solutions exists when truly and reliably secure transmission of
secrets is required for dealing with critical data and applications. Quantum
Cryptography (QC), in particular Quantum Key Distribution (QKD) can answer that
need.
  The business white paper (BWP) summarizes how secret key establishment and
distribution problems can be solved by quantum cryptography. It deals with
several considerations related to how the quantum cryptography innovation could
contribute to provide business effectiveness. It addresses advantages and also
limitations of quantum cryptography, proposes a scenario case study, and
invokes standardization related issues. In addition, it answers most frequently
asked questions about quantum cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4094</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4094</id><created>2009-04-27</created><authors><author><keyname>Yang</keyname><forenames>Jiansheng</forenames></author><author><keyname>Zhang</keyname><forenames>Yunying</forenames></author></authors><title>On the Upper Bounds of MDS Codes</title><categories>math.CO cs.IT math.IT</categories><comments>8 Pages</comments><msc-class>05E20, 94B05, 94B65</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Let $M_{q}(k)$ be the maximum length of MDS codes with parameters $q,k$. In
this paper, the properties of $M_{q}(k)$ are studied, and some new upper bounds
of $M_{q}(k)$ are obtained. Especially we obtain that $M_{q}(q-1)\leq
q+2(q\equiv4(mod 6)), M_{q}(q-2)\leq q+1(q\equiv4(mod 6)), M_{q}(k)\leq q+k-3
(q=36(5s+1), s\in N$ and $ k=6,7).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4119</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4119</id><created>2009-04-27</created><updated>2009-08-05</updated><authors><author><keyname>Bojanczyk</keyname><forenames>Mikolaj</forenames></author></authors><title>Two-Way Unary Temporal Logic over Trees</title><categories>cs.LO</categories><comments>29 pages. Journal version of a LICS 07 paper</comments><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (August 5,
  2009) lmcs:917</journal-ref><doi>10.2168/LMCS-5(3:5)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a temporal logic EF+F^-1 for unranked, unordered finite trees.
The logic has two operators: EF\phi, which says &quot;in some proper descendant \phi
holds&quot;, and F^-1\phi, which says &quot;in some proper ancestor \phi holds&quot;. We
present an algorithm for deciding if a regular language of unranked finite
trees can be expressed in EF+F^-1. The algorithm uses a characterization
expressed in terms of forest algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4120</identifier>
 <datestamp>2012-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4120</id><created>2009-04-27</created><updated>2012-08-02</updated><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Martini</keyname><forenames>Simone</forenames></author></authors><title>On Constructor Rewrite Systems and the Lambda-Calculus (Long Version)</title><categories>cs.PL cs.LO</categories><comments>20 pages. Extended version of a paper in the proceedings of ICALP
  2009, Track B</comments><acm-class>F.1.1; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that orthogonal constructor term rewrite systems and lambda-calculus
with weak (i.e., no reduction is allowed under the scope of a
lambda-abstraction) call-by-value reduction can simulate each other with a
linear overhead. In particular, weak call-by-value beta-reduction can be
simulated by an orthogonal constructor term rewrite system in the same number
of reduction steps. Conversely, each reduction in a term rewrite system can be
simulated by a constant number of beta-reduction steps. This is relevant to
implicit computational complexity, because the number of beta steps to normal
form is polynomially related to the actual cost (that is, as performed on a
Turing machine) of normalization, under weak call-by-value reduction.
Orthogonal constructor term rewrite systems and lambda-calculus are thus both
polynomially related to Turing machines, taking as notion of cost their natural
parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4152</identifier>
 <datestamp>2010-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4152</id><created>2009-04-27</created><authors><author><keyname>van Dyk</keyname><forenames>Danny</forenames></author><author><keyname>Geveler</keyname><forenames>Markus</forenames></author><author><keyname>Mallach</keyname><forenames>Sven</forenames></author><author><keyname>Ribbrock</keyname><forenames>Dirk</forenames></author><author><keyname>Goeddeke</keyname><forenames>Dominik</forenames></author><author><keyname>Gutwenger</keyname><forenames>Carsten</forenames></author></authors><title>HONEI: A collection of libraries for numerical computations targeting
  multiple processor architectures</title><categories>cs.MS</categories><comments>19 pages, 7 figures</comments><report-no>DO-TH 09/05</report-no><acm-class>G.4</acm-class><journal-ref>Computer Physics Communications 180(12), pp. 2534-2543, December
  2009</journal-ref><doi>10.1016/j.cpc.2009.04.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present HONEI, an open-source collection of libraries offering a hardware
oriented approach to numerical calculations. HONEI abstracts the hardware, and
applications written on top of HONEI can be executed on a wide range of
computer architectures such as CPUs, GPUs and the Cell processor. We
demonstrate the flexibility and performance of our approach with two test
applications, a Finite Element multigrid solver for the Poisson problem and a
robust and fast simulation of shallow water waves. By linking against HONEI's
libraries, we achieve a twofold speedup over straight forward C++ code using
HONEI's SSE backend, and additional 3-4 and 4-16 times faster execution on the
Cell and a GPU. A second important aspect of our approach is that the full
performance capabilities of the hardware under consideration can be exploited
by adding optimised application-specific operations to the HONEI libraries.
HONEI provides all necessary infrastructure for development and evaluation of
such kernels, significantly simplifying their development.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4155</identifier>
 <datestamp>2010-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4155</id><created>2009-04-27</created><updated>2010-08-20</updated><authors><author><keyname>Cho</keyname><forenames>Jeong-woo</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author></authors><title>Fundamentals of the Backoff Process in 802.11: Dichotomy of the
  Aggregation</title><categories>cs.NI cs.PF</categories><comments>15 pages, 4 figures; An abstract version of this paper was presented
  at ACM SIGMETRICS Workshop on MAthematical performance Modeling and Analysis
  (MAMA 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discovers fundamental principles of the backoff process that
governs the performance of IEEE 802.11. A simplistic principle founded upon
regular variation theory is that the backoff time has a truncated Pareto-type
tail distribution with an exponent of $(\log \gamma)/\log m$ ($m$ is the
multiplicative factor and $\gamma$ is the collision probability). This reveals
that the per-node backoff process is heavy-tailed in the strict sense for
$\gamma&gt;1/m^2$, and paves the way for the following unifying result.
  The state-of-the-art theory on the superposition of the heavy-tailed
processes is applied to establish a dichotomy exhibited by the aggregate
backoff process, putting emphasis on the importance of time-scale on which we
view the backoff processes. While the aggregation on normal time-scales leads
to a Poisson process, it is approximated by a new limiting process possessing
long-range dependence (LRD) on coarse time-scales. This dichotomy turns out to
be instrumental in formulating short-term fairness, extending existing formulas
to arbitrary population, and to elucidate the absence of LRD in practical
situations. A refined wavelet analysis is conducted to strengthen this
argument.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4174</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4174</id><created>2009-04-27</created><authors><author><keyname>Ignatenko</keyname><forenames>O.</forenames></author></authors><title>Denial of service attack in the Internet: agent-based intrusion
  detection and reaction</title><categories>cs.NI cs.MA</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper deals with denial of service attack. Overview of the existing
attacks and methods is proposed. Classification scheme is presented for a
different denial of service attacks. There is considered agent-based intrusion
detection systems architecture. Considered main components and working
principles for a systems of such kind.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4176</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4176</id><created>2009-04-27</created><updated>2009-04-30</updated><authors><author><keyname>Bonnel</keyname><forenames>Nicolas</forenames><affiliation>VALORIA</affiliation></author><author><keyname>Marteau</keyname><forenames>Pierre-Fran&#xe7;ois</forenames><affiliation>VALORIA</affiliation></author><author><keyname>M&#xe9;nier</keyname><forenames>Gildas G.</forenames><affiliation>VALORIA</affiliation></author></authors><title>Parallel Random Apollonian Networks</title><categories>cs.DM</categories><comments>Working paper</comments><proxy>ccsd hal-00375016</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present and study in this paper a simple algorithm that produces so called
growing Parallel Random Apollonian Networks (P-RAN) in any dimension d.
Analytical derivations show that these networks still exhibit small-word and
scale-free characteristics. To characterize further the structure of P-RAN, we
introduce new parameters that we refer to as the parallel degree and the
parallel coefficient, that determine locally and in average the number of
vertices inside the (d+1)-cliques composing the network. We provide analytical
derivations for the computation of the degree and parallel degree
distributions, parallel and clustering coefficients. We give an upper bound for
the average path lengths for P-RAN and finally show that our derivations are in
very good agreement with our simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4181</identifier>
 <datestamp>2009-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4181</id><created>2009-04-27</created><authors><author><keyname>Alustwani</keyname><forenames>Husam</forenames></author><author><keyname>Bahi</keyname><forenames>Jacques M.</forenames></author><author><keyname>Mostefaoui</keyname><forenames>Ahmed</forenames></author><author><keyname>Salomon</keyname><forenames>Michel</forenames></author></authors><title>Java Technology : a Strategic Solution for Interactive Distributed
  Applications</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a world demanding the best performance from financial investments,
distributed applications occupy the first place among the proposed solutions.
This particularity is due to their distributed architecture which is able to
acheives high performance. Currently, many research works aim to develop tools
that facilitate the implementation of such applications. The urgent need for
such applications in all areas pushes researchers to accelerate this process.
However, the lack of standardization results in the absence of strategic
decisions taken by computer science community. In this article, we argue that
Java technology represents an elegant compromise ahead of the list of the
currently available solutions. In fact, by promoting the independence of
hardware and software, Java technology makes it possible to overcome pitfalls
that are inherent to the creation of distributed applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4193</identifier>
 <datestamp>2009-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4193</id><created>2009-04-27</created><updated>2009-08-24</updated><authors><author><keyname>Dobzinski</keyname><forenames>Shahar</forenames></author><author><keyname>Dughmi</keyname><forenames>Shaddin</forenames></author></authors><title>On the Power of Randomization in Algorithmic Mechanism Design</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many settings the power of truthful mechanisms is severely bounded. In
this paper we use randomization to overcome this problem. In particular, we
construct an FPTAS for multi-unit auctions that is truthful in expectation,
whereas there is evidence that no polynomial-time truthful deterministic
mechanism provides an approximation ratio better than 2.
  We also show for the first time that truthful in expectation polynomial-time
mechanisms are \emph{provably} stronger than polynomial-time universally
truthful mechanisms. Specifically, we show that there is a setting in which:
(1) there is a non-polynomial time truthful mechanism that always outputs the
optimal solution, and that (2) no universally truthful randomized mechanism can
provide an approximation ratio better than 2 in polynomial time, but (3) an
FPTAS that is truthful in expectation exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4202</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4202</id><created>2009-04-27</created><updated>2010-11-16</updated><authors><author><keyname>Tournoux</keyname><forenames>Pierre-Ugo</forenames></author><author><keyname>Lochin</keyname><forenames>Emmanuel</forenames></author><author><keyname>Lacan</keyname><forenames>Jerome</forenames></author><author><keyname>Bouabdallah</keyname><forenames>Amine</forenames></author><author><keyname>Roca</keyname><forenames>Vincent</forenames></author></authors><title>On-the-fly erasure coding for real-time video applications</title><categories>cs.NI cs.MM</categories><doi>10.1109/TMM.2011.2126564</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a robust point-to-point transmission scheme: Tetrys,
that relies on a novel on-the-fly erasure coding concept which reduces the
delay for recovering lost data at the receiver side. In current erasure coding
schemes, the packets that are not rebuilt at the receiver side are either lost
or delayed by at least one RTT before transmission to the application. The
present contribution aims at demonstrating that Tetrys coding scheme can fill
the gap between real-time applications requirements and full reliability.
Indeed, we show that in several cases, Tetrys can recover lost packets below
one RTT over lossy and best-effort networks. We also show that Tetrys allows to
enable full reliability without delay compromise and as a result: significantly
improves the performance of time constrained applications. For instance, our
evaluations present that video-conferencing applications obtain a PSNR gain up
to 7dB compared to classic block-based erasure codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4283</identifier>
 <datestamp>2009-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4283</id><created>2009-04-27</created><authors><author><keyname>Shen</keyname><forenames>Cong</forenames></author><author><keyname>Fitz</keyname><forenames>Michael P.</forenames></author></authors><title>Opportunistic Spatial Orthogonalization and Its Application in Fading
  Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>26 pages, 6 figures, submitted for journal publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opportunistic Spatial Orthogonalization (OSO) is a cognitive radio scheme
that allows the existence of secondary users and hence increases the system
throughput, even if the primary user occupies all the frequency bands all the
time. Notably, this throughput advantage is obtained without sacrificing the
performance of the primary user, if the interference margin is carefully
chosen. The key idea is to exploit the spatial dimensions to orthogonalize
users and hence minimize interference. However, unlike the time and frequency
dimensions, there is no universal basis for the set of all multi-dimensional
spatial channels, which motivated the development of OSO. On one hand, OSO can
be viewed as a multi-user diversity scheme that exploits the channel randomness
and independence. On the other hand, OSO can be interpreted as an opportunistic
interference alignment scheme, where the interference from multiple secondary
users is opportunistically aligned at the direction that is orthogonal to the
primary user's signal space. In the case of multiple-input multiple-output
(MIMO) channels, the OSO scheme can be interpreted as &quot;riding the peaks&quot; over
the eigen-channels, and ill-conditioned MIMO channel, which is traditionally
viewed as detrimental, is shown to be beneficial with respect to the sum
throughput. Throughput advantages are thoroughly studied, both analytically and
numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4312</identifier>
 <datestamp>2009-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4312</id><created>2009-04-28</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Mumford</keyname><forenames>Elena</forenames></author></authors><title>Orientation-Constrained Rectangular Layouts</title><categories>cs.CG</categories><comments>To appear at Algorithms and Data Structures Symposium, Banff, Canada,
  August 2009. 12 pages, 5 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct partitions of rectangles into smaller rectangles from an input
consisting of a planar dual graph of the layout together with restrictions on
the orientations of edges and junctions of the layout. Such an
orientation-constrained layout, if it exists, may be constructed in polynomial
time, and all orientation-constrained layouts may be listed in polynomial time
per layout.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4331</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4331</id><created>2009-04-28</created><updated>2011-07-24</updated><authors><author><keyname>Manyem</keyname><forenames>Prabhu</forenames></author></authors><title>Lower Bounds on Syntactic Logic Expressions for Optimization Problems
  and Duality using Lagrangian Dual to characterize optimality conditions</title><categories>cs.LO cs.CC</categories><comments>An expansion of the previous version to include: a single call to a
  decision Turing machine to solve optimization problems obeying strong duality
  in polynomial time</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that simple syntactic expressions such as existential second order
(ESO) universal Horn formulae can express NP-hard optimisation problems. There
is a significant difference between the expressibilities of decision problems
and optimisation problems. This is similar to the difference in computation
times for the two classes of problems; for example, a 2SAT Horn formula can be
satisfied in polynomial time, whereas the optimisation version in NP-hard. It
is known that all polynomially solvable decision problems can be expressed as
ESO universal ($\Pi_1$) Horn sentences in the presence of a successor relation.
We show here that, on the other hand, if $P \neq NP$, optimisation problems
defy such a characterisation, by demonstrating that even a $\Pi_0$ (quantifier
free) Horn formula is unable to guarantee polynomial time solvability. Finally,
by connecting concepts in optimisation duality with those in descriptive
complexity, we will show a method by which optimisation problems can be solved
by a single call to a &quot;decision&quot; Turing machine, as opposed to multiple calls
using a classical binary search setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4343</identifier>
 <datestamp>2009-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4343</id><created>2009-04-28</created><authors><author><keyname>Tresch</keyname><forenames>Roland</forenames></author><author><keyname>Guillaud</keyname><forenames>Maxime</forenames></author><author><keyname>Riegler</keyname><forenames>Erwin</forenames></author></authors><title>On the Achievability of Interference Alignment in the K-User Constant
  MIMO Interference Channel</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Workshop on Statistical Signal Processing (SSP09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference alignment in the K-user MIMO interference channel with constant
channel coefficients is considered. A novel constructive method for finding the
interference alignment solution is proposed for the case where the number of
transmit antennas equals the number of receive antennas (NT = NR = N), the
number of transmitter-receiver pairs equals K = N + 1, and all interference
alignment multiplexing gains are one. The core of the method consists of
solving an eigenvalue problem that incorporates the channel matrices of all
interfering links. This procedure provides insight into the feasibility of
signal vector spaces alignment schemes in finite dimensional MIMO interference
channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4358</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4358</id><created>2009-04-28</created><updated>2011-07-20</updated><authors><author><keyname>Rabi</keyname><forenames>Maben</forenames></author><author><keyname>Moustakides</keyname><forenames>George V.</forenames></author><author><keyname>Baras</keyname><forenames>John S.</forenames></author></authors><title>Adaptive sampling for linear state estimation</title><categories>math.OC cs.SY math.PR math.ST stat.TH</categories><comments>Submitted to the SIAM journal on control and optimization. 32 pages,
  7 figures</comments><report-no>IR-EE-RT 2009:019</report-no><msc-class>93E10, 93E11, 62L15, 60G40, 60G35, 62L12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a sensor has continuous measurements but sends limited messages over a
data network to a supervisor which estimates the state, the available packet
rate fixes the achievable quality of state estimation. When such rate limits
turn stringent, the sensor's messaging policy should be designed anew. What are
the good causal messaging policies ? What should message packets contain ? What
is the lowest possible distortion in a causal estimate at the supervisor ? Is
Delta sampling better than periodic sampling ? We answer these questions under
an idealized model of the network and the assumption of perfect measurements at
the sensor. For a scalar, linear diffusion process, we study the problem of
choosing the causal sampling times that will give the lowest aggregate squared
error distortion. We stick to finite-horizons and impose a hard upper bound on
the number of allowed samples. We cast the design as a problem of choosing an
optimal sequence of stopping times. We reduce this to a nested sequence of
problems each asking for a single optimal stopping time. Under an unproven but
natural assumption about the least-square estimate at the supervisor, each of
these single stopping problems are of standard form. The optimal stopping times
are random times when the estimation error exceeds designed envelopes. For the
case where the state is a Brownian motion, we give analytically: the shape of
the optimal sampling envelopes, the shape of the envelopes under optimal Delta
sampling, and their performances. Surprisingly, we find that Delta sampling
performs badly. Hence, when the rate constraint is a hard limit on the number
of samples over a finite horizon, we should should not use Delta sampling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4360</identifier>
 <datestamp>2009-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4360</id><created>2009-04-28</created><authors><author><keyname>Bhattacharyya</keyname><forenames>Arnab</forenames></author><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author></authors><title>Robust Regulatory Networks</title><categories>q-bio.MN cs.CC q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the characteristic features of genetic networks is their inherent
robustness, that is, their ability to retain functionality in spite of the
introduction of random errors. In this paper, we seek to better understand how
robustness is achieved and what functionalities can be maintained robustly. Our
goal is to formalize some of the language used in biological discussions in a
reasonable mathematical framework, where questions can be answered in a
rigorous fashion. These results provide basic conceptual understanding of
robust regulatory networks that should be valuable independent of the details
of the formalism.
  We model the gene regulatory network as a boolean network, a general and
well-established model introduced by Stuart Kauffman. A boolean network is said
to be in a viable configuration if the node states of the network at its
fixpoint satisfy some given constraint. We specify how mutations affect the
behavior of the boolean network. A network is then said to be robust if most
random mutations to the network reach a viable configuration. The main question
investigated in our study is: given a constraint on the fixpoint configuration,
does there exist a network that is robust with respect to it and, if so, what
is its structure? We demonstrate both explicit constructions of robust networks
as well as negative results disproving their existence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4411</identifier>
 <datestamp>2009-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4411</id><created>2009-04-28</created><authors><author><keyname>Auzelle</keyname><forenames>Jean-Philippe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Nartz</keyname><forenames>Olivier</forenames><affiliation>AIP</affiliation></author><author><keyname>Bron</keyname><forenames>Jean-Yves</forenames><affiliation>CRAN, AIP</affiliation></author></authors><title>Ing\'enierie syst\`eme d'un syst\`eme d'information d'entreprise
  centr\'e sur le produit bas\'ee sur un cadre de mod\'elisation
  multi-\'echelles : application \`a un cas d'\'etude de l'AIP lorrain</title><categories>cs.SE</categories><proxy>ccsd hal-00378810</proxy><journal-ref>11\`eme Colloque National AIP PRIMECA, La Plagne : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Through its projects, the ?Atelier Inter-\'etablissements de Productique
Lorrain? (AIPL), as the owner and contractor of rank 1, is committed to provide
his customers (teachers, training courses, students etc...) credible teaching
materials at the scale of a real industrial flexible production of goods and
services. In this changing context, its managerial team has chosen to suppress
the CIM concept, which proposes an integrated enterprise, to steering
distributed system information (SI), heterogeneous, autonomous and scalable
depending on the ephemeral cooperation between industrial partners who now
exchanges information and material flows. These aspects are studied in research
on CRAN (Centre de Recherche en Automatique de Nancy ? Research Centre for
Automatic Control) as part of a thesis based on the recursive aspect of systems
and their models and their multi-scale aspects and multi-views, in a
Model-Based-System-Engineering (MBSE) methodology proposal of an
System-Engineering (SE) focused on the product. To validate this research, a
MBSE has been implemented on a case study to AIPL: the &quot;eLearning in
eProduction? project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4412</identifier>
 <datestamp>2009-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4412</id><created>2009-04-28</created><authors><author><keyname>Canteaut</keyname><forenames>Anne</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Naya-Plasencia</keyname><forenames>Maria</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Computing the biases of parity-check relations</title><categories>cs.CR</categories><proxy>ccsd hal-00379454</proxy><journal-ref>2009 IEEE International Symposium on Information Theory
  (ISIT2009), Seoul : Cor\'ee, R\'epublique de (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A divide-and-conquer cryptanalysis can often be mounted against some
keystream generators composed of several (nonlinear) independent devices
combined by a Boolean function. In particular, any parity-check relation
derived from the periods of some constituent sequences usually leads to a
distinguishing attack whose complexity is determined by the bias of the
relation. However, estimating this bias is a difficult problem since the
piling-up lemma cannot be used. Here, we give two exact expressions for this
bias. Most notably, these expressions lead to a new algorithm for computing the
bias of a parity-check relation, and they also provide some simple formulae for
this bias in some particular cases which are commonly used in cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4429</identifier>
 <datestamp>2009-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4429</id><created>2009-04-28</created><updated>2009-05-22</updated><authors><author><keyname>Orden</keyname><forenames>David</forenames></author><author><keyname>Ramos</keyname><forenames>Pedro</forenames></author><author><keyname>Salazar</keyname><forenames>Gelasio</forenames></author></authors><title>The number of generalized balanced lines</title><categories>math.CO cs.CG</categories><comments>6 pages, 3 figures, several typos fixed, reference added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $S$ be a set of $r$ red points and $b=r+2d$ blue points in general
position in the plane, with $d\geq 0$. A line $\ell$ determined by them is said
to be balanced if in each open half-plane bounded by $\ell$ the difference
between the number of red points and blue points is $d$. We show that every set
$S$ as above has at least $r$ balanced lines. The main techniques in the proof
are rotations and a generalization, sliding rotations, introduced here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4449</identifier>
 <datestamp>2009-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4449</id><created>2009-04-28</created><authors><author><keyname>Kencl</keyname><forenames>Lukas</forenames></author><author><keyname>Loebl</keyname><forenames>Martin</forenames></author></authors><title>DNA-Inspired Information Concealing</title><categories>cs.IT cs.CR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Protection of the sensitive content is crucial for extensive information
sharing. We present a technique of information concealing, based on
introduction and maintenance of families of repeats. Repeats in DNA constitute
a basic obstacle for its reconstruction by hybridization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4458</identifier>
 <datestamp>2010-04-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4458</id><created>2009-04-28</created><updated>2010-04-13</updated><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>Learning Character Strings via Mastermind Queries, with a Case Study
  Involving mtDNA</title><categories>cs.DS cs.CR cs.IT math.IT</categories><comments>Full version of related paper appearing in IEEE Symposium on Security
  and Privacy 2009, &quot;The Mastermind Attack on Genomic Data.&quot; This version
  corrects the proofs of what are now Theorems 2 and 4.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the degree to which a character string, $Q$, leaks details about
itself any time it engages in comparison protocols with a strings provided by a
querier, Bob, even if those protocols are cryptographically guaranteed to
produce no additional information other than the scores that assess the degree
to which $Q$ matches strings offered by Bob. We show that such scenarios allow
Bob to play variants of the game of Mastermind with $Q$ so as to learn the
complete identity of $Q$. We show that there are a number of efficient
implementations for Bob to employ in these Mastermind attacks, depending on
knowledge he has about the structure of $Q$, which show how quickly he can
determine $Q$. Indeed, we show that Bob can discover $Q$ using a number of
rounds of test comparisons that is much smaller than the length of $Q$, under
reasonable assumptions regarding the types of scores that are returned by the
cryptographic protocols and whether he can use knowledge about the distribution
that $Q$ comes from. We also provide the results of a case study we performed
on a database of mitochondrial DNA, showing the vulnerability of existing
real-world DNA data to the Mastermind attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4512</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4512</id><created>2009-04-28</created><authors><author><keyname>Salamon</keyname><forenames>Andr&#xe1;s Z.</forenames></author><author><keyname>Galpin</keyname><forenames>Vashti</forenames></author></authors><title>Bounds on series-parallel slowdown</title><categories>cs.DC cs.CC cs.PF</categories><comments>12 pages, 4 figures</comments><acm-class>D.1.3; D.3.3; D.4.8; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use activity networks (task graphs) to model parallel programs and
consider series-parallel extensions of these networks. Our motivation is
two-fold: the benefits of series-parallel activity networks and the modelling
of programming constructs, such as those imposed by current parallel computing
environments. Series-parallelisation adds precedence constraints to an activity
network, usually increasing its makespan (execution time). The slowdown ratio
describes how additional constraints affect the makespan. We disprove an
existing conjecture positing a bound of two on the slowdown when workload is
not considered. Where workload is known, we conjecture that 4/3 slowdown is
always achievable, and prove our conjecture for small networks using max-plus
algebra. We analyse a polynomial-time algorithm showing that achieving 4/3
slowdown is in exp-APX. Finally, we discuss the implications of our results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4525</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4525</id><created>2009-04-28</created><authors><author><keyname>Tune</keyname><forenames>Paul</forenames></author><author><keyname>Pillai</keyname><forenames>Sibiraj Bhaskaran</forenames></author><author><keyname>Hanly</keyname><forenames>Stephen</forenames></author></authors><title>Number of Measurements in Sparse Signal Recovery</title><categories>cs.IT math.IT</categories><comments>6 pages, 1 figure. Extended from conference version with proofs
  included</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the asymptotic performance of sparse signal recovery from noisy
measurements. In particular, we generalize some of the existing results for the
Gaussian case to subgaussian and other ensembles. An achievable result is
presented for the linear sparsity regime. A converse on the number of required
measurements in the sub-linear regime is also presented, which cover many of
the widely used measurement ensembles. Our converse idea makes use of a
correspondence between compressed sensing ideas and compound channels in
information theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4526</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4526</id><created>2009-04-28</created><authors><author><keyname>Yetis</keyname><forenames>Cenk M.</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Kayran</keyname><forenames>Ahmet H.</forenames></author></authors><title>Feasibility Conditions for Interference Alignment</title><categories>cs.IT cs.AR math.IT</categories><comments>6 pages. Submitted to IEEE Globecom March 31 2009</comments><journal-ref>IEEE Transactions on Signal Processing, Sep. 2010, Vol. 58, Issue:
  9, Pages: 4771-4782</journal-ref><doi>10.1109/TSP.2010.2050480</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The degrees of freedom of MIMO interference networks with constant channel
coefficients are not known in general. Determining the feasibility of a linear
interference alignment solution is a key step toward solving this open problem.
Our approach in this paper is to view the alignment problem as a system of
bilinear equations and determine its solvability by comparing the number of
equations and the number of variables. To this end, we divide interference
alignment problems into two classes - proper and improper. An interference
alignment problem is called proper if the number of equations does not exceed
the number of variables. Otherwise, it is called improper. Examples are
presented to support the intuition that for generic channel matrices, proper
systems are almost surely feasible and improper systems are almost surely
infeasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4527</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4527</id><created>2009-04-28</created><authors><author><keyname>Piatti</keyname><forenames>Alberto</forenames></author><author><keyname>Zaffalon</keyname><forenames>Marco</forenames></author><author><keyname>Trojani</keyname><forenames>Fabio</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Limits of Learning about a Categorical Latent Variable under Prior
  Near-Ignorance</title><categories>cs.LG</categories><comments>27 LaTeX pages</comments><journal-ref>International Journal of Approximate Reasoning, 50:4 (2009) pages
  597-611</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the coherent theory of (epistemic) uncertainty of
Walley, in which beliefs are represented through sets of probability
distributions, and we focus on the problem of modeling prior ignorance about a
categorical random variable. In this setting, it is a known result that a state
of prior ignorance is not compatible with learning. To overcome this problem,
another state of beliefs, called \emph{near-ignorance}, has been proposed.
Near-ignorance resembles ignorance very closely, by satisfying some principles
that can arguably be regarded as necessary in a state of ignorance, and allows
learning to take place. What this paper does, is to provide new and substantial
evidence that also near-ignorance cannot be really regarded as a way out of the
problem of starting statistical inference in conditions of very weak beliefs.
The key to this result is focusing on a setting characterized by a variable of
interest that is \emph{latent}. We argue that such a setting is by far the most
common case in practice, and we provide, for the case of categorical latent
variables (and general \emph{manifest} variables) a condition that, if
satisfied, prevents learning to take place under prior near-ignorance. This
condition is shown to be easily satisfied even in the most common statistical
problems. We regard these results as a strong form of evidence against the
possibility to adopt a condition of prior near-ignorance in real statistical
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4530</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4530</id><created>2009-04-29</created><authors><author><keyname>Li</keyname><forenames>Fei</forenames></author><author><keyname>Zhang</keyname><forenames>Zhi</forenames></author></authors><title>Online Maximizing Weighted Throughput In A Fading Channel</title><categories>cs.IT cs.DS math.IT</categories><comments>9 pages, appears in ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider online scheduling weighted packets with time constraints over a
fading channel. Packets arrive at the transmitter in an online manner. Each
packet has a value and a deadline by which it should be sent. The fade state of
the channel determines the throughput obtained per unit of time and the
channel's quality may change over time. In this paper, we design online
algorithms to maximize weighted throughput, defined as the total value of the
packets sent by their respective deadlines. Competitive ratio is employed to
measure an online algorithm's performance. For this problem and one of its
variants, we present two online algorithms with competitive ratios 2.618 and 2
respectively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4541</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4541</id><created>2009-04-29</created><updated>2011-05-28</updated><authors><author><keyname>Gohari</keyname><forenames>Amin Aminzadeh</forenames></author><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author></authors><title>Evaluation of Marton's Inner Bound for the General Broadcast Channel</title><categories>cs.IT math.IT</categories><comments>29 pages, 2 figures. Submitted to the IEEE Transactions on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The best known inner bound on the two-receiver general broadcast channel
without a common message is due to Marton [3]. This result was subsequently
generalized in [p. 391, Problem 10(c) 2] and [4] to broadcast channels with a
common message. However the latter region is not computable (except in certain
special cases) as no bounds on the cardinality of its auxiliary random
variables exist. Nor is it even clear that the inner bound is a closed set. The
main obstacle in proving cardinality bounds is the fact that the traditional
use of the Carath\'{e}odory theorem, the main known tool for proving
cardinality bounds, does not yield a finite cardinality result. One of the main
contributions of this paper is the introduction of a new tool based on an
identity that relates the second derivative of the Shannon entropy of a
discrete random variable (under a certain perturbation) to the corresponding
Fisher information. In order to go beyond the traditional Carath\'{e}odory type
arguments, we identify certain properties that the auxiliary random variables
corresponding to the extreme points of the inner bound need to satisfy. These
properties are then used to establish cardinality bounds on the auxiliary
random variables of the inner bound, thereby proving the computability of the
region, and its closedness.
  Lastly, we establish a conjecture of \cite{NairZizhou} that Marton's inner
bound and the recent outer bound of Nair and El Gamal do not match in general.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4542</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4542</id><created>2009-04-29</created><authors><author><keyname>Gohari</keyname><forenames>Amin Aminzadeh</forenames></author><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author></authors><title>A Generalized Cut-Set Bound</title><categories>cs.IT math.IT</categories><comments>22 pages, 1 figure, a short version of it appears in ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we generalize the well known cut-set bound to the problem of
lossy transmission of functions of arbitrarily correlated sources over a
discrete memoryless multiterminal network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4587</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4587</id><created>2009-04-29</created><authors><author><keyname>Torres-Moreno</keyname><forenames>Juan-Manuel</forenames></author><author><keyname>Gordon</keyname><forenames>Mirta B.</forenames></author></authors><title>Adaptive Learning with Binary Neurons</title><categories>cs.AI cs.NE</categories><comments>29 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A efficient incremental learning algorithm for classification tasks, called
NetLines, well adapted for both binary and real-valued input patterns is
presented. It generates small compact feedforward neural networks with one
hidden layer of binary units and binary output units. A convergence theorem
ensures that solutions with a finite number of hidden units exist for both
binary and real-valued input patterns. An implementation for problems with more
than two classes, valid for any binary classifier, is proposed. The
generalization error and the size of the resulting networks are compared to the
best published results on well-known classification benchmarks. Early stopping
is shown to decrease overfitting, without improving the generalization
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4600</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4600</id><created>2009-04-29</created><updated>2009-11-18</updated><authors><author><keyname>Engstr&#xf6;m</keyname><forenames>Robert</forenames></author><author><keyname>F&#xe4;rnqvist</keyname><forenames>Tommy</forenames></author><author><keyname>Jonsson</keyname><forenames>Peter</forenames></author><author><keyname>Thapper</keyname><forenames>Johan</forenames></author></authors><title>Graph Homomorphisms, Circular Colouring, and Fractional Covering by
  H-cuts</title><categories>cs.DM</categories><comments>24 pages, 1 figure Corrected the statements of Lemma 4.3 and 4.4</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph homomorphism is a vertex map which carries edges from a source graph
to edges in a target graph. The instances of the Weighted Maximum H-Colourable
Subgraph problem (MAX H-COL) are edge-weighted graphs G and the objective is to
find a subgraph of G that has maximal total edge weight, under the condition
that the subgraph has a homomorphism to H; note that for H=K_k this problem is
equivalent to MAX k-CUT. Farnqvist et al. have introduced a parameter on the
space of graphs that allows close study of the approximability properties of
MAX H-COL. Specifically, it can be used to extend previously known
(in)approximability results to larger classes of graphs. Here, we investigate
the properties of this parameter on circular complete graphs K_{p/q}, where 2
&lt;= p/q &lt;= 3. The results are extended to K_4-minor-free graphs and graphs with
bounded maximum average degree. We also consider connections with Samal's work
on fractional covering by cuts: we address, and decide, two conjectures
concerning cubical chromatic numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4608</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4608</id><created>2009-04-29</created><updated>2009-04-30</updated><authors><author><keyname>Laxman</keyname><forenames>Srivatsan</forenames></author><author><keyname>Shadid</keyname><forenames>Basel</forenames></author><author><keyname>Sastry</keyname><forenames>P. S.</forenames></author><author><keyname>Unnikrishnan</keyname><forenames>K. P.</forenames></author></authors><title>Temporal data mining for root-cause analysis of machine faults in
  automotive assembly lines</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Engine assembly is a complex and heavily automated distributed-control
process, with large amounts of faults data logged everyday. We describe an
application of temporal data mining for analyzing fault logs in an engine
assembly plant. Frequent episode discovery framework is a model-free method
that can be used to deduce (temporal) correlations among events from the logs
in an efficient manner. In addition to being theoretically elegant and
computationally efficient, frequent episodes are also easy to interpret in the
form actionable recommendations. Incorporation of domain-specific information
is critical to successful application of the method for analyzing fault logs in
the manufacturing domain. We show how domain-specific knowledge can be
incorporated using heuristic rules that act as pre-filters and post-filters to
frequent episode discovery. The system described here is currently being used
in one of the engine assembly plants of General Motors and is planned for
adaptation in other plants. To the best of our knowledge, this paper presents
the first real, large-scale application of temporal data mining in the
manufacturing domain. We believe that the ideas presented in this paper can
help practitioners engineer tools for analysis in other similar or related
application domains as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4615</identifier>
 <datestamp>2011-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4615</id><created>2009-04-29</created><updated>2011-02-10</updated><authors><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>INRIA Rocquencourt, LIP6</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>INRIA Rocquencourt, LIP6</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Dynamic FTSS in Asynchronous Systems: the Case of Unison</title><categories>cs.DS cs.NI</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed fault-tolerance can mask the effect of a limited number of
permanent faults, while self-stabilization provides forward recovery after an
arbitrary number of transient fault hit the system. FTSS protocols combine the
best of both worlds since they are simultaneously fault-tolerant and
self-stabilizing. To date, FTSS solutions either consider static (i.e. fixed
point) tasks, or assume synchronous scheduling of the system components. In
this paper, we present the first study of dynamic tasks in asynchronous
systems, considering the unison problem as a benchmark. Unison can be seen as a
local clock synchronization problem as neighbors must maintain digital clocks
at most one time unit away from each other, and increment their own clock value
infinitely often. We present many impossibility results for this difficult
problem and propose a FTSS solution when the problem is solvable that exhibits
optimal fault containment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4670</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4670</id><created>2009-04-29</created><authors><author><keyname>Atallah</keyname><forenames>Mikhail J.</forenames></author><author><keyname>Blanton</keyname><forenames>Marina</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Polu</keyname><forenames>Stanislas</forenames></author></authors><title>Discrepancy-Sensitive Dynamic Fractional Cascading, Dominated Maxima
  Searching, and 2-d Nearest Neighbors in Any Minkowski Metric</title><categories>cs.DS cs.CG</categories><comments>Expanded version of a paper that appeared in WADS 2007</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a discrepancy-sensitive approach to dynamic fractional
cascading. We provide an efficient data structure for dominated maxima
searching in a dynamic set of points in the plane, which in turn leads to an
efficient dynamic data structure that can answer queries for nearest neighbors
using any Minkowski metric. We provide an efficient data structure for
dominated maxima searching in a dynamic set of points in the plane, which in
turn leads to an efficient dynamic data structure that can answer queries for
nearest neighbors using any Minkowski metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4686</identifier>
 <datestamp>2009-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4686</id><created>2009-04-29</created><authors><author><keyname>Allauzen</keyname><forenames>Cyril</forenames></author><author><keyname>Mohri</keyname><forenames>Mehryar</forenames></author></authors><title>Linear-Space Computation of the Edit-Distance between a String and a
  Finite Automaton</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of computing the edit-distance between a string and a finite
automaton arises in a variety of applications in computational biology, text
processing, and speech recognition. This paper presents linear-space algorithms
for computing the edit-distance between a string and an arbitrary weighted
automaton over the tropical semiring, or an unambiguous weighted automaton over
an arbitrary semiring. It also gives an efficient linear-space algorithm for
finding an optimal alignment of a string and such a weighted automaton.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4708</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4708</id><created>2009-04-29</created><authors><author><keyname>Tsatsaronis</keyname><forenames>George</forenames></author><author><keyname>Halkidi</keyname><forenames>Maria</forenames></author><author><keyname>Giakoumakis</keyname><forenames>Emmanouel A.</forenames></author></authors><title>Quality Classifiers for Open Source Software Repositories</title><categories>cs.SE cs.AI</categories><comments>10 pages, 2 Tables, 7 equations, 13 references. Appeared in 2nd
  Artificial Intelligence Techniques in Software Engineering Workshop, AIAI
  2009</comments><acm-class>D.2.8</acm-class><journal-ref>2nd Artificial Intelligence Techniques in Software Engineering
  Workshop, 5th IFIP Conference on Artificial Intelligence Applications and
  Innovations, April 23-25, 2009, Thessaloniki, Greece</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open Source Software (OSS) often relies on large repositories, like
SourceForge, for initial incubation. The OSS repositories offer a large variety
of meta-data providing interesting information about projects and their
success. In this paper we propose a data mining approach for training
classifiers on the OSS meta-data provided by such data repositories. The
classifiers learn to predict the successful continuation of an OSS project. The
`successfulness' of projects is defined in terms of the classifier confidence
with which it predicts that they could be ported in popular OSS projects (such
as FreeBSD, Gentoo Portage).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4709</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4709</id><created>2009-04-29</created><authors><author><keyname>Beyer</keyname><forenames>Dirk</forenames></author><author><keyname>Cimatti</keyname><forenames>Alessandro</forenames></author><author><keyname>Griggio</keyname><forenames>Alberto</forenames></author><author><keyname>Keremoglu</keyname><forenames>M. Erkan</forenames></author><author><keyname>Sebastiani</keyname><forenames>Roberto</forenames></author></authors><title>Software Model Checking via Large-Block Encoding</title><categories>cs.SE cs.PL</categories><comments>13 pages (11 without cover), 4 figures, 5 tables</comments><report-no>SFU-CS-2009-09</report-no><acm-class>D.2.4; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The construction and analysis of an abstract reachability tree (ART) are the
basis for a successful method for software verification. The ART represents
unwindings of the control-flow graph of the program. Traditionally, a
transition of the ART represents a single block of the program, and therefore,
we call this approach single-block encoding (SBE). SBE may result in a huge
number of program paths to be explored, which constitutes a fundamental source
of inefficiency. We propose a generalization of the approach, in which
transitions of the ART represent larger portions of the program; we call this
approach large-block encoding (LBE). LBE may reduce the number of paths to be
explored up to exponentially. Within this framework, we also investigate
symbolic representations: for representing abstract states, in addition to
conjunctions as used in SBE, we investigate the use of arbitrary Boolean
formulas; for computing abstract-successor states, in addition to Cartesian
predicate abstraction as used in SBE, we investigate the use of Boolean
predicate abstraction. The new encoding leverages the efficiency of
state-of-the-art SMT solvers, which can symbolically compute abstract
large-block successors. Our experiments on benchmark C programs show that the
large-block encoding outperforms the single-block encoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4717</identifier>
 <datestamp>2011-09-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4717</id><created>2009-04-29</created><updated>2011-09-22</updated><authors><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author></authors><title>Continuous Strategy Replicator Dynamics for Multi--Agent Learning</title><categories>cs.LG cs.AI cs.GT nlin.AO</categories><comments>12 pages, 15 figures, accepted for publication in JAAMAS</comments><doi>10.1007/s10458-011-9181-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of multi-agent learning and adaptation has attracted a great deal
of attention in recent years. It has been suggested that the dynamics of multi
agent learning can be studied using replicator equations from population
biology. Most existing studies so far have been limited to discrete strategy
spaces with a small number of available actions. In many cases, however, the
choices available to agents are better characterized by continuous spectra.
This paper suggests a generalization of the replicator framework that allows to
study the adaptive dynamics of Q-learning agents with continuous strategy
spaces. Instead of probability vectors, agents strategies are now characterized
by probability measures over continuous variables. As a result, the ordinary
differential equations for the discrete case are replaced by a system of
coupled integral--differential replicator equations that describe the mutual
evolution of individual agent strategies. We derive a set of functional
equations describing the steady state of the replicator dynamics, examine their
solutions for several two-player games, and confirm our analytical results
using simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4727</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4727</id><created>2009-04-29</created><authors><author><keyname>Shen</keyname><forenames>Yi-Dong</forenames></author><author><keyname>You</keyname><forenames>Jia-Huai</forenames></author><author><keyname>Yuan</keyname><forenames>Li-Yan</forenames></author></authors><title>Characterizations of Stable Model Semantics for Logic Programs with
  Arbitrary Constraint Atoms</title><categories>cs.AI cs.LO cs.PL</categories><comments>34 pages. To appear in Theory and Practice of Logic Programming
  (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the stable model semantics of logic programs with
(abstract) constraint atoms and their properties. We introduce a succinct
abstract representation of these constraint atoms in which a constraint atom is
represented compactly. We show two applications. First, under this
representation of constraint atoms, we generalize the Gelfond-Lifschitz
transformation and apply it to define stable models (also called answer sets)
for logic programs with arbitrary constraint atoms. The resulting semantics
turns out to coincide with the one defined by Son et al., which is based on a
fixpoint approach. One advantage of our approach is that it can be applied, in
a natural way, to define stable models for disjunctive logic programs with
constraint atoms, which may appear in the disjunctive head as well as in the
body of a rule. As a result, our approach to the stable model semantics for
logic programs with constraint atoms generalizes a number of previous
approaches. Second, we show that our abstract representation of constraint
atoms provides a means to characterize dependencies of atoms in a program with
constraint atoms, so that some standard characterizations and properties
relying on these dependencies in the past for logic programs with ordinary
atoms can be extended to logic programs with constraint atoms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4735</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4735</id><created>2009-04-29</created><authors><author><keyname>Bagherikaram</keyname><forenames>Ghadamali</forenames></author><author><keyname>Motahari</keyname><forenames>Abolfazl S.</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>The Secrecy Capacity Region of the Degraded Vector Gaussian Broadcast
  Channel</title><categories>cs.IT math.IT</categories><comments>5 Pages, 1 Figure, To be Presented at the ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider a scenario where a source node wishes to broadcast
two confidential messages for two respective receivers via a Gaussian MIMO
broadcast channel. A wire-tapper also receives the transmitted signal via
another MIMO channel. It is assumed that the channels are degraded and the
wire-tapper has the worst channel. We establish the capacity region of this
scenario. Our achievability scheme is a combination of the superposition of
Gaussian codes and randomization within the layers which we will refer to as
Secret Superposition Coding. For the outerbound, we use the notion of enhanced
channel to show that the secret superposition of Gaussian codes is optimal. It
is shown that we only need to enhance the channels of the legitimate receivers,
and the channel of the eavesdropper remains unchanged.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4741</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4741</id><created>2009-04-30</created><authors><author><keyname>Kurkoski</keyname><forenames>Brian M.</forenames></author><author><keyname>Dauwels</keyname><forenames>Justin</forenames></author></authors><title>Belief-Propagation Decoding of Lattices Using Gaussian Mixtures</title><categories>cs.IT math.IT</categories><comments>7 pages, 5 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A belief-propagation decoder for low-density lattice codes is given which
represents messages explicitly as a mixture of Gaussians functions. The key
component is an algorithm for approximating a mixture of several Gaussians with
another mixture with a smaller number of Gaussians. This Gaussian mixture
reduction algorithm iteratively reduces the number of Gaussians by minimizing
the distance between the original mixture and an approximation with one fewer
Gaussians.
  Error rates and noise thresholds of this decoder are compared with those for
the previously-proposed decoder which discretely quantizes the messages. The
error rates are indistinguishable for dimension 1000 and 10000 lattices, and
the Gaussian-mixture decoder has a 0.2 dB loss for dimension 100 lattices. The
Gaussian-mixture decoder has a loss of about 0.03 dB in the noise threshold,
which is evaluated via Monte Carlo density evolution. Further, the
Gaussian-mixture decoder uses far less storage for the messages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4756</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4756</id><created>2009-04-30</created><authors><author><keyname>Manzonetto</keyname><forenames>Giulio</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Models and theories of lambda calculus</title><categories>cs.LO</categories><proxy>ccsd inria-00380183</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we briefly summarize the contents of Manzonetto's PhD thesis
which concerns denotational semantics and equational/order theories of the pure
untyped lambda-calculus. The main research achievements include: (i) a general
construction of lambda-models from reflexive objects in (possibly
non-well-pointed) categories; (ii) a Stone-style representation theorem for
combinatory algebras; (iii) a proof that no effective lambda-model can have
lambda-beta or lambda-beta-eta as its equational theory (this can be seen as a
partial answer to an open problem introduced by Honsell-Ronchi Della Rocca in
1984).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4774</identifier>
 <datestamp>2010-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4774</id><created>2009-04-30</created><updated>2010-03-01</updated><authors><author><keyname>Gribonval</keyname><forenames>Remi</forenames></author><author><keyname>Schnass</keyname><forenames>Karin</forenames></author></authors><title>Dictionary Identification - Sparse Matrix-Factorisation via
  $\ell_1$-Minimisation</title><categories>cs.IT cs.LG math.IT</categories><comments>32 pages (IEEE draft format), 8 figures, submitted to IEEE Trans.
  Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article treats the problem of learning a dictionary providing sparse
representations for a given signal class, via $\ell_1$-minimisation. The
problem can also be seen as factorising a $\ddim \times \nsig$ matrix $Y=(y_1
&gt;... y_\nsig), y_n\in \R^\ddim$ of training signals into a $\ddim \times
\natoms$ dictionary matrix $\dico$ and a $\natoms \times \nsig$ coefficient
matrix $\X=(x_1... x_\nsig), x_n \in \R^\natoms$, which is sparse. The exact
question studied here is when a dictionary coefficient pair $(\dico,\X)$ can be
recovered as local minimum of a (nonconvex) $\ell_1$-criterion with input
$Y=\dico \X$. First, for general dictionaries and coefficient matrices,
algebraic conditions ensuring local identifiability are derived, which are then
specialised to the case when the dictionary is a basis. Finally, assuming a
random Bernoulli-Gaussian sparse model on the coefficient matrix, it is shown
that sufficiently incoherent bases are locally identifiable with high
probability. The perhaps surprising result is that the typically sufficient
number of training samples $\nsig$ grows up to a logarithmic factor only
linearly with the signal dimension, i.e. $\nsig \approx C \natoms \log
\natoms$, in contrast to previous approaches requiring combinatorially many
samples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4789</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4789</id><created>2009-04-30</created><authors><author><keyname>Chafnaji</keyname><forenames>Houda</forenames></author><author><keyname>Ait-Idir</keyname><forenames>Tarik</forenames></author><author><keyname>Saoudi</keyname><forenames>Samir</forenames></author><author><keyname>Vasilakos</keyname><forenames>Athanasios V.</forenames></author></authors><title>Frequency Domain Hybrid-ARQ Chase Combining for Broadband MIMO CDMA
  Systems</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Vehicular Technology (Apr 2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider high-speed wireless packet access using code
division multiple access (CDMA) and multiple-input multiple-output (MIMO).
Current wireless standards, such as high speed packet access (HSPA), have
adopted multi-code transmission and hybrid-automatic repeat request (ARQ) as
major technologies for delivering high data rates. The key technique in
hybrid-ARQ, is that erroneous data packets are kept in the receiver to
detect/decode retransmitted ones. This strategy is refereed to as packet
combining. In CDMA MIMO-based wireless packet access, multi-code transmission
suffers from severe performance degradation due to the loss of code
orthogonality caused by both interchip interference (ICI) and co-antenna
interference (CAI). This limitation results in large transmission delays when
an ARQ mechanism is used in the link layer. In this paper, we investigate
efficient minimum mean square error (MMSE) frequency domain equalization
(FDE)-based iterative (turbo) packet combining for cyclic prefix (CP)-CDMA MIMO
with Chase-type ARQ. We introduce two turbo packet combining schemes: i) In the
first scheme, namely &quot;chip-level turbo packet combining&quot;, MMSE FDE and packet
combining are jointly performed at the chip-level. ii) In the second scheme,
namely &quot;symbol-level turbo packet combining&quot;, chip-level MMSE FDE and
despreading are separately carried out for each transmission, then packet
combining is performed at the level of the soft demapper. The computational
complexity and memory requirements of both techniques are quite insensitive to
the ARQ delay, i.e., maximum number of ARQ rounds. The throughput is evaluated
for some representative antenna configurations and load factors to show the
gains offered by the proposed techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4819</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4819</id><created>2009-04-30</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>The independence polynomial of a graph at -1</title><categories>math.CO cs.DM</categories><comments>16 pages; 13 figures</comments><msc-class>05C69 (Primary); 05A20, 05C05 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If alpha=alpha(G) is the maximum size of an independent set and s_{k} equals
the number of stable sets of cardinality k in graph G, then
I(G;x)=s_{0}+s_{1}x+...+s_{alpha}x^{alpha} is the independence polynomial of G.
  In this paper we prove that: 1. I(T;-1) equels either -1 or 0 or 1 for every
tree T; 2. I(G;-1)=0 for every connected well-covered graph G of girth &gt; 5,
non-isomorphic to C_{7} or K_{2}; 3. the absolute value of I(G;-1) is not
greater than 2^nu(G), for every graph G, where nu(G) is its cyclomatic number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4836</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4836</id><created>2009-04-30</created><authors><author><keyname>Mavridis</keyname><forenames>Nikolaos</forenames></author><author><keyname>Emami</keyname><forenames>Shervin</forenames></author><author><keyname>Datta</keyname><forenames>Chandan</forenames></author><author><keyname>Kamzi</keyname><forenames>Wajahat</forenames></author><author><keyname>BenAbdelkader</keyname><forenames>Chiraz</forenames></author><author><keyname>Toulis</keyname><forenames>Panos</forenames></author><author><keyname>Tanoto</keyname><forenames>Andry</forenames></author><author><keyname>Rabie</keyname><forenames>Tamer</forenames></author></authors><title>FaceBots: Steps Towards Enhanced Long-Term Human-Robot Interaction by
  Utilizing and Publishing Online Social Information</title><categories>cs.RO cs.AI cs.CV</categories><acm-class>H.5.2; I.2.9</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our project aims at supporting the creation of sustainable and meaningful
longer-term human-robot relationships through the creation of embodied robots
with face recognition and natural language dialogue capabilities, which exploit
and publish social information available on the web (Facebook). Our main
underlying experimental hypothesis is that such relationships can be
significantly enhanced if the human and the robot are gradually creating a pool
of shared episodic memories that they can co-refer to (shared memories), and if
they are both embedded in a social web of other humans and robots they both
know and encounter (shared friends). In this paper, we are presenting such a
robot, which as we will see achieves two significant novelties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4863</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4863</id><created>2009-04-30</created><updated>2009-06-04</updated><authors><author><keyname>Slater</keyname><forenames>Paul B.</forenames></author></authors><title>A two-stage algorithm for extracting the multiscale backbone of complex
  weighted networks</title><categories>physics.soc-ph cs.SI physics.data-an stat.AP</categories><comments>1 page, letter accepted by PNAS in response to the article by MA
  Serrano, M Boguna, and A Vespignani, &quot;Extracting the multiscale backbone of
  complex weighted networks&quot;, Proc Natl Acad Sci 106:6483-6488 (2009)</comments><journal-ref>PNAS June 30, 2009 vol. 106 no. 26 E66</journal-ref><doi>10.1073/pnas.0904725106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The central problem of concern to Serrano, Boguna and Vespignani (&quot;Extracting
the multiscale backbone of complex weighted networks&quot;, Proc Natl Acad Sci
106:6483-6488 [2009]) can be effectively and elegantly addressed using a
well-established two-stage algorithm that has been applied to internal
migration flows for numerous nations and several other forms of &quot;transaction
flow data&quot;.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4900</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4900</id><created>2009-04-30</created><authors><author><keyname>Payar&#xf3;</keyname><forenames>Miquel</forenames></author><author><keyname>Palomar</keyname><forenames>Daniel P.</forenames></author></authors><title>On optimal precoding in linear vector Gaussian channels with arbitrary
  input distribution</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2009 IEEE International Symposium on Information
  Theory, Seoul, Korea, June 28 - July 3, 2009</comments><msc-class>94A15; 94A05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of the precoder the maximizes the mutual information in linear
vector Gaussian channels with an arbitrary input distribution is studied.
Precisely, the precoder optimal left singular vectors and singular values are
derived. The characterization of the right singular vectors is left, in
general, as an open problem whose computational complexity is then studied in
three cases: Gaussian signaling, low SNR, and high SNR. For the Gaussian
signaling case and the low SNR regime, the dependence of the mutual information
on the right singular vectors vanishes, making the optimal precoder design
problem easy to solve. In the high SNR regime, however, the dependence on the
right singular vectors cannot be avoided and we show the difficulty of
computing the optimal precoder through an NP-hardness analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4902</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4902</id><created>2009-04-30</created><updated>2009-05-27</updated><authors><author><keyname>Lev-Ami</keyname><forenames>Tal</forenames></author><author><keyname>Immerman</keyname><forenames>Neil</forenames></author><author><keyname>Reps</keyname><forenames>Thomas</forenames></author><author><keyname>Sagiv</keyname><forenames>Mooly</forenames></author><author><keyname>Srivastava</keyname><forenames>Siddharth</forenames></author><author><keyname>Yorsh</keyname><forenames>Greta</forenames></author></authors><title>Simulating reachability using first-order logic with applications to
  verification of linked data structures</title><categories>cs.LO cs.PL</categories><comments>30 pages, LMCS</comments><acm-class>F.3.1; F.3.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 2 (May 28,
  2009) lmcs:680</journal-ref><doi>10.2168/LMCS-5(2:12)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows how to harness existing theorem provers for first-order
logic to automatically verify safety properties of imperative programs that
perform dynamic storage allocation and destructive updating of pointer-valued
structure fields. One of the main obstacles is specifying and proving the
(absence) of reachability properties among dynamically allocated cells.
  The main technical contributions are methods for simulating reachability in a
conservative way using first-order formulas--the formulas describe a superset
of the set of program states that would be specified if one had a precise way
to express reachability. These methods are employed for semi-automatic program
verification (i.e., using programmer-supplied loop invariants) on programs such
as mark-and-sweep garbage collection and destructive reversal of a singly
linked list. (The mark-and-sweep example has been previously reported as being
beyond the capabilities of ESC/Java.)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4911</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4911</id><created>2009-04-30</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>On the Algorithmic Complexity of the Mastermind Game with Black-Peg
  Results</title><categories>cs.DS cs.CC</categories><comments>Expanded version with a figure showing the Mastermind game</comments><journal-ref>Information Processing Letters, Volume 109, 675-678, 2009</journal-ref><doi>10.1016/j.ipl.2009.02.021</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the algorithmic complexity of the Mastermind game,
where results are single-color black pegs. This differs from the usual
dual-color version of the game, but better corresponds to applications in
genetics. We show that it is NP-complete to determine if a sequence of
single-color Mastermind results have a satisfying vector. We also show how to
devise efficient algorithms for discovering a hidden vector through
single-color queries. Indeed, our algorithm improves a previous method of
Chvatal by almost a factor of 2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4921</identifier>
 <datestamp>2009-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4921</id><created>2009-04-30</created><updated>2009-08-25</updated><authors><author><keyname>Manin</keyname><forenames>Yuri I.</forenames></author></authors><title>Renormalization and computation I: motivation and background</title><categories>math.QA cs.IT math.IT</categories><comments>49 pages, 1 figure In the new version typos are fixed, minor
  corrections made, dedication added, reference to Part II added</comments><msc-class>81T15; 68Q10; 68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper I argue that infinities in the classical computation theory
such as the unsolvability of the Halting Problem can be addressed in the same
way as Feynman divergences in Quantum Field Theory, and that meaningful
versions of renormalization in this context can be devised. Connections with
quantum computation are also touched upon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0904.4926</identifier>
 <datestamp>2009-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0904.4926</id><created>2009-04-30</created><authors><author><keyname>Lioumpas</keyname><forenames>Athanasios S.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>Variable-Rate M-PSK Communications without Channel Amplitude Estimation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel estimation at the receiver side is essential to adaptive modulation
schemes, prohibiting low complexity systems from using variable rate and/or
variable power transmissions. Towards providing a solution to this problem, we
introduce a variable-rate (VR) M-PSK modulation scheme, for communications over
fading channels, in the absence of channel gain estimation at the receiver. The
choice of the constellation size is based on the signal-plus-noise (S+N)
sampling value rather than on the signal-to-noise ratio (S/N). It is
analytically shown that S+N can serve as an excellent simpler criterion,
alternative to S/N, for determining the modulation order in VR systems. In this
way, low complexity transceivers can use VR transmissions in order to increase
their spectral efficiency under an error performance constraint. As an
application, we utilize the proposed VR modulation scheme in equal gain
combining (EGC) diversity receivers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0024</identifier>
 <datestamp>2009-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0024</id><created>2009-04-30</created><authors><author><keyname>Xiaoying</keyname><forenames>Gan</forenames></author><author><keyname>Da</keyname><forenames>Shan</forenames></author><author><keyname>Yuan</keyname><forenames>Zhou</forenames></author><author><keyname>Wei</keyname><forenames>Zhang</forenames></author><author><keyname>Liang</keyname><forenames>Qian</forenames></author></authors><title>Theoretical Analysis of Cyclic Frequency Domain Noise and Feature
  Detection for Cognitive Radio Systems</title><categories>cs.IT math.IT</categories><msc-class>94A05;94A13</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In cognitive radio systems, cyclostationary feature detection plays an
important role in spectrum sensing, especially in low SNR cases. To configure
the detection threshold under a certain noise level and a pre-set miss
detection probability Pf, it's important to derive the theoretical distribution
of the observation variable. In this paper, noise distribution in cyclic
frequency domain has been studied and Generalized Extreme Value (GEV)
distribution is found to be a precise match. Maximum likelihood estimation is
applied to estimate the parameters of GEV. Monte Carlo simulation has been
carried out to show that the simulated ROC curve is coincided with the
theoretical ROC curve, which proves the efficiency of the theoretical
distribution model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0036</identifier>
 <datestamp>2009-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0036</id><created>2009-04-30</created><authors><author><keyname>Koyluoglu</keyname><forenames>O. Ozan</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>On the Secrecy Rate Region for the Interference Channel</title><categories>cs.IT math.IT</categories><comments>Proceedings of the 2008 IEEE International Symposium on Personal,
  Indoor and Mobile Radio Communications (PIMRC 2008), Cannes, France, Sept.
  2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies interference channels with security constraints. The
existence of an external eavesdropper in a two-user interference channel is
assumed, where the network users would like to secure their messages from the
external eavesdropper. The cooperative binning and channel prefixing scheme is
proposed for this system model which allows users to cooperatively add
randomness to the channel in order to degrade the observations of the external
eavesdropper. This scheme allows users to add randomness to the channel in two
ways: 1) Users cooperate in their design of the binning codebooks, and 2) Users
cooperatively exploit the channel prefixing technique. As an example, the
channel prefixing technique is exploited in the Gaussian case to transmit a
superposition signal consisting of binning codewords and independently
generated noise samples. Gains obtained form the cooperative binning and
channel prefixing scheme compared to the single user scenario reveals the
positive effect of interference in increasing the network security. Remarkably,
interference can be exploited to cooperatively add randomness into the network
in order to enhance the security.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0044</identifier>
 <datestamp>2009-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0044</id><created>2009-04-30</created><updated>2009-06-15</updated><authors><author><keyname>Lee</keyname><forenames>Kiryung</forenames></author><author><keyname>Bresler</keyname><forenames>Yoram</forenames></author></authors><title>ADMiRA: Atomic Decomposition for Minimum Rank Approximation</title><categories>math.NA cs.IT math.IT</categories><comments>A short version (arXiv:0901.1898) will be presented at ISIT'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the inverse problem that arises in compressed sensing of a
low-rank matrix. Our approach is to pose the inverse problem as an
approximation problem with a specified target rank of the solution. A simple
search over the target rank then provides the minimum rank solution satisfying
a prescribed data approximation bound. We propose an atomic decomposition that
provides an analogy between parsimonious representations of a sparse vector and
a low-rank matrix. Efficient greedy algorithms to solve the inverse problem for
the vector case are extended to the matrix case through this atomic
decomposition. In particular, we propose an efficient and guaranteed algorithm
named ADMiRA that extends CoSaMP, its analogue for the vector case. The
performance guarantee is given in terms of the rank-restricted isometry
property and bounds both the number of iterations and the error in the
approximate solution for the general case where the solution is approximately
low-rank and the measurements are noisy. With a sparse measurement operator
such as the one arising in the matrix completion problem, the computation in
ADMiRA is linear in the number of measurements. The numerical experiments for
the matrix completion problem show that, although the measurement operator in
this case does not satisfy the rank-restricted isometry property, ADMiRA is a
competitive algorithm for matrix completion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0079</identifier>
 <datestamp>2009-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0079</id><created>2009-05-01</created><authors><author><keyname>Hehn</keyname><forenames>Thorsten</forenames></author><author><keyname>Huber</keyname><forenames>Johannes B.</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author><author><keyname>Laendner</keyname><forenames>Stefan</forenames></author></authors><title>Multiple-Bases Belief-Propagation Decoding of High-Density Cyclic Codes</title><categories>cs.IT math.IT</categories><comments>This full paper accompanies a letter submitted to &quot;IEEE Transactions
  on Communications&quot;. It is intended to provide detailed information for
  interested readers of the letter. 24 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new method for decoding short and moderate length linear block
codes with dense parity-check matrix representations of cyclic form, termed
multiple-bases belief-propagation (MBBP). The proposed iterative scheme makes
use of the fact that a code has many structurally diverse parity-check
matrices, capable of detecting different error patterns. We show that this
inherent code property leads to decoding algorithms with significantly better
performance when compared to standard BP decoding. Furthermore, we describe how
to choose sets of parity-check matrices of cyclic form amenable for
multiple-bases decoding, based on analytical studies performed for the binary
erasure channel. For several cyclic and extended cyclic codes, the MBBP
decoding performance can be shown to closely follow that of maximum-likelihood
decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0106</identifier>
 <datestamp>2009-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0106</id><created>2009-05-01</created><authors><author><keyname>Malmgren</keyname><forenames>R. Dean</forenames></author><author><keyname>Hofman</keyname><forenames>Jake M.</forenames></author><author><keyname>Amaral</keyname><forenames>Luis A. N.</forenames></author><author><keyname>Watts</keyname><forenames>Duncan J.</forenames></author></authors><title>Characterizing Individual Communication Patterns</title><categories>physics.soc-ph cs.CY physics.data-an</categories><comments>9 pages, 6 figures, to appear in Proceedings of the 15th ACM SIGKDD
  International Conference on Knowledge Discovery and Data Mining (KDD'09),
  June 28-July 1, Paris, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing availability of electronic communication data, such as that
arising from e-mail exchange, presents social and information scientists with
new possibilities for characterizing individual behavior and, by extension,
identifying latent structure in human populations. Here, we propose a model of
individual e-mail communication that is sufficiently rich to capture meaningful
variability across individuals, while remaining simple enough to be
interpretable. We show that the model, a cascading non-homogeneous Poisson
process, can be formulated as a double-chain hidden Markov model, allowing us
to use an efficient inference algorithm to estimate the model parameters from
observed data. We then apply this model to two e-mail data sets consisting of
404 and 6,164 users, respectively, that were collected from two universities in
different countries and years. We find that the resulting best-estimate
parameter distributions for both data sets are surprisingly similar, indicating
that at least some features of communication dynamics generalize beyond
specific contexts. We also find that variability of individual behavior over
time is significantly less than variability across the population, suggesting
that individuals can be classified into persistent &quot;types&quot;. We conclude that
communication patterns may prove useful as an additional class of attribute
data, complementing demographic and network data, for user classification and
outlier detection--a point that we illustrate with an interpretable clustering
of users based on their inferred model parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0192</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0192</id><created>2009-05-02</created><authors><author><keyname>Champenois</keyname><forenames>Gilles</forenames></author></authors><title>Fuzzy Mnesors</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fuzzy mnesor space is a semimodule over the positive real numbers. It can
be used as theoretical framework for fuzzy sets. Hence we can prove a great
number of properties for fuzzy sets without refering to the membership
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0197</identifier>
 <datestamp>2010-01-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0197</id><created>2009-05-02</created><updated>2010-01-11</updated><authors><author><keyname>Marek</keyname><forenames>V. W.</forenames></author><author><keyname>Remmel</keyname><forenames>J. B.</forenames></author></authors><title>An Application of Proof-Theory in Answer Set Programming</title><categories>cs.AI</categories><comments>22 pages. Short version was published in ICLP08. New version slightly
  shorter than the previous version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We apply proof-theoretic techniques in answer Set Programming. The main
results include: 1. A characterization of continuity properties of
Gelfond-Lifschitz operator for logic program. 2. A propositional
characterization of stable models of logic programs (without referring to loop
formulas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0200</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0200</id><created>2009-05-02</created><authors><author><keyname>Aoki</keyname><forenames>Paul M.</forenames></author><author><keyname>Honicky</keyname><forenames>R. J.</forenames></author><author><keyname>Mainwaring</keyname><forenames>Alan</forenames></author><author><keyname>Myers</keyname><forenames>Chris</forenames></author><author><keyname>Paulos</keyname><forenames>Eric</forenames></author><author><keyname>Subramanian</keyname><forenames>Sushmita</forenames></author><author><keyname>Woodruff</keyname><forenames>Allison</forenames></author></authors><title>A Vehicle for Research: Using Street Sweepers to Explore the Landscape
  of Environmental Community Action</title><categories>cs.HC</categories><comments>10 pages</comments><acm-class>H.5.m</acm-class><journal-ref>Proc. ACM SIGCHI Conf. on Human Factors in Computing Systems,
  Boston, MA, Apr. 2009, 375-384. ACM Press</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Researchers are developing mobile sensing platforms to facilitate public
awareness of environmental conditions. However, turning such awareness into
practical community action and political change requires more than just
collecting and presenting data. To inform research on mobile environmental
sensing, we conducted design fieldwork with government, private, and public
interest stakeholders. In parallel, we built an environmental air quality
sensing system and deployed it on street sweeping vehicles in a major U.S.
city; this served as a &quot;research vehicle&quot; by grounding our interviews and
affording us status as environmental action researchers. In this paper, we
present a qualitative analysis of the landscape of environmental action,
focusing on insights that will help researchers frame meaningful technological
interventions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0203</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0203</id><created>2009-05-02</created><authors><author><keyname>Luk</keyname><forenames>Rowena</forenames></author><author><keyname>Zaharia</keyname><forenames>Matei</forenames></author><author><keyname>Ho</keyname><forenames>Melissa</forenames></author><author><keyname>Levine</keyname><forenames>Brian</forenames></author><author><keyname>Aoki</keyname><forenames>Paul M.</forenames></author></authors><title>ICTD for Healthcare in Ghana: Two Parallel Case Studies</title><categories>cs.HC</categories><comments>11 pages</comments><acm-class>H.5.m; J.3</acm-class><journal-ref>Proc. IEEE/ACM Conf. on Information and Communication Technologies
  and Development, Doha, Qatar, Apr. 2009, 118-128. IEEE CS Press</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines two parallel case studies to promote remote medical
consultation in Ghana. These projects, initiated independently by different
researchers in different organizations, both deployed ICT solutions in the same
medical community in the same year. The Ghana Consultation Network currently
has over 125 users running a Web-based application over a delay-tolerant
network of servers. OneTouch MedicareLine is currently providing 1700 doctors
in Ghana with free mobile phone calls and text messages to other members of the
medical community. We present the consequences of (1) the institutional context
and identity of the investigators, as well as specific decisions made with
respect to (2) partnerships formed, (3) perceptions of technological
infrastructure, and (4) high-level design decisions. In concluding, we discuss
lessons learned and high-level implications for future ICTD research agendas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0233</identifier>
 <datestamp>2009-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0233</id><created>2009-05-02</created><updated>2009-12-09</updated><authors><author><keyname>Wright</keyname><forenames>John</forenames></author><author><keyname>Ganesh</keyname><forenames>Arvind</forenames></author><author><keyname>Rao</keyname><forenames>Shankar</forenames></author><author><keyname>Ma</keyname><forenames>Yi</forenames></author></authors><title>Robust Principal Component Analysis: Exact Recovery of Corrupted
  Low-Rank Matrices</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn due to a critical error near equation (71).
This error causes the entire argument of the paper to collapse.
  Emmanuel Candes of Stanford discovered the error, and has suggested a correct
analysis, which will be reported in a separate publication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0266</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0266</id><created>2009-05-03</created><authors><author><keyname>Aurell</keyname><forenames>Erik</forenames></author><author><keyname>Pfitzner</keyname><forenames>Ren&#xe9;</forenames></author></authors><title>Gaussian Belief with dynamic data and in dynamic network</title><categories>cs.AI cond-mat.stat-mech cs.IT math.IT physics.soc-ph</categories><comments>5 pages, 7 figures</comments><journal-ref>EPL (Europhysics Letters) 87, 68004, 2009</journal-ref><doi>10.1209/0295-5075/87/68004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyse Belief Propagation over a Gaussian model in a
dynamic environment. Recently, this has been proposed as a method to average
local measurement values by a distributed protocol (&quot;Consensus Propagation&quot;,
Moallemi &amp; Van Roy, 2006), where the average is available for read-out at every
single node. In the case that the underlying network is constant but the values
to be averaged fluctuate (&quot;dynamic data&quot;), convergence and accuracy are
determined by the spectral properties of an associated Ruelle-Perron-Frobenius
operator. For Gaussian models on Erdos-Renyi graphs, numerical computation
points to a spectral gap remaining in the large-size limit, implying
exceptionally good scalability. In a model where the underlying network also
fluctuates (&quot;dynamic network&quot;), averaging is more effective than in the dynamic
data case. Altogether, this implies very good performance of these methods in
very large systems, and opens a new field of statistical physics of large (and
dynamic) information systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0283</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0283</id><created>2009-05-03</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Wortman</keyname><forenames>Kevin A.</forenames></author></authors><title>Optimal Embedding Into Star Metrics</title><categories>cs.DS</categories><comments>12 pages, 3 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an O(n^3 log^2 n)-time algorithm for the following problem: given
a finite metric space X, create a star-topology network with the points of X as
its leaves, such that the distances in the star are at least as large as in X,
with minimum dilation. As part of our algorithm, we solve in the same time
bound the parametric negative cycle detection problem: given a directed graph
with edge weights that are increasing linear functions of a parameter lambda,
find the smallest value of lambda such that the graph contains no
negative-weight cycles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0315</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0315</id><created>2009-05-04</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Kokar</keyname><forenames>Yvan</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>Gheorghe</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author></authors><title>Millimeter-Wave System for High Data Rate Indoor Communications</title><categories>cs.NI</categories><comments>5 pages</comments><proxy>ccsd hal-00380497</proxy><journal-ref>ISSCS 2009, Iasi : Roumanie (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the realization of a wireless Gigabit Ethernet
communication system operating in the 60 GHz band. The system architecture uses
a single carrier modulation. A differential encoded binary phase shift keying
modulation and a differential demodulation scheme are adopted for the
intermediate frequency blocks. The baseband blocks use Reed- Solomon RS (255,
239) coding and decoding for channel forward error correction (FEC). First
results of bit error rate (BER) measurements at 875 Mbps, without channel
coding, are presented for different antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0316</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0316</id><created>2009-05-04</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Siaud</keyname><forenames>I.</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Kokar</keyname><forenames>Y.</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>G.</forenames><affiliation>IETR</affiliation></author><author><keyname>Brunet</keyname><forenames>F.</forenames><affiliation>FT R&amp;D</affiliation></author><author><keyname>Tanguy</keyname><forenames>E.</forenames><affiliation>IREENA</affiliation></author><author><keyname>Zein</keyname><forenames>G. El</forenames><affiliation>IETR</affiliation></author></authors><title>A low Complexity Wireless Gigabit Ethernet IFoF 60 GHz H/W Platform and
  Issues</title><categories>cs.NI</categories><comments>6 pages</comments><proxy>ccsd hal-00380498</proxy><journal-ref>WWRF, Paris : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a complete IFoF system architecture derived from
simplified IEEE802.15.3c PHY layer proposal to successfully ensure near 1 Gbps
on the air interface. The system architecture utilizes low complexity baseband
processing modules. The byte/frame synchronization technique is designed to
provide a high value of preamble detection probability and a very small value
of the false detection probability. Conventional Reed-Solomon RS (255, 239)
coding is used for Channel Forward Error Correction (FEC). Good communication
link quality and Bit Error Rate (BER) results at 875 Mbps are achieved with
directional antennas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0317</identifier>
 <datestamp>2010-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0317</id><created>2009-05-04</created><authors><author><keyname>Rakotondrainibe</keyname><forenames>Lahatra</forenames><affiliation>IETR</affiliation></author><author><keyname>Kokar</keyname><forenames>Yvan</forenames><affiliation>IETR</affiliation></author><author><keyname>Zaharia</keyname><forenames>Gheorghe</forenames><affiliation>IETR</affiliation></author><author><keyname>Zein</keyname><forenames>Gha&#xef;s El</forenames><affiliation>IETR</affiliation></author></authors><title>60 GHz High Data Rate Wireless Communication System</title><categories>cs.NI</categories><comments>5 pages,</comments><proxy>ccsd hal-00380496</proxy><journal-ref>VTC Spring 2009, Barcelone : Espagne (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the design and the realization of a 60 GHz wireless
Gigabit Ethernet communication system. A differential encoded binary phase
shift keying modulation (DBPSK) and differential demodulation schemes are
adopted for the IF blocks. The Gigabit Ethernet interface allows a high speed
transfer of multimedia files via a 60 GHz wireless link. First measurement
results are shown for 875 Mbps data rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0363</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0363</id><created>2009-05-04</created><updated>2009-05-14</updated><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Smolarczyk</keyname><forenames>Milosz</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Hiding Information in Retransmissions</title><categories>cs.CR</categories><comments>12 pages, 12 figures, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a new steganographic method called RSTEG (Retransmission
Steganography), which is intended for a broad class of protocols that utilises
retransmission mechanisms. The main innovation of RSTEG is to not acknowledge a
successfully received packet in order to intentionally invoke retransmission.
The retransmitted packet carries a steganogram instead of user data in the
payload field. RSTEG is presented in the broad context of network
steganography, and the utilisation of RSTEG for TCP (Transport Control
Protocol) retransmission mechanisms is described in detail. Simulation results
are also presented with the main aim to measure and compare the steganographic
bandwidth of the proposed method for different TCP retransmission mechanisms as
well as to determine the influence of RSTEG on the network retransmissions
level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0374</identifier>
 <datestamp>2009-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0374</id><created>2009-05-04</created><updated>2009-05-06</updated><authors><author><keyname>Thukral</keyname><forenames>Jatin</forenames></author><author><keyname>Boelcskei</keyname><forenames>Helmut</forenames></author></authors><title>Interference Alignment with Limited Feedback</title><categories>cs.IT math.IT</categories><comments>5 pages, 0 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider single-antenna interference networks where M sources, each with
an average transmit power of P/M, communicate with M destinations over
frequency-selective channels (with L taps each) and each destination has
perfect knowledge of its channels from each of the sources. Assuming that there
exist error-free non-interfering broadcast feedback links from each destination
to all the nodes (i.e., sources and destinations) in the network, we show that
naive interference alignment, in conjunction with vector quantization of the
impulse response coefficients according to the scheme proposed in Mukkavilli et
al., IEEE Trans. IT, 2003, achieves full spatial multiplexing gain of M/2,
provided that the number of feedback bits broadcast by each destination is at
least M(L-1) log P.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0385</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0385</id><created>2009-05-04</created><updated>2009-09-08</updated><authors><author><keyname>Raja</keyname><forenames>Adnan</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Diversity-Multiplexing tradeoff of the Two-User Interference Channel</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diversity-Multiplexing tradeoff (DMT) is a coarse high SNR approximation of
the fundamental tradeoff between data rate and reliability in a slow fading
channel. In this paper, we characterize the fundamental DMT of the two user
single antenna Gaussian interference channel. We show that the class of
multilevel superposition coding schemes universally achieves (for all fading
statistics) the DMT for the two-user interference channel. For the special case
of symmetric DMT, when the two users have identical rate and diversity gain
requirements, we characterize the DMT achieved by the Han-Kobayashi scheme,
which corresponds to two level superposition coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0397</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0397</id><created>2009-05-04</created><authors><author><keyname>Chakrabarti</keyname><forenames>Nirmal B.</forenames></author></authors><title>A representation of non-uniformly sampled deterministic and random
  signals and their reconstruction using sample values and derivatives</title><categories>cs.IT math.IT</categories><comments>9 pages, 7 figures, submitted to IEEE transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Shannon in his 1949 paper suggested the use of derivatives to increase the
W*T product of the sampled signal. Use of derivatives enables improved
reconstruction particularly in the case of non-uniformly sampled signals. An
FM-AM representation for Lagrange/Hermite type interpolation and a
reconstruction technique are discussed. The representation using a product of a
polynomial and exponential of a polynomial is extensible to two dimensions.
  When the directly available information is inadequate, estimation of the
signal and its derivative based on the correlation characteristics of Gaussian
filtered noise has been studied. This requires computation of incomplete normal
integrals. Reduction methods for reducing multivariate normal variables include
multistage partitioning, dynamic path integral and Hermite expansion for
computing the probability integrals necessary for estimating the mean of the
signal and its derivative at points intermediate between zero or threshold
crossings. The signals and their derivatives as measured or estimated are
utilized to reconstruct the signal at a desired sampling rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0417</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0417</id><created>2009-05-04</created><authors><author><keyname>Anthapadmanabhan</keyname><forenames>N. Prasanth</forenames></author><author><keyname>Barg</keyname><forenames>Alexander</forenames></author></authors><title>Two-Level Fingerprinting Codes</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, 1 figure, Proc. 2009 IEEE International Symposium on
  Information Theory (ISIT 2009), Seoul, Korea, June 28 - July 3, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of two-level fingerprinting and traceability codes.
In this setting, the users are organized in a hierarchical manner by
classifying them into various groups; for instance, by dividing the
distribution area into several geographic regions, and collecting users from
the same region into one group. Two-level fingerprinting and traceability codes
have the following property: As in traditional (one-level) codes, when given an
illegal copy produced by a coalition of users, the decoder identifies one of
the guilty users if the coalition size is less than a certain threshold $t$.
Moreover, even when the coalition is of a larger size $s$ $(&gt; t)$, the decoder
still provides partial information by tracing one of the groups containing a
guilty user.
  We establish sufficient conditions for a code to possess the two-level
traceability property. In addition, we also provide constructions for two-level
fingerprinting codes and characterize the corresponding set of achievable
rates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0440</identifier>
 <datestamp>2015-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0440</id><created>2009-05-04</created><authors><author><keyname>Harrison</keyname><forenames>Willie K</forenames></author><author><keyname>McLaughlin</keyname><forenames>Steven W.</forenames></author></authors><title>Tandem Coding and Cryptography on Wiretap Channels: EXIT Chart Analysis</title><categories>cs.IT cs.CR math.IT</categories><comments>11 pages, 5 figures, accepted at 2009 IEEE International Symposium on
  Information Theory (ISIT 2009)</comments><doi>10.1109/ISIT.2009.5205606</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional cryptography assumes an eavesdropper receives an error-free copy
of the transmitted ciphertext. Wyner's wiretap channel model recognizes that at
the physical layer both the intended receiver and the passive eavesdropper
inevitably receive an error-prone version of the transmitted message which must
be corrected prior to decryption. This paper considers the implications of
using both channel and cryptographic codes under the wiretap channel model in a
way that enhances the \emph{information-theoretic} security for the friendly
parties by keeping the information transfer to the eavesdropper small. We
consider a secret-key cryptographic system with a linear feedback shift
register (LFSR)-based keystream generator and observe the mutual information
between an LFSR-generated sequence and the received noise-corrupted ciphertext
sequence under a known-plaintext scenario. The effectiveness of a noniterative
fast correlation attack, which reduces the search time in a brute-force attack,
is shown to be correlated with this mutual information. For an iterative fast
correlation attack on this cryptographic system, it is shown that an EXIT chart
and mutual information are very good predictors of decoding success and failure
by a passive eavesdropper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0451</identifier>
 <datestamp>2009-05-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0451</id><created>2009-05-04</created><authors><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Nussbaum</keyname><forenames>Yahav</forenames></author></authors><title>Maximum Flow in Directed Planar Graphs with Vertex Capacities</title><categories>cs.DM cs.DS</categories><comments>12 pages, 5 figures</comments><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an O(n log n) algorithm for finding a maximum flow
in a directed planar graph, where the vertices are subject to capacity
constraints, in addition to the arcs. If the source and the sink are on the
same face, then our algorithm can be implemented in O(n) time.
  For general (not planar) graphs, vertex capacities do not make the problem
more difficult, as there is a simple reduction that eliminates vertex
capacities. However, this reduction does not preserve the planarity of the
graph. The essence of our algorithm is a different reduction that does preserve
the planarity, and can be implemented in linear time. For the special case of
undirected planar graph, an algorithm with the same time complexity was
recently claimed, but we show that it has a flaw.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0484</identifier>
 <datestamp>2009-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0484</id><created>2009-05-04</created><authors><author><keyname>Zinoviev</keyname><forenames>Anton</forenames></author></authors><title>Extended Bulgarian keyboard layouts</title><categories>cs.HC</categories><comments>32 pages, in Bulgarian</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The old Bulgarian keyboard standard BDS 5237-78 was developed for use mostly
on typewriter machines. The wide distribution of the computers forced the
update of this standard. On one hand this is because of the need to support
symbols such as the Bulgarian quotation marks, the Cyrillic letter I with grave
accent, the long dash, etc. On the other hand the so called &quot;phonetic layout&quot;
became popular and this layout is not standartized by BDS. In this work we are
analyzing the possibilities to improve the keyboard layout according to BDS
5237-78, as well as the traditional phonetic layout. At the same time we are
making a comparison with the new proposed Bulgarian keyboard layout standard
BDS 5237:2006. We are proposing an algorithm for placement of additional
symbols on the keys of the keyboard in a way that makes easy for the users to
find the symbols even when they are not inscripted on the keys. We are giving
formal definitions and illustrations of four keyboard layouts - three extended
keyboard layouts for typing in &quot;Cyrillic&quot; mode (BDS, traditional phonetic and
phonetic according to the new proposed BDS 5237:2006) and one extended layout
for typing in &quot;Latin&quot; mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0541</identifier>
 <datestamp>2009-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0541</id><created>2009-05-05</created><authors><author><keyname>Li</keyname><forenames>Teng</forenames></author><author><keyname>Collins</keyname><forenames>Oliver M.</forenames></author></authors><title>Design and Analysis of Successive Decoding with Finite Levels for the
  Markov Channel</title><categories>cs.IT math.IT</categories><comments>Accepted for publication at IEEE transaction on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a practical successive decoding scheme with finite levels
for the finite-state Markov channels where there is no a priori state
information at the transmitter or the receiver. The design employs either a
random interleaver or a deterministic interleaver with an irregular pattern and
an optional iterative estimation and decoding procedure within each level. The
interleaver design criteria may be the achievable rate or the extrinsic
information transfer (EXIT) chart, depending on the receiver type. For random
interleavers, the optimization problem is solved efficiently using a
pilot-utility function, while for deterministic interleavers, a good
construction is given using empirical rules. Simulation results demonstrate
that the new successive decoding scheme combined with irregular low-density
parity-check codes can approach the identically and uniformly distributed
(i.u.d.) input capacity on the Markov-fading channel using only a few levels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0564</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0564</id><created>2009-05-05</created><updated>2009-05-12</updated><authors><author><keyname>Michalopoulos</keyname><forenames>Diomidis S.</forenames></author><author><keyname>Lioumpas</keyname><forenames>Athanasios S.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author></authors><title>Selective Cooperative Relaying over Time-Varying Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In selective cooperative relaying only a single relay out of the set of
available relays is activated, hence the available power and bandwidth
resources are efficiently utilized. However, implementing selective cooperative
relaying in time-varying channels may cause frequent relay switchings that
deteriorate the overall performance. In this paper, we study the rate at which
a relay switching occurs in selective cooperative relaying applications in
time-varying fading channels. In particular, we derive closed-form expressions
for the relay switching rate (measured in Hz) for opportunistic relaying (OR)
and distributed switch and stay combining (DSSC). Additionally, expressions for
the average relay activation time for both of the considered schemes are also
provided, reflecting the average time that a selected relay remains active
until a switching occurs. Numerical results manifest that DSSC yields
considerably lower relay switching rates than OR, along with larger average
relay activation times, rendering it a better candidate for implementation of
relay selection in fast fading environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0567</identifier>
 <datestamp>2011-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0567</id><created>2009-05-05</created><updated>2011-10-19</updated><authors><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Mnich</keyname><forenames>Matthias</forenames></author></authors><title>Feedback Vertex Sets in Tournaments</title><categories>cs.DM cs.DS math.CO</categories><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study combinatorial and algorithmic questions around minimal feedback
vertex sets in tournament graphs.
  On the combinatorial side, we derive strong upper and lower bounds on the
maximum number of minimal feedback vertex sets in an n-vertex tournament. We
prove that every tournament on n vertices has at most 1.6740^n minimal feedback
vertex sets, and that there is an infinite family of tournaments, all having at
least 1.5448^n minimal feedback vertex sets. This improves and extends the
bounds of Moon (1971).
  On the algorithmic side, we design the first polynomial space algorithm that
enumerates the minimal feedback vertex sets of a tournament with polynomial
delay. The combination of our results yields the fastest known algorithm for
finding a minimum size feedback vertex set in a tournament.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0586</identifier>
 <datestamp>2009-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0586</id><created>2009-05-05</created><authors><author><keyname>Abouelhoda</keyname><forenames>Mohamed</forenames></author><author><keyname>Mohamed</keyname><forenames>Hisham</forenames></author></authors><title>WinBioinfTools: Bioinformatics Tools for Windows High Performance
  Computing Server 2008</title><categories>cs.MS cs.CE q-bio.QM</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Open source bioinformatics tools running under MS Windows are rare to find,
and those running under Windows HPC cluster are almost non-existing. This is
despite the fact that the Windows is the most popular operating system used
among life scientists. Therefore, we introduce in this initiative
WinBioinfTools, a toolkit containing a number of bioinformatics tools running
under Windows High Performance Computing Server 2008. It is an open source code
package, where users and developers can share and add to. We currently start
with three programs from the area of sequence analysis: 1) CoCoNUT for pairwise
genome comparison, 2) parallel BLAST for biological database search, and 3)
parallel global pairwise sequence alignment. In this report, we focus on
technical aspects concerning how some components of these tools were ported
from Linux/Unix environment to run under Windows. We also show the advantages
of using the Windows HPC Cluster 2008. We demonstrate by experiments the
performance gain achieved when using a computer cluster against a single
machine. Furthermore, we show the results of comparing the performance of
WinBioinfTools on the Windows and Linux Cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0602</identifier>
 <datestamp>2009-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0602</id><created>2009-05-05</created><authors><author><keyname>Elberfeld</keyname><forenames>Michael</forenames></author></authors><title>Perfect Phylogeny Haplotyping is Complete for Logspace</title><categories>cs.CC q-bio.GN q-bio.QM</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Haplotyping is the bioinformatics problem of predicting likely haplotypes
based on given genotypes. It can be approached using Gusfield's perfect
phylogeny haplotyping (PPH) method for which polynomial and linear time
algorithms exist. These algorithm use sophisticated data structures or do a
stepwise transformation of the genotype data into haplotype data and,
therefore, need a linear amount of space. We are interested in the exact
computational complexity of PPH and show that it can be solved
space-efficiently by an algorithm that needs only a logarithmic amount of
space. Together with the recently proved L-hardness of PPH, we establish
L-completeness. Our algorithm relies on a new characterization for PPH in terms
of bipartite graphs, which can be used both to decide and construct perfect
phylogenies for genotypes efficiently.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0606</identifier>
 <datestamp>2009-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0606</id><created>2009-05-05</created><authors><author><keyname>Novak</keyname><forenames>Clemens</forenames></author><author><keyname>Fertl</keyname><forenames>Peter</forenames></author><author><keyname>Matz</keyname><forenames>Gerald</forenames></author></authors><title>Quantization for Soft-Output Demodulators in Bit-Interleaved Coded
  Modulation Systems</title><categories>cs.IT math.IT</categories><comments>to be published at ISIT-2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study quantization of log-likelihood ratios (LLR) in bit-interleaved coded
modulation (BICM) systems in terms of an equivalent discrete channel. We
propose to design the quantizer such that the quantizer outputs become
equiprobable. We investigate semi-analytically and numerically the ergodic and
outage capacity over single- and multiple-antenna channels for different
quantizers. Finally, we show bit error rate simulations for BICM systems with
LLR quantization using a rate 1/2 low-density parity-check code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0619</identifier>
 <datestamp>2009-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0619</id><created>2009-05-05</created><authors><author><keyname>Durisi</keyname><forenames>Giuseppe</forenames></author><author><keyname>Morgenshtern</keyname><forenames>Veniamin I.</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>On the Sensitivity of Noncoherent Capacity to the Channel Model</title><categories>cs.IT math.IT</categories><comments>To be presented at IEEE Int. Symp. Inf. Theory 2009, Seoul, Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The noncoherent capacity of stationary discrete-time fading channels is known
to be very sensitive to the fine details of the channel model. More
specifically, the measure of the set of harmonics where the power spectral
density of the fading process is nonzero determines if capacity grows
logarithmically in SNR or slower than logarithmically. An engineering-relevant
problem is to characterize the SNR value at which this sensitivity starts to
matter.
  In this paper, we consider the general class of continuous-time
Rayleigh-fading channels that satisfy the wide-sense stationary
uncorrelated-scattering (WSSUS) assumption and are, in addition, underspread.
For this class of channels, we show that the noncoherent capacity is close to
the AWGN capacity for all SNR values of practical interest, independently of
whether the scattering function is compactly supported or not. As a byproduct
of our analysis, we obtain an information-theoretic pulse-design criterion for
orthogonal frequency-division multiplexing systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0642</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0642</id><created>2009-05-05</created><authors><author><keyname>Negahban</keyname><forenames>S.</forenames></author><author><keyname>Wainwright</keyname><forenames>M. J.</forenames></author></authors><title>Simultaneous support recovery in high dimensions: Benefits and perils of
  block $\ell_1/\ell_\infty$-regularization</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>Presented in part at NIPS 2008 conference, Vancouver, Canada,
  December 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the use of $\ell_{1}/\ell_{\infty}$-regularized regression for joint
estimation of a $\pdim \times \numreg$ matrix of regression coefficients. We
analyze the high-dimensional scaling of $\ell_1/\ell_\infty$-regularized
quadratic programming, considering both consistency in $\ell_\infty$-norm, and
variable selection. We begin by establishing bounds on the $\ell_\infty$-error
as well sufficient conditions for exact variable selection for fixed and random
designs. Our second set of results applies to $\numreg = 2$ linear regression
problems with standard Gaussian designs whose supports overlap in a fraction
$\alpha \in [0,1]$ of their entries: for this problem class, we prove that the
$\ell_{1}/\ell_{\infty}$-regularized method undergoes a phase transition--that
is, a sharp change from failure to success--characterized by the rescaled
sample size $\theta_{1,\infty}(n, p, s, \alpha) = n/\{(4 - 3 \alpha) s
\log(p-(2- \alpha) s)\}$. An implication of this threshold is that use of
$\ell_1 / \ell_{\infty}$-regularization yields improved statistical efficiency
if the overlap parameter is large enough ($\alpha &gt; 2/3$), but has \emph{worse}
statistical efficiency than a naive Lasso-based approach for moderate to small
overlap ($\alpha &lt; 2/3$). These results indicate that some caution needs to be
exercised in the application of $\ell_1/\ell_\infty$ block regularization: if
the data does not match its structure closely enough, it can impair statistical
performance relative to computationally less expensive schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0677</identifier>
 <datestamp>2009-05-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0677</id><created>2009-05-05</created><authors><author><keyname>Tyukin</keyname><forenames>Ivan</forenames></author><author><keyname>Prokhorov</keyname><forenames>Danil</forenames></author></authors><title>Feasibility of random basis function approximators for modeling and
  control</title><categories>cs.NE cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the role of random basis function approximators in modeling and
control. We analyze the published work on random basis function approximators
and demonstrate that their favorable error rate of convergence O(1/n) is
guaranteed only with very substantial computational resources. We also discuss
implications of our analysis for applications of neural networks in modeling
and control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0721</identifier>
 <datestamp>2009-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0721</id><created>2009-05-06</created><authors><author><keyname>Akcaba</keyname><forenames>Cemal</forenames></author><author><keyname>Boelcskei</keyname><forenames>Helmut</forenames></author></authors><title>Diversity-Multiplexing Tradeoff in Fading Interference Channels</title><categories>cs.IT math.IT</categories><comments>51 pages, submitted to IEEE Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze two-user single-antenna fading interference channels with perfect
receive channel state information (CSI) and no transmit CSI. We compute the
diversity-multiplexing tradeoff (DMT) region of a fixed-power-split Han and
Kobayashi (HK)-type superposition coding scheme and provide design criteria for
the corresponding superposition codes. We demonstrate that this scheme is
DMT-optimal under moderate, strong, and very strong interference by showing
that it achieves a DMT outer bound that we derive. Further, under very strong
interference, we show that a joint decoder is DMT-optimal and &quot;decouples&quot; the
fading interference channel, i.e., from a DMT perspective, it is possible to
transmit as if the interfering user were not present. In addition, we show
that, under very strong interference, decoding interference while treating the
intended signal as noise, subtracting the result out, and then decoding the
desired signal, a process known as &quot;stripping&quot;, achieves the optimal DMT
region. Our proofs are constructive in the sense that code design criteria for
achieving DMT-optimality (in the cases where we can demonstrate it) are
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0737</identifier>
 <datestamp>2009-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0737</id><created>2009-05-06</created><authors><author><keyname>Vega-Paez</keyname><forenames>Ignacio</forenames></author><author><keyname>Ortega</keyname><forenames>Jose Angel</forenames></author><author><keyname>Pulido</keyname><forenames>Georgina G.</forenames></author></authors><title>REC language is a live on IBM1130 simulator, EL lenguaje REC esta vivo
  en el simulador de la IBM 1130</title><categories>cs.PL</categories><comments>This work is archaeological reconstruction of REC/A language</comments><report-no>IBP-TR2009-04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  REC (Regular Expression Compiler) is a concise programming language
development in mayor Mexican Universities at end of 60s which allows students
to write programs without knowledge of the complicated syntax of languages like
FORTRAN and ALGOL. The language is recursive and contains only four elements
for control. This paper describes use of the interpreter of REC written in
FORTRAN on IBM1130 Simulator from -Computer History Simulation- Project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0740</identifier>
 <datestamp>2011-07-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0740</id><created>2009-05-06</created><authors><author><keyname>Cisneros</keyname><forenames>Gerardo</forenames></author></authors><title>A FORTRAN coded regular expression Compiler for IBM 1130 Computing
  System</title><categories>cs.CL cs.PL</categories><comments>This version of REC is archaeological reconstruction of REC/A
  language on IBM1130 Simulator (SIMH IBM 1130 Emulator and Disk Monitor System
  R2V12) from Computer History Simulation Project (www.ibm1130.org), also see
  REC language is a live for Ignacio Vega-Paez</comments><report-no>IBP-Memo 2008-12</report-no><journal-ref>Acta Mexicana de Ciencia y Tecnologia Vol. IV No. 1, page 30-86,
  1970</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  REC (Regular Expression Compiler) is a concise programming language which
allows students to write programs without knowledge of the complicated syntax
of languages like FORTRAN and ALGOL. The language is recursive and contains
only four elements for control. This paper describes an interpreter of REC
written in FORTRAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0744</identifier>
 <datestamp>2009-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0744</id><created>2009-05-06</created><authors><author><keyname>Yang</keyname><forenames>Hongkun</forenames></author><author><keyname>Liu</keyname><forenames>Bin</forenames></author></authors><title>Optimization of Energy Efficient Transmission in Underwater Sensor
  Networks</title><categories>cs.NI</categories><comments>16 pages, 8 figures, in submission to Globecom'09</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Underwater communication is a challenging topic due to its singular channel
characteristics. Most protocols used in terrestrial wireless communication can
not be directly applied in the underwater world. In this paper, we focus on the
issue of energy efficient transmission in underwater sensor networks (UWSNs)
and analyze this problem in a rigorous and theoretical way. We formalize an
optimization problem which aims to minimize energy consumption and
simultaneously accounts for other performance metrics such as the data
reliability and the communication delay. With the help of Karush-Kuhn-Tucker
conditions (KKT conditions), we derive a simple and explicit, but nevertheless
accurate, approximate solution under reasonable assumptions. This approximate
solution provides theoretical guidelines for designing durable and reliable
UWSNs. Our result also shows that reliability and communication delay are
crucial factors to the energy consumption for transmission.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0747</identifier>
 <datestamp>2009-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0747</id><created>2009-05-06</created><authors><author><keyname>Dieudonn&#xe9;</keyname><forenames>Yoann</forenames><affiliation>LaRIA, MIS</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LaRIA, LIP, INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author></authors><title>Self-stabilizing Determinsitic Gathering</title><categories>cs.MA</categories><proxy>ccsd inria-00381582</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the possibility to deterministically solve the
gathering problem (GP) with weak robots (anonymous, autonomous, disoriented,
deaf and dumb, and oblivious). We introduce strong multiplicity detection as
the ability for the robots to detect the exact number of robots located at a
given position. We show that with strong multiplicity detection, there exists a
deterministic self-stabilizing algorithm solving GP for n robots if, and only
if, n is odd.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0749</identifier>
 <datestamp>2009-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0749</id><created>2009-05-06</created><authors><author><keyname>Broqu&#xe8;re</keyname><forenames>Xavier</forenames><affiliation>LAAS</affiliation></author><author><keyname>Sidobre</keyname><forenames>Daniel</forenames><affiliation>LAAS</affiliation></author><author><keyname>Herrera-Aguilar</keyname><forenames>Ignacio</forenames><affiliation>LAAS</affiliation></author></authors><title>Soft Motion Trajectory Planner for Service Manipulator Robot</title><categories>cs.RO</categories><proxy>ccsd hal-00381574</proxy><journal-ref>International Conference on Intelligent Robots and Systems, IROS
  2008. IEEE/RSJ, Nice : France (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human interaction introduces two main constraints: Safety and Comfort.
Therefore service robot manipulator can't be controlled like industrial robotic
manipulator where personnel is isolated from the robot's work envelope. In this
paper, we present a soft motion trajectory planner to try to ensure that these
constraints are satisfied. This planner can be used on-line to establish visual
and force control loop suitable in presence of human. The cubic trajectories
build by this planner are good candidates as output of a manipulation task
planner. The obtained system is then homogeneous from task planning to robot
control. The soft motion trajectory planner limits jerk, acceleration and
velocity in cartesian space using quaternion. Experimental results carried out
on a Mitsubishi PA10-6CE arm are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0768</identifier>
 <datestamp>2010-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0768</id><created>2009-05-06</created><updated>2010-09-23</updated><authors><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author><author><keyname>Sadakane</keyname><forenames>Kunihiko</forenames></author></authors><title>Fully-Functional Static and Dynamic Succinct Trees</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose new succinct representations of ordinal trees, which have been
studied extensively. It is known that any $n$-node static tree can be
represented in $2n + o(n)$ bits and a number of operations on the tree can be
supported in constant time under the word-RAM model. However the data
structures are complicated and difficult to dynamize. We propose a simple and
flexible data structure, called the range min-max tree, that reduces the large
number of relevant tree operations considered in the literature to a few
primitives that are carried out in constant time on sufficiently small trees.
The result is extended to trees of arbitrary size, achieving $2n + O(n
/\polylog(n))$ bits of space. The redundancy is significantly lower than any
previous proposal. Our data structure builds on the range min-max tree to
achieve $2n+O(n/\log n)$ bits of space and $O(\log n)$ time for all the
operations. We also propose an improved data structure using $2n+O(n\log\log
n/\log n)$ bits and improving the time to the optimal $O(\log n/\log \log n)$
for most operations. Furthermore, we support sophisticated operations that
allow attaching and detaching whole subtrees, in time $\Order(\log^{1+\epsilon}
n / \log\log n)$. Our techniques are of independent interest. One allows
representing dynamic bitmaps and sequences supporting rank/select and indels,
within zero-order entropy bounds and optimal time $O(\log n / \log\log n)$ for
all operations on bitmaps and polylog-sized alphabets, and $O(\log n \log
\sigma / (\log\log n)^2)$ on larger alphabet sizes $\sigma$. This improves upon
the best existing bounds for entropy-bounded storage of dynamic sequences,
compressed full-text self-indexes, and compressed-space construction of the
Burrows-Wheeler transform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0792</identifier>
 <datestamp>2009-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0792</id><created>2009-05-06</created><authors><author><keyname>Treibig</keyname><forenames>Jan</forenames></author><author><keyname>Hager</keyname><forenames>Georg</forenames></author></authors><title>Introducing a Performance Model for Bandwidth-Limited Loop Kernels</title><categories>cs.PF cs.AR</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a performance model for bandwidth limited loop kernels which is
founded on the analysis of modern cache based microarchitectures. This model
allows an accurate performance prediction and evaluation for existing
instruction codes. It provides an in-depth understanding of how performance for
different memory hierarchy levels is made up. The performance of raw memory
load, store and copy operations and a stream vector triad are analyzed and
benchmarked on three modern x86-type quad-core architectures in order to
demonstrate the capabilities of the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0794</identifier>
 <datestamp>2009-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0794</id><created>2009-05-06</created><updated>2009-11-04</updated><authors><author><keyname>Zhang</keyname><forenames>WeiGuo</forenames></author><author><keyname>Xiao</keyname><forenames>GuoZhen</forenames></author></authors><title>Constructions of Almost Optimal Resilient Boolean Functions on Large
  Even Number of Variables</title><categories>cs.IT cs.CR math.IT</categories><comments>14 pages, 2 tables</comments><acm-class>E.4</acm-class><journal-ref>IEEE Transactions on Information Theory, vol. 55, no. 12, pp.
  5822-5831, December 2009</journal-ref><doi>10.1109/TIT.2009.2032736</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, a technique on constructing nonlinear resilient Boolean
functions is described. By using several sets of disjoint spectra functions on
a small number of variables, an almost optimal resilient function on a large
even number of variables can be constructed. It is shown that given any $m$,
one can construct infinitely many $n$-variable ($n$ even), $m$-resilient
functions with nonlinearity $&gt;2^{n-1}-2^{n/2}$. A large class of highly
nonlinear resilient functions which were not known are obtained. Then one
method to optimize the degree of the constructed functions is proposed. Last,
an improved version of the main construction is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0838</identifier>
 <datestamp>2009-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0838</id><created>2009-05-06</created><authors><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author><author><keyname>Lozano</keyname><forenames>Angel</forenames></author><author><keyname>Marzetta</keyname><forenames>Thomas L.</forenames></author></authors><title>What is the Value of Joint Processing of Pilots and Data in Block-Fading
  Channels?</title><categories>cs.IT math.IT</categories><comments>To appear at IEEE Int. Symposium on Information Theory; 5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The spectral efficiency achievable with joint processing of pilot and data
symbol observations is compared with that achievable through the conventional
(separate) approach of first estimating the channel on the basis of the pilot
symbols alone, and subsequently detecting the data symbols. Studied on the
basis of a mutual information lower bound, joint processing is found to provide
a non-negligible advantage relative to separate processing, particularly for
fast fading. It is shown that, regardless of the fading rate, only a very small
number of pilot symbols (at most one per transmit antenna and per channel
coherence interval) should be transmitted if joint processing is allowed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0848</identifier>
 <datestamp>2009-05-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0848</id><created>2009-05-06</created><authors><author><keyname>Boussier</keyname><forenames>Sylvain</forenames><affiliation>LIA</affiliation></author><author><keyname>Vasquez</keyname><forenames>Michel</forenames><affiliation>LGI2P, EMA</affiliation></author><author><keyname>Vimont</keyname><forenames>Yannick</forenames><affiliation>LGI2P</affiliation></author><author><keyname>Hanafi</keyname><forenames>Said</forenames><affiliation>LAMIH</affiliation></author><author><keyname>Michelon</keyname><forenames>Philippe</forenames><affiliation>LIA</affiliation></author></authors><title>Solving the 0-1 Multidimensional Knapsack Problem with Resolution Search</title><categories>cs.DM</categories><proxy>ccsd hal-00381898</proxy><journal-ref>VI ALIO/EURO Workshop on Applied Combinatorial Optimization,
  Buenos Aires : Argentine (2008)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an exact method which combines the resolution search and branch &amp;
bound algorithms for solving the 0?1 Multidimensional Knapsack Problem. This
algorithm is able to prove large?scale strong correlated instances. The optimal
values of the 10 constraint, 500 variable instances of the OR-Library are
exposed. These values were previously unknown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0869</identifier>
 <datestamp>2009-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0869</id><created>2009-05-06</created><authors><author><keyname>Roca</keyname><forenames>Carlos P.</forenames></author><author><keyname>Cuesta</keyname><forenames>Jos&#xe9; A.</forenames></author><author><keyname>S&#xe1;nchez</keyname><forenames>Angel</forenames></author></authors><title>Imperfect Imitation Can Enhance Cooperation</title><categories>q-bio.PE cs.GT physics.soc-ph</categories><comments>4 pages, 4 figures</comments><journal-ref>Europhysics Letters 87, 48005 (2009)</journal-ref><doi>10.1209/0295-5075/87/48005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The promotion of cooperation on spatial lattices is an important issue in
evolutionary game theory. This effect clearly depends on the update rule: it
diminishes with stochastic imitative rules whereas it increases with
unconditional imitation. To study the transition between both regimes, we
propose a new evolutionary rule, which stochastically combines unconditional
imitation with another imitative rule. We find that, surprinsingly, in many
social dilemmas this rule yields higher cooperative levels than any of the two
original ones. This nontrivial effect occurs because the basic rules induce a
separation of timescales in the microscopic processes at cluster interfaces.
The result is robust in the space of 2x2 symmetric games, on regular lattices
and on scale-free networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0940</identifier>
 <datestamp>2010-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0940</id><created>2009-05-06</created><updated>2010-11-21</updated><authors><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author><author><keyname>Anandkumar</keyname><forenames>Animashree</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Willsky</keyname><forenames>Alan S.</forenames></author></authors><title>A Large-Deviation Analysis of the Maximum-Likelihood Learning of Markov
  Tree Structures</title><categories>stat.ML cs.IT math.IT</categories><comments>Accepted to the IEEE Transactions on Information Theory on Nov 18,
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of maximum-likelihood (ML) estimation of discrete tree-structured
distributions is considered. Chow and Liu established that ML-estimation
reduces to the construction of a maximum-weight spanning tree using the
empirical mutual information quantities as the edge weights. Using the theory
of large-deviations, we analyze the exponent associated with the error
probability of the event that the ML-estimate of the Markov tree structure
differs from the true tree structure, given a set of independently drawn
samples. By exploiting the fact that the output of ML-estimation is a tree, we
establish that the error exponent is equal to the exponential rate of decay of
a single dominant crossover event. We prove that in this dominant crossover
event, a non-neighbor node pair replaces a true edge of the distribution that
is along the path of edges in the true tree graph connecting the nodes in the
non-neighbor pair. Using ideas from Euclidean information theory, we then
analyze the scenario of ML-estimation in the very noisy learning regime and
show that the error exponent can be approximated as a ratio, which is
interpreted as the signal-to-noise ratio (SNR) for learning tree distributions.
We show via numerical experiments that in this regime, our SNR approximation is
accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.0976</identifier>
 <datestamp>2011-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.0976</id><created>2009-05-07</created><authors><author><keyname>Zlati&#x107;</keyname><forenames>Vinko</forenames></author><author><keyname>Ghoshal</keyname><forenames>Gourab</forenames></author><author><keyname>Caldarelli</keyname><forenames>Guido</forenames></author></authors><title>Hypergraph topological quantities for tagged social networks</title><categories>physics.soc-ph cs.CY</categories><comments>8 pages, 9 figures, revtex</comments><journal-ref>Phys. Rev. E 80, 036118 (2009)</journal-ref><doi>10.1103/PhysRevE.80.036118</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent years have witnessed the emergence of a new class of social networks,
that require us to move beyond previously employed representations of complex
graph structures. A notable example is that of the folksonomy, an online
process where users collaboratively employ tags to resources to impart
structure to an otherwise undifferentiated database. In a recent paper[1] we
proposed a mathematical model that represents these structures as tripartite
hypergraphs and defined basic topological quantities of interest. In this paper
we extend our model by defining additional quantities such as edge
distributions, vertex similarity and correlations as well as clustering. We
then empirically measure these quantities on two real life folksonomies, the
popular online photo sharing site Flickr and the bookmarking site CiteULike. We
find that these systems share similar qualitative features with the majority of
complex networks that have been previously studied. We propose that the
quantities and methodology described here can be used as a standard tool in
measuring the structure of tagged networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1024</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1024</id><created>2009-05-07</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Greedoids on Vertex Sets of Unicycle Graphs</title><categories>math.CO cs.DM</categories><comments>9 pages; 4 figures</comments><msc-class>05C69, 05B35 (Primary); 51D10, 90C27 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A maximum stable set in a graph G is a stable set of maximum cardinality. S
is a local maximum stable set of G, if S is a maximum stable set of the
subgraph induced by its closed neighborhood.
  It is known that the family of all local maximum stable sets of a forest
forms a greedoid on its vertex set. Bipartite, triangle-free, and well-covered
graphs whose families of local maximum stable sets form greedoids have been
analyzed as well.
  A unicycle graph owns only one cycle. In this paper we characterize the
unicycle graphs whose families of local maximum stable sets form greedoids.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1039</identifier>
 <datestamp>2010-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1039</id><created>2009-05-07</created><updated>2010-09-18</updated><authors><author><keyname>Silagadze</keyname><forenames>Z. K.</forenames></author></authors><title>Citation entropy and research impact estimation</title><categories>physics.soc-ph cond-mat.stat-mech cs.DL</categories><comments>9 pages, 3 figures, significantly changed, version to by published in
  Acta Phys. Polon. B</comments><journal-ref>Acta Phys. Polon. B41 (2010), 2325-2333</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new indicator, a real valued $s$-index, is suggested to characterize a
quality and impact of the scientific research output. It is expected to be at
least as useful as the notorious $h$-index, at the same time avoiding some its
obvious drawbacks. However, surprisingly, the $h$-index is found to be quite a
good indicator for majority of real-life citation data with their alleged
Zipfian behaviour for which these drawbacks do not show up. The style of the
paper was chosen deliberately somewhat frivolous to indicate that any attempt
to characterize the scientific output of a researcher by just one number always
has an element of a grotesque game in it and should not be taken too seriously.
I hope this frivolous style will be perceived as a funny decoration only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1045</identifier>
 <datestamp>2009-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1045</id><created>2009-05-07</created><updated>2009-05-08</updated><authors><author><keyname>Malcher</keyname><forenames>Andreas</forenames></author><author><keyname>Pighizzini</keyname><forenames>Giovanni</forenames></author></authors><title>Descriptional complexity of bounded context-free languages</title><categories>cs.FL</categories><comments>31 pages, 1 figure. A preliminary version was presented at DLT 2007.
  The full version is submitted to a journal</comments><acm-class>F.1.1; F.2.3; F.4.2; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Finite-turn pushdown automata (PDA) are investigated concerning their
descriptional complexity. It is known that they accept exactly the class of
ultralinear context-free languages. Furthermore, the increase in size when
converting arbitrary PDAs accepting ultralinear languages to finite-turn PDAs
cannot be bounded by any recursive function. The latter phenomenon is known as
non-recursive trade-off. In this paper, finite-turn PDAs accepting bounded
languages are considered. First, letter-bounded languages are studied. We prove
that in this case the non-recursive trade-off is reduced to a recursive
trade-off, more precisely, to an exponential trade-off. A conversion algorithm
is presented and the optimality of the construction is shown by proving tight
lower bounds. Furthermore, the question of reducing the number of turns of a
given finite-turn PDA is studied. Again, a conversion algorithm is provided
which shows that in this case the trade-off is at most polynomial. Finally, the
more general case of word-bounded languages is investigated. We show how the
results obtained for letter-bounded languages can be extended to word-bounded
languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1056</identifier>
 <datestamp>2015-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1056</id><created>2009-05-07</created><updated>2010-04-12</updated><authors><author><keyname>Soprunov</keyname><forenames>Ivan</forenames></author><author><keyname>Soprunova</keyname><forenames>Evgenia</forenames></author></authors><title>Bringing Toric Codes to the next dimension</title><categories>math.AG cs.IT math.IT</categories><comments>11 pages, 1 figure; Major changes in the section on parameters, new
  examples.</comments><msc-class>94B27, 14G50, 52B20</msc-class><journal-ref>SIAM J. Discrete Math. Volume 24, no. 2, pp. 655-665 (2010)</journal-ref><doi>10.1137/090762592</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with the minimum distance computation for higher
dimensional toric codes defined by lattice polytopes. We show that the minimum
distance is multiplicative with respect to taking the product of polytopes, and
behaves in a simple way when one builds a k-dilate of a pyramid over a
polytope. This allows us to construct a large class of examples of higher
dimensional toric codes where we can compute the minimum distance explicitly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1093</identifier>
 <datestamp>2009-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1093</id><created>2009-05-07</created><authors><author><keyname>Gibson</keyname><forenames>Matt</forenames></author><author><keyname>Varadarajan</keyname><forenames>Kasturi</forenames></author></authors><title>Decomposing Coverings and the Planar Sensor Cover Problem</title><categories>cs.CG</categories><comments>18 pages, 13 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that a $k$-fold covering using translates of an arbitrary convex
polygon can be decomposed into $\Omega(k)$ covers (using an efficient
algorithm). We generalize this result to obtain a constant factor approximation
to the sensor cover problem where the ranges of the sensors are translates of a
given convex polygon. The crucial ingredient in this generalization is a
constant factor approximation algorithm for a one-dimensional version of the
sensor cover problem, called the Restricted Strip Cover (RSC) problem, where
sensors are intervals of possibly different lengths. Our algorithm for RSC
improves on the previous $O(\log \log \log n)$ approximation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1108</identifier>
 <datestamp>2009-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1108</id><created>2009-05-07</created><authors><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author><author><keyname>Musoyan</keyname><forenames>Vahe</forenames></author><author><keyname>Cohen</keyname><forenames>Paul</forenames></author></authors><title>Maximizing Influence Propagation in Networks with Community Structure</title><categories>physics.soc-ph cond-mat.stat-mech cs.CY</categories><comments>7 pages, 8 figures</comments><journal-ref>Phys. Rev. E 79, 056102 (2009)</journal-ref><doi>10.1103/PhysRevE.79.056102</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the algorithmic problem of selecting a set of target nodes that
cause the biggest activation cascade in a network. In case when the activation
process obeys the diminishing returns property, a simple hill-climbing
selection mechanism has been shown to achieve a provably good performance. Here
we study models of influence propagation that exhibit critical behavior, and
where the property of diminishing returns does not hold. We demonstrate that in
such systems, the structural properties of networks can play a significant
role. We focus on networks with two loosely coupled communities, and show that
the double-critical behavior of activation spreading in such systems has
significant implications for the targeting strategies. In particular, we show
that simple strategies that work well for homogeneous networks can be overly
sub-optimal, and suggest simple modification for improving the performance, by
taking into account the community structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1113</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1113</id><created>2009-05-07</created><authors><author><keyname>Nicolae</keyname><forenames>Bogdan</forenames><affiliation>INRIA - IRISA</affiliation></author><author><keyname>Antoniu</keyname><forenames>Gabriel</forenames><affiliation>INRIA - IRISA, INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author><author><keyname>Boug&#xe9;</keyname><forenames>Luc</forenames><affiliation>INRIA - IRISA, INRIA Rh&#xf4;ne-Alpes / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme</affiliation></author></authors><title>BlobSeer: How to Enable Efficient Versioning for Large Object Storage
  under Heavy Access Concurrency</title><categories>cs.DC</categories><proxy>ccsd inria-00382354</proxy><journal-ref>DAMAP 2009 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To accommodate the needs of large-scale distributed P2P systems, scalable
data management strategies are required, allowing applications to efficiently
cope with continuously growing, highly dis tributed data. This paper addresses
the problem of efficiently stor ing and accessing very large binary data
objects (blobs). It proposesan efficient versioning scheme allowing a large
number of clients to concurrently read, write and append data to huge blobs
that are fragmented and distributed at a very large scale. Scalability under
heavy concurrency is achieved thanks to an original metadata scheme, based on a
distributed segment tree built on top of a Distributed Hash Table (DHT). Our
approach has been implemented and experimented within our BlobSeer prototype on
the Grid'5000 testbed, using up to 175 nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1129</identifier>
 <datestamp>2009-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1129</id><created>2009-05-07</created><updated>2009-05-22</updated><authors><author><keyname>Currie</keyname><forenames>James</forenames></author><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author></authors><title>A proof of Dejean's conjecture</title><categories>math.CO cs.FL</categories><comments>proof details added</comments><msc-class>68R15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove Dejean's conjecture. Specifically, we show that Dejean's conjecture
holds for the last remaining open values of n, namely 15 &lt;= n &lt;= 26.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1130</identifier>
 <datestamp>2009-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1130</id><created>2009-05-07</created><authors><author><keyname>Boudin</keyname><forenames>Florian</forenames></author><author><keyname>Velazquez-Morales</keyname><forenames>Patricia</forenames></author><author><keyname>Torres-Moreno</keyname><forenames>Juan-Manuel</forenames></author></authors><title>Statistical Automatic Summarization in Organic Chemistry</title><categories>cs.IR cs.CL</categories><comments>10 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an oriented numerical summarizer algorithm, applied to producing
automatic summaries of scientific documents in Organic Chemistry. We present
its implementation named Yachs (Yet Another Chemistry Summarizer) that combines
a specific document pre-processing with a sentence scoring method relying on
the statistical properties of documents. We show that Yachs achieves the best
results among several other summarizers on a corpus of Organic Chemistry
articles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1187</identifier>
 <datestamp>2012-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1187</id><created>2009-05-08</created><updated>2011-07-21</updated><authors><author><keyname>Grasmair</keyname><forenames>Markus</forenames></author><author><keyname>Haltmeier</keyname><forenames>Markus</forenames></author><author><keyname>Scherzer</keyname><forenames>Otmar</forenames></author></authors><title>The Residual Method for Regularizing Ill-Posed Problems</title><categories>math.OC cs.SY</categories><comments>29 pages, one figure</comments><msc-class>65J20, 47J06, 49J27</msc-class><journal-ref>Appl. Math. Comput. 218(6): pp. 2693-2710 (2011)</journal-ref><doi>10.1016/j.amc.2011.08.009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although the \emph{residual method}, or \emph{constrained regularization}, is
frequently used in applications, a detailed study of its properties is still
missing. This sharply contrasts the progress of the theory of Tikhonov
regularization, where a series of new results for regularization in Banach
spaces has been published in the recent years. The present paper intends to
bridge the gap between the existing theories as far as possible. We develop a
stability and convergence theory for the residual method in general topological
spaces. In addition, we prove convergence rates in terms of (generalized)
Bregman distances, which can also be applied to non-convex regularization
functionals. We provide three examples that show the applicability of our
theory. The first example is the regularized solution of linear operator
equations on $L^p$-spaces, where we show that the results of Tikhonov
regularization generalize unchanged to the residual method. As a second
example, we consider the problem of density estimation from a finite number of
sampling points, using the Wasserstein distance as a fidelity term and an
entropy measure as regularization term. It is shown that the densities obtained
in this way depend continuously on the location of the sampled points and that
the underlying density can be recovered as the number of sampling points tends
to infinity. Finally, we apply our theory to compressed sensing. Here, we show
the well-posedness of the method and derive convergence rates both for convex
and non-convex regularization under rather weak conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1200</identifier>
 <datestamp>2012-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1200</id><created>2009-05-08</created><updated>2010-07-23</updated><authors><author><keyname>Foniok</keyname><forenames>Jan</forenames></author><author><keyname>Nesetril</keyname><forenames>Jaroslav</forenames></author><author><keyname>Tardif</keyname><forenames>Claude</forenames></author></authors><title>Interleaved adjoints on directed graphs</title><categories>math.CO cs.DM math.CT</categories><msc-class>05C15 (Primary) 05C20, 18A40 (Secondary)</msc-class><journal-ref>European J. Combin., 32(7), pp. 1018--1024, 2011</journal-ref><doi>10.1016/j.ejc.2011.03.013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For an integer k &gt;= 1, the k-th interlacing adjoint of a digraph G is the
digraph i_k(G) with vertex-set V(G)^k, and arcs ((u_1, ..., u_k), (v_1, ...,
v_k)) such that (u_i,v_i) \in A(G) for i = 1, ..., k and (v_i, u_{i+1}) \in
A(G) for i = 1, ..., k-1. For every k we derive upper and lower bounds for the
chromatic number of i_k(G) in terms of that of G. In particular, we find tight
bounds on the chromatic number of interlacing adjoints of transitive
tournaments. We use this result in conjunction with categorial properties of
adjoint functors to derive the following consequence. For every integer ell,
there exists a directed path Q_{\ell} of algebraic length ell which admits
homomorphisms into every directed graph of chromatic number at least 4. We
discuss a possible impact of this approach on the multifactor version of the
weak Hedetniemi conjecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1202</identifier>
 <datestamp>2009-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1202</id><created>2009-05-08</created><updated>2009-11-16</updated><authors><author><keyname>Velasco</keyname><forenames>Pedro Pablo Perez</forenames></author></authors><title>Matrix Graph Grammars as a Model of Computation</title><categories>cs.DM cs.CC cs.FL</categories><comments>33 pages, 19 figures. English improved. One new section introducing
  an algebra of matrices</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Matrix Graph Grammars (MGG) is a novel approach to the study of graph
dynamics ([15]). In the present contribution we look at MGG as a formal grammar
and as a model of computation, which is a necessary step in the more ambitious
program of tackling complexity theory through MGG. We also study its relation
with other well-known models such as Turing machines (TM) and Boolean circuits
(BC) as well as non-determinism. As a side effect, all techniques available for
MGG can be applied to TMs and BCs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1215</identifier>
 <datestamp>2009-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1215</id><created>2009-05-08</created><authors><author><keyname>Seethaler</keyname><forenames>Dominik</forenames></author><author><keyname>Jald&#xe9;n</keyname><forenames>Joakim</forenames></author><author><keyname>Studer</keyname><forenames>Christoph</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Tail Behavior of Sphere-Decoding Complexity in Random Lattices</title><categories>cs.IT cs.CC math.IT math.ST stat.TH</categories><comments>To be presented at IEEE ISIT 2009, Seoul, Korea</comments><acm-class>C.2.1; B.7.1; F.2; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the (computational) complexity distribution of sphere-decoding
(SD) for random infinite lattices. In particular, we show that under fairly
general assumptions on the statistics of the lattice basis matrix, the tail
behavior of the SD complexity distribution is solely determined by the inverse
volume of a fundamental region of the underlying lattice. Particularizing this
result to NxM, N&gt;=M, i.i.d. Gaussian lattice basis matrices, we find that the
corresponding complexity distribution is of Pareto-type with tail exponent
given by N-M+1. We furthermore show that this tail exponent is not improved by
lattice-reduction, which includes layer-sorting as a special case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1235</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1235</id><created>2009-05-08</created><updated>2009-07-25</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Sinclair</keyname><forenames>Stephen</forenames></author><author><keyname>Cl&#xe9;ment</keyname><forenames>Ian</forenames></author><author><keyname>Nicolacopoulos</keyname><forenames>Dimitrios</forenames></author><author><keyname>Group</keyname><forenames>for the MARF R&amp;D</forenames></author></authors><title>The Modular Audio Recognition Framework (MARF) and its Applications:
  Scientific and Software Engineering Notes</title><categories>cs.SD cs.CL cs.CV cs.MM cs.NE</categories><comments>v2: add missing .ind file for index; 224 pages, 40 figures, 19
  tables; index. A comprehensive description of AI and PR algorithms and data
  structures, software engineering design and implementation, and experiments.
  Source revision is maintained in the CVS at http://marf.sf.net</comments><acm-class>I.5; I.2.6; D.2.10; D.2.11; D.2.5; D.2.2; I.2.7</acm-class><doi>10.1007/978-1-4020-8741-7_84 10.1007/978-3-540-68825-9_21
  10.1145/1370256.1370262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  MARF is an open-source research platform and a collection of
voice/sound/speech/text and natural language processing (NLP) algorithms
written in Java and arranged into a modular and extensible framework
facilitating addition of new algorithms. MARF can run distributively over the
network and may act as a library in applications or be used as a source for
learning and extension. A few example applications are provided to show how to
use the framework. There is an API reference in the Javadoc format as well as
this set of accompanying notes with the detailed description of the
architectural design, algorithms, and applications. MARF and its applications
are released under a BSD-style license and is hosted at SourceForge.net. This
document provides the details and the insight on the internals of MARF and some
of the mentioned applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1248</identifier>
 <datestamp>2009-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1248</id><created>2009-05-08</created><authors><author><keyname>Pighizzini</keyname><forenames>Giovanni</forenames></author></authors><title>Deterministic pushdown automata and unary languages</title><categories>cs.FL</categories><comments>17 pages. Preprint of an article submitted for consideration in the
  International Journal of Foundations of Computer Science (World Scientific
  Publishing Company). A preliminary version was presented at the conference
  CIAA 2008</comments><acm-class>F.1.1; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The simulation of deterministic pushdown automata defined over a one-letter
alphabet by finite state automata is investigated from a descriptional
complexity point of view. We show that each unary deterministic pushdown
automaton of size s can be simulated by a deterministic finite automaton with a
number of states that is exponential in s. We prove that this simulation is
tight. Furthermore, its cost cannot be reduced even if it is performed by a
two-way nondeterministic automaton. We also prove that there are unary
languages for which deterministic pushdown automata cannot be exponentially
more succinct than finite automata. In order to state this result, we
investigate the conversion of deterministic pushdown automata into context-free
grammars. We prove that in the unary case the number of variables in the
resulting grammar is strictly smaller than the number of variables needed in
the case of nonunary alphabets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1271</identifier>
 <datestamp>2009-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1271</id><created>2009-05-08</created><authors><author><keyname>Pighizzini</keyname><forenames>Giovanni</forenames></author></authors><title>Nondeterministic one-tape off-line Turing machines and their time
  complexity</title><categories>cs.FL cs.CC</categories><comments>18 pages. The paper will appear on the Journal of Automata, Languages
  and Combinatorics</comments><acm-class>F.1.1; F.1.2; F.1.3; F.2.3; F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the time and the crossing sequence complexities of
one-tape off-line Turing machines. We show that the running time of each
nondeterministic machine accepting a nonregular language must grow at least as
n\log n, in the case all accepting computations are considered (accept
measure). We also prove that the maximal length of the crossing sequences used
in accepting computations must grow at least as \log n. On the other hand, it
is known that if the time is measured considering, for each accepted string,
only the faster accepting computation (weak measure), then there exist
nonregular languages accepted in linear time. We prove that under this measure,
each accepting computation should exhibit a crossing sequence of length at
least \log\log n. We also present efficient implementations of algorithms
accepting some unary nonregular languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1300</identifier>
 <datestamp>2009-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1300</id><created>2009-05-08</created><authors><author><keyname>Jain</keyname><forenames>Rahul</forenames></author><author><keyname>Upadhyay</keyname><forenames>Sarvagya</forenames></author><author><keyname>Watrous</keyname><forenames>John</forenames></author></authors><title>Two-message quantum interactive proofs are in PSPACE</title><categories>cs.CC quant-ph</categories><comments>24 pages</comments><acm-class>F.1.3; F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that QIP(2), the class of problems having two-message quantum
interactive proof systems, is a subset of PSPACE. This relationship is obtained
by means of an efficient parallel algorithm, based on the multiplicative
weights update method, for approximately solving a certain class of
semidefinite programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1305</identifier>
 <datestamp>2009-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1305</id><created>2009-05-08</created><authors><author><keyname>Chatzidiamantis</keyname><forenames>Nestor D.</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>On the Distribution of the Sum of Gamma-Gamma Variates and Applications
  in RF and Optical Wireless Communications</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Gamma-Gamma (GG) distribution has recently attracted the interest within
the research community due to its involvement in various communication systems.
In the context of RF wireless communications, GG distribution accurately models
the power statistics in composite shadowing/fading channels as well as in
cascade multipath fading channels, while in optical wireless (OW) systems, it
describes the fluctuations of the irradiance of optical signals distorted by
atmospheric turbulence. Although GG channel model offers analytical
tractability in the analysis of single input single output (SISO) wireless
systems, difficulties arise when studying multiple input multiple output (MIMO)
systems, where the distribution of the sum of independent GG variates is
required. In this paper, we present a novel simple closed-form approximation
for the distribution of the sum of independent, but not necessarily identically
distributed GG variates. It is shown that the probability density function
(PDF) of the GG sum can be efficiently approximated either by the PDF of a
single GG distribution, or by a finite weighted sum of PDFs of GG
distributions. To reveal the importance of the proposed approximation, the
performance of RF wireless systems in the presence of composite fading, as well
as MIMO OW systems impaired by atmospheric turbulence, are investigated.
Numerical results and simulations illustrate the accuracy of the proposed
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1307</identifier>
 <datestamp>2009-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1307</id><created>2009-05-08</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Tamassia</keyname><forenames>Roberto</forenames></author><author><keyname>Hasic</keyname><forenames>Jasminka</forenames></author></authors><title>An Efficient Dynamic and Distributed RSA Accumulator</title><categories>cs.CR</categories><comments>Expanded version of a paper appearing in the 5th International
  Information Security Conference (ISC)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how to use the RSA one-way accumulator to realize an efficient and
dynamic authenticated dictionary, where untrusted directories provide
cryptographically verifiable answers to membership queries on a set maintained
by a trusted source. Our accumulator-based scheme for authenticated
dictionaries supports efficient incremental updates of the underlying set by
insertions and deletions of elements. Also, the user can optimally verify in
constant time the authenticity of the answer provided by a directory with a
simple and practical algorithm. We have also implemented this scheme and we
give empirical results that can be used to determine the best strategy for
systems implementation with respect to resources that are available. This work
has applications to certificate revocation in public key infrastructure and
end-to-end integrity of data collections published by third parties on the
Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1362</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1362</id><created>2009-05-08</created><authors><author><keyname>Preda</keyname><forenames>Stere</forenames></author><author><keyname>Cuppens-Boulahia</keyname><forenames>Nora</forenames></author><author><keyname>Cuppens</keyname><forenames>Frederic</forenames></author><author><keyname>Garcia-Alfaro</keyname><forenames>Joaquin</forenames></author><author><keyname>Toutain</keyname><forenames>Laurent</forenames></author></authors><title>Reliable Process for Security Policy Deployment</title><categories>cs.CR cs.SE</categories><comments>12 pages</comments><journal-ref>Proc. 2007 International Conference on Security and Cryptography
  (Secrypt 2007), Barcelona, Spain, July 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus in this paper on the problem of configuring and managing network
security devices, such as Firewalls, Virtual Private Network (VPN) tunnels, and
Intrusion Detection Systems (IDSs). Our proposal is the following. First, we
formally specify the security requirements of a given system by using an
expressive access control model. As a result, we obtain an abstract security
policy, which is free of ambiguities, redundancies or unnecessary details.
Second, we deploy such an abstract policy through a set of automatic
compilations into the security devices of the system. This proposed deployment
process not only simplifies the security administrator's job, but also
guarantees a resulting configuration free of anomalies and/or inconsistencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1375</identifier>
 <datestamp>2010-11-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1375</id><created>2009-05-09</created><authors><author><keyname>Huang</keyname><forenames>Yen-Wei</forenames></author><author><keyname>Moulin</keyname><forenames>Pierre</forenames></author></authors><title>Saddle-point Solution of the Fingerprinting Capacity Game Under the
  Marking Assumption</title><categories>cs.IT cs.CR math.IT</categories><comments>5 pages, to appear in 2009 IEEE International Symposium on
  Information Theory (ISIT 2009), Seoul, Korea, June 2009</comments><doi>10.1109/ISIT.2009.5205882</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a fingerprinting game in which the collusion channel is unknown. The
encoder embeds fingerprints into a host sequence and provides the decoder with
the capability to trace back pirated copies to the colluders.
  Fingerprinting capacity has recently been derived as the limit value of a
sequence of maxmin games with mutual information as the payoff function.
However, these games generally do not admit saddle-point solutions and are very
hard to solve numerically. Here under the so-called Boneh-Shaw marking
assumption, we reformulate the capacity as the value of a single two-person
zero-sum game, and show that it is achieved by a saddle-point solution.
  If the maximal coalition size is $k$ and the fingerprint alphabet is binary,
we derive equations that can numerically solve the capacity game for arbitrary
$k$. We also provide tight upper and lower bounds on the capacity. Finally, we
discuss the asymptotic behavior of the fingerprinting game for large $k$ and
practical implementation issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1385</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1385</id><created>2009-05-09</created><authors><author><keyname>Niennattrakul</keyname><forenames>Vit</forenames></author><author><keyname>Ratanamahatana</keyname><forenames>Chotirat Ann</forenames></author></authors><title>Making Hand Geometry Verification System More Accurate Using Time Series
  Representation with R-K Band Learning</title><categories>cs.CR</categories><comments>In Proceedings of 11th National Computer Science and Engineering
  Conference (NCSEC 2007), Bangkok, Thailand, 19/11/2007. 8 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  At present, applications of biometrics are rapidly increasing due to
inconveniences in using traditional passwords and physical keys. Hand geometry,
one of the most well-known biometrics, is implemented in many verification
systems with various feature extraction methods. In recent work, a hand
geometry verification system using time series conversion techniques and
Dynamic Time Warping (DTW) distance measure with Sakoe-Chiba band has been
proposed. This system demonstrates many advantages, especially ease of
implementation and small storage space requirement using time series
representation. In this paper, we propose a novel hand geometry verification
system that exploits DTW distance measure and R-K band learning to further
improve the system performance. Finally, our evaluation reveals that our
proposed system outperforms the current system by a wide margin, in terms of
False Acceptance Rate (FAR), False Rejection Rate (FRR), and Total Success Rate
(TSR) at Equal Error Rate (EER).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1386</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1386</id><created>2009-05-09</created><updated>2009-06-26</updated><authors><author><keyname>Coronel</keyname><forenames>Pedro</forenames></author><author><keyname>G&#xe4;rtner</keyname><forenames>Markus</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Selective-Fading Multiple-Access MIMO Channels: Diversity-Multiplexing
  Tradeoff and Dominant Outage Event Regions</title><categories>cs.IT math.IT</categories><comments>Corrections in Section V</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish the optimal diversity-multiplexing (DM) tradeoff for coherent
selective-fading multiple-access MIMO channels and provide corresponding code
design criteria. As a byproduct, on the conceptual level, we find an
interesting relation between the DM tradeoff framework and the notion of
dominant error event regions, first introduced in the AWGN case by Gallager,
IEEE Trans. IT, 1985. This relation allows us to accurately characterize the
error mechanisms in MIMO fading multiple-access channels. In particular, we
find that, for a given rate tuple, the maximum achievable diversity order is
determined by a single outage event that dominates the total error probability
exponentially in SNR. Finally, we examine the distributed space-time code
construction proposed by Badr and Belfiore, Int. Zurich Seminar on Commun.,
2008, using the code design criteria derived in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1424</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1424</id><created>2009-05-09</created><authors><author><keyname>Kuznetsov</keyname><forenames>Sergei O.</forenames></author><author><keyname>Ignatov</keyname><forenames>Dmitry I.</forenames></author></authors><title>Concept Stability for Constructing Taxonomies of Web-site Users</title><categories>cs.CY cs.AI cs.SI stat.ML</categories><comments>Sergei O. Kuznetsov, D.I. Ignatov, Concept Stability for Constructing
  Taxonomies of Web-site users, in Proc. Social Network Analysis and Conceptual
  Structures: Exploring Opportunities, S. Obiedkov, C. Roth (Eds.),
  Clermont-Ferrand (France), February 16, 2007</comments><acm-class>H.2.8; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Owners of a web-site are often interested in analysis of groups of users of
their site. Information on these groups can help optimizing the structure and
contents of the site. In this paper we use an approach based on formal concepts
for constructing taxonomies of user groups. For decreasing the huge amount of
concepts that arise in applications, we employ stability index of a concept,
which describes how a group given by a concept extent differs from other such
groups. We analyze resulting taxonomies of user groups for three target
websites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1460</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1460</id><created>2009-05-10</created><authors><author><keyname>Gao</keyname><forenames>Feifei</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Liang</keyname><forenames>Ying-Chang</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Design of Learning Based MIMO Cognitive Radio Systems</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the design issues of the multi-antenna-based cognitive
radio (CR) system that is able to operate concurrently with the licensed
primary radio (PR) system. We propose a practical CR transmission strategy
consisting of three major stages: environment learning, channel training, and
data transmission. In the environment learning stage, the CR transceivers both
listen to the PR transmission and apply blind algorithms to estimate the spaces
that are orthogonal to the channels from the PR. Assuming time-division duplex
(TDD) based transmission for the PR, cognitive beamforming is then designed and
applied at CR transceivers to restrict the interference to/from the PR during
the subsequent channel training and data transmission stages. In the channel
training stage, the CR transmitter sends training signals to the CR receiver,
which applies the linear-minimum-mean-square-error (LMMSE) based estimator to
estimate the effective channel. Considering imperfect estimations in both
learning and training stages, we derive a lower bound on the ergodic capacity
achievable for the CR in the data transmission stage. From this capacity lower
bound, we observe a general learning/training/throughput tradeoff associated
with the proposed scheme, pertinent to transmit power allocation between
training and transmission stages, as well as time allocation among learning,
training, and transmission stages. We characterize the aforementioned tradeoff
by optimizing the associated power and time allocation to maximize the CR
ergodic capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1512</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1512</id><created>2009-05-10</created><authors><author><keyname>Mahdavifar</keyname><forenames>Hessam</forenames></author><author><keyname>Siegel</keyname><forenames>Paul H.</forenames></author><author><keyname>Vardy</keyname><forenames>Alexander</forenames></author><author><keyname>Wolf</keyname><forenames>Jack K.</forenames></author><author><keyname>Yaakobi</keyname><forenames>Eitan</forenames></author></authors><title>A Nearly Optimal Construction of Flash Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Flash memory is a non-volatile computer memory comprised of blocks of cells,
wherein each cell can take on q different values or levels. While increasing
the cell level is easy, reducing the level of a cell can be accomplished only
by erasing an entire block. Since block erasures are highly undesirable, coding
schemes - known as floating codes or flash codes - have been designed in order
to maximize the number of times that information stored in a flash memory can
be written (and re-written) prior to incurring a block erasure. An (n,k,t)_q
flash code C is a coding scheme for storing k information bits in n cells in
such a way that any sequence of up to t writes (where a write is a transition 0
-&gt; 1 or 1 -&gt; 0 in any one of the k bits) can be accommodated without a block
erasure. The total number of available level transitions in n cells is n(q-1),
and the write deficiency of C, defined as \delta(C) = n(q-1) - t, is a measure
of how close the code comes to perfectly utilizing all these transitions. For k
&gt; 6 and large n, the best previously known construction of flash codes achieves
a write deficiency of O(qk^2). On the other hand, the best known lower bound on
write deficiency is \Omega(qk). In this paper, we present a new construction of
flash codes that approaches this lower bound to within a factor logarithmic in
k. To this end, we first improve upon the so-called &quot;indexed&quot; flash codes, due
to Jiang and Bruck, by eliminating the need for index cells in the Jiang-Bruck
construction. Next, we further increase the number of writes by introducing a
new multi-stage (recursive) indexing scheme. We then show that the write
deficiency of the resulting flash codes is O(qk\log k) if q \geq \log_2k, and
at most O(k\log^2 k) otherwise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1537</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1537</id><created>2009-05-11</created><authors><author><keyname>Choi</keyname><forenames>Sang Won</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>On the Separability of Parallel Gaussian Interference Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, to appear in proc. IEEE ISIT, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The separability in parallel Gaussian interference channels (PGICs) is
studied in this paper. We generalize the separability results in one-sided
PGICs (OPGICs) by Sung \emph{et al.} to two-sided PGICs (TPGICs). Specifically,
for strong and mixed TPGICs, we show necessary and sufficient conditions for
the separability. For this, we show diagonal covariance matrices are sum-rate
optimal for strong and mixed TPGICs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1543</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1543</id><created>2009-05-11</created><authors><author><keyname>Jeon</keyname><forenames>Sang-Woon</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Sum capacity of multi-source linear finite-field relay networks with
  fading</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, to appear in proc. IEEE ISIT, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a fading linear finite-field relay network having multiple
source-destination pairs. Because of the interference created by different
unicast sessions, the problem of finding its capacity region is in general
difficult. We observe that, since channels are time-varying, relays can deliver
their received signals by waiting for appropriate channel realizations such
that the destinations can decode their messages without interference. We
propose a block Markov encoding and relaying scheme that exploits such channel
variations. By deriving a general cut-set upper bound and an achievable rate
region, we characterize the sum capacity for some classes of channel
distributions and network topologies. For example, when the channels are
uniformly distributed, the sum capacity is given by the minimum average rank of
the channel matrices constructed by all cuts that separate the entire sources
and destinations. We also describe other cases where the capacity is
characterized.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1546</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1546</id><created>2009-05-11</created><updated>2009-05-14</updated><authors><author><keyname>Zhu</keyname><forenames>Zhisu</forenames></author><author><keyname>So</keyname><forenames>Anthony Man-Cho</forenames></author><author><keyname>Ye</keyname><forenames>Yinyu</forenames></author></authors><title>Fast and Near-Optimal Matrix Completion via Randomized Basis Pursuit</title><categories>cs.IT cs.LG math.IT</categories><comments>23 pages. New section (Section 3.3) added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the philosophy and phenomenal success of compressed sensing, the
problem of reconstructing a matrix from a sampling of its entries has attracted
much attention recently. Such a problem can be viewed as an
information-theoretic variant of the well-studied matrix completion problem,
and the main objective is to design an efficient algorithm that can reconstruct
a matrix by inspecting only a small number of its entries. Although this is an
impossible task in general, Cand\`es and co-authors have recently shown that
under a so-called incoherence assumption, a rank $r$ $n\times n$ matrix can be
reconstructed using semidefinite programming (SDP) after one inspects
$O(nr\log^6n)$ of its entries. In this paper we propose an alternative approach
that is much more efficient and can reconstruct a larger class of matrices by
inspecting a significantly smaller number of the entries. Specifically, we
first introduce a class of so-called stable matrices and show that it includes
all those that satisfy the incoherence assumption. Then, we propose a
randomized basis pursuit (RBP) algorithm and show that it can reconstruct a
stable rank $r$ $n\times n$ matrix after inspecting $O(nr\log n)$ of its
entries. Our sampling bound is only a logarithmic factor away from the
information-theoretic limit and is essentially optimal. Moreover, the runtime
of the RBP algorithm is bounded by $O(nr^2\log n+n^2r)$, which compares very
favorably with the $\Omega(n^4r^2\log^{12}n)$ runtime of the SDP-based
algorithm. Perhaps more importantly, our algorithm will provide an exact
reconstruction of the input matrix in polynomial time. By contrast, the
SDP-based algorithm can only provide an approximate one in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1583</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1583</id><created>2009-05-11</created><authors><author><keyname>Elekes</keyname><forenames>Gy&#xf6;rgy</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author></authors><title>On Lines, Joints, and Incidences in Three Dimensions</title><categories>cs.CG</categories><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We extend (and somewhat simplify) the algebraic proof technique of Guth and
Katz \cite{GK}, to obtain several sharp bounds on the number of incidences
between lines and points in three dimensions. Specifically, we show: (i) The
maximum possible number of incidences between $n$ lines in $\reals^3$ and $m$
of their joints (points incident to at least three non-coplanar lines) is
$\Theta(m^{1/3}n)$ for $m\ge n$, and $\Theta(m^{2/3}n^{2/3}+m+n)$ for $m\le n$.
(ii) In particular, the number of such incidences cannot exceed $O(n^{3/2})$.
(iii) The bound in (i) also holds for incidences between $n$ lines and $m$
arbitrary points (not necessarily joints), provided that no plane contains more
than O(n) points and each point is incident to at least three lines. As a
preliminary step, we give a simpler proof of (an extension of) the bound
$O(n^{3/2})$, established by Guth and Katz, on the number of joints in a set of
$n$ lines in $\reals^3$. We also present some further extensions of these
bounds, and give a proof of Bourgain's conjecture on incidences between points
and lines in 3-space, which constitutes a simpler alternative to the proof of
\cite{GK}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1587</identifier>
 <datestamp>2010-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1587</id><created>2009-05-11</created><updated>2010-10-28</updated><authors><author><keyname>Scheder</keyname><forenames>Dominik</forenames></author></authors><title>Unsatisfiable Linear CNF Formulas Are Large and Complex</title><categories>cs.DM</categories><comments>12 pages plus a two-page appendix; corrected an inconsistency between
  title of the paper and title of the arxiv submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We call a CNF formula linear if any two clauses have at most one variable in
common. We show that there exist unsatisfiable linear k-CNF formulas with at
most 4k^2 4^k clauses, and on the other hand, any linear k-CNF formula with at
most 4^k/(8e^2k^2) clauses is satisfiable. The upper bound uses probabilistic
means, and we have no explicit construction coming even close to it. One reason
for this is that unsatisfiable linear formulas exhibit a more complex structure
than general (non-linear) formulas: First, any treelike resolution refutation
of any unsatisfiable linear k-CNF formula has size at least 2^(2^(k/2-1))$.
This implies that small unsatisfiable linear k-CNF formulas are hard instances
for Davis-Putnam style splitting algorithms. Second, if we require that the
formula F have a strict resolution tree, i.e. every clause of F is used only
once in the resolution tree, then we need at least a^a^...^a clauses, where a
is approximately 2 and the height of this tower is roughly k.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1594</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1594</id><created>2009-05-11</created><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author><author><keyname>Allen</keyname><forenames>David W.</forenames></author><author><keyname>Shinavier</keyname><forenames>Joshua</forenames></author><author><keyname>Ebersole</keyname><forenames>Gary</forenames></author></authors><title>A Recommender System to Support the Scholarly Communication Process</title><categories>cs.DL cs.IR</categories><report-no>KRS-2009-02</report-no><acm-class>H.3.5; H.3.7; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of researchers, articles, journals, conferences, funding
opportunities, and other such scholarly resources continues to grow every year
and at an increasing rate. Many services have emerged to support scholars in
navigating particular aspects of this resource-rich environment. Some
commercial publishers provide recommender and alert services for the articles
and journals in their digital libraries. Similarly, numerous noncommercial
social bookmarking services have emerged for citation sharing. While these
services do provide some support, they lack an understanding of the various
problem-solving scenarios that researchers face daily. Example scenarios, to
name a few, include when a scholar is in search of an article related to
another article of interest, when a scholar is in search of a potential
collaborator for a funding opportunity, when a scholar is in search of an
optimal venue to which to submit their article, and when a scholar, in the role
of an editor, is in search of referees to review an article. All of these
example scenarios can be represented as a problem in information filtering by
means of context-sensitive recommendation. This article presents an overview of
a context-sensitive recommender system to support the scholarly communication
process that is based on the standards and technology set forth by the Semantic
Web initiative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1608</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1608</id><created>2009-05-11</created><authors><author><keyname>Lasserre</keyname><forenames>Jean</forenames><affiliation>LAAS</affiliation></author><author><keyname>Zeron</keyname><forenames>S.</forenames></author></authors><title>Certificates and relaxations for integer programming and the semi-group
  membership problem</title><categories>math.OC cs.DM</categories><comments>21 pages</comments><proxy>ccsd hal-00382774</proxy><msc-class>90, C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider integer programming and the semi-group membership problem. We
provide the following theorem of the alternative: the system Ax=b has no
nonnegative integral solution x if and only if p(b) &lt;0 for some given
polynomial p whose vector of coefficients lies in a convex cone that we
characterize. We also provide a hierarchy of linear programming relaxations,
where the continuous case Ax=b with x real and nonnegative, describes the first
relaxation in the hierarchy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1609</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1609</id><created>2009-05-11</created><authors><author><keyname>Hathout</keyname><forenames>Nabil</forenames><affiliation>CLLE</affiliation></author></authors><title>Acquisition of morphological families and derivational series from a
  machine readable dictionary</title><categories>cs.CL</categories><comments>proceedings of the 6th D\'ecembrettes</comments><proxy>ccsd hal-00382808</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents a linguistic and computational model aiming at making the
morphological structure of the lexicon emerge from the formal and semantic
regularities of the words it contains. The model is word-based. The proposed
morphological structure consists of (1) binary relations that connect each
headword with words that are morphologically related, and especially with the
members of its morphological family and its derivational series, and of (2) the
analogies that hold between the words. The model has been tested on the lexicon
of French using the TLFi machine readable dictionary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1643</identifier>
 <datestamp>2009-05-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1643</id><created>2009-05-11</created><updated>2009-05-11</updated><authors><author><keyname>Ma</keyname><forenames>Shiqian</forenames></author><author><keyname>Goldfarb</keyname><forenames>Donald</forenames></author><author><keyname>Chen</keyname><forenames>Lifeng</forenames></author></authors><title>Fixed Point and Bregman Iterative Methods for Matrix Rank Minimization</title><categories>math.OC cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The linearly constrained matrix rank minimization problem is widely
applicable in many fields such as control, signal processing and system
identification. The tightest convex relaxation of this problem is the linearly
constrained nuclear norm minimization. Although the latter can be cast as a
semidefinite programming problem, such an approach is computationally expensive
to solve when the matrices are large. In this paper, we propose fixed point and
Bregman iterative algorithms for solving the nuclear norm minimization problem
and prove convergence of the first of these algorithms. By using a homotopy
approach together with an approximate singular value decomposition procedure,
we get a very fast, robust and powerful algorithm, which we call FPCA (Fixed
Point Continuation with Approximate SVD), that can solve very large matrix rank
minimization problems. Our numerical results on randomly generated and real
matrix completion problems demonstrate that this algorithm is much faster and
provides much better recoverability than semidefinite programming solvers such
as SDPT3. For example, our algorithm can recover 1000 x 1000 matrices of rank
50 with a relative error of 1e-5 in about 3 minutes by sampling only 20 percent
of the elements. We know of no other method that achieves as good
recoverability. Numerical experiments on online recommendation, DNA microarray
data set and image inpainting problems demonstrate the effectiveness of our
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1737</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1737</id><created>2009-05-11</created><authors><author><keyname>Czyzowicz</keyname><forenames>J.</forenames></author><author><keyname>Dobrev</keyname><forenames>S.</forenames></author><author><keyname>Gasieniec</keyname><forenames>L.</forenames></author><author><keyname>Ilcinkas</keyname><forenames>D.</forenames></author><author><keyname>Jansson</keyname><forenames>J.</forenames></author><author><keyname>Klasing</keyname><forenames>R.</forenames></author><author><keyname>Lignos</keyname><forenames>I.</forenames></author><author><keyname>Martin</keyname><forenames>R.</forenames></author><author><keyname>Sadakane</keyname><forenames>K.</forenames></author><author><keyname>Sung</keyname><forenames>W. -K.</forenames></author></authors><title>More efficient periodic traversal in anonymous undirected graphs</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of periodic graph exploration in which a mobile
entity with constant memory, an agent, has to visit all n nodes of an arbitrary
undirected graph G in a periodic manner. Graphs are supposed to be anonymous,
that is, nodes are unlabeled. However, while visiting a node, the robot has to
distinguish between edges incident to it. For each node v the endpoints of the
edges incident to v are uniquely identified by different integer labels called
port numbers. We are interested in minimisation of the length of the
exploration period.
  This problem is unsolvable if the local port numbers are set arbitrarily.
However, surprisingly small periods can be achieved when assigning carefully
the local port numbers. Dobrev et al. described an algorithm for assigning port
numbers, and an oblivious agent (i.e. agent with no memory) using it, such that
the agent explores all graphs of size n within period 10n. Providing the agent
with a constant number of memory bits, the optimal length of the period was
previously proved to be no more than 3.75n (using a different assignment of the
port numbers). In this paper, we improve both these bounds. More precisely, we
show a period of length at most 4 1/3 n for oblivious agents, and a period of
length at most 3.5n for agents with constant memory. Moreover, we give the
first non-trivial lower bound, 2.8n, on the period length for the oblivious
case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1738</identifier>
 <datestamp>2010-07-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1738</id><created>2009-05-11</created><updated>2010-07-28</updated><authors><author><keyname>Jelenkovic</keyname><forenames>Predrag R.</forenames></author><author><keyname>Olvera-Cravioto</keyname><forenames>Mariana</forenames></author></authors><title>Information Ranking and Power Laws on Trees</title><categories>math.PR cs.PF</categories><msc-class>60H25, 60J80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the situations when the solution to a weighted stochastic recursion
has a power law tail. To this end, we develop two complementary approaches, the
first one extends Goldie's (1991) implicit renewal theorem to cover recursions
on trees; and the second one is based on a direct sample path large deviations
analysis of weighted recursive random sums. We believe that these methods may
be of independent interest in the analysis of more general weighted branching
processes as well as in the analysis of algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1740</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1740</id><created>2009-05-11</created><authors><author><keyname>Wu</keyname><forenames>Fang</forenames></author><author><keyname>Wilkinson</keyname><forenames>Dennis M.</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>Feedback loops of attention in peer production</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A significant percentage of online content is now published and consumed via
the mechanism of crowdsourcing. While any user can contribute to these forums,
a disproportionately large percentage of the content is submitted by very
active and devoted users, whose continuing participation is key to the sites'
success. As we show, people's propensity to keep participating increases the
more they contribute, suggesting motivating factors which increase over time.
This paper demonstrates that submitters who stop receiving attention tend to
stop contributing, while prolific contributors attract an ever increasing
number of followers and their attention in a feedback loop. We demonstrate that
this mechanism leads to the observed power law in the number of contributions
per user and support our assertions by an analysis of hundreds of millions of
contributions to top content sharing websites Digg.com and Youtube.com.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1744</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1744</id><created>2009-05-11</created><authors><author><keyname>Saeed</keyname><forenames>Fahad</forenames></author><author><keyname>Khokhar</keyname><forenames>Ashfaq</forenames></author></authors><title>A Domain Decomposition Strategy for Alignment of Multiple Biological
  Sequences on Multiprocessor Platforms</title><categories>cs.DC q-bio.QM</categories><comments>36 pages, 17 figures, Accepted manuscript in Journal of Parallel and
  Distributed Computing(JPDC)</comments><journal-ref>as: F. Saeed, A. Khokhar, A domain decomposition strategy for
  alignment of multiple biological sequences on multiprocessor platforms, J.
  Parallel Distrib. Comput. (2009)</journal-ref><doi>10.1016/j.jpdc.2009.03.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple Sequences Alignment (MSA) of biological sequences is a fundamental
problem in computational biology due to its critical significance in wide
ranging applications including haplotype reconstruction, sequence homology,
phylogenetic analysis, and prediction of evolutionary origins. The MSA problem
is considered NP-hard and known heuristics for the problem do not scale well
with increasing number of sequences. On the other hand, with the advent of new
breed of fast sequencing techniques it is now possible to generate thousands of
sequences very quickly. For rapid sequence analysis, it is therefore desirable
to develop fast MSA algorithms that scale well with the increase in the dataset
size. In this paper, we present a novel domain decomposition based technique to
solve the MSA problem on multiprocessing platforms. The domain decomposition
based technique, in addition to yielding better quality, gives enormous
advantage in terms of execution time and memory requirements. The proposed
strategy allows to decrease the time complexity of any known heuristic of
O(N)^x complexity by a factor of O(1/p)^x, where N is the number of sequences,
x depends on the underlying heuristic approach, and p is the number of
processing nodes. In particular, we propose a highly scalable algorithm,
Sample-Align-D, for aligning biological sequences using Muscle system as the
underlying heuristic. The proposed algorithm has been implemented on a cluster
of workstations using MPI library. Experimental results for different problem
sizes are analyzed in terms of quality of alignment, execution time and
speed-up.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1745</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1745</id><created>2009-05-12</created><authors><author><keyname>Gou</keyname><forenames>Tiangao</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author></authors><title>Capacity of a Class of Symmetric SIMO Gaussian Interference Channels
  within O(1)</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The N+1 user, 1 x N single input multiple output (SIMO) Gaussian interference
channel where each transmitter has a single antenna and each receiver has N
antennas is studied. The symmetric capacity within O(1) is characterized for
the symmetric case where all direct links have the same signal-to-noise ratio
(SNR) and all undesired links have the same interference-to-noise ratio (INR).
The gap to the exact capacity is a constant which is independent of SNR and
INR. To get this result, we first generalize the deterministic interference
channel introduced by El Gamal and Costa to model interference channels with
multiple antennas. We derive the capacity region of this deterministic
interference channel. Based on the insights provided by the deterministic
channel, we characterize the generalized degrees of freedom (GDOF) of Gaussian
case, which directly leads to the O(1) capacity approximation. On the
achievability side, an interesting conclusion is that the generalized degrees
of freedom (GDOF) regime where treating interference as noise is found to be
optimal in the 2 user interference channel, does not appear in the N+1 user, 1
x N SIMO case. On the converse side, new multi-user outer bounds emerge out of
this work that do not follow directly from the 2 user case. In addition to the
GDOF region, the outer bounds identify a strong interference regime where the
capacity region is established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1751</identifier>
 <datestamp>2009-10-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1751</id><created>2009-05-12</created><updated>2009-10-24</updated><authors><author><keyname>Pang</keyname><forenames>Chao-Yang</forenames></author><author><keyname>Wang</keyname><forenames>Chong-Bao</forenames></author><author><keyname>Hu</keyname><forenames>Ben-Qiong</forenames></author></authors><title>Experiment Study of Entropy Convergence of Ant Colony Optimization</title><categories>cs.NE cs.AI</categories><comments>21 papges, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ant colony optimization (ACO) has been applied to the field of combinatorial
optimization widely. But the study of convergence theory of ACO is rare under
general condition. In this paper, the authors try to find the evidence to prove
that entropy is related to the convergence of ACO, especially to the estimation
of the minimum iteration number of convergence. Entropy is a new view point
possibly to studying the ACO convergence under general condition. Key Words:
Ant Colony Optimization, Convergence of ACO, Entropy
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1755</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1755</id><created>2009-05-11</created><authors><author><keyname>Wong</keyname><forenames>Raymond Chi-Wing</forenames></author><author><keyname>Fu</keyname><forenames>Ada Wai-Chee</forenames></author><author><keyname>Wang</keyname><forenames>Ke</forenames></author><author><keyname>Xu</keyname><forenames>Yabo</forenames></author><author><keyname>Yu</keyname><forenames>Philip S.</forenames></author></authors><title>Can the Utility of Anonymized Data be used for Privacy Breaches?</title><categories>cs.DB</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Group based anonymization is the most widely studied approach for privacy
preserving data publishing. This includes k-anonymity, l-diversity, and
t-closeness, to name a few. The goal of this paper is to raise a fundamental
issue on the privacy exposure of the current group based approach. This has
been overlooked in the past. The group based anonymization approach basically
hides each individual record behind a group to preserve data privacy. If not
properly anonymized, patterns can actually be derived from the published data
and be used by the adversary to breach individual privacy. For example, from
the medical records released, if patterns such as people from certain countries
rarely suffer from some disease can be derived, then the information can be
used to imply linkage of other people in an anonymized group with this disease
with higher likelihood. We call the derived patterns from the published data
the foreground knowledge. This is in contrast to the background knowledge that
the adversary may obtain from other channels as studied in some previous work.
Finally, we show by experiments that the attack is realistic in the privacy
benchmark dataset under the traditional group based anonymization approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1769</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1769</id><created>2009-05-12</created><authors><author><keyname>Choudhury</keyname><forenames>Pabitra Pal</forenames></author><author><keyname>Sahoo</keyname><forenames>Sudhakar</forenames></author><author><keyname>Hasssan</keyname><forenames>Sk Sarif</forenames></author><author><keyname>Basu</keyname><forenames>Satrajit</forenames></author><author><keyname>Ghosh</keyname><forenames>Dibyendu</forenames></author><author><keyname>Kar</keyname><forenames>Debarun</forenames></author><author><keyname>Ghosh</keyname><forenames>Abhishek</forenames></author><author><keyname>Ghosh</keyname><forenames>Avijit</forenames></author><author><keyname>Ghosh</keyname><forenames>Amal K.</forenames></author></authors><title>Classification of Cellular Automata Rules Based on Their Properties</title><categories>cs.DM</categories><comments>Releted to Cellular Automata!</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a classification of Cellular Automata rules based on its
properties at the nth iteration. Elaborate computer program has been designed
to get the nth iteration for arbitrary 1-D or 2-D CA rules. Studies indicate
that the figures at some particular iteration might be helpful for some
specific application. The hardware circuit implementation can be done using
opto-electronic components [1-7].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1778</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1778</id><created>2009-05-12</created><authors><author><keyname>Aly</keyname><forenames>Salah A.</forenames></author><author><keyname>Kamal</keyname><forenames>Ahmed E.</forenames></author></authors><title>Encoding of Network Protection Codes Against Link and Node Failures Over
  Finite Fields</title><categories>cs.IT cs.CR cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Link and node failures are common two fundamental problems that affect
operational networks. Hence, protection of communication networks is essential
to increase their reliability, performance, and operations. Much research work
has been done to protect against link and node failures, and to provide
reliable solutions based on pre-defined provision or dynamic restoration of the
domain. In this paper we develop network protection strategies against multiple
link failures using network coding and joint capacities. In these strategies,
the source nodes apply network coding for their transmitted data to provide
backup copies for recovery at the receivers' nodes. Such techniques can be
applied to optical, IP, and mesh networks. The encoding operations of
protection codes are defined over finite fields. Furthermore, the normalized
capacity of the communication network is given by $(n-t)/n$ in case of $t$ link
failures. In addition, a bound on the minimum required field size is derived.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1780</identifier>
 <datestamp>2009-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1780</id><created>2009-05-12</created><updated>2009-10-01</updated><authors><author><keyname>Calamoneri</keyname><forenames>Tiziana</forenames></author></authors><title>The L(2, 1)-Labeling Problem on Oriented Regular Grids</title><categories>cs.DM cs.DS</categories><comments>The content of this paper has been presented to ICTCS 2009, 28-30
  September, Cremona, Italy. This updated version is a longer and more complete
  version of the first submission (from 10 to 13 pages, from 5 to 7 figures)
  and a wrong figure has been corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The L(2, 1)-labeling of a digraph G is a function f from the node set of $G$
to the set of all nonnegative integers such that $|f(x)-f(y)| \geq 2$ if $x$
and $y$ are at distance 1, and $f(x)=f(y)$ if $x$ and $y$ are at distance 2,
where the distance from vertex $x$ to vertex $y$ is the length of a shortest
dipath from $x$ to $y$. The minimum of the maximum used label over all $L(2,
1)$-labelings of $G$ is called $\lambda(G)$. In this paper we study the L(2,
1)-labeling problem on squared, triangular and hexagonal grids and for them we
compute the exact values of $\lambda$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1786</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1786</id><created>2009-05-12</created><authors><author><keyname>Cournier</keyname><forenames>Alain</forenames><affiliation>MIS</affiliation></author><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Villain</keyname><forenames>Vincent</forenames><affiliation>MIS</affiliation></author></authors><title>Une CNS pour l'acheminement de messages instantan\'ement stabilisant</title><categories>cs.DC</categories><proxy>ccsd inria-00383116</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A snap-stabilizing algorithm ensures that it always behaves according to its
specifications whenever it starts from an arbitrary configuration. In this
paper, we interest in the message forwarding problem in a message-switched
network. We must manage network ressources in order to deliver messages to any
processor of the network. In this goal, we need information given by a routing
algorithm. But, due to the context of stabilization, this information can be
initially corrupted. It is why the existence of snap-stabilizing algorithms for
this task (proved in [CDV09]) implies that we can ask the system to begin
forwarding messages even if routing tables are initially corrupted. In this
paper, we generalize the previous result given a necessary and sufficient
condition to solve the forwarding problem in a snap-stabilizing way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1820</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1820</id><created>2009-05-12</created><authors><author><keyname>Baldoni</keyname><forenames>Velleda</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>Berline</keyname><forenames>Nicole</forenames><affiliation>CMLS-EcolePolytechnique</affiliation></author><author><keyname>Vergne</keyname><forenames>Mich&#xe8;le</forenames><affiliation>CMLS-EcolePolytechnique, IMJ</affiliation></author></authors><title>Summing a polynomial function over integral points of a polygon. User's
  guide</title><categories>cs.CG math.CO</categories><proxy>ccsd hal-00383196</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This document is a companion for the Maple program \textbf{Summing a
polynomial function over integral points of a polygon}. It contains two parts.
First, we see what this programs does. In the second part, we briefly recall
the mathematical background.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1883</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1883</id><created>2009-05-12</created><authors><author><keyname>Cuff</keyname><forenames>Paul</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Su</keyname><forenames>Han-I</forenames><affiliation>Stanford University</affiliation></author><author><keyname>Gamal</keyname><forenames>Abbas El</forenames><affiliation>Stanford University</affiliation></author></authors><title>Cascade multiterminal source coding</title><categories>cs.IT math.IT</categories><comments>ISIT 2009, 5 pages, 1 eps figure, uses IEEEtran.cls</comments><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate distributed source coding of two correlated sources X and Y
where messages are passed to a decoder in a cascade fashion. The encoder of X
sends a message at rate R_1 to the encoder of Y. The encoder of Y then sends a
message to the decoder at rate R_2 based both on Y and on the message it
received about X. The decoder's task is to estimate a function of X and Y. For
example, we consider the minimum mean squared-error distortion when encoding
the sum of jointly Gaussian random variables under these constraints. We also
characterize the rates needed to reconstruct a function of X and Y losslessly.
  Our general contribution toward understanding the limits of the cascade
multiterminal source coding network is in the form of inner and outer bounds on
the achievable rate region for satisfying a distortion constraint for an
arbitrary distortion function d(x,y,z). The inner bound makes use of a balance
between two encoding tactics--relaying the information about X and
recompressing the information about X jointly with Y. In the Gaussian case, a
threshold is discovered for identifying which of the two extreme strategies
optimizes the inner bound. Relaying outperforms recompressing the sum at the
relay for some rate pairs if the variance of X is greater than the variance of
Y.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1893</identifier>
 <datestamp>2010-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1893</id><created>2009-05-12</created><updated>2010-04-01</updated><authors><author><keyname>Bradde</keyname><forenames>S.</forenames></author><author><keyname>Braunstein</keyname><forenames>A.</forenames></author><author><keyname>Mahmoudi</keyname><forenames>H.</forenames></author><author><keyname>Tria</keyname><forenames>F.</forenames></author><author><keyname>Weigt</keyname><forenames>M.</forenames></author><author><keyname>Zecchina</keyname><forenames>R.</forenames></author></authors><title>Aligning graphs and finding substructures by a cavity approach</title><categories>q-bio.QM cond-mat.stat-mech cs.DS</categories><comments>5 pages, 4 figures</comments><journal-ref>2010 Europhys. Lett. 89 37009</journal-ref><doi>10.1209/0295-5075/89/37009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new distributed algorithm for aligning graphs or finding
substructures within a given graph. It is based on the cavity method and is
used to study the maximum-clique and the graph-alignment problems in random
graphs. The algorithm allows to analyze large graphs and may find applications
in fields such as computational biology. As a proof of concept we use our
algorithm to align the similarity graphs of two interacting protein families
involved in bacterial signal transduction, and to predict actually interacting
protein partners between these families.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1906</identifier>
 <datestamp>2009-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1906</id><created>2009-05-12</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Hirschberg</keyname><forenames>Daniel S.</forenames></author></authors><title>Improved Adaptive Group Testing Algorithms with Applications to Multiple
  Access Channels and Dead Sensor Diagnosis</title><categories>cs.DS cs.IT math.IT</categories><comments>Expanded version of a paper appearing in ACM Symposium on Parallelism
  in Algorithms and Architectures (SPAA), and preliminary version of paper
  appearing in Journal of Combinatorial Optimization</comments><journal-ref>Journal of Combinatorial Optimization, Volume 15, Number 1,
  January, 2008</journal-ref><doi>10.1007/s10878-007-9087-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study group-testing algorithms for resolving broadcast conflicts on a
multiple access channel (MAC) and for identifying the dead sensors in a mobile
ad hoc wireless network. In group-testing algorithms, we are asked to identify
all the defective items in a set of items when we can test arbitrary subsets of
items. In the standard group-testing problem, the result of a test is
binary--the tested subset either contains defective items or not. In the more
generalized versions we study in this paper, the result of each test is
non-binary. For example, it may indicate whether the number of defective items
contained in the tested subset is zero, one, or at least two. We give adaptive
algorithms that are provably more efficient than previous group testing
algorithms. We also show how our algorithms can be applied to solve conflict
resolution on a MAC and dead sensor diagnosis. Dead sensor diagnosis poses an
interesting challenge compared to MAC resolution, because dead sensors are not
locally detectable, nor are they themselves active participants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1964</identifier>
 <datestamp>2009-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1964</id><created>2009-05-12</created><updated>2009-05-15</updated><authors><author><keyname>Haddad</keyname><forenames>Rony EL</forenames></author><author><keyname>Smith</keyname><forenames>Brian</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>On Models of Multi-user Gaussian Channels with Fading</title><categories>cs.IT math.IT</categories><comments>6 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An analytically tractable model for Gaussian multiuser channels with fading
is studied, and the capacity region of this model is found to be a good
approximation of the capacity region of the original Gaussian network. This
work extends the existing body of work on deterministic models for Gaussian
multiuser channels to include the physical phenomenon of fading. In particular,
it generalizes these results to a unicast, multiple node network setting with
fading.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1990</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1990</id><created>2009-05-12</created><updated>2009-05-13</updated><authors><author><keyname>Jeong</keyname><forenames>Halyun</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>Sparse Linear Representation</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in proc. IEEE ISIT, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the question of how well a signal can be reprsented by a
sparse linear combination of reference signals from an overcomplete dictionary.
When the dictionary size is exponential in the dimension of signal, then the
exact characterization of the optimal distortion is given as a function of the
dictionary size exponent and the number of reference signals for the linear
representation. Roughly speaking, every signal is sparse if the dictionary size
is exponentially large, no matter how small the exponent is. Furthermore, an
iterative method similar to matching pursuit that successively finds the best
reference signal at each stage gives asymptotically optimal representations.
This method is essentially equivalent to successive refinement for multiple
descriptions and provides a simple alternative proof of the successive
refinability of white Gaussian sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1993</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1993</id><created>2009-05-13</created><authors><author><keyname>Bourgeois</keyname><forenames>Nicolas</forenames></author><author><keyname>Escoffier</keyname><forenames>Bruno</forenames></author><author><keyname>Paschos</keyname><forenames>Vangelis Th.</forenames></author></authors><title>Fast algorithms for min independent dominating set</title><categories>cs.DS cs.CC cs.DM</categories><doi>10.1007/978-3-642-13284-1_20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We first devise a branching algorithm that computes a minimum independent
dominating set on any graph with running time O*(2^0.424n) and polynomial
space. This improves the O*(2^0.441n) result by (S. Gaspers and M. Liedloff, A
branch-and-reduce algorithm for finding a minimum independent dominating set in
graphs, Proc. WG'06). We then show that, for every r&gt;3, it is possible to
compute an r-((r-1)/r)log_2(r)-approximate solution for min independent
dominating set within time O*(2^(nlog_2(r)/r)).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.1995</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.1995</id><created>2009-05-12</created><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Papadimitriou</keyname><forenames>Christos</forenames></author><author><keyname>Schapira</keyname><forenames>Michael</forenames></author><author><keyname>Singer</keyname><forenames>Yaron</forenames></author></authors><title>VC v. VCG: Inapproximability of Combinatorial Auctions via
  Generalizations of the VC Dimension</title><categories>cs.GT cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The existence of incentive-compatible computationally-efficient protocols for
combinatorial auctions with decent approximation ratios is the paradigmatic
problem in computational mechanism design. It is believed that in many cases
good approximations for combinatorial auctions may be unattainable due to an
inherent clash between truthfulness and computational efficiency. However, to
date, researchers lack the machinery to prove such results. In this paper, we
present a new approach that we believe holds great promise for making progress
on this important problem. We take the first steps towards the development of
new technologies for lower bounding the VC dimension of k-tuples of disjoint
sets. We apply this machinery to prove the first computational-complexity
inapproximability results for incentive-compatible mechanisms for combinatorial
auctions. These results hold for the important class of VCG-based mechanisms,
and are based on the complexity assumption that NP has no polynomial-size
circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2004</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2004</id><created>2009-05-12</created><authors><author><keyname>Shen</keyname><forenames>Yi-Dong</forenames></author><author><keyname>De Schreye</keyname><forenames>Danny</forenames></author><author><keyname>Voets</keyname><forenames>Dean</forenames></author></authors><title>Termination Prediction for General Logic Programs</title><categories>cs.PL cs.AI cs.LO</categories><comments>28 pages, 12 figures. to appear in Theory and Practice of Logic
  Programming (TPLP)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a heuristic framework for attacking the undecidable termination
problem of logic programs, as an alternative to current
termination/non-termination proof approaches. We introduce an idea of
termination prediction, which predicts termination of a logic program in case
that neither a termination nor a non-termination proof is applicable. We
establish a necessary and sufficient characterization of infinite (generalized)
SLDNF-derivations with arbitrary (concrete or moded) queries, and develop an
algorithm that predicts termination of general logic programs with arbitrary
non-floundering queries. We have implemented a termination prediction tool and
obtained quite satisfactory experimental results. Except for five programs
which break the experiment time limit, our prediction is 100% correct for all
296 benchmark programs of the Termination Competition 2007, of which eighteen
programs cannot be proved by any of the existing state-of-the-art analyzers
like AProVE07, NTI, Polytool and TALP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2028</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2028</id><created>2009-05-13</created><authors><author><keyname>Chang</keyname><forenames>Weng-Long</forenames></author><author><keyname>Ren</keyname><forenames>Ting-Ting</forenames></author><author><keyname>Feng</keyname><forenames>Mang</forenames></author><author><keyname>Luo</keyname><forenames>Jun</forenames></author><author><keyname>Lin</keyname><forenames>Kawuu Weicheng</forenames></author><author><keyname>Guo</keyname><forenames>Minyi</forenames></author><author><keyname>Lu</keyname><forenames>Lai Chin</forenames></author></authors><title>Quantum Algorithms of Bio-molecular Solutions for the Clique Problem on
  a Quantum Computer</title><categories>cs.DS</categories><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, it is demonstrated that the DNA-based algorithm [Ho et al.
2005] for solving an instance of the clique problem to any a graph G = (V, E)
with n vertices and p edges and its complementary graph G1 = (V, E1) with n
vertices and m = (((n*(n-1))/2)-p) edges can be implemented by Hadamard gates,
NOT gates, CNOT gates, CCNOT gates, Grover's operators, and quantum
measurements on a quantum computer. It is also demonstrated that if Grovers
algorithm is employed to accomplish the readout step in the DNA-based
algorithm, the quantum implementation of the DNA-based algorithm is equivalent
to the oracle work (in the language of Grover's algorithm), that is, the target
state labeling preceding Grover,s searching steps. It is shown that one oracle
work can be completed with O((2 * n) * (n + 1) * (n + 2) / 3) NOT gates, one
CNOT gate and O((4 * m) + (((2 * n) * (n + 1) * (n + 14)) / 6)) CCNOT gates.
This is to say that for the quantum implementation of the DNA-based algorithm
[Ho et al. 2005] a faster labeling of the target state is attained, which also
implies a speedy solution to an instance of the clique problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2098</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2098</id><created>2009-05-13</created><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author><author><keyname>Heath</keyname><forenames>Robert W.</forenames><suffix>Jr</suffix></author></authors><title>End-to-End Joint Antenna Selection Strategy and Distributed Compress and
  Forward Strategy for Relay Channels</title><categories>cs.IT math.IT</categories><comments>Accepted for publication in the special issue on cooperative
  communication in the Eurasip Journal on Wireless Communication and Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-hop relay channels use multiple relay stages, each with multiple relay
nodes, to facilitate communication between a source and destination.
Previously, distributed space-time codes were proposed to maximize the
achievable diversity-multiplexing tradeoff, however, they fail to achieve all
the points of the optimal diversity-multiplexing tradeoff. In the presence of a
low-rate feedback link from the destination to each relay stage and the source,
this paper proposes an end-to-end antenna selection (EEAS) strategy as an
alternative to distributed space-time codes. The EEAS strategy uses a subset of
antennas of each relay stage for transmission of the source signal to the
destination with amplify and forwarding at each relay stage. The subsets are
chosen such that they maximize the end-to-end mutual information at the
destination. The EEAS strategy achieves the corner points of the optimal
diversity-multiplexing tradeoff (corresponding to maximum diversity gain and
maximum multiplexing gain) and achieves better diversity gain at intermediate
values of multiplexing gain, versus the best known distributed space-time
coding strategies. A distributed compress and forward (CF) strategy is also
proposed to achieve all points of the optimal diversity-multiplexing tradeoff
for a two-hop relay channel with multiple relay nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2125</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2125</id><created>2009-05-13</created><updated>2010-03-22</updated><authors><author><keyname>Jitsev</keyname><forenames>Jenia</forenames></author><author><keyname>von der Malsburg</keyname><forenames>Christoph</forenames></author></authors><title>Experience-driven formation of parts-based representations in a model of
  layered visual memory</title><categories>q-bio.NC cs.LG nlin.AO</categories><comments>34 pages, 12 Figures, 1 Table, published in Frontiers in
  Computational Neuroscience (Special Issue on Complex Systems Science and
  Brain Dynamics),
  http://www.frontiersin.org/neuroscience/computationalneuroscience/paper/10.3389/neuro.10/015.2009/</comments><journal-ref>Front. Comput. Neurosci. 3:15 (2009)</journal-ref><doi>10.3389/neuro.10.015.2009</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Growing neuropsychological and neurophysiological evidence suggests that the
visual cortex uses parts-based representations to encode, store and retrieve
relevant objects. In such a scheme, objects are represented as a set of
spatially distributed local features, or parts, arranged in stereotypical
fashion. To encode the local appearance and to represent the relations between
the constituent parts, there has to be an appropriate memory structure formed
by previous experience with visual objects. Here, we propose a model how a
hierarchical memory structure supporting efficient storage and rapid recall of
parts-based representations can be established by an experience-driven process
of self-organization. The process is based on the collaboration of slow
bidirectional synaptic plasticity and homeostatic unit activity regulation,
both running at the top of fast activity dynamics with winner-take-all
character modulated by an oscillatory rhythm. These neural mechanisms lay down
the basis for cooperation and competition between the distributed units and
their synaptic connections. Choosing human face recognition as a test task, we
show that, under the condition of open-ended, unsupervised incremental
learning, the system is able to form memory traces for individual faces in a
parts-based fashion. On a lower memory layer the synaptic structure is
developed to represent local facial features and their interrelations, while
the identities of different persons are captured explicitly on a higher layer.
An additional property of the resulting representations is the sparseness of
both the activity during the recall and the synaptic patterns comprising the
memory traces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2141</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2141</id><created>2009-05-13</created><authors><author><keyname>Volnyansky</keyname><forenames>Ilya</forenames></author></authors><title>Curse of Dimensionality in the Application of Pivot-based Indexes to the
  Similarity Search Problem</title><categories>cs.DS</categories><comments>56 pages, 7 figures Master's Thesis in Mathematics, University of
  Ottawa (Canada) Supervisor: Vladimir Pestov</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we study the validity of the so-called curse of dimensionality
for indexing of databases for similarity search. We perform an asymptotic
analysis, with a test model based on a sequence of metric spaces $(\Omega_d)$
from which we pick datasets $X_d$ in an i.i.d. fashion. We call the subscript
$d$ the dimension of the space $\Omega_d$ (e.g. for $\mathbb{R}^d$ the
dimension is just the usual one) and we allow the size of the dataset $n=n_d$
to be such that $d$ is superlogarithmic but subpolynomial in $n$.
  We study the asymptotic performance of pivot-based indexing schemes where the
number of pivots is $o(n/d)$. We pick the relatively simple cost model of
similarity search where we count each distance calculation as a single
computation and disregard the rest.
  We demonstrate that if the spaces $\Omega_d$ exhibit the (fairly common)
concentration of measure phenomenon the performance of similarity search using
such indexes is asymptotically linear in $n$. That is for large enough $d$ the
difference between using such an index and performing a search without an index
at all is negligeable. Thus we confirm the curse of dimensionality in this
setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2158</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2158</id><created>2009-05-13</created><authors><author><keyname>De Cristofaro</keyname><forenames>Emiliano</forenames></author><author><keyname>Ding</keyname><forenames>Xuhua</forenames></author><author><keyname>Tsudik</keyname><forenames>Gene</forenames></author></authors><title>Privacy-Preserving Querying in Sensor Networks</title><categories>cs.CR</categories><comments>Preliminary version of this paper appeared in the Proceedings of
  ICCCN'09 under the same title</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless Sensor Networks (WSNs) provide sensing and monitoring services by
means of many tiny autonomous devices equipped with wireless radio
transceivers. As WSNs are deployed on a large-scale and/or on long-term basis,
not only traditional security but also privacy issues must be taken into
account. Furthermore, when network operators offer on-demand access to sensor
measurements to their clients, query mechanisms should ideally leak neither
client interests nor query patterns. In this paper, we present a
privacy-preserving WSN query mechanism that uses standard cryptographic
techniques. Besides preventing unauthorized entities from accessing sensor
readings, it minimizes leakage of (potentially sensitive) information about
users' query targets and patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2159</identifier>
 <datestamp>2009-05-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2159</id><created>2009-05-13</created><authors><author><keyname>Agrawal</keyname><forenames>Shweta</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>On the Secrecy Rate of Interference Networks using structured codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows that structured transmission schemes are a good choice for
secret communication over interference networks with an eavesdropper.
Structured transmission is shown to exploit channel asymmetries and thus
perform better than randomly generated codebooks for such channels. For a class
of interference channels, we show that an equivocation sumrate that is within
two bits of the maximum possible legitimate communication sum-rate is
achievable using lattice codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2177</identifier>
 <datestamp>2009-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2177</id><created>2009-05-13</created><updated>2009-12-20</updated><authors><author><keyname>Enge</keyname><forenames>Andreas</forenames><affiliation>INRIA Bordeaux - Sud-Ouest</affiliation></author><author><keyname>Gaudry</keyname><forenames>Pierrick</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Thom&#xe9;</keyname><forenames>Emmanuel</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>An $L (1/3)$ Discrete Logarithm Algorithm for Low Degree Curves</title><categories>cs.CR math.AG</categories><proxy>ccsd inria-00383941</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for solving the discrete logarithm problem in
Jacobians of families of plane curves whose degrees in $X$ and $Y$ are low with
respect to their genera. The finite base fields $\FF_q$ are arbitrary, but
their sizes should not grow too fast compared to the genus. For such families,
the group structure and discrete logarithms can be computed in subexponential
time of $L_{q^g}(1/3, O(1))$. The runtime bounds rely on heuristics similar to
the ones used in the number field sieve or the function field sieve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2195</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2195</id><created>2009-05-13</created><authors><author><keyname>Chatterjee</keyname><forenames>Krishnendu</forenames></author><author><keyname>Doyen</keyname><forenames>Laurent</forenames></author><author><keyname>Henzinger</keyname><forenames>Thomas A.</forenames></author></authors><title>Expressiveness and Closure Properties for Quantitative Languages</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Weighted automata are nondeterministic automata with numerical weights on
transitions. They can define quantitative languages $L$ that assign to each
word $w$ a real number $L(w)$. In the case of infinite words, the value of a
run is naturally computed as the maximum, limsup, liminf, limit average, or
discounted sum of the transition weights. We study expressiveness and closure
questions about these quantitative languages.
  We first show that the set of words with value greater than a threshold can
be non-$\omega$-regular for deterministic limit-average and discounted-sum
automata, while this set is always $\omega$-regular when the threshold is
isolated (i.e., some neighborhood around the threshold contains no word). In
the latter case, we prove that the $\omega$-regular language is robust against
small perturbations of the transition weights.
  We next consider automata with transition weights 0 or 1 and show that they
are as expressive as general weighted automata in the limit-average case, but
not in the discounted-sum case.
  Third, for quantitative languages $L_1$ and $L_2$, we consider the operations
$\max(L_1,L_2)$, $\min(L_1,L_2)$, and $1-L_1$, which generalize the boolean
operations on languages, as well as the sum $L_1 + L_2$. We establish the
closure properties of all classes of quantitative languages with respect to
these four operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2200</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2200</id><created>2009-05-13</created><authors><author><keyname>Cao</keyname><forenames>Yong</forenames></author><author><keyname>Patnaik</keyname><forenames>Debprakash</forenames></author><author><keyname>Ponce</keyname><forenames>Sean</forenames></author><author><keyname>Archuleta</keyname><forenames>Jeremy</forenames></author><author><keyname>Butler</keyname><forenames>Patrick</forenames></author><author><keyname>Feng</keyname><forenames>Wu-chun</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Naren</forenames></author></authors><title>Towards Chip-on-Chip Neuroscience: Fast Mining of Frequent Episodes
  Using Graphics Processors</title><categories>cs.DC cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational neuroscience is being revolutionized with the advent of
multi-electrode arrays that provide real-time, dynamic, perspectives into brain
function. Mining event streams from these chips is critical to understanding
the firing patterns of neurons and to gaining insight into the underlying
cellular activity. We present a GPGPU solution to mining spike trains. We focus
on mining frequent episodes which captures coordinated events across time even
in the presence of intervening background/&quot;junk&quot; events. Our algorithmic
contributions are two-fold: MapConcatenate, a new computation-to-core mapping
scheme, and a two-pass elimination approach to quickly find supported episodes
from a large number of candidates. Together, they help realize a real-time
&quot;chip-on-chip&quot; solution to neuroscience data mining, where one chip (the
multi-electrode array) supplies the spike train data and another (the GPGPU)
mines it at a scale unachievable previously. Evaluation on both synthetic and
real datasets demonstrate the potential of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2203</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2203</id><created>2009-05-13</created><authors><author><keyname>Patnaik</keyname><forenames>Debprakash</forenames></author><author><keyname>Ponce</keyname><forenames>Sean P.</forenames></author><author><keyname>Cao</keyname><forenames>Yong</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Naren</forenames></author></authors><title>Accelerator-Oriented Algorithm Transformation for Temporal Data Mining</title><categories>cs.DC cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Temporal data mining algorithms are becoming increasingly important in many
application domains including computational neuroscience, especially the
analysis of spike train data. While application scientists have been able to
readily gather multi-neuronal datasets, analysis capabilities have lagged
behind, due to both lack of powerful algorithms and inaccessibility to powerful
hardware platforms. The advent of GPU architectures such as Nvidia's GTX 280
offers a cost-effective option to bring these capabilities to the
neuroscientist's desktop. Rather than port existing algorithms onto this
architecture, we advocate the need for algorithm transformation, i.e.,
rethinking the design of the algorithm in a way that need not necessarily
mirror its serial implementation strictly. We present a novel implementation of
a frequent episode discovery algorithm by revisiting &quot;in-the-large&quot; issues such
as problem decomposition as well as &quot;in-the-small&quot; issues such as data layouts
and memory access patterns. This is non-trivial because frequent episode
discovery does not lend itself to GPU-friendly data-parallel mapping
strategies. Applications to many datasets and comparisons to CPU as well as
prior GPU implementations showcase the advantages of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2212</identifier>
 <datestamp>2011-12-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2212</id><created>2009-05-13</created><updated>2011-12-12</updated><authors><author><keyname>Scheiblechner</keyname><forenames>Peter</forenames></author></authors><title>Castelnuovo-Mumford Regularity and Computing the de Rham Cohomology of
  Smooth Projective Varieties</title><categories>math.AG cs.SC</categories><comments>32 pages - filled a gap in Section 4.2, specific example added, minor
  improvements</comments><msc-class>14Q15, 14Q20, 68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a parallel polynomial time algorithm for computing the
topological Betti numbers of a smooth complex projective variety $X$. It is the
first single exponential time algorithm for computing the Betti numbers of a
significant class of complex varieties of arbitrary dimension. Our main
theoretical result is that the Castelnuovo-Mumford regularity of the sheaf of
differential $p$-forms on $X$ is bounded by $p(em+1)D$, where $e$, $m$, and $D$
are the maximal codimension, dimension, and degree, respectively, of all
irreducible components of $X$. It follows that, for a union $V$ of generic
hyperplane sections in $X$, the algebraic de Rham cohomology of $X\setminus V$
is described by differential forms with poles along $V$ of single exponential
order. This yields a similar description of the de Rham cohomology of $X$,
which allows its efficient computation. Furthermore, we give a parallel
polynomial time algorithm for testing whether a projective variety is smooth.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2213</identifier>
 <datestamp>2011-04-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2213</id><created>2009-05-13</created><updated>2011-04-10</updated><authors><author><keyname>Hwang</keyname><forenames>Eduardo</forenames></author></authors><title>Outlining an elegant solver for 3-SAT</title><categories>cs.DS</categories><comments>This paper has been withdrawn by the author due to its inadequacy,
  given more structured approaches to the subject</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this article is to incite clever ways to attack problems. It
advocates in favor of more elegant algorithms, in place of brute force (albeit
its very well crafted) usages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2214</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2214</id><created>2009-05-13</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Nelson</keyname><forenames>Michael J.</forenames></author><author><keyname>Sun</keyname><forenames>Jonathan Z.</forenames></author></authors><title>The Rainbow Skip Graph: A Fault-Tolerant Constant-Degree P2P Relay
  Structure</title><categories>cs.DS cs.NI</categories><comments>Expanded version of a paper appearing in ACM-SIAM Symp. on Discrete
  Algorithms (SODA)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a distributed data structure, which we call the rainbow skip
graph. To our knowledge, this is the first peer-to-peer data structure that
simultaneously achieves high fault tolerance, constant-sized nodes, and fast
update and query times for ordered data. It is a non-trivial adaptation of the
SkipNet/skip-graph structures of Harvey et al. and Aspnes and Shah, so as to
provide fault-tolerance as these structures do, but to do so using
constant-sized nodes, as in the family tree structure of Zatloukal and Harvey.
It supports successor queries on a set of n items using O(log n) messages with
high probability, an improvement over the expected O(log n) messages of the
family tree.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2227</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2227</id><created>2009-05-13</created><authors><author><keyname>Zhao</keyname><forenames>Jichang</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Enhancing the robustness of scale-free networks</title><categories>cs.NI cond-mat.stat-mech physics.soc-ph</categories><comments>8 pages, 4 figures</comments><journal-ref>J. Phys. A: Math. Theor. 42 (2009) 195003</journal-ref><doi>10.1088/1751-8113/42/19/195003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Error tolerance and attack vulnerability are two common and important
properties of complex networks, which are usually used to evaluate the
robustness of a network. Recently, much work has been devoted to determining
the network design with optimal robustness. However, little attention has been
paid to the problem of how to improve the robustness of existing networks. In
this paper, we present a new parameter alpha, called enforcing parameter, to
guide the process of enhancing the robustness of scale-free networks by
gradually adding new links. Intuitively, alpha &lt; 0 means the nodes with lower
degrees are selected preferentially while the nodes with higher degrees will be
more probably selected when alpha &gt; 0. It is shown both theoretically and
experimentally that when alpha &lt; 0 the attack survivability of the network can
be enforced apparently. Then we propose new strategies to enhance the network
robustness. Through extensive experiments and comparisons, we conclude that
establishing new links between nodes with low degrees can drastically enforce
the attack survivability of scale-free networks while having little impact on
the error tolerance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2234</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2234</id><created>2009-05-13</created><authors><author><keyname>Xiao</keyname><forenames>Bo</forenames></author><author><keyname>Liu</keyname><forenames>Lian-dong</forenames></author><author><keyname>Guo</keyname><forenames>Xiao-chen</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Modeling the IPv6 Internet AS-level Topology</title><categories>cs.NI physics.soc-ph</categories><comments>15 pages, 5 figures</comments><journal-ref>Physica A 388(2009):529-540</journal-ref><doi>10.1016/j.physa.2008.10.034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To measure the IPv6 internet AS-level topology, a network topology discovery
system, called Dolphin, was developed. By comparing the measurement result of
Dolphin with that of CAIDA's Scamper, it was found that the IPv6 Internet at AS
level, similar to other complex networks, is also scale-free but the exponent
of its degree distribution is 1.2, which is much smaller than that of the IPv4
Internet and most other scale-free networks. In order to explain this feature
of IPv6 Internet we argue that the degree exponent is a measure of uniformity
of the degree distribution. Then, for the purpose on modeling the networks, we
propose a new model based on the two major factors affecting the exponent of
the EBA model. It breaks the lower bound of degree exponent which is 2 for most
models. To verify the validity of this model, both theoretical and experimental
analyses have been carried out. Finally, we demonstrate how this model can be
successfully used to reproduce the topology of the IPv6 Internet.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2248</identifier>
 <datestamp>2010-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2248</id><created>2009-05-14</created><updated>2010-08-31</updated><authors><author><keyname>Li</keyname><forenames>Shizheng</forenames></author><author><keyname>Ramamoorthy</keyname><forenames>Aditya</forenames></author></authors><title>Protection against link errors and failures using network coding</title><categories>cs.IT cs.NI math.IT</categories><comments>The first version of this paper was accepted by IEEE Intl' Symp. on
  Info. Theo. 2009. The second version of this paper is submitted to IEEE
  Transactions on Communications (under minor revision). The third version of
  this paper has been accepted by IEEE Transactions on Communications</comments><acm-class>E.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We propose a network-coding based scheme to protect multiple bidirectional
unicast connections against adversarial errors and failures in a network. The
network consists of a set of bidirectional primary path connections that carry
the uncoded traffic. The end nodes of the bidirectional connections are
connected by a set of shared protection paths that provide the redundancy
required for protection. Such protection strategies are employed in the domain
of optical networks for recovery from failures. In this work we consider the
problem of simultaneous protection against adversarial errors and failures.
  Suppose that n_e paths are corrupted by the omniscient adversary. Under our
proposed protocol, the errors can be corrected at all the end nodes with 4n_e
protection paths. More generally, if there are n_e adversarial errors and n_f
failures, 4n_e + 2n_f protection paths are sufficient. The number of protection
paths only depends on the number of errors and failures being protected against
and is independent of the number of unicast connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2249</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2249</id><created>2009-05-14</created><authors><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Some Properties of Yao Y4 Subgraphs</title><categories>cs.CG cs.DM</categories><comments>7 pages, 6 figures</comments><report-no>Smith Technical Report 093</report-no><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Yao graph for k=4, Y4, is naturally partitioned into four subgraphs, one
per quadrant. We show that the subgraphs for one quadrant differ from the
subgraphs for two adjacent quadrants in three properties: planarity,
connectedness, and whether the directed graphs are spanners.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2257</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2257</id><created>2009-05-14</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>A protocol for instruction stream processing</title><categories>cs.PL cs.DC</categories><comments>15pages</comments><report-no>PRG0905</report-no><acm-class>D.2.1; D.2.4; F.1.1; F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The behaviour produced by an instruction sequence under execution is a
behaviour to be controlled by some execution environment: each step performed
actuates the processing of an instruction by the execution environment and a
reply returned at completion of the processing determines how the behaviour
proceeds. In this paper, we are concerned with the case where the processing
takes place remotely. We describe a protocol to deal with the case where the
behaviour produced by an instruction sequence under execution leads to the
generation of a stream of instructions to be processed and a remote execution
unit handles the processing of that stream of instructions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2287</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2287</id><created>2009-05-14</created><authors><author><keyname>Blin</keyname><forenames>L&#xe9;lia</forenames><affiliation>IBISC</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria Gradinariu</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Rovedakis</keyname><forenames>Stephane</forenames><affiliation>IBISC</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Futurs, LIP6</affiliation></author></authors><title>A New Self-Stabilizing Minimum Spanning Tree Construction with Loop-free
  Property</title><categories>cs.DS cs.DC cs.NI</categories><proxy>ccsd inria-00384041</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The minimum spanning tree (MST) construction is a classical problem in
Distributed Computing for creating a globally minimized structure
distributedly. Self-stabilization is versatile technique for forward recovery
that permits to handle any kind of transient faults in a uni?ed manner. The
loop-free property provides interesting safety assurance in dynamic networks
where edge-cost changes during operation of the protocol. We present a new
self-stabilizing MST protocol that improves on previous known ap- proaches in
several ways. First, it makes fewer system hypotheses as the size of the
network (or an upper bound on the size) need not be known to the participants.
Second, it is loop-free in the sense that it guarantees that a spanning tree
structure is always preserved while edge costs change dynamically and the
protocol adjusts to a new MST. Finally, time complexity matches the best known
results, while space complexity results show that this protocol is the most
e?cient to date.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2288</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2288</id><created>2009-05-14</created><authors><author><keyname>Zhang</keyname><forenames>Hongyu</forenames></author><author><keyname>Tan</keyname><forenames>Hee Beng Kuan</forenames></author><author><keyname>Marchesi</keyname><forenames>Michele</forenames></author></authors><title>The Distribution of Program Sizes and Its Implications: An Eclipse Case
  Study</title><categories>cs.SE cs.PL</categories><comments>10 pages, 2 figures, 6 tables</comments><acm-class>D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A large software system is often composed of many inter-related programs of
different sizes. Using the public Eclipse dataset, we replicate our previous
study on the distribution of program sizes. Our results confirm that the
program sizes follow the lognormal distribution. We also investigate the
implications of the program size distribution on size estimation and quality
predication. We find that the nature of size distribution can be used to
estimate the size of a large Java system. We also find that a small percentage
of largest programs account for a large percentage of defects, and the number
of defects across programs follows the Weibull distribution when the programs
are ranked by their sizes. Our results show that the distribution of program
sizes is an important property for understanding large and complex software
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2297</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2297</id><created>2009-05-14</created><authors><author><keyname>Rajesh</keyname><forenames>R</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author></authors><title>On Optimal Distributed Joint Source-Channel Coding for Correlated
  Gaussian Sources over Gaussian Channels</title><categories>cs.IT math.IT</categories><comments>24 pages, 9 figures submitted to IEEE Trans Wireless commn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of distributed joint source-channel coding of
correlated Gaussian sources over a Gaussian Multiple Access Channel (GMAC).
There may be side information at the decoder and/or at the encoders. First we
specialize a general result (for transmission of correlated sources over a MAC
with side information) to obtain sufficient conditions for reliable
transmission over a Gaussian MAC. This system does not satisfy the
source-channel separation. We study and compare three joint source-channel
coding schemes available in literature. We show that each of these schemes is
optimal under different scenarios. One of the schemes, Amplify and Forward (AF)
which simplifies the design of encoders and the decoder, is optimal at low SNR
but not at high SNR. Another scheme is asymptotically optimal at high SNR. The
third coding scheme is optimal for orthogonal Gaussian channels. We also show
that AF is close to the optimal scheme for orthogonal channels even at high
SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2311</identifier>
 <datestamp>2010-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2311</id><created>2009-05-14</created><authors><author><keyname>Couvreur</keyname><forenames>A.</forenames></author></authors><title>Residus de 2-formes differentielles sur les surfaces algebriques et
  applications aux codes correcteurs d'erreurs</title><categories>math.AG cs.IT math.IT</categories><comments>168 pages</comments><msc-class>14J20, 94B27</msc-class><journal-ref>PhD Thesis - Universit\'e de Toulouse - 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of algebraic-geometric codes has been developed in the beginning
of the 80's after a paper of V.D. Goppa. Given a smooth projective algebraic
curve X over a finite field, there are two different constructions of
error-correcting codes. The first one, called &quot;functional&quot;, uses some rational
functions on X and the second one, called &quot;differential&quot;, involves some
rational 1-forms on this curve. Hundreds of papers are devoted to the study of
such codes.
  In addition, a generalization of the functional construction for algebraic
varieties of arbitrary dimension is given by Y. Manin in an article of 1984. A
few papers about such codes has been published, but nothing has been done
concerning a generalization of the differential construction to the
higher-dimensional case.
  In this thesis, we propose a differential construction of codes on algebraic
surfaces. Afterwards, we study the properties of these codes and particularly
their relations with functional codes. A pretty surprising fact is that a main
difference with the case of curves appears. Indeed, if in the case of curves, a
differential code is always the orthogonal of a functional one, this assertion
generally fails for surfaces. Last observation motivates the study of codes
which are the orthogonal of some functional code on a surface. Therefore, we
prove that, under some condition on the surface, these codes can be realized as
sums of differential codes. Moreover, we show that some answers to some open
problems &quot;a la Bertini&quot; could give very interesting informations on the
parameters of these codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2341</identifier>
 <datestamp>2011-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2341</id><created>2009-05-14</created><updated>2010-12-01</updated><authors><author><keyname>Couvreur</keyname><forenames>A.</forenames></author></authors><title>Differential approach for the study of duals of algebraic-geometric
  codes on surfaces</title><categories>math.AG cs.IT math.IT math.NT</categories><comments>21 pages</comments><msc-class>14J20, 94B27, 11G25</msc-class><journal-ref>Journal de Theorie des Nombres de Bordeaux, Volume 23(2), p95-120,
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of the present article is the study of duals of functional codes
on algebraic surfaces. We give a direct geometrical description of them, using
differentials. Even if this geometrical description is less trivial, it can be
regarded as a natural extension to surfaces of the result asserting that the
dual of a functional code on a curve is a differential code. We study the
parameters of such codes and state a lower bound for their minimum distance.
Using this bound, one can study some examples of codes on surfaces, and in
particular surfaces with Picard number 1 like elliptic quadrics or some
particular cubic surfaces. The parameters of some of the studied codes reach
those of the best known codes up to now.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2345</identifier>
 <datestamp>2013-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2345</id><created>2009-05-14</created><updated>2011-11-10</updated><authors><author><keyname>Couvreur</keyname><forenames>A.</forenames></author></authors><title>The dual minimum distance of arbitrary dimensional algebraic--geometric
  codes</title><categories>math.AG cs.IT math.IT</categories><comments>24 pages</comments><msc-class>14J20, 94B27, 14C20</msc-class><journal-ref>J. Algebra. 350(1), 84-107. 2012</journal-ref><doi>10.1016/j.jalgebra.2011.09.030</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, the minimum distance of the dual $C^{\bot}$ of a functional
code $C$ on an arbitrary dimensional variety $X$ over a finite field $\F_q$ is
studied. The approach consists in finding minimal configurations of points on
$X$ which are not in &quot;general position&quot;. If $X$ is a curve, the result improves
in some situations the well-known Goppa designed distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2347</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2347</id><created>2009-05-14</created><authors><author><keyname>Torres-Moreno</keyname><forenames>Juan-Manuel</forenames></author><author><keyname>Bougrain</keyname><forenames>Laurent</forenames></author><author><keyname>Alexandre</keyname><forenames>Frd&#xe9;ric</forenames></author></authors><title>Combining Supervised and Unsupervised Learning for GIS Classification</title><categories>cs.LG</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new hybrid learning algorithm for unsupervised
classification tasks. We combined Fuzzy c-means learning algorithm and a
supervised version of Minimerror to develop a hybrid incremental strategy
allowing unsupervised classifications. We applied this new approach to a
real-world database in order to know if the information contained in unlabeled
features of a Geographic Information System (GIS), allows to well classify it.
Finally, we compared our results to a classical supervised classification
obtained by a multilayer perceptron.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2355</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2355</id><created>2009-05-14</created><authors><author><keyname>Chen</keyname><forenames>Zhe</forenames></author><author><keyname>Motet</keyname><forenames>Gilles</forenames></author></authors><title>Modeling System Safety Requirements Using Input/Output Constraint
  Meta-Automata</title><categories>cs.SE cs.FL</categories><comments>6 pages. In Proceedings of the 4th International Conference on
  Systems (ICONS 2009), Gosier, Guadeloupe, France, pp. 228-233. IEEE Computer
  Society, 2009</comments><acm-class>D.2; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most recent software related accidents have been system accidents. To
validate the absence of system hazards concerning dysfunctional interactions,
industrials call for approaches of modeling system safety requirements and
interaction constraints among components and with environments (e.g., between
humans and machines). This paper proposes a framework based on input/output
constraint meta-automata, which restricts system behavior at the meta level.
This approach can formally model safe interactions between a system and its
environment or among its components. This framework differs from the framework
of the traditional model checking. It explicitly separates the tasks of product
engineers and safety engineers, and provides a top-down technique for modeling
a system with safety constraints, and for automatically composing a safe system
that conforms to safety requirements. The contributions of this work include
formalizing system safety requirements and a way of automatically ensuring
system safety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2364</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2364</id><created>2009-05-14</created><authors><author><keyname>Chen</keyname><forenames>Zhe</forenames></author><author><keyname>Motet</keyname><forenames>Gilles</forenames></author></authors><title>Formalizing Safety Requirements Using Controlling Automata</title><categories>cs.SE cs.FL</categories><comments>6 pages. In Proceedings of the 2nd International Conference on
  Dependability (DEPEND 2009), Athens, Greece. IEEE Computer Society, 2009</comments><acm-class>D.2; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Safety is an important element of dependability. It is defined as the absence
of accidents. Most accidents involving software-intensive systems have been
system accidents, which are caused by unsafe inter-system or inter-component
interactions. To validate the absence of system hazards concerning
dysfunctional interactions, industrials call for approaches of modeling system
safety requirements and interaction constraints among components. This paper
proposes such a formalism, namely interface control systems (or shortly
C-Systems). An interface C-System is composed of an interface automaton and a
controlling automaton, which formalizes safe interactions and restricts system
behavior at the meta level. This framework differs from the framework of
traditional model checking. It explicitly separates the tasks of product
engineers and safety engineers, and provides a top-down technique for modeling
a system with safety constraints, and for automatically composing a safe system
that conforms to safety requirements. The contributions of this work include
formalizing safety requirements and a way of automatically ensuring system
safety.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2367</identifier>
 <datestamp>2009-05-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2367</id><created>2009-05-14</created><authors><author><keyname>Chen</keyname><forenames>Zhe</forenames></author><author><keyname>Motet</keyname><forenames>Gilles</forenames></author></authors><title>A Language-theoretic View on Guidelines and Consistency Rules of UML</title><categories>cs.SE cs.FL</categories><comments>16 pages. In Proceedings of the 5th European Conference on Model
  Driven Architecture - Foundations and Applications (ECMDA-FA 2009), Enschede,
  The Netherlands, Lecture Notes in Computer Science 5562, pp. 66-81. Springer,
  2009</comments><acm-class>D.2; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Guidelines and consistency rules of UML are used to control the degrees of
freedom provided by the language to prevent faults. Guidelines are used in
specific domains (e.g., avionics) to recommend the proper use of technologies.
Consistency rules are used to deal with inconsistencies in models. However,
guidelines and consistency rules use informal restrictions on the uses of
languages, which makes checking difficult. In this paper, we consider these
problems from a language-theoretic view. We propose the formalism of C-Systems,
short for &quot;formal language control systems&quot;. A C-System consists of a
controlled grammar and a controlling grammar. Guidelines and consistency rules
are formalized as controlling grammars that control the uses of UML, i.e. the
derivations using the grammar of UML. This approach can be implemented as a
parser, which can automatically verify the rules on a UML user model in XMI
format. A comparison to related work shows our contribution: a generic top-down
and syntax-based approach that checks language level constraints at
compile-time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2381</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2381</id><created>2009-05-14</created><authors><author><keyname>Brubaker</keyname><forenames>S. Charles</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>Random Tensors and Planted Cliques</title><categories>cs.DS cs.CC</categories><doi>10.1007/978-3-642-03685-9_31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The r-parity tensor of a graph is a generalization of the adjacency matrix,
where the tensor's entries denote the parity of the number of edges in
subgraphs induced by r distinct vertices. For r=2, it is the adjacency matrix
with 1's for edges and -1's for nonedges. It is well-known that the 2-norm of
the adjacency matrix of a random graph is O(\sqrt{n}). Here we show that the
2-norm of the r-parity tensor is at most f(r)\sqrt{n}\log^{O(r)}n, answering a
question of Frieze and Kannan who proved this for r=3. As a consequence, we get
a tight connection between the planted clique problem and the problem of
finding a vector that approximates the 2-norm of the r-parity tensor of a
random graph. Our proof method is based on an inductive application of
concentration of measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2386</identifier>
 <datestamp>2010-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2386</id><created>2009-05-14</created><updated>2010-10-17</updated><authors><author><keyname>Ratsaby</keyname><forenames>Joel</forenames></author></authors><title>Combinatorial information distance</title><categories>cs.DM cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $|A|$ denote the cardinality of a finite set $A$. For any real number $x$
define $t(x)=x$ if $x\geq1$ and 1 otherwise. For any finite sets $A,B$ let
$\delta(A,B)$ $=$ $\log_{2}(t(|B\cap\bar{A}||A|))$. We define {This appears as
Technical Report # arXiv:0905.2386v4. A shorter version appears in the {Proc.
of Mini-Conference on Applied Theoretical Computer Science (MATCOS-10)},
Slovenia, Oct. 13-14, 2010.} a new cobinatorial distance $d(A,B)$ $=$
$\max\{\delta(A,B),\delta(B,A)\} $ which may be applied to measure the distance
between binary strings of different lengths. The distance is based on a
classical combinatorial notion of information introduced by Kolmogorov.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2392</identifier>
 <datestamp>2009-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2392</id><created>2009-05-14</created><updated>2009-08-31</updated><authors><author><keyname>Sahai</keyname><forenames>Achaleshwar</forenames></author><author><keyname>Aggarwal</keyname><forenames>Vaneet</forenames></author><author><keyname>Yuksel</keyname><forenames>Melda</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>On Channel Output Feedback in Deterministic Interference Channels</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE ITW, Oct. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the effect of channel output feedback on the sum
capacity in a two-user symmetric deterministic interference channel. We find
that having a single feedback link from one of the receivers to its own
transmitter results in the same sum capacity as having a total of 4 feedback
links from both the receivers to both the transmitters. Hence, from the sum
capacity point of view, the three additional feedback links are not helpful. We
also consider a half-duplex feedback model where the forward and the feedback
resources are symmetric and timeshared. Surprisingly, we find that there is no
gain in sum-capacity with feedback in a half-duplex feedback model when
interference links have more capacity than direct links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2413</identifier>
 <datestamp>2009-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2413</id><created>2009-05-14</created><updated>2009-06-04</updated><authors><author><keyname>Zeng</keyname><forenames>Meng</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Outage Capacity and Optimal Transmission for Dying Channels</title><categories>cs.IT math.IT</categories><comments>31 pages, 9 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In wireless networks, communication links may be subject to random fatal
impacts: for example, sensor networks under sudden power losses or cognitive
radio networks with unpredictable primary user spectrum occupancy. Under such
circumstances, it is critical to quantify how fast and reliably the information
can be collected over attacked links. For a single point-to-point channel
subject to a random attack, named as a \emph{dying channel}, we model it as a
block-fading (BF) channel with a finite and random delay constraint. First, we
define the outage capacity as the performance measure, followed by studying the
optimal coding length $K$ such that the outage probability is minimized when
uniform power allocation is assumed. For a given rate target and a coding
length $K$, we then minimize the outage probability over the power allocation
vector $\mv{P}_{K}$, and show that this optimization problem can be cast into a
convex optimization problem under some conditions. The optimal solutions for
several special cases are discussed.
  Furthermore, we extend the single point-to-point dying channel result to the
parallel multi-channel case where each sub-channel is a dying channel, and
investigate the corresponding asymptotic behavior of the overall outage
probability with two different attack models: the independent-attack case and
the $m$-dependent-attack case. It can be shown that the overall outage
probability diminishes to zero for both cases as the number of sub-channels
increases if the \emph{rate per unit cost} is less than a certain threshold.
The outage exponents are also studied to reveal how fast the outage probability
improves over the number of sub-channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2416</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2416</id><created>2009-05-14</created><authors><author><keyname>Akritidis</keyname><forenames>Leonidas</forenames></author><author><keyname>Katsaros</keyname><forenames>Dimitrios</forenames></author><author><keyname>Bozanis</keyname><forenames>Panayiotis</forenames></author></authors><title>Identifying Influential Bloggers: Time Does Matter</title><categories>cs.IR cs.DL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Blogs have recently become one of the most favored services on the Web. Many
users maintain a blog and write posts to express their opinion, experience and
knowledge about a product, an event and every subject of general or specific
interest. More users visit blogs to read these posts and comment them. This
&quot;participatory journalism&quot; of blogs has such an impact upon the masses that
Keller and Berry argued that through blogging &quot;one American in tens tells the
other nine how to vote, where to eat and what to buy&quot; \cite{keller1}.
Therefore, a significant issue is how to identify such influential bloggers.
This problem is very new and the relevant literature lacks sophisticated
solutions, but most importantly these solutions have not taken into account
temporal aspects for identifying influential bloggers, even though the time is
the most critical aspect of the Blogosphere. This article investigates the
issue of identifying influential bloggers by proposing two easily computed
blogger ranking methods, which incorporate temporal aspects of the blogging
activity. Each method is based on a specific metric to score the blogger's
posts. The first metric, termed MEIBI, takes into consideration the number of
the blog post's inlinks and its comments, along with the publication date of
the post. The second metric, MEIBIX, is used to score a blog post according to
the number and age of the blog post's inlinks and its comments. These methods
are evaluated against the state-of-the-art influential blogger identification
method utilizing data collected from a real-world community blog site. The
obtained results attest that the new methods are able to better identify
significant temporal patterns in the blogging behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2419</identifier>
 <datestamp>2010-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2419</id><created>2009-05-14</created><updated>2010-08-23</updated><authors><author><keyname>Gottesman</keyname><forenames>Daniel</forenames></author><author><keyname>Irani</keyname><forenames>Sandy</forenames></author></authors><title>The Quantum and Classical Complexity of Translationally Invariant Tiling
  and Hamiltonian Problems</title><categories>quant-ph cs.CC</categories><comments>67 pages, approximately 6 gazillion figures. v2 has new results
  proving hardness for reflection-invariant quantum and classical systems and a
  discussion of the infinite quantum chain</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the complexity of a class of problems involving satisfying
constraints which remain the same under translations in one or more spatial
directions. In this paper, we show hardness of a classical tiling problem on an
N x N 2-dimensional grid and a quantum problem involving finding the ground
state energy of a 1-dimensional quantum system of N particles. In both cases,
the only input is N, provided in binary. We show that the classical problem is
NEXP-complete and the quantum problem is QMA_EXP-complete. Thus, an algorithm
for these problems which runs in time polynomial in N (exponential in the input
size) would imply that EXP = NEXP or BQEXP = QMA_EXP, respectively. Although
tiling in general is already known to be NEXP-complete, to our knowledge, all
previous reductions require that either the set of tiles and their constraints
or some varying boundary conditions be given as part of the input. In the
problem considered here, these are fixed, constant-sized parameters of the
problem. Instead, the problem instance is encoded solely in the size of the
system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2422</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2422</id><created>2009-05-14</created><authors><author><keyname>Pourahmadi</keyname><forenames>Vahid</forenames></author><author><keyname>Bayesteh</keyname><forenames>Alireza</forenames></author><author><keyname>Khandani</keyname><forenames>Amir K.</forenames></author></authors><title>Multilevel Coding over Two-Hop Single-User Networks</title><categories>cs.IT math.IT</categories><comments>21 pages, 7 figures, Submitted to IEEE Transactions on Information
  Theory on April 6, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a two-hop network in which information is transmitted from a
source via a relay to a destination is considered. It is assumed that the
channels are static fading with additive white Gaussian noise. All nodes are
equipped with a single antenna and the Channel State Information (CSI) of each
hop is not available at the corresponding transmitter. The relay is assumed to
be simple, i.e., not capable of data buffering over multiple coding blocks,
water-filling over time, or rescheduling. A commonly used design criterion in
such configurations is the maximization of the average received rate at the
destination. We show that using a continuum of multilevel codes at both the
source and the relay, in conjunction with decode and forward strategy at the
relay, performs optimum in this setup. In addition, we present a scheme to
optimally allocate the available source and relay powers to different levels of
their corresponding codes. The performance of this scheme is evaluated assuming
Rayleigh fading and compared with the previously known strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2423</identifier>
 <datestamp>2011-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2423</id><created>2009-05-14</created><updated>2010-09-08</updated><authors><author><keyname>Barg</keyname><forenames>Alexander</forenames></author><author><keyname>Musin</keyname><forenames>Oleg R.</forenames></author></authors><title>Bounds on sets with few distances</title><categories>math.CO cs.IT math.IT math.MG</categories><comments>11 pages</comments><journal-ref>Journal of Combinatorial Theory Ser. A, 118 , no. 4, 2011, pp.
  1465-1474,</journal-ref><doi>10.1016/j.jcta.2011.01.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a new estimate of the size of finite sets of points in metric
spaces with few distances. The following applications are considered:
  (1) we improve the Ray-Chaudhuri--Wilson bound of the size of uniform
intersecting families of subsets;
  (2) we refine the bound of Delsarte-Goethals-Seidel on the maximum size of
spherical sets with few distances;
  (3) we prove a new bound on codes with few distances in the Hamming space,
improving an earlier result of Delsarte.
  We also find the size of maximal binary codes and maximal constant-weight
codes of small length with 2 and 3 distances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2429</identifier>
 <datestamp>2011-01-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2429</id><created>2009-05-14</created><updated>2009-11-20</updated><authors><author><keyname>Gedalyahu</keyname><forenames>Kfir</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>Time Delay Estimation from Low Rate Samples: A Union of Subspaces
  Approach</title><categories>cs.IT math.IT</categories><doi>10.1109/TSP.2010.2044253</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Time delay estimation arises in many applications in which a multipath medium
has to be identified from pulses transmitted through the channel. Various
approaches have been proposed in the literature to identify time delays
introduced by multipath environments. However, these methods either operate on
the analog received signal, or require high sampling rates in order to achieve
reasonable time resolution. In this paper, our goal is to develop a unified
approach to time delay estimation from low rate samples of the output of a
multipath channel. Our methods result in perfect recovery of the multipath
delays from samples of the channel output at the lowest possible rate, even in
the presence of overlapping transmitted pulses. This rate depends only on the
number of multipath components and the transmission rate, but not on the
bandwidth of the probing signal. In addition, our development allows for a
variety of different sampling methods. By properly manipulating the low-rate
samples, we show that the time delays can be recovered using the well-known
ESPRIT algorithm. Combining results from sampling theory with those obtained in
the context of direction of arrival estimation methods, we develop necessary
and sufficient conditions on the transmitted pulse and the sampling functions
in order to ensure perfect recovery of the channel parameters at the minimal
possible rate. Our results can be viewed in a broader context, as a sampling
theorem for analog signals defined over an infinite union of subspaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2435</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2435</id><created>2009-05-14</created><authors><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author><author><keyname>Paulson</keyname><forenames>Lawrence C.</forenames></author></authors><title>Quantified Multimodal Logics in Simple Type Theory</title><categories>cs.AI cs.LO</categories><comments>ii + 22 pages</comments><report-no>SEKI Report SR-2009-02</report-no><acm-class>I.2.4; I.2.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a straightforward embedding of quantified multimodal logic in
simple type theory and prove its soundness and completeness. Modal operators
are replaced by quantification over a type of possible worlds. We present
simple experiments, using existing higher-order theorem provers, to demonstrate
that the embedding allows automated proofs of statements in these logics, as
well as meta properties of them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2447</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2447</id><created>2009-05-14</created><authors><author><keyname>Sezgin</keyname><forenames>Aydin</forenames></author><author><keyname>Jafar</keyname><forenames>Syed Ali</forenames></author><author><keyname>Jafarkhani</keyname><forenames>Hamid</forenames></author></authors><title>The Diversity Multiplexing Tradeoff for Interference Networks</title><categories>cs.IT math.IT</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The diversity-multiplexing tradeoff (DMT) for interference networks, such as
the interference channel, the X channel, the Z interference channel and the Z
channel, is analyzed. In particular, we investigate the impact of
rate-splitting and channel knowledge at the transmitters. We also use the DMT
of the Z channel and the Z interference channel to distill insights into the
&quot;loud neighbor&quot; problem for femto-cell networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2449</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2449</id><created>2009-05-14</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>The Role of Self-Forensics in Vehicle Crash Investigations and Event
  Reconstruction</title><categories>cs.CY cs.AI cs.CR cs.OH</categories><comments>10 pages; preliminary version for CMRSC</comments><acm-class>D.2.5; D.2.4; D.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper further introduces and formalizes a novel concept of
self-forensics for automotive vehicles, specified in the Forensic Lucid
language. We argue that self-forensics, with the forensics taken out of the
cybercrime domain, is applicable to &quot;self-dissection&quot; of intelligent vehicles
and hardware systems for automated incident and anomaly analysis and event
reconstruction by the software with or without the aid of the engineering teams
in a variety of forensic scenarios. We propose a formal design, requirements,
and specification of the self-forensic enabled units (similar to blackboxes) in
vehicles that will help investigation of incidents and also automated reasoning
and verification of theories along with the events reconstruction in a formal
model. We argue such an analysis is beneficial to improve the safety of the
passengers and their vehicles, like the airline industry does for planes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2459</identifier>
 <datestamp>2010-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2459</id><created>2009-05-14</created><updated>2009-07-26</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>On Design and Implementation of the Distributed Modular Audio
  Recognition Framework: Requirements and Specification Design Document</title><categories>cs.CV cs.DC cs.MM cs.NE cs.SD</categories><comments>53 pages, 8 figures, 2 tables. A 2006 report on software design and
  implementation of Distributed MARF, which is a distributed extension of
  classical MARF documented at arXiv:0905.1235 . Parts are to appear at the
  CISSE'08 conference (Springer). The content of the document and code are
  open-source and released at http://marf.sf.net ; v2 adds missing .ind file</comments><acm-class>C.2.4; I.5; I.2.6; D.2.10; D.2.11; D.2.5; D.2.2; I.2.7</acm-class><doi>10.1007/978-90-481-3662-9_72</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We present the requirements and design specification of the open-source
Distributed Modular Audio Recognition Framework (DMARF), a distributed
extension of MARF. The distributed version aggregates a number of distributed
technologies (e.g. Java RMI, CORBA, Web Services) in a pluggable and modular
model along with the provision of advanced distributed systems algorithms. We
outline the associated challenges incurred during the design and implementation
as well as overall specification of the project and its advantages and
limitations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2463</identifier>
 <datestamp>2009-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2463</id><created>2009-05-14</created><updated>2009-06-07</updated><authors><author><keyname>Shen</keyname><forenames>Chunhua</forenames></author><author><keyname>Kim</keyname><forenames>Junae</forenames></author><author><keyname>Wang</keyname><forenames>Hanzi</forenames></author></authors><title>Generalized Kernel-based Visual Tracking</title><categories>cs.CV cs.MM</categories><comments>12 pages</comments><journal-ref>IEEE Transactions on Circuits and Systems for Video Technology,
  2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we generalize the plain MS trackers and attempt to overcome
standard mean shift trackers' two limitations.
  It is well known that modeling and maintaining a representation of a target
object is an important component of a successful visual tracker.
  However, little work has been done on building a robust template model for
kernel-based MS tracking. In contrast to building a template from a single
frame, we train a robust object representation model from a large amount of
data. Tracking is viewed as a binary classification problem, and a
discriminative classification rule is learned to distinguish between the object
and background. We adopt a support vector machine (SVM) for training. The
tracker is then implemented by maximizing the classification score. An
iterative optimization scheme very similar to MS is derived for this purpose.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2473</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2473</id><created>2009-05-15</created><authors><author><keyname>Burjorjee</keyname><forenames>Keki M.</forenames></author></authors><title>On the Workings of Genetic Algorithms: The Genoclique Fixing Hypothesis</title><categories>cs.NE cs.AI</categories><comments>25 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We recently reported that the simple genetic algorithm (SGA) is capable of
performing a remarkable form of sublinear computation which has a
straightforward connection with the general problem of interacting attributes
in data-mining. In this paper we explain how the SGA can leverage this
computational proficiency to perform efficient adaptation on a broad class of
fitness functions. Based on the relative ease with which a practical fitness
function might belong to this broad class, we submit a new hypothesis about the
workings of genetic algorithms. We explain why our hypothesis is superior to
the building block hypothesis, and, by way of empirical validation, we present
the results of an experiment in which the use of a simple mechanism called
clamping dramatically improved the performance of an SGA with uniform crossover
on large, randomly generated instances of the MAX 3-SAT problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2479</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2479</id><created>2009-05-15</created><authors><author><keyname>Han</keyname><forenames>Guangyue</forenames></author><author><keyname>Marcus</keyname><forenames>Brian</forenames></author><author><keyname>Peres</keyname><forenames>Yuval</forenames></author></authors><title>A note on a complex Hilbert metric with application to domain of
  analyticity for entropy rate of hidden Markov processes</title><categories>math.DS cs.IT math.IT</categories><comments>15 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we show that small complex perturbations of positive matrices
are contractions, with respect to a complex version of the Hilbert metric, on
the standard complex simplex. We show that this metric can be used to obtain
estimates of the domain of analyticity of entropy rate for a hidden Markov
process when the underlying Markov chain has strictly positive transition
probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2485</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2485</id><created>2009-05-15</created><authors><author><keyname>Ballard</keyname><forenames>Grey</forenames></author><author><keyname>Demmel</keyname><forenames>James</forenames></author><author><keyname>Holtz</keyname><forenames>Olga</forenames></author><author><keyname>Schwartz</keyname><forenames>Oded</forenames></author></authors><title>Minimizing Communication in Linear Algebra</title><categories>cs.CC cs.DS cs.NA math.NA</categories><comments>27 pages, 2 tables</comments><journal-ref>SIAM. J. Matrix Anal. &amp; Appl. 32 (2011), no. 3, 866-901</journal-ref><doi>10.1137/090769156</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1981 Hong and Kung proved a lower bound on the amount of communication
needed to perform dense, matrix-multiplication using the conventional $O(n^3)$
algorithm, where the input matrices were too large to fit in the small, fast
memory. In 2004 Irony, Toledo and Tiskin gave a new proof of this result and
extended it to the parallel case. In both cases the lower bound may be
expressed as $\Omega$(#arithmetic operations / $\sqrt{M}$), where M is the size
of the fast memory (or local memory in the parallel case). Here we generalize
these results to a much wider variety of algorithms, including LU
factorization, Cholesky factorization, $LDL^T$ factorization, QR factorization,
algorithms for eigenvalues and singular values, i.e., essentially all direct
methods of linear algebra. The proof works for dense or sparse matrices, and
for sequential or parallel algorithms. In addition to lower bounds on the
amount of data moved (bandwidth) we get lower bounds on the number of messages
required to move it (latency). We illustrate how to extend our lower bound
technique to compositions of linear algebra operations (like computing powers
of a matrix), to decide whether it is enough to call a sequence of simpler
optimal algorithms (like matrix multiplication) to minimize communication, or
if we can do better. We give examples of both. We also show how to extend our
lower bounds to certain graph theoretic problems.
  We point out recently designed algorithms for dense LU, Cholesky, QR,
eigenvalue and the SVD problems that attain these lower bounds; implementations
of LU and QR show large speedups over conventional linear algebra algorithms in
standard libraries like LAPACK and ScaLAPACK. Many open problems remain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2501</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2501</id><created>2009-05-15</created><authors><author><keyname>Sonntag</keyname><forenames>Daniel</forenames></author><author><keyname>Zapatrin</keyname><forenames>Rom&#xe0;n R.</forenames></author></authors><title>Macrodynamics of users' behavior in Information Retrieval</title><categories>cs.IR</categories><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a method to geometrize massive data sets from search engines query
logs. For this purpose, a macrodynamic-like quantitative model of the
Information Retrieval (IR) process is developed, whose paradigm is inspired by
basic constructions of Einstein's general relativity theory in which all IR
objects are uniformly placed in a common Room. The Room has a structure similar
to Einsteinian spacetime, namely that of a smooth manifold. Documents and
queries are treated as matter objects and sources of material fields.
Relevance, the central notion of IR, becomes a dynamical issue controlled by
both gravitation (or, more precisely, as the motion in a curved spacetime) and
forces originating from the interactions of matter fields. The spatio-temporal
description ascribes dynamics to any document or query, thus providing a
uniform description for documents of both initially static and dynamical
nature. Within the IR context, the techniques presented are based on two ideas.
The first is the placement of all objects participating in IR into a common
continuous space. The second idea is the `objectivization' of the IR process;
instead of expressing users' wishes, we consider the overall IR as an objective
physical process, representing the IR process in terms of motion in a given
external-fields configuration. Various semantic environments are treated as
various IR universes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2509</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2509</id><created>2009-05-15</created><authors><author><keyname>Di Iorio</keyname><forenames>Angelo</forenames><affiliation>PPS</affiliation></author><author><keyname>Vitali</keyname><forenames>Fabio</forenames><affiliation>PPS</affiliation></author><author><keyname>Rossi</keyname><forenames>Davide</forenames><affiliation>PPS</affiliation></author><author><keyname>Zacchiroli</keyname><forenames>Stefano</forenames><affiliation>PPS</affiliation></author></authors><title>Where are your Manners? Sharing Best Community Practices in the Web 2.0</title><categories>cs.CY</categories><comments>ACM symposium on Applied Computing, Honolulu : \'Etats-Unis
  d'Am\'erique (2009)</comments><proxy>ccsd hal-00384408</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Web 2.0 fosters the creation of communities by offering users a wide
array of social software tools. While the success of these tools is based on
their ability to support different interaction patterns among users by imposing
as few limitations as possible, the communities they support are not free of
rules (just think about the posting rules in a community forum or the editing
rules in a thematic wiki). In this paper we propose a framework for the sharing
of best community practices in the form of a (potentially rule-based)
annotation layer that can be integrated with existing Web 2.0 community tools
(with specific focus on wikis). This solution is characterized by minimal
intrusiveness and plays nicely within the open spirit of the Web 2.0 by
providing users with behavioral hints rather than by enforcing the strict
adherence to a set of rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2539</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2539</id><created>2009-05-15</created><updated>2009-07-15</updated><authors><author><keyname>Kesner</keyname><forenames>Delia</forenames></author></authors><title>A Theory of Explicit Substitutions with Safe and Full Composition</title><categories>cs.PL cs.LO</categories><comments>29 pages Special Issue: Selected Papers of the Conference
  &quot;International Colloquium on Automata, Languages and Programming 2008&quot; edited
  by Giuseppe Castagna and Igor Walukiewicz</comments><acm-class>F.3.2; D.1.1; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (July 15,
  2009) lmcs:816</journal-ref><doi>10.2168/LMCS-5(3:1)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many different systems with explicit substitutions have been proposed to
implement a large class of higher-order languages. Motivations and challenges
that guided the development of such calculi in functional frameworks are
surveyed in the first part of this paper. Then, very simple technology in named
variable-style notation is used to establish a theory of explicit substitutions
for the lambda-calculus which enjoys a whole set of useful properties such as
full composition, simulation of one-step beta-reduction, preservation of
beta-strong normalisation, strong normalisation of typed terms and confluence
on metaterms. Normalisation of related calculi is also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2540</identifier>
 <datestamp>2009-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2540</id><created>2009-05-15</created><authors><author><keyname>Cournier</keyname><forenames>Alain</forenames><affiliation>MIS</affiliation></author><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Villain</keyname><forenames>Vincent</forenames><affiliation>MIS</affiliation></author></authors><title>Two snap-stabilizing point-to-point communication protocols in
  message-switched networks</title><categories>cs.DS cs.DC</categories><proxy>ccsd inria-00384540</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A snap-stabilizing protocol, starting from any configuration, always behaves
according to its specification. In this paper, we present a snap-stabilizing
protocol to solve the message forwarding problem in a message-switched network.
In this problem, we must manage resources of the system to deliver messages to
any processor of the network. In this purpose, we use information given by a
routing algorithm. By the context of stabilization (in particular, the system
starts in an arbitrary configuration), this information can be corrupted. So,
the existence of a snap-stabilizing protocol for the message forwarding problem
implies that we can ask the system to begin forwarding messages even if routing
information are initially corrupted. In this paper, we propose two
snap-stabilizing algorithms (in the state model) for the following
specification of the problem: - Any message can be generated in a finite time.
- Any emitted message is delivered to its destination once and only once in a
finite time. This implies that our protocol can deliver any emitted message
regardless of the state of routing tables in the initial configuration. These
two algorithms are based on the previous work of [MS78]. Each algorithm needs a
particular method to be transform into a snap-stabilizing one but both of them
do not introduce a significant overcost in memory or in time with respect to
algorithms of [MS78].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2545</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2545</id><created>2009-05-15</created><authors><author><keyname>David</keyname><forenames>Ren&#xe9;</forenames><affiliation>LAMA</affiliation></author></authors><title>A direct proof of the confluence of combinatory strong reduction</title><categories>math.LO cs.LO</categories><comments>To appear in TCS</comments><proxy>ccsd hal-00384573</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I give a proof of the confluence of combinatory strong reduction that does
not use the one of lambda-calculus. I also give simple and direct proofs of a
standardization theorem for this reduction and the strong normalization of
simply typed terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2605</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2605</id><created>2009-05-15</created><updated>2009-05-15</updated><authors><author><keyname>Gao</keyname><forenames>Jie</forenames></author><author><keyname>Zhou</keyname><forenames>Dengpan</forenames></author></authors><title>The Emergence of Sparse Spanners and Greedy Well-Separated Pair
  Decomposition</title><categories>cs.CG cs.DS</categories><doi>10.1007/978-3-642-13731-0_6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A spanner graph on a set of points in $R^d$ contains a shortest path between
any pair of points with length at most a constant factor of their Euclidean
distance. In this paper we investigate new models and aim to interpret why good
spanners 'emerge' in reality, when they are clearly built in pieces by agents
with their own interests and the construction is not coordinated. Our main
result is to show that if edges are built in an arbitrary order but an edge is
built if and only if its endpoints are not 'close' to the endpoints of an
existing edge, the graph is a $(1 + \eps)$-spanner with a linear number of
edges, constant average degree, and the total edge length as a small
logarithmic factor of the cost of the minimum spanning tree. As a side product,
we show a simple greedy algorithm for constructing optimal size well-separated
pair decompositions that may be of interest on its own.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2635</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2635</id><created>2009-05-15</created><authors><author><keyname>Myronenko</keyname><forenames>Andriy</forenames></author><author><keyname>Song</keyname><forenames>Xubo</forenames></author></authors><title>Point-Set Registration: Coherent Point Drift</title><categories>cs.CV</categories><journal-ref>IEEE Trans. on Pattern Analysis and Machine Intelligence, vol. 32,
  issue 12, pp. 2262-2275</journal-ref><doi>10.1109/TPAMI.2010.46</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Point set registration is a key component in many computer vision tasks. The
goal of point set registration is to assign correspondences between two sets of
points and to recover the transformation that maps one point set to the other.
Multiple factors, including an unknown non-rigid spatial transformation, large
dimensionality of point set, noise and outliers, make the point set
registration a challenging problem. We introduce a probabilistic method, called
the Coherent Point Drift (CPD) algorithm, for both rigid and non-rigid point
set registration. We consider the alignment of two point sets as a probability
density estimation problem. We fit the GMM centroids (representing the first
point set) to the data (the second point set) by maximizing the likelihood. We
force the GMM centroids to move coherently as a group to preserve the
topological structure of the point sets. In the rigid case, we impose the
coherence constraint by re-parametrization of GMM centroid locations with rigid
parameters and derive a closed form solution of the maximization step of the EM
algorithm in arbitrary dimensions. In the non-rigid case, we impose the
coherence constraint by regularizing the displacement field and using the
variational calculus to derive the optimal transformation. We also introduce a
fast algorithm that reduces the method computation complexity to linear. We
test the CPD algorithm for both rigid and non-rigid transformations in the
presence of noise, outliers and missing points, where CPD shows accurate
results and outperforms current state-of-the-art methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2636</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2636</id><created>2009-05-15</created><authors><author><keyname>Shi</keyname><forenames>Xiaolin</forenames></author><author><keyname>Tseng</keyname><forenames>Belle</forenames></author><author><keyname>Adamic</keyname><forenames>Lada A.</forenames></author></authors><title>Information Diffusion in Computer Science Citation Networks</title><categories>cs.DL cs.CY</categories><comments>long version of poster published at ICWSM 2009</comments><acm-class>H.3.4; H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper citation network is a traditional social medium for the exchange of
ideas and knowledge. In this paper we view citation networks from the
perspective of information diffusion. We study the structural features of the
information paths through the citation networks of publications in computer
science, and analyze the impact of various citation choices on the subsequent
impact of the article. We find that citing recent papers and papers within the
same scholarly community garners a slightly larger number of citations on
average. However, this correlation is weaker among well-cited papers implying
that for high impact work citing within one's field is of lesser importance. We
also study differences in information flow for specific subsets of citation
networks: books versus conference and journal articles, different areas of
computer science, and different time periods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2637</identifier>
 <datestamp>2011-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2637</id><created>2009-05-15</created><authors><author><keyname>Cruz</keyname><forenames>Felipe A.</forenames></author><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author><author><keyname>Barba</keyname><forenames>L. A.</forenames></author></authors><title>PetFMM--A dynamically load-balancing parallel fast multipole library</title><categories>cs.DC cs.DS</categories><comments>28 pages, 9 figures</comments><journal-ref>Int. J. Num. Meth. Eng., 85(4): 403-428 (Jan. 2011)</journal-ref><doi>10.1002/nme.2972</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Fast algorithms for the computation of $N$-body problems can be broadly
classified into mesh-based interpolation methods, and hierarchical or
multiresolution methods. To this last class belongs the well-known fast
multipole method (FMM), which offers O(N) complexity. This paper presents an
extensible parallel library for $N$-body interactions utilizing the FMM
algorithm, built on the framework of PETSc. A prominent feature of this library
is that it is designed to be extensible, with a view to unifying efforts
involving many algorithms based on the same principles as the FMM and enabling
easy development of scientific application codes. The paper also details an
exhaustive model for the computation of tree-based $N$-body algorithms in
parallel, including both work estimates and communications estimates. With this
model, we are able to implement a method to provide automatic, a priori load
balancing of the parallel execution, achieving optimal distribution of the
computational work among processors and minimal inter-processor communications.
Using a client application that performs the calculation of velocity induced by
$N$ vortex particles, ample verification and testing of the library was
performed. Strong scaling results are presented with close to a million
particles in up to 64 processors, including both speedup and parallel
efficiency. The library is currently able to achieve over 85% parallel
efficiency for 64 processors. The software library is open source under the
PETSc license; this guarantees the maximum impact to the scientific community
and encourages peer-based collaboration for the extensions and applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2638</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2638</id><created>2009-05-15</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Secure Degrees of Freedom for Gaussian Channels with Interference:
  Structured Codes Outperform Gaussian Signaling</title><categories>cs.IT math.IT</categories><comments>6 pages, Submitted to IEEE Globecom, March 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we prove that a positive secure degree of freedom is achievable
for a large class of Gaussian channels as long as the channel is not degraded
and the channel is fully connected. This class includes the MAC wire-tap
channel, the 2-user interference channel with confidential messages, the 2-user
interference channel with an external eavesdropper. Best known achievable
schemes to date for these channels use Gaussian signaling. In this work, we
show that structured codes outperform Gaussian random codes at high SNR when
channel gains are real numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2639</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2639</id><created>2009-05-15</created><authors><author><keyname>Santhanam</keyname><forenames>Narayana</forenames></author><author><keyname>Wainwright</keyname><forenames>Martin J.</forenames></author></authors><title>Information-theoretic limits of selecting binary graphical models in
  high dimensions</title><categories>cs.IT cs.LG math.IT math.ST stat.TH</categories><comments>27 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of graphical model selection is to correctly estimate the graph
structure of a Markov random field given samples from the underlying
distribution. We analyze the information-theoretic limitations of the problem
of graph selection for binary Markov random fields under high-dimensional
scaling, in which the graph size $p$ and the number of edges $k$, and/or the
maximal node degree $d$ are allowed to increase to infinity as a function of
the sample size $n$. For pairwise binary Markov random fields, we derive both
necessary and sufficient conditions for correct graph selection over the class
$\mathcal{G}_{p,k}$ of graphs on $p$ vertices with at most $k$ edges, and over
the class $\mathcal{G}_{p,d}$ of graphs on $p$ vertices with maximum degree at
most $d$. For the class $\mathcal{G}_{p, k}$, we establish the existence of
constants $c$ and $c'$ such that if $\numobs &lt; c k \log p$, any method has
error probability at least 1/2 uniformly over the family, and we demonstrate a
graph decoder that succeeds with high probability uniformly over the family for
sample sizes $\numobs &gt; c' k^2 \log p$. Similarly, for the class
$\mathcal{G}_{p,d}$, we exhibit constants $c$ and $c'$ such that for $n &lt; c d^2
\log p$, any method fails with probability at least 1/2, and we demonstrate a
graph decoder that succeeds with high probability for $n &gt; c' d^3 \log p$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2640</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2640</id><created>2009-05-15</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>The Gaussian Many-to-One Interference Channel with Confidential Messages</title><categories>cs.IT math.IT</categories><comments>5 pages, To appear at IEEE ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the $K$-user many-to-one interference channel with
confidential messages in which the $K$th user experiences interference from all
other $K-1$ users, and is at the same time treated as an eavesdropper to all
the messages of these users. We derive achievable rates and an upper bound on
the sum rate for this channel and show that the gap between the achievable sum
rate and its upper bound is $\log_2(K-1)$ bits per channel use under very
strong interference, when the interfering users have equal power constraints
and interfering link channel gains. The main contributions of this work are:
(i) nested lattice codes are shown to provide secrecy when interference is
present, (ii) a secrecy sum rate upper bound is found for strong interference
regime and (iii) it is proved that under very strong interference and a
symmetric setting, the gap between the achievable sum rate and the upper bound
is constant with respect to transmission powers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2643</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2643</id><created>2009-05-15</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>K-user Interference Channels: Achievable Secrecy Rate and Degrees of
  Freedom</title><categories>cs.IT math.IT</categories><comments>5 pages. To appear at IEEE ITW 2009, Volos, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we consider achievable secrecy rates for symmetric $K$-user ($K
\ge 3$) interference channels with confidential messages. We find that nested
lattice codes and layered coding are useful in providing secrecy for these
channels. Achievable secrecy rates are derived for very strong interference. In
addition, we derive the secure degrees of freedom for a range of channel
parameters. As a by-product of our approach, we also demonstrate that nested
lattice codes are useful for K-user symmetric interference channels without
secrecy constraints in that they yield higher degrees of freedom than previous
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2645</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2645</id><created>2009-05-15</created><authors><author><keyname>He</keyname><forenames>Xiang</forenames></author><author><keyname>Yener</keyname><forenames>Aylin</forenames></author></authors><title>Providing Secrecy with Lattice Codes</title><categories>cs.IT math.IT</categories><comments>This paper appeared in the Proceedings of the 2008 Allerton
  Conference on Communication, Control, and Computing, September 2008. Theorems
  1 and 2 in this paper derived the Equivocation when using Nested Lattice
  Codes, leading to the &quot;one-bit&quot; result for the secrecy rate</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent results have shown that lattice codes can be used to construct good
channel codes, source codes and physical layer network codes for Gaussian
channels. On the other hand, for Gaussian channels with secrecy constraints,
efforts to date rely on random codes. In this work, we provide a tool to bridge
these two areas so that the secrecy rate can be computed when lattice codes are
used. In particular, we address the problem of bounding equivocation rates
under nonlinear modulus operation that is present in lattice encoders/decoders.
The technique is then demonstrated in two Gaussian channel examples: (1) a
Gaussian wiretap channel with a cooperative jammer, and (2) a multi-hop line
network from a source to a destination with untrusted intermediate relay nodes
from whom the information needs to be kept secret. In both cases, lattice codes
are used to facilitate cooperative jamming. In the second case, interestingly,
we demonstrate that a non-vanishing positive secrecy rate is achievable
regardless of the number of hops.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2649</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2649</id><created>2009-05-15</created><authors><author><keyname>Banerjee</keyname><forenames>Soumya</forenames></author></authors><title>An Immune System Inspired Approach to Automated Program Verification</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An immune system inspired Artificial Immune System (AIS) algorithm is
presented, and is used for the purposes of automated program verification.
Relevant immunological concepts are discussed and the field of AIS is briefly
reviewed. It is proposed to use this AIS algorithm for a specific automated
program verification task: that of predicting shape of program invariants. It
is shown that the algorithm correctly predicts program invariant shape for a
variety of benchmarked programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2657</identifier>
 <datestamp>2009-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2657</id><created>2009-05-16</created><authors><author><keyname>Aouiche</keyname><forenames>Kamel</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Godin</keyname><forenames>Robert</forenames></author></authors><title>Web 2.0 OLAP: From Data Cubes to Tag Clouds</title><categories>cs.DB</categories><journal-ref>Kamel Aouiche, Daniel Lemire and Robert Godin, Web 2.0 OLAP: From
  Data Cubes to Tag Clouds, Lecture Notes in Business Information Processing
  Vol. 18, pages 51-64, 2009</journal-ref><doi>10.1007/978-3-642-01344-7_5</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Increasingly, business projects are ephemeral. New Business Intelligence
tools must support ad-lib data sources and quick perusal. Meanwhile, tag clouds
are a popular community-driven visualization technique. Hence, we investigate
tag-cloud views with support for OLAP operations such as roll-ups, slices,
dices, clustering, and drill-downs. As a case study, we implemented an
application where users can upload data and immediately navigate through its ad
hoc dimensions. To support social networking, views can be easily shared and
embedded in other Web sites. Algorithmically, our tag-cloud views are
approximate range top-k queries over spontaneous data cubes. We present
experimental evidence that iceberg cuboids provide adequate online
approximations. We benchmark several browser-oblivious tag-cloud layout
optimizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2659</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2659</id><created>2009-05-16</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author><author><keyname>Ba&#x15f;ar</keyname><forenames>Tamer</forenames></author></authors><title>Coalitional Games for Distributed Collaborative Spectrum Sensing in
  Cognitive Radio Networks</title><categories>cs.GT cs.IT math.IT</categories><comments>in proceedings of IEEE INFOCOM 2009</comments><journal-ref>IEEE INFOCOM 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Collaborative spectrum sensing among secondary users (SUs) in cognitive
networks is shown to yield a significant performance improvement. However,
there exists an inherent trade off between the gains in terms of probability of
detection of the primary user (PU) and the costs in terms of false alarm
probability. In this paper, we study the impact of this trade off on the
topology and the dynamics of a network of SUs seeking to reduce the
interference on the PU through collaborative sensing. Moreover, while existing
literature mainly focused on centralized solutions for collaborative sensing,
we propose distributed collaboration strategies through game theory. We model
the problem as a non-transferable coalitional game, and propose a distributed
algorithm for coalition formation through simple merge and split rules. Through
the proposed algorithm, SUs can autonomously collaborate and self-organize into
disjoint independent coalitions, while maximizing their detection probability
taking into account the cooperation costs (in terms of false alarm). We study
the stability of the resulting network structure, and show that a maximum
number of SUs per formed coalition exists for the proposed utility model.
Simulation results show that the proposed algorithm allows a reduction of up to
86.6% of the average missing probability per SU (probability of missing the
detection of the PU) relative to the non-cooperative case, while maintaining a
certain false alarm level. In addition, through simulations, we compare the
performance of the proposed distributed solution with respect to an optimal
centralized solution that minimizes the average missing probability per SU.
Finally, the results also show how the proposed algorithm autonomously adapts
the network topology to environmental changes such as mobility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2676</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2676</id><created>2009-05-16</created><authors><author><keyname>Perlaza</keyname><forenames>Samir M.</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Bogucka</keyname><forenames>Hanna</forenames></author></authors><title>On the Benefits of Bandwidth Limiting in Decentralized Vector Multiple
  Access Channels</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the network spectral efficiency of decentralized vector multiple
access channels (MACs) when the number of accessible dimensions per transmitter
is strategically limited. Considering each dimension as a frequency band, we
call this limiting process bandwidth limiting (BL). Assuming that each
transmitter maximizes its own data rate by water-filling over the available
frequency bands, we consider two scenarios. In the first scenario, transmitters
use non-intersecting sets of bands (spectral resource partition), and in the
second one, they freely exploit all the available frequency bands (spectral
resource sharing). In the latter case, successive interference cancelation
(SIC) is used. We show the existence of an optimal number of dimensions that a
transmitter must use in order to maximize the network performance measured in
terms of spectral efficiency. We provide a closed form expression for the
optimal number of accessible bands in the first scenario. Such an optimum
point, depends on the number of active transmitters, the number of available
frequency bands and the different signal-to-noise ratios. In the second
scenario, we show that BL does not bring a significant improvement on the
network spectral efficiency, when all transmitters use the same BL policy. For
both scenarios, we provide simulation results to validate our conclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2705</identifier>
 <datestamp>2009-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2705</id><created>2009-05-16</created><updated>2009-08-19</updated><authors><author><keyname>Kuleshov</keyname><forenames>A.</forenames></author><author><keyname>Reshetnyak</keyname><forenames>A. A.</forenames></author></authors><title>Programming Realization of Symbolic Computations for Non-linear
  Commutator Superalgebras over the Heisenberg--Weyl Superalgebra: Data
  Structures and Processing Methods</title><categories>hep-th cs.SC math.QA math.RT</categories><comments>35 pages, 2 figures in eps-format, corrected typos, added references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We suggest a programming realization of an algorithm for verifying a given
set of algebraic relations in the form of a supercommutator multiplication
table for the Verma module, which is constructed according to a generalized
Cartan procedure for a quadratic superalgebra and whose elements are realized
as a formal power series with respect to non-commuting elements. To this end,
we propose an algebraic procedure of Verma module construction and its
realization in terms of non-commuting creation and annihilation operators of a
given Heisenberg--Weyl superalgebra. In doing so, we set up a problem which
naturally arises within a Lagrangian description of higher-spin fields in
anti-de-Sitter (AdS) spaces: to verify the fact that the resulting Verma module
elements obey the given commutator multiplication for the original non-linear
superalgebra. The problem setting is based on a restricted principle of
mathematical induction, in powers of inverse squared radius of the AdS-space.
For a construction of an algorithm resolving this problem, we use a two-level
data model within the object-oriented approach, which is realized on a basis of
the programming language C#. The program allows one to consider objects (of a
less general nature than non-linear commutator superalgebras) that fall under
the class of so-called $GR$-algebras, for whose treatment one widely uses the
module \emph{Plural} of the system \emph{Singular} of symbolic computations for
polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2718</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2718</id><created>2009-05-17</created><authors><author><keyname>Cui</keyname><forenames>Tao</forenames></author><author><keyname>Ho</keyname><forenames>Tracey</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author></authors><title>Achievable Rate and Optimal Physical Layer Rate Allocation in
  Interference-Free Wireless Networks</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in Proc. IEEE ISIT, July 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the achievable rate in interference-free wireless networks with
physical layer fading channels and orthogonal multiple access. As a starting
point, the point-to-point channel is considered. We find the optimal physical
and network layer rate trade-off which maximizes the achievable overall rate
for both a fixed rate transmission scheme and an improved scheme based on
multiple virtual users and superposition coding. These initial results are
extended to the network setting, where, based on a cut-set formulation, the
achievable rate at each node and its upper bound are derived. We propose a
distributed optimization algorithm which allows to jointly determine the
maximum achievable rate, the optimal physical layer rates on each network link,
and an opportunistic back-pressure-type routing strategy on the network layer.
This inherently justifies the layered architecture in existing wireless
networks. Finally, we show that the proposed layered optimization approach can
achieve almost all of the ergodic network capacity in high SNR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2796</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2796</id><created>2009-05-17</created><authors><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Zeng</keyname><forenames>Weifei</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Sparse Network Coding with Overlapping Classes</title><categories>cs.IT math.IT</categories><comments>15 pages, 5 figures, to be published at NetCod 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel approach to network coding for distribution of
large files. Instead of the usual approach of splitting packets into disjoint
classes (also known as generations) we propose the use of overlapping classes.
The overlapping allows the decoder to alternate between Gaussian elimination
and back substitution, simultaneously boosting the performance and reducing the
decoding complexity. Our approach can be seen as a combination of fountain
coding and network coding. Simulation results are presented that demonstrate
the promise of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2817</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2817</id><created>2009-05-18</created><updated>2009-08-12</updated><authors><author><keyname>Huang</keyname><forenames>Haiping</forenames></author><author><keyname>Zhou</keyname><forenames>Haijun</forenames></author></authors><title>Cavity approach to the Sourlas code system</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT</categories><comments>12 pages, 6 figures</comments><journal-ref>Phys. Rev. E 80, 056113 (2009)</journal-ref><doi>10.1103/PhysRevE.80.056113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The statistical physics properties of regular and irregular Sourlas codes are
investigated in this paper by the cavity method. At finite temperatures, the
free energy density of these coding systems is derived and compared with the
result obtained by the replica method. In the zero temperature limit, the
Shannon's bound is recovered in the case of infinite-body interactions while
the code rate is still finite. However, the decoding performance as obtained by
the replica theory has not considered the zero-temperature entropic effect. The
cavity approach is able to consider the ground-state entropy. It leads to a set
of evanescent cavity fields propagation equations which further improve the
decoding performance, as confirmed by our numerical simulations on single
instances. For the irregular Sourlas code, we find that it takes the trade-off
between good dynamical property and high performance of decoding. In agreement
with the results found from the algorithmic point of view, the decoding
exhibits a first order phase transition as occurs in the regular code system
with three-body interactions. The cavity approach for the Sourlas code system
can be extended to consider first-step replica-symmetry-breaking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2825</identifier>
 <datestamp>2010-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2825</id><created>2009-05-18</created><authors><author><keyname>Kim</keyname><forenames>Beom Jun</forenames></author><author><keyname>Holme</keyname><forenames>Petter</forenames></author><author><keyname>Fodor</keyname><forenames>Viktoria</forenames></author></authors><title>Heterogeneous attachment strategies optimize the topology of dynamic
  wireless networks</title><categories>cs.NI</categories><acm-class>C.2.1; G.2.2</acm-class><journal-ref>Eur. Phys. J. B 73, 597--604 (2010)</journal-ref><doi>10.1140/epjb/e2010-00049-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In optimizing the topology of wireless networks built of a dynamic set of
spatially embedded agents, there are many trade-offs to be dealt with. The
network should preferably be as small (in the sense that the average, or
maximal, pathlength is short) as possible, it should be robust to failures, not
consume too much power, and so on. In this paper, we investigate simple models
of how agents can choose their neighbors in such an environment. In our model
of attachment, we can tune from one situation where agents prefer to attach to
others in closest proximity, to a situation where distance is ignored (and thus
attachments can be made to agents further away). We evaluate this scenario with
several performance measures and find that the optimal topologies, for most of
the quantities, is obtained for strategies resulting in a mix of most local and
a few random connections.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2880</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2880</id><created>2009-05-18</created><authors><author><keyname>David</keyname><forenames>Ren&#xe9;</forenames><affiliation>LAMA</affiliation></author><author><keyname>Zaionc</keyname><forenames>Marek</forenames></author></authors><title>Counting proofs in propositional logic</title><categories>math.LO cs.LO</categories><proxy>ccsd hal-00385164</proxy><journal-ref>Archive for Mathematical Logic 48 (2009) P 185-199</journal-ref><doi>10.1007/s00153-009-0119-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a procedure for counting the number of different proofs of a formula
in various sorts of propositional logic. This number is either an integer (that
may be 0 if the formula is not provable) or infinite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2882</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2882</id><created>2009-05-18</created><authors><author><keyname>Bercachi</keyname><forenames>Maroun</forenames><affiliation>I3S</affiliation></author><author><keyname>Collard</keyname><forenames>Philippe</forenames><affiliation>I3S</affiliation></author><author><keyname>Clergue</keyname><forenames>Manuel</forenames><affiliation>I3S</affiliation></author><author><keyname>Verel</keyname><forenames>Sebastien</forenames><affiliation>I3S</affiliation></author></authors><title>Do not Choose Representation just Change: An Experimental Study in
  States based EA</title><categories>cs.NE cs.AI</categories><proxy>ccsd hal-00383711</proxy><journal-ref>Genetic and Evolutionary Computation Conference 2009, Montr\'eal :
  Canada (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our aim in this paper is to analyse the phenotypic effects (evolvability) of
diverse coding conversion operators in an instance of the states based
evolutionary algorithm (SEA). Since the representation of solutions or the
selection of the best encoding during the optimization process has been proved
to be very important for the efficiency of evolutionary algorithms (EAs), we
will discuss a strategy of coupling more than one representation and different
procedures of conversion from one coding to another during the search.
Elsewhere, some EAs try to use multiple representations (SM-GA, SEA, etc.) in
intention to benefit from the characteristics of each of them. In spite of
those results, this paper shows that the change of the representation is also a
crucial approach to take into consideration while attempting to increase the
performances of such EAs. As a demonstrative example, we use a two states SEA
(2-SEA) which has two identical search spaces but different coding conversion
operators. The results show that the way of changing from one coding to another
and not only the choice of the best representation nor the representation
itself is very advantageous and must be taken into account in order to
well-desing and improve EAs execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2892</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2892</id><created>2009-05-18</created><authors><author><keyname>David</keyname><forenames>Ren&#xe9;</forenames><affiliation>LAMA</affiliation></author><author><keyname>Nour</keyname><forenames>Karim</forenames><affiliation>LAMA</affiliation></author></authors><title>Strong normalization results by translation</title><categories>math.LO cs.LO</categories><comments>Submitted to APAL</comments><proxy>ccsd hal-00385206</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the strong normalization of full classical natural deduction (i.e.
with conjunction, disjunction and permutative conversions) by using a
translation into the simply typed lambda-mu-calculus. We also extend Mendler's
result on recursive equations to this system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2918</identifier>
 <datestamp>2011-10-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2918</id><created>2009-05-18</created><updated>2011-10-21</updated><authors><author><keyname>Wiesner</keyname><forenames>Karoline</forenames></author><author><keyname>Gu</keyname><forenames>Mile</forenames></author><author><keyname>Rieper</keyname><forenames>Elisabeth</forenames></author><author><keyname>Vedral</keyname><forenames>Vlatko</forenames></author></authors><title>Information erasure lurking behind measures of complexity</title><categories>physics.data-an cond-mat.stat-mech cs.CC</categories><comments>Withdrawn: The main results, a corrected version of Theorem 1, and
  further results are contained in the new paper &quot;Information-theoretic bound
  on the energy cost of stochastic simulation&quot;, http://arxiv.org/abs/1110.4217</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex systems are found in most branches of science. It is still argued how
to best quantify their complexity and to what end. One prominent measure of
complexity (the statistical complexity) has an operational meaning in terms of
the amount of resources needed to forecasting a system's behaviour. Another one
(the effective measure complexity, aka excess entropy) is a measure of mutual
information stored in the system proper. We show that for any given system the
two measures differ by the amount of information erased during forecasting. We
interpret the difference as inefficiency of a given model. We find a bound to
the ratio of the two measures defined as information-processing efficiency, in
analogy to the second law of thermodynamics. This new link between two
prominent measures of complexity provides a quantitative criterion for good
models of complex systems, namely those with little information erasure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2919</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2919</id><created>2009-05-18</created><authors><author><keyname>Grigorescu</keyname><forenames>Elena</forenames></author><author><keyname>Kaufman</keyname><forenames>Tali</forenames></author><author><keyname>Sudan</keyname><forenames>Madhu</forenames></author></authors><title>Succinct Representation of Codes with Applications to Testing</title><categories>cs.IT math.IT</categories><doi>10.1007/978-3-642-03685-9_40</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by questions in property testing, we search for linear
error-correcting codes that have the &quot;single local orbit&quot; property: i.e., they
are specified by a single local constraint and its translations under the
symmetry group of the code. We show that the dual of every &quot;sparse&quot; binary code
whose coordinates are indexed by elements of F_{2^n} for prime n, and whose
symmetry group includes the group of non-singular affine transformations of
F_{2^n} has the single local orbit property. (A code is said to be &quot;sparse&quot; if
it contains polynomially many codewords in its block length.) In particular
this class includes the dual-BCH codes for whose duals (i.e., for BCH codes)
simple bases were not known. Our result gives the first short (O(n)-bit, as
opposed to the natural exp(n)-bit) description of a low-weight basis for BCH
codes. The interest in the &quot;single local orbit&quot; property comes from the recent
result of Kaufman and Sudan (STOC 2008) that shows that the duals of codes that
have the single local orbit property under the affine symmetry group are
locally testable. When combined with our main result, this shows that all
sparse affine-invariant codes over the coordinates F_{2^n} for prime n are
locally testable. If, in addition to n being prime, if 2^n-1 is also prime
(i.e., 2^n-1 is a Mersenne prime), then we get that every sparse cyclic code
also has the single local orbit. In particular this implies that BCH codes of
Mersenne prime length are generated by a single low-weight codeword and its
cyclic shifts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2924</identifier>
 <datestamp>2009-05-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2924</id><created>2009-05-18</created><authors><author><keyname>Mohammad</keyname><forenames>Nassir</forenames></author><author><keyname>Balinsky</keyname><forenames>Alexander</forenames></author></authors><title>Colorization of Natural Images via L1 Optimization</title><categories>cs.CV</categories><comments>5 pages, 3 figures</comments><report-no>0905.2921</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Natural images in the colour space YUV have been observed to have a
non-Gaussian, heavy tailed distribution (called 'sparse') when the filter
G(U)(r) = U(r) - sum_{s \in N(r)} w{(Y)_{rs}} U(s), is applied to the
chromacity channel U (and equivalently to V), where w is a weighting function
constructed from the intensity component Y [1]. In this paper we develop
Bayesian analysis of the colorization problem using the filter response as a
regularization term to arrive at a non-convex optimization problem. This
problem is convexified using L1 optimization which often gives the same results
for sparse signals [2]. It is observed that L1 optimization, in many cases,
over-performs the famous colorization algorithm by Levin et al [3].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2958</identifier>
 <datestamp>2010-02-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2958</id><created>2009-05-18</created><updated>2010-02-12</updated><authors><author><keyname>Oaknin</keyname><forenames>J. H.</forenames></author></authors><title>A statistical learning approach to color demosaicing</title><categories>cs.CV</categories><comments>24 pages, 4 figures, 1 table. Rewritten manuscript. New abstract</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A statistical learning/inference framework for color demosaicing is
presented. We start with simplistic assumptions about color constancy, and
recast color demosaicing as a blind linear inverse problem: color parameterizes
the unknown kernel, while brightness takes on the role of a latent variable. An
expectation-maximization algorithm naturally suggests itself for the estimation
of them both. Then, as we gradually broaden the family of hypothesis where
color is learned, we let our demosaicing behave adaptively, in a manner that
reflects our prior knowledge about the statistics of color images. We show that
we can incorporate realistic, learned priors without essentially changing the
complexity of the simple expectation-maximization algorithm we started with.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2977</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2977</id><created>2009-05-18</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Cryptography for Multi-Located Parties</title><categories>cs.CR quant-ph</categories><comments>7 pages; 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note describes some cryptographic issues related to multi-located
parties. In general, multi-located parties make it difficult for the
eavesdropper to mount the man-in-the-middle attack. Conversely, they make it
easier to address problems such as joint encryption and error correction
coding. It is easier to implement the three-stage quantum cryptography
protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2990</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2990</id><created>2009-05-18</created><authors><author><keyname>Torres-Moreno</keyname><forenames>Juan-Manuel</forenames></author><author><keyname>St-Onge</keyname><forenames>Pier-Luc</forenames></author><author><keyname>Gagnon</keyname><forenames>Michel</forenames></author><author><keyname>El-B&#xe8;ze</keyname><forenames>Marc</forenames></author><author><keyname>Bellot</keyname><forenames>Patrice</forenames></author></authors><title>Automatic Summarization System coupled with a Question-Answering System
  (QAAS)</title><categories>cs.IR cs.CL</categories><comments>28 pages, 11 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To select the most relevant sentences of a document, it uses an optimal
decision algorithm that combines several metrics. The metrics processes,
weighting and extract pertinence sentences by statistical and informational
algorithms. This technique might improve a Question-Answering system, whose
function is to provide an exact answer to a question in natural language. In
this paper, we present the results obtained by coupling the Cortex summarizer
with a Question-Answering system (QAAS). Two configurations have been
evaluated. In the first one, a low compression level is selected and the
summarization system is only used as a noise filter. In the second
configuration, the system actually functions as a summarizer, with a very high
level of compression. Our results on French corpus demonstrate that the
coupling of Automatic Summarization system with a Question-Answering system is
promising. Then the system has been adapted to generate a customized summary
depending on the specific question. Tests on a french multi-document corpus
have been realized, and the personalized QAAS system obtains the best
performances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.2997</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.2997</id><created>2009-05-18</created><authors><author><keyname>Guillory</keyname><forenames>Andrew</forenames></author><author><keyname>Bilmes</keyname><forenames>Jeff</forenames></author></authors><title>Average-Case Active Learning with Costs</title><categories>cs.LG</categories><comments>14 pages, 2 figures</comments><report-no>UWEETR-2009-0005</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the expected cost of a greedy active learning algorithm. Our
analysis extends previous work to a more general setting in which different
queries have different costs. Moreover, queries may have more than two possible
responses and the distribution over hypotheses may be non uniform. Specific
applications include active learning with label costs, active learning for
multiclass and partial label queries, and batch mode active learning. We also
discuss an approximate version of interest when there are very many queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3012</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3012</id><created>2009-05-18</created><authors><author><keyname>Du</keyname><forenames>Ye</forenames></author></authors><title>On the Complexity of Deciding Degeneracy in Games</title><categories>cs.GT cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that it is NP-Complete to decide whether a bimatrix game is
degenerate and it is Co-NP-Complete to decide whether a bimatrix game is
nondegenerate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3023</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3023</id><created>2009-05-19</created><updated>2009-05-20</updated><authors><author><keyname>Hanif</keyname><forenames>Muhammad Fainan</forenames></author><author><keyname>Shafi</keyname><forenames>Mansoor</forenames></author><author><keyname>Smith</keyname><forenames>Peter J.</forenames></author><author><keyname>Dmochowski</keyname><forenames>Pawel A.</forenames></author></authors><title>Interference and Deployment Issues for Cognitive Radio Systems in
  Shadowing Environments</title><categories>cs.IT math.IT</categories><comments>to be presented at IEEE ICC 2009. This posting is the same as the
  original one. Only author's list is updated that was unfortunately not
  correctly mentioned in first version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe a model for calculating the aggregate interference
encountered by primary receivers in the presence of randomly placed cognitive
radios (CRs). We show that incorporating the impact of distance attenuation and
lognormal fading on each constituent interferer in the aggregate, leads to a
composite interference that cannot be satisfactorily modeled by a lognormal.
Using the interference statistics we determine a number of key parameters
needed for the deployment of CRs. Examples of these are the exclusion zone
radius, needed to protect the primary receiver under different types of fading
environments and acceptable interference levels, and the numbers of CRs that
can be deployed. We further show that if the CRs have apriori knowledge of the
radio environment map (REM), then a much larger number of CRs can be deployed
especially in a high density environment. Given REM information, we also look
at the CR numbers achieved by two different types of techniques to process the
scheduling information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3030</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3030</id><created>2009-05-19</created><updated>2009-05-20</updated><authors><author><keyname>Hanif</keyname><forenames>Muhammad Fainan</forenames></author><author><keyname>Smith</keyname><forenames>Peter J.</forenames></author><author><keyname>Shafi</keyname><forenames>Mansoor</forenames></author></authors><title>Performance of Cognitive Radio Systems with Imperfect Radio Environment
  Map Information</title><categories>cs.IT math.IT</categories><comments>presented at IEEE AusCTW 2009. Journal versions are under
  preparation. This posting is the same as the original one. Only author's list
  is updated that was unfortunately not correctly mentioned in the first
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we describe the effect of imperfections in the radio
environment map (REM) information on the performance of cognitive radio (CR)
systems. Via simulations we explore the relationship between the required
precision of the REM and various channel/system properties. For example, the
degree of spatial correlation in the shadow fading is a key factor as is the
interference constraint employed by the primary user. Based on the CR
interferers obtained from the simulations, we characterize the temporal
behavior of such systems by computing the level crossing rates (LCRs) of the
cumulative interference represented by these CRs. This evaluates the effect of
short term fluctuations above acceptable interference levels due to the fast
fading. We derive analytical formulae for the LCRs in Rayleigh and Rician fast
fading conditions. The analytical results are verified by Monte Carlo
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3049</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3049</id><created>2009-05-19</created><authors><author><keyname>Hamra</keyname><forenames>Anwar Al</forenames><affiliation>UCLA-CS</affiliation></author><author><keyname>Liogkas</keyname><forenames>Nikitas</forenames><affiliation>UCLA-CS</affiliation></author><author><keyname>Legout</keyname><forenames>Arnaud</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Barakat</keyname><forenames>Chadi</forenames><affiliation>INRIA Sophia Antipolis / INRIA Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Swarming Overlay Construction Strategies</title><categories>cs.NI</categories><proxy>ccsd inria-00385351</proxy><journal-ref>ICCCN 2009 (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Swarming peer-to-peer systems play an increasingly instrumental role in
Internet content distribution. It is therefore important to better understand
how these systems behave in practice. Recent research efforts have looked at
various protocol parameters and have measured how they affect system
performance and robustness. However, the importance of the strategy based on
which peers establish connections has been largely overlooked. This work
utilizes extensive simulations to examine the default overlay construction
strategy in BitTorrent systems. Based on the results, we identify a critical
parameter, the maximum allowable number of outgoing connections at each peer,
and evaluate its impact on the robustness of the generated overlay. We find
that there is no single optimal value for this parameter using the default
strategy. We then propose an alternative strategy that allows certain new peer
connection requests to replace existing connections. Further experiments with
the new strategy demonstrate that it outperforms the default one for all
considered metrics by creating an overlay more robust to churn. Additionally,
our proposed strategy exhibits optimal behavior for a well-defined value of the
maximum number of outgoing connections, thereby removing the need to set this
parameter in an ad-hoc manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3070</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3070</id><created>2009-05-19</created><authors><author><keyname>Gyllenback</keyname><forenames>Katarina Borg</forenames></author></authors><title>Narrative Bridging - a specification of a modelling method for game
  design</title><categories>cs.HC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Very little has been explored about the narrative as a process when
constructing entertainment for interactive media. Simultaneously, the interest
in narrative vehicles increases while certain occupations, seeing the narrative
as a structure, obscure the examination of the process of selecting, arranging
and rendering story material. To correct this deficiency, a method for a
narrative bridging that encourages research and design while exploring
narration as a process, is proposed with the aim to not diminish the properties
of the interactive media. This method focuses on the initial phase where
establishing and handling the information takes place and creates a foundation
that precedes its systematization and computation. The aim is to give designers
a comfortable design tool that firmly aids the design without interfering with
creativity, and at the same time aids the construction of interplay between
narration, spatiality and interactivity. The method aided the practise of a
discipline that was established through a qualitative study conducted as part
of a university course in rapid prototyping. The results demonstrated that the
method aided time-constrained design processes, simultaneously detecting
inconsistencies that would prevent the team from making improvements. The
method gave the team a shared vocabulary and outlook, allowing them to progress
without interfering with the creative flow. This enabled the team to reason
about the process and easily advice design stakeholders. The study also
provides directions for future developments within research of narrative
processes in game design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3076</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3076</id><created>2009-05-19</created><authors><author><keyname>Paolini</keyname><forenames>E.</forenames></author><author><keyname>Flanagan</keyname><forenames>M. F.</forenames></author><author><keyname>Chiani</keyname><forenames>M.</forenames></author><author><keyname>Fossorier</keyname><forenames>M. P. C.</forenames></author></authors><title>On a Class of Doubly-Generalized LDPC Codes with Single Parity-Check
  Variable Nodes</title><categories>cs.IT math.IT</categories><comments>2009 IEEE Int. Symp. on Information Theory. 5 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A class of doubly-generalized low-density parity-check (D-GLDPC) codes, where
single parity-check (SPC) codes are used as variable nodes (VNs), is
investigated. An expression for the growth rate of the weight distribution of
any D-GLDPC ensemble with a uniform check node (CN) set is presented at first,
together with an analytical technique for its efficient evaluation. These tools
are then used for detailed analysis of a case study, namely, a rate-1/2 D-GLDPC
ensemble where all the CNs are (7,4) Hamming codes and all the VNs are length-7
SPC codes. It is illustrated how the VN representations can heavily affect the
code properties and how different VN representations can be combined within the
same graph to enhance some of the code parameters. The analysis is conducted
over the binary erasure channel. Interesting features of the new codes include
the capability of achieving a good compromise between waterfall and error floor
performance while preserving graphical regularity, and values of threshold
outperforming LDPC counterparts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3086</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3086</id><created>2009-05-19</created><updated>2009-05-20</updated><authors><author><keyname>Lim</keyname><forenames>Sung Hoon</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Deterministic Relay Networks with State Information</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in proc. IEEE ISIT, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by fading channels and erasure channels, the problem of reliable
communication over deterministic relay networks is studied, in which relay
nodes receive a function of the incoming signals and a random network state. An
achievable rate is characterized for the case in which destination nodes have
full knowledge of the state information. If the relay nodes receive a linear
function of the incoming signals and the state in a finite field, then the
achievable rate is shown to be optimal, meeting the cut-set upper bound on the
capacity. This result generalizes on a unified framework the work of
Avestimehr, Diggavi, and Tse on the deterministic networks with state
dependency, the work of Dana, Gowaikar, Palanki, Hassibi, and Effros on linear
erasure networks with interference, and the work of Smith and Vishwanath on
linear erasure networks with broadcast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3107</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3107</id><created>2009-05-19</created><authors><author><keyname>Gagie</keyname><forenames>Travis</forenames></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Fast and Compact Prefix Codes</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that, given a probability distribution over $n$ characters,
in the worst case it takes (\Theta (n \log n)) bits to store a prefix code with
minimum expected codeword length. However, in this paper we first show that,
for any $0&lt;\epsilon&lt;1/2$ with (1 / \epsilon = \Oh{\polylog{n}}), it takes
$\Oh{n \log \log (1 / \epsilon)}$ bits to store a prefix code with expected
codeword length within $\epsilon$ of the minimum. We then show that, for any
constant (c &gt; 1), it takes $\Oh{n^{1 / c} \log n}$ bits to store a prefix code
with expected codeword length at most $c$ times the minimum. In both cases, our
data structures allow us to encode and decode any character in $\Oh{1}$ time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3108</identifier>
 <datestamp>2009-05-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3108</id><created>2009-05-19</created><authors><author><keyname>Kazakov</keyname><forenames>Yevgeny</forenames></author><author><keyname>Pratt-Hartmann</keyname><forenames>Ian</forenames></author></authors><title>A Note on the Complexity of the Satisfiability Problem for Graded Modal
  Logics</title><categories>cs.LO cs.AI cs.CC</categories><comments>Full proofs for paper presented at the IEEE Conference on Logic in
  Computer Science, 2009</comments><acm-class>F.4.1; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graded modal logic is the formal language obtained from ordinary
(propositional) modal logic by endowing its modal operators with cardinality
constraints. Under the familiar possible-worlds semantics, these augmented
modal operators receive interpretations such as &quot;It is true at no fewer than 15
accessible worlds that...&quot;, or &quot;It is true at no more than 2 accessible worlds
that...&quot;. We investigate the complexity of satisfiability for this language
over some familiar classes of frames. This problem is more challenging than its
ordinary modal logic counterpart--especially in the case of transitive frames,
where graded modal logic lacks the tree-model property. We obtain tight
complexity bounds for the problem of determining the satisfiability of a given
graded modal logic formula over the classes of frames characterized by any
combination of reflexivity, seriality, symmetry, transitivity and the Euclidean
property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3109</identifier>
 <datestamp>2011-01-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3109</id><created>2009-05-19</created><updated>2010-11-06</updated><authors><author><keyname>Prabhakaran</keyname><forenames>Vinod M.</forenames></author><author><keyname>Viswanath</keyname><forenames>Pramod</forenames></author></authors><title>Interference Channels with Source Cooperation</title><categories>cs.IT math.IT</categories><comments>revised based on reviewers' comments</comments><journal-ref>IEEE Trans. Inform. Theory 57 (2011) 156-186</journal-ref><doi>10.1109/TIT.2010.2090231</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The role of cooperation in managing interference - a fundamental feature of
the wireless channel - is investigated by studying the two-user Gaussian
interference channel where the source nodes can both transmit and receive in
full-duplex. The sum-capacity of this channel is obtained within a gap of a
constant number of bits. The coding scheme used builds up on the superposition
scheme of Han and Kobayashi (1981) for the two-user interference channel
without cooperation. New upperbounds on the sum-capacity are also derived. The
same coding scheme is shown to obtain the sum-capacity of the symmetric
two-user Gaussian interference channel with noiseless feedback within a
constant gap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3135</identifier>
 <datestamp>2009-09-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3135</id><created>2009-05-19</created><updated>2009-09-21</updated><authors><author><keyname>Mahalanobis</keyname><forenames>Ayan</forenames></author></authors><title>The discrete logarithm problem in the group of non-singular circulant
  matrices</title><categories>cs.CR cs.DM cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The discrete logarithm problem is one of the backbones in public key
cryptography. In this paper we study the discrete logarithm problem in the
group of circulant matrices over a finite field. This gives rise to secure and
fast public key cryptosystems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3158</identifier>
 <datestamp>2010-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3158</id><created>2009-05-19</created><updated>2010-05-31</updated><authors><author><keyname>Mairesse</keyname><forenames>Jean</forenames><affiliation>LIAFA</affiliation></author><author><keyname>Nguyen</keyname><forenames>Hoang-Thach</forenames><affiliation>LIAFA</affiliation></author></authors><title>Deficiency Zero Petri Nets and Product Form</title><categories>cs.DM</categories><comments>This is a long and improved version of the conference paper: J.
  Mairesse and H.-T. Nguyen. Deficiency zero Petri nets and product form. In G.
  Franceschinis and K. Wolf, editors, Petri Nets 2009, volume 5606 of LNCS,
  pages 103-122. Springer-Verlag, 2009</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a Markovian Petri net with race policy. The marking process has a
&quot;product form&quot; stationary distribution if the probability of viewing a given
marking can be decomposed as the product over places of terms depending only on
the local marking. First we observe that the Deficiency Zero Theorem of
Feinberg, developped for chemical reaction networks, provides a structural and
simple sufficient condition for the existence of a product form. In view of
this, we study the classical subclass of free-choice nets. Roughly, we show
that the only such Petri nets having a product form are the state machines
which can alternatively be viewed as Jackson networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3178</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3178</id><created>2009-05-19</created><authors><author><keyname>Dejter</keyname><forenames>Italo J.</forenames></author></authors><title>SQS-graphs of Solov'eva-Phelps codes</title><categories>math.CO cs.IT math.IT</categories><comments>14 pages, 15 tables</comments><msc-class>05C90; 94B25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A binary extended 1-perfect code $\mathcal C$ folds over its kernel via the
Steiner quadruple systems associated with its codewords. The resulting folding,
proposed as a graph invariant for $\mathcal C$, distinguishes among the 361
nonlinear codes $\mathcal C$ of kernel dimension $\kappa$ obtained via
Solov'eva-Phelps doubling construction, where $9\geq\kappa\geq 5$. Each of the
361 resulting graphs has most of its nonloop edges expressible in terms of
lexicographically ordered quarters of products of classes from extended
1-perfect partitions of length 8 (as classified by Phelps) and loops mostly
expressible in terms of the lines of the Fano plane.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3191</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3191</id><created>2009-05-19</created><authors><author><keyname>Chakraborty</keyname><forenames>Tanmoy</forenames></author><author><keyname>Huang</keyname><forenames>Zhiyi</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>Dynamic and Non-Uniform Pricing Strategies for Revenue Maximization</title><categories>cs.GT</categories><comments>23 pages, 0 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the Item Pricing problem for revenue maximization in the limited
supply setting, where a single seller with $n$ items caters to $m$ buyers with
unknown subadditive valuation functions who arrive in a sequence. The seller
sets the prices on individual items. Each buyer buys a subset of yet unsold
items that maximizes her utility. Our goal is to design pricing strategies that
guarantee an expected revenue that is within a small factor $\alpha$ of the
maximum possible social welfare -- an upper bound on the maximum revenue that
can be generated. Most earlier work has focused on the unlimited supply
setting, where selling items to some buyer does not affect their availability
to the future buyers. Balcan et. al. (EC 2008) studied the limited supply
setting, giving a randomized strategy that assigns a single price to all items
(uniform strategy), and never changes it (static strategy), that gives an
$2^{O(\sqrt{\log n \log \log n})}$-approximation, and moreover, no static
uniform pricing strategy can give better than $2^{\Omega(\log^{1/4} n)}$-
approximation. We improve this lower bound to $2^{\Omega(sqrt{\log n})}$.
  We consider dynamic uniform strategies, which can change the price upon the
arrival of each buyer but the price on all unsold items is the same at all
times, and static non-uniform strategies, which can assign different prices to
different items but can never change it after setting it initially. We design
such pricing strategies that give a poly-logarithmic approximation to maximum
revenue. Thus in the limited supply setting, our results highlight a strong
separation between the power of dynamic and non-uniform pricing versus static
uniform pricing. To our knowledge, this is the first non-trivial analysis of
dynamic and non-uniform pricing schemes for revenue maximization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3201</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3201</id><created>2009-05-20</created><authors><author><keyname>Hanif</keyname><forenames>Muhammad Fainan</forenames></author><author><keyname>Smith</keyname><forenames>Peter J.</forenames></author><author><keyname>Shafi</keyname><forenames>Mansoor</forenames></author></authors><title>On the Statistics of Cognitive Radio Capacity in Shadowing and Fast
  Fading Environments</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE CrownCom 2009 Proc</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the capacity of the cognitive radio channel in a
fading environment under a &quot;low interference regime&quot;. This capacity depends
critically on a power loss parameter, $\alpha$, which governs how much transmit
power the cognitive radio dedicates to relaying the primary message. We derive
a simple, accurate approximation to $\alpha$ which gives considerable insight
into system capacity. We also investigate the effects of system parameters and
propagation environment on $\alpha$ and the cognitive radio capacity. In all
cases, the use of the approximation is shown to be extremely accurate. Finally,
we derive the probability that the &quot;low interference regime&quot; holds and
demonstrate that this is the dominant case, especially in practical cognitive
radio deployment scenarios.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3245</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3245</id><created>2009-05-20</created><authors><author><keyname>Li</keyname><forenames>Lianlin</forenames></author><author><keyname>Li</keyname><forenames>Fang</forenames></author></authors><title>Novel Algorithm for Sparse Solutions to Linear Inverse Problems with
  Multiple Measurements</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, a novel efficient algorithm for recovery of jointly sparse
signals (sparse matrix) from multiple incomplete measurements has been
presented, in particular, the NESTA-based MMV optimization method. In a
nutshell, the jointly sparse recovery is obviously superior to applying
standard sparse reconstruction methods to each channel individually. Moreover
several efforts have been made to improve the NESTA-based MMV algorithm, in
particular, (1) the NESTA-based MMV algorithm for partially known support to
greatly improve the convergence rate, (2) the detection of partial (or all)
locations of unknown jointly sparse signals by using so-called MUSIC algorithm;
(3) the iterative NESTA-based algorithm by combing hard thresholding technique
to decrease the numbers of measurements. It has been shown that by using
proposed approach one can recover the unknown sparse matrix X with () Spark A
-sparsity from () Spark A measurements, predicted in Ref. [1], where the
measurement matrix denoted by A satisfies the so-called restricted isometry
property (RIP). Under a very mild condition on the sparsity of X and
characteristics of the A, the iterative hard threshold (IHT)-based MMV method
has been shown to be also a very good candidate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3267</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3267</id><created>2009-05-20</created><authors><author><keyname>Ghosh</keyname><forenames>Asim</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Anindya Sundar</forenames></author><author><keyname>Chakrabarti</keyname><forenames>Bikas K.</forenames></author></authors><title>Kolkata Paise Restaurant Problem in Some Uniform Learning Strategy
  Limits</title><categories>cs.GT physics.soc-ph</categories><comments>to be published in &quot;Econophysics &amp; Economics of Games, Social Choices
  &amp; Quantitative Techniques&quot;, Proc. Econophys-Kolkata IV, Springer, Milan
  (2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the dynamics of some uniform learning strategy limits or a
probabilistic version of the &quot;Kolkata Paise Restaurant&quot; problem, where N agents
choose among N equally priced but differently ranked restaurants every evening
such that each agent can get dinner in the best possible ranked restaurant
(each serving only one customer and the rest arriving there going without
dinner that evening). We consider the learning to be uniform among the agents
and assume that each follow the same probabilistic strategy dependent on the
information of the past successes in the game. The numerical results for
utilization of the restaurants in some limiting cases are analytically
examined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3287</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3287</id><created>2009-05-20</created><authors><author><keyname>Murgia</keyname><forenames>Alessandro</forenames></author><author><keyname>Concas</keyname><forenames>Giulio</forenames></author><author><keyname>Pinna</keyname><forenames>Sandro</forenames></author><author><keyname>Tonelli</keyname><forenames>Roberto</forenames></author><author><keyname>Turnu</keyname><forenames>Ivana</forenames></author></authors><title>Empirical study of software quality evolution in open source projects
  using agile practices</title><categories>cs.SE cs.PL</categories><comments>12 pages, 6 figures 2 tables</comments><acm-class>D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the time evolution of two open source Java projects: Eclipse and
Netbeans, both developed following agile practices, though to a different
extent. Our study is centered on quality analysis of the systems, measured as
defects absence, and its relation with software metrics evolution. The two
projects are described through a software graph in which nodes are represented
by Java files and edges describe the existing relation between nodes. We
propose a metrics suite for Java files based on Chidamber and Kemerer suite,
and use it to study software evolution and its relationship with bug count.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3296</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3296</id><created>2009-05-20</created><authors><author><keyname>Murgia</keyname><forenames>Alessandro</forenames></author><author><keyname>Concas</keyname><forenames>Giulio</forenames></author><author><keyname>Marchesi</keyname><forenames>Michele</forenames></author><author><keyname>Tonelli</keyname><forenames>Roberto</forenames></author><author><keyname>Turnu</keyname><forenames>Ivana</forenames></author></authors><title>An Analysis of Bug Distribution in Object Oriented Systems</title><categories>cs.SE cs.PL</categories><comments>17 pages, 8 figures, 10 tables</comments><acm-class>D.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduced a new approach to describe Java software as graph, where nodes
represent a Java file - called compilation unit (CU) - and an edges represent a
relations between them. The software system is characterized by the degree
distribution of the graph properties, like in-or-out links, as well as by the
distribution of Chidamber and Kemerer metrics computed on its CUs. Every CU can
be related to one or more bugs during its life. We find a relationship among
the software system and the bugs hitting its nodes. We found that the
distribution of some metrics, and the number of bugs per CU, exhibit a
power-law behavior in their tails, as well as the number of CUs influenced by a
specific bug. We examine the evolution of software metrics across different
releases to understand how relationships among CUs metrics and CUs faultness
change with time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3318</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3318</id><created>2009-05-20</created><authors><author><keyname>Hijzelendoorn</keyname><forenames>Maarten</forenames></author><author><keyname>Cremers</keyname><forenames>Crit</forenames></author></authors><title>An Object-Oriented and Fast Lexicon for Semantic Generation</title><categories>cs.CL cs.DB cs.DS cs.IR cs.PL</categories><comments>Paper presented at the 18th Computational Linguistics In the
  Netherlands Meeting (CLIN), Nijmegen, 10 December 2007, 15pp</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about the technical design of a large computational lexicon,
its storage, and its access from a Prolog environment. Traditionally, efficient
access and storage of data structures is implemented by a relational database
management system. In Delilah, a lexicon-based NLP system, efficient access to
the lexicon by the semantic generator is vital. We show that our highly
detailed HPSG-style lexical specifications do not fit well in the Relational
Model, and that they cannot be efficiently retrieved. We argue that they fit
more naturally in the Object-Oriented Model. Although storage of objects is
redundant, we claim that efficient access is still possible by applying
indexing, and compression techniques from the Relational Model to the
Object-Oriented Model. We demonstrate that it is possible to implement
object-oriented storage and fast access in ISO Prolog.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3330</identifier>
 <datestamp>2011-05-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3330</id><created>2009-05-20</created><updated>2009-07-29</updated><authors><author><keyname>Kutateladze</keyname><forenames>S. S.</forenames></author></authors><title>The Game of Cipher Beads</title><categories>cs.DL math.HO</categories><comments>The last data are inserted</comments><journal-ref>J.Appl. Indust. Math., 2009, V.3, No.3, 364-366</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Comparison between the various impact factors of a few Russian journals
demonstrates the deficiencies of the popular citation indices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3347</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3347</id><created>2009-05-20</created><authors><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames></author></authors><title>Information Distance in Multiples</title><categories>cs.CV cs.LG</categories><comments>LateX 14 pages, Submitted to a technical journal</comments><acm-class>J.3; E.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information distance is a parameter-free similarity measure based on
compression, used in pattern recognition, data mining, phylogeny, clustering,
and classification. The notion of information distance is extended from pairs
to multiples (finite lists). We study maximal overlap, metricity, universality,
minimal overlap, additivity, and normalized information distance in multiples.
We use the theoretical notion of Kolmogorov complexity which for practical
purposes is approximated by the length of the compressed version of the file
involved, using a real-world compression program.
  {\em Index Terms}-- Information distance, multiples, pattern recognition,
data mining, similarity, Kolmogorov complexity
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3348</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3348</id><created>2009-05-20</created><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Paterson</keyname><forenames>Mike</forenames></author></authors><title>False name manipulations in weighted voting games: splitting, merging
  and annexation</title><categories>cs.GT</categories><comments>Preprint of AAMAS 2009 (Eighth International Conference on Autonomous
  Agents and Multiagent Systems) paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important aspect of mechanism design in social choice protocols and
multiagent systems is to discourage insincere and manipulative behaviour. We
examine the computational complexity of false-name manipulation in weighted
voting games which are an important class of coalitional voting games. Weighted
voting games have received increased interest in the multiagent community due
to their compact representation and ability to model coalitional formation
scenarios. Bachrach and Elkind in their AAMAS 2008 paper examined divide and
conquer false-name manipulation in weighted voting games from the point of view
of Shapley-Shubik index. We analyse the corresponding case of the Banzhaf index
and check how much the Banzhaf index of a player increases or decreases if it
splits up into sub-players. A pseudo-polynomial algorithm to find the optimal
split is also provided. Bachrach and Elkind also mentioned manipulation via
merging as an open problem. In the paper, we examine the cases where a player
annexes other players or merges with them to increase their Banzhaf index or
Shapley-Shubik index payoff. We characterize the computational complexity of
such manipulations and provide limits to the manipulation. The annexation
non-monotonicity paradox is also discovered in the case of the Banzhaf index.
The results give insight into coalition formation and manipulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3356</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3356</id><created>2009-05-20</created><authors><author><keyname>Parfionov</keyname><forenames>George</forenames></author><author><keyname>Zapatrin</keyname><forenames>Rom&#xe0;n</forenames></author></authors><title>Memento Ludi: Information Retrieval from a Game-Theoretic Perspective</title><categories>cs.IR cs.GT</categories><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a macro-model of information retrieval process using Game Theory
as a mathematical theory of conflicts. We represent the participants of the
Information Retrieval process as a game of two abstract players. The first
player is the `intellectual crowd' of users of search engines, the second is a
community of information retrieval systems. In order to apply Game Theory, we
treat search log data as Nash equilibrium strategies and solve the inverse
problem of finding appropriate payoff functions. For that, we suggest a
particular model, which we call Alpha model. Within this model, we suggest a
method, called shifting, which makes it possible to partially control the
behavior of massive users.
  This Note is addressed to researchers in both game theory (providing a new
class of real life problems) and information retrieval, for whom we present new
techniques to control the IR environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3359</identifier>
 <datestamp>2009-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3359</id><created>2009-05-20</created><authors><author><keyname>Kehagias</keyname><forenames>Ath.</forenames></author><author><keyname>Hollinger</keyname><forenames>G.</forenames></author><author><keyname>Gelastopoulos</keyname><forenames>A.</forenames></author></authors><title>Searching the Nodes of a Graph: Theory and Algorithms</title><categories>cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One or more searchers must capture an invisible evader hiding in the nodes of
a graph. We study this graph search problem; we emphasize that we study the
capture of a node-located evader, which has received less attention than edge
search. We show that in general graphs the problem of node search is easier
than that of edge search (however node search is NP-complete, just like edge
search). We concentrate on the internal monotone connected (IMC) node search of
trees and show that it is essentially equivalent to IMC edge search. For IMC
node search on general graphs we present a new algorithm: GSST (Guaranteed
Search by Spanning Tree) which clears the graph G by performing all its
clearing moves along a spanning tree T of G. We prove the existence of
probabilistically complete variants of GSST. Our experiments also indicate that
GSST can efficiently node-clear large graphs given only a small running time.
An implementation of GSST is also provided and made publicly available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3360</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3360</id><created>2009-05-20</created><authors><author><keyname>Lopez-Ruiz</keyname><forenames>R.</forenames></author><author><keyname>Nagy</keyname><forenames>A.</forenames></author><author><keyname>Romera</keyname><forenames>E.</forenames></author><author><keyname>Sanudo</keyname><forenames>J.</forenames></author></authors><title>A Generalized Statistical Complexity Measure: Applications to Quantum
  Systems</title><categories>quant-ph cs.IT math.IT nlin.AO physics.atom-ph</categories><comments>15 pages, 3 figures</comments><doi>10.1063/1.3274387</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-parameter family of complexity measures $\tilde{C}^{(\alpha,\beta)}$
based on the R\'enyi entropies is introduced and characterized by a detailed
study of its mathematical properties. This family is the generalization of a
continuous version of the LMC complexity, which is recovered for $\alpha=1$ and
$\beta=2$. These complexity measures are obtained by multiplying two quantities
bringing global information on the probability distribution defining the
system. When one of the parameters, $\alpha$ or $\beta$, goes to infinity, one
of the global factors becomes a local factor. For this special case, the
complexity is calculated on different quantum systems: H-atom, harmonic
oscillator and square well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3369</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3369</id><created>2009-05-20</created><updated>2009-06-03</updated><authors><author><keyname>Langford</keyname><forenames>John</forenames></author><author><keyname>Salakhutdinov</keyname><forenames>Ruslan</forenames></author><author><keyname>Zhang</keyname><forenames>Tong</forenames></author></authors><title>Learning Nonlinear Dynamic Models</title><categories>cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a novel approach for learning nonlinear dynamic models, which
leads to a new set of tools capable of solving problems that are otherwise
difficult. We provide theory showing this new approach is consistent for models
with long range structure, and apply the approach to motion capture and
high-dimensional video data, yielding results superior to standard
alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3378</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3378</id><created>2009-05-20</created><updated>2009-05-20</updated><authors><author><keyname>Rodriguez</keyname><forenames>Marko A.</forenames></author></authors><title>Interpretations of the Web of Data</title><categories>cs.AI cs.DL</categories><report-no>LA-UR-09-03344</report-no><acm-class>I.2.4; G.2.2; D.1.5</acm-class><journal-ref>Data Management in the Semantic Web, eds. H. Jin and Z. Lv,
  series: Distributed, Cluster and Grid Computing, pp. 1-37, Nova Publishing,
  ISBN:978-1-61324-760-0, 2011</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The emerging Web of Data utilizes the web infrastructure to represent and
interrelate data. The foundational standards of the Web of Data include the
Uniform Resource Identifier (URI) and the Resource Description Framework (RDF).
URIs are used to identify resources and RDF is used to relate resources. While
RDF has been posited as a logic language designed specifically for knowledge
representation and reasoning, it is more generally useful if it can
conveniently support other models of computing. In order to realize the Web of
Data as a general-purpose medium for storing and processing the world's data,
it is necessary to separate RDF from its logic language legacy and frame it
simply as a data model. Moreover, there is significant advantage in seeing the
Semantic Web as a particular interpretation of the Web of Data that is focused
specifically on knowledge representation and reasoning. By doing so, other
interpretations of the Web of Data are exposed that realize RDF in different
capacities and in support of different computing models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3407</identifier>
 <datestamp>2011-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3407</id><created>2009-05-20</created><updated>2011-10-18</updated><authors><author><keyname>Gao</keyname><forenames>Long</forenames></author><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Yin</keyname><forenames>Changchuan</forenames></author><author><keyname>Cui</keyname><forenames>Shuguang</forenames></author></authors><title>Throughput and Delay Scaling in Supportive Two-Tier Networks</title><categories>cs.IT math.IT</categories><comments>13 pages, double-column, 6 figures, accepted for publication in JSAC
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a wireless network that has two tiers with different priorities: a
primary tier vs. a secondary tier, which is an emerging network scenario with
the advancement of cognitive radio technologies. The primary tier consists of
randomly distributed legacy nodes of density $n$, which have an absolute
priority to access the spectrum. The secondary tier consists of randomly
distributed cognitive nodes of density $m=n^\beta$ with $\beta\geq 2$, which
can only access the spectrum opportunistically to limit the interference to the
primary tier. Based on the assumption that the secondary tier is allowed to
route the packets for the primary tier, we investigate the throughput and delay
scaling laws of the two tiers in the following two scenarios: i) the primary
and secondary nodes are all static; ii) the primary nodes are static while the
secondary nodes are mobile. With the proposed protocols for the two tiers, we
show that the primary tier can achieve a per-node throughput scaling of
$\lambda_p(n)=\Theta(1/\log n)$ in the above two scenarios. In the associated
delay analysis for the first scenario, we show that the primary tier can
achieve a delay scaling of $D_p(n)=\Theta(\sqrt{n^\beta\log n}\lambda_p(n))$
with $\lambda_p(n)=O(1/\log n)$. In the second scenario, with two mobility
models considered for the secondary nodes: an i.i.d. mobility model and a
random walk model, we show that the primary tier can achieve delay scaling laws
of $\Theta(1)$ and $\Theta(1/S)$, respectively, where $S$ is the random walk
step size. The throughput and delay scaling laws for the secondary tier are
also established, which are the same as those for a stand-alone network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3428</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3428</id><created>2009-05-20</created><authors><author><keyname>Rebbapragada</keyname><forenames>Umaa</forenames></author><author><keyname>Protopapas</keyname><forenames>Pavlos</forenames></author><author><keyname>Brodley</keyname><forenames>Carla E.</forenames></author><author><keyname>Alcock</keyname><forenames>Charles</forenames></author></authors><title>Finding Anomalous Periodic Time Series: An Application to Catalogs of
  Periodic Variable Stars</title><categories>cs.LG astro-ph.IM physics.data-an</categories><journal-ref>Machine Learning 74:281,2009</journal-ref><doi>10.1007/s10994-008-5093-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Catalogs of periodic variable stars contain large numbers of periodic
light-curves (photometric time series data from the astrophysics domain).
Separating anomalous objects from well-known classes is an important step
towards the discovery of new classes of astronomical objects. Most anomaly
detection methods for time series data assume either a single continuous time
series or a set of time series whose periods are aligned. Light-curve data
precludes the use of these methods as the periods of any given pair of
light-curves may be out of sync. One may use an existing anomaly detection
method if, prior to similarity calculation, one performs the costly act of
aligning two light-curves, an operation that scales poorly to massive data
sets. This paper presents PCAD, an unsupervised anomaly detection method for
large sets of unsynchronized periodic time-series data, that outputs a ranked
list of both global and local anomalies. It calculates its anomaly score for
each light-curve in relation to a set of centroids produced by a modified
k-means clustering algorithm. Our method is able to scale to large data sets
through the use of sampling. We validate our method on both light-curve data
and other time series data sets. We demonstrate its effectiveness at finding
known anomalies, and discuss the effect of sample size and number of centroids
on our results. We compare our method to naive solutions and existing time
series anomaly detection methods for unphased data, and show that PCAD's
reported anomalies are comparable to or better than all other methods. Finally,
astrophysicists on our team have verified that PCAD finds true anomalies that
might be indicative of novel astrophysical phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3429</identifier>
 <datestamp>2009-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3429</id><created>2009-05-20</created><authors><author><keyname>Babaioff</keyname><forenames>Moshe</forenames></author><author><keyname>Blumrosen</keyname><forenames>Liad</forenames></author><author><keyname>Roth</keyname><forenames>Aaron L.</forenames></author></authors><title>Auctions with Online Supply</title><categories>cs.GT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of selling identical goods to n unit-demand bidders in a
setting in which the total supply of goods is unknown to the mechanism. Items
arrive dynamically, and the seller must make the allocation and payment
decisions online with the goal of maximizing social welfare. We consider two
models of unknown supply: the adversarial supply model, in which the mechanism
must produce a welfare guarantee for any arbitrary supply, and the stochastic
supply model, in which supply is drawn from a distribution known to the
mechanism, and the mechanism need only provide a welfare guarantee in
expectation.
  Our main result is a separation between these two models. We show that all
truthful mechanisms, even randomized, achieve a diminishing fraction of the
optimal social welfare (namely, no better than a Omega(loglog n) approximation)
in the adversarial setting. In sharp contrast, in the stochastic model, under a
standard monotone hazard-rate condition, we present a truthful mechanism that
achieves a constant approximation. We show that the monotone hazard rate
condition is necessary, and also characterize a natural subclass of truthful
mechanisms in our setting, the set of online-envy-free mechanisms. All of the
mechanisms we present fall into this class, and we prove almost optimal lower
bounds for such mechanisms. Since auctions with unknown supply are regularly
run in many online-advertising settings, our main results emphasize the
importance of considering distributional information in the design of auctions
in such environments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3432</identifier>
 <datestamp>2009-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3432</id><created>2009-05-20</created><authors><author><keyname>de Carvalho-Junior</keyname><forenames>Francisco Heron</forenames></author><author><keyname>Lins</keyname><forenames>Rafael Dueire</forenames></author></authors><title>A Type System for Parallel Components</title><categories>cs.PL</categories><comments>Submitted to SBLP 2009 (Brazilian Symposium on Programming Languages)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The # component model was proposed to improve the practice of parallel
programming. This paper introduces a type system for # programming systems,
aiming to lift the abstraction and safety of programming for parallel computing
architectures by introducing a notion of abstract component based on universal
and existential bounded quantification. Issues about the implementation of such
type system in HPE, a # programming system, are also discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3434</identifier>
 <datestamp>2009-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3434</id><created>2009-05-21</created><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author><author><keyname>Cioffi</keyname><forenames>John M.</forenames></author></authors><title>Exploiting Opportunistic Multiuser Detection in Decentralized Multiuser
  MIMO Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the design of a decentralized multiuser multi-antenna
(MIMO) system for spectrum sharing over a fixed narrow band, where the
coexisting users independently update their transmit covariance matrices for
individual transmit-rate maximization via an iterative manner. This design
problem was usually investigated in the literature by assuming that each user
treats the co-channel interference from all the other users as additional
(colored) noise at the receiver, i.e., the conventional single-user decoder
(SUD) is applied. This paper proposes a new decoding method for the
decentralized multiuser MIMO system, whereby each user opportunistically
cancels the co-channel interference from some or all of the other users via
applying multiuser detection techniques, thus termed opportunistic multiuser
detection (OMD). This paper studies the optimal transmit covariance design for
users' iterative maximization of individual transmit rates with the proposed
OMD, and demonstrates the resulting capacity gains in decentralized multiuser
MIMO systems against the conventional SUD.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3436</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3436</id><created>2009-05-21</created><updated>2010-06-21</updated><authors><author><keyname>Zhang</keyname><forenames>Rui</forenames></author></authors><title>On Active Learning and Supervised Transmission of Spectrum Sharing Based
  Cognitive Radios by Exploiting Hidden Primary Radio Feedback</title><categories>cs.IT math.IT</categories><comments>accepted in IEEE Transactions on Communications, June 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the wireless spectrum sharing between a pair of
distributed primary radio (PR) and cognitive radio (CR) links. Assuming that
the PR link adapts its transmit power and/or rate upon receiving an
interference signal from the CR and such transmit adaptations are observable by
the CR, this results in a new form of feedback from the PR to CR, refereed to
as hidden PR feedback, whereby the CR learns the PR's strategy for transmit
adaptations without the need of a dedicated feedback channel from the PR. In
this paper, we exploit the hidden PR feedback to design new learning and
transmission schemes for spectrum sharing based CRs, namely active learning and
supervised transmission. For active learning, the CR initiatively sends a
probing signal to interfere with the PR, and from the observed PR transmit
adaptations the CR estimates the channel gain from its transmitter to the PR
receiver, which is essential for the CR to control its interference to the PR
during the subsequent data transmission. This paper proposes a new transmission
protocol for the CR to implement the active learning and the solutions to deal
with various practical issues for implementation, such as time synchronization,
rate estimation granularity, power measurement noise, and channel variation.
Furthermore, with the acquired knowledge from active learning, the CR designs a
supervised data transmission by effectively controlling the interference powers
both to and from the PR, so as to achieve the optimum performance tradeoffs for
the PR and CR links. Numerical results are provided to evaluate the
effectiveness of the proposed schemes for CRs under different system setups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3454</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3454</id><created>2009-05-21</created><authors><author><keyname>Kuhn</keyname><forenames>Fabian</forenames></author><author><keyname>Oshman</keyname><forenames>Rotem</forenames></author></authors><title>Gradient Clock Synchronization using Reference Broadcasts</title><categories>cs.DC cs.DS</categories><comments>21 page, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we suggest a method by which reference broadcast
synchronization (RBS), and other methods of estimating clock values, can be
incorporated in standard clock synchronization algorithms to improve
synchronization quality. We advocate a logical separation of the task of
estimating the clock values of other nodes in the network from the task of
using these estimates to output a logical clock value.
  The separation is achieved by means of a virtual estimate graph, overlaid on
top of the real network graph, which represents the information various nodes
can obtain about each other. RBS estimates are represented in the estimate
graph as edges between nodes at distance 2 from each other in the original
network graph. A clock synchronization algorithm then operates on the estimate
graph as though it were the original network.
  To illustrate the merits of this approach, we modify a recent optimal
gradient clock synchronization algorithm to work in this setting. The modified
algorithm transparently takes advantage of RBS estimates and any other means by
which nodes can estimate each others' clock values.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3487</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3487</id><created>2009-05-21</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>A Simple Proof of an Inequality Connecting the Alternating Number of
  Independent Sets and the Decycling Number</title><categories>math.CO cs.DM</categories><comments>4 pages</comments><msc-class>05C69, 05A20 (Primary); 52B05, 57M15 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If alpha=alpha(G) is the maximum size of an independent set and s_{k} equals
the number of stable sets of cardinality k in graph G, then
I(G;x)=s_{0}+s_{1}x+...+s_{alpha}x^{alpha} is the independence polynomial of G.
In this paper we provide an elementary proof of the inequality claiming that
the absolute value of I(G;-1) is not greater than 2^phi(G), for every graph G,
where phi(G) is its decycling number.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3527</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3527</id><created>2009-05-21</created><updated>2009-05-28</updated><authors><author><keyname>Kurihara</keyname><forenames>Kenichi</forenames></author><author><keyname>Tanaka</keyname><forenames>Shu</forenames></author><author><keyname>Miyashita</keyname><forenames>Seiji</forenames></author></authors><title>Quantum Annealing for Clustering</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.LG quant-ph</categories><comments>8 pages, 6 figures, Proceedings of the 25th Conference on Uncertainty
  in Artificial Intelligence (UAI 2009) accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies quantum annealing (QA) for clustering, which can be seen
as an extension of simulated annealing (SA). We derive a QA algorithm for
clustering and propose an annealing schedule, which is crucial in practice.
Experiments show the proposed QA algorithm finds better clustering assignments
than SA. Furthermore, QA is as easy as SA to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3528</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3528</id><created>2009-05-21</created><updated>2009-05-28</updated><authors><author><keyname>Sato</keyname><forenames>Issei</forenames></author><author><keyname>Kurihara</keyname><forenames>Kenichi</forenames></author><author><keyname>Tanaka</keyname><forenames>Shu</forenames></author><author><keyname>Nakagawa</keyname><forenames>Hiroshi</forenames></author><author><keyname>Miyashita</keyname><forenames>Seiji</forenames></author></authors><title>Quantum Annealing for Variational Bayes Inference</title><categories>cond-mat.dis-nn cond-mat.stat-mech cs.LG quant-ph</categories><comments>9 pages, 4 figures, Proceedings of the 25th Conference on Uncertainty
  in Artificial Intelligence (UAI 2009) accepted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents studies on a deterministic annealing algorithm based on
quantum annealing for variational Bayes (QAVB) inference, which can be seen as
an extension of the simulated annealing for variational Bayes (SAVB) inference.
QAVB is as easy as SAVB to implement. Experiments revealed QAVB finds a better
local optimum than SAVB in terms of the variational free energy in latent
Dirichlet allocation (LDA).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3548</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3548</id><created>2009-05-21</created><authors><author><keyname>Pavlovic</keyname><forenames>Dusko</forenames></author></authors><title>A semantical approach to equilibria and rationality</title><categories>cs.GT</categories><comments>18 pages; Proceedings of CALCO 2009</comments><acm-class>F.3.2</acm-class><doi>10.1007/978-3-642-03741-2_22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game theoretic equilibria are mathematical expressions of rationality.
Rational agents are used to model not only humans and their software
representatives, but also organisms, populations, species and genes,
interacting with each other and with the environment. Rational behaviors are
achieved not only through conscious reasoning, but also through spontaneous
stabilization at equilibrium points.
  Formal theories of rationality are usually guided by informal intuitions,
which are acquired by observing some concrete economic, biological, or network
processes. Treating such processes as instances of computation, we reconstruct
and refine some basic notions of equilibrium and rationality from the some
basic structures of computation.
  It is, of course, well known that equilibria arise as fixed points; the point
is that semantics of computation of fixed points seems to be providing novel
methods, algebraic and coalgebraic, for reasoning about them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3564</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3564</id><created>2009-05-21</created><authors><author><keyname>Lalescu</keyname><forenames>Cristian Constantin</forenames></author></authors><title>Two hierarchies of spline interpolations. Practical algorithms for
  multivariate higher order splines</title><categories>cs.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A systematic construction of higher order splines using two hierarchies of
polynomials is presented. Explicit instructions on how to implement one of
these hierarchies are given. The results are limited to interpolations on
regular, rectangular grids, but an approach to other types of grids is also
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3569</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3569</id><created>2009-05-21</created><authors><author><keyname>Voyant</keyname><forenames>Cyril</forenames></author><author><keyname>Muselli</keyname><forenames>Marc</forenames></author><author><keyname>Paoli</keyname><forenames>Christophe</forenames></author><author><keyname>Nivet</keyname><forenames>Marie Laure</forenames></author><author><keyname>Poggi</keyname><forenames>Philippe</forenames></author></authors><title>Predictability of PV power grid performance on insular sites without
  weather stations: use of artificial neural networks</title><categories>cs.OH</categories><comments>4 pages, 3 figures, 24th European Photovoltaic Solar Energy
  Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The official meteorological network is poor on the island of Corsica: only
three sites being about 50 km apart are equipped with pyranometers which enable
measurements by hourly and daily step. These sites are Ajaccio (seaside),
Bastia (seaside) and Corte (average altitude of 486 meters). This lack of
weather station makes difficult the predictability of PV power grid
performance. This work intends to study a methodology which can predict global
solar irradiation using data available from another location for daily and
hourly horizon. In order to achieve this prediction, we have used Artificial
Neural Network which is a popular artificial intelligence technique in the
forecasting domain. A simulator has been obtained using data available for the
station of Ajaccio that is the only station for which we have a lot of data: 16
years from 1972 to 1987. Then we have tested the efficiency of this simulator
in two places with different geographical features: Corte, a mountainous region
and Bastia, a coastal region. On daily horizon, the relocation has implied
fewer errors than a naive prediction method based on the persistence (RMSE=1468
Vs 1383Wh/m2 to Bastia and 1325 Vs 1213Wh/m2 to Corte). On hourly case, the
results were still satisfactory, and widely better than persistence (RMSE=138.8
Vs 109.3 Wh/m2 to Bastia and 135.1 Vs 114.7 Wh/m2 to Corte). The last
experiment was to evaluate the accuracy of our simulator on a PV power grid
localized at 10 km from the station of Ajaccio. We got errors very suitable
(nRMSE=27.9%, RMSE=99.0 W.h) compared to those obtained with the persistence
(nRMSE=42.2%, RMSE=149.7 W.h).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3582</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3582</id><created>2009-05-21</created><updated>2010-06-14</updated><authors><author><keyname>Maeno</keyname><forenames>Yoshiharu</forenames></author></authors><title>Profiling of a network behind an infectious disease outbreak</title><categories>cs.AI q-bio.PE</categories><journal-ref>Physica A vol.389, pp.4755-4768 (2010)</journal-ref><doi>10.1016/j.physa.2010.07.014</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stochasticity and spatial heterogeneity are of great interest recently in
studying the spread of an infectious disease. The presented method solves an
inverse problem to discover the effectively decisive topology of a
heterogeneous network and reveal the transmission parameters which govern the
stochastic spreads over the network from a dataset on an infectious disease
outbreak in the early growth phase. Populations in a combination of
epidemiological compartment models and a meta-population network model are
described by stochastic differential equations. Probability density functions
are derived from the equations and used for the maximal likelihood estimation
of the topology and parameters. The method is tested with computationally
synthesized datasets and the WHO dataset on SARS outbreak.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3584</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3584</id><created>2009-05-21</created><authors><author><keyname>Devroye</keyname><forenames>Luc</forenames></author><author><keyname>Gudmundsson</keyname><forenames>Joachim</forenames></author><author><keyname>Morin</keyname><forenames>Pat</forenames></author></authors><title>On the Expected Maximum Degree of Gabriel and Yao Graphs</title><categories>cs.CG cs.DC</categories><comments>20 pages, 10 figures</comments><acm-class>I.3.5; E.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications of Gabriel graphs and Yao graphs in wireless ad-hoc
networks, we show that the maximal degree of a random Gabriel graph or Yao
graph defined on $n$ points drawn uniformly at random from a unit square grows
as $\Theta (\log n / \log \log n)$ in probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3587</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3587</id><created>2009-05-21</created><authors><author><keyname>Ellison</keyname><forenames>Christopher J.</forenames></author><author><keyname>Mahoney</keyname><forenames>John R.</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author></authors><title>Prediction, Retrodiction, and The Amount of Information Stored in the
  Present</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.IT math.IT physics.data-an</categories><comments>17 pages, 7 figures, 1 table;
  http://users.cse.ucdavis.edu/~cmg/compmech/pubs/pratisp.htm</comments><doi>10.1007/s10955-009-9808-z</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an ambidextrous view of stochastic dynamical systems, comparing
their forward-time and reverse-time representations and then integrating them
into a single time-symmetric representation. The perspective is useful
theoretically, computationally, and conceptually. Mathematically, we prove that
the excess entropy--a familiar measure of organization in complex systems--is
the mutual information not only between the past and future, but also between
the predictive and retrodictive causal states. Practically, we exploit the
connection between prediction and retrodiction to directly calculate the excess
entropy. Conceptually, these lead one to discover new system invariants for
stochastic dynamical systems: crypticity (information accessibility) and causal
irreversibility. Ultimately, we introduce a time-symmetric representation that
unifies all these quantities, compressing the two directional representations
into one. The resulting compression offers a new conception of the amount of
information stored in the present.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3602</identifier>
 <datestamp>2013-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3602</id><created>2009-05-22</created><authors><author><keyname>Hanif</keyname><forenames>Muhammad Fainan</forenames></author><author><keyname>Smith</keyname><forenames>Peter J.</forenames></author></authors><title>Level Crossing Rates of Interference in Cognitive Radio Networks</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE Transactions on Wireless Communications</comments><journal-ref>IEEE Transactions on Wireless Communications, vol.9, no.4,
  pp.1283-1287, 2010</journal-ref><doi>10.1109/TWC.2010.04.090749</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The future deployment of cognitive radios is critically dependent on the fact
that the incumbent primary user system must remain as oblivious as possible to
their presence. This in turn heavily relies on the fluctuations of the
interfering cognitive radio signals. In this letter we compute the level
crossing rates of the cumulative interference created by the cognitive radios.
We derive analytical formulae for the level crossing rates in Rayleigh and
Rician fast fading conditions. We approximate Rayleigh and Rician level
crossing rates using fluctuation rates of gamma and scaled noncentral $\chi^2$
processes respectively. The analytical results and the approximations used in
their derivations are verified by Monte Carlo simulations and the analysis is
applied to a particular CR allocation strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3640</identifier>
 <datestamp>2010-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3640</id><created>2009-05-22</created><authors><author><keyname>Protopapas</keyname><forenames>Mattheos K.</forenames></author><author><keyname>Kosmatopoulos</keyname><forenames>Elias B.</forenames></author><author><keyname>Battaglia</keyname><forenames>Francesco</forenames></author></authors><title>Coevolutionary Genetic Algorithms for Establishing Nash Equilibrium in
  Symmetric Cournot Games</title><categories>cs.GT cs.LG</categories><comments>18 pages, 4 figures</comments><journal-ref>Advances in Decision Sciences, vol. 2010, Article ID 573107</journal-ref><doi>10.1155/2010/573107</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We use co-evolutionary genetic algorithms to model the players' learning
process in several Cournot models, and evaluate them in terms of their
convergence to the Nash Equilibrium. The &quot;social-learning&quot; versions of the two
co-evolutionary algorithms we introduce, establish Nash Equilibrium in those
models, in contrast to the &quot;individual learning&quot; versions which, as we see
here, do not imply the convergence of the players' strategies to the Nash
outcome. When players use &quot;canonical co-evolutionary genetic algorithms&quot; as
learning algorithms, the process of the game is an ergodic Markov Chain, and
therefore we analyze simulation results using both the relevant methodology and
more general statistical tests, to find that in the &quot;social&quot; case, states
leading to NE play are highly frequent at the stationary distribution of the
chain, in contrast to the &quot;individual learning&quot; case, when NE is not reached at
all in our simulations; to find that the expected Hamming distance of the
states at the limiting distribution from the &quot;NE state&quot; is significantly
smaller in the &quot;social&quot; than in the &quot;individual learning case&quot;; to estimate the
expected time that the &quot;social&quot; algorithms need to get to the &quot;NE state&quot; and
verify their robustness and finally to show that a large fraction of the games
played are indeed at the Nash Equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3668</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3668</id><created>2009-05-22</created><updated>2009-08-04</updated><authors><author><keyname>van Benthem</keyname><forenames>Johan</forenames></author><author><keyname>Cate</keyname><forenames>Balder ten</forenames></author><author><keyname>Vaananen</keyname><forenames>Jouko</forenames></author></authors><title>Lindstrom theorems for fragments of first-order logic</title><categories>cs.LO</categories><comments>Appears in Logical Methods in Computer Science (LMCS)</comments><acm-class>F.4.1; F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (August 3,
  2009) lmcs:895</journal-ref><doi>10.2168/LMCS-5(3:3)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lindstr\&quot;om theorems characterize logics in terms of model-theoretic
conditions such as Compactness and the L\&quot;owenheim-Skolem property. Most
existing characterizations of this kind concern extensions of first-order
logic. But on the other hand, many logics relevant to computer science are
fragments or extensions of fragments of first-order logic, e.g., k-variable
logics and various modal logics. Finding Lindstr\&quot;om theorems for these
languages can be challenging, as most known techniques rely on coding arguments
that seem to require the full expressive power of first-order logic. In this
paper, we provide Lindstr\&quot;om theorems for several fragments of first-order
logic, including the k-variable fragments for k&gt;2, Tarski's relation algebra,
graded modal logic, and the binary guarded fragment. We use two different proof
techniques. One is a modification of the original Lindstr\&quot;om proof. The other
involves the modal concepts of bisimulation, tree unraveling, and finite depth.
Our results also imply semantic preservation theorems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3678</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3678</id><created>2009-05-22</created><updated>2009-09-01</updated><authors><author><keyname>Madgazin</keyname><forenames>Vadim R.</forenames></author></authors><title>Major and minor. The formula of musical emotions</title><categories>cs.SD q-bio.NC</categories><comments>22 pages, 3 figures, in Russian, added figures, changed content</comments><acm-class>H.5.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The new formulas, which determine sign and amplitude of utilitarian emotions,
are proposed on the basis of the information theory of emotions. In area of
perception of musical chords the force of emotions depends on the relative
pitch of sounds of major and minor chords.
  Is advanced hypothesis that in the perception of a musical chord in the
psyche caused by the subject value of some objective function L. This function
is expressed directly through the proportion of the pitch of chord. Major
chords are expressed as the straight proportions, which generate idea about an
increase in the objective function (L&gt;1) and are caused positive utilitarian
emotions. Minor chords are expressed as the inverse proportion, which generate
idea about the decrease of objective function (L&lt;1) and are caused negative
utilitarian emotions.
  The formula of musical emotions is advanced: Pwe = log(L) =
(1/M)*log(n1*n2*n3* ... *nM), where M is a quantity of voices of chord, ni -
integer number (or reciprocal fraction) from the pitch proportion, which
corresponds to the i-th voice of chord.
  Confined experimental check is produced. The limits of the applicability of
the formula of musical emotions are investigated.
  Keywords: sound, music, chord, major, minor, emotions, the formula of musical
emotions, the information theory of emotions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3689</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3689</id><created>2009-05-22</created><authors><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Jindal</keyname><forenames>Nihar</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author></authors><title>Optimized Training and Feedback for MIMO Downlink Channels</title><categories>cs.IT math.IT</categories><comments>To appear at IEEE Information Theory Workshop, Volos, Greece, June
  2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a MIMO fading broadcast channel where channel state information
is acquired at user terminals via downlink training and channel feedback is
used to provide transmitter channel state information (CSIT) to the base
station. The feedback channel (the corresponding uplink) is modeled as an AWGN
channel, orthogonal across users. The total bandwidth consumed is the sum of
the bandwidth/resources used for downlink training, channel feedback, and data
transmission. Assuming that the channel follows a block fading model and that
zeroforcing beamforming is used, we optimize the net achievable rate for
unquantized (analog) and quantized (digital) channel feedback. The optimal
number of downlink training pilots is seen to be essentially the same for both
feedback techniques, but digital feedback is shown to provide a larger net rate
than analog feedback.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3709</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3709</id><created>2009-05-22</created><authors><author><keyname>Tagiew</keyname><forenames>Rustam</forenames></author></authors><title>Towards Barter Double Auction as Model for Bilateral Social Cooperations</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The idea of this paper is an advanced game concept. This concept is expected
to model non-monetary bilateral cooperations between self-interested agents.
Such non-monetary cases are social cooperations like allocation of high level
jobs or sexual relationships among humans. In a barter double auction, there is
a big amount of agents. Every agent has a vector of parameters which specifies
his demand and a vector which specifies his offer. Two agents can achieve a
commitment through barter exchange. The subjective satisfaction level (a number
between 0% and 100%) of an agent is as high as small is the distance between
his demand and the accepted offer. This paper introduces some facets of this
complex game concept.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3713</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3713</id><created>2009-05-22</created><updated>2009-05-27</updated><authors><author><keyname>Xiang</keyname><forenames>Limin</forenames></author></authors><title>A formal proof of the four color theorem</title><categories>cs.DM</categories><comments>9 pages, 2 Figures</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A formal proof has not been found for the four color theorem since 1852 when
Francis Guthrie first conjectured the four color theorem. Why? A bad idea, we
think, directed people to a rough road. Using a similar method to that for the
formal proof of the five color theorem, a formal proof is proposed in this
paper of the four color theorem, namely, every planar graph is four-colorable.
The formal proof proposed can also be regarded as an algorithm to color a
planar graph using four colors so that no two adjacent vertices receive the
same color.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3715</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3715</id><created>2009-05-22</created><updated>2009-08-11</updated><authors><author><keyname>VanderZee</keyname><forenames>Evan</forenames></author><author><keyname>Hirani</keyname><forenames>Anil N.</forenames></author><author><keyname>Zharnitsky</keyname><forenames>Vadim</forenames></author><author><keyname>Guoy</keyname><forenames>Damrong</forenames></author></authors><title>A Dihedral Acute Triangulation of the Cube</title><categories>cs.CG math.MG</categories><comments>Minor edits for journal version. Added some material to the
  introduction</comments><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that there exists a dihedral acute triangulation of the
three-dimensional cube. The method of constructing the acute triangulation is
described, and symmetries of the triangulation are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3720</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3720</id><created>2009-05-22</created><authors><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Where are the really hard manipulation problems? The phase transition in
  manipulating the veto rule</title><categories>cs.AI cs.CC</categories><comments>Proceedings of the Twenty-first International Joint Conference on
  Artificial Intelligence (IJCAI-09)</comments><acm-class>I.2.4</acm-class><journal-ref>IJCAI-2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voting is a simple mechanism to aggregate the preferences of agents. Many
voting rules have been shown to be NP-hard to manipulate. However, a number of
recent theoretical results suggest that this complexity may only be in the
worst-case since manipulation is often easy in practice. In this paper, we show
that empirical studies are useful in improving our understanding of this issue.
We demonstrate that there is a smooth transition in the probability that a
coalition can elect a desired candidate using the veto rule as the size of the
manipulating coalition increases. We show that a rescaled probability curve
displays a simple and universal form independent of the size of the problem. We
argue that manipulation of the veto rule is asymptotically easy for many
independent and identically distributed votes even when the coalition of
manipulators is critical in size. Based on this argument, we identify a
situation in which manipulation is computationally hard. This is when votes are
highly correlated and the election is &quot;hung&quot;. We show, however, that even a
single uncorrelated voter is enough to make manipulation easy again.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3733</identifier>
 <datestamp>2009-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3733</id><created>2009-05-22</created><authors><author><keyname>Koller</keyname><forenames>Christian</forenames></author><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author><author><keyname>Kliewer</keyname><forenames>Joerg</forenames></author><author><keyname>Costello</keyname><forenames>Daniel J.</forenames><suffix>Jr</suffix></author></authors><title>Trapping Set Enumerators for Repeat Multiple Accumulate Code Ensembles</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in proc. IEEE ISIT, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The serial concatenation of a repetition code with two or more accumulators
has the advantage of a simple encoder structure. Furthermore, the resulting
ensemble is asymptotically good and exhibits minimum distance growing linearly
with block length. However, in practice these codes cannot be decoded by a
maximum likelihood decoder, and iterative decoding schemes must be employed.
For low-density parity-check codes, the notion of trapping sets has been
introduced to estimate the performance of these codes under iterative message
passing decoding. In this paper, we present a closed form finite length
ensemble trapping set enumerator for repeat multiple accumulate codes by
creating a trellis representation of trapping sets. We also obtain the
asymptotic expressions when the block length tends to infinity and evaluate
them numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3755</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3755</id><created>2009-05-22</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Quimper</keyname><forenames>Claude-Guy</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Decompositions of All Different, Global Cardinality and Related
  Constraints</title><categories>cs.AI</categories><comments>Proceedings of the Twenty-first International Joint Conference on
  Artificial Intelligence (IJCAI-09)</comments><acm-class>I.2.4</acm-class><journal-ref>IJCAI-2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that some common and important global constraints like ALL-DIFFERENT
and GCC can be decomposed into simple arithmetic constraints on which we
achieve bound or range consistency, and in some cases even greater pruning.
These decompositions can be easily added to new solvers. They also provide
other constraints with access to the state of the propagator by sharing of
variables. Such sharing can be used to improve propagation between constraints.
We report experiments with our decomposition in a pseudo-Boolean solver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3757</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3757</id><created>2009-05-22</created><authors><author><keyname>Bessiere</keyname><forenames>Christian</forenames></author><author><keyname>Katsirelos</keyname><forenames>George</forenames></author><author><keyname>Narodytska</keyname><forenames>Nina</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Circuit Complexity and Decompositions of Global Constraints</title><categories>cs.AI cs.CC</categories><comments>Proceedings of the Twenty-first International Joint Conference on
  Artificial Intelligence (IJCAI-09). Old file included deleted</comments><acm-class>I.2.4</acm-class><journal-ref>IJCAI-2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that tools from circuit complexity can be used to study
decompositions of global constraints. In particular, we study decompositions of
global constraints into conjunctive normal form with the property that unit
propagation on the decomposition enforces the same level of consistency as a
specialized propagation algorithm. We prove that a constraint propagator has a
a polynomial size decomposition if and only if it can be computed by a
polynomial size monotone Boolean circuit. Lower bounds on the size of monotone
Boolean circuits thus translate to lower bounds on the size of decompositions
of global constraints. For instance, we prove that there is no polynomial sized
decomposition of the domain consistency propagator for the ALLDIFFERENT
constraint.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3763</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3763</id><created>2009-05-22</created><authors><author><keyname>Manandhar</keyname><forenames>Suresh</forenames></author><author><keyname>Tarim</keyname><forenames>Armagan</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Scenario-based Stochastic Constraint Programming</title><categories>cs.AI</categories><comments>Proceedings of the Eighteenth International Joint Conference on
  Artificial Intelligence (IJCAI-03)</comments><acm-class>I.2.4</acm-class><journal-ref>IJCAI 2003: 257-262</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To model combinatorial decision problems involving uncertainty and
probability, we extend the stochastic constraint programming framework proposed
in [Walsh, 2002] along a number of important dimensions (e.g. to multiple
chance constraints and to a range of new objectives). We also provide a new
(but equivalent) semantics based on scenarios. Using this semantics, we can
compile stochastic constraint programs down into conventional (nonstochastic)
constraint programs. This allows us to exploit the full power of existing
constraint solvers. We have implemented this framework for decision making
under uncertainty in stochastic OPL, a language which is based on the OPL
constraint modelling language [Hentenryck et al., 1999]. To illustrate the
potential of this framework, we model a wide range of problems in areas as
diverse as finance, agriculture and production.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3766</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3766</id><created>2009-05-22</created><authors><author><keyname>Domshlak</keyname><forenames>Carmel</forenames></author><author><keyname>Rossi</keyname><forenames>Francesca</forenames></author><author><keyname>Venable</keyname><forenames>Kristen Brent</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Reasoning about soft constraints and conditional preferences: complexity
  results and approximation techniques</title><categories>cs.AI</categories><comments>Proceedings of the Eighteenth International Joint Conference on
  Artificial Intelligence (IJCAI-03)</comments><acm-class>I.2.4</acm-class><journal-ref>IJCAI 2003: 215-220</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real life optimization problems contain both hard and soft constraints,
as well as qualitative conditional preferences. However, there is no single
formalism to specify all three kinds of information. We therefore propose a
framework, based on both CP-nets and soft constraints, that handles both hard
and soft constraints as well as conditional preferences efficiently and
uniformly. We study the complexity of testing the consistency of preference
statements, and show how soft constraints can faithfully approximate the
semantics of conditional preference statements whilst improving the
computational complexity
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3769</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3769</id><created>2009-05-22</created><authors><author><keyname>Frisch</keyname><forenames>Alan M.</forenames></author><author><keyname>Miguel</keyname><forenames>Ian</forenames></author><author><keyname>Kiziltan</keyname><forenames>Zeynep</forenames></author><author><keyname>Hnich</keyname><forenames>Brahim</forenames></author><author><keyname>Walsh</keyname><forenames>Toby</forenames></author></authors><title>Multiset Ordering Constraints</title><categories>cs.AI</categories><comments>Proceedings of the Eighteenth International Joint Conference on
  Artificial Intelligence (IJCAI-03)</comments><acm-class>I.2.4</acm-class><journal-ref>IJCAI 2003: 221-226</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We identify a new and important global (or non-binary) constraint. This
constraint ensures that the values taken by two vectors of variables, when
viewed as multisets, are ordered. This constraint is useful for a number of
different applications including breaking symmetry and fuzzy constraint
satisfaction. We propose and implement an efficient linear time algorithm for
enforcing generalised arc consistency on such a multiset ordering constraint.
Experimental results on several problem domains show considerable promise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3771</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3771</id><created>2009-05-22</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Memory Retrieved from Single Neurons</title><categories>cs.NE q-bio.NC</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper examines the problem of accessing a vector memory from a single
neuron in a Hebbian neural network. It begins with the review of the author's
earlier method, which is different from the Hopfield model in that it recruits
neighboring neurons by spreading activity, making it possible for single or
group of neurons to become associated with vector memories. Some open issues
associated with this approach are identified. It is suggested that fragments
that generate stored memories could be associated with single neurons through
local spreading activity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3802</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3802</id><created>2009-05-25</created><authors><author><keyname>Fassetti</keyname><forenames>Fabio</forenames></author><author><keyname>Palopoli</keyname><forenames>Luigi</forenames></author></authors><title>On the complexity of identifying Head Elementary Set Free programs</title><categories>cs.LO cs.CC</categories><comments>11 pages. To appear in Theory and Practice of Logic Programming
  (TPLP)</comments><acm-class>F.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Head-elementary-set-free programs were proposed in (Gebser et al. 2007) and
shown to generalize over head-cycle-free programs while retaining their nice
properties. It was left as an open problem in (Gebser et al. 2007) to establish
the complexity of identifying head-elementary-set-free programs. This note
solves the open problem, by showing that the problem is complete for co-NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3812</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3812</id><created>2009-05-23</created><authors><author><keyname>Ghosh</keyname><forenames>Subhas Kumar</forenames></author><author><keyname>Sinha</keyname><forenames>Koushik</forenames></author></authors><title>Some Results On Convex Greedy Embedding Conjecture for 3-Connected
  Planar Graphs</title><categories>cs.DS cs.CG cs.DM cs.NI</categories><comments>19 pages, A short version of this paper has been accepted for
  presentation in FCT 2009 - 17th International Symposium on Fundamentals of
  Computation Theory</comments><doi>10.1007/978-3-642-03409-1_14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A greedy embedding of a graph $G = (V,E)$ into a metric space $(X,d)$ is a
function $x : V(G) \to X$ such that in the embedding for every pair of
non-adjacent vertices $x(s), x(t)$ there exists another vertex $x(u)$ adjacent
to $x(s)$ which is closer to $x(t)$ than $x(s)$. This notion of greedy
embedding was defined by Papadimitriou and Ratajczak (Theor. Comput. Sci.
2005), where authors conjectured that every 3-connected planar graph has a
greedy embedding (possibly planar and convex) in the Euclidean plane. Recently,
greedy embedding conjecture has been proved by Leighton and Moitra (FOCS 2008).
However, their algorithm do not result in a drawing that is planar and convex
for all 3-connected planar graph in the Euclidean plane. In this work we
consider the planar convex greedy embedding conjecture and make some progress.
We derive a new characterization of planar convex greedy embedding that given a
3-connected planar graph $G = (V,E)$, an embedding $x: V \to \bbbr^2$ of $G$ is
a planar convex greedy embedding if and only if, in the embedding $x$, weight
of the maximum weight spanning tree ($T$) and weight of the minimum weight
spanning tree ($\func{MST}$) satisfies $\WT(T)/\WT(\func{MST}) \leq
(\card{V}-1)^{1 - \delta}$, for some $0 &lt; \delta \leq 1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3830</identifier>
 <datestamp>2011-06-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3830</id><created>2009-05-23</created><authors><author><keyname>Murtagh</keyname><forenames>F.</forenames></author><author><keyname>Ganz</keyname><forenames>A.</forenames></author><author><keyname>McKie</keyname><forenames>S.</forenames></author><author><keyname>Mothe</keyname><forenames>J.</forenames></author><author><keyname>Englmeier</keyname><forenames>K.</forenames></author></authors><title>Tag Clouds for Displaying Semantics: The Case of Filmscripts</title><categories>cs.AI</categories><comments>23 pages, 7 figures</comments><acm-class>I.5.4; I.2.7; H.3.1</acm-class><journal-ref>Information Visualization 9, 253-262, 2010</journal-ref><doi>10.1057/ivs.2009.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We relate tag clouds to other forms of visualization, including planar or
reduced dimensionality mapping, and Kohonen self-organizing maps. Using a
modified tag cloud visualization, we incorporate other information into it,
including text sequence and most pertinent words. Our notion of word pertinence
goes beyond just word frequency and instead takes a word in a mathematical
sense as located at the average of all of its pairwise relationships. We
capture semantics through context, taken as all pairwise relationships. Our
domain of application is that of filmscript analysis. The analysis of
filmscripts, always important for cinema, is experiencing a major gain in
importance in the context of television. Our objective in this work is to
visualize the semantics of filmscript, and beyond filmscript any other
partially structured, time-ordered, sequence of text segments. In particular we
develop an innovative approach to plot characterization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3858</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3858</id><created>2009-05-23</created><authors><author><keyname>Jain</keyname><forenames>Aman</forenames></author><author><keyname>Kulkarni</keyname><forenames>Sanjeev R.</forenames></author><author><keyname>Verdu</keyname><forenames>Sergio</forenames></author></authors><title>Multicasting in Large Wireless Networks: Bounds on the Minimum Energy
  per Bit</title><categories>cs.IT math.IT</categories><comments>40 pages, 4 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider scaling laws for maximal energy efficiency of communicating a
message to all the nodes in a wireless network, as the number of nodes in the
network becomes large. Two cases of large wireless networks are studied --
dense random networks and constant density (extended) random networks. In
addition, we also study finite size regular networks in order to understand how
regularity in node placement affects energy consumption.
  We first establish an information-theoretic lower bound on the minimum energy
per bit for multicasting in arbitrary wireless networks when the channel state
information is not available at the transmitters. Upper bounds are obtained by
constructing a simple flooding scheme that requires no information at the
receivers about the channel states or the locations and identities of the
nodes. The gap between the upper and lower bounds is only a constant factor for
dense random networks and regular networks, and differs by a poly-logarithmic
factor for extended random networks. Furthermore, we show that the proposed
upper and lower bounds for random networks hold almost surely in the node
locations as the number of nodes approaches infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3885</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3885</id><created>2009-05-24</created><authors><author><keyname>Elkind</keyname><forenames>E.</forenames></author><author><keyname>Faliszewski</keyname><forenames>P.</forenames></author><author><keyname>Slinko</keyname><forenames>A.</forenames></author></authors><title>Swap Bribery</title><categories>cs.GT cs.AI</categories><comments>17 pages</comments><doi>10.1007/978-3-642-04645-2_27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In voting theory, bribery is a form of manipulative behavior in which an
external actor (the briber) offers to pay the voters to change their votes in
order to get her preferred candidate elected. We investigate a model of bribery
where the price of each vote depends on the amount of change that the voter is
asked to implement. Specifically, in our model the briber can change a voter's
preference list by paying for a sequence of swaps of consecutive candidates.
Each swap may have a different price; the price of a bribery is the sum of the
prices of all swaps that it involves. We prove complexity results for this
model, which we call swap bribery, for a broad class of election systems,
including variants of approval and k-approval, Borda, Copeland, and maximin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3927</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3927</id><created>2009-05-24</created><updated>2012-12-22</updated><authors><author><keyname>Standish</keyname><forenames>Russell K.</forenames></author></authors><title>SuperNOVA: a novel algorithm for graph automorphism calculations</title><categories>cs.DS cs.DM</categories><comments>This paper was rejected for publication, primarily because it
  implements known techniques. I have updated the manuscript with experimental
  data comparing the algorithm with other well known automorphism
  implementations</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The graph isomorphism problem is of practical importance, as well as being a
theoretical curiosity in computational complexity theory in that it is not
known whether it is $NP$-complete or $P$. However, for many graphs, the problem
is tractable, and related to the problem of finding the automorphism group of
the graph. Perhaps the most well known state-of-the art implementation for
finding the automorphism group is Nauty. However, Nauty is particularly
susceptible to poor performance on star configurations, where the spokes of the
star are isomorphic with each other. In this work, I present an algorithm that
explodes these star configurations, reducing the problem to a sequence of
simpler automorphism group calculations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3934</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3934</id><created>2009-05-24</created><updated>2011-04-21</updated><authors><author><keyname>Koyluoglu</keyname><forenames>O. Ozan</forenames></author><author><keyname>Gamal</keyname><forenames>Hesham El</forenames></author></authors><title>Cooperative encoding for secrecy in interference channels</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory (submitted May
  2009 and revised September 2010)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the fundamental performance limits of the two-user
interference channel in the presence of an external eavesdropper. In this
setting, we construct an inner bound, to the secrecy capacity region, based on
the idea of cooperative encoding in which the two users cooperatively design
their randomized codebooks and jointly optimize their channel prefixing
distributions. Our achievability scheme also utilizes message-splitting in
order to allow for partial decoding of the interference at the non-intended
receiver. Outer bounds are then derived and used to establish the optimality of
the proposed scheme in certain cases. In the Gaussian case, the previously
proposed cooperative jamming and noise-forwarding techniques are shown to be
special cases of our proposed approach. Overall, our results provide structural
insights on how the interference can be exploited to increase the secrecy
capacity of wireless networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3946</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3946</id><created>2009-05-25</created><authors><author><keyname>Cheng</keyname><forenames>Chih-Hong</forenames></author><author><keyname>Buckl</keyname><forenames>Christian</forenames></author><author><keyname>Esparza</keyname><forenames>Javier</forenames></author><author><keyname>Knoll</keyname><forenames>Alois</forenames></author></authors><title>FTOS-Verify: Analysis and Verification of Non-Functional Properties for
  Fault-Tolerant Systems</title><categories>cs.DC cs.LO</categories><comments>(bibliography update)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The focus of the tool FTOS is to alleviate designers' burden by offering code
generation for non-functional aspects including fault-tolerance mechanisms. One
crucial aspect in this context is to ensure that user-selected mechanisms for
the system model are sufficient to resist faults as specified in the underlying
fault hypothesis. In this paper, formal approaches in verification are proposed
to assist the claim. We first raise the precision of FTOS into pure
mathematical constructs, and formulate the deterministic assumption, which is
necessary as an extension of Giotto-like systems (e.g., FTOS) to equip with
fault-tolerance abilities. We show that local properties of a system with the
deterministic assumption will be preserved in a modified synchronous system
used as the verification model. This enables the use of techniques known from
hardware verification. As for implementation, we develop a prototype tool
called FTOS-Verify, deploy it as an Eclipse add-on for FTOS, and conduct
several case studies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3949</identifier>
 <datestamp>2011-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3949</id><created>2009-05-25</created><updated>2011-03-22</updated><authors><author><keyname>Herscovici</keyname><forenames>David S.</forenames></author><author><keyname>Hester</keyname><forenames>Benjamin D.</forenames></author><author><keyname>Hurlbert</keyname><forenames>Glenn H.</forenames></author></authors><title>t-Pebbling and Extensions</title><categories>math.CO cs.DM</categories><comments>29 pages</comments><msc-class>05C99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph pebbling is the study of moving discrete pebbles from certain initial
distributions on the vertices of a graph to various target distributions via
pebbling moves. A pebbling move removes two pebbles from a vertex and places
one pebble on one of its neighbors (losing the other as a toll). For t &gt;= 1 the
t-pebbling number of a graph is the minimum number of pebbles necessary so that
from any initial distribution of them it is possible to move t pebbles to any
vertex. We provide the best possible upper bound on the t-pebbling number of a
diameter two graph, proving a conjecture of Curtis, et al., in the process. We
also give a linear time (in the number of edges) algorithm to t-pebble such
graphs, as well as a quartic time (in the number of vertices) algorithm to
compute the pebbling number of such graphs, improving the best known result of
Bekmetjev and Cusack. Furthermore, we show that, for complete graphs, cycles,
trees, and cubes, we can allow the target to be any distribution of t pebbles
without increasing the corresponding t-pebbling numbers; we conjecture that
this behavior holds for all graphs. Finally, we explore fractional and optimal
fractional versions of pebbling, proving the fractional pebbling number
conjecture of Hurlbert and using linear optimization to reveal results on the
optimal fractional pebbling number of vertex-transitive graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3951</identifier>
 <datestamp>2009-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3951</id><created>2009-05-25</created><updated>2009-10-21</updated><authors><author><keyname>Cheng</keyname><forenames>Chih-Hong</forenames></author><author><keyname>Buckl</keyname><forenames>Christian</forenames></author><author><keyname>Esparza</keyname><forenames>Javier</forenames></author><author><keyname>Knoll</keyname><forenames>Alois</forenames></author></authors><title>Modeling and Verification for Timing Satisfaction of Fault-Tolerant
  Systems with Finiteness</title><categories>cs.DC cs.LO</categories><comments>1. Appear in the 13-th IEEE/ACM International Symposium on
  Distributed Simulation and Real Time Applications (DS-RT'09). 2. Compared to
  the DS-RT version, we add motivations for editing automata, and footnote that
  the sketch of editing algo is only applicable in our job-processing element
  to avoid ambiguity (because actions are chained)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing use of model-based tools enables further use of formal
verification techniques in the context of distributed real-time systems. To
avoid state explosion, it is necessary to construct verification models that
focus on the aspects under consideration.
  In this paper, we discuss how we construct a verification model for timing
analysis in distributed real-time systems. We (1) give observations concerning
restrictions of timed automata to model these systems, (2) formulate
mathematical representations on how to perform model-to-model transformation to
derive verification models from system models, and (3) propose some theoretical
criteria how to reduce the model size. The latter is in particular important,
as for the verification of complex systems, an efficient model reflecting the
properties of the system under consideration is equally important to the
verification algorithm itself. Finally, we present an extension of the
model-based development tool FTOS, designed to develop fault-tolerant systems,
to demonstrate %the benefits of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3964</identifier>
 <datestamp>2010-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3964</id><created>2009-05-25</created><authors><author><keyname>Kalantari</keyname><forenames>Mahzad</forenames></author><author><keyname>Hashemi</keyname><forenames>Amir</forenames></author><author><keyname>Jung</keyname><forenames>Franck</forenames></author><author><keyname>Guedon</keyname><forenames>JeanPierre</forenames></author></authors><title>A New Solution to the Relative Orientation Problem using only 3 Points
  and the Vertical Direction</title><categories>cs.CV</categories><report-no>0924-9907</report-no><doi>10.1007/s10851-010-0234-2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method to recover the relative pose between two
images, using three points and the vertical direction information. The vertical
direction can be determined in two ways: 1- using direct physical measurement
like IMU (inertial measurement unit), 2- using vertical vanishing point. This
knowledge of the vertical direction solves 2 unknowns among the 3 parameters of
the relative rotation, so that only 3 homologous points are requested to
position a couple of images. Rewriting the coplanarity equations leads to a
simpler solution. The remaining unknowns resolution is performed by an
algebraic method using Grobner bases. The elements necessary to build a
specific algebraic solver are given in this paper, allowing for a real-time
implementation. The results on real and synthetic data show the efficiency of
this method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3967</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3967</id><created>2009-05-25</created><authors><author><keyname>Bouzid</keyname><forenames>Zohir</forenames><affiliation>LIP6</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6, INRIA Futurs</affiliation></author></authors><title>Optimal byzantine resilient convergence in oblivious robot networks</title><categories>cs.DC cs.RO</categories><proxy>ccsd inria-00387525</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of robots with arbitrary initial location and no agreement on a
global coordinate system, convergence requires that all robots asymptotically
approach the exact same, but unknown beforehand, location. Robots are
oblivious-- they do not recall the past computations -- and are allowed to move
in a one-dimensional space. Additionally, robots cannot communicate directly,
instead they obtain system related information only via visual sensors. We draw
a connection between the convergence problem in robot networks, and the
distributed \emph{approximate agreement} problem (that requires correct
processes to decide, for some constant $\epsilon$, values distance $\epsilon$
apart and within the range of initial proposed values). Surprisingly, even
though specifications are similar, the convergence implementation in robot
networks requires specific assumptions about synchrony and Byzantine
resilience. In more details, we prove necessary and sufficient conditions for
the convergence of mobile robots despite a subset of them being Byzantine (i.e.
they can exhibit arbitrary behavior). Additionally, we propose a deterministic
convergence algorithm for robot networks and analyze its correctness and
complexity in various synchrony settings. The proposed algorithm tolerates f
Byzantine robots for (2f+1)-sized robot networks in fully synchronous networks,
(3f+1)-sized in semi-synchronous networks. These bounds are optimal for the
class of cautious algorithms, which guarantee that correct robots always move
inside the range of positions of the correct robots.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3993</identifier>
 <datestamp>2010-11-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3993</id><created>2009-05-25</created><updated>2010-11-11</updated><authors><author><keyname>Mantzaflaris</keyname><forenames>Angelos</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Mourrain</keyname><forenames>Bernard</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Tsigaridas</keyname><forenames>Elias P. P.</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author></authors><title>Continued Fraction Expansion of Real Roots of Polynomial Systems</title><categories>cs.SC</categories><comments>10 pages</comments><proxy>ccsd</proxy><journal-ref>SNC, conference on Symbolic-Numeric Computation, Kyoto : Japan
  (2009)</journal-ref><doi>10.1145/1577190.1577207</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new algorithm for isolating the real roots of a system of
multivariate polynomials, given in the monomial basis. It is inspired by
existing subdivision methods in the Bernstein basis; it can be seen as
generalization of the univariate continued fraction algorithm or alternatively
as a fully analog of Bernstein subdivision in the monomial basis. The
representation of the subdivided domains is done through homographies, which
allows us to use only integer arithmetic and to treat efficiently unbounded
regions. We use univariate bounding functions, projection and preconditionning
techniques to reduce the domain of search. The resulting boxes have optimized
rational coordinates, corresponding to the first terms of the continued
fraction expansion of the real roots. An extension of Vincent's theorem to
multivariate polynomials is proved and used for the termination of the
algorithm. New complexity bounds are provided for a simplified version of the
algorithm. Examples computed with a preliminary C++ implementation illustrate
the approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.3998</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.3998</id><created>2009-05-25</created><authors><author><keyname>Hyvernat</keyname><forenames>Pierre</forenames><affiliation>IML</affiliation></author></authors><title>Predicate Transformers and Linear Logic, yet another denotational model</title><categories>cs.LO math.LO</categories><proxy>ccsd hal-00387490</proxy><journal-ref>Computer Science and Logic 2004, Karpacz : Pologne (2004)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the refinement calculus, monotonic predicate transformers are used to
model specifications for (imperative) programs. Together with a natural notion
of simulation, they form a category enjoying many algebraic properties. We
build on this structure to make predicate transformers into a de notational
model of full linear logic: all the logical constructions have a natural
interpretation in terms of predicate transformers (i.e. in terms of
specifications). We then interpret proofs of a formula by a safety property for
the corresponding specification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4021</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4021</id><created>2009-05-25</created><authors><author><keyname>Kelif</keyname><forenames>Jean-Marc</forenames></author></authors><title>A Physical Model of Wireless Network</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using an approach developed in physics, we propose a new framework for the
study of cellular networks. The key idea of the physical network model we
propose is to replace the discrete base stations (BS) entities by a continuum
of transmitters which are spatially distributed in the network. This allows us
to establish a closed form formula of the other-cell downlink interference
factor f, as a function of the location of the mobile. We define here f as the
ratio of outer cell received power (i.e. the power received from other cells)
to the inner cell received power. This physical model allows calculating the
influence of interference on any mobile in a cell, whatever its position.
Results obtained with that closed-form formula are close to the ones obtained
by simulations using a traditional hexagonal network model. Since the physical
model allows to establish a closed form formula of the interference factor, it
allows to do analytical studies of wireless networks such as outage
probability, quality of service, capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4022</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4022</id><created>2009-05-25</created><authors><author><keyname>Dhillon</keyname><forenames>Paramveer S.</forenames></author><author><keyname>Foster</keyname><forenames>Dean</forenames></author><author><keyname>Ungar</keyname><forenames>Lyle</forenames></author></authors><title>Transfer Learning Using Feature Selection</title><categories>cs.LG</categories><comments>Masters' Thesis</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present three related ways of using Transfer Learning to improve feature
selection. The three methods address different problems, and hence share
different kinds of information between tasks or feature classes, but all three
are based on the information theoretic Minimum Description Length (MDL)
principle and share the same underlying Bayesian interpretation. The first
method, MIC, applies when predictive models are to be built simultaneously for
multiple tasks (``simultaneous transfer'') that share the same set of features.
MIC allows each feature to be added to none, some, or all of the task models
and is most beneficial for selecting a small set of predictive features from a
large pool of features, as is common in genomic and biological datasets. Our
second method, TPC (Three Part Coding), uses a similar methodology for the case
when the features can be divided into feature classes. Our third method,
Transfer-TPC, addresses the ``sequential transfer'' problem in which the task
to which we want to transfer knowledge may not be known in advance and may have
different amounts of data than the other tasks. Transfer-TPC is most beneficial
when we want to transfer knowledge between tasks which have unequal amounts of
labeled data, for example the data for disambiguating the senses of different
verbs. We demonstrate the effectiveness of these approaches with experimental
results on real world data pertaining to genomics and to Word Sense
Disambiguation (WSD).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4023</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4023</id><created>2009-05-25</created><authors><author><keyname>Jalden</keyname><forenames>Joakim</forenames></author><author><keyname>Elia</keyname><forenames>Petros</forenames></author></authors><title>DMT Optimality of LR-Aided Linear Decoders for a General Class of
  Channels, Lattice Designs, and System Models</title><categories>cs.IT math.IT</categories><comments>16 pages, 1 figure (3 subfigures), submitted to the IEEE Transactions
  on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work identifies the first general, explicit, and non-random MIMO
encoder-decoder structures that guarantee optimality with respect to the
diversity-multiplexing tradeoff (DMT), without employing a computationally
expensive maximum-likelihood (ML) receiver. Specifically, the work establishes
the DMT optimality of a class of regularized lattice decoders, and more
importantly the DMT optimality of their lattice-reduction (LR)-aided linear
counterparts. The results hold for all channel statistics, for all channel
dimensions, and most interestingly, irrespective of the particular lattice-code
applied. As a special case, it is established that the LLL-based LR-aided
linear implementation of the MMSE-GDFE lattice decoder facilitates DMT optimal
decoding of any lattice code at a worst-case complexity that grows at most
linearly in the data rate. This represents a fundamental reduction in the
decoding complexity when compared to ML decoding whose complexity is generally
exponential in rate.
  The results' generality lends them applicable to a plethora of pertinent
communication scenarios such as quasi-static MIMO, MIMO-OFDM, ISI,
cooperative-relaying, and MIMO-ARQ channels, in all of which the DMT optimality
of the LR-aided linear decoder is guaranteed. The adopted approach yields
insight, and motivates further study, into joint transceiver designs with an
improved SNR gap to ML decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4039</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4039</id><created>2009-05-25</created><authors><author><keyname>Cilibrasi</keyname><forenames>Rudi L.</forenames><affiliation>software consultant Oakland, CA</affiliation></author><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI, Amsterdam</affiliation></author></authors><title>Normalized Web Distance and Word Similarity</title><categories>cs.CL cs.IR</categories><comments>Latex, 20 pages, 7 figures, to appear in: Handbook of Natural
  Language Processing, Second Edition, Nitin Indurkhya and Fred J. Damerau
  Eds., CRC Press, Taylor and Francis Group, Boca Raton, FL, 2010, ISBN
  978-1420085921</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is a great deal of work in cognitive psychology, linguistics, and
computer science, about using word (or phrase) frequencies in context in text
corpora to develop measures for word similarity or word association, going back
to at least the 1960s. The goal of this chapter is to introduce the
normalizedis a general way to tap the amorphous low-grade knowledge available
for free on the Internet, typed in by local users aiming at personal
gratification of diverse objectives, and yet globally achieving what is
effectively the largest semantic electronic database in the world. Moreover,
this database is available for all by using any search engine that can return
aggregate page-count estimates for a large range of search-queries. In the
paper introducing the NWD it was called `normalized Google distance (NGD),' but
since Google doesn't allow computer searches anymore, we opt for the more
neutral and descriptive NWD. web distance (NWD) method to determine similarity
between words and phrases. It
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4057</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4057</id><created>2009-05-25</created><authors><author><keyname>Saad</keyname><forenames>Walid</forenames></author><author><keyname>Han</keyname><forenames>Zhu</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Hj&#xf8;rungnes</keyname><forenames>Are</forenames></author><author><keyname>Basar</keyname><forenames>Tamer</forenames></author></authors><title>Coalitional Game Theory for Communication Networks: A Tutorial</title><categories>cs.IT cs.GT math.IT</categories><comments>IEEE Signal Processing Magazine, Special Issue on Game Theory, to
  appear, 2009. IEEE Signal Processing Magazine, Special Issue on Game Theory,
  to appear, 2009</comments><doi>10.1109/MSP.2009.000000</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Game theoretical techniques have recently become prevalent in many
engineering applications, notably in communications. With the emergence of
cooperation as a new communication paradigm, and the need for self-organizing,
decentralized, and autonomic networks, it has become imperative to seek
suitable game theoretical tools that allow to analyze and study the behavior
and interactions of the nodes in future communication networks. In this
context, this tutorial introduces the concepts of cooperative game theory,
namely coalitional games, and their potential applications in communication and
wireless networks. For this purpose, we classify coalitional games into three
categories: Canonical coalitional games, coalition formation games, and
coalitional graph games. This new classification represents an
application-oriented approach for understanding and analyzing coalitional
games. For each class of coalitional games, we present the fundamental
components, introduce the key properties, mathematical techniques, and solution
concepts, and describe the methodologies for applying these games in several
applications drawn from the state-of-the-art research in communications. In a
nutshell, this article constitutes a unified treatment of coalitional game
theory tailored to the demands of communications and network engineers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4059</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4059</id><created>2009-05-25</created><updated>2011-09-20</updated><authors><author><keyname>Hyvernat</keyname><forenames>Pierre</forenames><affiliation>Universit&#xe9; de Savoie</affiliation></author></authors><title>Coherent and finiteness spaces</title><categories>cs.LO math.LO</categories><comments>short note</comments><proxy>LMCS</proxy><acm-class>F.4.1, F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 3 (September
  22, 2011) lmcs:1131</journal-ref><doi>10.2168/LMCS-7(3:15)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note presents a new relation between coherent spaces and
finiteness spaces. This takes the form of a functor from COH to FIN commuting
with the additive and multiplicative structure of linear logic. What makes this
correspondence possible and conceptually interesting is the use of the infinite
Ramsey theorem. Along the way, the question of the cardinality of the
collection of finiteness spaces on N is answered. Basic knowledge about
coherent spaces and finiteness spaces is assumed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4060</identifier>
 <datestamp>2009-11-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4060</id><created>2009-05-25</created><updated>2009-11-03</updated><authors><author><keyname>Hyvernat</keyname><forenames>Pierre</forenames><affiliation>LAMA</affiliation></author></authors><title>A Completeness Theorem for &quot;Total Boolean Functions&quot;</title><categories>cs.LO math.LO</categories><comments>short note</comments><proxy>ccsd hal-00387612</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Christine Tasson introduced an algebraic notion of totality for a
denotational model of linear logic in the category of vector spaces. The notion
of total boolean function is, in a way, quite intuitive. This note provides a
positive answer to the question of completeness of the &quot;boolean centroidal
calculus&quot; w.r.t. total boolean functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4062</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4062</id><created>2009-05-25</created><authors><author><keyname>Hyvernat</keyname><forenames>Pierre</forenames><affiliation>LAMA</affiliation></author></authors><title>Interaction Systems and Linear Logic, a different games semantics</title><categories>cs.LO math.LO</categories><comments>39 pages</comments><proxy>ccsd hal-00387605</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define a model for linear logic based on two well-known ingredients: games
and simulations. This model is interesting in the following respect: while it
is obvious that the objects interpreting formulas are games and that everything
is developed with the intuition of interaction in mind, the notion of morphism
is very different from traditional morphisms in games semantics. In particular,
we make no use of the notion of strategy! The resulting structure is very
different from what is usually found in categories of games. We start by
defining several constructions on those games and show, using elementary
considerations, that they enjoy the appropriate algebraic properties making
this category a denotational model for intuitionistic linear logic. An
interesting point is that the tensor product corresponds to a strongly
synchronous operation on games. This category can also, using traditional
translations, serve as a model for the simply typed -calculus. We use some of
the additional structure of the category to extend this to a model of the
simply typed differential -calculus. Once this is done, we go a little further
by constructing a reflexive object in this category, thus getting a concrete
non-trivial model for the untyped differential -calculus. We then show, using a
highly non-constructive principle, that this category is in fact a model for
full classical linear logic ; and we finally have a brief look at the related
notions of predicate transformers and containers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4063</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4063</id><created>2009-05-25</created><authors><author><keyname>Hancock</keyname><forenames>Peter</forenames><affiliation>IML</affiliation></author><author><keyname>Hyvernat</keyname><forenames>Pierre</forenames><affiliation>IML</affiliation></author></authors><title>Programming interfaces and basic topology</title><categories>cs.LO math.LO</categories><proxy>ccsd hal-00387603</proxy><journal-ref>Annals of Pure and Applied Logic 137, 1--3 (2006) 189--239</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A pattern of interaction that arises again and again in programming is a
&quot;handshake&quot;, in which two agents exchange data. The exchange is thought of as
provision of a service. Each interaction is initiated by a specific agent--the
client or Angel--and concluded by the other--the server or Demon. We present a
category in which the objects--called interaction structures in the
paper--serve as descriptions of services provided across such handshaken
interfaces. The morphisms--called (general) simulations--model components that
provide one such service, relying on another. The morphisms are relations
between the underlying sets of the interaction structures. The proof that a
relation is a simulation can serve (in principle) as an executable program,
whose specification is that it provides the service described by its domain,
given an implementation of the service described by its codomain. This category
is then shown to coincide with the subcategory of &quot;generated&quot; basic topologies
in Sambin's terminology, where a basic topology is given by a closure operator
whose induced sup-lattice structure need not be distributive; and moreover,
this operator is inductively generated from a basic cover relation. This
coincidence provides topologists with a natural source of examples for
non-distributive formal topology. It raises a number of questions of interest
both for formal topology and programming. The extra structure needed to make
such a basic topology into a real formal topology is then interpreted in the
context of interaction structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4064</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4064</id><created>2009-05-25</created><authors><author><keyname>Hirschowitz</keyname><forenames>Andr&#xe9;</forenames><affiliation>JAD</affiliation></author><author><keyname>Hirschowitz</keyname><forenames>Michel</forenames><affiliation>LIX, LIST</affiliation></author><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>LAMA</affiliation></author></authors><title>Contraction-free proofs and finitary games for Linear Logic</title><categories>cs.LO math.LO</categories><comments>19 pages, uses tikz and Paul Taylor's diagrams</comments><proxy>ccsd hal-00387452</proxy><journal-ref>MFPS 2009, Oxford : Royaume-Uni (2009)</journal-ref><doi>10.1016/j.entcs.2009.07.095</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the standard sequent presentations of Girard's Linear Logic (LL), there
are two &quot;non-decreasing&quot; rules, where the premises are not smaller than the
conclusion, namely the cut and the contraction rules. It is a universal concern
to eliminate the cut rule. We show that, using an admissible modification of
the tensor rule, contractions can be eliminated, and that cuts can be
simultaneously limited to a single initial occurrence. This view leads to a
consistent, but incomplete game model for LL with exponentials, which is
finitary, in the sense that each play is finite. The game is based on a set of
inference rules which does not enjoy cut elimination. Nevertheless, the cut
rule is valid in the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4066</identifier>
 <datestamp>2009-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4066</id><created>2009-05-25</created><authors><author><keyname>Hyvernat</keyname><forenames>Pierre</forenames><affiliation>IML</affiliation></author></authors><title>Synchronous Games, Simulations and lambda-calculus</title><categories>cs.LO math.LO</categories><proxy>ccsd hal-00387826</proxy><journal-ref>Games for Logic and Programming Languages, European Conferences on
  Theory and Practice of Software (ETAPS 2005), Edinburgh : Royaume-Uni (2005)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We refine a model for linear logic based on two well-known ingredients: games
and simulations. We have already shown that usual simulation relations form a
sound notion of morphism between games; and that we can interpret all linear
logic in this way. One particularly interesting point is that we interpret
multiplicative connectives by synchronous operations on games. We refine this
work by giving computational contents to our simulation relations. To achieve
that, we need to restrict to intuitionistic linear logic. This allows to work
in a constructive setting, thus keeping a computational content to the proofs.
We then extend it by showing how to interpret some of the additional structure
of the exponentials. To be more precise, we first give a denotational model for
the typed lambda-calculus; and then give a denotational model for the
differential lambda-calculus of Ehrhard and Regnier. Both this models are
proved correct constructively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4068</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4068</id><created>2009-05-25</created><updated>2010-02-03</updated><authors><author><keyname>Je&#x17c;</keyname><forenames>&#x141;ukasz</forenames></author></authors><title>A 4/3-competitive randomized algorithm for online scheduling of packets
  with agreeable deadlines</title><categories>cs.DS</categories><comments>11 pages, 3-4 figures; new version due to STACS submission</comments><acm-class>F.2.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In 2005 Li et al. gave a phi-competitive deterministic online algorithm for
scheduling of packets with agreeable deadlines with a very interesting
analysis. This is known to be optimal due to a lower bound by Hajek. We claim
that the algorithm by Li et al. can be slightly simplified, while retaining its
competitive ratio. Then we introduce randomness to the modified algorithm and
argue that the competitive ratio against oblivious adversary is at most 4/3.
Note that this still leaves a gap between the best known lower bound of 5/4 by
Chin et al. for randomised algorithms against oblivious adversary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4087</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4087</id><created>2009-05-25</created><authors><author><keyname>Fu</keyname><forenames>Fangwen</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Structural Solutions for Cross-Layer Optimization of Wireless Multimedia
  Transmission</title><categories>cs.MM cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a systematic solution to the problem of cross-layer
optimization for delay-sensitive media transmission over time-varying wireless
channels as well as investigate the structures and properties of this solution,
such that it can be easily implemented in various multimedia systems and
applications. Specifically, we formulate this problem as a finite-horizon
Markov decision process (MDP) by explicitly considering the users'
heterogeneous multimedia traffic characteristics (e.g. delay deadlines,
distortion impacts and dependencies etc.), time-varying network conditions as
well as, importantly, their ability to adapt their cross-layer transmission
strategies in response to these dynamics. Based on the heterogeneous
characteristics of the media packets, we are able to express the transmission
priorities between packets as a new type of directed acyclic graph (DAG). This
DAG provides the necessary structure for determining the optimal cross-layer
actions in each time slot: the root packet in the DAG will always be selected
for transmission since it has the highest positive marginal utility; and the
complexity of the proposed cross-layer solution is demonstrated to linearly
increase w.r.t. the number of disconnected packet pairs in the DAG and
exponentially increase w.r.t. the number of packets on which the current
packets depend on. The simulation results demonstrate that the proposed
solution significantly outperforms existing state-of-the-art cross-layer
solutions. Moreover, we show that our solution provides the upper bound
performance for the cross-layer optimization solutions with delayed feedback
such as the well-known RaDiO framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4090</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4090</id><created>2009-05-25</created><authors><author><keyname>Jacobs</keyname><forenames>Bart</forenames></author></authors><title>Orthomodular lattices, Foulis Semigroups and Dagger Kernel Categories</title><categories>cs.LO</categories><comments>31 pages</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is a sequel to arXiv:0902.2355 and continues the study of quantum
logic via dagger kernel categories. It develops the relation between these
categories and both orthomodular lattices and Foulis semigroups. The relation
between the latter two notions has been uncovered in the 1960s. The current
categorical perspective gives a broader context and reconstructs this
relationship between orthomodular lattices and Foulis semigroups as special
instance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4091</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4091</id><created>2009-05-25</created><authors><author><keyname>Shen</keyname><forenames>Cong</forenames></author><author><keyname>Fitz</keyname><forenames>Michael P.</forenames></author></authors><title>Hybrid ARQ in Multiple-Antenna Slow Fading Channels: Performance Limits
  and Optimal Linear Dispersion Code Design</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on studying the fundamental performance limits and linear
dispersion code design for the MIMO-ARQ slow fading channel. Optimal average
rate of well-known HARQ protocols is analyzed. The optimal design of space-time
coding for the MIMO-ARQ channel is discussed. Information-theoretic measures
are used to optimize the rate assignment and derive the optimum design
criterion, which is then used to evaluate the optimality of existing space-time
codes. A different design criterion, which is obtained from the error
probability analysis of space-time coded MIMO-HARQ, is presented. Examples are
studied to reveal the gain of ARQ feedback in space-time coded MIMO systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4100</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4100</id><created>2009-05-25</created><authors><author><keyname>Feldman</keyname><forenames>Jon</forenames></author><author><keyname>Mehta</keyname><forenames>Aranyak</forenames></author><author><keyname>Mirrokni</keyname><forenames>Vahab</forenames></author><author><keyname>Muthukrishnan</keyname><forenames>S.</forenames></author></authors><title>Online Stochastic Matching: Beating 1-1/e</title><categories>cs.DS cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the online stochastic bipartite matching problem, in a form
motivated by display ad allocation on the Internet. In the online, but
adversarial case, the celebrated result of Karp, Vazirani and Vazirani gives an
approximation ratio of $1-1/e$. In the online, stochastic case when nodes are
drawn repeatedly from a known distribution, the greedy algorithm matches this
approximation ratio, but still, no algorithm is known that beats the $1 - 1/e$
bound.
  Our main result is a 0.67-approximation online algorithm for stochastic
bipartite matching, breaking this $1 - {1/e}$ barrier. Furthermore, we show
that no online algorithm can produce a $1-\epsilon$ approximation for an
arbitrarily small $\epsilon$ for this problem.
  We employ a novel application of the idea of the power of two choices from
load balancing: we compute two disjoint solutions to the expected instance, and
use both of them in the online algorithm in a prescribed preference order.
  To identify these two disjoint solutions, we solve a max flow problem in a
boosted flow graph, and then carefully decompose this maximum flow to two
edge-disjoint (near-)matchings. These two offline solutions are used to
characterize an upper bound for the optimum in any scenario. This is done by
identifying a cut whose value we can bound under the arrival distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4103</identifier>
 <datestamp>2009-07-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4103</id><created>2009-05-25</created><authors><author><keyname>Estrada</keyname><forenames>Ernesto</forenames></author><author><keyname>Hatano</keyname><forenames>Naomichi</forenames></author></authors><title>Communicability Graph and Community Structures in Complex Networks</title><categories>physics.soc-ph cond-mat.stat-mech cs.CY</categories><comments>36 pages, 5 figures, to appear in Applied Mathematics and Computation</comments><journal-ref>Appl. Math. Comp. 214 (2009) 500-511</journal-ref><doi>10.1016/j.amc.2009.04.024</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use the concept of the network communicability (Phys. Rev. E 77 (2008)
036111) to define communities in a complex network. The communities are defined
as the cliques of a communicability graph, which has the same set of nodes as
the complex network and links determined by the communicability function. Then,
the problem of finding the network communities is transformed to an all-clique
problem of the communicability graph. We discuss the efficiency of this
algorithm of community detection. In addition, we extend here the concept of
the communicability to account for the strength of the interactions between the
nodes by using the concept of inverse temperature of the network. Finally, we
develop an algorithm to manage the different degrees of overlapping between the
communities in a complex network. We then analyze the USA airport network, for
which we successfully detect two big communities of the eastern airports and of
the western/central airports as well as two bridging central communities. In
striking contrast, a well-known algorithm groups all but two of the continental
airports into one community.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4138</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4138</id><created>2009-05-26</created><authors><author><keyname>Attikos</keyname><forenames>Christos</forenames></author><author><keyname>Doumpos</keyname><forenames>Michael</forenames></author></authors><title>Faster estimation of the correlation fractal dimension using
  box-counting</title><categories>cs.DB cs.DS</categories><comments>4 pages, to appear in BCI 2009 - 4th Balkan Conference in Informatics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fractal dimension is widely adopted in spatial databases and data mining,
among others as a measure of dataset skewness. State-of-the-art algorithms for
estimating the fractal dimension exhibit linear runtime complexity whether
based on box-counting or approximation schemes. In this paper, we revisit a
correlation fractal dimension estimation algorithm that redundantly rescans the
dataset and, extending that work, we propose another linear, yet faster and as
accurate method, which completes in a single pass.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4147</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4147</id><created>2009-05-26</created><authors><author><keyname>Brakerski</keyname><forenames>Zvika</forenames></author><author><keyname>Patt-Shamir</keyname><forenames>Boaz</forenames></author></authors><title>Distributed Discovery of Large Near-Cliques</title><categories>cs.DC</categories><acm-class>C.2.4; F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an undirected graph and $0\le\epsilon\le1$, a set of nodes is called
$\epsilon$-near clique if all but an $\epsilon$ fraction of the pairs of nodes
in the set have a link between them. In this paper we present a fast
synchronous network algorithm that uses small messages and finds a near-clique.
Specifically, we present a constant-time algorithm that finds, with constant
probability of success, a linear size $\epsilon$-near clique if there exists an
$\epsilon^3$-near clique of linear size in the graph. The algorithm uses
messages of $O(\log n)$ bits. The failure probability can be reduced to
$n^{-\Omega(1)}$ in $O(\log n)$ time, and the algorithm also works if the graph
contains a clique of size $\Omega(n/\log^{\alpha}\log n)$ for some $\alpha \in
(0,1)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4160</identifier>
 <datestamp>2014-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4160</id><created>2009-05-26</created><updated>2014-10-18</updated><authors><author><keyname>Guzeltepe</keyname><forenames>Murat</forenames></author><author><keyname>Ozen</keyname><forenames>Mehmet</forenames></author></authors><title>Codes over Quaternion Integers with Respect to Lipschitz Metric</title><categories>cs.IT math.IT</categories><comments>The paper cannot give enough novalities. The technic had been already
  known</comments><msc-class>94B05, 94B15, 94B35, 94B60</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I want to withdraw this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4162</identifier>
 <datestamp>2010-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4162</id><created>2009-05-26</created><updated>2009-08-20</updated><authors><author><keyname>Shepelyansky</keyname><forenames>D. L.</forenames><affiliation>CNRS, Toulouse &amp; BINP, Novosibirsk</affiliation></author><author><keyname>Zhirov</keyname><forenames>O. V.</forenames><affiliation>CNRS, Toulouse &amp; BINP, Novosibirsk</affiliation></author></authors><title>Google matrix, dynamical attractors and Ulam networks</title><categories>cs.IR</categories><comments>9 pages, 11 figs; discussion, refs and fig added, data, title
  modified, research at http://www.quantware.ups-tlse.fr</comments><journal-ref>Phys. Rev. E v.81, p.036213 (2010)</journal-ref><doi>10.1103/PhysRevE.81.036213</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the properties of the Google matrix generated by a coarse-grained
Perron-Frobenius operator of the Chirikov typical map with dissipation. The
finite size matrix approximant of this operator is constructed by the Ulam
method. This method applied to the simple dynamical model creates the directed
Ulam networks with approximate scale-free scaling and characteristics being
rather similar to those of the World Wide Web. The simple dynamical attractors
play here the role of popular web sites with a strong concentration of
PageRank. A variation of the Google parameter $\alpha$ or other parameters of
the dynamical map can drive the PageRank of the Google matrix to a delocalized
phase with a strange attractor where the Google search becomes inefficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4163</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4163</id><created>2009-05-26</created><authors><author><keyname>Guzeltepe</keyname><forenames>Murat</forenames></author><author><keyname>Ozen</keyname><forenames>Mehmet</forenames></author></authors><title>Cyclic Codes over Some Finite Rings</title><categories>cs.IT math.CO math.IT</categories><msc-class>91B05, 94B15, 94B35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper cyclic codes are established with respect to the Mannheim
metric over some finite rings by using Gaussian integers and the decoding
algorithm for these codes is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4164</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4164</id><created>2009-05-26</created><authors><author><keyname>Knudsen</keyname><forenames>Joakim Grahl</forenames></author><author><keyname>Riera</keyname><forenames>Constanza</forenames></author><author><keyname>Danielsen</keyname><forenames>Lars Eirik</forenames></author><author><keyname>Parker</keyname><forenames>Matthew G.</forenames></author><author><keyname>Rosnes</keyname><forenames>Eirik</forenames></author></authors><title>Iterative Decoding on Multiple Tanner Graphs Using Random Edge Local
  Complementation</title><categories>cs.IT math.IT</categories><comments>5 pages, to appear in proc. IEEE ISIT, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose to enhance the performance of the sum-product
algorithm (SPA) by interleaving SPA iterations with a random local graph update
rule. This rule is known as edge local complementation (ELC), and has the
effect of modifying the Tanner graph while preserving the code. We have
previously shown how the ELC operation can be used to implement an iterative
permutation group decoder (SPA-PD)--one of the most successful iterative
soft-decision decoding strategies at small blocklengths. In this work, we
exploit the fact that ELC can also give structurally distinct parity-check
matrices for the same code. Our aim is to describe a simple iterative decoder,
running SPA-PD on distinct structures, based entirely on random usage of the
ELC operation. This is called SPA-ELC, and we focus on small blocklength codes
with strong algebraic structure. In particular, we look at the extended Golay
code and two extended quadratic residue codes. Both error rate performance and
average decoding complexity, measured by the average total number of messages
required in the decoding, significantly outperform those of the standard SPA,
and compares well with SPA-PD. However, in contrast to SPA-PD, which requires a
global action on the Tanner graph, we obtain a performance improvement via
local action alone. Such localized algorithms are of mathematical interest in
their own right, but are also suited to parallel/distributed realizations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4165</identifier>
 <datestamp>2010-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4165</id><created>2009-05-26</created><authors><author><keyname>Guzeltepe</keyname><forenames>Murat</forenames></author><author><keyname>Ozen</keyname><forenames>Mehmet</forenames></author></authors><title>Cyclic Codes over Some Finite Quaternion Integer Rings</title><categories>cs.IT math.IT</categories><msc-class>94B05, 94B15, 94B35, 94B60</msc-class><doi>10.1016/j.jfranklin.2010.02.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, cyclic codes are established over some finite quaternion
integer rings with respect to the quaternion Mannheim distance, and de- coding
algorithm for these codes is given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4193</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4193</id><created>2009-05-26</created><authors><author><keyname>Masopust</keyname><forenames>Tomas</forenames></author></authors><title>Answers to Questions Formulated in the Paper &quot;On States Observability in
  Deterministic Finite Automata&quot;</title><categories>cs.FL</categories><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives answers to questions formulated as open in the paper &quot;On
State Observability in Deterministic Finite Automata&quot; by A. Mateescu and Gh.
Paun. Specifically, it demonstrates that for all k &gt;= 2, the families of
regular languages acceptable by deterministic finite automata with no more than
k semi-observable states, denoted by Tk, are anti-AFL's, and that the family T1
differs in the closure property under Kleene +.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4200</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4200</id><created>2009-05-26</created><authors><author><keyname>Garner</keyname><forenames>Richard</forenames><affiliation>LAMA</affiliation></author><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>LAMA</affiliation></author><author><keyname>Pardon</keyname><forenames>Aur&#xe9;lien</forenames><affiliation>LIP</affiliation></author></authors><title>Variable binding, symmetric monoidal closed theories, and bigraphs</title><categories>cs.LO cs.PL math.CT</categories><comments>An introduction to two more technical previous preprints. Accepted at
  Concur '09</comments><proxy>ccsd hal-00388100</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the use of symmetric monoidal closed (SMC) structure
for representing syntax with variable binding, in particular for languages with
linear aspects. In our setting, one first specifies an SMC theory T, which may
express binding operations, in a way reminiscent from higher-order abstract
syntax. This theory generates an SMC category S(T) whose morphisms are, in a
sense, terms in the desired syntax. We apply our approach to Jensen and
Milner's (abstract binding) bigraphs, which are linear w.r.t. processes. This
leads to an alternative category of bigraphs, which we compare to the original.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4201</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4201</id><created>2009-05-26</created><authors><author><keyname>Akinwalle</keyname><forenames>A. T.</forenames></author><author><keyname>Ibharalu</keyname><forenames>F. T.</forenames></author></authors><title>The Usefulness of Multilevel Hash Tables with Multiple Hash Functions in
  Large Databases</title><categories>cs.DS cs.DB</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),11-20</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, attempt is made to select three good hash functions which
uniformly distribute hash values that permute their internal states and allow
the input bits to generate different output bits. These functions are used in
different levels of hash tables that are coded in Java Programming Language and
a quite number of data records serve as primary data for testing the
performances. The result shows that the two-level hash tables with three
different hash functions give a superior performance over one-level hash table
with two hash functions or zero-level hash table with one function in term of
reducing the conflict keys and quick lookup for a particular element. The
result assists to reduce the complexity of join operation in query language
from O(n2) to O(1) by placing larger query result, if any, in multilevel hash
tables with multiple hash functions and generate shorter query result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4203</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4203</id><created>2009-05-26</created><authors><author><keyname>Sabrin</keyname><forenames>Alasu Paul</forenames></author></authors><title>Multimedia Aplication for Solving a Sudoku Game</title><categories>cs.OH</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),21-30</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article explains the way in which, with the help of Action Script 3 in
combination with Flash, a method of solving Sudoku game was implemented,
through searching for the certain numbers and after that trying to guess for
the squares where there are two possible numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4205</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4205</id><created>2009-05-26</created><authors><author><keyname>Anghel</keyname><forenames>Cristian</forenames></author><author><keyname>Muia</keyname><forenames>Vlad</forenames></author><author><keyname>Stoianovici</keyname><forenames>Miodrag</forenames></author></authors><title>Development and Optimization of a Multimedia Product</title><categories>cs.MM</categories><comments>6 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009), 31-36</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a new concept of a multimedia interactive product. It
is a multiuser versatile platform that can be used for different purposes. The
first implementation of the platform is a multiplayer game called Texas Hold
'em, which is a very popular community card game. The paper shows the product's
multimedia structure where Hardware and Software work together in creating a
realistic feeling for the users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4226</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4226</id><created>2009-05-26</created><authors><author><keyname>Abate</keyname><forenames>Pietro</forenames><affiliation>PPS</affiliation></author><author><keyname>Boender</keyname><forenames>Jaap</forenames><affiliation>PPS</affiliation></author><author><keyname>Di Cosmo</keyname><forenames>Roberto</forenames><affiliation>PPS</affiliation></author><author><keyname>Zacchiroli</keyname><forenames>Stefano</forenames><affiliation>PPS</affiliation></author></authors><title>Strong Dependencies between Software Components</title><categories>cs.SE</categories><proxy>ccsd hal-00388093</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Component-based systems often describe context requirements in terms of
explicit inter-component dependencies. Studying large instances of such
systems?such as free and open source software (FOSS) distributions?in terms of
declared dependencies between packages is appealing. It is however also
misleading when the language to express dependencies is as expressive as
boolean formulae, which is often the case. In such settings, a more appropriate
notion of component dependency exists: strong dependency. This paper introduces
such notion as a first step towards modeling semantic, rather then syntactic,
inter-component relationships. Furthermore, a notion of component sensitivity
is derived from strong dependencies, with ap- plications to quality assurance
and to the evaluation of upgrade risks. An empirical study of strong
dependencies and sensitivity is presented, in the context of one of the
largest, freely available, component-based system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4237</identifier>
 <datestamp>2010-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4237</id><created>2009-05-26</created><authors><author><keyname>Panigrahi</keyname><forenames>Prasanta K.</forenames></author><author><keyname>Ghosh</keyname><forenames>Sayantan</forenames></author><author><keyname>Manimaran</keyname><forenames>P.</forenames></author><author><keyname>Ahalpara</keyname><forenames>Dilip P.</forenames></author></authors><title>Statistical Properties of Fluctuations: A Method to Check Market
  Behavior</title><categories>q-fin.ST cs.DS physics.data-an</categories><comments>9 pages, 6 figures, Econophys-IV, Kolkata, 2009</comments><journal-ref>Econophysics &amp; Economics of Games, Social Choices and Quantitative
  Techniques, pp.110-118, Springer-Verlag, Milan (2009)</journal-ref><doi>10.1007/978-88-470-1501-2_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the Bombay stock exchange (BSE) price index over the period of
last 12 years. Keeping in mind the large fluctuations in last few years, we
carefully find out the transient, non-statistical and locally structured
variations. For that purpose, we make use of Daubechies wavelet and
characterize the fractal behavior of the returns using a recently developed
wavelet based fluctuation analysis method. the returns show a fat-tail
distribution as also weak non-statistical behavior. We have also carried out
continuous wavelet as well as Fourier power spectral analysis to characterize
the periodic nature and correlation properties of the time series.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4241</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4241</id><created>2009-05-26</created><authors><author><keyname>Chazelle</keyname><forenames>Bernard</forenames></author></authors><title>The Convergence of Bird Flocking</title><categories>cs.CG</categories><acm-class>F.2.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We bound the time it takes for a group of birds to reach steady state in a
standard flocking model. We prove that (i) within single exponential time
fragmentation ceases and each bird settles on a fixed flying direction; (ii)
the flocking network converges only after a number of steps that is an iterated
exponential of height logarithmic in the number of birds. We also prove the
highly surprising result that this bound is optimal. The model directs the
birds to adjust their velocities repeatedly by averaging them with their
neighbors within a fixed radius. The model is deterministic, but we show that
it can tolerate a reasonable amount of stochastic or even adversarial noise.
Our methods are highly general and we speculate that the results extend to a
wider class of models based on undirected flocking networks, whether defined
metrically or topologically. This work introduces new techniques of broader
interest, including the &quot;flight net,&quot; the &quot;iterated spectral shift,&quot; and a
certain &quot;residue-clearing&quot; argument in circuit complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4251</identifier>
 <datestamp>2009-05-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4251</id><created>2009-05-26</created><authors><author><keyname>de Carvalho</keyname><forenames>Daniel</forenames></author></authors><title>Execution Time of lambda-Terms via Denotational Semantics and
  Intersection Types</title><categories>cs.LO cs.CC</categories><comments>36 pages</comments><acm-class>F.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multiset based relational model of linear logic induces a semantics of
the type free lambda-calculus, which corresponds to a non-idempotent
intersection type system, System R. We prove that, in System R, the size of the
type derivations and the size of the types are closely related to the execution
time of lambda-terms in a particular environment machine, Krivine's machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4303</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4303</id><created>2009-05-26</created><authors><author><keyname>Singh</keyname><forenames>Jaspreet</forenames></author><author><keyname>Madhow</keyname><forenames>Upamanyu</forenames></author></authors><title>On Block Noncoherent Communication with Low-Precision Phase Quantization
  at the Receiver</title><categories>cs.IT math.IT</categories><comments>IEEE ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider communication over the block noncoherent AWGN channel with
low-precision Analog-to-Digital Converters (ADCs) at the receiver. For standard
uniform Phase Shift Keying (PSK) modulation, we investigate the performance of
a receiver architecture that quantizes only the phase of the received signal;
this has the advantage of being implementable without automatic gain control,
using multiple 1-bit ADCs preceded by analog multipliers. We study the
structure of the transition density of the resulting channel model. Several
results, based on the symmetry inherent in the channel, are provided to
characterize this transition density. A low complexity procedure for computing
the channel capacity is obtained using these results. Numerical capacity
computations for QPSK show that 8-bin phase quantization of the received signal
recovers more than 80-85 % of the capacity attained with unquantized
observations, while 12-bin phase quantization recovers above 90-95 % of the
unquantized capacity. Dithering the constellation is shown to improve the
performance in the face of drastic quantization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4322</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4322</id><created>2009-05-27</created><authors><author><keyname>Antohe</keyname><forenames>Valerian</forenames></author><author><keyname>Stanciu</keyname><forenames>Constantin</forenames></author></authors><title>Mathematical Models in Danube Water Quality</title><categories>cs.OH</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009), 37-46</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The mathematical shaping in the study of water quality has become a branch of
environmental engineering. The comprehension and effective application of
mathematical models in studying environmental phenomena keep up with the
results in the domain of mathematics and the development of specialized
software as well. Integrated software programs simulate and predict extreme
events, propose solutions, analyzing and processing data in due time. This
paper presents a browsing through some mathematical categories of processing
the statistical data, examples and their analysis concerning the degree of
water pollution downstream the river Danube.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4325</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4325</id><created>2009-05-27</created><authors><author><keyname>Dodson</keyname><forenames>Donna</forenames></author><author><keyname>Fujiwara</keyname><forenames>Mikio</forenames></author><author><keyname>Grangier</keyname><forenames>Philippe</forenames></author><author><keyname>Hayashi</keyname><forenames>Masahito</forenames></author><author><keyname>Imafuku</keyname><forenames>Kentaro</forenames></author><author><keyname>Kitayama</keyname><forenames>Ken-ichi</forenames></author><author><keyname>Kumar</keyname><forenames>Prem</forenames></author><author><keyname>Kurtsiefer</keyname><forenames>Christian</forenames></author><author><keyname>Lenhart</keyname><forenames>Gaby</forenames></author><author><keyname>Luetkenhaus</keyname><forenames>Norbert</forenames></author><author><keyname>Matsumoto</keyname><forenames>Tsutomu</forenames></author><author><keyname>Munro</keyname><forenames>William J.</forenames></author><author><keyname>Nishioka</keyname><forenames>Tsuyoshi</forenames></author><author><keyname>Peev</keyname><forenames>Momtchil</forenames></author><author><keyname>Sasaki</keyname><forenames>Masahide</forenames></author><author><keyname>Sata</keyname><forenames>Yutaka</forenames></author><author><keyname>Takada</keyname><forenames>Atsushi</forenames></author><author><keyname>Takeoka</keyname><forenames>Masahiro</forenames></author><author><keyname>Tamaki</keyname><forenames>Kiyoshi</forenames></author><author><keyname>Tanaka</keyname><forenames>Hidema</forenames></author><author><keyname>Tokura</keyname><forenames>Yasuhiro</forenames></author><author><keyname>Tomita</keyname><forenames>Akihisa</forenames></author><author><keyname>Toyoshima</keyname><forenames>Morio</forenames></author><author><keyname>van Meter</keyname><forenames>Rodney</forenames></author><author><keyname>Yamagishi</keyname><forenames>Atsuhiro</forenames></author><author><keyname>Yamamoto</keyname><forenames>Yoshihisa</forenames></author><author><keyname>Yamamura</keyname><forenames>Akihiro</forenames></author></authors><title>Updating Quantum Cryptography Report ver. 1</title><categories>quant-ph cs.CR</categories><comments>74 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum cryptographic technology (QCT) is expected to be a fundamental
technology for realizing long-term information security even against
as-yet-unknown future technologies. More advanced security could be achieved
using QCT together with contemporary cryptographic technologies. To develop and
spread the use of QCT, it is necessary to standardize devices, protocols, and
security requirements and thus enable interoperability in a multi-vendor,
multi-network, and multi-service environment. This report is a technical
summary of QCT and related topics from the viewpoints of 1) consensual
establishment of specifications and requirements of QCT for standardization and
commercialization and 2) the promotion of research and design to realize
New-Generation Quantum Cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4332</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4332</id><created>2009-05-27</created><authors><author><keyname>Wang</keyname><forenames>Yanjing</forenames></author><author><keyname>Dechesne</keyname><forenames>Francien</forenames></author></authors><title>On expressive power and class invariance</title><categories>cs.LO</categories><comments>18 pages</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In computer science, various logical languages are defined to analyze
properties of systems. One way to pinpoint the essential differences between
those logics is to compare their expressivity in terms of distinguishing power
and expressive power. In this paper, we study those two concepts by regarding
the latter notion as the former lifted to classes of models. We show some
general results on lifting an invariance relation on models to one on classes
of models, such that when the former corresponds to the distinguishing power of
a logic, the latter corresponds to its expressive power, given certain
compactness requirements. In particular, we introduce the notion of class
bisimulation to capture the expressive power of modal logics. We demonstrate
the application of our results by revisiting modal definability with our new
insights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4341</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4341</id><created>2009-05-27</created><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames><affiliation>INRIA Futurs, LIFL, INRIA Lille - Nord Europe</affiliation></author></authors><title>Characterizing predictable classes of processes</title><categories>cs.AI cs.IT math.IT math.PR</categories><proxy>ccsd inria-00388523</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem is sequence prediction in the following setting. A sequence
$x_1,...,x_n,...$ of discrete-valued observations is generated according to
some unknown probabilistic law (measure) $\mu$. After observing each outcome,
it is required to give the conditional probabilities of the next observation.
The measure $\mu$ belongs to an arbitrary class $\C$ of stochastic processes.
We are interested in predictors $\rho$ whose conditional probabilities converge
to the &quot;true&quot; $\mu$-conditional probabilities if any $\mu\in\C$ is chosen to
generate the data. We show that if such a predictor exists, then a predictor
can also be obtained as a convex combination of a countably many elements of
$\C$. In other words, it can be obtained as a Bayesian predictor whose prior is
concentrated on a countable set. This result is established for two very
different measures of performance of prediction, one of which is very strong,
namely, total variation, and the other is very weak, namely, prediction in
expected average Kullback-Leibler divergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4369</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4369</id><created>2009-05-27</created><authors><author><keyname>Benzmueller</keyname><forenames>Christoph</forenames></author></authors><title>Automating Quantified Multimodal Logics in Simple Type Theory -- A Case
  Study</title><categories>cs.AI cs.LO</categories><comments>ii + 30 pages</comments><report-no>SEKI Working-Paper SWP-2009-02</report-no><acm-class>I.2.4; I.2.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a case study we investigate whether off the shelf higher-order theorem
provers and model generators can be employed to automate reasoning in and about
quantified multimodal logics. In our experiments we exploit the new TPTP
infrastructure for classical higher-order logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4378</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4378</id><created>2009-05-27</created><updated>2009-09-29</updated><authors><author><keyname>Ben-Haim</keyname><forenames>Zvika</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author></authors><title>The Cramer-Rao Bound for Sparse Estimation</title><categories>math.ST cs.IT math.IT stat.TH</categories><comments>11 pages, 2 figures. Submitted to IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to characterize the best achievable performance for
the problem of estimating an unknown parameter having a sparse representation.
Specifically, we consider the setting in which a sparsely representable
deterministic parameter vector is to be estimated from measurements corrupted
by Gaussian noise, and derive a lower bound on the mean-squared error (MSE)
achievable in this setting. To this end, an appropriate definition of bias in
the sparse setting is developed, and the constrained Cramer-Rao bound (CRB) is
obtained. This bound is shown to equal the CRB of an estimator with knowledge
of the support set, for almost all feasible parameter values. Consequently, in
the unbiased case, our bound is identical to the MSE of the oracle estimator.
Combined with the fact that the CRB is achieved at high signal-to-noise ratios
by the maximum likelihood technique, our result provides a new interpretation
for the common practice of using the oracle estimator as a gold standard
against which practical approaches are compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4387</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4387</id><created>2009-05-27</created><authors><author><keyname>Kebair</keyname><forenames>Fahem</forenames></author><author><keyname>Serin</keyname><forenames>Frederic</forenames></author></authors><title>Information Modeling for a Dynamic Representation of an Emergency
  Situation</title><categories>cs.AI cs.MA</categories><comments>6</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we propose an approach to build a decision support system that
can help emergency planners and responders to detect and manage emergency
situations. The internal mechanism of the system is independent from the
treated application. Therefore, we think the system may be used or adapted
easily to different case studies. We focus here on a first step in the
decision-support process which concerns the modeling of information issued from
the perceived environment and their representation dynamically using a
multiagent system. This modeling was applied on the RoboCupRescue Simulation
System. An implementation and some results are presented here.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4430</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4430</id><created>2009-05-27</created><authors><author><keyname>Antohe</keyname><forenames>Valerian</forenames></author></authors><title>Limits of Educational Soft &quot;GeoGebra&quot; in a Critical Constructive Review</title><categories>cs.MS</categories><comments>8 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009), 47-54</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical educational soft explore, investigating in a dynamical way, some
algebraically, geometrically problems, the expected results being used to
involve a lot of mathematical results. One such software soft is GeoGebra. The
software is free and multi-platform dynamic mathematics software for learning
and teaching, awards in Europe and the USA. This paper describes some critical
but constructive investigation using the platform for graph functions and
dynamic geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4433</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4433</id><created>2009-05-27</created><authors><author><keyname>Bruyere</keyname><forenames>Sebastien</forenames></author><author><keyname>Pillet</keyname><forenames>Vincent</forenames></author><author><keyname>Quoniam</keyname><forenames>Luc</forenames></author></authors><title>Proposition d'une methode de qualification et de selection d'un logiciel
  d'analyse et de suivi du referencement dans les moteurs de recherche</title><categories>cs.OH</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009), 55-64</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to measure website visibility in search engines, there are softwares
for analytics and referencing follow-up. They permit to quantify website's
efficacity of referencing and optimize its positionning in search engines. With
regard to search engines' algorithms' evolution and centralization of Key
Performance Indicators for Marketing decision making, it becomes hard to find
solutions to effectively lead a lot of projects for referencing. That's why we
have built a methodology in order compare, evaluate and choose a software for
analytics and referencing follow-up in search engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4441</identifier>
 <datestamp>2014-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4441</id><created>2009-05-27</created><updated>2010-09-01</updated><authors><author><keyname>Cheong</keyname><forenames>Otfried</forenames></author><author><keyname>Vigneron</keyname><forenames>Antoine</forenames></author><author><keyname>Yon</keyname><forenames>Juyoung</forenames></author></authors><title>Reverse nearest neighbor queries in fixed dimension</title><categories>cs.CG cs.DS</categories><comments>7 pages, 3 figures; typos corrected; more background material on
  compressed quadtrees</comments><acm-class>I.3.5; E.1</acm-class><doi>10.1142/S0218195911003603</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reverse nearest neighbor queries are defined as follows: Given an input
point-set P, and a query point q, find all the points p in P whose nearest
point in P U {q} \ {p} is q. We give a data structure to answer reverse nearest
neighbor queries in fixed-dimensional Euclidean space. Our data structure uses
O(n) space, its preprocessing time is O(n log n), and its query time is O(log
n).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4444</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4444</id><created>2009-05-27</created><authors><author><keyname>Frederickson</keyname><forenames>Greg N.</forenames></author><author><keyname>Wittman</keyname><forenames>Barry</forenames></author></authors><title>Approximation Algorithms for the Traveling Repairman and Speeding
  Deliveryman Problems</title><categories>cs.DS</categories><comments>20 pages, 1 figure</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constant-factor, polynomial-time approximation algorithms are presented for
two variations of the traveling salesman problem with time windows. In the
first variation, the traveling repairman problem, the goal is to find a tour
that visits the maximum possible number of locations during their time windows.
In the second variation, the speeding deliveryman problem, the goal is to find
a tour that uses the minimum possible speedup to visit all locations during
their time windows. For both variations, the time windows are of unit length,
and the distance metric is based on a weighted, undirected graph. Algorithms
with improved approximation ratios are given for the case when the input is
defined on a tree rather than a general graph. The algorithms are also extended
to handle time windows whose lengths fall in any bounded range.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4452</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4452</id><created>2009-05-27</created><authors><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI, Amsterdam</affiliation></author></authors><title>Analysis of Sorting Algorithms by Kolmogorov Complexity (A Survey)</title><categories>cs.DS cs.CC</categories><comments>18 Pages, 2 figures, LaTeX</comments><journal-ref>Pp.209--232 in: In: Entropy, Search, Complexity, Bolyai Society
  Mathematical Studies, 16, I. Csiszar, G.O.H. Katona, G. Tardos, Eds.,
  Springer-Verlag, 2007</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, many results on the computational complexity of sorting algorithms
were obtained using Kolmogorov complexity (the incompressibility method).
Especially, the usually hard average-case analysis is ammenable to this method.
Here we survey such results about Bubblesort, Heapsort, Shellsort,
Dobosiewicz-sort, Shakersort, and sorting with stacks and queues in sequential
or parallel mode. Especially in the case of Shellsort the uses of Kolmogorov
complexity surprisingly easily resolved problems that had stayed open for a
long time despite strenuous attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4476</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4476</id><created>2009-05-27</created><authors><author><keyname>Tajer</keyname><forenames>Ali</forenames></author><author><keyname>Wang</keyname><forenames>Xiaodong</forenames></author></authors><title>Beacon-Assisted Spectrum Access with Cooperative Cognitive Transmitter
  and Receiver</title><categories>cs.IT math.IT</categories><comments>36 pages, 6 figures, To appear in IEEE Transaction on Mobile
  Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum access is an important function of cognitive radios for detecting
and utilizing spectrum holes without interfering with the legacy systems. In
this paper we propose novel cooperative communication models and show how
deploying such cooperations between a pair of secondary transmitter and
receiver assists them in identifying spectrum opportunities more reliably.
These cooperations are facilitated by dynamically and opportunistically
assigning one of the secondary users as a relay to assist the other one which
results in more efficient spectrum hole detection. Also, we investigate the
impact of erroneous detection of spectrum holes and thereof missing
communication opportunities on the capacity of the secondary channel. The
capacity of the secondary users with interference-avoiding spectrum access is
affected by 1) how effectively the availability of vacant spectrum is sensed by
the secondary transmitter-receiver pair, and 2) how correlated are the
perceptions of the secondary transmitter-receiver pair about network spectral
activity. We show that both factors are improved by using the proposed
cooperative protocols. One of the proposed protocols requires explicit
information exchange in the network. Such information exchange in practice is
prone to wireless channel errors (i.e., is imperfect) and costs bandwidth loss.
We analyze the effects of such imperfect information exchange on the capacity
as well as the effect of bandwidth cost on the achievable throughput. The
protocols are also extended to multiuser secondary networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4482</identifier>
 <datestamp>2009-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4482</id><created>2009-05-27</created><authors><author><keyname>Needell</keyname><forenames>Deanna</forenames></author></authors><title>Topics in Compressed Sensing</title><categories>math.NA cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressed sensing has a wide range of applications that include error
correction, imaging, radar and many more. Given a sparse signal in a high
dimensional space, one wishes to reconstruct that signal accurately and
efficiently from a number of linear measurements much less than its actual
dimension. Although in theory it is clear that this is possible, the difficulty
lies in the construction of algorithms that perform the recovery efficiently,
as well as determining which kind of linear measurements allow for the
reconstruction. There have been two distinct major approaches to sparse
recovery that each present different benefits and shortcomings. The first,
L1-minimization methods such as Basis Pursuit, use a linear optimization
problem to recover the signal. This method provides strong guarantees and
stability, but relies on Linear Programming, whose methods do not yet have
strong polynomially bounded runtimes. The second approach uses greedy methods
that compute the support of the signal iteratively. These methods are usually
much faster than Basis Pursuit, but until recently had not been able to provide
the same guarantees. This gap between the two approaches was bridged when we
developed and analyzed the greedy algorithm Regularized Orthogonal Matching
Pursuit (ROMP). ROMP provides similar guarantees to Basis Pursuit as well as
the speed of a greedy algorithm. Our more recent algorithm Compressive Sampling
Matching Pursuit (CoSaMP) improves upon these guarantees, and is optimal in
every important aspect.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4487</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4487</id><created>2009-05-27</created><authors><author><keyname>Cheng</keyname><forenames>Qi</forenames></author><author><keyname>Meng</keyname><forenames>Xianmeng</forenames></author><author><keyname>Sun</keyname><forenames>Celi</forenames></author><author><keyname>Chen</keyname><forenames>Jiazhe</forenames></author></authors><title>Bounding the Sum of Square Roots via Lattice Reduction</title><categories>cs.CG</categories><comments>To appear in Mathematics of Computation</comments><doi>10.1090/S0025-5718-09-02304-7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $k$ and $n$ be positive integers. Define $R(n,k)$ to be the minimum
positive value of $$ | e_i \sqrt{s_1} + e_2 \sqrt{s_2} + ... + e_k \sqrt{s_k}
-t | $$ where $ s_1, s_2, ..., s_k$ are positive integers no larger than $n$,
$t$ is an integer and $e_i\in \{1,0, -1\}$ for all $1\leq i\leq k$. It is
important in computational geometry to determine a good lower and upper bound
of $ R(n,k)$. In this paper we show that this problem is closely related to the
shortest vector problem in certain integral lattices and present an algorithm
to find lower bounds based on lattice reduction algorithms. Although we can
only prove an exponential time upper bound for the algorithm, it is efficient
for large $k$ when an exhaustive search for the minimum value is clearly
infeasible. It produces lower bounds much better than the root separation
technique does. Based on numerical data, we formulate a conjecture on the
length of the shortest nonzero vector in the lattice, whose validation implies
that our algorithm runs in polynomial time and the problem of comparing two
sums of square roots of small integers can be solved in polynomial time. As a
side result, we obtain constructive upper bounds for $R(n,k)$ when $ n$ is much
smaller than $2^{2k}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4541</identifier>
 <datestamp>2010-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4541</id><created>2009-05-27</created><updated>2010-08-04</updated><authors><author><keyname>Ait-Idir</keyname><forenames>Tarik</forenames></author><author><keyname>Saoudi</keyname><forenames>Samir</forenames></author></authors><title>Turbo Packet Combining Strategies for the MIMO-ISI ARQ Channel</title><categories>cs.IT math.IT</categories><comments>13 pages, 7 figures, and 2 tables</comments><journal-ref>IEEE Transactions on Communications, vol. 57, no. 12, pp.
  3782-3793, Dec. 2009</journal-ref><doi>10.1109/TCOMM.2009.12.080318</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the issue of efficient turbo packet combining techniques
for coded transmission with a Chase-type automatic repeat request (ARQ)
protocol operating over a multiple-input--multiple-output (MIMO) channel with
intersymbol interference (ISI). First of all, we investigate the outage
probability and the outage-based power loss of the MIMO-ISI ARQ channel when
optimal maximum a posteriori (MAP) turbo packet combining is used at the
receiver. We show that the ARQ delay (i.e., the maximum number of ARQ rounds)
does not completely translate into a diversity gain. We then introduce two
efficient turbo packet combining algorithms that are inspired by minimum mean
square error (MMSE)-based turbo equalization techniques. Both schemes can be
viewed as low-complexity versions of the optimal MAP turbo combiner. The first
scheme is called signal-level turbo combining and performs packet combining and
multiple transmission ISI cancellation jointly at the signal-level. The second
scheme, called symbol-level turbo combining, allows ARQ rounds to be separately
turbo equalized, while combining is performed at the filter output. We conduct
a complexity analysis where we demonstrate that both algorithms have almost the
same computational cost as the conventional log-likelihood ratio (LLR)-level
combiner. Simulation results show that both proposed techniques outperform
LLR-level combining, while for some representative MIMO configurations,
signal-level combining has better ISI cancellation capability and achievable
diversity order than that of symbol-level combining.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4545</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4545</id><created>2009-05-28</created><authors><author><keyname>Amat</keyname><forenames>Alexandre Graell i</forenames></author><author><keyname>Bidan</keyname><forenames>Raphael Le</forenames></author></authors><title>Minimum Distance and Convergence Analysis of
  Hamming-Accumulate-Acccumulate Codes</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this letter we consider the ensemble of codes formed by the serial
concatenation of a Hamming code and two accumulate codes. We show that this
ensemble is asymptotically good, in the sense that most codes in the ensemble
have minimum distance growing linearly with the block length. Thus, the
resulting codes achieve high minimum distances with high probability, about
half or more of the minimum distance of a typical random linear code of the
same rate and length in our examples. The proposed codes also show reasonably
good iterative convergence thresholds, which makes them attractive for
applications requiring high code rates and low error rates, such as optical
communications and magnetic recording.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4567</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4567</id><created>2009-05-28</created><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Masini</keyname><forenames>Andrea</forenames></author><author><keyname>Zorzi</keyname><forenames>Margherita</forenames></author></authors><title>Confluence Results for a Quantum Lambda Calculus with Measurements</title><categories>cs.LO</categories><comments>21 pages</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A strong confluence result for Q*, a quantum lambda-calculus with
measurements, is proved. More precisely, confluence is shown to hold both for
finite and infinite computations. The technique used in the confluence proof is
syntactical but innovative. This makes Q* different from similar quantum lambda
calculi, which are either measurement-free or provided with a reduction
strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4570</identifier>
 <datestamp>2010-02-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4570</id><created>2009-05-28</created><updated>2010-02-16</updated><authors><author><keyname>Yu</keyname><forenames>Yang</forenames></author><author><keyname>Zhou</keyname><forenames>Zhi-Hua</forenames></author></authors><title>Weak Evolvability Equals Strong Evolvability</title><categories>cs.AI cs.NE</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An updated version will be uploaded later.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4581</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4581</id><created>2009-05-28</created><authors><author><keyname>Bania</keyname><forenames>Piotr</forenames></author></authors><title>Generic Unpacking of Self-modifying, Aggressive, Packed Binary Programs</title><categories>cs.CR</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays most of the malware applications are either packed or protected.
This techniques are applied especially to evade signature based detectors and
also to complicate the job of reverse engineers or security analysts. The time
one must spend on unpacking or decrypting malware layers is often very long and
in fact remains the most complicated task in the overall process of malware
analysis. In this report author proposes MmmBop as a relatively new concept of
using dynamic binary instrumentation techniques for unpacking and bypassing
detection by self-modifying and highly aggressive packed binary code. MmmBop is
able to deal with most of the known and unknown packing algorithms and it is
also suitable to successfully bypass most of currently used anti-reversing
tricks. This framework does not depend on any other 3rd party software and it
is developed entirely in user mode (ring3). MmmBop supports the IA-32
architecture and it is targeted for Microsoft Windows XP, some of the further
deliberations will be referring directly to this operating system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4592</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4592</id><created>2009-05-28</created><authors><author><keyname>Sakka</keyname><forenames>Omar</forenames><affiliation>LIESP</affiliation></author><author><keyname>Botta-Genoulaz</keyname><forenames>Valerie</forenames><affiliation>LIESP</affiliation></author><author><keyname>Trilling</keyname><forenames>Lorraine</forenames><affiliation>LIESP</affiliation></author></authors><title>Mod\'elisation des facteurs influen\c{c}ant la performance de la
  cha\^ine logistique</title><categories>cs.SE</categories><comments>7 pages</comments><proxy>ccsd hal-00389129</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Improvement of industrial performance such as cost, lead-time, adaptability,
variety and traceability is the major finality of companies. At this need
corresponds the necessity to collaborate and to strengthen their coordination
mechanisms. Information exchange becomes then a strategic question: what is the
nature of the information that can be shared with customers and suppliers?
Which impact on the performance of a company is expectable? What about the
performance of the whole supply chain? It is essential for a company to
identify the information whose exchange contributes to its performance and to
control its information flows. This study aims to release from the literature
the main tendencies of collaboration practices and information exchanges
leading to the performance and to propose a model of hypothesis gathering these
practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4596</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4596</id><created>2009-05-28</created><authors><author><keyname>Duval</keyname><forenames>Dominique</forenames><affiliation>LMC - IMAG</affiliation></author><author><keyname>Reynaud</keyname><forenames>Jean-Claude</forenames><affiliation>LSR - IMAG</affiliation></author></authors><title>About raising and handling exceptions</title><categories>cs.PL cs.LO</categories><proxy>ccsd hal-00389167</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a unified framework for dealing with a deduction system
and a denotational semantics of exceptions. It is based on the fact that
handling exceptions can be seen as a kind of generalized case distinction. This
point of view on exceptions has been introduced in 2004, it is based on the
notion of diagrammatic logic, which assumes some familiarity with category
theory. Extensive sums of types can be used for dealing with case distinctions.
The aim of this new paper is to focus on the role of generalized extensivity
property for dealing with exceptions. Moreover, the presentation of this paper
makes only a restricted use of category theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4598</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4598</id><created>2009-05-28</created><authors><author><keyname>Chirilov</keyname><forenames>Claudiu</forenames></author></authors><title>Iterative Methods for Systems' Solving - a C# approach</title><categories>cs.MS</categories><comments>8 pages,exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009), 71-78</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work wishes to support various mathematical issues concerning the
iterative methods with the help of new programming languages. We consider a way
to show how problems in math have an answer by using different academic
resources and different thoughts. Here we treat methods like Gauss-Seidel's,
Cramer's and Gauss-Jordan's.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4601</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4601</id><created>2009-05-28</created><authors><author><keyname>Cicortas</keyname><forenames>Alexandru</forenames></author><author><keyname>Iordan</keyname><forenames>Victoria Stana</forenames></author><author><keyname>Fortis</keyname><forenames>Alexandra Emilia</forenames></author></authors><title>Considerations on Construction Ontologies</title><categories>cs.AI</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),79-88</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes an analysis on some existent ontologies, in order to point
out ways to resolve semantic heterogeneity in information systems. Authors are
highlighting the tasks in a Knowledge Acquisiton System and identifying aspects
related to the addition of new information to an intelligent system. A solution
is proposed, as a combination of ontology reasoning services and natural
languages generation. A multi-agent system will be conceived with an extractor
agent, a reasoner agent and a competence management agent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4604</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4604</id><created>2009-05-28</created><authors><author><keyname>Cojocariu</keyname><forenames>Adrian</forenames></author><author><keyname>Stanciu</keyname><forenames>Cristina Ofelia</forenames></author></authors><title>XML Technologies in Computer Assisted Learning and Testing Systems</title><categories>cs.OH</categories><comments>6 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),89-94</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The learning and assessment activities have undergone major changes due to
the development of modern technologies. The computer-assisted learning and
testing has proven a number of advantages in the development of modern
educational system. The paper suggests a solution for the computer-assisted
testing, which uses XML technologies, a solution that could make the basis for
developing a learning computer-assisted system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4605</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4605</id><created>2009-05-28</created><authors><author><keyname>Crista</keyname><forenames>Ovidiu</forenames></author></authors><title>Techniques for Securing Data Exchange between a Database Server and a
  Client Program</title><categories>cs.DB</categories><comments>6 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),95-100</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of the presented work is to illustrate a method by which the data
exchange between a standalone computer software and a shared database server
can be protected of unauthorized interceptation of the traffic in Internet
network, a transport network for data managed by those two systems,
interceptation by which an attacker could gain illegetimate access to the
database, threatening this way the data integrity and compromising the
database.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4608</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4608</id><created>2009-05-28</created><authors><author><keyname>Fintineanu</keyname><forenames>Georgiana-Petruta</forenames></author><author><keyname>Pintea</keyname><forenames>Florentina Anica</forenames></author></authors><title>Designing a Framework to Develop WEB Graphical Interfaces for ORACLE
  Databases - Web Dialog</title><categories>cs.OH</categories><comments>6 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),125-130</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present article aims to describe a project consisting in designing a
framework of applications used to create graphical interfaces with an Oracle
distributed database. The development of the project supposed the use of the
latest technologies: database Oracle server, Tomcat web server, JDBC (Java
library used for accessing a database), JSP and Tag Library (for the
development of graphical interfaces).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4610</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4610</id><created>2009-05-28</created><authors><author><keyname>Fortis</keyname><forenames>Alexandra-Emilia</forenames></author></authors><title>Indexing Research Papers in Open Access Databases</title><categories>cs.DL</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),131-140</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper synthesizes the actions performed in order to transform a classic
scientific research journal - 'Annals. Computer Science Series' - available
only in printed form until 2008, into a modern e-journal with free access to
the full text of the articles. For achieving this goal, the research papers
have been included in various article databases, portals and library catalogs
which offered a high visibility to the journal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4611</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4611</id><created>2009-05-28</created><authors><author><keyname>Iacob</keyname><forenames>Ioana</forenames></author></authors><title>The Effectiveness of Computer Assisted Classes for English as a Second
  Language</title><categories>cs.OH</categories><comments>8 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),141-148</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present study aims to evaluate the efficiency of the computer assisted
English classes and to emphasize the necessity of developing sound
methodological strategies adjusted to the new technology. It also present the
benefits of using the computer in the pre-school and elementary school classes,
highlighted by a report on the comparative observation of four groups of
children studying English in a computer assisted environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4612</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4612</id><created>2009-05-28</created><updated>2009-05-29</updated><authors><author><keyname>Bergstra</keyname><forenames>Jan A.</forenames></author><author><keyname>Bethke</keyname><forenames>Inge</forenames></author></authors><title>Straight-line instruction sequence completeness for total calculation on
  cancellation meadows</title><categories>cs.LO</categories><comments>24 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A combination of program algebra with the theory of meadows is designed
leading to a theory of computation in algebraic structures which use in
addition to a zero test and copying instructions the instruction set $\{x
\Leftarrow 0, x \Leftarrow 1, x\Leftarrow -x, x\Leftarrow x^{-1}, x\Leftarrow
x+y, x\Leftarrow x\cdot y\}$. It is proven that total functions on cancellation
meadows can be computed by straight-line programs using at most 5 auxiliary
variables. A similar result is obtained for signed meadows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4613</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4613</id><created>2009-05-28</created><authors><author><keyname>Ilea</keyname><forenames>Daniela</forenames></author></authors><title>Athos - The C# GUI Generator</title><categories>cs.SE</categories><comments>8 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),149-156</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This application comes to help software architects and developers during the
long process between user's stories, designing the application's structure and
actually coding it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4614</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4614</id><created>2009-05-28</created><updated>2013-04-29</updated><authors><author><keyname>Artikis</keyname><forenames>A.</forenames></author><author><keyname>Sergot</keyname><forenames>M.</forenames></author><author><keyname>Paliouras</keyname><forenames>G.</forenames></author></authors><title>A Logic Programming Approach to Activity Recognition</title><categories>cs.AI</categories><comments>The original publication is available in the Proceedings of the 2nd
  ACM international workshop on Events in multimedia, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We have been developing a system for recognising human activity given a
symbolic representation of video content. The input of our system is a set of
time-stamped short-term activities detected on video frames. The output of our
system is a set of recognised long-term activities, which are pre-defined
temporal combinations of short-term activities. The constraints on the
short-term activities that, if satisfied, lead to the recognition of a
long-term activity, are expressed using a dialect of the Event Calculus. We
illustrate the expressiveness of the dialect by showing the representation of
several typical complex activities. Furthermore, we present a detailed
evaluation of the system through experimentation on a benchmark dataset of
surveillance videos.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4627</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4627</id><created>2009-05-28</created><updated>2009-06-01</updated><authors><author><keyname>Bolettieri</keyname><forenames>Paolo</forenames></author><author><keyname>Esuli</keyname><forenames>Andrea</forenames></author><author><keyname>Falchi</keyname><forenames>Fabrizio</forenames></author><author><keyname>Lucchese</keyname><forenames>Claudio</forenames></author><author><keyname>Perego</keyname><forenames>Raffaele</forenames></author><author><keyname>Piccioli</keyname><forenames>Tommaso</forenames></author><author><keyname>Rabitti</keyname><forenames>Fausto</forenames></author></authors><title>CoPhIR: a Test Collection for Content-Based Image Retrieval</title><categories>cs.MM cs.IR</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The scalability, as well as the effectiveness, of the different Content-based
Image Retrieval (CBIR) approaches proposed in literature, is today an important
research issue. Given the wealth of images on the Web, CBIR systems must in
fact leap towards Web-scale datasets. In this paper, we report on our
experience in building a test collection of 100 million images, with the
corresponding descriptive features, to be used in experimenting new scalable
techniques for similarity searching, and comparing their results. In the
context of the SAPIR (Search on Audio-visual content using Peer-to-peer
Information Retrieval) European project, we had to experiment our distributed
similarity searching technology on a realistic data set. Therefore, since no
large-scale collection was available for research purposes, we had to tackle
the non-trivial process of image crawling and descriptive feature extraction
(we used five MPEG-7 features) using the European EGEE computer GRID. The
result of this effort is CoPhIR, the first CBIR test collection of such scale.
CoPhIR is now open to the research community for experiments and comparisons,
and access to the collection was already granted to more than 50 research
groups worldwide.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4656</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4656</id><created>2009-05-28</created><authors><author><keyname>Li</keyname><forenames>Zhiheng</forenames></author><author><keyname>Li</keyname><forenames>Li</forenames></author><author><keyname>Chen</keyname><forenames>Yudong</forenames></author><author><keyname>Zhang</keyname><forenames>Yi</forenames></author></authors><title>Quantization Errors of fGn and fBm Signals</title><categories>cs.IT math.IT</categories><journal-ref>Zhiheng Li, Yudong Chen, Li Li*, Yi Zhang, &quot;Quantization errors of
  uniformly quantized fGn and fBm signals,&quot; IEEE Signal Processing Letters,
  vol. 16, no. 12, pp. 1059-1062, 2009.</journal-ref><doi>10.1109/LSP.2009.2030115</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this Letter, we show that under the assumption of high resolution, the
quantization errors of fGn and fBm signals with uniform quantizer can be
treated as uncorrelated white noises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4684</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4684</id><created>2009-05-28</created><authors><author><keyname>Xin</keyname><forenames>Yan</forenames></author><author><keyname>Zhang</keyname><forenames>Honghai</forenames></author></authors><title>A Simple Sequential Spectrum Sensing Scheme for Cognitive Radio</title><categories>cs.IT math.IT</categories><comments>29 pages, 3 figures, submitted to IEEE Transactions on Signal
  Processing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio that supports a secondary and opportunistic access to
licensed spectrum shows great potential to dramatically improve spectrum
utilization. Spectrum sensing performed by secondary users to detect unoccupied
spectrum bands, is a key enabling technique for cognitive radio. This paper
proposes a truncated sequential spectrum sensing scheme, namely the sequential
shifted chi-square test (SSCT). The SSCT has a simple test statistic and does
not rely on any deterministic knowledge about primary signals. As figures of
merit, the exact false-alarm probability is derived, and the miss-detection
probability as well as the average sample number (ASN) are evaluated by using a
numerical integration algorithm. Corroborating numerical examples show that, in
comparison with fixed-sample size detection schemes such as energy detection,
the SSCT delivers considerable reduction on the ASN while maintaining a
comparable detection performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4700</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4700</id><created>2009-05-28</created><authors><author><keyname>Ho</keyname><forenames>Zuleita Ka Ming</forenames></author><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Cheng</keyname><forenames>Roger S. K.</forenames></author></authors><title>Cross-Layer Design of FDD-OFDM Systems based on ACK/NAK Feedbacks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well-known that cross-layer scheduling which adapts power, rate and
user allocation can achieve significant gain on system capacity. However,
conventional cross-layer designs all require channel state information at the
base station (CSIT) which is difficult to obtain in practice. In this paper, we
focus on cross-layer resource optimization based on ACK/NAK feedback flows in
OFDM systems without explicit CSIT. While the problem can be modeled as Markov
Decision Process (MDP), brute force approach by policy iteration or value
iteration cannot lead to any viable solution. Thus, we derive a simple
closed-form solution for the MDP cross-layer problem, which is asymptotically
optimal for sufficiently small target packet error rate (PER). The proposed
solution also has low complexity and is suitable for realtime implementation.
It is also shown to achieve significant performance gain compared with systems
that do not utilize the ACK/NAK feedbacks for cross-layer designs or
cross-layer systems that utilize very unreliable CSIT for adaptation with
mismatch in CSIT error statistics. Asymptotic analysis is also provided to
obtain useful design insights.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4713</identifier>
 <datestamp>2009-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4713</id><created>2009-05-28</created><authors><author><keyname>Kwuida</keyname><forenames>Leonard</forenames></author><author><keyname>Missaoui</keyname><forenames>Rokia</forenames></author><author><keyname>Boumedjout</keyname><forenames>Lahcen</forenames></author><author><keyname>Vaillancourt</keyname><forenames>Jean</forenames></author></authors><title>Mining Generalized Patterns from Large Databases using Ontologies</title><categories>cs.AI cs.DB cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal Concept Analysis (FCA) is a mathematical theory based on the
formalization of the notions of concept and concept hierarchies. It has been
successfully applied to several Computer Science fields such as data
mining,software engineering, and knowledge engineering, and in many domains
like medicine, psychology, linguistics and ecology. For instance, it has been
exploited for the design, mapping and refinement of ontologies. In this paper,
we show how FCA can benefit from a given domain ontology by analyzing the
impact of a taxonomy (on objects and/or attributes) on the resulting concept
lattice. We willmainly concentrate on the usage of a taxonomy to extract
generalized patterns (i.e., knowledge generated from data when elements of a
given domain ontology are used) in the form of concepts and rules, and improve
navigation through these patterns. To that end, we analyze three generalization
cases and show their impact on the size of the generalized pattern set.
Different scenarios of simultaneous generalizations on both objects and
attributes are also discussed
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4717</identifier>
 <datestamp>2012-02-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4717</id><created>2009-05-28</created><updated>2011-10-31</updated><authors><author><keyname>Nojoumian</keyname><forenames>Mehrdad</forenames></author><author><keyname>Lethbridge</keyname><forenames>Timothy C.</forenames></author></authors><title>Reengineering PDF-Based Documents Targeting Complex Software
  Specifications</title><categories>cs.DL</categories><comments>27 pages, 15 figures; International Journal of Knowledge and Web
  Intelligence (IJKWI), Inderscience Publishers, 2011</comments><acm-class>I.7.2; I.7.5; H.5.2; H.5.4; H.3.3; H.3.6</acm-class><journal-ref>International Journal of Knowledge and Web Intelligence (IJKWI),
  Inderscience, vol. 2, no. 4, pp. 292-319, 2011</journal-ref><doi>10.1504/IJKWI.2011.045165</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article aims at reengineering of PDF-based complex documents, where
specifications of the Object Management Group (OMG) are our initial targets.
Our motivation is that such specifications are dense and intricate to use, and
tend to have complicated structures. Our objective is therefore to create an
approach that allows us to reengineer PDF-based documents, and to illustrate
how to make more usable versions of electronic documents (such as
specifications, technical books, etc) so that end users to have a better
experience with them. The first step was to extract the logical structure of
the document in a meaningful XML format for subsequent processing. Our initial
assumption was that, many key concepts of a document are expressed in this
structure. In the next phase, we created a multilayer hypertext version of the
document to facilitate browsing and navigating. Although we initially focused
on OMG software specifications, we chose a general approach for different
phases of our work including format conversions, logical structure extraction,
text extraction, multilayer hypertext generation, and concept exploration. As a
consequence, we can process other complex documents to achieve our goals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4745</identifier>
 <datestamp>2009-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4745</id><created>2009-05-28</created><updated>2009-09-08</updated><authors><author><keyname>Tygert</keyname><forenames>Mark</forenames></author></authors><title>A fast algorithm for computing minimal-norm solutions to underdetermined
  systems of linear equations</title><categories>cs.NA</categories><comments>13 pages, 4 tables</comments><report-no>UCLA Computational and Applied Math. Technical Report 09-48</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a randomized algorithm for computing the minimal-norm solution
to an underdetermined system of linear equations. Given an arbitrary full-rank
m x n matrix A with m&lt;n, any m x 1 vector b, and any positive real number
epsilon less than 1, the procedure computes an n x 1 vector x approximating to
relative precision epsilon or better the n x 1 vector p of minimal Euclidean
norm satisfying Ap=b. The algorithm typically requires O(mn
log(sqrt(n)/epsilon) + m**3) floating-point operations, generally less than the
O(m**2 n) required by the classical schemes based on QR-decompositions or
bidiagonalization. We present several numerical examples illustrating the
performance of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4757</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4757</id><created>2009-05-28</created><updated>2011-07-27</updated><authors><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Stochastic Optimization for Markov Modulated Networks with Application
  to Delay Constrained Wireless Scheduling</title><categories>math.OC cs.SY</categories><comments>This version adds an author and includes simulation results. It also
  corrects an error in the earlier version of this arxiv tech report,
  concerning use of a norm defined in terms of expectations (see footnote 4 of
  the current version for a discussion of the error). The current paper uses a
  standard norm without expectations</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless system with a small number of delay constrained users
and a larger number of users without delay constraints. We develop a scheduling
algorithm that reacts to time varying channels and maximizes throughput utility
(to within a desired proximity), stabilizes all queues, and satisfies the delay
constraints. The problem is solved by reducing the constrained optimization to
a set of weighted stochastic shortest path problems, which act as natural
generalizations of max-weight policies to Markov decision networks. We also
present approximation results for the corresponding shortest path problems, and
discuss the additional complexity and delay incurred as compared to systems
without delay constraints. The solution technique is general and applies to
other constrained stochastic decision problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4761</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4761</id><created>2009-05-28</created><authors><author><keyname>Leighton</keyname><forenames>Gregory</forenames></author><author><keyname>Barbosa</keyname><forenames>Denilson</forenames></author></authors><title>Optimizing XML Compression</title><categories>cs.DB</categories><comments>16 pages, extended version of paper accepted for XSym 2009</comments><acm-class>H.2.0</acm-class><doi>10.1007/978-3-642-03555-5_8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The eXtensible Markup Language (XML) provides a powerful and flexible means
of encoding and exchanging data. As it turns out, its main advantage as an
encoding format (namely, its requirement that all open and close markup tags
are present and properly balanced) yield also one of its main disadvantages:
verbosity. XML-conscious compression techniques seek to overcome this drawback.
Many of these techniques first separate XML structure from the document
content, and then compress each independently. Further compression gains can be
realized by identifying and compressing together document content that is
highly similar, thereby amortizing the storage costs of auxiliary information
required by the chosen compression algorithm. Additionally, the proper choice
of compression algorithm is an important factor not only for the achievable
compression gain, but also for access performance. Hence, choosing a
compression configuration that optimizes compression gain requires one to
determine (1) a partitioning strategy for document content, and (2) the best
available compression algorithm to apply to each set within this partition. In
this paper, we show that finding an optimal compression configuration with
respect to compression gain is an NP-hard optimization problem. This problem
remains intractable even if one considers a single compression algorithm for
all content. We also describe an approximation algorithm for selecting a
partitioning strategy for document content based on the branch-and-bound
paradigm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4771</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4771</id><created>2009-05-28</created><updated>2010-12-14</updated><authors><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Valocchi</keyname><forenames>A. J.</forenames></author></authors><title>Variational structure of the optimal artificial diffusion method for the
  advection-diffusion equation</title><categories>cs.CE cs.NA</categories><comments>2 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research note we provide a variational basis for the optimal
artificial diffusion method, which has been a cornerstone in developing many
stabilized methods. The optimal artificial diffusion method produces exact
nodal solutions when applied to one-dimensional problems with constant
coefficients and forcing function. We first present a variational principle for
a multi-dimensional advective-diffusive system, and then derive a new stable
weak formulation. When applied to one-dimensional problems with constant
coefficients and forcing function, this resulting weak formulation will be
equivalent to the optimal artificial diffusion method. We present
representative numerical results to corroborate our theoretical findings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4813</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4813</id><created>2009-05-29</created><updated>2009-09-15</updated><authors><author><keyname>Ghani</keyname><forenames>Neil</forenames></author><author><keyname>Hancock</keyname><forenames>Peter</forenames></author><author><keyname>Pattinson</keyname><forenames>Dirk</forenames></author></authors><title>Representations of Stream Processors Using Nested Fixed Points</title><categories>cs.DS cs.LO</categories><acm-class>E.1; E.2; F.2.1; F.2.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (September
  15, 2009) lmcs:713</journal-ref><doi>10.2168/LMCS-5(3:9)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define representations of continuous functions on infinite streams of
discrete values, both in the case of discrete-valued functions, and in the case
of stream-valued functions. We define also an operation on the representations
of two continuous functions between streams that yields a representation of
their composite.
  In the case of discrete-valued functions, the representatives are
well-founded (finite-path) trees of a certain kind. The underlying idea can be
traced back to Brouwer's justification of bar-induction, or to Kreisel and
Troelstra's elimination of choice-sequences. In the case of stream-valued
functions, the representatives are non-wellfounded trees pieced together in a
coinductive fashion from well-founded trees. The definition requires an
alternating fixpoint construction of some ubiquity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4850</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4850</id><created>2009-05-29</created><authors><author><keyname>Garcia-Alfaro</keyname><forenames>Joaquin</forenames></author><author><keyname>Navarro-Arribas</keyname><forenames>Guillermo</forenames></author></authors><title>A Survey on Cross-Site Scripting Attacks</title><categories>cs.CR</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web applications are becoming truly pervasive in all kinds of business models
and organizations. Today, most critical systems such as those related to health
care, banking, or even emergency response, are relying on these applications.
They must therefore include, in addition to the expected value offered to their
users, reliable mechanisms to ensure their security. In this paper, we focus on
the specific problem of cross-site scripting attacks against web applications.
We present a study of this kind of attacks, and survey current approaches for
their prevention. Applicability and limitations of each proposal are also
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4860</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4860</id><created>2009-05-29</created><authors><author><keyname>Isac</keyname><forenames>Alin</forenames></author><author><keyname>Isac</keyname><forenames>Claudia</forenames></author></authors><title>Informatics Issues Used in the Production Dashboard</title><categories>cs.OH</categories><comments>6 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),157-162</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to present some computer aspects regarding the
implementation and the employing of a dashboard in relation to the production
activity. The paper begins with the theoretical presentation of the managerial
perspective regarding the necessity of using the dashboard. The main functions
of the dashboard in the production activity and the way it is employed are
presented in the second part of the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4863</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4863</id><created>2009-05-29</created><authors><author><keyname>Jasmine</keyname><forenames>K. S.</forenames></author><author><keyname>Vasantha</keyname><forenames>R.</forenames></author></authors><title>Derivation of UML Based Performance Models for Design Assessment in a
  Reuse Based Software Development Approach</title><categories>cs.SE</categories><comments>18 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),163-180</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reuse-based software development provides an opportunity for better quality
and increased productivity in the software products. One of the most critical
aspects of the quality of a software system is its performance. The systematic
application of software performance engineering techniques throughout the
development process can help to identify design alternatives that preserve
desirable qualities such as extensibility and reusability while meeting
performance objectives. In the present scenario, most of the performance
failures are due to a lack of consideration of performance issues early in the
development process, especially in the design phase. These performance failures
results in damaged customer relations, lost productivity for users, cost
overruns due to tuning or redesign, and missed market windows. In this paper,
we propose UML based Performance Models for design assessment in a reuse based
software development scenario.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4864</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4864</id><created>2009-05-29</created><authors><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author><author><keyname>Crista</keyname><forenames>Ovidiu</forenames></author><author><keyname>Tuican</keyname><forenames>Catalin</forenames></author></authors><title>Computer Based Interpretation of the Students' Evaluation of the
  Teaching Staff</title><categories>cs.HC</categories><comments>8 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),181-188</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to offer a full support for universities and
quality assessment committees in retrieving the feedback from their students
regarding to their teaching staff. The computer based application presented
before ([Cri07]) collects data from the students. Another part of the
application, presented in this paper, processes this data and presents the
statistical results concerning each teacher.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4887</identifier>
 <datestamp>2009-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4887</id><created>2009-05-29</created><authors><author><keyname>de Silva</keyname><forenames>Vin</forenames></author><author><keyname>Vejdemo-Johansson</keyname><forenames>Mikael</forenames></author></authors><title>Persistent Cohomology and Circular Coordinates</title><categories>math.AT cs.CG</categories><comments>10 pages, 7 figures. To appear in the proceedings of the ACM
  Symposium on Computational Geometry 2009</comments><msc-class>55-04; 62H25</msc-class><journal-ref>SCG '09: Proceedings of the 25th annual symposium on Computational
  geometry (2009) pp 227--236</journal-ref><doi>10.1145/1542362.1542406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonlinear dimensionality reduction (NLDR) algorithms such as Isomap, LLE and
Laplacian Eigenmaps address the problem of representing high-dimensional
nonlinear data in terms of low-dimensional coordinates which represent the
intrinsic structure of the data. This paradigm incorporates the assumption that
real-valued coordinates provide a rich enough class of functions to represent
the data faithfully and efficiently. On the other hand, there are simple
structures which challenge this assumption: the circle, for example, is
one-dimensional but its faithful representation requires two real coordinates.
In this work, we present a strategy for constructing circle-valued functions on
a statistical data set. We develop a machinery of persistent cohomology to
identify candidates for significant circle-structures in the data, and we use
harmonic smoothing and integration to obtain the circle-valued coordinate
functions themselves. We suggest that this enriched class of coordinate
functions permits a precise NLDR analysis of a broader range of realistic data
sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4902</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4902</id><created>2009-05-29</created><authors><author><keyname>Lacrama</keyname><forenames>Dan L.</forenames></author><author><keyname>Snep</keyname><forenames>Ioan</forenames></author></authors><title>Flexible frontiers for text division into rows</title><categories>cs.OH</categories><comments>6 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),199-204</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an original solution for flexible hand-written text
division into rows. Unlike the standard procedure, the proposed method avoids
the isolated characters extensions amputation and reduces the recognition error
rate in the final stage.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4905</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4905</id><created>2009-05-29</created><authors><author><keyname>Luca</keyname><forenames>Lucian</forenames></author><author><keyname>Luca</keyname><forenames>Lucian L.</forenames></author></authors><title>Aspects Regarding Operations with Fuzzy Processes</title><categories>cs.LO</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),205-214</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the notion of fuzzy process as a formalism for the idea
of fuzzy contact between a device and its environment. The notions of absolute
correctness and relative correctness are defined. In order to work with
concurrency it has been built an approach to manipulate the interactive
processes as a single process and the resulted behavior has been observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4906</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4906</id><created>2009-05-29</created><authors><author><keyname>Luca</keyname><forenames>Lucian</forenames></author><author><keyname>Luca</keyname><forenames>Lucian L.</forenames></author></authors><title>On Some Manipulations with Fuzzy Processes</title><categories>cs.LO</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),215-224</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper starts from the observation on the complexity of the manipulation
of fuzzy processes that increases very rapidly with the extents of the
processes representation. Therefore, a productive approach is to divide the
problem into smaller parts, treated separately and then the results combined.
Some algebraic results obtained by the authors are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4909</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4909</id><created>2009-05-29</created><authors><author><keyname>Maruster</keyname><forenames>Laura</forenames></author><author><keyname>Maruster</keyname><forenames>Stefan</forenames></author></authors><title>On the Convex Feasibility Problem</title><categories>cs.NA</categories><comments>14 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),225-238</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The convergence of the projection algorithm for solving the convex
feasibility problem for a family of closed convex sets, is in connection with
the regularity properties of the family. In the paper [18] are pointed out four
cases of such a family depending of the two characteristics: the emptiness and
boudedness of the intersection of the family. The case four (the interior of
the intersection is empty and the intersection itself is bounded) is unsolved.
In this paper we give a (partial) answer for the case four: in the case of two
closed convex sets in R3 the regularity property holds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4918</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4918</id><created>2009-05-29</created><authors><author><keyname>Pujol</keyname><forenames>Josep M.</forenames></author><author><keyname>Erramilli</keyname><forenames>Vijay</forenames></author><author><keyname>Rodriguez</keyname><forenames>Pablo</forenames></author></authors><title>Divide and Conquer: Partitioning Online Social Networks</title><categories>cs.NI cs.AI cs.DC</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online Social Networks (OSNs) have exploded in terms of scale and scope over
the last few years. The unprecedented growth of these networks present
challenges in terms of system design and maintenance. One way to cope with this
is by partitioning such large networks and assigning these partitions to
different machines. However, social networks possess unique properties that
make the partitioning problem non-trivial. The main contribution of this paper
is to understand different properties of social networks and how these
properties can guide the choice of a partitioning algorithm. Using large scale
measurements representing real OSNs, we first characterize different properties
of social networks, and then we evaluate qualitatively different partitioning
methods that cover the design space. We expose different trade-offs involved
and understand them in light of properties of social networks. We show that a
judicious choice of a partitioning scheme can help improve performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4923</identifier>
 <datestamp>2010-10-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4923</id><created>2009-05-29</created><updated>2010-10-04</updated><authors><author><keyname>Currie</keyname><forenames>James D.</forenames></author></authors><title>Lexicographically least words in the orbit closure of the Rudin-Shapiro
  word</title><categories>cs.FL math.CO</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an effective characterization of the lexicographically least word in
the orbit closure of the Rudin-Shapiro word w having a specified prefix. In
particular, the lexicographically least word in the orbit closure of the
Rudin-Shapiro word is 0w. This answers a question Allouche et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4926</identifier>
 <datestamp>2009-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4926</id><created>2009-05-29</created><authors><author><keyname>Mordachev</keyname><forenames>Vladimir</forenames></author><author><keyname>Loyka</keyname><forenames>Sergey</forenames></author></authors><title>On Node Density -- Outage Probability Tradeoff in Wireless Networks</title><categories>cs.IT math.IT</categories><comments>IEEE Journal on Selected Areas in Communications, accepted, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A statistical model of interference in wireless networks is considered, which
is based on the traditional propagation channel model and a Poisson model of
random spatial distribution of nodes in 1-D, 2-D and 3-D spaces with both
uniform and non-uniform densities. The power of nearest interferer is used as a
major performance indicator, instead of a traditionally-used total interference
power, since at the low outage region, they have the same statistics so that
the former is an accurate approximation of the latter. This simplifies the
problem significantly and allows one to develop a unified framework for the
outage probability analysis, including the impacts of complete/partial
interference cancelation, of different types of fading and of linear filtering,
either alone or in combination with each other. When a given number of nearest
interferers are completely canceled, the outage probability is shown to scale
down exponentially in this number. Three different models of partial
cancelation are considered and compared via their outage probabilities. The
partial cancelation level required to eliminate the impact of an interferer is
quantified. The effect of a broad class of fading processes (including all
popular fading models) is included in the analysis in a straightforward way,
which can be positive or negative depending on a particular model and
propagation/system parameters. The positive effect of linear filtering (e.g. by
directional antennas) is quantified via a new statistical selectivity
parameter. The analysis results in formulation of a tradeoff relationship
between the network density and the outage probability, which is a result of
the interplay between random geometry of node locations, the propagation path
loss and the distortion effects at the victim receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4930</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4930</id><created>2009-05-29</created><updated>2009-09-02</updated><authors><author><keyname>Biedl</keyname><forenames>Therese</forenames></author><author><keyname>Durocher</keyname><forenames>Stephane</forenames></author><author><keyname>Hoos</keyname><forenames>Holger H.</forenames></author><author><keyname>Luan</keyname><forenames>Shuang</forenames></author><author><keyname>Saia</keyname><forenames>Jared</forenames></author><author><keyname>Young</keyname><forenames>Maxwell</forenames></author></authors><title>Improved Approximation Algorithms for Segment Minimization in Intensity
  Modulated Radiation Therapy</title><categories>cs.DS</categories><comments>18 pages</comments><journal-ref>&quot;A Note on Improving the Performance of Approximation Algorithms
  for Radiation Therapy''. Information Processing Letters, 111(7), 326-333,
  2011</journal-ref><doi>10.1016/j.ipl.2010.12.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  he segment minimization problem consists of finding the smallest set of
integer matrices that sum to a given intensity matrix, such that each summand
has only one non-zero value, and the non-zeroes in each row are consecutive.
This has direct applications in intensity-modulated radiation therapy, an
effective form of cancer treatment. We develop three approximation algorithms
for matrices with arbitrarily many rows. Our first two algorithms improve the
approximation factor from the previous best of $1+\log_2 h $ to (roughly) $3/2
\cdot (1+\log_3 h)$ and $11/6\cdot(1+\log_4{h})$, respectively, where $h$ is
the largest entry in the intensity matrix. We illustrate the limitations of the
specific approach used to obtain these two algorithms by proving a lower bound
of $\frac{(2b-2)}{b}\cdot\log_b{h} + \frac{1}{b}$ on the approximation
guarantee. Our third algorithm improves the approximation factor from $2 \cdot
(\log D+1)$ to $24/13 \cdot (\log D+1)$, where $D$ is (roughly) the largest
difference between consecutive elements of a row of the intensity matrix.
Finally, experimentation with these algorithms shows that they perform well
with respect to the optimum and outperform other approximation algorithms on
77% of the 122 test cases we consider, which include both real world and
synthetic data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0905.4937</identifier>
 <datestamp>2014-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0905.4937</id><created>2009-05-29</created><updated>2014-12-26</updated><authors><author><keyname>Ryabko</keyname><forenames>Daniil</forenames><affiliation>INRIA Futurs, LIFL, INRIA Lille - Nord Europe</affiliation></author></authors><title>A criterion for hypothesis testing for stationary processes</title><categories>math.ST cs.IT math.IT math.PR stat.TH</categories><comments>part or this report appeared as: Test, vol. 21(2), pp. 317-329, 2012</comments><proxy>ccsd inria-00389689</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a finite-valued sample $X_1,...,X_n$ we wish to test whether it was
generated by a stationary ergodic process belonging to a family $H_0$, or it
was generated by a stationary ergodic process outside $H_0$. We require the
Type I error of the test to be uniformly bounded, while the type II error has
to be mande not more than a finite number of times with probability 1. For this
notion of consistency we provide necessary and sufficient conditions on the
family $H_0$ for the existence of a consistent test. This criterion is
illustrated with applications to testing for a membership to parametric
families, generalizing some existing results. In addition, we analyze a
stronger notion of consistency, which requires finite-sample guarantees on
error of both types, and provide some necessary and some sufficient conditions
for the existence of a consistent test. We emphasize that no assumption on the
process distributions are made beyond stationarity and ergodicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0037</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0037</id><created>2009-05-29</created><authors><author><keyname>Fawaz</keyname><forenames>Nadia</forenames></author><author><keyname>Zarifi</keyname><forenames>Keyvan</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author></authors><title>Asymptotic Capacity and Optimal Precoding in MIMO Multi-Hop Relay
  Networks</title><categories>cs.IT math.IT</categories><comments>45 pages, 7 figures, submitted to IEEE Transactions on Information
  Theory, December 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multi-hop relaying system is analyzed where data sent by a multi-antenna
source is relayed by successive multi-antenna relays until it reaches a
multi-antenna destination. Assuming correlated fading at each hop, each relay
receives a faded version of the signal from the previous level, performs linear
precoding and retransmits it to the next level. Using free probability theory
and assuming that the noise power at relaying levels-- but not at destination--
is negligible, the closed-form expression of the asymptotic instantaneous
end-to-end mutual information is derived as the number of antennas at all
levels grows large. The so-obtained deterministic expression is independent
from the channel realizations while depending only on channel statistics.
Moreover, it also serves as the asymptotic value of the average end-to-end
mutual information. The optimal singular vectors of the precoding matrices that
maximize the average mutual information with finite number of antennas at all
levels are also provided. It turns out that the optimal precoding singular
vectors are aligned to the eigenvectors of the channel correlation matrices.
Thus they can be determined using only the known channel statistics. As the
optimal precoding singular vectors are independent from the system size, they
are also optimal in the asymptotic regime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0049</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0049</id><created>2009-05-29</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author><author><keyname>Debbabi</keyname><forenames>Mourad</forenames></author></authors><title>Towards Automated Deduction in Blackmail Case Analysis with Forensic
  Lucid</title><categories>cs.LO cs.CR cs.PL</categories><comments>11 pages, 7 figures; related to arXiv:0904.3789 and arXiv:0905.2449</comments><acm-class>D.3.1; D.3.2; D.3.3; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work-in-progress focuses on the refinement of application of the
intensional logic to cyberforensic analysis and its benefits are compared with
the finite-state automata approach. This work extends the use of the scientific
intensional programming paradigm onto modeling and implementation of a
cyberforensics investigation process with the backtrace of event
reconstruction, modeling the evidence as multidimensional hierarchical
contexts, and proving or disproving the claims with it in the intensional
manner of evaluation. This is a practical, context-aware improvement over the
finite state automata (FSA) approach we have seen in the related works. As a
base implementation language model we use in this approach is a new dialect of
the Lucid programming language, that we call Forensic Lucid and in this paper
we focus on defining hierarchical contexts based on the intensional logic for
the evaluation of cyberforensic expressions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0052</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0052</id><created>2009-05-29</created><authors><author><keyname>Tomasik</keyname><forenames>Brian</forenames></author></authors><title>A Minimum Description Length Approach to Multitask Feature Selection</title><categories>cs.LG cs.AI</categories><comments>29 pages, 3 figures, undergraduate thesis</comments><acm-class>I.2.6; G.3; J.3</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Many regression problems involve not one but several response variables
(y's). Often the responses are suspected to share a common underlying
structure, in which case it may be advantageous to share information across
them; this is known as multitask learning. As a special case, we can use
multiple responses to better identify shared predictive features -- a project
we might call multitask feature selection.
  This thesis is organized as follows. Section 1 introduces feature selection
for regression, focusing on ell_0 regularization methods and their
interpretation within a Minimum Description Length (MDL) framework. Section 2
proposes a novel extension of MDL feature selection to the multitask setting.
The approach, called the &quot;Multiple Inclusion Criterion&quot; (MIC), is designed to
borrow information across regression tasks by more easily selecting features
that are associated with multiple responses. We show in experiments on
synthetic and real biological data sets that MIC can reduce prediction error in
settings where features are at least partially shared across responses. Section
3 surveys hypothesis testing by regression with a single response, focusing on
the parallel between the standard Bonferroni correction and an MDL approach.
Mirroring the ideas in Section 2, Section 4 proposes a novel MIC approach to
hypothesis testing with multiple responses and shows that on synthetic data
with significant sharing of features across responses, MIC sometimes
outperforms standard FDR-controlling methods in terms of finding true positives
for a given level of false positives. Section 5 concludes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0060</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0060</id><created>2009-05-30</created><updated>2011-06-17</updated><authors><author><keyname>Gjoka</keyname><forenames>Minas</forenames></author><author><keyname>Kurant</keyname><forenames>Maciej</forenames></author><author><keyname>Butts</keyname><forenames>Carter T.</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author></authors><title>A Walk in Facebook: Uniform Sampling of Users in Online Social Networks</title><categories>cs.SI cs.NI physics.data-an physics.soc-ph stat.ME</categories><comments>published in IEEE INFOCOM '10; IEEE Journal on Selected Areas in
  Communications (JSAC), Special Issue on Measurement of Internet Topologies,
  2011 under the title &quot;Practical Recommendations on Crawling Online Social
  Networks&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our goal in this paper is to develop a practical framework for obtaining a
uniform sample of users in an online social network (OSN) by crawling its
social graph. Such a sample allows to estimate any user property and some
topological properties as well. To this end, first, we consider and compare
several candidate crawling techniques. Two approaches that can produce
approximately uniform samples are the Metropolis-Hasting random walk (MHRW) and
a re-weighted random walk (RWRW). Both have pros and cons, which we demonstrate
through a comparison to each other as well as to the &quot;ground truth.&quot; In
contrast, using Breadth-First-Search (BFS) or an unadjusted Random Walk (RW)
leads to substantially biased results. Second, and in addition to offline
performance assessment, we introduce online formal convergence diagnostics to
assess sample quality during the data collection process. We show how these
diagnostics can be used to effectively determine when a random walk sample is
of adequate size and quality. Third, as a case study, we apply the above
methods to Facebook and we collect the first, to the best of our knowledge,
representative sample of Facebook users. We make it publicly available and
employ it to characterize several key properties of Facebook.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0065</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0065</id><created>2009-05-30</created><updated>2009-07-26</updated><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames><affiliation>Concordia University, Montreal, Canada</affiliation></author><author><keyname>Huynh</keyname><forenames>Lee Wei</forenames><affiliation>Concordia University, Montreal, Canada</affiliation></author><author><keyname>Li</keyname><forenames>Jian</forenames><affiliation>Concordia University, Montreal, Canada</affiliation></author></authors><title>Managing Distributed MARF with SNMP</title><categories>cs.DC cs.CV</categories><comments>39 pages, 16 figures, TOC, index. A large portion of this report has
  been published at PDPTA'08. This 2007 report is a successor of the original
  DMARF work documented at arXiv:0905.2459 ; v2 adds missing .ind file for the
  index</comments><acm-class>C.2.4; I.5; I.2.6; D.2.10; D.2.11; D.2.5; D.2.2; I.2.7</acm-class><journal-ref>Proceedings of PDPTA'08 (2008), Volume 2, pp. 948-954</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The scope of this project's work focuses on the research and prototyping of
the extension of the Distributed MARF such that its services can be managed
through the most popular management protocol familiarly, SNMP. The rationale
behind SNMP vs. MARF's proprietary management protocols, is that can be
integrated with the use of common network service and device management, so the
administrators can manage MARF nodes via a already familiar protocol, as well
as monitor their performance, gather statistics, set desired configuration,
etc. perhaps using the same management tools they've been using for other
network devices and application servers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0072</identifier>
 <datestamp>2009-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0072</id><created>2009-06-01</created><updated>2009-06-07</updated><authors><author><keyname>Marcinkowski</keyname><forenames>Jerzy</forenames></author><author><keyname>Michaliszyn</keyname><forenames>Jakub</forenames></author></authors><title>The cost of being co-Buchi is nonlinear</title><categories>cs.FL</categories><comments>12 pages, 4 figures; added information about grand</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is well known, and easy to see, that not each nondeterministic Buchi
automaton on infinite words can be simulated by a nondeterministic co-Buchi
automaton. We show that in the cases when such a simulation is possible, the
number of states needed for it can grow nonlinearly. More precisely, we show a
sequence of - as we believe, simple and elegant - languages which witness the
existence of a nondeterministic Buchi automaton with n states, which can be
simulated by a nondeterministic co-Buchi automaton, but cannot be simulated by
any nondeterministic co-Buchi automaton with less than c*n^{7/6} states for
some constant c. This improves on the best previously known lower bound of
3(n-1)/2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0080</identifier>
 <datestamp>2009-08-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0080</id><created>2009-05-30</created><updated>2009-08-06</updated><authors><author><keyname>Akbar</keyname><forenames>Z.</forenames></author><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>Reverse method for labeling the information from semi-structured web
  pages</title><categories>cs.IR cs.DS</categories><comments>5 pages, Proceeding of the 2009 International Conference on Signal
  Processing Systems pp. 551-555</comments><report-no>FISIKALIPI-09017</report-no><doi>10.1109/ICSPS.2009.86</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new technique to infer the structure and extract the tokens of
data from the semi-structured web sources which are generated using a
consistent template or layout with some implicit regularities. The attributes
are extracted and labeled reversely from the region of interest of targeted
contents. This is in contrast with the existing techniques which always
generate the trees from the root. We argue and show that our technique is
simpler, more accurate and effective especially to detect the changes of the
templates of targeted web pages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0151</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0151</id><created>2009-05-31</created><authors><author><keyname>Hoseininia</keyname><forenames>Mahtab</forenames></author><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author><author><keyname>Esfahani</keyname><forenames>Mir Mehdi Seyyed</forenames></author></authors><title>Inventory competition in a multi channel distribution system: The Nash
  and Stackelberg game</title><categories>cs.GT</categories><comments>20 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates inventory management in a multi channel distribution
system consisting of one manufacturer and an arbitrary number of retailers that
face stochastic demand. Existence of the pure Nash equilibrium is proved and
parameter restriction which implies uniqueness of it is derived. Also the
Stackelberg game where the manufacturer plays a roll as a leader is discussed.
Under specified parameter restrictions which guarantee profitability,
sufficient condition for uniqueness of Stackelberg equilibrium is obtained. In
addition comparison with simultaneous move game is made. The result shows that
when whole prices are equal to production cost, manufacturer carries more
inventory than simultaneous move game. Keywords: Inventory management,
Substitution, Nash equilibrium, Stackelberg equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0202</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0202</id><created>2009-05-31</created><authors><author><keyname>Mohaisen</keyname><forenames>Abedelaziz</forenames></author><author><keyname>Hong</keyname><forenames>Dowon</forenames></author></authors><title>Mitigating the ICA Attack against Rotation Based Transformation for
  Privacy Preserving Clustering</title><categories>cs.CR</categories><comments>3 pages, 1 figure, appeared as a letter in ETRI journal</comments><journal-ref>Abedelaziz Mohaisen, and Dowon Hong: Mitigating the ICA Attack
  against Rotation-Based Transformation for Privacy Preserving Clustering, ETRI
  Journal, vol.30, no.6, Dec. 2008, pp.868-870</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rotation based transformation (RBT) for privacy preserving data mining
(PPDM) is vulnerable to the independent component analysis (ICA) attack. This
paper introduces a modified multiple rotation based transformation (MRBT)
technique for special mining applications mitigating the ICA attack while
maintaining the advantages of the RBT.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0205</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0205</id><created>2009-05-31</created><authors><author><keyname>Zhang</keyname><forenames>Yuanlin</forenames></author><author><keyname>Bao</keyname><forenames>Forrest Sheng</forenames></author></authors><title>A Survey of Tree Convex Sets Test</title><categories>cs.DS cs.CC</categories><comments>13 pages, 5 figures, 2 tables</comments><acm-class>F.2</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Tree convex sets refer to a collection of sets such that each set in the
collection is a subtree of a tree whose nodes are the elements of these sets.
They extend the concept of row convex sets each of which is an interval over a
total ordering of the elements of those sets. They have been applied to
identify tractable Constraint Satisfaction Problems and Combinatorial Auction
Problems. Recently, polynomial algorithms have been proposed to recognize tree
convex sets. In this paper, we review the materials that are the key to a
linear recognition algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0211</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0211</id><created>2009-06-01</created><updated>2009-06-02</updated><authors><author><keyname>Watanabe</keyname><forenames>Sumio</forenames></author></authors><title>Equations of States in Statistical Learning for a Nonparametrizable and
  Regular Case</title><categories>cs.LG</categories><doi>10.1587/transfun.E93.A.617</doi><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Many learning machines that have hierarchical structure or hidden variables
are now being used in information science, artificial intelligence, and
bioinformatics. However, several learning machines used in such fields are not
regular but singular statistical models, hence their generalization performance
is still left unknown. To overcome these problems, in the previous papers, we
proved new equations in statistical learning, by which we can estimate the
Bayes generalization loss from the Bayes training loss and the functional
variance, on the condition that the true distribution is a singularity
contained in a learning machine. In this paper, we prove that the same
equations hold even if a true distribution is not contained in a parametric
model. Also we prove that, the proposed equations in a regular case are
asymptotically equivalent to the Takeuchi information criterion. Therefore, the
proposed equations are always applicable without any condition on the unknown
true distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0231</identifier>
 <datestamp>2010-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0231</id><created>2009-06-01</created><updated>2010-07-14</updated><authors><author><keyname>Kato</keyname><forenames>Kimikazu</forenames></author><author><keyname>Hosino</keyname><forenames>Tikara</forenames></author></authors><title>Solving $k$-Nearest Neighbor Problem on Multiple Graphics Processors</title><categories>cs.IR cs.DS cs.NE</categories><comments>5 pages, 8 figures, 1 table</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The recommendation system is a software system to predict customers' unknown
preferences from known preferences. In the recommendation system, customers'
preferences are encoded into vectors, and finding the nearest vectors to each
vector is an essential part. This vector-searching part of the problem is
called a $k$-nearest neighbor problem. We give an effective algorithm to solve
this problem on multiple graphics processor units (GPUs).
  Our algorithm consists of two parts: an $N$-body problem and a partial sort.
For a algorithm of the $N$-body problem, we applied the idea of a known
algorithm for the $N$-body problem in physics, although another trick is need
to overcome the problem of small sized shared memory. For the partial sort, we
give a novel GPU algorithm which is effective for small $k$. In our partial
sort algorithm, a heap is accessed in parallel by threads with a low cost of
synchronization. Both of these two parts of our algorithm utilize maximal power
of coalesced memory access, so that a full bandwidth is achieved.
  By an experiment, we show that when the size of the problem is large, an
implementation of the algorithm on two GPUs runs more than 330 times faster
than a single core implementation on a latest CPU. We also show that our
algorithm scales well with respect to the number of GPUs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0237</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0237</id><created>2009-06-01</created><authors><author><keyname>Roche</keyname><forenames>Thomas</forenames></author><author><keyname>Tavernier</keyname><forenames>C&#xe9;dric</forenames></author></authors><title>Multi-Linear cryptanalysis in Power Analysis Attacks MLPA</title><categories>cs.CR</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Power analysis attacks against embedded secret key cryptosystems are widely
studied since the seminal paper of Paul Kocher, Joshua Ja, and Benjamin Jun in
1998 where has been introduced the powerful Differential Power Analysis. The
strength of DPA is such that it became necessary to develop sound and efficient
countermeasures. Nowadays embedded cryptographic primitives usually integrate
one or several of these countermeasures (e.g. masking techniques, asynchronous
designs, balanced dynamic dual-rail gates designs, noise adding, power
consumption smoothing, etc. ...). This document presents a simple, yet
interesting, countermeasure to DPA and HO-DPA attacks, called brutal
countermeasure and new power analysis attacks using multi-linear approximations
(MLPA attacks) based on very recent and still unpublished results of Tavernier
et al..
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0247</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0247</id><created>2009-06-01</created><authors><author><keyname>Kim</keyname><forenames>Tung T.</forenames></author><author><keyname>Fabregas</keyname><forenames>Albert Guillen i</forenames></author></authors><title>Coded Modulation with Mismatched CSIT over Block-Fading Channels</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE Transactions on Information Theory. To be
  presented (in part) at the 2009 IEEE International Symposium on Information
  Theory, Seoul, South Korea, June-July 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reliable communication over delay-constrained block-fading channels with
discrete inputs and mismatched (imperfect) channel state information at the
transmitter (CSIT) is studied. The CSIT mismatch is modeled as Gaussian random
variables, whose variances decay as a power of the signal-to-noise ratio (SNR).
A special focus is placed on the large-SNR decay of the outage probability when
power control with long-term power constraints is used. Without explicitly
characterizing the corresponding power allocation algorithms, we derive the
outage exponent as a function of the system parameters, including the CSIT
noise variance exponent and the exponent of the peak power constraint. It is
shown that CSIT, even if noisy, is always beneficial and leads to important
gains in terms of exponents. It is also shown that when multidimensional
rotations or precoders are used at the transmitter, further exponent gains can
be attained, but at the expense of larger decoding complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0249</identifier>
 <datestamp>2015-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0249</id><created>2009-06-01</created><updated>2010-12-01</updated><authors><author><keyname>Ghasemmehdi</keyname><forenames>Arash</forenames></author><author><keyname>Agrell</keyname><forenames>Erik</forenames></author></authors><title>Faster Projection in Sphere Decoding</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Information Theory, vol. 57, no. 6, pp.
  3530-3536, June 2011</journal-ref><doi>10.1109/TIT.2011.2143830</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the calculations in standard sphere decoders are redundant, in the
sense that they either calculate quantities that are never used or calculate
some quantities more than once. A new method, which is applicable to lattices
as well as finite constellations, is proposed to avoid these redundant
calculations while still returning the same result. Pseudocode is given to
facilitate immediate implementation. Simulations show that the speed gain with
the proposed method increases linearly with the lattice dimension. At dimension
60, the new algorithms avoid about 75% of all floating-point operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0252</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0252</id><created>2009-06-01</created><authors><author><keyname>Lee</keyname><forenames>Jeong-Hoon</forenames></author><author><keyname>Whang</keyname><forenames>Kyu-Young</forenames></author><author><keyname>Lim</keyname><forenames>Hyo-Sang</forenames></author><author><keyname>Lee</keyname><forenames>Byung-Suk</forenames></author><author><keyname>Heo</keyname><forenames>Jun-Seok</forenames></author></authors><title>Progressive Processing of Continuous Range Queries in Hierarchical
  Wireless Sensor Networks</title><categories>cs.DB</categories><comments>41 pages, 20 figures</comments><doi>10.1587/transinf.E93.D.1832</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the problem of processing continuous range queries in
a hierarchical wireless sensor network. Contrasted with the traditional
approach of building networks in a &quot;flat&quot; structure using sensor devices of the
same capability, the hierarchical approach deploys devices of higher capability
in a higher tier, i.e., a tier closer to the server. While query processing in
flat sensor networks has been widely studied, the study on query processing in
hierarchical sensor networks has been inadequate. In wireless sensor networks,
the main costs that should be considered are the energy for sending data and
the storage for storing queries. There is a trade-off between these two costs.
Based on this, we first propose a progressive processing method that
effectively processes a large number of continuous range queries in
hierarchical sensor networks. The proposed method uses the query merging
technique proposed by Xiang et al. as the basis and additionally considers the
trade-off between the two costs. More specifically, it works toward reducing
the storage cost at lower-tier nodes by merging more queries, and toward
reducing the energy cost at higher-tier nodes by merging fewer queries (thereby
reducing &quot;false alarms&quot;). We then present how to build a hierarchical sensor
network that is optimal with respect to the weighted sum of the two costs. It
allows for a cost-based systematic control of the trade-off based on the
relative importance between the storage and energy in a given network
environment and application. Experimental results show that the proposed method
achieves a near-optimal control between the storage and energy and reduces the
cost by 0.989~84.995 times compared with the cost achieved using the flat
(i.e., non-hierarchical) setup as in the work by Xiang et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0268</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0268</id><created>2009-06-01</created><authors><author><keyname>Nelis</keyname><forenames>Vincent</forenames></author><author><keyname>Goossens</keyname><forenames>Joel</forenames></author></authors><title>MORA: an Energy-Aware Slack Reclamation Scheme for Scheduling Sporadic
  Real-Time Tasks upon Multiprocessor Platforms</title><categories>cs.OS</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the global and preemptive energy-aware scheduling
problem of sporadic constrained-deadline tasks on DVFS-identical multiprocessor
platforms. We propose an online slack reclamation scheme which profits from the
discrepancy between the worst- and actual-case execution time of the tasks by
slowing down the speed of the processors in order to save energy. Our algorithm
called MORA takes into account the application-specific consumption profile of
the tasks. We demonstrate that MORA does not jeopardize the system
schedulability and we show by performing simulations that it can save up to 32%
of energy (in average) compared to execution without using any energy-aware
algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0281</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0281</id><created>2009-06-01</created><authors><author><keyname>Firmansyah</keyname><forenames>I.</forenames></author><author><keyname>Akbar</keyname><forenames>Z.</forenames></author><author><keyname>Handoko</keyname><forenames>L. T.</forenames></author></authors><title>Microcontroller based distributed and networked control system for
  public cluster</title><categories>cs.DC</categories><comments>4 pages, Proceeding of the International Conference on Quality in
  Research 2009</comments><report-no>FISIKALIPI-09022</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the architecture and application of the distributed control in
public cluster, a parallel machine which is open for public access. Following
the nature of public cluster, the integrated distributed control system is
fully accessible through network using a user-friendly web interface. The
system is intended mainly to control the power of each node in a block of
parallel computers provided to certain users. This is especially important to
extend the life-time of related hardwares, and to reduce the whole running and
maintainance costs. The system consists of two parts : the master- and
node-controllers, and both are connected each other through RS-485 interface.
Each node-controller is assigned with a unique address to distinguish each of
them. We also discuss briefly the implementation of the system at the LIPI
Public Cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0298</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0298</id><created>2009-06-01</created><authors><author><keyname>Lau</keyname><forenames>Vincent K. N.</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author></authors><title>Delay-Optimal Power and Precoder Adaptation for Multi-stream MIMO
  Systems</title><categories>cs.IT math.IT</categories><journal-ref>IEEE Transactions on Wireless Communications, June 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider delay-optimal MIMO precoder and power allocation
design for a MIMO Link in wireless fading channels. There are $L$ data streams
spatially multiplexed onto the MIMO link with heterogeneous packet arrivals and
delay requirements. The transmitter is assumed to have knowledge of the channel
state information (CSI) as well as the joint queue state information (QSI) of
the $L$ buffers. Using $L$-dimensional Markov Decision Process (MDP), we obtain
optimal precoding and power allocation policies for general delay regime, which
consists of an online solution and an offline solution. The online solution has
negligible complexity but the offline solution has worst case complexity ${\cal
O}((N+1)^L)$ where $N$ is the buffer size. Using {\em static sorting} of the
$L$ eigenchannels, we decompose the MDP into $L$ independent 1-dimensional
subproblems and obtained low complexity offline solution with linear complexity
order ${\cal O}(NL)$ and close-to-optimal performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0311</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0311</id><created>2009-06-01</created><authors><author><keyname>Paoli</keyname><forenames>Christophe</forenames></author><author><keyname>Voyant</keyname><forenames>Cyril</forenames></author><author><keyname>Muselli</keyname><forenames>Marc</forenames></author><author><keyname>Nivet</keyname><forenames>Marie-Laure</forenames></author></authors><title>Solar radiation forecasting using ad-hoc time series preprocessing and
  neural networks</title><categories>cs.AI cs.NA physics.data-an</categories><comments>14 pages, 8 figures, 2009 International Conference on Intelligent
  Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present an application of neural networks in the renewable
energy domain. We have developed a methodology for the daily prediction of
global solar radiation on a horizontal surface. We use an ad-hoc time series
preprocessing and a Multi-Layer Perceptron (MLP) in order to predict solar
radiation at daily horizon. First results are promising with nRMSE &lt; 21% and
RMSE &lt; 998 Wh/m2. Our optimized MLP presents prediction similar to or even
better than conventional methods such as ARIMA techniques, Bayesian inference,
Markov chains and k-Nearest-Neighbors approximators. Moreover we found that our
data preprocessing approach can reduce significantly forecasting errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0328</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0328</id><created>2009-06-01</created><authors><author><keyname>Pasquinucci</keyname><forenames>Andrea</forenames></author></authors><title>Rivisiting Token/Bucket Algorithms in New Applications</title><categories>cs.DS</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a somehow peculiar Token/Bucket problem which at first sight
looks confusing and difficult to solve. The winning approach to solve the
problem consists in going back to the simple and traditional methods to solve
computer science problems like the one taught to us by Knuth. Somehow the main
trick is to be able to specify clearly what needs to be achieved, and then the
solution, even if complex, appears almost by itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0330</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0330</id><created>2009-06-01</created><authors><author><keyname>Chirikjian</keyname><forenames>Gregory S.</forenames></author></authors><title>Information-Theoretic Inequalities on Unimodular Lie Groups</title><categories>cs.IT math-ph math.IT math.MP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical inequalities used in information theory such as those of de Bruijn,
Fisher, and Kullback carry over from the setting of probability theory on
Euclidean space to that of unimodular Lie groups. These are groups that posses
integration measures that are invariant under left and right shifts, which
means that even in noncommutative cases they share many of the useful features
of Euclidean space. In practical engineering terms the rotation group and
Euclidean motion group are the unimodular Lie groups of most interest, and the
development of information theory applicable to these Lie groups opens up the
potential to study problems relating to image reconstruction from irregular or
random projection directions, information gathering in mobile robotics,
satellite attitude control, and bacterial chemotaxis and information
processing. Several definitions are extended from the Euclidean case to that of
Lie groups including the Fisher information matrix, and inequalities analogous
to those in classical information theory are derived and stated in the form of
fifteen small theorems. In all such inequalities, addition of random variables
is replaced with the group product, and the appropriate generalization of
convolution of probability densities is employed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0343</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0343</id><created>2009-06-01</created><updated>2010-06-08</updated><authors><author><keyname>LaMar</keyname><forenames>M. Drew</forenames></author></authors><title>Algorithms for realizing degree sequences of directed graphs</title><categories>math.CO cs.DM</categories><comments>35 pages, 14 figures</comments><msc-class>05C07, 05C20, 05C85, 05C75</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Havel-Hakimi algorithm for constructing realizations of degree sequences
for undirected graphs has been used extensively in the literature. A result by
Kleitman and Wang extends the Havel-Hakimi algorithm to degree sequences for
directed graphs. In this paper we go a step further and describe a modification
of Kleitman and Wang's algorithm that is a more natural extension of
Havel-Hakimi's algorithm, in the sense that our extension can be made
equivalent to Havel-Hakimi's algorithm when the degree sequence has equal in
and out degrees and an even degree sum. We identify special degree sequences,
called directed 3-cycle anchored, that are ill-defined for the algorithm and
force a particular local structure on all directed graph realizations. We give
structural characterizations of these realizations, as well as
characterizations of the ill-defined degree sequences, leading to a
well-defined algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0346</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0346</id><created>2009-06-01</created><authors><author><keyname>Li-Thiao-T&#xe9;</keyname><forenames>S&#xe9;bastien</forenames><affiliation>CMLA</affiliation></author></authors><title>Semiparametric Estimation of a Noise Model with Quantization Errors</title><categories>cs.DM math.ST stat.TH</categories><comments>19 p</comments><proxy>ccsd hal-00390325</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The detectors in mass spectrometers are precise enough to count ion events.
In practice, the statistics of chemical noise are affected by large
quantization errors and overdispersion because of amplification in the
detector. The detector signal is modelled as X =floor(t N) where N represents
integer-valued ion counts and t represents the gain parameter. When t &lt;= 1, the
gain parameter cannot be recovered without a priori information on N. When t &gt;
1 however, we introduce compatible lattices and derive an estimator for t that
is optimal, independent of N and enables subsequent analyses of the ion counts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0350</identifier>
 <datestamp>2009-06-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0350</id><created>2009-06-01</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tirsa</keyname><forenames>Eliana-Dina</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author><author><keyname>Pop</keyname><forenames>Florin</forenames></author><author><keyname>Dobre</keyname><forenames>Ciprian Mihai</forenames></author></authors><title>Towards a Centralized Scheduling Framework for Communication Flows in
  Distributed Systems</title><categories>cs.DS cs.DC cs.NI</categories><acm-class>G.2.2; G.2.1; C.2.4</acm-class><journal-ref>Proceedings of the 17th International Conference on Control
  Systems and Computer Science (CSCS), vol. 1, pp. 441-448, Bucharest, Romania,
  26-29 May, 2009. (ISSN: 2066-4451)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The overall performance of a distributed system is highly dependent on the
communication efficiency of the system. Although network resources (links,
bandwidth) are becoming increasingly more available, the communication
performance of data transfers involving large volumes of data does not
necessarily improve at the same rate. This is due to the inefficient usage of
the available network resources. A solution to this problem consists of data
transfer scheduling techniques, which manage and allocate the network resources
in an efficient manner. In this paper we present several online and offline
data transfer optimization techniques, in the context of a centrally controlled
distributed system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0376</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0376</id><created>2009-06-01</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tirsa</keyname><forenames>Eliana-Dina</forenames></author><author><keyname>Costan</keyname><forenames>Alexandru</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>Offline Algorithms for Several Network Design, Clustering and QoS
  Optimization Problems</title><categories>cs.DS cs.DC cs.NI</categories><acm-class>G.2.2; G.2.1; C.2.4</acm-class><journal-ref>Proceedings of the 17th International Conference on Control
  Systems and Computer Science (CSCS), vol. 1, pp. 273-280, Bucharest, Romania,
  26-29 May, 2009. (ISSN: 2066-4451)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we address several network design, clustering and Quality of
Service (QoS) optimization problems and present novel, efficient, offline
algorithms which compute optimal or near-optimal solutions. The QoS
optimization problems consist of reliability improvement (by computing backup
shortest paths) and network link upgrades (in order to reduce the latency on
several paths). The network design problems consist of determining small
diameter networks, as well as very well connected and regular network
topologies. The network clustering problems consider only the restricted model
of static and mobile path networks, for which we were able to develop optimal
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0379</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0379</id><created>2009-06-01</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tirsa</keyname><forenames>Eliana-Dina</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>Data Distribution Optimization using Offline Algorithms and a
  Peer-to-Peer Small Diameter Tree Architecture with Bounded Node Degrees</title><categories>cs.DC cs.DS cs.NI</categories><acm-class>C.2.1; C.2.4; G.2.1; G.2.2</acm-class><journal-ref>Proc. of the 17th Intl. Conf. on Control Systems and Computer
  Science (CSCS), vol. 2, pp. 445-452, 2009 (3rd Intl. Workshop on High
  Performance Grid Middleware - HiPerGrid). (ISSN: 2066-4451)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multicast data transfers occur in many distributed systems and applications
(e.g. IPTV, Grids, content delivery networks). Because of this, efficient
multicast data distribution optimization techniques are required. In the first
part of this paper we present a small diameter, bounded degree, collaborative
peer-to-peer multicast tree architecture, which supports dynamic node arrivals
and departures making local decisions only. The architecture is fault tolerant
and, at low arrival and departure rates, converges towards a theoretically
optimal structure. In the second part of the paper we consider several offline
data distribution optimization problems, for which we present novel and
time-efficient algorithmic solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0380</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0380</id><created>2009-06-01</created><updated>2009-12-22</updated><authors><author><keyname>Mazza</keyname><forenames>Damiano</forenames></author></authors><title>Observational Equivalence and Full Abstraction in the Symmetric
  Interaction Combinators</title><categories>cs.LO cs.DM</categories><acm-class>F.3.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 4 (December
  22, 2009) lmcs:1150</journal-ref><doi>10.2168/LMCS-5(4:6)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The symmetric interaction combinators are an equally expressive variant of
Lafont's interaction combinators. They are a graph-rewriting model of
deterministic computation. We define two notions of observational equivalence
for them, analogous to normal form and head normal form equivalence in the
lambda-calculus. Then, we prove a full abstraction result for each of the two
equivalences. This is obtained by interpreting nets as certain subsets of the
Cantor space, called edifices, which play the same role as Boehm trees in the
theory of the lambda-calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0391</identifier>
 <datestamp>2009-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0391</id><created>2009-06-01</created><updated>2009-06-18</updated><authors><author><keyname>Volnyansky</keyname><forenames>Ilya</forenames></author><author><keyname>Pestov</keyname><forenames>Vladimir</forenames></author></authors><title>Curse of Dimensionality in Pivot-based Indexes</title><categories>cs.DS</categories><comments>9 pp., 4 figures, latex 2e, a revised submission to the 2nd
  International Workshop on Similarity Search and Applications, 2009</comments><journal-ref>Proc. 2nd Int. Workshop on Similarity Search and Applications
  (SISAP 2009), Prague, Aug. 29-30, 2009, T. Skopal and P. Zezula (eds.), IEEE
  Computer Society, Los Alamitos--Washington--Tokyo, 2009, pp. 39-46.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We offer a theoretical validation of the curse of dimensionality in the
pivot-based indexing of datasets for similarity search, by proving, in the
framework of statistical learning, that in high dimensions no pivot-based
indexing scheme can essentially outperform the linear scan.
  A study of the asymptotic performance of pivot-based indexing schemes is
performed on a sequence of datasets modeled as samples $X_d$ picked in i.i.d.
fashion from metric spaces $\Omega_d$. We allow the size of the dataset $n=n_d$
to be such that $d$, the ``dimension'', is superlogarithmic but subpolynomial
in $n$. The number of pivots is allowed to grow as $o(n/d)$. We pick the least
restrictive cost model of similarity search where we count each distance
calculation as a single computation and disregard the rest.
  We demonstrate that if the intrinsic dimension of the spaces $\Omega_d$ in
the sense of concentration of measure phenomenon is $O(d)$, then the
performance of similarity search pivot-based indexes is asymptotically linear
in $n$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0409</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0409</id><created>2009-06-01</created><authors><author><keyname>Han</keyname><forenames>Xin</forenames></author><author><keyname>Chin</keyname><forenames>Francis Y. L.</forenames></author><author><keyname>Ting</keyname><forenames>Hing-Fung</forenames></author><author><keyname>Zhang</keyname><forenames>Guochuan</forenames></author></authors><title>A New Upper Bound on 2D Online Bin Packing</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The 2D Online Bin Packing is a fundamental problem in Computer Science and
the determination of its asymptotic competitive ratio has attracted great
research attention. In a long series of papers, the lower bound of this ratio
has been improved from 1.808, 1.856 to 1.907 and its upper bound reduced from
3.25, 3.0625, 2.8596, 2.7834 to 2.66013. In this paper, we rewrite the upper
bound record to 2.5545. Our idea for the improvement is as follows. In SODA
2002 \cite{SS03}, Seiden and van Stee proposed an elegant algorithm called $H
\otimes B$, comprised of the {\em Harmonic algorithm} $H$ and the {\em Improved
Harmonic algorithm} $B$, for the two-dimensional online bin packing problem and
proved that the algorithm has an asymptotic competitive ratio of at most
2.66013. Since the best known online algorithm for one-dimensional bin packing
is the {\em Super Harmonic algorithm} \cite{S02}, a natural question to ask is:
could a better upper bound be achieved by using the Super Harmonic algorithm
instead of the Improved Harmonic algorithm? However, as mentioned in
\cite{SS03}, the previous analysis framework does not work. In this paper, we
give a positive answer for the above question. A new upper bound of 2.5545 is
obtained for 2-dimensional online bin packing. The main idea is to develop new
weighting functions for the Super Harmonic algorithm and propose new techniques
to bound the total weight in a rectangular bin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0422</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0422</id><created>2009-06-02</created><authors><author><keyname>Vanetik</keyname><forenames>Natalia</forenames></author></authors><title>Computing the tree number of a cut-outerplanar graph</title><categories>cs.DM cs.DS</categories><comments>13 pages, 11 figures Main file outerplanar1.tex</comments><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  While the notion of arboricity of a graph is well-known in graph theory, very
few results are dedicated to the minimal number of trees covering the edges of
a graph, called the tree number of a graph. In this paper we propose a method
for computing in polynomial time the tree number of a subclass of planar
graphs. The subclass in question includes but is not limited to outerplanar
graphs; the difference between arboricity and tree number for graphs in this
class can be arbitrarily big.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0426</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0426</id><created>2009-06-02</created><authors><author><keyname>Li</keyname><forenames>Li</forenames></author><author><keyname>Chen</keyname><forenames>Yudong</forenames></author><author><keyname>Zhang</keyname><forenames>Yi</forenames></author></authors><title>A Mixed-Fractal Model for Network Traffic</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this short paper, we propose a new multi-fractal flow model, aiming to
provide a possible explanation for the crossover phenomena that appear in the
estimation of Hurst exponent for network traffic. It is shown that crossover
occurs if the network flow consists of several components with different Hurst
components. Our results indicate that this model might be useful in network
traffic modeling and simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0434</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0434</id><created>2009-06-02</created><authors><author><keyname>Chopra</keyname><forenames>Aditya</forenames></author><author><keyname>Lian</keyname><forenames>Heng</forenames></author></authors><title>Total Variation, Adaptive Total Variation and Nonconvex Smoothly Clipped
  Absolute Deviation Penalty for Denoising Blocky Images</title><categories>cs.CV cs.NA stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The total variation-based image denoising model has been generalized and
extended in numerous ways, improving its performance in different contexts. We
propose a new penalty function motivated by the recent progress in the
statistical literature on high-dimensional variable selection. Using a
particular instantiation of the majorization-minimization algorithm, the
optimization problem can be efficiently solved and the computational procedure
realized is similar to the spatially adaptive total variation model. Our
two-pixel image model shows theoretically that the new penalty function solves
the bias problem inherent in the total variation model. The superior
performance of the new penalty is demonstrated through several experiments. Our
investigation is limited to &quot;blocky&quot; images which have small total variation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0447</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0447</id><created>2009-06-02</created><authors><author><keyname>Lasaulce</keyname><forenames>S.</forenames></author><author><keyname>Debbah</keyname><forenames>M.</forenames></author><author><keyname>Altman</keyname><forenames>E.</forenames></author></authors><title>Methodologies for Analyzing Equilibria in Wireless Games</title><categories>cs.GT</categories><comments>To appear in IEEE Signal Processing Magazine, Sep. 2009</comments><doi>10.1109/MSP.2009.933496</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Under certain assumptions in terms of information and models, equilibria
correspond to possible stable outcomes in conflicting or cooperative scenarios
where rational entities interact. For wireless engineers, it is of paramount
importance to be able to predict and even ensure such states at which the
network will effectively operate. In this article, we provide non-exhaustive
methodologies for characterizing equilibria in wireless games in terms of
existence, uniqueness, selection, and efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0470</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0470</id><created>2009-06-02</created><authors><author><keyname>Torres-Moreno</keyname><forenames>Juan-Manuel</forenames></author><author><keyname>Gordon</keyname><forenames>Mirta B.</forenames></author></authors><title>An optimal linear separator for the Sonar Signals Classification task</title><categories>cs.LG</categories><comments>8 pages, 6 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of classifying sonar signals from rocks and mines first studied
by Gorman and Sejnowski has become a benchmark against which many learning
algorithms have been tested. We show that both the training set and the test
set of this benchmark are linearly separable, although with different
hyperplanes. Moreover, the complete set of learning and test patterns together,
is also linearly separable. We give the weights that separate these sets, which
may be used to compare results found by other algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0485</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0485</id><created>2009-06-02</created><authors><author><keyname>Holzner</keyname><forenames>Andre</forenames></author><author><keyname>Igo-Kemenes</keyname><forenames>Peter</forenames></author><author><keyname>Mele</keyname><forenames>Salvatore</forenames></author></authors><title>First results from the PARSE.Insight project: HEP survey on data
  preservation, re-use and (open) access</title><categories>cs.DL hep-ex physics.data-an</categories><comments>Contribution to the First Workshop on Data Preservation and Long-Term
  Analysis in High-Energy Physics, DESY, Hamburg, Germany, January 26th-28th
  2009</comments><report-no>CERN-OPEN-2009-006</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  There is growing interest in the issues of preservation and re-use of the
records of science, in the &quot;digital era&quot;. The aim of the PARSE.Insight project,
partly financed by the European Commission under the Seventh Framework Program,
is twofold: to provide an assessment of the current activities, trends and
risks in the field of digital preservation of scientific results, from primary
data to published articles; to inform the design of the preservation layer of
an emerging e-Infrastructure for e-Science. CERN, as a partner of the
PARSE.Insight consortium, is performing an in-depth case study on data
preservation, re-use and (open) access within the High-Energy Physics (HEP)
community. The first results of this large-scale survey of the attitudes and
concerns of HEP scientists are presented. The survey reveals the widespread
opinion that data preservation is &quot;very important&quot; to &quot;crucial&quot;. At the same
time, it also highlights the chronic lack of resources and infrastructure to
tackle this issue, as well as deeply-rooted concerns on the access to, and the
understanding of, preserved data in future analyses.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0504</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0504</id><created>2009-06-01</created><updated>2009-07-27</updated><authors><author><keyname>Haikal</keyname><forenames>G.</forenames></author></authors><title>A stabilized finite element formulation of non-smooth contact</title><categories>cs.NA</categories><comments>Corrects some miscompiled items</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computational modeling of many engineering problems using the Finite
Element method involves the modeling of two or more bodies that meet through an
interface. The interface can be physical, as in multi-physics and contact
problems, or purely numerical, as in the coupling of non-conforming meshes. The
most critical part of the modeling process is to ensure geometric compatibility
and a complete transfer of surface tractions between the different components
at the connecting interfaces. Popular contact modeling techniques rely on
geometric projections to detect and resolve overlapping or mass
interpenetration between two or more contacting bodies. Such approaches have
been shown to have two major drawbacks: they are not suitable for contact at
highly nonlinear surfaces and sharp corners where smooth normal projections are
not feasible, and they fail to guarantee a complete and accurate transfer of
pressure across the interface. This dissertation presents a novel formulation
for the modeling of contact problems that possesses the ability to resolve
complicated contact scenarios effectively, while being simpler to implement and
more widely applicable than currently available methods. We show that the
formulation boils down to a node-to-surface gap function that works effectively
for non-smooth contact. The numerical implementation using the midpoint rule
shows the need to guarantee the conservation of the total energy during impact,
for which a Lagrange multiplier method is used. We propose a local enrichment
of the interface and a simple stabilization procedure based on the
discontinuous Galerkin method to guarantee an accurate transfer of the pressure
field. The result is a robust interface formulation for contact problems and
the coupling of non-conforming meshes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0531</identifier>
 <datestamp>2010-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0531</id><created>2009-06-02</created><updated>2010-01-07</updated><authors><author><keyname>Park</keyname><forenames>Jaeok</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Medium Access Control Protocols With Memory</title><categories>cs.NI cs.IT math.IT</categories><comments>32 pages, 7 figures, 2 tables</comments><journal-ref>IEEE/ACM Transactions on Networking, 2010</journal-ref><doi>10.1109/TNET.2010.2050699</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many existing medium access control (MAC) protocols utilize past information
(e.g., the results of transmission attempts) to adjust the transmission
parameters of users. This paper provides a general framework to express and
evaluate distributed MAC protocols utilizing a finite length of memory for a
given form of feedback information. We define protocols with memory in the
context of a slotted random access network with saturated arrivals. We
introduce two performance metrics, throughput and average delay, and formulate
the problem of finding an optimal protocol. We first show that a TDMA outcome,
which is the best outcome in the considered scenario, can be obtained after a
transient period by a protocol with (N-1)-slot memory, where N is the total
number of users. Next, we analyze the performance of protocols with 1-slot
memory using a Markov chain and numerical methods. Protocols with 1-slot memory
can achieve throughput arbitrarily close to 1 (i.e., 100% channel utilization)
at the expense of large average delay, by correlating successful users in two
consecutive slots. Finally, we apply our framework to wireless local area
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0550</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0550</id><created>2009-06-02</created><authors><author><keyname>Zinoviev</keyname><forenames>J. Borges J. Rifa V.</forenames></author></authors><title>On linear completely regular codes with covering radius $\rho=1$.
  Construction and classification</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE, Trans. Inf. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Completely regular codes with covering radius $\rho=1$ must have minimum
distance $d\leq 3$. For $d=3$, such codes are perfect and their parameters are
well known. In this paper, the cases $d=1$ and $d=2$ are studied and completely
characterized when the codes are linear. Moreover, it is proven that all these
codes are completely transitive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0557</identifier>
 <datestamp>2009-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0557</id><created>2009-06-02</created><updated>2009-10-07</updated><authors><author><keyname>Lan</keyname><forenames>Tian</forenames></author><author><keyname>Kao</keyname><forenames>David</forenames></author><author><keyname>Chiang</keyname><forenames>Mung</forenames></author><author><keyname>Sabharwal</keyname><forenames>Ashutosh</forenames></author></authors><title>An Axiomatic Theory of Fairness in Network Resource Allocation</title><categories>cs.NI cs.PF</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We present a set of five axioms for fairness measures in resource allocation.
A family of fairness measures satisfying the axioms is constructed. Well-known
notions such as alpha-fairness, Jain's index, and entropy are shown to be
special cases. Properties of fairness measures satisfying the axioms are
proven, including Schur-concavity. Among the engineering implications is a
generalized Jain's index that tunes the resolution of the fairness measure, a
new understanding of alpha-fair utility functions, and an interpretation of
&quot;larger alpha is more fair&quot;. We also construct an alternative set of four
axioms to capture efficiency objectives and feasibility constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0558</identifier>
 <datestamp>2009-06-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0558</id><created>2009-06-02</created><authors><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Sharir</keyname><forenames>Micha</forenames></author><author><keyname>Shustin</keyname><forenames>Eugenii</forenames></author></authors><title>On lines and Joints</title><categories>cs.CG</categories><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $L$ be a set of $n$ lines in $\reals^d$, for $d\ge 3$. A {\em joint} of
$L$ is a point incident to at least $d$ lines of $L$, not all in a common
hyperplane. Using a very simple algebraic proof technique, we show that the
maximum possible number of joints of $L$ is $\Theta(n^{d/(d-1)})$. For $d=3$,
this is a considerable simplification of the orignal algebraic proof of Guth
and Katz~\cite{GK}, and of the follow-up simpler proof of Elekes et al.
\cite{EKS}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0612</identifier>
 <datestamp>2010-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0612</id><created>2009-06-03</created><updated>2010-01-25</updated><authors><author><keyname>Fortunato</keyname><forenames>Santo</forenames></author></authors><title>Community detection in graphs</title><categories>physics.soc-ph cond-mat.stat-mech cs.IR physics.bio-ph physics.comp-ph q-bio.QM</categories><comments>Review article. 103 pages, 42 figures, 2 tables. Two sections
  expanded + minor modifications. Three figures + one table + references added.
  Final version published in Physics Reports</comments><journal-ref>Physics Reports 486, 75-174 (2010)</journal-ref><doi>10.1016/j.physrep.2009.11.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The modern science of networks has brought significant advances to our
understanding of complex systems. One of the most relevant features of graphs
representing real systems is community structure, or clustering, i. e. the
organization of vertices in clusters, with many edges joining vertices of the
same cluster and comparatively few edges joining vertices of different
clusters. Such clusters, or communities, can be considered as fairly
independent compartments of a graph, playing a similar role like, e. g., the
tissues or the organs in the human body. Detecting communities is of great
importance in sociology, biology and computer science, disciplines where
systems are often represented as graphs. This problem is very hard and not yet
satisfactorily solved, despite the huge effort of a large interdisciplinary
community of scientists working on it over the past few years. We will attempt
a thorough exposition of the topic, from the definition of the main elements of
the problem, to the presentation of most methods developed, with a special
focus on techniques designed by statistical physicists, from the discussion of
crucial issues like the significance of clustering and how methods should be
tested and compared against each other, to the description of applications to
real networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0651</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0651</id><created>2009-06-03</created><authors><author><keyname>Bouzid</keyname><forenames>Zohir</forenames><affiliation>LIP6</affiliation></author><author><keyname>Potop-Butucaru</keyname><forenames>Maria</forenames><affiliation>LIP6, INRIA Rocquencourt</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6, INRIA Futurs</affiliation></author></authors><title>Optimal Byzantine Resilient Convergence in Asynchronous Robot Networks</title><categories>cs.DC cs.RO</categories><proxy>ccsd inria-00390870</proxy><doi>10.1007/978-3-642-05118-0_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the first deterministic algorithm that tolerates up to $f$
byzantine faults in $3f+1$-sized networks and performs in the asynchronous
CORDA model. Our solution matches the previously established lower bound for
the semi-synchronous ATOM model on the number of tolerated Byzantine robots.
Our algorithm works under bounded scheduling assumptions for oblivious robots
moving in a uni-dimensional space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0667</identifier>
 <datestamp>2009-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0667</id><created>2009-06-03</created><authors><author><keyname>Niedermeier</keyname><forenames>Florian</forenames></author><author><keyname>Niedermeier</keyname><forenames>Michael</forenames></author><author><keyname>Kosch</keyname><forenames>Harald</forenames></author></authors><title>Quality assessment of the MPEG-4 scalable video CODEC</title><categories>cs.MM cs.CV</categories><journal-ref>published in a shorter version at ICIAP 2009 Conference</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the performance of the emerging MPEG-4 SVC CODEC is evaluated.
In the first part, a brief introduction on the subject of quality assessment
and the development of the MPEG-4 SVC CODEC is given. After that, the used test
methodologies are described in detail, followed by an explanation of the actual
test scenarios. The main part of this work concentrates on the performance
analysis of the MPEG-4 SVC CODEC - both objective and subjective.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0675</identifier>
 <datestamp>2010-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0675</id><created>2009-06-03</created><authors><author><keyname>Holmes</keyname><forenames>Martin</forenames><affiliation>HCMC</affiliation></author><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>INRIA Saclay - Ile de France, IDSL</affiliation></author></authors><title>Encoding models for scholarly literature</title><categories>cs.CL</categories><proxy>ccsd hal-00390966</proxy><journal-ref>Publishing and digital libraries: Legal and organizational issues,
  Ioannis Iglezakis, Tatiana-Eleni Synodinou, Sarantos Kapidakis (Ed.) (2010) -</journal-ref><doi>10.4018/978-1-60960-031-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the issue of digital formats for document encoding, archiving and
publishing, through the specific example of &quot;born-digital&quot; scholarly journal
articles. We will begin by looking at the traditional workflow of journal
editing and publication, and how these practices have made the transition into
the online domain. We will examine the range of different file formats in which
electronic articles are currently stored and published. We will argue strongly
that, despite the prevalence of binary and proprietary formats such as PDF and
MS Word, XML is a far superior encoding choice for journal articles. Next, we
look at the range of XML document structures (DTDs, Schemas) which are in
common use for encoding journal articles, and consider some of their strengths
and weaknesses. We will suggest that, despite the existence of specialized
schemas intended specifically for journal articles (such as NLM), and more
broadly-used publication-oriented schemas such as DocBook, there are strong
arguments in favour of developing a subset or customization of the Text
Encoding Initiative (TEI) schema for the purpose of journal-article encoding;
TEI is already in use in a number of journal publication projects, and the
scale and precision of the TEI tagset makes it particularly appropriate for
encoding scholarly articles. We will outline the document structure of a
TEI-encoded journal article, and look in detail at suggested markup patterns
for specific features of journal articles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0684</identifier>
 <datestamp>2009-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0684</id><created>2009-06-03</created><authors><author><keyname>Giannella</keyname><forenames>Chris</forenames></author></authors><title>New Instability Results for High Dimensional Nearest Neighbor Search</title><categories>cs.DB cs.IR</categories><journal-ref>Information Processing Letters 109(19), 2009.</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a dataset of n(d) points generated independently from R^d according
to a common p.d.f. f_d with support(f_d) = [0,1]^d and sup{f_d([0,1]^d)}
growing sub-exponentially in d. We prove that: (i) if n(d) grows
sub-exponentially in d, then, for any query point q^d in [0,1]^d and any
epsilon&gt;0, the ratio of the distance between any two dataset points and q^d is
less that 1+epsilon with probability --&gt;1 as d--&gt;infinity; (ii) if
n(d)&gt;[4(1+epsilon)]^d for large d, then for all q^d in [0,1]^d (except a small
subset) and any epsilon&gt;0, the distance ratio is less than 1+epsilon with
limiting probability strictly bounded away from one. Moreover, we provide
preliminary results along the lines of (i) when f_d=N(mu_d,Sigma_d).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0687</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0687</id><created>2009-06-03</created><updated>2009-09-11</updated><authors><author><keyname>Holtz</keyname><forenames>Olga</forenames></author><author><keyname>Shomron</keyname><forenames>Noam</forenames></author></authors><title>Computational Complexity and Numerical Stability of Linear Problems</title><categories>cs.CC cs.DS cs.NA math.HO math.NA math.RA</categories><comments>16 pages; updated to reflect referees' remarks; to appear in
  Proceedings of the 5th European Congress of Mathematics</comments><journal-ref>European Congress of Mathematics Amsterdam, 14-18 July, 2008, EMS
  Publishing House, pp. 381-400</journal-ref><doi>10.4171/077-1/16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey classical and recent developments in numerical linear algebra,
focusing on two issues: computational complexity, or arithmetic costs, and
numerical stability, or performance under roundoff error. We present a brief
account of the algebraic complexity theory as well as the general error
analysis for matrix multiplication and related problems. We emphasize the
central role played by the matrix multiplication problem and discuss historical
and modern approaches to its solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0690</identifier>
 <datestamp>2010-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0690</id><created>2009-06-03</created><authors><author><keyname>Harremoes</keyname><forenames>Peter</forenames></author><author><keyname>Johnson</keyname><forenames>Oliver</forenames></author><author><keyname>Kontoyiannis</keyname><forenames>Ioannis</forenames></author></authors><title>Thinning, Entropy and the Law of Thin Numbers</title><categories>cs.IT math.IT math.PR</categories><journal-ref>IEEE Transactions on Information Theory, Vol 56/9, 2010, pages
  4228-4244</journal-ref><doi>10.1109/TIT.2010.2053893</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Renyi's &quot;thinning&quot; operation on a discrete random variable is a natural
discrete analog of the scaling operation for continuous random variables. The
properties of thinning are investigated in an information-theoretic context,
especially in connection with information-theoretic inequalities related to
Poisson approximation results. The classical Binomial-to-Poisson convergence
(sometimes referred to as the &quot;law of small numbers&quot; is seen to be a special
case of a thinning limit theorem for convolutions of discrete distributions. A
rate of convergence is provided for this limit, and nonasymptotic bounds are
also established. This development parallels, in part, the development of
Gaussian inequalities leading to the information-theoretic version of the
central limit theorem. In particular, a &quot;thinning Markov chain&quot; is introduced,
and it is shown to play a role analogous to that of the Ornstein-Uhlenbeck
process in connection to the entropy power inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0695</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0695</id><created>2009-06-03</created><updated>2011-08-30</updated><authors><author><keyname>Rai</keyname><forenames>Brijesh Kumar</forenames></author><author><keyname>Dey</keyname><forenames>Bikash Kumar</forenames></author></authors><title>On network coding for sum-networks</title><categories>cs.IT math.IT</categories><comments>Accepted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A directed acyclic network is considered where all the terminals need to
recover the sum of the symbols generated at all the sources. We call such a
network a sum-network. It is shown that there exists a solvably (and linear
solvably) equivalent sum-network for any multiple-unicast network, and thus for
any directed acyclic communication network. It is also shown that there exists
a linear solvably equivalent multiple-unicast network for every sum-network. It
is shown that for any set of polynomials having integer coefficients, there
exists a sum-network which is scalar linear solvable over a finite field F if
and only if the polynomials have a common root in F. For any finite or cofinite
set of prime numbers, a network is constructed which has a vector linear
solution of any length if and only if the characteristic of the alphabet field
is in the given set. The insufficiency of linear network coding and
unachievability of the network coding capacity are proved for sum-networks by
using similar known results for communication networks. Under fractional vector
linear network coding, a sum-network and its reverse network are shown to be
equivalent. However, under non-linear coding, it is shown that there exists a
solvable sum-network whose reverse network is not solvable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0716</identifier>
 <datestamp>2009-10-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0716</id><created>2009-06-03</created><authors><author><keyname>Bernhardsson</keyname><forenames>Sebastian</forenames></author><author><keyname>da Rocha</keyname><forenames>Luis Enrique Correa</forenames></author><author><keyname>Minnhagen</keyname><forenames>Petter</forenames></author></authors><title>Size dependent word frequencies and translational invariance of books</title><categories>cs.CL physics.soc-ph</categories><comments>10 pages, 2 appendices (6 pages), 5 figures</comments><journal-ref>Physica A 389:2, pp. 330-341 (2010)</journal-ref><doi>10.1016/j.physa.2009.09.022</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is shown that a real novel shares many characteristic features with a null
model in which the words are randomly distributed throughout the text. Such a
common feature is a certain translational invariance of the text. Another is
that the functional form of the word-frequency distribution of a novel depends
on the length of the text in the same way as the null model. This means that an
approximate power-law tail ascribed to the data will have an exponent which
changes with the size of the text-section which is analyzed. A further
consequence is that a novel cannot be described by text-evolution models like
the Simon model. The size-transformation of a novel is found to be well
described by a specific Random Book Transformation. This size transformation in
addition enables a more precise determination of the functional form of the
word-frequency distribution. The implications of the results are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0724</identifier>
 <datestamp>2009-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0724</id><created>2009-06-03</created><authors><author><keyname>Bania</keyname><forenames>Piotr</forenames></author></authors><title>Dynamic Data Flow Analysis via Virtual Code Integration (aka The
  SpiderPig case)</title><categories>cs.CR</categories><comments>48 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Paper addresses the process of dynamic data flow analysis using virtual code
integration (VCI), often refered to as dynamic binary rewriting. This article
will try to demonstrate all of the techniques that were applied in the
SpiderPig project. It will also discuss the main differences between the
methods that were employed and those used in other available software, as well
as introducing other related work. SpiderPig's approach was found to be very
fast and was transparent enough for reliable and usable data flow analysis. It
was created with the purpose of providing a tool which would aid vulnerability
and security researchers with tracing and analyzing any necessary data and its
further propagation through a program. At the current state it works on IA-32
platforms with Microsoft Windows systems and it supports FPU, SSE, MMX and all
of the IA-32 general instructions. SpiderPig also demonstrates the usage of a
virtual code integration (VCI) framework which allows for modifying the target
application code at the instruction level. By this I mean that the VCI
framework allows for custom code insertion, original code modification and full
customization of the original application's code. Instructions can be swapped
out, deleted or modified at a whim, without corrupting the surrounding code and
side-effects of the modification are resolved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0731</identifier>
 <datestamp>2009-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0731</id><created>2009-05-27</created><authors><author><keyname>Vitanyi</keyname><forenames>Paul M. B.</forenames><affiliation>CWI, Amsterdam</affiliation></author></authors><title>Distributed elections in an Archimedean ring of processors</title><categories>cs.DC cs.DS</categories><journal-ref>16th ACM Symposium on Theory of Computing, Washington D.C., 1984,
  542 - 547</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Unlimited asynchronism is intolerable in real physically distributed computer
systems. Such systems, synchronous or not, use clocks and timeouts. Therefore
the magnitudes of elapsed absolute time in the system need to satisfy the axiom
of Archimedes. Under this restriction of asynchronicity logically
time-independent solutions can be derived which are nonetheless better (in
number of message passes) than is possible otherwise. The use of clocks by the
individual processors, in elections in a ring of asynchronous processors
without central control, allows a deterministic solution which requires but a
linear number of message passes. To obtain the result it has to be assumed that
the clocks measure finitely proportional absolute time-spans for their time
units, that is, the magnitudes of elapsed time in the ring network satisfy the
axiom of Archimedes. As a result, some basic subtilities associated with
distributed computations are highlighted. For instance, the known nonlinear
lower bound on the required number of message passes is cracked. For the
synchronous case, in which the necessary assumptions hold a fortiori, the
method is -asymptotically- the most efficient one yet, and of optimal order of
magnitude. The deterministic algorithm is of -asymptotically- optimal bit
complexity, and, in the synchronous case, also yields an optimal method to
determine the ring size. All of these results improve the known ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0739</identifier>
 <datestamp>2009-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0739</id><created>2009-06-03</created><authors><author><keyname>Zheng</keyname><forenames>Kun</forenames></author><author><keyname>Li</keyname><forenames>Husheng</forenames></author><author><keyname>Djouadi</keyname><forenames>Seddik M.</forenames></author><author><keyname>Wang</keyname><forenames>Jun</forenames></author></authors><title>Spectrum Sensing in Low SNR Regime via Stochastic Resonance</title><categories>cs.IT math.IT</categories><comments>5 pages, 9 figures, submitted to Asilomar 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spectrum sensing is essential in cognitive radio to enable dynamic spectrum
access. In many scenarios, primary user signal must be detected reliably in low
signal-to-noise ratio (SNR) regime under required sensing time. We propose to
use stochastic resonance, a nonlinear filter having certain resonance
frequency, to detect primary users when the SNR is very low. Both block and
sequential detection schemes are studied. Simulation results show that, under
the required false alarm rate, both detection probability and average detection
delay can be substantially improved. A few implementation issues are also
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0744</identifier>
 <datestamp>2011-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0744</id><created>2009-06-03</created><updated>2011-01-25</updated><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Ergodic Fading Interference Channels: Sum-Capacity and Separability</title><categories>cs.IT math.IT</categories><comments>accepted for publication in the IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The sum-capacity for specific sub-classes of ergodic fading Gaussian two-user
interference channels (IFCs) is developed under the assumption of perfect
channel state information at all transmitters and receivers. For the
sub-classes of uniformly strong (every fading state is strong) and ergodic very
strong two-sided IFCs (a mix of strong and weak fading states satisfying
specific fading averaged conditions) the optimality of completely decoding the
interference, i.e., converting the IFC to a compound multiple access channel
(C-MAC), is proved. It is also shown that this capacity-achieving scheme
requires encoding and decoding jointly across all fading states. As an
achievable scheme and also as a topic of independent interest, the capacity
region and the corresponding optimal power policies for an ergodic fading C-MAC
are developed. For the sub-class of uniformly weak IFCs (every fading state is
weak), genie-aided outer bounds are developed. The bounds are shown to be
achieved by treating interference as noise and by separable coding for
one-sided fading IFCs. Finally, for the sub-class of one-sided hybrid IFCs (a
mix of weak and strong states that do not satisfy ergodic very strong
conditions), an achievable scheme involving rate splitting and joint coding
across all fading states is developed and is shown to perform at least as well
as a separable coding scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0798</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0798</id><created>2009-06-03</created><authors><author><keyname>Kak</keyname><forenames>Subhash</forenames></author></authors><title>Single Neuron Memories and the Network's Proximity Matrix</title><categories>cs.NE</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper extends the treatment of single-neuron memories obtained by the
B-matrix approach. The spreading of the activity within the network is
determined by the network's proximity matrix which represents the separations
amongst the neurons through the neural pathways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0840</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0840</id><created>2009-06-04</created><authors><author><keyname>Studer</keyname><forenames>Christoph</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Soft-Input Soft-Output Single Tree-Search Sphere Decoding</title><categories>cs.IT math.IT</categories><comments>submitted to the IEEE Trans. Inf. Theory, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Soft-input soft-output (SISO) detection algorithms form the basis for
iterative decoding. The computational complexity of SISO detection often poses
significant challenges for practical receiver implementations, in particular in
the context of multiple-input multiple-output (MIMO) wireless communication
systems. In this paper, we present a low-complexity SISO sphere-decoding
algorithm, based on the single tree-search paradigm proposed originally for
soft-output MIMO detection in Studer, et al., IEEE J-SAC, 2008. The new
algorithm incorporates clipping of the extrinsic log-likelihood ratios (LLRs)
into the tree-search, which results in significant complexity savings and
allows to cover a large performance/complexity tradeoff region by adjusting a
single parameter. Furthermore, we propose a new method for correcting
approximate LLRs --resulting from sub-optimal detectors-- which (often
significantly) improves detection performance at low additional computational
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0845</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0845</id><created>2009-06-04</created><authors><author><keyname>Ismail</keyname><forenames>Mohd Nazri</forenames></author></authors><title>Analyzing of MOS and Codec Selection for Voice over IP Technology</title><categories>cs.NI</categories><comments>14 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),263-276</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this research, we propose an architectural solution to implement the voice
over IP (VoIP) service in campus environment network. Voice over IP (VoIP)
technology has become a discussion issue for this time being. Today, the
deployment of this technology on an organization truly can give a great
financial benefit over traditional telephony. Therefore, this study is to
analyze the VoIP Codec selection and investigate the Mean Opinion Score (MOS)
performance areas evolved with the quality of service delivered by soft phone
and IP phone. This study focuses on quality of voice prediction such as i)
accuracy of MOS between automated system and human perception and ii) different
types of codec performance measurement via human perception using MOS
technique. In this study, network management system (NMS) is used to monitor
and capture the performance of VoIP in campus environment. In addition, the
most apparent of implementing soft phone and IP phone in campus environment is
to define the best codec selection that can be used in operational environment.
Based on the finding result, the MOS measurement through automated and manual
system is able to predict and evaluate VoIP performance. In addition, based on
manual MOS measurement, VoIP conversations over LAN contribute more reliability
and availability performance compare to WAN.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0851</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0851</id><created>2009-06-04</created><authors><author><keyname>Saiko</keyname><forenames>Vasiliy</forenames></author></authors><title>Specific Characteristics of Applying the Paired Comparison Method for
  Parameterization of Consumer Wants</title><categories>cs.OH</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),305-314</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The article describes the main problems concerned with using expert
assessment method in consumer preference researches. The author proved the
expediency of using a 3-point measurement scale. The author suggested an
algorithm for controlling the judgments' consistency that includes analyzing
and correcting the input estimates in real-time mode.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0857</identifier>
 <datestamp>2009-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0857</id><created>2009-06-04</created><updated>2009-09-29</updated><authors><author><keyname>Formenti</keyname><forenames>Enrico</forenames></author><author><keyname>Dennunzio</keyname><forenames>Alberto</forenames></author><author><keyname>Weiss</keyname><forenames>Michael</forenames></author></authors><title>2D cellular automata: dynamics and undecidability</title><categories>cs.FL</categories><comments>24 pages, 12 figures. paper submitted to an international conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce the notion of quasi-expansivity for 2D CA and we
show that it shares many properties with expansivity (that holds only for 1D
CA). Similarly, we introduce the notions of quasi-sensitivity and prove that
the classical dichotomy theorem holds in this new setting. Moreover, we show a
tight relation between closingness and openness for 2D CA. Finally, the
undecidability of closingness property for 2D CA is proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0859</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0859</id><created>2009-06-04</created><authors><author><keyname>Schwab</keyname><forenames>Emil Daniel</forenames></author></authors><title>A Partial Order on Bipartite Graphs with n Vertices</title><categories>cs.DM</categories><comments>10 pages,exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),315-324</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper examines a partial order on bipartite graphs (X1, X2, E) with n
vertices, X1UX2={1,2,...,n}. This partial order is a natural partial order of
subobjects of an object in a triangular category with bipartite graphs as
morphisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0861</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0861</id><created>2009-06-04</created><authors><author><keyname>Shumeyko</keyname><forenames>A. A.</forenames></author><author><keyname>Sotnik</keyname><forenames>S. L.</forenames></author></authors><title>Using Genetic Algorithms for Texts Classification Problems</title><categories>cs.LG cs.NE</categories><comments>16 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),325-340</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The avalanche quantity of the information developed by mankind has led to
concept of automation of knowledge extraction - Data Mining ([1]). This
direction is connected with a wide spectrum of problems - from recognition of
the fuzzy set to creation of search machines. Important component of Data
Mining is processing of the text information. Such problems lean on concept of
classification and clustering ([2]). Classification consists in definition of
an accessory of some element (text) to one of in advance created classes.
Clustering means splitting a set of elements (texts) on clusters which quantity
are defined by localization of elements of the given set in vicinities of these
some natural centers of these clusters. Realization of a problem of
classification initially should lean on the given postulates, basic of which -
the aprioristic information on primary set of texts and a measure of affinity
of elements and classes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0862</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0862</id><created>2009-06-04</created><authors><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author></authors><title>A Memetic Algorithm for the Multidimensional Assignment Problem</title><categories>cs.DS</categories><comments>14 pages</comments><journal-ref>Lecture Notes in Computer Science 5752 (2009) 125-129</journal-ref><doi>10.1007/978-3-642-03751-1_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Multidimensional Assignment Problem (MAP or s-AP in the case of s
dimensions) is an extension of the well-known assignment problem. The most
studied case of MAP is 3-AP, though the problems with larger values of s have
also a number of applications. In this paper we propose a memetic algorithm for
MAP that is a combination of a genetic algorithm with a local search procedure.
The main contribution of the paper is an idea of dynamically adjusted
generation size, that yields an outstanding flexibility of the algorithm to
perform well for both small and large fixed running times. The results of
computational experiments for several instance families show that the proposed
algorithm produces solutions of very high quality in a reasonable time and
outperforms the state-of-the art 3-AP memetic algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0863</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0863</id><created>2009-06-04</created><authors><author><keyname>Stanciu</keyname><forenames>Cristina Ofelia</forenames></author></authors><title>Decision Support Systems Architectures</title><categories>cs.OH</categories><comments>8 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),341-348</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the main components of the decision assisting systems.
Further on three types of architectures of these systems are described,
analyzed, and respectively compared, namely: the network architecture, the
centralized architecture and the hierarchical architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0866</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0866</id><created>2009-06-04</created><authors><author><keyname>Streian</keyname><forenames>Virgiliu</forenames></author><author><keyname>Ionescu</keyname><forenames>Adela</forenames></author></authors><title>Web Publishing of the Files Obtained by Flash</title><categories>cs.MM</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),349-358</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this article is to familiarize the user with the Web publishing of
the files obtained by Flash. The article contains an overview of Macromedia
Flash 5, as well as the running of a Playing Flash movie, information on Flash
and Generator, the publishing of Flash movies, a HTLM publishing for Flash
Player files and publishing by Generator templates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0867</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0867</id><created>2009-06-04</created><authors><author><keyname>Vasilescu</keyname><forenames>Ramona</forenames></author></authors><title>PDF/A standard for long term archiving</title><categories>cs.DL</categories><comments>8 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),359-366</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PDF/A is defined by ISO 19005-1 as a file format based on PDF format. The
standard provides a mechanism for representing electronic documents in a way
that preserves their visual appearance over time, independent of the tools and
systems used for creating or storing the files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0869</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0869</id><created>2009-06-04</created><authors><author><keyname>Vieriu</keyname><forenames>Valentin</forenames></author><author><keyname>Tuican</keyname><forenames>Catalin</forenames></author></authors><title>Adobe AIR, Bringing Rich Internet Applications to the Desktop</title><categories>cs.OH</categories><comments>14 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),367-380</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rich Internet Applications are the new trend in software development today.
Adobe AIR offers the possibility to create cross-platform desktop applications
using popular Web technologies like HTML, JavaScript, Flash and Flex. This
article is focused on presenting the advantages that this new environment has
to offer for the web development community and how quickly you can develop a
desktop application using Adobe AIR.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0871</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0871</id><created>2009-06-04</created><authors><author><keyname>Karnyanszky</keyname><forenames>Tiberiu Marius</forenames></author><author><keyname>Titu</keyname><forenames>Mihai</forenames></author></authors><title>Upon the Modeling and the Optimization of the Debiting Process through
  Computer Aided Non-Conventional Technologies</title><categories>cs.OH</categories><comments>10 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),189-198</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The debiting process of the remarkable properties materials can be managed
through unconventional technologies as the complex electrical erosion. We
present the modeling of the previous experimental results to obtain a
mathematical dependence of the output parameters (processing time, surface
quality) on the input parameters (voltage or current). All the experimental
data are memorized on a database and for each particular debiting process a new
dependence is built. Because all the experiments applied in the Romanian
laboratories or practical applications of the nonconventional technological
processes in the factories were based on the particular conditions of one
activity, this papers presents the technical implementation of a computer-aided
solution that keeps all previous experimental data, optimizes the processing
conditions and eventual manage the driving gear. The flow-chart we present in
this paper offers a solution for practitioners to reduce the electrical
consumption while a technological processing of special materials is necessary.
The computer program and the database can be easily adapted to any
technological processes (conventional or not).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0872</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0872</id><created>2009-06-04</created><authors><author><keyname>Yangel</keyname><forenames>Boris</forenames></author></authors><title>Fast Weak Learner Based on Genetic Algorithm</title><categories>cs.LG cs.NE</categories><comments>4 pages, acmsiggraph latex style packed with the latex source in the
  single archive</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An approach to the acceleration of parametric weak classifier boosting is
proposed. Weak classifier is called parametric if it has fixed number of
parameters and, so, can be represented as a point into multidimensional space.
Genetic algorithm is used instead of exhaustive search to learn parameters of
such classifier. Proposed approach also takes cases when effective algorithm
for learning some of the classifier parameters exists into account. Experiments
confirm that such an approach can dramatically decrease classifier training
time while keeping both training and test errors small.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0877</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0877</id><created>2009-06-04</created><authors><author><keyname>Pintea</keyname><forenames>Florentina Anica</forenames></author><author><keyname>Fintineanu</keyname><forenames>Georgiana Petruta</forenames></author><author><keyname>Selariu</keyname><forenames>Bogdan Ioan</forenames></author></authors><title>PayPal in Romania</title><categories>cs.OH</categories><comments>8 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),277-284</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The present paper refers to the usefulness of online payment through PayPal
and to the development of this payment manner in Romania. PayPal is an example
of a payment intermediary service that facilitates worldwide e-commerce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0885</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0885</id><created>2009-06-04</created><authors><author><keyname>Tong</keyname><forenames>Yongxin</forenames></author><author><keyname>Zhao</keyname><forenames>Li</forenames></author><author><keyname>Yu</keyname><forenames>Dan</forenames></author><author><keyname>Ma</keyname><forenames>Shilong</forenames></author><author><keyname>Xu</keyname><forenames>Ke</forenames></author></authors><title>Mining Compressed Repetitive Gapped Sequential Patterns Efficiently</title><categories>cs.DB cs.AI</categories><comments>19 pages, 7 figures</comments><acm-class>H.2.8</acm-class><journal-ref>The 5th International Conference on Advanced Data Mining and
  Applications (ADMA2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mining frequent sequential patterns from sequence databases has been a
central research topic in data mining and various efficient mining sequential
patterns algorithms have been proposed and studied. Recently, in many problem
domains (e.g, program execution traces), a novel sequential pattern mining
research, called mining repetitive gapped sequential patterns, has attracted
the attention of many researchers, considering not only the repetition of
sequential pattern in different sequences but also the repetition within a
sequence is more meaningful than the general sequential pattern mining which
only captures occurrences in different sequences. However, the number of
repetitive gapped sequential patterns generated by even these closed mining
algorithms may be too large to understand for users, especially when support
threshold is low. In this paper, we propose and study the problem of
compressing repetitive gapped sequential patterns. Inspired by the ideas of
summarizing frequent itemsets, RPglobal, we develop an algorithm, CRGSgrow
(Compressing Repetitive Gapped Sequential pattern grow), including an efficient
pruning strategy, SyncScan, and an efficient representative pattern checking
scheme, -dominate sequential pattern checking. The CRGSgrow is a two-step
approach: in the first step, we obtain all closed repetitive sequential
patterns as the candidate set of representative repetitive sequential patterns,
and at the same time get the most of representative repetitive sequential
patterns; in the second step, we only spend a little time in finding the
remaining the representative patterns from the candidate set. An empirical
study with both real and synthetic data sets clearly shows that the CRGSgrow
has good performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0910</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0910</id><created>2009-06-04</created><authors><author><keyname>Noel</keyname><forenames>Sylvie</forenames></author><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author></authors><title>On the Challenges of Collaborative Data Processing</title><categories>cs.DB cs.HC</categories><comments>to appear as a chapter in an upcoming book (Collaborative Information
  Behavior)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The last 30 years have seen the creation of a variety of electronic
collaboration tools for science and business. Some of the best-known
collaboration tools support text editing (e.g., wikis). Wikipedia's success
shows that large-scale collaboration can produce highly valuable content.
Meanwhile much structured data is being collected and made publicly available.
We have never had access to more powerful databases and statistical packages.
Is large-scale collaborative data analysis now possible? Using a quantitative
analysis of Web 2.0 data visualization sites, we find evidence that at least
moderate open collaboration occurs. We then explore some of the limiting
factors of collaboration over data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0921</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0921</id><created>2009-06-04</created><authors><author><keyname>Marriotti</keyname><forenames>Matthew</forenames></author></authors><title>Course Material Selection Rubric for Creating Network Security Courses</title><categories>cs.CY cs.CR</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Teaching network security can be a difficult task for university teachers,
especially for teachers at smaller universities where the course loads are more
diverse. Creating a new course in network security requires investigation into
multiple subject areas within the field and from multiple sources. This task
can be daunting and overwhelming for teachers from smaller universities because
of their requirement to teach multiple subjects, not just network security.
Along with the requirement of teachers to understand the material that they
wish to teach, the factors of obsolescence and the ability to build material
off of core topics need to be addressed. These three factors are difficult for
a smaller university teacher to address without a set of standards to analyze
these areas. A rubric addressing these topic areas of timelessness,
associability, and simplicity has been created to assist in the selection of
materials based on the three criteria. The use of this rubric provides an
effective means to choose material for a new course and help teachers to
present the material they determine most appropriate to teach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0937</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0937</id><created>2009-06-04</created><authors><author><keyname>Hou</keyname><forenames>Xiaorong</forenames></author><author><keyname>Shao</keyname><forenames>Junwei</forenames></author></authors><title>Spherical Distribution of 5 Points with Maximal Distance Sum</title><categories>cs.DM cs.SC</categories><comments>45 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we mainly consider the problem of spherical distribution of 5
points, that is, how to configure 5 points on a sphere such that the mutual
distance sum attains the maximum. It is conjectured that the sum of distances
is maximal if 5 points form a bipyramid configuration in which case two points
are positioned at two poles of the sphere and the other three are positioned
uniformly on the equator. We study this problem using interval methods and
related technics, and give a proof for the conjecture through computers in
finite time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0958</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0958</id><created>2009-06-04</created><authors><author><keyname>Kompalli</keyname><forenames>Sayee C.</forenames></author><author><keyname>Mazumdar</keyname><forenames>Ravi R.</forenames></author></authors><title>On a Generalized Foster-Lyapunov Type Criterion for the Stability of
  Multidimensional Markov chains with Applications to the Slotted-Aloha
  Protocol with Finite Number of Queues</title><categories>cs.IT cs.NI math.IT</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this paper, we generalize a positive recurrence criterion for
multidimensional discrete-time Markov chains over countable state spaces due to
Rosberg (JAP, Vol. 17, No. 3, 1980). We revisit the stability analysis of well
known slotted-Aloha protocol with finite number of queues. Under standard
modeling assumptions, we derive a sufficient condition for the stability by
applying our positive recurrence criterion. Our sufficiency condition for
stability is linear in arrival rates and does not require knowledge of the
stationary joint statistics of queue lengths. We believe that the technique
reported here could be useful in analyzing other stability problems in
countable space Markovian settings. Toward the end, we derive some sufficient
conditions for instability of the protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0964</identifier>
 <datestamp>2009-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0964</id><created>2009-06-04</created><authors><author><keyname>Carroll</keyname><forenames>Brian</forenames></author></authors><title>On Sparse Channel Estimation</title><categories>cs.IT math.IT</categories><comments>M.S. Thesis (106 pages, 35 figures)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Channel Estimation is an essential component in applications such as radar
and data communication. In multi path time varying environments, it is
necessary to estimate time-shifts, scale-shifts (the wideband equivalent of
Doppler-shifts), and the gains/phases of each of the multiple paths. With
recent advances in sparse estimation (or &quot;compressive sensing&quot;), new estimation
techniques have emerged which yield more accurate estimates of these channel
parameters than traditional strategies. These estimation strategies, however,
restrict potential estimates of time-shifts and scale-shifts to a finite set of
values separated by a choice of grid spacing. A small grid spacing increases
the number of potential estimates, thus lowering the quantization error, but
also increases complexity and estimation time. Conversely, a large grid spacing
lowers the number of potential estimates, thus lowering the complexity and
estimation time, but increases the quantization error. In this thesis, we
derive an expression which relates the choice of grid spacing to the
mean-squared quantization error. Furthermore, we consider the case when
scale-shifts are approximated by Doppler-shifts, and derive a similar
expression relating the choice of the grid spacing and the quantization error.
Using insights gained from these expressions, we further explore the effects of
the choice and grid spacing, and examine when a wideband model can be well
approximated by a narrowband model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.0997</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.0997</id><created>2009-06-04</created><updated>2009-06-09</updated><authors><author><keyname>Sethuraman</keyname><forenames>B. A.</forenames></author></authors><title>Division Algebras and Wireless Communication</title><categories>math.RA cs.IT math.IT math.NT</categories><comments>Survey paper, 12 pages; minor edits in second version</comments><msc-class>16-02; 94-02</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey the recent use of division algebras in wireless communication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1018</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1018</id><created>2009-06-04</created><authors><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author></authors><title>Eliminating Human Insight: An Algorithmic Proof of Stembridge's TSPP
  Theorem</title><categories>cs.SC cs.DM math.CO</categories><comments>12 pages, 4 figures, submitted to Contemporary Mathematics</comments><acm-class>G.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new proof of Stembridge's theorem about the enumeration of
totally symmetric plane partitions using the methodology suggested in the
recent Koutschan-Kauers-Zeilberger semi-rigorous proof of the Andrews-Robbins
q-TSPP conjecture. Our proof makes heavy use of computer algebra and is
completely automatic. We describe new methods that make the computations
feasible in the first place. The tantalizing aspect of this work is that the
same methods can be applied to prove the q-TSPP conjecture (that is a
q-analogue of Stembridge's theorem and open for more than 25 years); the only
hurdle here is still the computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1019</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1019</id><created>2009-06-04</created><authors><author><keyname>Aggarwal</keyname><forenames>Gagan</forenames></author><author><keyname>Goel</keyname><forenames>Gagan</forenames></author><author><keyname>Mehta</keyname><forenames>Aranyak</forenames></author></authors><title>Efficiency of (Revenue-)Optimal Mechanisms</title><categories>cs.GT</categories><comments>ACM conference on Electronic Commerce, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compare the expected efficiency of revenue maximizing (or {\em optimal})
mechanisms with that of efficiency maximizing ones. We show that the efficiency
of the revenue maximizing mechanism for selling a single item with k +
log_{e/(e-1)} k + 1 bidders is at least as much as the efficiency of the
efficiency maximizing mechanism with k bidders, when bidder valuations are
drawn i.i.d. from a Monotone Hazard Rate distribution. Surprisingly, we also
show that this bound is tight within a small additive constant of 5.7. In other
words, Theta(log k) extra bidders suffice for the revenue maximizing mechanism
to match the efficiency of the efficiency maximizing mechanism, while o(log k)
do not. This is in contrast to the result of Bulow and Klemperer comparing the
revenue of the two mechanisms, where only one extra bidder suffices. More
precisely, they show that the revenue of the efficiency maximizing mechanism
with k+1 bidders is no less than the revenue of the revenue maximizing
mechanism with k bidders.
  We extend our result for the case of selling t identical items and show that
2.2 log k + t Theta(log log k) extra bidders suffice for the revenue maximizing
mechanism to match the efficiency of the efficiency maximizing mechanism.
  In order to prove our results, we do a classification of Monotone Hazard Rate
(MHR) distributions and identify a family of MHR distributions, such that for
each class in our classification, there is a member of this family that is
pointwise lower than every distribution in that class. This lets us prove
interesting structural theorems about distributions with Monotone Hazard Rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1030</identifier>
 <datestamp>2013-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1030</id><created>2009-06-04</created><updated>2011-09-08</updated><authors><author><keyname>Koenig</keyname><forenames>Robert</forenames></author><author><keyname>Wehner</keyname><forenames>Stephanie</forenames></author><author><keyname>Wullschleger</keyname><forenames>Juerg</forenames></author></authors><title>Unconditional security from noisy quantum storage</title><categories>quant-ph cs.CR</categories><comments>25 pages (IEEE two column), 13 figures, v4: published version (to
  appear in IEEE Transactions on Information Theory), including bit wise
  min-entropy sampling. however, for experimental purposes block sampling can
  be much more convenient, please see v3 arxiv version if needed. See
  arXiv:0911.2302 for a companion paper addressing aspects of a practical
  implementation using block sampling</comments><journal-ref>IEEE Trans. Inf. Th., vol. 58, no. 3, p. 1962-1984 (2012)</journal-ref><doi>10.1109/TIT.2011.2177772</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the implementation of two-party cryptographic primitives based on
the sole assumption that no large-scale reliable quantum storage is available
to the cheating party. We construct novel protocols for oblivious transfer and
bit commitment, and prove that realistic noise levels provide security even
against the most general attack. Such unconditional results were previously
only known in the so-called bounded-storage model which is a special case of
our setting. Our protocols can be implemented with present-day hardware used
for quantum key distribution. In particular, no quantum storage is required for
the honest parties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1053</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1053</id><created>2009-06-05</created><authors><author><keyname>Bouche</keyname><forenames>Thierry</forenames><affiliation>IF, CCDNM</affiliation></author></authors><title>Report on the current state of the French DMLs</title><categories>cs.DL</categories><proxy>ccsd hal-00391860</proxy><journal-ref>DML 2009 ? Towards a Digital Mathematics Library, Grand Bend,
  Ontario : Canada (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a survey of the existing digital collections of French mathematical
literature, run by non-profit organizations. This includes research monographs,
serials, proceedings, Ph. D. theses, collected works, books and personal
websites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1079</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1079</id><created>2009-06-05</created><authors><author><keyname>Pope</keyname><forenames>Graeme</forenames></author></authors><title>Modified Frame Reconstruction Algorithm for Compressive Sensing</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Compressive sensing is a technique to sample signals well below the Nyquist
rate using linear measurement operators. In this paper we present an algorithm
for signal reconstruction given such a set of measurements. This algorithm
generalises and extends previous iterative hard thresholding algorithms and we
give sufficient conditions for successful reconstruction of the original data
signal. In addition we show that by underestimating the sparsity of the data
signal we can increase the success rate of the algorithm.
  We also present a number of modifications to this algorithm: the
incorporation of a least squares step, polynomial acceleration and an adaptive
method for choosing the step-length. These modified algorithms converge to the
correct solution under similar conditions to the original un-modified
algorithm. Empirical evidence show that these modifications dramatically
increase both the success rate and the rate of convergence, and can outperform
other algorithms previously used for signal reconstruction in compressive
sensing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1084</identifier>
 <datestamp>2012-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1084</id><created>2009-06-05</created><authors><author><keyname>Annila</keyname><forenames>Arto</forenames></author></authors><title>Physical portrayal of computational complexity</title><categories>cs.CC</categories><comments>16, pages, 7 figures</comments><journal-ref>ISRN Computational Mathematics 2012 ID: 321372, 1-15</journal-ref><doi>10.5402/2012/321372</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computational complexity is examined using the principle of increasing
entropy. To consider computation as a physical process from an initial instance
to the final acceptance is motivated because many natural processes have been
recognized to complete in non-polynomial time (NP). The irreversible process
with three or more degrees of freedom is found intractable because, in terms of
physics, flows of energy are inseparable from their driving forces. In
computational terms, when solving problems in the class NP, decisions will
affect subsequently available sets of decisions. The state space of a
non-deterministic finite automaton is evolving due to the computation itself
hence it cannot be efficiently contracted using a deterministic finite
automaton that will arrive at a solution in super-polynomial time. The solution
of the NP problem itself is verifiable in polynomial time (P) because the
corresponding state is stationary. Likewise the class P set of states does not
depend on computational history hence it can be efficiently contracted to the
accepting state by a deterministic sequence of dissipative transformations.
Thus it is concluded that the class P set of states is inherently smaller than
the set of class NP. Since the computational time to contract a given set is
proportional to dissipation, the computational complexity class P is a subset
of NP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1086</identifier>
 <datestamp>2011-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1086</id><created>2009-06-05</created><updated>2010-05-31</updated><authors><author><keyname>Fouquet</keyname><forenames>Jean-Luc</forenames><affiliation>LIFO</affiliation></author><author><keyname>Vanherpe</keyname><forenames>Jean-Marie</forenames><affiliation>LIFO</affiliation></author></authors><title>On Fulkerson conjecture</title><categories>cs.DM</categories><comments>Accepted for publication in Discussiones Mathematicae Graph Theory;
  Discussiones Mathematicae Graph Theory (2010) xxx-yyy</comments><proxy>ccsd</proxy><journal-ref>Discussiones Mathematicae Graph Theory 31, 2 (2011) 253-272</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If $G$ is a bridgeless cubic graph, Fulkerson conjectured that we can find 6
perfect matchings (a{\em Fulkerson covering}) with the property that every edge
of $G$ is contained in exactly two of them. A consequence of the Fulkerson
conjecture would be that every bridgeless cubic graph has 3 perfect matchings
with empty intersection (this problem is known as the Fan Raspaud Conjecture).
A {\em FR-triple} is a set of 3 such perfect matchings. We show here how to
derive a Fulkerson covering from two FR-triples. Moreover, we give a simple
proof that the Fulkerson conjecture holds true for some classes of well known
snarks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1126</identifier>
 <datestamp>2010-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1126</id><created>2009-06-05</created><updated>2010-05-31</updated><authors><author><keyname>Sopena</keyname><forenames>Eric</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Wu</keyname><forenames>Jiaojiao</forenames><affiliation>LaBRI</affiliation></author></authors><title>Coloring the square of the Cartesian product of two cycles</title><categories>cs.DM</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The square $G^2$ of a graph $G$ is defined on the vertex set of $G$ in such a
way that distinct vertices with distance at most two in $G$ are joined by an
edge. We study the chromatic number of the square of the Cartesian product
$C_m\Box C_n$ of two cycles and show that the value of this parameter is at
most 7 except when $m=n=3$, in which case the value is 9, and when $m=n=4$ or
$m=3$ and $n=5$, in which case the value is 8. Moreover, we conjecture that
whenever $G=C_m\Box C_n$, the chromatic number of $G^2$ equals $\lceil
mn/\alpha(G^2) \rceil$, where $\alpha(G^2)$ denotes the size of a maximal
independent set in $G^2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1147</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1147</id><created>2009-06-05</created><authors><author><keyname>Khalid</keyname><forenames>Omer</forenames></author><author><keyname>Anthony</keyname><forenames>Richard</forenames></author><author><keyname>Nillson</keyname><forenames>Paul</forenames></author><author><keyname>Keahey</keyname><forenames>Kate</forenames></author><author><keyname>Schulz</keyname><forenames>Markus</forenames></author><author><keyname>Petridis</keyname><forenames>Miltos</forenames></author><author><keyname>Parrott</keyname><forenames>Kevin</forenames></author></authors><title>Enabling and Optimizing Pilot Jobs using Xen based Virtual Machines for
  the HPC Grid Applications</title><categories>cs.DC cs.PF cs.SE</categories><comments>8 pages; Published in VTDC09 workshop which is part of IEEE ICAC09
  Conference</comments><journal-ref>Khalid O. et al, Enabling and Optimizing Pilot Jobs using Xen
  Virtual Machines for HPC Grid Applications,. International Workshop on
  Virtualiztion Technologies and Distributed Computing, ICAC 09, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The primary motivation for uptake of virtualization have been resource
isolation, capacity management and resource customization: isolation and
capacity management allow providers to isolate users from the site and control
their resources usage while customization allows end-users to easily project
the required environment onto a variety of sites. Various approaches have been
taken to integrate virtualization with Grid technologies. In this paper, we
propose an approach that combines virtualization on the existing software
infrastructure such as Pilot Jobs with minimum change on the part of resource
providers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1148</identifier>
 <datestamp>2009-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1148</id><created>2009-06-05</created><authors><author><keyname>Shang</keyname><forenames>Ming-Sheng</forenames></author><author><keyname>Jin</keyname><forenames>Ci-Hang</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Collaborative filtering based on multi-channel diffusion</title><categories>cs.IR</categories><comments>9 pages, 3 figures</comments><journal-ref>Physica A 388 (2009) 4867-4871</journal-ref><doi>10.1016/j.physa.2009.08.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, by applying a diffusion process, we propose a new index to
quantify the similarity between two users in a user-object bipartite graph. To
deal with the discrete ratings on objects, we use a multi-channel
representation where each object is mapped to several channels with the number
of channels being equal to the number of different ratings. Each channel
represents a certain rating and a user having voted an object will be connected
to the channel corresponding to the rating. Diffusion process taking place on
such a user-channel bipartite graph gives a new similarity measure of user
pairs, which is further demonstrated to be more accurate than the classical
Pearson correlation coefficient under the standard collaborative filtering
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1166</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1166</id><created>2009-06-05</created><authors><author><keyname>Cardona</keyname><forenames>Gabriel</forenames></author><author><keyname>Llabres</keyname><forenames>Merce</forenames></author><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author><author><keyname>Valiente</keyname><forenames>Gabriel</forenames></author></authors><title>Comparison of Galled Trees</title><categories>q-bio.PE cs.CE cs.DM q-bio.QM</categories><comments>36 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Galled trees, directed acyclic graphs that model evolutionary histories with
isolated hybridization events, have become very popular due to both their
biological significance and the existence of polynomial time algorithms for
their reconstruction. In this paper we establish to which extent several
distance measures for the comparison of evolutionary networks are metrics for
galled trees, and hence when they can be safely used to evaluate galled tree
reconstruction methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1182</identifier>
 <datestamp>2009-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1182</id><created>2009-06-05</created><authors><author><keyname>Mancarella</keyname><forenames>P.</forenames></author><author><keyname>Terreni</keyname><forenames>G.</forenames></author><author><keyname>Sadri</keyname><forenames>F.</forenames></author><author><keyname>Toni</keyname><forenames>F.</forenames></author><author><keyname>Endriss</keyname><forenames>U.</forenames></author></authors><title>The CIFF Proof Procedure for Abductive Logic Programming with
  Constraints: Theory, Implementation and Experiments</title><categories>cs.AI cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the CIFF proof procedure for abductive logic programming with
constraints, and we prove its correctness. CIFF is an extension of the IFF
proof procedure for abductive logic programming, relaxing the original
restrictions over variable quantification (allowedness conditions) and
incorporating a constraint solver to deal with numerical constraints as in
constraint logic programming. Finally, we describe the CIFF system, comparing
it with state of the art abductive systems and answer set solvers and showing
how to use it to program some applications. (To appear in Theory and Practice
of Logic Programming - TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1189</identifier>
 <datestamp>2009-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1189</id><created>2009-06-05</created><updated>2009-11-04</updated><authors><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author></authors><title>On the Throughput/Bit-Cost Tradeoff in CSMA Based Cooperative Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>6 pages. To be presented at SCC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless local area networks (WLAN) still suffer from a severe performance
discrepancy between different users in the uplink. This is because of the
spatially varying channel conditions provided by the wireless medium.
Cooperative medium access control (MAC) protocols as for example CoopMAC were
proposed to mitigate this problem. In this work, it is shown that cooperation
implies for cooperating nodes a tradeoff between throughput and bit-cost, which
is the energy needed to transmit one bit. The tradeoff depends on the degree of
cooperation. For carrier sense multiple access (CSMA) based networks, the
throughput/bit-cost tradeoff curve is theoretically derived. A new distributed
CSMA protocol called fairMAC is proposed and it is theoretically shown that
fairMAC can asymptotically achieve any operating point on the tradeoff curve
when the packet lengths go to infinity. The theoretical results are validated
through Monte Carlo simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1199</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1199</id><created>2009-06-05</created><authors><author><keyname>Chevalier</keyname><forenames>Yannick</forenames><affiliation>LORIA</affiliation></author><author><keyname>Mounira</keyname><forenames>Kourjieh</forenames><affiliation>IRIT</affiliation></author></authors><title>On the Decidability of (ground) Reachability Problems for Cryptographic
  Protocols (extended version)</title><categories>cs.LO cs.CR</categories><proxy>ccsd inria-00392226</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Analysis of cryptographic protocols in a symbolic model is relative to a
deduction system that models the possible actions of an attacker regarding an
execution of this protocol. We present in this paper a transformation algorithm
for such deduction systems provided the equational theory has the finite
variant property. the termination of this transformation entails the
decidability of the ground reachability problems. We prove that it is necessary
to add one other condition to obtain the decidability of non-ground problems,
and provide one new such criterion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1225</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1225</id><created>2009-06-05</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author></authors><title>Pipelined Algorithms to Detect Cheating in Long-Term Grid Computations</title><categories>cs.CR</categories><comments>Expanded version with an additional figure; ISSN 0304-3975</comments><journal-ref>Theoretical Computer Science, Volume 408, Issues 2-3, Excursions
  in Algorithmics: A Collection of Papers in Honor of Franco P. Preparata, 28
  November 2008, Pages 199-207</journal-ref><doi>10.1016/j.tcs.2008.08.008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies pipelined algorithms for protecting distributed grid
computations from cheating participants, who wish to be rewarded for tasks they
receive but don't perform. We present improved cheater detection algorithms
that utilize natural delays that exist in long-term grid computations. In
particular, we partition the sequence of grid tasks into two interleaved
sequences of task rounds, and we show how to use those rounds to devise the
first general-purpose scheme that can catch all cheaters, even when cheaters
collude. The main idea of this algorithm might at first seem
counter-intuitive--we have the participants check each other's work. A naive
implementation of this approach would, of course, be susceptible to collusion
attacks, but we show that by, adapting efficient solutions to the parallel
processor diagnosis problem, we can tolerate collusions of lazy cheaters, even
if the number of such cheaters is a fraction of the total number of
participants. We also include a simple economic analysis of cheaters in grid
computations and a parameterization of the main deterrent that can be used
against them--the probability of being caught.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1226</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1226</id><created>2009-06-05</created><authors><author><keyname>Peters</keyname><forenames>Jorg</forenames></author><author><keyname>Fan</keyname><forenames>Jianhua</forenames></author></authors><title>On the Complexity of Smooth Spline Surfaces from Quad Meshes</title><categories>cs.GR cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper derives strong relations that boundary curves of a smooth complex
of patches have to obey when the patches are computed by local averaging. These
relations restrict the choice of reparameterizations for geometric continuity.
In particular, when one bicubic tensor-product B-spline patch is associated
with each facet of a quadrilateral mesh with n-valent vertices and we do not
want segments of the boundary curves forced to be linear, then the relations
dictate the minimal number and multiplicity of knots: For general data, the
tensor-product spline patches must have at least two internal double knots per
edge to be able to model a G^1-conneced complex of C^1 splines. This lower
bound on the complexity of any construction is proven to be sharp by suitably
interpreting an existing surface construction. That is, we have a tight bound
on the complexity of smoothing quad meshes with bicubic tensor-product B-spline
patches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1244</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1244</id><created>2009-06-05</created><authors><author><keyname>Reid</keyname><forenames>Mark D.</forenames></author><author><keyname>Williamson</keyname><forenames>Robert C.</forenames></author></authors><title>Generalised Pinsker Inequalities</title><categories>cs.IT math.IT</categories><comments>21 pages, 3 figures, accepted to COLT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generalise the classical Pinsker inequality which relates variational
divergence to Kullback-Liebler divergence in two ways: we consider arbitrary
f-divergences in place of KL divergence, and we assume knowledge of a sequence
of values of generalised variational divergences. We then develop a best
possible inequality for this doubly generalised situation. Specialising our
result to the classical case provides a new and tight explicit bound relating
KL to variational divergence (solving a problem posed by Vajda some 40 years
ago). The solution relies on exploiting a connection between divergences and
the Bayes risk of a learning problem via an integral representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1245</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1245</id><created>2009-06-05</created><authors><author><keyname>Azer</keyname><forenames>Marianne</forenames></author><author><keyname>El-Kassas</keyname><forenames>Sherif</forenames></author><author><keyname>El-Soudani</keyname><forenames>Magdy</forenames></author></authors><title>A Full Image of the Wormhole Attacks - Towards Introducing Complex
  Wormhole Attacks in wireless Ad Hoc Networks</title><categories>cs.CR</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper analyzes wormhole attack modes and classes and point to its threat
impacts on ad hoc networks. New improvements are suggested to these types of
attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1272</identifier>
 <datestamp>2013-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1272</id><created>2009-06-06</created><updated>2013-03-13</updated><authors><author><keyname>Dzhumadil'daev</keyname><forenames>Askar</forenames></author><author><keyname>Zusmanovich</keyname><forenames>Pasha</forenames></author></authors><title>The alternative operad is not Koszul</title><categories>math.RA cs.MS cs.SC math.CO</categories><comments>v3: added corrigendum</comments><msc-class>17D05, 17D15, 05A05, 16N40, 16S37, 17-04, 18D50, 65F99</msc-class><journal-ref>Experiment. Math. 20 (2011), 138-144; Corrigendum: 21 (2012), 418</journal-ref><doi>10.1080/10586458.2011.544558 10.1080/10586458.2012.738538</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using computer calculations, we prove the statement in the title.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1326</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1326</id><created>2009-06-07</created><authors><author><keyname>Liu</keyname><forenames>Xu</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Tu</keyname><forenames>Bibo</forenames></author><author><keyname>Zou</keyname><forenames>Ming</forenames></author><author><keyname>Meng</keyname><forenames>Dan</forenames></author></authors><title>Similarity Analysis in Automatic Performance Debugging of SPMD Parallel
  Programs</title><categories>cs.DC cs.PF</categories><comments>http://iss.ices.utexas.edu/sc08nlplss/program.html</comments><journal-ref>Supercomputing 2008 Workshop on Node Level Parallelism for Large
  Scale Supercomputers</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different from sequential programs, parallel programs possess their own
characteristics which are difficult to analyze in the multi-process or
multi-thread environment. This paper presents an innovative method to
automatically analyze the SPMD programs. Firstly, with the help of clustering
method focusing on similarity analysis, an algorithm is designed to locate
performance problems in parallel programs automatically. Secondly a Rough Set
method is used to uncover the performance problem and provide the insight into
the micro-level causes. Lastly, we have analyzed a production parallel
application to verify the effectiveness of our method and system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1328</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1328</id><created>2009-06-07</created><authors><author><keyname>Zhou</keyname><forenames>Wei</forenames></author><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Meng</keyname><forenames>Dan</forenames></author></authors><title>Multidimensional Analysis of System Logs in Large-scale Cluster Systems</title><categories>cs.DC</categories><journal-ref>The Proceeding of 38th Annual IEEE/IFIP International Conference
  on Dependable Systems and Networks (DSN 2008), Fast abstract</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is effective to improve the reliability and availability of large-scale
cluster systems through the analysis of failures. Existed failure analysis
methods understand and analyze failures from one or few dimension. The analysis
results are partial and with less precision because of the limitation of data
source. This paper presents multidimensional analysis based on graph mining to
analyze multi-source system logs, which is a promising failure analysis method
to get more complete and precise failure knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1339</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1339</id><created>2009-06-07</created><authors><author><keyname>Kaspi</keyname><forenames>Yonatan</forenames></author><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Error Exponents for Broadcast Channels with Degraded Message Sets</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a broadcast channel with a degraded message set, in which a
single transmitter sends a common message to two receivers and a private
message to one of the receivers only. The main goal of this work is to find new
lower bounds to the error exponents of the strong user, the one that should
decode both messages, and of the weak user, that should decode only the common
message. Unlike previous works, where suboptimal decoders where used, the
exponents we derive in this work pertain to optimal decoding and depend on both
rates. We take two different approaches.
  The first approach is based, in part, on variations of Gallager-type bounding
techniques that were presented in a much earlier work on error exponents for
erasure/list decoding. The resulting lower bounds are quite simple to
understand and to compute.
  The second approach is based on a technique that is rooted in statistical
physics, and it is exponentially tight from the initial step and onward. This
technique is based on analyzing the statistics of certain enumerators.
Numerical results show that the bounds obtained by this technique are tighter
than those obtained by the first approach and previous results. The derivation,
however, is more complex than the first approach and the retrieved exponents
are harder to compute.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1341</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1341</id><created>2009-06-07</created><authors><author><keyname>Andreica</keyname><forenames>Madalina Ecaterina</forenames></author><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Angela</forenames></author></authors><title>Efficient Algorithms for Several Constrained Activity Scheduling
  Problems in the Time and Space Domains</title><categories>cs.DS</categories><acm-class>F.2.2; G.2.1</acm-class><journal-ref>Proceedings of the 33rd American Romanian Academy of Arts and
  Sciences' International Congress, vol. 1, pp. 59-63, Sibiu, Romania, 2-5
  June, 2009. (ISBN: 978-2-553-01433-8)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider several constrained activity scheduling problems in
the time and space domains, like finding activity orderings which optimize the
values of several objective functions (time scheduling) or finding optimal
locations where certain types of activities will take place (space scheduling).
We present novel, efficient algorithmic solutions for all the considered
problems, based on the dynamic programming and greedy techniques. In each case
we compute exact, optimal solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1343</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1343</id><created>2009-06-07</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Madalina Ecaterina</forenames></author><author><keyname>Ardelean</keyname><forenames>Daniel</forenames></author></authors><title>Efficient Algorithms for Several Constrained Resource Allocation,
  Management and Discovery Problems</title><categories>cs.DS cs.CG</categories><acm-class>F.2.2; G.2.1</acm-class><journal-ref>Proceedings of the 33rd American Romanian Academy of Arts and
  Sciences' International Congress, vol. 1, pp. 64-68, Sibiu, Romania, 2-5
  June, 2009. (ISBN: 978-2-553-01433-8)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present efficient algorithmic solutions for several
constrained resource allocation, management and discovery problems. We consider
new types of resource allocation models and constraints, and we present new
geometric techniques which are useful when the resources are mapped to points
into a multidimensional feature space. We also consider a resource discovery
problem for which we present a guessing game theoretical model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1346</identifier>
 <datestamp>2010-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1346</id><created>2009-06-07</created><updated>2010-07-16</updated><authors><author><keyname>Zhan</keyname><forenames>Jianfeng</forenames></author><author><keyname>Wang</keyname><forenames>Lei</forenames></author><author><keyname>Tu</keyname><forenames>Bibo</forenames></author><author><keyname>Li</keyname><forenames>Yong</forenames></author><author><keyname>Wang</keyname><forenames>Peng</forenames></author><author><keyname>Zhou</keyname><forenames>Wei</forenames></author><author><keyname>Meng</keyname><forenames>Dan</forenames></author></authors><title>Phoenix Cloud: Consolidating Different Computing Loads on Shared Cluster
  System for Large Organization</title><categories>cs.DC</categories><comments>5 page, 8 figures, The First Workshop of Cloud Computing and its
  Application, The modified version. The original version is on the web site of
  http://www.cca08.org/, which is dated from August 13, 2008</comments><journal-ref>The first workshop of cloud computing and its application (CCA
  08), Chicago, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Different departments of a large organization often run dedicated cluster
systems for different computing loads, like HPC (high performance computing)
jobs or Web service applications. In this paper, we have designed and
implemented a cloud management system software Phoenix Cloud to consolidate
heterogeneous workloads from different departments affiliated to the same
organization on the shared cluster system. We have also proposed cooperative
resource provisioning and management policies for a large organization and its
affiliated departments, running HPC jobs and Web service applications, to share
the consolidated cluster system. The experiments show that in comparison with
the case that each department operates its dedicated cluster system, Phoenix
Cloud significantly decreases the scale of the required cluster system for a
large organization, improves the benefit of the scientific computing
department, and at the same time provisions enough resources to the other
department running Web services with varying loads.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1350</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1350</id><created>2009-06-07</created><updated>2009-12-18</updated><authors><author><keyname>Hritcu</keyname><forenames>Catalin</forenames></author><author><keyname>Schwinghammer</keyname><forenames>Jan</forenames></author></authors><title>A Step-indexed Semantics of Imperative Objects</title><categories>cs.PL cs.LO</categories><acm-class>D.3.1; F.3.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 4 (December
  18, 2009) lmcs:744</journal-ref><doi>10.2168/LMCS-5(4:2)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Step-indexed semantic interpretations of types were proposed as an
alternative to purely syntactic proofs of type safety using subject reduction.
The types are interpreted as sets of values indexed by the number of
computation steps for which these values are guaranteed to behave like proper
elements of the type. Building on work by Ahmed, Appel and others, we introduce
a step-indexed semantics for the imperative object calculus of Abadi and
Cardelli. Providing a semantic account of this calculus using more
`traditional', domain-theoretic approaches has proved challenging due to the
combination of dynamically allocated objects, higher-order store, and an
expressive type system. Here we show that, using step-indexing, one can
interpret a rich type discipline with object types, subtyping, recursive and
bounded quantified types in the presence of state.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1356</identifier>
 <datestamp>2009-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1356</id><created>2009-06-07</created><updated>2009-08-18</updated><authors><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Kim</keyname><forenames>E. J.</forenames></author><author><keyname>Szeider</keyname><forenames>S.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>A Probabilistic Approach to Problems Parameterized Above or Below Tight
  Bounds</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new approach for establishing fixed-parameter tractability of
problems parameterized above tight lower bounds. To illustrate the approach we
consider three problems of this type of unknown complexity that were introduced
by Mahajan, Raman and Sikdar (J. Comput. Syst. Sci. 75, 2009). We show that a
generalization of one of the problems and non-trivial special cases of the
other two are fixed-parameter tractable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1359</identifier>
 <datestamp>2010-03-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1359</id><created>2009-06-07</created><updated>2009-10-31</updated><authors><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Karapetyan</keyname><forenames>D.</forenames></author><author><keyname>Razgon</keyname><forenames>I.</forenames></author></authors><title>Fixed-Parameter Algorithms in Analysis of Heuristics for Extracting
  Networks in Linear Programs</title><categories>cs.DS cs.SE</categories><journal-ref>Lecture Notes in Computer Science 5917 (2009) 222-233</journal-ref><doi>10.1007/978-3-642-11269-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of extracting a maximum-size reflected network in a
linear program. This problem has been studied before and a state-of-the-art SGA
heuristic with two variations have been proposed.
  In this paper we apply a new approach to evaluate the quality of SGA\@. In
particular, we solve majority of the instances in the testbed to optimality
using a new fixed-parameter algorithm, i.e., an algorithm whose runtime is
polynomial in the input size but exponential in terms of an additional
parameter associated with the given problem.
  This analysis allows us to conclude that the the existing SGA heuristic, in
fact, produces solutions of a very high quality and often reaches the optimal
objective values. However, SGA contain two components which leave some space
for improvement: building of a spanning tree and searching for an independent
set in a graph. In the hope of obtaining even better heuristic, we tried to
replace both of these components with some equivalent algorithms.
  We tried to use a fixed-parameter algorithm instead of a greedy one for
searching of an independent set. But even the exact solution of this subproblem
improved the whole heuristic insignificantly. Hence, the crucial part of SGA is
building of a spanning tree. We tried three different algorithms, and it
appears that the Depth-First search is clearly superior to the other ones in
building of the spanning tree for SGA.
  Thereby, by application of fixed-parameter algorithms, we managed to check
that the existing SGA heuristic is of a high quality and selected the component
which required an improvement. This allowed us to intensify the research in a
proper direction which yielded a superior variation of SGA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1360</identifier>
 <datestamp>2010-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1360</id><created>2009-06-07</created><updated>2010-01-03</updated><authors><author><keyname>Queiros</keyname><forenames>Silvio M. Duarte</forenames></author></authors><title>On the effectiveness of a binless entropy estimator for generalised
  entropic forms</title><categories>cs.IT cs.DS math.IT math.NA</categories><comments>10 pages. 5 Figures. 2 Appendices with 2 figures</comments><journal-ref>Phys. Rev. E 80, 062101 (2009)</journal-ref><doi>10.1103/PhysRevE.80.062101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this manuscript we discuss the effectiveness of the Kozachenko-Leonenko
entropy estimator when generalised to cope with entropic forms customarily
applied to study systems evincing asymptotic scale invariance and dependence
(either linear or non-linear type). We show that when the variables are
independently and identically distributed the estimator is only valuable along
the whole domain if the data follow the uniform distribution, whereas for other
distributions the estimator is only effectual in the limit of the
Boltzmann-Gibbs-Shanon entropic form. We also analyse the influence of the
dependence (linear and non-linear) between variables on the accuracy of the
estimator between variables. As expected in the last case the estimator looses
efficiency for the Boltzmann-Gibbs-Shanon entropic form as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1370</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1370</id><created>2009-06-07</created><authors><author><keyname>Viola</keyname><forenames>Emanuele</forenames></author></authors><title>Cell-Probe Lower Bounds for Prefix Sums</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that to store n bits x so that each prefix-sum query Sum(i) :=
sum_{k &lt; i} x_k can be answered by non-adaptively probing q cells of log n
bits, one needs memory &gt; n + n/log^{O(q)} n. Our bound matches a recent upper
bound of n + n/log^{Omega(q)} n by Patrascu (FOCS 2008), also non-adaptive. We
also obtain a n + n/log^{2^{O(q)}} n lower bound for storing a string of
balanced brackets so that each Match(i) query can be answered by non-adaptively
probing q cells. To obtain these bounds we show that a too efficient data
structure allows us to break the correlations between query answers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1399</identifier>
 <datestamp>2010-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1399</id><created>2009-06-07</created><updated>2010-02-03</updated><authors><author><keyname>Sherstov</keyname><forenames>Alexander A.</forenames></author></authors><title>On Quantum-Classical Equivalence for Composed Communication Problems</title><categories>cs.CC quant-ph</categories><comments>Journal version</comments><journal-ref>Quantum Information &amp; Computation, 10(5-6):435-455, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An open problem in communication complexity proposed by several authors is to
prove that for every Boolean function f, the task of computing f(x AND y) has
polynomially related classical and quantum bounded-error complexities. We solve
a variant of this question. For every f, we prove that the task of computing,
on input x and y, both of the quantities f(x AND y) and f(x OR y) has
polynomially related classical and quantum bounded-error complexities. We
further show that the quantum bounded-error complexity is polynomially related
to the classical deterministic complexity and the block sensitivity of f. This
result holds regardless of prior entanglement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1429</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1429</id><created>2009-06-08</created><authors><author><keyname>Chevallereau</keyname><forenames>Benjamin</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Bernard</keyname><forenames>Alain</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>M&#xe9;vellec</keyname><forenames>Pierre</forenames><affiliation>LEMNA</affiliation></author></authors><title>Am\'eliorer les performances de l'industrie logicielle par une meilleure
  compr\'ehension des besoins</title><categories>cs.SE</categories><proxy>ccsd hal-00392384</proxy><journal-ref>Conf\'erence Internationale de G\'enie Industriel, Bagn\`eres de
  Bigorre : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Actual organization are structured and act with the help of their information
systems. In spite of considerable progresses made by computer technology, we
note that actors are very often critical on their information systems.
Difficulties to product specifications enough detailed for functional profile
and interpretable by information system expert is one of reason of this gap
between hopes and reality. Our proposition wants to get over this obstacle by
organizing user requirements in a common language of operational profile and
technical expert.-- Les organisations actuelles se structurent et agissent en
s'appuyant sur leurs syst\`emes d'information. Malgr\'e les progr\`es
consid\'erables r\'ealis\'es par la technologie informatique, on constate que
les acteurs restent tr\`es souvent critiques par rapport \`a leur syst\`emes
d'information. Une des causes de cet \'ecart entre les espoirs et la
r\'ealit\'e trouve sa source dans la difficult\'e \`a produire un cahier des
charges suffisamment d\'etaill\'e pour les op\'erationnels et interpr\'etable
par les sp\'ecialistes des syst\`emes d'information. Notre proposition vise \`a
surmonter cet obstacle en organisant l'expression des besoins dans un langage
commun aux op\'erationnels et aux experts techniques. Pour cela, le langage
propos\'e pour exprimer les besoins est bas\'e sur la notion de but.
L'ing\'enierie dirig\'ee par les mod\`eles est pr\'esente \`a toute les
\'etapes, c'est-\`a-dire au moment de la capture et de l'interpr\'etation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1437</identifier>
 <datestamp>2009-08-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1437</id><created>2009-06-08</created><updated>2009-08-27</updated><authors><author><keyname>Emiris</keyname><forenames>Ioannis Z.</forenames></author><author><keyname>Tsigaridas</keyname><forenames>Elias P.</forenames></author><author><keyname>Varvitsiotis</keyname><forenames>Antonios</forenames></author></authors><title>Algebraic methods for counting Euclidean embeddings of rigid graphs</title><categories>cs.CG</categories><comments>8 pages, 7 figures, 2 tables. To appear in Graph Drawing 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of (minimally) rigid graphs is motivated by numerous applications,
mostly in robotics and bioinformatics. A major open problem concerns the number
of embeddings of such graphs, up to rigid motions, in Euclidean space. We
capture embeddability by polynomial systems with suitable structure, so that
their mixed volume, which bounds the number of common roots, to yield
interesting upper bounds on the number of embeddings. We focus on $\RR^2$ and
$\RR^3$, where Laman graphs and 1-skeleta of convex simplicial polyhedra,
respectively, admit inductive Henneberg constructions. We establish the first
lower bound in $\RR^3$ of about $2.52^n$, where $n$ denotes the number of
vertices. Moreover, our implementation yields upper bounds for $n \le 10$ in
$\RR^2$ and $\RR^3$, which reduce the existing gaps, and tight bounds up to
$n=7$ in $\RR^3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1467</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1467</id><created>2009-06-08</created><authors><author><keyname>Biemann</keyname><forenames>Chris</forenames></author><author><keyname>Choudhury</keyname><forenames>Monojit</forenames></author><author><keyname>Mukherjee</keyname><forenames>Animesh</forenames></author></authors><title>Syntax is from Mars while Semantics from Venus! Insights from Spectral
  Analysis of Distributional Similarity Networks</title><categories>physics.data-an cs.CL</categories><comments>In the proceedings of ACL 2009 (short paper)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the global topology of the syntactic and semantic distributional
similarity networks for English through the technique of spectral analysis. We
observe that while the syntactic network has a hierarchical structure with
strong communities and their mixtures, the semantic network has several tightly
knit communities along with a large core without any such well-defined
community structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1487</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1487</id><created>2009-06-08</created><authors><author><keyname>Dai</keyname><forenames>Qi</forenames></author><author><keyname>Sha</keyname><forenames>Wei</forenames></author></authors><title>The Physics of Compressive Sensing and the Gradient-Based Recovery
  Algorithms</title><categories>cs.IT math.IT</categories><comments>7 pages, 11 Figures. It is a research report which has not been
  published in any Journal or Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The physics of compressive sensing (CS) and the gradient-based recovery
algorithms are presented. First, the different forms for CS are summarized.
Second, the physical meanings of coherence and measurement are given. Third,
the gradient-based recovery algorithms and their geometry explanations are
provided. Finally, we conclude the report and give some suggestion for future
work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1489</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1489</id><created>2009-06-08</created><authors><author><keyname>Meier</keyname><forenames>Arne</forenames></author><author><keyname>Mundhenk</keyname><forenames>Martin</forenames></author><author><keyname>Schneider</keyname><forenames>Thomas</forenames></author><author><keyname>Thomas</keyname><forenames>Michael</forenames></author><author><keyname>Weber</keyname><forenames>Volker</forenames></author><author><keyname>Weiss</keyname><forenames>Felix</forenames></author></authors><title>The Complexity of Satisfiability for Fragments of Hybrid Logic -- Part I</title><categories>cs.LO cs.CC</categories><acm-class>F.4.1</acm-class><doi>10.1016/j.jal.2010.08.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The satisfiability problem of hybrid logics with the downarrow binder is
known to be undecidable. This initiated a research program on decidable and
tractable fragments. In this paper, we investigate the effect of restricting
the propositional part of the language on decidability and on the complexity of
the satisfiability problem over arbitrary, transitive, total frames, and frames
based on equivalence relations. We also consider different sets of modal and
hybrid operators. We trace the border of decidability and give the precise
complexity of most fragments, in particular for all fragments including
negation. For the monotone fragments, we are able to distinguish the easy from
the hard cases, depending on the allowed set of operators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1538</identifier>
 <datestamp>2009-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1538</id><created>2009-06-08</created><updated>2009-08-07</updated><authors><author><keyname>Ayanoglu</keyname><forenames>Ender</forenames></author></authors><title>On &quot;A Novel Maximum Likelihood Decoding Algorithm for Orthogonal
  Space-Time Block Codes&quot;</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The computational complexity of the Maximum Likelihood decoding algorithm in
[1], [2] for orthogonal space-time block codes is smaller than specified.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1557</identifier>
 <datestamp>2009-06-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1557</id><created>2009-06-08</created><authors><author><keyname>Levin</keyname><forenames>Asaf</forenames></author><author><keyname>Yovel</keyname><forenames>Uri</forenames></author></authors><title>Uniform unweighted set cover: The power of non-oblivious local search</title><categories>cs.DS cs.DM</categories><comments>31 pages, includes figures</comments><acm-class>F.2.2; G.2.1; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are given n base elements and a finite collection of subsets of them. The
size of any subset varies between p to k (p &lt; k). In addition, we assume that
the input contains all possible subsets of size p. Our objective is to find a
subcollection of minimum-cardinality which covers all the elements. This
problem is known to be NP-hard. We provide two approximation algorithms for it,
one for the generic case, and an improved one for the special case of (p,k) =
(2,4). The algorithm for the generic case is a greedy one, based on packing
phases: at each phase we pick a collection of disjoint subsets covering i new
elements, starting from i = k down to i = p+1. At a final step we cover the
remaining base elements by the subsets of size p. We derive the exact
performance guarantee of this algorithm for all values of k and p, which is
less than Hk, where Hk is the k'th harmonic number. However, the algorithm
exhibits the known improvement methods over the greedy one for the unweighted
k-set cover problem (in which subset sizes are only restricted not to exceed
k), and hence it serves as a benchmark for our improved algorithm. The improved
algorithm for the special case of (p,k) = (2,4) is based on non-oblivious local
search: it starts with a feasible cover, and then repeatedly tries to replace
sets of size 3 and 4 so as to maximize an objective function which prefers big
sets over small ones. For this case, our generic algorithm achieves an
asymptotic approximation ratio of 1.5 + epsilon, and the local search algorithm
achieves a better ratio, which is bounded by 1.458333... + epsilon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1565</identifier>
 <datestamp>2010-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1565</id><created>2009-06-08</created><updated>2010-10-27</updated><authors><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author></authors><title>Correcting a Fraction of Errors in Nonbinary Expander Codes with Linear
  Programming</title><categories>cs.IT math.IT</categories><comments>Part of this work was presented at the IEEE International Symposium
  on Information Theory 2009, Seoul, Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A linear-programming decoder for \emph{nonbinary} expander codes is
presented. It is shown that the proposed decoder has the maximum-likelihood
certificate properties. It is also shown that this decoder corrects any pattern
of errors of a relative weight up to approximately 1/4 \delta_A \delta_B (where
\delta_A and \delta_B are the relative minimum distances of the constituent
codes).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1593</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1593</id><created>2009-06-06</created><authors><author><keyname>Didehvar</keyname><forenames>Farzad</forenames></author></authors><title>On Defining 'I' &quot;I logy&quot;</title><categories>cs.AI cs.LO</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Could we define I? Throughout this article we give a negative answer to this
question. More exactly, we show that there is no definition for I in a certain
way. But this negative answer depends on our definition of definability. Here,
we try to consider sufficient generalized definition of definability. In the
middle of paper a paradox will arise which makes us to modify the way we use
the concept of property and definability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1599</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1599</id><created>2009-06-08</created><updated>2011-08-22</updated><authors><author><keyname>Lutz</keyname><forenames>Tobias</forenames></author><author><keyname>Hausl</keyname><forenames>Christoph</forenames></author><author><keyname>K&#xf6;tter</keyname><forenames>Ralf</forenames></author></authors><title>Bits Through Deterministic Relay Cascades with Half-Duplex Constraint</title><categories>cs.IT math.IT</categories><comments>accepted for publication in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a relay cascade, i.e. a network where a source node, a sink node and
a certain number of intermediate source/relay nodes are arranged on a line and
where adjacent node pairs are connected by error-free (q+1)-ary pipes. Suppose
the source and a subset of the relays wish to communicate independent
information to the sink under the condition that each relay in the cascade is
half-duplex constrained. A coding scheme is developed which transfers
information by an information-dependent allocation of the transmission and
reception slots of the relays. The coding scheme requires synchronization on
the symbol level through a shared clock. The coding strategy achieves capacity
for a single source. Numerical values for the capacity of cascades of various
lengths are provided, and the capacities are significantly higher than the
rates which are achievable with a predetermined time-sharing approach. If the
cascade includes a source and a certain number of relays with their own
information, the strategy achieves the cut-set bound when the rates of the
relay sources fall below certain thresholds. For cascades composed of an
infinite number of half-duplex constrained relays and a single source, we
derive an explicit capacity expression. Remarkably, the capacity in bits/use
for q=1 is equal to the logarithm of the golden ratio, and the capacity for q=2
is 1 bit/use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1603</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1603</id><created>2009-06-08</created><authors><author><keyname>Zaidi</keyname><forenames>Abdellatif</forenames></author><author><keyname>Kotagiri</keyname><forenames>Shiva Prasad</forenames></author><author><keyname>Laneman</keyname><forenames>J. Nicholas</forenames></author><author><keyname>Vandendorpe</keyname><forenames>Luc</forenames></author></authors><title>Multiaccess Channels with State Known to One Encoder: Another Case of
  Degraded Message Sets</title><categories>cs.IT math.IT</categories><comments>5 pages, Proc. of IEEE International Symposium on Information theory,
  ISIT 2009, Seoul, Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two-user state-dependent multiaccess channel in which only one
of the encoders is informed, non-causally, of the channel states. Two
independent messages are transmitted: a common message transmitted by both the
informed and uninformed encoders, and an individual message transmitted by only
the uninformed encoder. We derive inner and outer bounds on the capacity region
of this model in the discrete memoryless case as well as the Gaussian case.
Further, we show that the bounds for the Gaussian case are tight in some
special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1618</identifier>
 <datestamp>2013-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1618</id><created>2009-06-08</created><authors><author><keyname>Hanif</keyname><forenames>Muhammad Fainan</forenames></author><author><keyname>Smith</keyname><forenames>Peter J.</forenames></author></authors><title>On the Statistics of Cognitive Radio Capacity in Shadowing and Fast
  Fading Environments (Journal Version)</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Wireless Commun. The conference
  version of this paper appears in Proc. IEEE CrownCom, 2009</comments><journal-ref>IEEE Transactions on Wireless Communications, vol.9, no.2,
  pp.844-852, 2010</journal-ref><doi>10.1109/TWC.2010.02.090864</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the capacity of the cognitive radio channel in
different fading environments under a low interference regime. First we derive
the probability that the low interference regime holds under shadow fading as
well as Rayleigh and Rician fast fading conditions. We demonstrate that this is
the dominant case, especially in practical cognitive radio deployment
scenarios. The capacity of the cognitive radio channel depends critically on a
power loss parameter, $\alpha$, which governs how much transmit power the
cognitive radio dedicates to relaying the primary message. We derive a simple,
accurate approximation to $\alpha$ in Rayleigh and Rician fading environments
which gives considerable insight into system capacity. We also investigate the
effects of system parameters and propagation environment on $\alpha$ and the
cognitive radio capacity. In all cases, the use of the approximation is shown
to be extremely accurate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1644</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1644</id><created>2009-06-09</created><authors><author><keyname>Micle</keyname><forenames>Dorel</forenames></author><author><keyname>Torok-Oance</keyname><forenames>Marcel</forenames></author><author><keyname>Maruia</keyname><forenames>Liviu</forenames></author></authors><title>The morpho-topographic and cartographic analysis of the archaeological
  site Cornesti &quot;Iarcuri&quot;, Timis County, Romania, using computer sciences
  methods (GIS and Remote Sensing techniques)</title><categories>cs.OH</categories><comments>14 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),249-262</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The archaeological site Cornesti &quot;Iarcuri&quot; is the largest earth fortification
in Romania, made out of four concentric compounds, spreading over 1780
hectares. It is known since 1700, but it had only a few small attempts of
systematic research, the fortress gained interest only after the publishing of
some satellite images by Google Earth. It is located in an area of high fields
and it occupies three interfluves and contains two streams. Our paper contains
a geomorphologic, topographic and cartographic analysis of the site in order to
determine the limits, the structure, the morphology, the construction technique
and the functionality of such a fortification.Our research is based on
satellite image analysis, on archaeological topography, on soil, climate and
vegetation analysis as a way to offer a complex image, through this
interdisciplinary study of landscape archaeology. Through our work we try not
to date the site as this objective will be achieved only after completing the
systematic excavations which started in 2007, but only to analyze the
co-relationship with the environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1667</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1667</id><created>2009-06-09</created><authors><author><keyname>Rasenack</keyname><forenames>Rolf Andreas</forenames></author></authors><title>Analyser Framework to verify Software Component</title><categories>cs.SE</categories><comments>20 pages, exposed on 5th International Conference &quot;Actualities and
  Perspectives on Hardware and Software&quot; - APHS2009, Timisoara, Romania</comments><journal-ref>Ann. Univ. Tibiscus Comp. Sci. Series VII(2009),285-304</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, it is important for software companies to build software systems in a
short time-interval, to reduce costs and to have a good market position.
Therefore well organized and systematic development approaches are required.
Reusing software components, which are well tested, can be a good solution to
develop software applications in effective manner. The reuse of software
components is less expensive and less time consuming than a development from
scratch. But it is dangerous to think that software components can be match
together without any problems. Software components itself are well tested, of
course, but even if they composed together problems occur. Most problems are
based on interaction respectively communication. Avoiding such errors a
framework has to be developed for analysing software components. That framework
determines the compatibility of corresponding software components.The promising
approach discussed here, presents a novel technique for analysing software
components by applying an Abstract Syntax Language Tree (ASLT). A supportive
environment will be designed that checks the compatibility of black-box
software components. This article is concerned to the question how can be
coupled software components verified by using an analyzer framework and
determines the usage of the ASLT. Black-box Software Components and Abstract
Syntax Language Tree are the basis for developing the proposed framework and
are discussed here to provide the background knowledge. The practical
implementation of this framework is discussed and shows the result by using a
test environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1673</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1673</id><created>2009-06-09</created><authors><author><keyname>Oladejo</keyname><forenames>Bolanle</forenames><affiliation>LORIA</affiliation></author><author><keyname>Osofisan</keyname><forenames>Adenike</forenames><affiliation>LORIA</affiliation></author><author><keyname>Odumuyiwa</keyname><forenames>Victor</forenames><affiliation>LORIA</affiliation></author></authors><title>Knowledge Management in Economic Intelligence with Reasoning on Temporal
  Attributes</title><categories>cs.AI</categories><proxy>ccsd inria-00392754</proxy><journal-ref>VSST 2009, S\'eminaire on Veille Strat\'egique Scientifique et
  Technologique (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  People have to make important decisions within a time frame. Hence, it is
imperative to employ means or strategy to aid effective decision making.
Consequently, Economic Intelligence (EI) has emerged as a field to aid
strategic and timely decision making in an organization. In the course of
attaining this goal: it is indispensable to be more optimistic towards
provision for conservation of intellectual resource invested into the process
of decision making. This intellectual resource is nothing else but the
knowledge of the actors as well as that of the various processes for effecting
decision making. Knowledge has been recognized as a strategic economic resource
for enhancing productivity and a key for innovation in any organization or
community. Thus, its adequate management with cognizance of its temporal
properties is highly indispensable. Temporal properties of knowledge refer to
the date and time (known as timestamp) such knowledge is created as well as the
duration or interval between related knowledge. This paper focuses on the needs
for a user-centered knowledge management approach as well as exploitation of
associated temporal properties. Our perspective of knowledge is with respect to
decision-problems projects in EI. Our hypothesis is that the possibility of
reasoning about temporal properties in exploitation of knowledge in EI projects
should foster timely decision making through generation of useful inferences
from available and reusable knowledge for a new project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1677</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1677</id><created>2009-06-09</created><authors><author><keyname>Piantanida</keyname><forenames>Pablo</forenames></author><author><keyname>Matz</keyname><forenames>Gerald</forenames></author><author><keyname>Duhamel</keyname><forenames>Pierre</forenames></author></authors><title>Outage Behavior of Discrete Memoryless Channels (DMCs) Under Channel
  Estimation Errors</title><categories>cs.IT cs.DM math.IT</categories><comments>To appear in IEEE Transactions on Information Theory, Sep. 2009</comments><acm-class>E.4; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Communication systems are usually designed by assuming perfect channel state
information (CSI). However, in many practical scenarios, only a noisy estimate
of the channel is available, which may strongly differ from the true channel.
This imperfect CSI scenario is addressed by introducing the notion of
estimation-induced outage (EIO) capacity. We derive a single-letter
characterization of the maximal EIO rate and prove an associated coding theorem
and its strong converse for discrete memoryless channels (DMCs). The
transmitter and the receiver rely on the channel estimate and the statistics of
the estimate to construct codes that guarantee reliable communication with a
certain outage probability. This ensures that in the non-outage case the
transmission meets the target rate with small error probability, irrespective
of the quality of the channel estimate. Applications of the EIO capacity to a
single-antenna (non-ergodic) Ricean fading channel are considered. The EIO
capacity for this case is compared to the EIO rates of a communication system
in which the receiver decodes by using a mismatched ML decoder. The effects of
rate-limited feedback to provide the transmitter with quantized CSI are also
investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1680</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1680</id><created>2009-06-09</created><authors><author><keyname>Cocheteux</keyname><forenames>Pierre</forenames><affiliation>CRAN</affiliation></author><author><keyname>Voisin</keyname><forenames>Alexandre</forenames><affiliation>CRAN</affiliation></author><author><keyname>Levrat</keyname><forenames>Eric</forenames><affiliation>CRAN</affiliation></author><author><keyname>Iung</keyname><forenames>Beno&#xee;t</forenames><affiliation>CRAN</affiliation></author></authors><title>Methodology for assessing system performance loss within a proactive
  maintenance framework</title><categories>cs.PF</categories><proxy>ccsd hal-00392932</proxy><journal-ref>13th IFAC Symposium on Information Control Problems in
  Manufacturing, INCOM'09, Moscow : Russie (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Maintenance plays now a critical role in manufacturing for achieving
important cost savings and competitive advantage while preserving product
conditions. It suggests moving from conventional maintenance practices to
predictive strategy. Indeed the maintenance action has to be done at the right
time based on the system performance and component Remaining Useful Life (RUL)
assessed by a prognostic process. In that way, this paper proposes a
methodology in order to evaluate the performance loss of the system according
to the degradation of component and the deviations of system input flows. This
methodology is supported by the neuro-fuzzy tool ANFIS (Adaptive Neuro-Fuzzy
Inference Systems) that allows to integrate knowledge from two different
sources: expertise and real data. The feasibility and added value of such
methodology is then highlighted through an application case extracted from the
TELMA platform used for education and research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1694</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1694</id><created>2009-06-09</created><authors><author><keyname>Glazunov</keyname><forenames>Nikolaj</forenames></author></authors><title>Toward a Category Theory Design of Ontological Knowledge Bases</title><categories>cs.AI</categories><comments>10 pages, Preliminary results to International Joint Conference on
  Knowledge Discovery, Knowledge Engineering and Knowledge Management (IC3K
  2009)</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I discuss (ontologies_and_ontological_knowledge_bases /
formal_methods_and_theories) duality and its category theory extensions as a
step toward a solution to Knowledge-Based Systems Theory. In particular I focus
on the example of the design of elements of ontologies and ontological
knowledge bases of next three electronic courses: Foundations of Research
Activities, Virtual Modeling of Complex Systems and Introduction to String
Theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1702</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1702</id><created>2009-06-09</created><authors><author><keyname>Moore</keyname><forenames>Cristopher</forenames></author><author><keyname>Russell</keyname><forenames>Alexander</forenames></author></authors><title>Approximating the Permanent via Nonabelian Determinants</title><categories>cs.CC cs.DM math.CO quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Celebrated work of Jerrum, Sinclair, and Vigoda has established that the
permanent of a {0,1} matrix can be approximated in randomized polynomial time
by using a rapidly mixing Markov chain. A separate strand of the literature has
pursued the possibility of an alternate, purely algebraic, polynomial-time
approximation scheme. These schemes work by replacing each 1 with a random
element of an algebra A, and considering the determinant of the resulting
matrix. When A is noncommutative, this determinant can be defined in several
ways. We show that for estimators based on the conventional determinant, the
critical ratio of the second moment to the square of the first--and therefore
the number of trials we need to obtain a good estimate of the permanent--is (1
+ O(1/d))^n when A is the algebra of d by d matrices. These results can be
extended to group algebras, and semi-simple algebras in general. We also study
the symmetrized determinant of Barvinok, showing that the resulting estimator
has small variance when d is large enough. However, for constant d--the only
case in which an efficient algorithm is known--we show that the critical ratio
exceeds 2^{n} / n^{O(d)}. Thus our results do not provide a new polynomial-time
approximation scheme for the permanent. Indeed, they suggest that the algebraic
approach to approximating the permanent faces significant obstacles.
  We obtain these results using diagrammatic techniques in which we express
matrix products as contractions of tensor products. When these matrices are
random, in either the Haar measure or the Gaussian measure, we can evaluate the
trace of these products in terms of the cycle structure of a suitably random
permutation. In the symmetrized case, our estimates are then derived by a
connection with the character theory of the symmetric group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1713</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1713</id><created>2009-06-09</created><authors><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Feature Reinforcement Learning: Part I: Unstructured MDPs</title><categories>cs.LG cs.AI cs.IT math.IT</categories><comments>24 LaTeX pages, 5 diagrams</comments><journal-ref>Journal of Artificial General Intelligence, 1 (2009) pages 3-24</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  General-purpose, intelligent, learning agents cycle through sequences of
observations, actions, and rewards that are complex, uncertain, unknown, and
non-Markovian. On the other hand, reinforcement learning is well-developed for
small finite state Markov decision processes (MDPs). Up to now, extracting the
right state representations out of bare observations, that is, reducing the
general agent setup to the MDP framework, is an art that involves significant
effort by designers. The primary goal of this work is to automate the reduction
process and thereby significantly expand the scope of many existing
reinforcement learning algorithms and the agents that employ them. Before we
can think of mechanizing this search for suitable MDPs, we need a formal
objective criterion. The main contribution of this article is to develop such a
criterion. I also integrate the various parts into one learning algorithm.
Extensions to more realistic dynamic Bayesian networks are developed in Part
II. The role of POMDPs is also considered there.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1726</identifier>
 <datestamp>2010-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1726</id><created>2009-06-09</created><updated>2010-08-18</updated><authors><author><keyname>Adams</keyname><forenames>Robin</forenames></author><author><keyname>Luo</keyname><forenames>Zhaohui</forenames></author></authors><title>Classical Predicative Logic-Enriched Type Theories</title><categories>cs.LO math.LO</categories><comments>49 pages. Accepted for publication in special edition of Annals of
  Pure and Applied Logic on Computation in Classical Logic. v2: Minor mistakes
  corrected</comments><msc-class>03B15, 03B30, 03B70, 03F25, 03F35, 68T15</msc-class><doi>10.1016/j.apal.2010.04.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A logic-enriched type theory (LTT) is a type theory extended with a primitive
mechanism for forming and proving propositions. We construct two LTTs, named
LTTO and LTTO*, which we claim correspond closely to the classical predicative
systems of second order arithmetic ACAO and ACA. We justify this claim by
translating each second-order system into the corresponding LTT, and proving
that these translations are conservative. This is part of an ongoing research
project to investigate how LTTs may be used to formalise different approaches
to the foundations of mathematics.
  The two LTTs we construct are subsystems of the logic-enriched type theory
LTTW, which is intended to formalise the classical predicative foundation
presented by Herman Weyl in his monograph Das Kontinuum. The system ACAO has
also been claimed to correspond to Weyl's foundation. By casting ACAO and ACA
as LTTs, we are able to compare them with LTTW. It is a consequence of the work
in this paper that LTTW is strictly stronger than ACAO.
  The conservativity proof makes use of a novel technique for proving one LTT
conservative over another, involving defining an interpretation of the stronger
system out of the expressions of the weaker. This technique should be
applicable in a wide variety of different cases outside the present work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1763</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1763</id><created>2009-06-09</created><updated>2009-06-10</updated><authors><author><keyname>Gholami</keyname><forenames>Behnood</forenames><affiliation>School of Aerospace Engineering, Georgia Institute of Technology</affiliation></author><author><keyname>Tannenbaum</keyname><forenames>Allen R.</forenames><affiliation>School of Electrical &amp; Computer Engineering, Georgia Institute of Technology</affiliation><affiliation>Department of Biomedical Engineering, Georgia Institute of Technology</affiliation></author><author><keyname>Haddad</keyname><forenames>Wassim M.</forenames><affiliation>School of Aerospace Engineering, Georgia Institute of Technology</affiliation></author></authors><title>Segmentation of Facial Expressions Using Semi-Definite Programming and
  Generalized Principal Component Analysis</title><categories>cs.CV</categories><comments>Corrected for typos and spacing errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we use semi-definite programming and generalized principal
component analysis (GPCA) to distinguish between two or more different facial
expressions. In the first step, semi-definite programming is used to reduce the
dimension of the image data and &quot;unfold&quot; the manifold which the data points
(corresponding to facial expressions) reside on. Next, GPCA is used to fit a
series of subspaces to the data points and associate each data point with a
subspace. Data points that belong to the same subspace are claimed to belong to
the same facial expression category. An example is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1777</identifier>
 <datestamp>2009-06-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1777</id><created>2009-06-09</created><authors><author><keyname>Breslav</keyname><forenames>Andrey</forenames></author></authors><title>Creating Textual Language Dialects Using Aspect-like Techniques</title><categories>cs.PL cs.SE</categories><comments>extended abstract for GTTSE'09</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we present a work aimed on efficiently creating textual language
dialects and supporting tools for them (e.g. compiler front-ends, IDE support,
pretty-printers, etc.). A dialect is a language which may be described with a
(relatively small) set of changes to some other language (a parent language).
For example we can consider SQL dialects used in DB-management systems.
  We propose to use aspects for grammars to define different features of the
anguage and to transform grammars. A dialect is created by defining a
syntactical spect which modifies the parent language. This technique is not
dependent on any particular language design, AST structure or parsing
technology and provides a uniform way for creating dialects, which extend or
restrict languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1814</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1814</id><created>2009-06-09</created><authors><author><keyname>Min</keyname><forenames>Martin Renqiang</forenames></author><author><keyname>Stanley</keyname><forenames>David A.</forenames></author><author><keyname>Yuan</keyname><forenames>Zineng</forenames></author><author><keyname>Bonner</keyname><forenames>Anthony</forenames></author><author><keyname>Zhang</keyname><forenames>Zhaolei</forenames></author></authors><title>Large-Margin kNN Classification Using a Deep Encoder Network</title><categories>cs.LG cs.AI</categories><comments>13 pages (preliminary version)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  KNN is one of the most popular classification methods, but it often fails to
work well with inappropriate choice of distance metric or due to the presence
of numerous class-irrelevant features. Linear feature transformation methods
have been widely applied to extract class-relevant information to improve kNN
classification, which is very limited in many applications. Kernels have been
used to learn powerful non-linear feature transformations, but these methods
fail to scale to large datasets. In this paper, we present a scalable
non-linear feature mapping method based on a deep neural network pretrained
with restricted boltzmann machines for improving kNN classification in a
large-margin framework, which we call DNet-kNN. DNet-kNN can be used for both
classification and for supervised dimensionality reduction. The experimental
results on two benchmark handwritten digit datasets show that DNet-kNN has much
better performance than large-margin kNN using a linear mapping and kNN based
on a deep autoencoder pretrained with retricted boltzmann machines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1835</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1835</id><created>2009-06-09</created><authors><author><keyname>Khisti</keyname><forenames>Ashish</forenames></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames></author><author><keyname>Wornell</keyname><forenames>Gregory</forenames></author></authors><title>Secret-Key Generation using Correlated Sources and Channels</title><categories>cs.IT cs.CR math.IT</categories><comments>29 Pages, Submitted IEEE Trans. Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of generating a shared secret key between two terminals
in a joint source-channel setup -- the sender communicates to the receiver over
a discrete memoryless wiretap channel and additionally the terminals have
access to correlated discrete memoryless source sequences. We establish lower
and upper bounds on the secret-key capacity. These bounds coincide,
establishing the capacity, when the underlying channel consists of independent,
parallel and reversely degraded wiretap channels. In the lower bound, the
equivocation terms of the source and channel components are functionally
additive. The secret-key rate is maximized by optimally balancing the the
source and channel contributions. This tradeoff is illustrated in detail for
the Gaussian case where it is also shown that Gaussian codebooks achieve the
capacity. When the eavesdropper also observes a source sequence, the secret-key
capacity is established when the sources and channels of the eavesdropper are a
degraded version of the legitimate receiver. Finally the case when the
terminals also have access to a public discussion channel is studied. We
propose generating separate keys from the source and channel components and
establish the optimality of this approach when the when the channel outputs of
the receiver and the eavesdropper are conditionally independent given the
input.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1842</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1842</id><created>2009-06-09</created><authors><author><keyname>Shaban-Nejad</keyname><forenames>Arash</forenames></author><author><keyname>Ormandjieva</keyname><forenames>Olga</forenames></author><author><keyname>Kassab</keyname><forenames>Mohamad</forenames></author><author><keyname>Haarslev</keyname><forenames>Volker</forenames></author></authors><title>Managing Requirement Volatility in an Ontology-Driven Clinical LIMS
  Using Category Theory. International Journal of Telemedicine and Applications</title><categories>cs.AI cs.MA</categories><comments>36 Pages, 16 Figures</comments><acm-class>I.2.4; D.2.1</acm-class><journal-ref>International Journal of Telemedicine and Applications, Volume
  2009, Article ID 917826, 14 pages, PubMed ID: 19343191</journal-ref><doi>10.1155/2009/917826</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Requirement volatility is an issue in software engineering in general, and in
Web-based clinical applications in particular, which often originates from an
incomplete knowledge of the domain of interest. With advances in the health
science, many features and functionalities need to be added to, or removed
from, existing software applications in the biomedical domain. At the same
time, the increasing complexity of biomedical systems makes them more difficult
to understand, and consequently it is more difficult to define their
requirements, which contributes considerably to their volatility. In this
paper, we present a novel agent-based approach for analyzing and managing
volatile and dynamic requirements in an ontology-driven laboratory information
management system (LIMS) designed for Web-based case reporting in medical
mycology. The proposed framework is empowered with ontologies and formalized
using category theory to provide a deep and common understanding of the
functional and nonfunctional requirement hierarchies and their interrelations,
and to trace the effects of a change on the conceptual framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1845</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1845</id><created>2009-06-10</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author></authors><title>Towards Improving Validation, Verification, Crash Investigations, and
  Event Reconstruction of Flight-Critical Systems with Self-Forensics</title><categories>cs.SE cs.AI</categories><comments>10 pages; a white discussion paper submitted in response to NASA's
  RFI NNH09ZEA001L at
  http://prod.nais.nasa.gov/cgi-bin/eps/synopsis.cgi?acqid=134490</comments><acm-class>D.2.5; D.2.4; D.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a novel concept of self-forensics to complement the
standard autonomic self-CHOP properties of the self-managed systems, to be
specified in the Forensic Lucid language. We argue that self-forensics, with
the forensics taken out of the cybercrime domain, is applicable to
&quot;self-dissection&quot; for the purpose of verification of autonomous software and
hardware systems of flight-critical systems for automated incident and anomaly
analysis and event reconstruction by the engineering teams in a variety of
incident scenarios during design and testing as well as actual flight data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1849</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1849</id><created>2009-06-10</created><authors><author><keyname>Ghosh</keyname><forenames>Subhas Kumar</forenames><affiliation>Honeywell Technology Solutions</affiliation></author><author><keyname>Misra</keyname><forenames>Janardan</forenames><affiliation>Honeywell Technology Solutions</affiliation></author></authors><title>A Randomized Algorithm for 3-SAT</title><categories>cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we propose and analyze a simple randomized algorithm to find a
satisfiable assignment for a Boolean formula in conjunctive normal form (CNF)
having at most 3 literals in every clause. Given a k-CNF formula phi on n
variables, and alpha in{0,1}^n that satisfies phi, a clause of phi is critical
if exactly one literal of that clause is satisfied under assignment alpha.
Paturi et. al. (Chicago Journal of Theoretical Computer Science 1999) proposed
a simple randomized algorithm (PPZ) for k-SAT for which success probability
increases with the number of critical clauses (with respect to a fixed
satisfiable solution of the input formula). Here, we first describe another
simple randomized algorithm DEL which performs better if the number of critical
clauses are less (with respect to a fixed satisfiable solution of the input
formula). Subsequently, we combine these two simple algorithms such that the
success probability of the combined algorithm is maximum of the success
probabilities of PPZ and DEL on every input instance. We show that when the
average number of clauses per variable that appear as unique true literal in
one or more critical clauses in phi is between 1 and 1.9317, combined algorithm
performs better than the PPZ algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1900</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1900</id><created>2009-06-10</created><authors><author><keyname>Thomas</keyname><forenames>Philippe</forenames><affiliation>CRAN</affiliation></author><author><keyname>Thomas</keyname><forenames>Andr&#xe9;</forenames><affiliation>CRAN</affiliation></author></authors><title>How deals with discrete data for the reduction of simulation models
  using neural network</title><categories>cs.NE</categories><proxy>ccsd hal-00393987</proxy><journal-ref>13th IFAC Symp. On Information Control Problems in Manufacturing
  INCOM'09, Moscou : Russie (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Simulation is useful for the evaluation of a Master Production/distribution
Schedule (MPS). Also, the goal of this paper is the study of the design of a
simulation model by reducing its complexity. According to theory of
constraints, we want to build reduced models composed exclusively by
bottlenecks and a neural network. Particularly a multilayer perceptron, is
used. The structure of the network is determined by using a pruning procedure.
This work focuses on the impact of discrete data on the results and compares
different approaches to deal with these data. This approach is applied to
sawmill internal supply chain
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1905</identifier>
 <datestamp>2009-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1905</id><created>2009-06-10</created><authors><author><keyname>Guio</keyname><forenames>P.</forenames></author><author><keyname>Achilleos</keyname><forenames>N.</forenames></author></authors><title>The VOISE Algorithm: a Versatile Tool for Automatic Segmentation of
  Astronomical Images</title><categories>astro-ph.IM astro-ph.EP cs.CV physics.data-an stat.AP</categories><comments>9 pages, 7 figures; accepted for publication in MNRAS</comments><journal-ref>Mon. Not. R. Astron. Soc. 398 (2009) 1254-1262</journal-ref><doi>10.1111/j.1365-2966.2009.15218.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The auroras on Jupiter and Saturn can be studied with a high sensitivity and
resolution by the Hubble Space Telescope (HST) ultraviolet (UV) and
far-ultraviolet (FUV) Space Telescope spectrograph (STIS) and Advanced Camera
for Surveys (ACS) instruments. We present results of automatic detection and
segmentation of Jupiter's auroral emissions as observed by HST ACS instrument
with VOronoi Image SEgmentation (VOISE). VOISE is a dynamic algorithm for
partitioning the underlying pixel grid of an image into regions according to a
prescribed homogeneity criterion. The algorithm consists of an iterative
procedure that dynamically constructs a tessellation of the image plane based
on a Voronoi Diagram, until the intensity of the underlying image within each
region is classified as homogeneous. The computed tessellations allow the
extraction of quantitative information about the auroral features such as mean
intensity, latitudinal and longitudinal extents and length scales. These
outputs thus represent a more automated and objective method of characterising
auroral emissions than manual inspection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1947</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1947</id><created>2009-06-10</created><authors><author><keyname>Nesterenko</keyname><forenames>Mikhail</forenames><affiliation>LIP6</affiliation></author><author><keyname>Tixeuil</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LIP6</affiliation></author></authors><title>Ideal Stabilization</title><categories>cs.DC</categories><proxy>ccsd inria-00394118</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define and explore the concept of ideal stabilization. The program is
ideally stabilizing if its every state is legitimate. Ideal stabilization
allows the specification designer to prescribe with arbitrary degree of
precision not only the fault-free program behavior but also its recovery
operation. Specifications may or may not mention all possible states. We
identify approaches to designing ideal stabilization to both kinds of
specifications. For the first kind, we state the necessary condition for an
ideally stabilizing solution. On the basis of this condition we prove that
there is no ideally stabilizing solution to the leader election problem. We
illustrate the utility of the concept by providing examples of well-known
programs and proving them ideally stabilizing. Specifically, we prove ideal
stabilization of the conflict manager, the alternator, the propagation of
information with feedback and the alternating bit protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1953</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1953</id><created>2009-06-10</created><updated>2012-04-29</updated><authors><author><keyname>F&#xfc;rer</keyname><forenames>Martin</forenames></author><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Kasiviswanathan</keyname><forenames>Shiva Prasad</forenames></author></authors><title>An Exponential Time 2-Approximation Algorithm for Bandwidth</title><categories>cs.DS cs.DM</categories><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The bandwidth of a graph G on n vertices is the minimum b such that the
vertices of G can be labeled from 1 to n such that the labels of every pair of
adjacent vertices differ by at most b.
  In this paper, we present a 2-approximation algorithm for the bandwidth
problem that takes worst-case O(1.9797^n) time and uses polynomial space. This
improves both the previous best 2- and 3-approximation algorithms of Cygan et
al. which have an O(3^n) and O(2^n) worst-case time bounds, respectively. Our
algorithm is based on constructing bucket decompositions of the input graph. A
bucket decomposition partitions the vertex set of a graph into ordered sets
(called buckets) of (almost) equal sizes such that all edges are either
incident to vertices in the same bucket or to vertices in two consecutive
buckets. The idea is to find the smallest bucket size for which there exists a
bucket decomposition. The algorithm uses a simple divide-and-conquer strategy
along with dynamic programming to achieve this improved time bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1963</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1963</id><created>2009-06-10</created><authors><author><keyname>Bania</keyname><forenames>Piotr</forenames></author></authors><title>Evading network-level emulation</title><categories>cs.CR</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently more and more attention has been paid to the intrusion detection
systems (IDS) which don't rely on signature based detection approach. Such
solutions try to increase their defense level by using heuristics detection
methods like network-level emulation. This technique allows the intrusion
detection systems to stop unknown threats, which normally couldn't be stopped
by standard signature detection techniques.
  In this article author will describe general concepts of network-level
emulation technique including its advantages and disadvantages (weak sides)
together with providing potential countermeasures against this type of
detection method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.1980</identifier>
 <datestamp>2009-06-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.1980</id><created>2009-06-10</created><authors><author><keyname>Allahverdyan</keyname><forenames>Armen</forenames></author><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author></authors><title>On Maximum a Posteriori Estimation of Hidden Markov Processes</title><categories>cs.AI cond-mat.stat-mech cs.IT math.IT physics.data-an stat.ML</categories><comments>9 pages, to appear in the Proceedings of the 25th Conference on
  Uncertainty in Artificial Intelligence (UAI-2009)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a theoretical analysis of Maximum a Posteriori (MAP) sequence
estimation for binary symmetric hidden Markov processes. We reduce the MAP
estimation to the energy minimization of an appropriately defined Ising spin
model, and focus on the performance of MAP as characterized by its accuracy and
the number of solutions corresponding to a typical observed sequence. It is
shown that for a finite range of sufficiently low noise levels, the solution is
uniquely related to the observed sequence, while the accuracy degrades linearly
with increasing the noise strength. For intermediate noise values, the accuracy
is nearly noise-independent, but now there are exponentially many solutions to
the estimation problem, which is reflected in non-zero ground-state entropy for
the Ising model. Finally, for even larger noise intensities, the number of
solutions reduces again, but the accuracy is poor. It is shown that these
regimes are different thermodynamic phases of the Ising model that are related
to each other via first-order phase transitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2020</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2020</id><created>2009-06-10</created><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Krishnaswamy</keyname><forenames>Ravishankar</forenames></author><author><keyname>Kumar</keyname><forenames>Amit</forenames></author><author><keyname>Segev</keyname><forenames>Danny</forenames></author></authors><title>Scheduling with Outliers</title><categories>cs.DS</categories><comments>23 pages, 3 figures</comments><doi>10.1007/978-3-642-03685-9_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In classical scheduling problems, we are given jobs and machines, and have to
schedule all the jobs to minimize some objective function. What if each job has
a specified profit, and we are no longer required to process all jobs -- we can
schedule any subset of jobs whose total profit is at least a (hard) target
profit requirement, while still approximately minimizing the objective
function?
  We refer to this class of problems as scheduling with outliers. This model
was initiated by Charikar and Khuller (SODA'06) on the minimum max-response
time in broadcast scheduling. We consider three other well-studied scheduling
objectives: the generalized assignment problem, average weighted completion
time, and average flow time, and provide LP-based approximation algorithms for
them. For the minimum average flow time problem on identical machines, we give
a logarithmic approximation algorithm for the case of unit profits based on
rounding an LP relaxation; we also show a matching integrality gap. For the
average weighted completion time problem on unrelated machines, we give a
constant factor approximation. The algorithm is based on randomized rounding of
the time-indexed LP relaxation strengthened by the knapsack-cover inequalities.
For the generalized assignment problem with outliers, we give a simple
reduction to GAP without outliers to obtain an algorithm whose makespan is
within 3 times the optimum makespan, and whose cost is at most (1 + \epsilon)
times the optimal cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2027</identifier>
 <datestamp>2012-04-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2027</id><created>2009-06-10</created><updated>2012-04-09</updated><authors><author><keyname>Keshavan</keyname><forenames>Raghunandan H.</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author><author><keyname>Oh</keyname><forenames>Sewoong</forenames></author></authors><title>Matrix Completion from Noisy Entries</title><categories>cs.LG stat.ML</categories><comments>22 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a matrix M of low-rank, we consider the problem of reconstructing it
from noisy observations of a small, random subset of its entries. The problem
arises in a variety of applications, from collaborative filtering (the `Netflix
problem') to structure-from-motion and positioning. We study a low complexity
algorithm introduced by Keshavan et al.(2009), based on a combination of
spectral techniques and manifold optimization, that we call here OptSpace. We
prove performance guarantees that are order-optimal in a number of
circumstances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2032</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2032</id><created>2009-06-10</created><authors><author><keyname>Wang</keyname><forenames>Liming</forenames></author><author><keyname>Schonfeld</keyname><forenames>Dan</forenames></author></authors><title>Mapping Equivalence for Symbolic Sequences: Theory and Applications</title><categories>cs.IT cs.NA math.FA math.IT</categories><doi>10.1109/TSP.2009.2026544</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Processing of symbolic sequences represented by mapping of symbolic data into
numerical signals is commonly used in various applications. It is a
particularly popular approach in genomic and proteomic sequence analysis.
Numerous mappings of symbolic sequences have been proposed for various
applications. It is unclear however whether the processing of symbolic data
provides an artifact of the numerical mapping or is an inherent property of the
symbolic data. This issue has been long ignored in the engineering and
scientific literature. It is possible that many of the results obtained in
symbolic signal processing could be a byproduct of the mapping and might not
shed any light on the underlying properties embedded in the data. Moreover, in
many applications, conflicting conclusions may arise due to the choice of the
mapping used for numerical representation of symbolic data. In this paper, we
present a novel framework for the analysis of the equivalence of the mappings
used for numerical representation of symbolic data. We present strong and weak
equivalence properties and rely on signal correlation to characterize
equivalent mappings. We derive theoretical results which establish conditions
for consistency among numerical mappings of symbolic data. Furthermore, we
introduce an abstract mapping model for symbolic sequences and extend the
notion of equivalence to an algebraic framework. Finally, we illustrate our
theoretical results by application to DNA sequence analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2048</identifier>
 <datestamp>2009-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2048</id><created>2009-06-11</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Im</keyname><forenames>Sungjin</forenames></author><author><keyname>Moseley</keyname><forenames>Benjamin</forenames></author></authors><title>Minimizing Maximum Response Time and Delay Factor in Broadcast
  Scheduling</title><categories>cs.DS</categories><comments>16 pages, 2 figures</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider online algorithms for pull-based broadcast scheduling. In this
setting there are n pages of information at a server and requests for pages
arrive online. When the server serves (broadcasts) a page p, all outstanding
requests for that page are satisfied. We study two related metrics, namely
maximum response time (waiting time) and maximum delay-factor and their
weighted versions. We obtain the following results in the worst-case online
competitive model.
  - We show that FIFO (first-in first-out) is 2-competitive even when the page
sizes are different. Previously this was known only for unit-sized pages [10]
via a delicate argument. Our proof differs from [10] and is perhaps more
intuitive.
  - We give an online algorithm for maximum delay-factor that is
O(1/eps^2)-competitive with (1+\eps)-speed for unit-sized pages and with
(2+\eps)-speed for different sized pages. This improves on the algorithm in
[12] which required (2+\eps)-speed and (4+\eps)-speed respectively. In addition
we show that the algorithm and analysis can be extended to obtain the same
results for maximum weighted response time and delay factor.
  - We show that a natural greedy algorithm modeled after LWF
(Longest-Wait-First) is not O(1)-competitive for maximum delay factor with any
constant speed even in the setting of standard scheduling with unit-sized jobs.
This complements our upper bound and demonstrates the importance of the
tradeoff made in our algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2061</identifier>
 <datestamp>2009-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2061</id><created>2009-06-11</created><authors><author><keyname>Pulikkoonattu</keyname><forenames>Rethnakaran</forenames></author></authors><title>On the Minimum Distance of Non Binary LDPC Codes</title><categories>cs.IT math.IT</categories><comments>Student project report LTHC, EPFL, Switzerland, Jun. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minimum distance is an important parameter of a linear error correcting code.
For improved performance of binary Low Density Parity Check (LDPC) codes, we
need to have the minimum distance grow fast with n, the codelength. However,
the best we can hope for is a linear growth in dmin with n. For binary LDPC
codes, the necessary and sufficient conditions on the LDPC ensemble parameters,
to ensure linear growth of minimum distance is well established. In the case of
non-binary LDPC codes, the structure of logarithmic weight codewords is
different from that of binary codes. We have carried out a preliminary study on
the logarithmic bound on the the minimum distance of non-binary LDPC code
ensembles. In particular, we have investigated certain configurations which
would lead to low weight codewords. A set of simulations are performed to
identify some of these configurations. Finally, we have provided a bound on the
logarithmic minimum distance of nonbinary codes, using a strategy similar to
the girth bound for binary codes. This bound has the same asymptotic behaviour
as that of binary codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2094</identifier>
 <datestamp>2010-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2094</id><created>2009-06-11</created><updated>2010-10-21</updated><authors><author><keyname>Mertikopoulos</keyname><forenames>Panayotis</forenames></author><author><keyname>Moustakas</keyname><forenames>Aris L.</forenames></author></authors><title>The emergence of rational behavior in the presence of stochastic
  perturbations</title><categories>math.PR cs.GT</categories><comments>Published in at http://dx.doi.org/10.1214/09-AAP651 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP651</report-no><journal-ref>Annals of Applied Probability 2010, Vol. 20, No. 4, 1359-1388</journal-ref><doi>10.1214/09-AAP651</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study repeated games where players use an exponential learning scheme in
order to adapt to an ever-changing environment. If the game's payoffs are
subject to random perturbations, this scheme leads to a new stochastic version
of the replicator dynamics that is quite different from the &quot;aggregate shocks&quot;
approach of evolutionary game theory. Irrespective of the perturbations'
magnitude, we find that strategies which are dominated (even iteratively)
eventually become extinct and that the game's strict Nash equilibria are
stochastically asymptotically stable. We complement our analysis by
illustrating these results in the case of congestion games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2135</identifier>
 <datestamp>2009-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2135</id><created>2009-06-11</created><authors><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author><author><keyname>Lagoze</keyname><forenames>Carl</forenames></author><author><keyname>Nelson</keyname><forenames>Michael L.</forenames></author><author><keyname>Warner</keyname><forenames>Simeon</forenames></author><author><keyname>Sanderson</keyname><forenames>Robert</forenames></author><author><keyname>Johnston</keyname><forenames>Pete</forenames></author></authors><title>Adding eScience Assets to the Data Web</title><categories>cs.DL</categories><comments>10 pages, 7 figures. Proceedings of Linked Data on the Web (LDOW2009)
  Workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Aggregations of Web resources are increasingly important in scholarship as it
adopts new methods that are data-centric, collaborative, and networked-based.
The same notion of aggregations of resources is common to the mashed-up,
socially networked information environment of Web 2.0. We present a mechanism
to identify and describe aggregations of Web resources that has resulted from
the Open Archives Initiative - Object Reuse and Exchange (OAI-ORE) project. The
OAI-ORE specifications are based on the principles of the Architecture of the
World Wide Web, the Semantic Web, and the Linked Data effort. Therefore, their
incorporation into the cyberinfrastructure that supports eScholarship will
ensure the integration of the products of scholarly research into the Data Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2143</identifier>
 <datestamp>2009-06-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2143</id><created>2009-06-11</created><authors><author><keyname>Moscicki</keyname><forenames>J. T.</forenames></author><author><keyname>Manara</keyname><forenames>A.</forenames></author><author><keyname>Lamanna</keyname><forenames>M.</forenames></author><author><keyname>Mendez</keyname><forenames>P.</forenames></author><author><keyname>Muraru</keyname><forenames>A.</forenames></author></authors><title>Dependable Distributed Computing for the International Telecommunication
  Union Regional Radio Conference RRC06</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The International Telecommunication Union (ITU) Regional Radio Conference
(RRC06) established in 2006 a new frequency plan for the introduction of
digital broadcasting in European, African, Arab, CIS countries and Iran. The
preparation of the plan involved complex calculations under short deadline and
required dependable and efficient computing capability. The ITU designed and
deployed in-situ a dedicated PC farm, in parallel to the European Organization
for Nuclear Research (CERN) which provided and supported a system based on the
EGEE Grid. The planning cycle at the RRC06 required a periodic execution in the
order of 200,000 short jobs, using several hundreds of CPU hours, in a period
of less than 12 hours. The nature of the problem required dynamic
workload-balancing and low-latency access to the computing resources. We
present the strategy and key technical choices that delivered a reliable
service to the RRC06.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2154</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2154</id><created>2009-06-11</created><updated>2011-04-27</updated><authors><author><keyname>Japaridze</keyname><forenames>Giorgi</forenames><affiliation>School of Computer Science and Technology, Shandong University, Department of Co</affiliation></author></authors><title>From formulas to cirquents in computability logic</title><categories>cs.LO cs.AI cs.CC math.LO</categories><comments>LMCS 7 (2:1) 2011</comments><proxy>LMCS</proxy><acm-class>F.1.1, F.1.2, F.1.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (April 21,
  2011) lmcs:1121</journal-ref><doi>10.2168/LMCS-7(2:1)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computability logic (CoL) (see http://www.cis.upenn.edu/~giorgi/cl.html) is a
recently introduced semantical platform and ambitious program for redeveloping
logic as a formal theory of computability, as opposed to the formal theory of
truth that logic has more traditionally been. Its expressions represent
interactive computational tasks seen as games played by a machine against the
environment, and &quot;truth&quot; is understood as existence of an algorithmic winning
strategy. With logical operators standing for operations on games, the
formalism of CoL is open-ended, and has already undergone series of extensions.
This article extends the expressive power of CoL in a qualitatively new way,
generalizing formulas (to which the earlier languages of CoL were limited) to
circuit-style structures termed cirquents. The latter, unlike formulas, are
able to account for subgame/subtask sharing between different parts of the
overall game/task. Among the many advantages offered by this ability is that it
allows us to capture, refine and generalize the well known
independence-friendly logic which, after the present leap forward, naturally
becomes a conservative fragment of CoL, just as classical logic had been known
to be a conservative fragment of the formula-based version of CoL. Technically,
this paper is self-contained, and can be read without any prior familiarity
with CoL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2212</identifier>
 <datestamp>2009-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2212</id><created>2009-06-11</created><authors><author><keyname>Ghosh</keyname><forenames>Rumi</forenames></author><author><keyname>Lerman</keyname><forenames>Kristina</forenames></author></authors><title>Structure of Heterogeneous Networks</title><categories>cs.CY</categories><journal-ref>2009 IEEE International Conference on Social Computing
  (SocialCom-09)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Heterogeneous networks play a key role in the evolution of communities and
the decisions individuals make. These networks link different types of
entities, for example, people and the events they attend. Network analysis
algorithms usually project such networks unto simple graphs composed of
entities of a single type. In the process, they conflate relations between
entities of different types and loose important structural information. We
develop a mathematical framework that can be used to compactly represent and
analyze heterogeneous networks that combine multiple entity and link types. We
generalize Bonacich centrality, which measures connectivity between nodes by
the number of paths between them, to heterogeneous networks and use this
measure to study network structure. Specifically, we extend the popular
modularity-maximization method for community detection to use this centrality
metric. We also rank nodes based on their connectivity to other nodes. One
advantage of this centrality metric is that it has a tunable parameter we can
use to set the length scale of interactions. By studying how rankings change
with this parameter allows us to identify important nodes in the network. We
apply the proposed method to analyze the structure of several heterogeneous
networks. We show that exploiting additional sources of evidence corresponding
to links between, as well as among, different entity types yields new insights
into network structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2228</identifier>
 <datestamp>2009-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2228</id><created>2009-06-11</created><updated>2009-06-13</updated><authors><author><keyname>Pearce</keyname><forenames>David</forenames></author><author><keyname>Tompits</keyname><forenames>Hans</forenames></author><author><keyname>Woltran</keyname><forenames>Stefan</forenames></author></authors><title>Characterising equilibrium logic and nested logic programs: Reductions
  and complexity</title><categories>cs.LO cs.AI</categories><acm-class>F.4.1</acm-class><journal-ref>Theory and Practice of Logic Programming (2009), 9 : 565-616</journal-ref><doi>10.1017/S147106840999010X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Equilibrium logic is an approach to nonmonotonic reasoning that extends the
stable-model and answer-set semantics for logic programs. In particular, it
includes the general case of nested logic programs, where arbitrary Boolean
combinations are permitted in heads and bodies of rules, as special kinds of
theories. In this paper, we present polynomial reductions of the main reasoning
tasks associated with equilibrium logic and nested logic programs into
quantified propositional logic, an extension of classical propositional logic
where quantifications over atomic formulas are permitted. We provide reductions
not only for decision problems, but also for the central semantical concepts of
equilibrium logic and nested logic programs. In particular, our encodings map a
given decision problem into some formula such that the latter is valid
precisely in case the former holds. The basic tasks we deal with here are the
consistency problem, brave reasoning, and skeptical reasoning. Additionally, we
also provide encodings for testing equivalence of theories or programs under
different notions of equivalence, viz. ordinary, strong, and uniform
equivalence. For all considered reasoning tasks, we analyse their computational
complexity and give strict complexity bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2252</identifier>
 <datestamp>2009-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2252</id><created>2009-06-12</created><authors><author><keyname>Vaze</keyname><forenames>Chinmay S.</forenames></author><author><keyname>Varanasi</keyname><forenames>Mahesh K.</forenames></author></authors><title>Dirty Paper Coding for the MIMO Cognitive Radio Channel with Imperfect
  CSIT</title><categories>cs.IT math.IT</categories><comments>To be presented at ISIT 2009, Seoul, S. Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Dirty Paper Coding (DPC) based transmission scheme for the Gaussian
multiple-input multiple-output (MIMO) cognitive radio channel (CRC) is studied
when there is imperfect and perfect channel knowledge at the transmitters
(CSIT) and the receivers, respectively. In particular, the problem of
optimizing the sum-rate of the MIMO CRC over the transmit covariance matrices
is dealt with. Such an optimization, under the DPC-based transmission strategy,
needs to be performed jointly with an optimization over the inflation factor.
To this end, first the problem of determination of inflation factor over the
MIMO channel $Y=H_1 X + H_2 S + Z$ with imperfect CSIT is investigated. For
this problem, two iterative algorithms, which generalize the corresponding
algorithms proposed for the channel $Y=H(X+S)+Z$, are developed. Later, the
necessary conditions for maximizing the sum-rate of the MIMO CRC over the
transmit covariances for a given choice of inflation factor are derived. Using
these necessary conditions and the algorithms for the determination of the
inflation factor, an iterative, numerical algorithm for the joint optimization
is proposed. Some interesting observations are made from the numerical results
obtained from the algorithm. Furthermore, the high-SNR sum-rate scaling factor
achievable over the CRC with imperfect CSIT is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2274</identifier>
 <datestamp>2009-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2274</id><created>2009-06-12</created><authors><author><keyname>Zuki&#x107;</keyname><forenames>D&#x17e;enan</forenames></author><author><keyname>Rezk-Salama</keyname><forenames>Christof</forenames></author><author><keyname>Kolb</keyname><forenames>Andreas</forenames></author></authors><title>A Neural Network Classifier of Volume Datasets</title><categories>cs.GR cs.AI</categories><comments>10 pages, 10 figures, 1 table, 3IA conference http://3ia.teiath.gr/</comments><acm-class>I.3.6; I.2.6</acm-class><journal-ref>International Conference on Computer Graphics and Artificial
  Intelligence, Proceedings (2009) 53-62</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many state-of-the art visualization techniques must be tailored to the
specific type of dataset, its modality (CT, MRI, etc.), the recorded object or
anatomical region (head, spine, abdomen, etc.) and other parameters related to
the data acquisition process. While parts of the information (imaging modality
and acquisition sequence) may be obtained from the meta-data stored with the
volume scan, there is important information which is not stored explicitly
(anatomical region, tracing compound). Also, meta-data might be incomplete,
inappropriate or simply missing.
  This paper presents a novel and simple method of determining the type of
dataset from previously defined categories. 2D histograms based on intensity
and gradient magnitude of datasets are used as input to a neural network, which
classifies it into one of several categories it was trained with. The proposed
method is an important building block for visualization systems to be used
autonomously by non-experts. The method has been tested on 80 datasets, divided
into 3 classes and a &quot;rest&quot; class.
  A significant result is the ability of the system to classify datasets into a
specific class after being trained with only one dataset of that class. Other
advantages of the method are its easy implementation and its high computational
performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2291</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2291</id><created>2009-06-12</created><updated>2009-06-15</updated><authors><author><keyname>Breitling</keyname><forenames>F.</forenames></author></authors><title>A standard transformation from XML to RDF via XSLT</title><categories>astro-ph.IM cs.DL</categories><comments>4 pages, 1 figure, accepted for publication in Astronomical Notes
  (AN)</comments><doi>10.1002/asna.200811233</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A generic transformation of XML data into the Resource Description Framework
(RDF) and its implementation by XSLT transformations is presented. It was
developed by the grid integration project for robotic telescopes of AstroGrid-D
to provide network communication through the Remote Telescope Markup Language
(RTML) to its RDF based information service. The transformation's generality is
explained by this example. It automates the transformation of XML data into RDF
and thus solves this problem of semantic computing. Its design also permits the
inverse transformation but this is not yet implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2307</identifier>
 <datestamp>2009-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2307</id><created>2009-06-12</created><authors><author><keyname>Cherubini</keyname><forenames>Mauro</forenames></author><author><keyname>de Oliveira</keyname><forenames>Rodrigo</forenames></author><author><keyname>Oliver</keyname><forenames>Nuria</forenames></author></authors><title>Shopping Uncertainties in a Mobile and Social Context</title><categories>cs.HC</categories><comments>Presented in the Late Breaking Results category of Pervasive 2009.
  May 11-14, Nara, Japan. http://www.pervasive2009.org/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We conducted a qualitative user study with 77 consumers to investigate what
social aspects are relevant when supporting customers during their shopping
activities and particularly in situations when they are undecided. Twenty-five
respondents (32%) reported seeking extra information on web pages and forums,
in addition to asking their peers for advice (related to the nature of the item
to be bought). Moreover, from the remaining 52 subjects, only 6 (8%) were
confident enough to make prompt comparisons between items and an immediate
purchasing choice, while 17 respondents (22%) expressed the need for being away
from persuasive elements. The remaining 29 respondents (38%) reported having a
suboptimal strategy for making their shopping decisions (i.e. buying all items,
not buying, or choosing randomly). Therefore, the majority of our participants
(70% = 32% + 38%) had social and information needs when making purchasing
decisions. This result motivates the development of applications that would
allow consumers to ask shopping questions to their social network while
on-the-go.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2311</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2311</id><created>2009-06-12</created><updated>2010-01-31</updated><authors><author><keyname>Avin</keyname><forenames>Chen</forenames></author><author><keyname>Lotker</keyname><forenames>Zvi</forenames></author><author><keyname>Pasquale</keyname><forenames>Francesco</forenames></author><author><keyname>Pignolet</keyname><forenames>Yvonne-Anne</forenames></author></authors><title>A note on uniform power connectivity in the SINR model</title><categories>cs.DM cs.PF</categories><comments>13 pages</comments><doi>10.1007/978-3-642-05434-1_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the connectivity problem for wireless networks under
the Signal to Interference plus Noise Ratio (SINR) model. Given a set of radio
transmitters distributed in some area, we seek to build a directed strongly
connected communication graph, and compute an edge coloring of this graph such
that the transmitter-receiver pairs in each color class can communicate
simultaneously. Depending on the interference model, more or less colors,
corresponding to the number of frequencies or time slots, are necessary. We
consider the SINR model that compares the received power of a signal at a
receiver to the sum of the strength of other signals plus ambient noise . The
strength of a signal is assumed to fade polynomially with the distance from the
sender, depending on the so-called path-loss exponent $\alpha$.
  We show that, when all transmitters use the same power, the number of colors
needed is constant in one-dimensional grids if $\alpha&gt;1$ as well as in
two-dimensional grids if $\alpha&gt;2$. For smaller path-loss exponents and
two-dimensional grids we prove upper and lower bounds in the order of
$\mathcal{O}(\log n)$ and $\Omega(\log n/\log\log n)$ for $\alpha=2$ and
$\Theta(n^{2/\alpha-1})$ for $\alpha&lt;2$ respectively. If nodes are distributed
uniformly at random on the interval $[0,1]$, a \emph{regular} coloring of
$\mathcal{O}(\log n)$ colors guarantees connectivity, while $\Omega(\log \log
n)$ colors are required for any coloring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2315</identifier>
 <datestamp>2009-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2315</id><created>2009-06-12</created><updated>2009-06-14</updated><authors><author><keyname>Jolly</keyname><forenames>Raphael</forenames></author><author><keyname>Kredel</keyname><forenames>Heinz</forenames></author></authors><title>Symbolic Script Programming for Java</title><categories>cs.SC</categories><acm-class>G.4; I.1; D.2.11</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computer algebra in Java is a promising field of development. It has not yet
reached an industrial strength, in part because of a lack of good user
interfaces. Using a general purpose scripting language can bring a natural
mathematical notation, akin to the one of specialized interfaces included in
most computer algebra systems. We present such an interface for Java computer
algebra libraries, using scripts available in the JSR 223 framework. We
introduce the concept of `symbolic programming' and show its usefulness by
prototypes of symbolic polynomials and polynomial rings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2351</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2351</id><created>2009-06-12</created><authors><author><keyname>De Vieilleville</keyname><forenames>F.</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Lachaud</keyname><forenames>Jacques-Olivier</forenames><affiliation>LaBRI</affiliation></author></authors><title>Revisiting Digital Straight Segment Recognition</title><categories>cs.DM</categories><proxy>ccsd hal-00308338</proxy><journal-ref>Proc. Int. Conf. Discrete Geometry for Computer Imagery
  (DGCI2006), Szeged : Hongrie (2006)</journal-ref><doi>10.1007/11907350_30</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents new results about digital straight segments, their
recognition and related properties. They come from the study of the
arithmetically based recognition algorithm proposed by I. Debled-Rennesson and
J.-P. Reveill\`es in 1995 [Debled95]. We indeed exhibit the relations
describing the possible changes in the parameters of the digital straight
segment under investigation. This description is achieved by considering new
parameters on digital segments: instead of their arithmetic description, we
examine the parameters related to their combinatoric description. As a result
we have a better understanding of their evolution during recognition and
analytical formulas to compute them. We also show how this evolution can be
projected onto the Stern-Brocot tree. These new relations have interesting
consequences on the geometry of digital curves. We show how they can for
instance be used to bound the slope difference between consecutive maximal
segments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2369</identifier>
 <datestamp>2010-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2369</id><created>2009-06-12</created><authors><author><keyname>Maletti</keyname><forenames>Andreas</forenames></author><author><keyname>Tirnauca</keyname><forenames>Catalin Ionut</forenames></author></authors><title>Properties of quasi-alphabetic tree bimorphisms</title><categories>cs.CL cs.FL</categories><comments>15 pages, 1 figure</comments><acm-class>F.4.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the class of quasi-alphabetic relations, i.e., tree transformations
defined by tree bimorphisms with two quasi-alphabetic tree homomorphisms and a
regular tree language. We present a canonical representation of these
relations; as an immediate consequence, we get the closure under union. Also,
we show that they are not closed under intersection and complement, and do not
preserve most common operations on trees (branches, subtrees, v-product,
v-quotient, f-top-catenation). Moreover, we prove that the translations defined
by quasi-alphabetic tree bimorphism are exactly products of context-free string
languages. We conclude by presenting the connections between quasi-alphabetic
relations, alphabetic relations and classes of tree transformations defined by
several types of top-down tree transducers. Furthermore, we get that
quasi-alphabetic relations preserve the recognizable and algebraic tree
languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2372</identifier>
 <datestamp>2009-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2372</id><created>2009-06-12</created><authors><author><keyname>Tal</keyname><forenames>Ido</forenames></author><author><keyname>Roth</keyname><forenames>Ron M.</forenames></author></authors><title>Bounds on the Rate of 2-D Bit-Stuffing Encoders</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A method for bounding the rate of bit-stuffing encoders for 2-D constraints
is presented. Instead of considering the original encoder, we consider a
related one which is quasi-stationary. We use the quasi-stationary property in
order to formulate linear requirements that must hold on the probabilities of
the constrained arrays that are generated by the encoder. These requirements
are used as part of a linear program. The minimum and maximum of the linear
program bound the rate of the encoder from below and from above, respectively.
  A lower bound on the rate of an encoder is also a lower bound on the capacity
of the corresponding constraint. For some constraints, our results lead to
tighter lower bounds than what was previously known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2395</identifier>
 <datestamp>2009-06-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2395</id><created>2009-06-12</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Im</keyname><forenames>Sungjin</forenames></author><author><keyname>Moseley</keyname><forenames>Benjamin</forenames></author></authors><title>Longest Wait First for Broadcast Scheduling</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider online algorithms for broadcast scheduling. In the pull-based
broadcast model there are $n$ unit-sized pages of information at a server and
requests arrive online for pages. When the server transmits a page $p$, all
outstanding requests for that page are satisfied. The longest-wait-first} (LWF)
algorithm is a natural algorithm that has been shown to have good empirical
performance. In this paper we make two main contributions to the analysis of
LWF and broadcast scheduling. \begin{itemize} \item We give an intuitive and
easy to understand analysis of LWF which shows that it is
$O(1/\eps^2)$-competitive for average flow-time with $(4+\eps)$ speed. Using a
more involved analysis, we show that LWF is $O(1/\eps^3)$-competitive for
average flow-time with $(3.4+\epsilon)$ speed. \item We show that a natural
extension of LWF is O(1)-speed O(1)-competitive for more general objective
functions such as average delay-factor and $L_k$ norms of delay-factor (for
fixed $k$). \end{itemize}
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2415</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2415</id><created>2009-06-12</created><authors><author><keyname>Danescu-Niculescu-Mizil</keyname><forenames>Cristian</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author><author><keyname>Ducott</keyname><forenames>Richard</forenames></author></authors><title>Without a 'doubt'? Unsupervised discovery of downward-entailing
  operators</title><categories>cs.CL</categories><comments>System output available at
  http://www.cs.cornell.edu/~cristian/Without_a_doubt_-_Data.html</comments><journal-ref>Proceedings of NAACL HLT, pp. 137--145, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important part of textual inference is making deductions involving
monotonicity, that is, determining whether a given assertion entails
restrictions or relaxations of that assertion. For instance, the statement 'We
know the epidemic spread quickly' does not entail 'We know the epidemic spread
quickly via fleas', but 'We doubt the epidemic spread quickly' entails 'We
doubt the epidemic spread quickly via fleas'. Here, we present the first
algorithm for the challenging lexical-semantics problem of learning linguistic
constructions that, like 'doubt', are downward entailing (DE). Our algorithm is
unsupervised, resource-lean, and effective, accurately recovering many DE
operators that are missing from the hand-constructed lists that
textual-inference systems currently use.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2446</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2446</id><created>2009-06-13</created><updated>2009-07-27</updated><authors><author><keyname>Laverdi&#xe8;re</keyname><forenames>Marc-Andr&#xe9;</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Tsapa</keyname><forenames>Suhasini</forenames></author><author><keyname>Benredjem</keyname><forenames>Djamel</forenames></author></authors><title>Ftklipse - Design and Implementation of an Extendable Computer Forensics
  Environment: Software Requirements Specification Document</title><categories>cs.CR cs.SE</categories><comments>SRS project document of an open-source project; 25 pages; 4 figures;
  from April 2006; v2 adds missing .ind file for the index</comments><acm-class>D.4.6; D.3.3; D.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The purpose behind this article is to describe the features of Ftklipse, an
extendable platform for computer forensics. This document designed to provide a
detailed specification for the developers of Ftklipse. Ftklipse is a
thick-client solution for forensics investigation. It is designed to collect
and preserve evidence, to analyze it and to report on it. It supports chain of
custody management, access control policies, and batch operation of its
included tools in order to facilitate and accelerate the investigation. The
environment itself and its tools are configurable as well and is based on
Eclipse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2447</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2447</id><created>2009-06-13</created><updated>2009-07-27</updated><authors><author><keyname>Laverdi&#xe8;re</keyname><forenames>Marc-Andr&#xe9;</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Tsapa</keyname><forenames>Suhasini</forenames></author><author><keyname>Benredjem</keyname><forenames>Djamel</forenames></author></authors><title>Ftklipse - Design and Implementation of an Extendable Computer Forensics
  Environment: Specification Design Document</title><categories>cs.CR cs.SE</categories><comments>37 pages, 11 figures, 3 tables, index; April 24, 2006 project. This
  SDD document follows the SRS specification of the same project found at
  arXiv:0906.2446 ; v2 adds the missing .ind file for the index</comments><acm-class>D.4.6; D.3.3; D.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The purpose of this work is to design and implement a plugin-based
environment that allows to integrate forensic tools working together to support
programming tasks and addition of new tools. Integration is done through GUI
components. The end-system environment must have user friendly GUI,
configuration capabilities, plug-in capabilities to insert/inject new tools,
case management, and chain of custody capabilities, along with evidence
gathering capabilities, evidence preservation capabilities, and, finally report
generation capabilities. A subset of these requirements has been implemented in
Ftklipse, an open-source project, which is detailed throughout the rest of this
document.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2448</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2448</id><created>2009-06-13</created><authors><author><keyname>Chandrasekaran</keyname><forenames>Karthekeyan</forenames></author><author><keyname>Deshpande</keyname><forenames>Amit</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>The Limit of Convexity Based Isoperimetry: Sampling Harmonic-Concave
  Functions</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logconcave functions represent the current frontier of efficient algorithms
for sampling, optimization and integration in R^n. Efficient sampling
algorithms to sample according to a probability density (to which the other two
problems can be reduced) relies on good isoperimetry which is known to hold for
arbitrary logconcave densities. In this paper, we extend this frontier in two
ways: first, we characterize convexity-like conditions that imply good
isoperimetry, i.e., what condition on function values along every line
guarantees good isoperimetry? The answer turns out to be the set of
(1/(n-1))-harmonic concave functions in R^n; we also prove that this is the
best possible characterization along every line, of functions having good
isoperimetry. Next, we give the first efficient algorithm for sampling
according to such functions with complexity depending on a smoothness
parameter. Further, noting that the multivariate Cauchy density is an important
distribution in this class, we exploit certain properties of the Cauchy density
to give an efficient sampling algorithm based on random walks with a mixing
time that matches the current best bounds known for sampling logconcave
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2459</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2459</id><created>2009-06-13</created><authors><author><keyname>Niennattrakul</keyname><forenames>Vit</forenames></author><author><keyname>Ruengronghirunya</keyname><forenames>Pongsakorn</forenames></author><author><keyname>Ratanamahatana</keyname><forenames>Chotirat Ann</forenames></author></authors><title>Exact Indexing for Massive Time Series Databases under Time Warping
  Distance</title><categories>cs.DB cs.AI cs.IR</categories><comments>Submitted to Data Mining and Knowledge Discovery (DMKD). 33 pages, 19
  figures, and 8 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Among many existing distance measures for time series data, Dynamic Time
Warping (DTW) distance has been recognized as one of the most accurate and
suitable distance measures due to its flexibility in sequence alignment.
However, DTW distance calculation is computationally intensive. Especially in
very large time series databases, sequential scan through the entire database
is definitely impractical, even with random access that exploits some index
structures since high dimensionality of time series data incurs extremely high
I/O cost. More specifically, a sequential structure consumes high CPU but low
I/O costs, while an index structure requires low CPU but high I/O costs. In
this work, we therefore propose a novel indexed sequential structure called
TWIST (Time Warping in Indexed Sequential sTructure) which benefits from both
sequential access and index structure. When a query sequence is issued, TWIST
calculates lower bounding distances between a group of candidate sequences and
the query sequence, and then identifies the data access order in advance, hence
reducing a great number of both sequential and random accesses. Impressively,
our indexed sequential structure achieves significant speedup in a querying
process by a few orders of magnitude. In addition, our method shows superiority
over existing rival methods in terms of query processing time, number of page
accesses, and storage requirement with no false dismissal guaranteed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2461</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2461</id><created>2009-06-13</created><authors><author><keyname>Demaine</keyname><forenames>Erik D.</forenames></author><author><keyname>Demaine</keyname><forenames>Martin L.</forenames></author><author><keyname>Hart</keyname><forenames>Vi</forenames></author><author><keyname>Iacono</keyname><forenames>John</forenames></author><author><keyname>Langerman</keyname><forenames>Stefan</forenames></author><author><keyname>O'Rourke</keyname><forenames>Joseph</forenames></author></authors><title>Continuous Blooming of Convex Polyhedra</title><categories>cs.CG cs.DS</categories><comments>13 pages, 6 figures</comments><acm-class>I.3.5; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct the first two continuous bloomings of all convex polyhedra.
First, the source unfolding can be continuously bloomed. Second, any unfolding
of a convex polyhedron can be refined (further cut, by a linear number of cuts)
to have a continuous blooming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2466</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2466</id><created>2009-06-13</created><authors><author><keyname>Chekuri</keyname><forenames>Chandra</forenames></author><author><keyname>Gamzu</keyname><forenames>Iftah</forenames></author></authors><title>Truthful Mechanisms via Greedy Iterative Packing</title><categories>cs.GT cs.DS</categories><comments>20 pages, 1 figure</comments><acm-class>F.2</acm-class><doi>10.1007/978-3-642-03685-9_5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important research thread in algorithmic game theory studies the design of
efficient truthful mechanisms that approximate the optimal social welfare. A
fundamental question is whether an \alpha-approximation algorithm translates
into an \alpha-approximate truthful mechanism. It is well-known that plugging
an \alpha-approximation algorithm into the VCG technique may not yield a
truthful mechanism. Thus, it is natural to investigate properties of
approximation algorithms that enable their use in truthful mechanisms.
  The main contribution of this paper is to identify a useful and natural
property of approximation algorithms, which we call loser-independence; this
property is applicable in the single-minded and single-parameter settings.
Intuitively, a loser-independent algorithm does not change its outcome when the
bid of a losing agent increases, unless that agent becomes a winner. We
demonstrate that loser-independent algorithms can be employed as sub-procedures
in a greedy iterative packing approach while preserving monotonicity. A greedy
iterative approach provides a good approximation in the context of maximizing a
non-decreasing submodular function subject to independence constraints. Our
framework gives rise to truthful approximation mechanisms for various problems.
Notably, some problems arise in online mechanism design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2470</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2470</id><created>2009-06-13</created><authors><author><keyname>Mir</keyname><forenames>Arnau</forenames></author><author><keyname>Rossello</keyname><forenames>Francesc</forenames></author></authors><title>The mean value of the squared path-difference distance for rooted
  phylogenetic trees</title><categories>q-bio.PE cs.DM math.CA q-bio.QM</categories><comments>16 pages</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The path-difference metric is one of the oldest distances for the comparison
of fully resolved phylogenetic trees, but its statistical properties are still
quite unknown. In this paper we compute the mean value of the square of the
path-difference metric between two fully resolved rooted phylogenetic trees
with $n$ leaves, under the uniform distribution. This complements previous work
by Steel and Penny, who computed this mean value for fully resolved unrooted
phylogenetic trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2477</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2477</id><created>2009-06-13</created><authors><author><keyname>Reis</keyname><forenames>Rog&#xe9;rio</forenames></author><author><keyname>Moreira</keyname><forenames>Nelma</forenames></author><author><keyname>Almeida</keyname><forenames>Marco</forenames></author></authors><title>On the Representation of Finite Automata</title><categories>cs.FL</categories><comments>DCFS 2005</comments><report-no>DCC-2005-04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an unique string representation, up to isomorphism, for initially
connected deterministic finite automata (ICDFAs) with n states over an alphabet
of k symbols. We show how to generate all these strings for each n and k, and
how its enumeration provides an alternative way to obtain the exact number of
ICDFAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2509</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2509</id><created>2009-06-14</created><authors><author><keyname>Li</keyname><forenames>Ruihu</forenames></author><author><keyname>Xu</keyname><forenames>Zongben</forenames></author></authors><title>On $[[n,n-4,3]]_{q}$ Quantum MDS Codes for odd prime power $q$</title><categories>cs.IT math.IT</categories><comments>7 pages, submitted to IEEE Trans. Inf. Theory</comments><report-no>CLN: 9-456</report-no><doi>10.1103/PhysRevA.82.052316</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  For each odd prime power $q$, let $4 \leq n\leq q^{2}+1$. Hermitian
self-orthogonal $[n,2,n-1]$ codes over $GF(q^{2})$ with dual distance three are
constructed by using finite field theory. Hence, $[[n,n-4,3]]_{q}$ quantum MDS
codes for $4 \leq n\leq q^{2}+1$ are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2511</identifier>
 <datestamp>2011-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2511</id><created>2009-06-14</created><updated>2011-11-17</updated><authors><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>Robust Rate-Adaptive Wireless Communication Using ACK/NAK-Feedback</title><categories>cs.IT cs.NI math.IT</categories><comments>Relative to the original version, this version includes a revised
  introduction and a few minor technical changes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To combat the detrimental effects of the variability in wireless channels, we
consider cross-layer rate adaptation based on limited feedback. In particular,
based on limited feedback in the form of link-layer acknowledgements (ACK) and
negative acknowledgements (NAK), we maximize the physical-layer transmission
rate subject to an upper bound on the expected packet error rate. \textr{We
take a robust approach in that we do not assume} any particular prior
distribution on the channel state. We first analyze the fundamental limitations
of such systems and derive an upper bound on the achievable rate for signaling
schemes based on uncoded QAM and random Gaussian ensembles. We show that, for
channel estimation based on binary ACK/NAK feedback, it may be preferable to
use a separate training sequence at high error rates, rather than to exploit
low-error-rate data packets themselves. We also develop an adaptive recursive
estimator, which is provably asymptotically optimal and asymptotically
efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2512</identifier>
 <datestamp>2009-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2512</id><created>2009-06-14</created><updated>2009-07-27</updated><authors><author><keyname>Laverdi&#xe8;re</keyname><forenames>Marc-Andr&#xe9;</forenames></author><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Benredjem</keyname><forenames>Djamel</forenames></author></authors><title>On Implementation of a Safer C Library, ISO/IEC TR 24731</title><categories>cs.SE cs.CR</categories><comments>33 pages, 6 figures, 16 listings, index; a report document on the
  open source project. April 2006. v2 adds missing .ind file for the index</comments><acm-class>D.4.6; D.2</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The functions standardized as part of ISO C 1999 and their addendums improved
very little the security options from the previously available library. The
largest flaw remained that no function asked for the buffer size of destination
buffers for any function copying data into a user-supplied buffer. According to
earlier research we performed, we know that error condition handling was the
first solution to security vulnerabilities, followed by precondition
validation. The standard C functions typically perform little precondition
validation and error handling, allowing for a wide range of security issues to
be introduced in their use. ISO/IEC TR 24731, titled as &quot;TR 24731: Safer C
library functions&quot;, defines 41 new library functions for memory copying, string
handling (both for normal and wide character strings), time printing, sorting,
searching etc. Another innovation it brings is a constraint handling
architecture, forcing error handling when certain security-related
preconditions are violated when the functions are called. It also specifies the
null-termination of all strings manipulated through its function and introduces
a new unsigned integer type that helps preventing integer overflows and
underflows. It is currently implemented by Microsoft as part of their Visual
Studio 2005 and above. We examine the architecture of our implementation of
ISO/IEC TR 24731. We first introduce our architectural philosophy before
informing the reader about the Siemens Four View Model, an architectural
methodology for the conception of large-scale software systems. Afterwards, we
examine each of the view, as architected for our library. Finally, we conclude
with other software engineering matters that were of high importance in the
development of our implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2521</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2521</id><created>2009-06-14</created><authors><author><keyname>Weber</keyname><forenames>Volker</forenames></author></authors><title>On the Complexity of Branching-Time Logics</title><categories>cs.LO</categories><comments>The author of this paper, Volker Weber, died after submitting it to
  CSL 2009. The version published here incorporates a few small changes as
  suggested by reviewers of CSL. It was prepared by his Ph.D. advisor, Thomas
  Schwentick</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We classify the complexity of the satisfiability problem for extensions of
CTL and UB. The extensions we consider are Boolean combinations of path
formulas, fairness properties, past modalities, and forgettable past. Our main
result shows that satisfiability for CTL with all these extensions is still in
2-EXPTIME, which strongly contrasts with the nonelementary complexity of CTL*
with forgettable past. We give a complete classification of combinations of
these extensions, yielding a dichotomy between extensions with
2-EXPTIME-complete and those with EXPTIME-complete complexity. In particular,
we show that satisfiability for the extension of UB with forgettable past is
complete for 2-EXPTIME, contradicting a claim for a stronger logic in the
literature. The upper bounds are established with the help of a new kind of
pebble automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2530</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2530</id><created>2009-06-14</created><authors><author><keyname>Donoho</keyname><forenames>David L.</forenames></author><author><keyname>Tanner</keyname><forenames>Jared</forenames></author></authors><title>Observed Universality of Phase Transitions in High-Dimensional Geometry,
  with Implications for Modern Data Analysis and Signal Processing</title><categories>math.ST cs.IT math.IT physics.data-an stat.CO stat.TH</categories><comments>47 pages, 24 figures, 10 tables</comments><doi>10.1098/rsta.2009.0152</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review connections between phase transitions in high-dimensional
combinatorial geometry and phase transitions occurring in modern
high-dimensional data analysis and signal processing. In data analysis, such
transitions arise as abrupt breakdown of linear model selection, robust data
fitting or compressed sensing reconstructions, when the complexity of the model
or the number of outliers increases beyond a threshold. In combinatorial
geometry these transitions appear as abrupt changes in the properties of face
counts of convex polytopes when the dimensions are varied. The thresholds in
these very different problems appear in the same critical locations after
appropriate calibration of variables.
  These thresholds are important in each subject area: for linear modelling,
they place hard limits on the degree to which the now-ubiquitous
high-throughput data analysis can be successful; for robustness, they place
hard limits on the degree to which standard robust fitting methods can tolerate
outliers before breaking down; for compressed sensing, they define the sharp
boundary of the undersampling/sparsity tradeoff in undersampling theorems.
  Existing derivations of phase transitions in combinatorial geometry assume
the underlying matrices have independent and identically distributed (iid)
Gaussian elements. In applications, however, it often seems that Gaussianity is
not required. We conducted an extensive computational experiment and formal
inferential analysis to test the hypothesis that these phase transitions are
{\it universal} across a range of underlying matrix ensembles. The experimental
results are consistent with an asymptotic large-$n$ universality across matrix
ensembles; finite-sample universality can be rejected.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2541</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2541</id><created>2009-06-14</created><authors><author><keyname>Kara</keyname><forenames>Ahmet</forenames></author><author><keyname>Lange</keyname><forenames>Martin</forenames></author><author><keyname>Schwentick</keyname><forenames>Thomas</forenames></author><author><keyname>Weber</keyname><forenames>Volker</forenames></author></authors><title>On the Hybrid Extension of CTL and CTL+</title><categories>cs.LO</categories><doi>10.1007/978-3-642-03816-7_37</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper studies the expressivity, relative succinctness and complexity of
satisfiability for hybrid extensions of the branching-time logics CTL and CTL+
by variables. Previous complexity results show that only fragments with one
variable do have elementary complexity. It is shown that H1CTL+ and H1CTL, the
hybrid extensions with one variable of CTL+ and CTL, respectively, are
expressively equivalent but H1CTL+ is exponentially more succinct than H1CTL.
On the other hand, HCTL+, the hybrid extension of CTL with arbitrarily many
variables does not capture CTL*, as it even cannot express the simple CTL*
property EGFp. The satisfiability problem for H1CTL+ is complete for triply
exponential time, this remains true for quite weak fragments and quite strong
extensions of the logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2547</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2547</id><created>2009-06-15</created><updated>2011-09-12</updated><authors><author><keyname>Cubitt</keyname><forenames>Toby S.</forenames></author><author><keyname>Chen</keyname><forenames>Jianxin</forenames></author><author><keyname>Harrow</keyname><forenames>Aram W.</forenames></author></authors><title>Superactivation of the Asymptotic Zero-Error Classical Capacity of a
  Quantum Channel</title><categories>quant-ph cs.IT math.IT</categories><comments>24 pages. Despite the similar title, contains different results from
  arXiv:0906.2527. See &quot;Note Added&quot; at end of paper for details. V2: Includes
  significantly revised proof of Theorem 27. V3: Includes expanded explanation
  of some of the technical details</comments><journal-ref>IEEE Trans. Inf. Th., vol. 57, no. 12, pp. 8114-8126, Dec 2011</journal-ref><doi>10.1109/TIT.2011.2169109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The zero-error classical capacity of a quantum channel is the asymptotic rate
at which it can be used to send classical bits perfectly, so that they can be
decoded with zero probability of error. We show that there exist pairs of
quantum channels, neither of which individually have any zero-error capacity
whatsoever (even if arbitrarily many uses of the channels are available), but
such that access to even a single copy of both channels allows classical
information to be sent perfectly reliably. In other words, we prove that the
zero-error classical capacity can be superactivated. This result is the first
example of superactivation of a classical capacity of a quantum channel.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2549</identifier>
 <datestamp>2010-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2549</id><created>2009-06-14</created><updated>2009-10-20</updated><authors><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author><author><keyname>Mayernik</keyname><forenames>Matthew</forenames></author><author><keyname>Borgman</keyname><forenames>Christine L.</forenames></author><author><keyname>Van de Sompel</keyname><forenames>Herbert</forenames></author></authors><title>From Artifacts to Aggregations: Modeling Scientific Life Cycles on the
  Semantic Web</title><categories>cs.DL cs.CY</categories><comments>28 pages. To appear in the Journal of the American Society for
  Information Science and Technology (JASIST)</comments><journal-ref>Journal of the American Society for Information Science and
  Technology (JASIST). Volume 61, Issue 3. 2010</journal-ref><doi>10.1002/asi.21263</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the process of scientific research, many information objects are
generated, all of which may remain valuable indefinitely. However, artifacts
such as instrument data and associated calibration information may have little
value in isolation; their meaning is derived from their relationships to each
other. Individual artifacts are best represented as components of a life cycle
that is specific to a scientific research domain or project. Current cataloging
practices do not describe objects at a sufficient level of granularity nor do
they offer the globally persistent identifiers necessary to discover and manage
scholarly products with World Wide Web standards. The Open Archives
Initiative's Object Reuse and Exchange data model (OAI-ORE) meets these
requirements. We demonstrate a conceptual implementation of OAI-ORE to
represent the scientific life cycles of embedded networked sensor applications
in seismology and environmental sciences. By establishing relationships between
publications, data, and contextual research information, we illustrate how to
obtain a richer and more realistic view of scientific practices. That view can
facilitate new forms of scientific research and learning. Our analysis is
framed by studies of scientific practices in a large, multi-disciplinary,
multi-university science and engineering research center, the Center for
Embedded Networked Sensing (CENS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2582</identifier>
 <datestamp>2011-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2582</id><created>2009-06-14</created><updated>2011-03-07</updated><authors><author><keyname>Watanabe</keyname><forenames>Shun</forenames></author><author><keyname>Matsumoto</keyname><forenames>Ryutaroh</forenames></author><author><keyname>Uyematsu</keyname><forenames>Tomohiko</forenames></author></authors><title>Strongly Secure Privacy Amplification Cannot Be Obtained by Encoder of
  Slepian-Wolf Code</title><categories>cs.IT math.IT</categories><comments>10 pages, no figure, A part of this paper will be presented at 2009
  IEEE International Symposium on Information Theory in Seoul, Korea. Version 2
  is a published version. The results are not changed from version 1.
  Explanations are polished and some references are added. In version 3, only
  style and DOI are edited</comments><journal-ref>IEICE Trans. Fundamentals, vol. 93, no. 9, pp. 1650-1659,
  September 2010</journal-ref><doi>10.1587/transfun.E93.A.1650</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The privacy amplification is a technique to distill a secret key from a
random variable by a function so that the distilled key and eavesdropper's
random variable are statistically independent. There are three kinds of
security criteria for the key distilled by the privacy amplification: the
normalized divergence criterion, which is also known as the weak security
criterion, the variational distance criterion, and the divergence criterion,
which is also known as the strong security criterion. As a technique to distill
a secret key, it is known that the encoder of a Slepian-Wolf (the source coding
with full side-information at the decoder) code can be used as a function for
the privacy amplification if we employ the weak security criterion. In this
paper, we show that the encoder of a Slepian-Wolf code cannot be used as a
function for the privacy amplification if we employ the criteria other than the
weak one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2603</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2603</id><created>2009-06-15</created><authors><author><keyname>Soundararajan</keyname><forenames>Rajiv</forenames></author><author><keyname>Vishwanath</keyname><forenames>Sriram</forenames></author></authors><title>Hybrid Coding for Gaussian Broadcast Channels with Gaussian Sources</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, to be presented at ISIT 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a degraded Gaussian broadcast channel over which
Gaussian sources are to be communicated. When the sources are independent, this
paper shows that hybrid coding achieves the optimal distortion region, the same
as that of separate source and channel coding. It also shows that uncoded
transmission is not optimal for this setting. For correlated sources, the paper
shows that a hybrid coding strategy has a better distortion region than
separate source-channel coding below a certain signal to noise ratio threshold.
Thus, hybrid coding is a good choice for Gaussian broadcast channels with
correlated Gaussian sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2609</identifier>
 <datestamp>2015-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2609</id><created>2009-06-15</created><updated>2015-10-19</updated><authors><author><keyname>Lee</keyname><forenames>O. K.</forenames></author><author><keyname>Ye</keyname><forenames>J. C.</forenames></author></authors><title>Concatenate and Boost for Multiple Measurement Vector Problems</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors due to the insufficient
  novelty</comments><acm-class>E.4; G.1.3; G.1.6; H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multiple measurement vector (MMV) problem addresses the recovery of a set of
sparse signal vectors that share common non-zero support, and has emerged an
important topics in compressed sensing. Even though the fundamental performance
limit of recoverable sparsity level has been formally derived, conventional
algorithms still exhibit significant performance gaps from the theoretical
bound. The main contribution of this paper is a novel concatenate MMV and boost
(CoMBo) algorithm that achieves the theoretical bound. More specifically, the
algorithm concatenates MMV to a larger dimensional SMV problem and boosts it by
multiplying random orthonormal matrices. Extensive simulation results
demonstrate that CoMBo outperforms all existing methods and achieves the
theoretical bound as the number of measurement vector increases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2615</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2615</id><created>2009-06-15</created><authors><author><keyname>Graham</keyname><forenames>Carl</forenames><affiliation>CMAP</affiliation></author><author><keyname>Robert</keyname><forenames>Philippe</forenames><affiliation>INRIA</affiliation></author><author><keyname>Verloop</keyname><forenames>Maaike</forenames><affiliation>CWI</affiliation></author></authors><title>Stability Properties of Networks with Interacting TCP Flows</title><categories>cs.NI</categories><proxy>ccsd inria-00395116</proxy><doi>10.1007/978-3-642-10406-0_1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The equilibrium distributions of a Markovian model describing the interaction
of several classes of permanent connections in a network are analyzed. It has
been introduced by Graham and Robert. For this model each of the connections
has a self-adaptive behavior in that its transmission rate along its route
depends on the level of congestion of the nodes on its route. It has been shown
that the invariant distributions are determined by the solutions of a fixed
point equation in a finite dimensional space. In this paper, several examples
of these fixed point equations are studied. The topologies investigated are
rings, trees and a linear network, with various sets of routes through the
nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2635</identifier>
 <datestamp>2010-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2635</id><created>2009-06-15</created><authors><author><keyname>Vina&#x159;</keyname><forenames>Tom&#xe1;&#x161;</forenames></author><author><keyname>Brejov&#xe1;</keyname><forenames>Bro&#x148;a</forenames></author><author><keyname>Song</keyname><forenames>Giltae</forenames></author><author><keyname>Siepel</keyname><forenames>Adam</forenames></author></authors><title>Bayesian History Reconstruction of Complex Human Gene Clusters on a
  Phylogeny</title><categories>cs.LG</categories><acm-class>G.3; J.3</acm-class><journal-ref>Comparative Genomics, International Workshop (RECOMB-CG), 5817
  volume of Lecture Notes in Bioinformatics, pp. 150-163, Budapest, September
  2009. Springer</journal-ref><doi>10.1007/978-3-642-04744-2_13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Clusters of genes that have evolved by repeated segmental duplication present
difficult challenges throughout genomic analysis, from sequence assembly to
functional analysis. Improved understanding of these clusters is of utmost
importance, since they have been shown to be the source of evolutionary
innovation, and have been linked to multiple diseases, including HIV and a
variety of cancers. Previously, Zhang et al. (2008) developed an algorithm for
reconstructing parsimonious evolutionary histories of such gene clusters, using
only human genomic sequence data. In this paper, we propose a probabilistic
model for the evolution of gene clusters on a phylogeny, and an MCMC algorithm
for reconstruction of duplication histories from genomic sequences in multiple
species. Several projects are underway to obtain high quality BAC-based
assemblies of duplicated clusters in multiple species, and we anticipate that
our method will be useful in analyzing these valuable new data sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2667</identifier>
 <datestamp>2010-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2667</id><created>2009-06-15</created><authors><author><keyname>Kretz</keyname><forenames>Tobias</forenames></author></authors><title>The use of dynamic distance potential fields for pedestrian flow around
  corners</title><categories>cs.MA physics.soc-ph</categories><comments>Prepared and Accepted for &quot;First International Conference on
  Evacuation Modeling and Management&quot; (ICEM 09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This contribution investigates situations in pedestrian dynamics, where
trying to walk the shortest path leads to largely different results than trying
to walk the quickest path. A heuristic one-shot method to model the influence
of the will to walk the quickest path is introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2671</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2671</id><created>2009-06-15</created><authors><author><keyname>Doss</keyname><forenames>Catherine</forenames><affiliation>LJLL</affiliation></author><author><keyname>Thieullen</keyname><forenames>Mich&#xe8;le</forenames><affiliation>PMA</affiliation></author></authors><title>Oscillations and Random Perturbations of a FitzHugh-Nagumo System</title><categories>cs.DS</categories><proxy>ccsd hal-00395284</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a stochastic perturbation of a FitzHugh-Nagumo system. We show
that it is possible to generate oscillations for values of parameters which do
not allow oscillations for the deterministic system. We also study the
appearance of a new equilibrium point and new bifurcation parameters due to the
noisy component.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2716</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2716</id><created>2009-06-15</created><authors><author><keyname>De Vieilleville</keyname><forenames>F.</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Lachaud</keyname><forenames>Jacques-Olivier</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Feschet</keyname><forenames>F.</forenames><affiliation>LLAIC1</affiliation></author></authors><title>Maximal digital straight segments and convergence of discrete geometric
  estimators</title><categories>cs.CV cs.CG cs.DM</categories><proxy>ccsd hal-00308336</proxy><journal-ref>Proc. 14th Scandinavian Conference on Image Analysis (SCIA2005),
  Joensuu : Finlande (2005)</journal-ref><doi>10.1007/11499145_100</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete geometric estimators approach geometric quantities on digitized
shapes without any knowledge of the continuous shape. A classical yet difficult
problem is to show that an estimator asymptotically converges toward the true
geometric quantity as the resolution increases. We study here the convergence
of local estimators based on Digital Straight Segment (DSS) recognition. It is
closely linked to the asymptotic growth of maximal DSS, for which we show
bounds both about their number and sizes. These results not only give better
insights about digitized curves but indicate that curvature estimators based on
local DSS recognition are not likely to converge. We indeed invalidate an
hypothesis which was essential in the only known convergence theorem of a
discrete curvature estimator. The proof involves results from arithmetic
properties of digital lines, digital convexity, combinatorics, continued
fractions and random polytopes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2727</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2727</id><created>2009-06-15</created><updated>2009-08-06</updated><authors><author><keyname>Di Gianantonio</keyname><forenames>Pietro</forenames></author><author><keyname>Honsell</keyname><forenames>Furio</forenames></author><author><keyname>Lenisa</keyname><forenames>Marina</forenames></author></authors><title>RPO, Second-order Contexts, and Lambda-calculus</title><categories>cs.PL cs.LO</categories><comments>35 pages, published in Logical Methods in Computer Science</comments><acm-class>F.3.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 5, Issue 3 (August 6,
  2009) lmcs:1120</journal-ref><doi>10.2168/LMCS-5(3:6)2009</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  First, we extend Leifer-Milner RPO theory, by giving general conditions to
obtain IPO labelled transition systems (and bisimilarities) with a reduced set
of transitions, and possibly finitely branching. Moreover, we study the weak
variant of Leifer-Milner theory, by giving general conditions under which the
weak bisimilarity is a congruence. Then, we apply such extended RPO technique
to the lambda-calculus, endowed with lazy and call by value reduction
strategies.
  We show that, contrary to process calculi, one can deal directly with the
lambda-calculus syntax and apply Leifer-Milner technique to a category of
contexts, provided that we work in the framework of weak bisimilarities.
  However, even in the case of the transition system with minimal contexts, the
resulting bisimilarity is infinitely branching, due to the fact that, in
standard context categories, parametric rules such as the beta-rule can be
represented only by infinitely many ground rules.
  To overcome this problem, we introduce the general notion of second-order
context category. We show that, by carrying out the RPO construction in this
setting, the lazy observational equivalence can be captured as a weak
bisimilarity equivalence on a finitely branching transition system. This result
is achieved by considering an encoding of lambda-calculus in Combinatory Logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2738</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2738</id><created>2009-06-15</created><updated>2009-10-05</updated><authors><author><keyname>Nekrich</keyname><forenames>Yakov</forenames></author></authors><title>Data Structures for Approximate Range Counting</title><categories>cs.DS cs.CG</categories><comments>13 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new data structures for approximately counting the number of
points in orthogonal range.
  There is a deterministic linear space data structure that supports updates in
O(1) time and approximates the number of elements in a 1-D range up to an
additive term $k^{1/c}$ in $O(\log \log U\cdot\log \log n)$ time, where $k$ is
the number of elements in the answer, $U$ is the size of the universe and $c$
is an arbitrary fixed constant. We can estimate the number of points in a
two-dimensional orthogonal range up to an additive term $ k^{\rho}$ in $O(\log
\log U+ (1/\rho)\log\log n)$ time for any $\rho&gt;0$. We can estimate the number
of points in a three-dimensional orthogonal range up to an additive term
$k^{\rho}$ in $O(\log \log U + (\log\log n)^3+ (3^v)\log\log n)$ time for
$v=\log \frac{1}{\rho}/\log {3/2}+2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2742</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2742</id><created>2009-06-13</created><authors><author><keyname>Ceuppens</keyname><forenames>Luc</forenames></author><author><keyname>Sardella</keyname><forenames>Alan</forenames></author><author><keyname>Kharitonov</keyname><forenames>Daniel</forenames></author></authors><title>Power Saving Strategies and Technologies in Network Equipment
  Opportunities and Challenges, Risk and Rewards</title><categories>cs.NI</categories><comments>IEEE SAINT 2008 proceedings, July 28th - Aug 1st 2008, PCFNS workshop</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Drawing from todays best-in-class solutions, we identify power-saving
strategies that have succeeded in the past and look forward to new ideas and
paradigms. We strongly believe that designing energy-efficient network
equipment can be compared to building sports cars, task-oriented, focused and
fast. However, unlike track-bound sports cars, ultra-fast and purpose-built
silicon yields better energy efficiency when compared to more generic family
sedan designs that mitigate go-to-market risks by being the masters of many
tasks. Thus, we demonstrate that the best opportunities for power savings come
via protocol simplification, best-of-breed technology, and silicon and software
optimization, to achieve the least amount of processing necessary to move
packets. We also look to the future of networking from a new angle, where
energy efficiency and environmental concerns are viewed as fundamental design
criteria and forces that need to be harnessed to continually create more
powerful networking equipment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2756</identifier>
 <datestamp>2010-11-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2756</id><created>2009-06-15</created><updated>2010-11-06</updated><authors><author><keyname>Hewitt</keyname><forenames>Carl</forenames></author></authors><title>Norms and Commitment for iOrgs(TM) Information Systems: Direct Logic(TM)
  and Participatory Grounding Checking</title><categories>cs.MA cs.LO cs.SE</categories><comments>expanded article</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fundamental assumption of the Event Calculus is overly simplistic when it
comes to organizations in which time-varying properties have to be actively
maintained and managed in order to continue to hold and termination by another
action is not required for a property to no longer hold. I.e., if active
measures are not taken then things will go haywire by default. Similarly
extension and revision is required for Grounding Checking properties of systems
based on a set of ground inferences. Previously Model Checking as been
performed using the model of nondeterministic automata based on states
determined by time-points. These nondeterministic automata are not suitable for
iOrgs, which are highly structured and operate asynchronously with only loosely
bounded nondeterminism. iOrgs Information Systems have been developed as a
technology in which organizations have people that are tightly integrated with
information technology that enables them to function organizationally. iOrgs
formalize existing practices to provide a framework for addressing issues of
authority, accountability, scalability, and robustness using methods that are
analogous to human organizations. In general -iOrgs are a natural extension Web
Services, which are the standard for distributed computing and software
application interoperability in large-scale Organizational Computing. -iOrgs
are structured by Organizational Commitment that is a special case of Physical
Commitment that is defined to be information pledged. iOrgs norms are used to
illustrate the following: -Even a very simple microtheory for normative
reasoning can engender inconsistency In practice, it is impossible to verify
the consistency of a theory for a practical domain. -Improved Safety in
Reasoning. It is not safe to use classical logic and probability theory in
practical reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2760</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2760</id><created>2009-06-15</created><authors><author><keyname>Setter</keyname><forenames>Ophir</forenames></author></authors><title>Constructing Two-Dimensional Voronoi Diagrams via Divide-and-Conquer of
  Envelopes in Space</title><categories>cs.CG</categories><comments>M.Sc. thesis. The work has been carried out at Tel-Aviv University
  under the supervision of Prof. Dan Halperin. 85 pages, 17 figures, 4 tables.
  For some reason the arXiv PDF version looks different than it should. PS is
  preferable</comments><doi>10.1007/978-3-642-16007-3_1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a general framework for computing two-dimensional Voronoi diagrams
of different classes of sites under various distance functions. The framework
is sufficiently general to support diagrams embedded on a family of
two-dimensional parametric surfaces in $R^3$. The computation of the diagrams
is carried out through the construction of envelopes of surfaces in 3-space
provided by CGAL (the Computational Geometry Algorithm Library). The
construction of the envelopes follows a divide-and-conquer approach. A
straightforward application of the divide-and-conquer approach for computing
Voronoi diagrams yields algorithms that are inefficient in the worst case. We
prove that through randomization the expected running time becomes near-optimal
in the worst case. We show how to employ our framework to realize various types
of Voronoi diagrams with different properties by providing implementations for
a vast collection of commonly used Voronoi diagrams. We also show how to apply
the new framework and other existing tools from CGAL to compute minimum-width
annuli of sets of disks, which requires the computation of two Voronoi diagrams
of two different types, and of the overlay of the two diagrams. We do not
assume general position. Namely, we handle degenerate input, and produce exact
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2767</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2767</id><created>2009-06-15</created><authors><author><keyname>Lachaud</keyname><forenames>Jacques-Olivier</forenames><affiliation>LaBRI</affiliation></author></authors><title>Coding cells of digital spaces: a framework to write generic digital
  topology algorithms</title><categories>cs.DM cs.CV</categories><proxy>ccsd hal-00308202</proxy><journal-ref>Proc. Int. Work. Combinatorial Image Analysis (IWCIA2003), Palermo
  : Italie (2003)</journal-ref><doi>10.1016/S1571-0653(04)00497-4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a concise coding of the cells of n-dimensional finite
regular grids. It induces a simple, generic and efficient framework for
implementing classical digital topology data structures and algorithms.
Discrete subsets of multidimensional images (e.g. regions, digital surfaces,
cubical cell complexes) have then a common and compact representation.
Moreover, algorithms have a straightforward and efficient implementation, which
is independent from the dimension or sizes of digital images. We illustrate
that point with generic hypersurface boundary extraction algorithms by scanning
or tracking. This framework has been implemented and basic operations as well
as the presented applications have been benchmarked.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2770</identifier>
 <datestamp>2009-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2770</id><created>2009-06-15</created><authors><author><keyname>De Calignon</keyname><forenames>Martin Braure</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Brun</keyname><forenames>Luc</forenames><affiliation>GREYC</affiliation></author><author><keyname>Lachaud</keyname><forenames>Jacques-Olivier</forenames><affiliation>LaBRI</affiliation></author></authors><title>Combinatorial pyramids and discrete geometry for energy-minimizing
  segmentation</title><categories>cs.CV</categories><proxy>ccsd hal-00308162</proxy><journal-ref>Proc. Int. Symposium on Visual Computing (ISVC2006), Lake Tahoe,
  Nevada : \'Etats-Unis d'Am\'erique (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper defines the basis of a new hierarchical framework for segmentation
algorithms based on energy minimization schemes. This new framework is based on
two formal tools. First, a combinatorial pyramid encode efficiently a hierarchy
of partitions. Secondly, discrete geometric estimators measure precisely some
important geometric parameters of the regions. These measures combined with
photometrical and topological features of the partition allows to design energy
terms based on discrete measures. Our segmentation framework exploits these
energies to build a pyramid of image partitions with a minimization scheme.
Some experiments illustrating our framework are shown and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2812</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2812</id><created>2009-06-15</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>Partial randomness and dimension of recursively enumerable reals</title><categories>cs.CC cs.IT math.IT math.LO</categories><comments>12 pages, no figures, to appear in the Proceedings of the 34st
  International Symposium on Mathematical Foundations of Computer Science (MFCS
  2009), Novy Smokovec, High Tatras, Slovakia, August 24 - 28, 2009</comments><doi>10.1007/978-3-642-03816-7_58</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A real \alpha is called recursively enumerable (&quot;r.e.&quot; for short) if there
exists a computable, increasing sequence of rationals which converges to
\alpha. It is known that the randomness of an r.e. real \alpha can be
characterized in various ways using each of the notions; program-size
complexity, Martin-L\&quot;{o}f test, Chaitin \Omega number, the domination and
\Omega-likeness of \alpha, the universality of a computable, increasing
sequence of rationals which converges to \alpha, and universal probability. In
this paper, we generalize these characterizations of randomness over the notion
of partial randomness by parameterizing each of the notions above by a real T
in (0,1], where the notion of partial randomness is a stronger representation
of the compression rate by means of program-size complexity. As a result, we
present ten equivalent characterizations of the partial randomness of an r.e.
real. The resultant characterizations of partial randomness are powerful and
have many important applications. One of them is to present equivalent
characterizations of the dimension of an individual r.e. real. The equivalence
between the notion of Hausdorff dimension and compression rate by program-size
complexity (or partial randomness) has been established at present by a series
of works of many researchers over the last two decades. We present ten
equivalent characterizations of the dimension of an individual r.e. real.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2819</identifier>
 <datestamp>2009-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2819</id><created>2009-06-15</created><authors><author><keyname>Ramezani</keyname><forenames>Mahdi</forenames></author><author><keyname>Ardakani</keyname><forenames>Masoud</forenames></author></authors><title>Disjoint LDPC Coding for Gaussian Broadcast Channels</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, 3 tables, To appear in Proc. IEEE International
  Symposium on Information Theory (ISIT 2009), Seoul, Korea, June-July 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Low-density parity-check (LDPC) codes have been used for communication over a
two-user Gaussian broadcast channel. It has been shown in the literature that
the optimal decoding of such system requires joint decoding of both user
messages at each user. Also, a joint code design procedure should be performed.
We propose a method which uses a novel labeling strategy and is based on the
idea behind the bit-interleaved coded modulation. This method does not require
joint decoding and/or joint code optimization. Thus, it reduces the overall
complexity of near-capacity coding in broadcast channels. For different rate
pairs on the boundary of the capacity region, pairs of LDPC codes are designed
to demonstrate the success of this technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2820</identifier>
 <datestamp>2009-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2820</id><created>2009-06-15</created><authors><author><keyname>Ma</keyname><forenames>Xudong</forenames></author></authors><title>Equalization for Non-Coherent UWB Systems with Approximate Semi-Definite
  Programming</title><categories>cs.IT math.IT</categories><comments>7 pages, 5 figures, submitted to the 3rd International Conference on
  Signal Processing and Communication Systems, 28 - 30 September 2009, Omaha,
  Nebraska</comments><journal-ref>Proceeding of the 3rd International Conference on Signal
  Processing and Communication Systems, 28 - 30 September 2009, Omaha, Nebraska</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose an approximate semi-definite programming framework
for demodulation and equalization of non-coherent ultra-wide-band communication
systems with inter-symbol-interference. It is assumed that the communication
systems follow non-linear second-order Volterra models. We formulate the
demodulation and equalization problems as semi-definite programming problems.
We propose an approximate algorithm for solving the formulated semi-definite
programming problems. Compared with the existing non-linear equalization
approaches, the proposed semi-definite programming formulation and approximate
solving algorithm have low computational complexity and storage requirements.
We show that the proposed algorithm has satisfactory error probability
performance by simulation results. The proposed non-linear equalization
approach can be adopted for a wide spectrum of non-coherent ultra-wide-band
systems, due to the fact that most non-coherent ultra-wide-band systems with
inter-symbol-interference follow non-linear second-order Volterra signal
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2824</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2824</id><created>2009-06-15</created><authors><author><keyname>Gershenson</keyname><forenames>Carlos</forenames></author></authors><title>What Does Artificial Life Tell Us About Death?</title><categories>cs.AI cs.OH</categories><comments>5 pages</comments><journal-ref>International Journal of Artificial Life Research 2(3):1-5. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Short philosophical essay
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2835</identifier>
 <datestamp>2009-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2835</id><created>2009-06-15</created><authors><author><keyname>Basilyan</keyname><forenames>Mikhail</forenames></author></authors><title>Employing Wikipedia's Natural Intelligence For Cross Language
  Information Retrieval</title><categories>cs.IR cs.CL</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel method for retrieving information in
languages other than that of the query. We use this technique in combination
with existing traditional Cross Language Information Retrieval (CLIR)
techniques to improve their results. This method has a number of advantages
over traditional techniques that rely on machine translation to translate the
query and then search the target document space using a machine translation.
This method is not limited to the availability of a machine translation
algorithm for the desired language and uses already existing sources of readily
available translated information on the internet as a &quot;middle-man&quot; approach. In
this paper we use Wikipedia; however, any similar multilingual, cross
referenced body of documents can be used. For evaluation and comparison
purposes we also implemented a traditional machine translation approach
separately as well as the Wikipedia approach separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2864</identifier>
 <datestamp>2009-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2864</id><created>2009-06-16</created><authors><author><keyname>You</keyname><forenames>Barco</forenames></author></authors><title>Discussion of Twenty Questions Problem</title><categories>cs.IT math.IT</categories><comments>2 pages, 5figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discuss several tricks for solving twenty question problems which in this
paper is depicted as a guessing game. Player tries to find a ball in twenty
boxes by asking as few questions as possible, and these questions are answered
by only &quot;Yes&quot; or &quot;No&quot;. With the discussion, demonstration of source coding
methods is the main concern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2866</identifier>
 <datestamp>2009-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2866</id><created>2009-06-16</created><authors><author><keyname>Hyvernat</keyname><forenames>Pierre</forenames><affiliation>LAMA, Iml</affiliation></author></authors><title>Predicate Transformers, (co)Monads and Resolutions</title><categories>cs.LO</categories><proxy>ccsd hal-00395633</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This short note contains random thoughts about a factorization theorem for
closure/interior operators on a powerset which is reminiscent to the notion of
resolution for a monad/comonad. The question originated from formal topology
but is interesting in itself. The result holds constructively (even if it
classically has several variations); but usually not predicatively (in the
sense that the interpolant will no be given by a set). For those not familiar
with predicativity issues, we look at a ``classical'' version where we bound
the size of the interpolant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2888</identifier>
 <datestamp>2013-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2888</id><created>2009-06-16</created><authors><author><keyname>Benoit</keyname><forenames>Alexandre</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Salvy</keyname><forenames>Bruno</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Chebyshev Expansions for Solutions of Linear Differential Equations</title><categories>cs.SC</categories><proxy>ccsd inria-00395716</proxy><journal-ref>ISSAC'09 (2009)</journal-ref><doi>10.1145/1576702.1576709</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Chebyshev expansion is a series in the basis of Chebyshev polynomials of
the first kind. When such a series solves a linear differential equation, its
coefficients satisfy a linear recurrence equation. We interpret this equation
as the numerator of a fraction of linear recurrence operators. This
interpretation lets us give a simple view of previous algorithms, analyze their
complexity, and design a faster one for large orders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2895</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2895</id><created>2009-06-16</created><updated>2010-11-07</updated><authors><author><keyname>Ilic</keyname><forenames>Velimir M.</forenames></author><author><keyname>Stankovic</keyname><forenames>Miomir S.</forenames></author><author><keyname>Todorovic</keyname><forenames>Branimir T.</forenames></author></authors><title>Entropy Message Passing</title><categories>cs.LG cs.IT math.IT</categories><comments>5 pages, 1 figure, to appear in IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes a new message passing algorithm for cycle-free factor
graphs. The proposed &quot;entropy message passing&quot; (EMP) algorithm may be viewed as
sum-product message passing over the entropy semiring, which has previously
appeared in automata theory. The primary use of EMP is to compute the entropy
of a model. However, EMP can also be used to compute expressions that appear in
expectation maximization and in gradient descent algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2914</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2914</id><created>2009-06-16</created><updated>2009-06-18</updated><authors><author><keyname>Zerola</keyname><forenames>Michal</forenames></author><author><keyname>Lauret</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author><author><keyname>Bart&#xe1;k</keyname><forenames>Roman</forenames></author><author><keyname>&#x160;umbera</keyname><forenames>Michal</forenames></author></authors><title>Efficient Multi-site Data Movement Using Constraint Programming for Data
  Hungry Science</title><categories>cs.DC</categories><comments>To appear in proceedings of Computing in High Energy and Nuclear
  Physics 2009</comments><doi>10.1088/1742-6596/219/6/062069</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the past decade, HENP experiments have been heading towards a distributed
computing model in an effort to concurrently process tasks over enormous data
sets that have been increasing in size as a function of time. In order to
optimize all available resources (geographically spread) and minimize the
processing time, it is necessary to face also the question of efficient data
transfers and placements. A key question is whether the time penalty for moving
the data to the computational resources is worth the presumed gain. Onward to
the truly distributed task scheduling we present the technique using a
Constraint Programming (CP) approach. The CP technique schedules data transfers
from multiple resources considering all available paths of diverse
characteristic (capacity, sharing and storage) having minimum user's waiting
time as an objective. We introduce a model for planning data transfers to a
single destination (data transfer) as well as its extension for an optimal data
set spreading strategy (data placement). Several enhancements for a solver of
the CP model will be shown, leading to a faster schedule computation time using
symmetry breaking, branch cutting, well studied principles from job-shop
scheduling field and several heuristics. Finally, we will present the design
and implementation of a corner-stone application aimed at moving datasets
according to the schedule. Results will include comparison of performance and
trade-off between CP techniques and a Peer-2-Peer model from simulation
framework as well as the real case scenario taken from a practical usage of a
CP scheduler.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2924</identifier>
 <datestamp>2009-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2924</id><created>2009-06-16</created><authors><author><keyname>Cheong</keyname><forenames>Otfried</forenames><affiliation>KAIST</affiliation></author><author><keyname>Goaoc</keyname><forenames>Xavier</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author><author><keyname>Holmsen</keyname><forenames>Andreas</forenames><affiliation>KAIST</affiliation></author></authors><title>Lower Bounds for Pinning Lines by Balls</title><categories>cs.CG</categories><proxy>ccsd inria-00395837</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A line L is a transversal to a family F of convex objects in R^d if it
intersects every member of F. In this paper we show that for every integer d&gt;2
there exists a family of 2d-1 pairwise disjoint unit balls in R^d with the
property that every subfamily of size 2d-2 admits a transversal, yet any line
misses at least one member of the family. This answers a question of Danzer
from 1957.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2925</identifier>
 <datestamp>2009-06-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2925</id><created>2009-06-16</created><authors><author><keyname>Bus&#xe9;</keyname><forenames>Laurent</forenames><affiliation>INRIA Sophia Antipolis</affiliation></author><author><keyname>Ch&#xe8;ze</keyname><forenames>Guillaume</forenames><affiliation>IMT</affiliation></author><author><keyname>Najib</keyname><forenames>Salah</forenames><affiliation>MPI-MIS</affiliation></author></authors><title>Noether's forms for the study of non-composite rational functions and
  their spectrum</title><categories>math.NT cs.SC math.AC</categories><proxy>ccsd inria-00395839</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the spectrum and the decomposability of a multivariate
rational function are studied by means of the effective Noether's
irreducibility theorem given by Ruppert. With this approach, some new effective
results are obtained. In particular, we show that the reduction modulo p of the
spectrum of a given integer multivariate rational function r coincides with the
spectrum of the reduction of r modulo p for p a prime integer greater or equal
to an explicit bound. This bound is given in terms of the degree, the height
and the number of variables of r. With the same strategy, we also study the
decomposability of r modulo p. Some similar explicit results are also provided
for the case of polynomials with coefficients in a polynomial ring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2935</identifier>
 <datestamp>2011-02-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2935</id><created>2009-06-16</created><authors><author><keyname>Fanali</keyname><forenames>Stefania</forenames></author><author><keyname>Giulietti</keyname><forenames>Massimo</forenames></author></authors><title>AG codes on certain maximal curves</title><categories>math.AG cs.IT math.IT</categories><msc-class>94B05, 94B27, 14G50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Algebraic Geometric codes associated to a recently discovered class of
maximal curves are investigated. As a result, some linear codes with better
parameters with respect to the previously known ones are discovered, and 70
improvements on MinT's tables are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2947</identifier>
 <datestamp>2009-11-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2947</id><created>2009-06-16</created><updated>2009-11-10</updated><authors><author><keyname>Basagiannis</keyname><forenames>Stylianos</forenames></author><author><keyname>Katsaros</keyname><forenames>Panagiotis</forenames></author><author><keyname>Pombortsis</keyname><forenames>Andrew</forenames></author></authors><title>Attacking an OT-Based Blind Signature Scheme</title><categories>cs.CR</categories><comments>3 pages, 2 figures, sumbitted for evaluation, under the title
  &quot;Security Analysis of an OT-based blind signature scheme&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we describe an attack against one of the
Oblivious-Transfer-based blind signatures scheme, proposed in [1]. An attacker
with a primitive capability of producing specific-range random numbers, while
exhibiting a partial MITM behavior, is able to corrupt the communication
between the protocol participants. The attack is quite efficient as it leads to
a protocol communication corruption and has a sound-minimal computational cost.
We propose a solution to fix the security flaw.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2960</identifier>
 <datestamp>2012-05-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2960</id><created>2009-06-16</created><authors><author><keyname>Karapetyan</keyname><forenames>Daniel</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Goldengorin</keyname><forenames>Boris</forenames></author></authors><title>Empirical evaluation of construction heuristics for the multidimensional
  assignment problem</title><categories>cs.DS</categories><comments>15 pages</comments><journal-ref>Text in Algorithmics 11 (2009) 107-122</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The multidimensional assignment problem (MAP) (abbreviated s-AP in the case
of s dimensions) is an extension of the well-known assignment problem. The most
studied case of MAP is 3-AP, though the problems with larger values of s have
also a number of applications. In this paper we consider four fast construction
heuristics for MAP. One of the heuristics is new. A modification of the
heuristics is proposed to optimize the access to slow computer memory. The
results of computational experiments for several instance families are provided
and discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2995</identifier>
 <datestamp>2009-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2995</id><created>2009-06-16</created><updated>2009-10-02</updated><authors><author><keyname>Diekert</keyname><forenames>Volker</forenames></author><author><keyname>Kufleitner</keyname><forenames>Manfred</forenames></author></authors><title>Fragments of first-order logic over infinite words</title><categories>cs.FL cs.LO</categories><comments>Conference version presented at 26th International Symposium on
  Theoretical Aspects of Computer Science, STACS 2009</comments><acm-class>F.4.3; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give topological and algebraic characterizations as well as language
theoretic descriptions of the following subclasses of first-order logic FO[&lt;]
for omega-languages: Sigma_2, FO^2, the intersection of FO^2 and Sigma_2, and
Delta_2 (and by duality Pi_2 and the intersection of FO^2 and Pi_2). These
descriptions extend the respective results for finite words. In particular, we
relate the above fragments to language classes of certain (unambiguous)
polynomials. An immediate consequence is the decidability of the membership
problem of these classes, but this was shown before by Wilke and Bojanczyk and
is therefore not our main focus. The paper is about the interplay of algebraic,
topological, and language theoretic properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.2997</identifier>
 <datestamp>2010-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.2997</id><created>2009-06-16</created><updated>2010-11-03</updated><authors><author><keyname>Palmer</keyname><forenames>Ian</forenames></author><author><keyname>Bellissard</keyname><forenames>Jean</forenames></author></authors><title>The Jewett-Krieger Construction for Tilings</title><categories>math.DS cs.IT math.IT math.PR</categories><comments>This paper has been withdrawn in order to address conceptual
  problems. It will be rewritten and resubmitted at a later date</comments><msc-class>37B50 (Primary), 37A35, 37B10, 37A50 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a random distribution of impurities on a periodic crystal, an
equivalent uniquely ergodic tiling space is built, made of aperiodic,
repetitive tilings with finite local complexity, and with configurational
entropy close to the entropy of the impurity distribution. The construction is
the tiling analog of the Jewett-Kreger theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3036</identifier>
 <datestamp>2009-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3036</id><created>2009-06-16</created><updated>2009-10-08</updated><authors><author><keyname>Champenois</keyname><forenames>Gilles</forenames></author></authors><title>Mnesors for automatic control</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mnesors are defined as elements of a semimodule over the min-plus integers.
This two-sorted structure is able to merge graduation properties of vectors and
idempotent properties of boolean numbers, which makes it appropriate for hybrid
systems. We apply it to the control of an inverted pendulum and design a full
logical controller, that is, without the usual algebra of real numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3038</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3038</id><created>2009-06-16</created><authors><author><keyname>Pelechrinis</keyname><forenames>Konstantinos</forenames></author><author><keyname>Broustis</keyname><forenames>Ioannis</forenames></author><author><keyname>Krishnamurthy</keyname><forenames>Srikanth V.</forenames></author><author><keyname>Gkantsidis</keyname><forenames>Christos</forenames></author></authors><title>A measurement driven, 802.11 anti-jamming system</title><categories>cs.NI</categories><comments>16 pages, full version of a submitted work to CoNext 2009 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dense, unmanaged 802.11 deployments tempt saboteurs into launching jamming
attacks by injecting malicious interference. Nowadays, jammers can be portable
devices that transmit intermittently at low power in order to conserve energy.
In this paper, we first conduct extensive experiments on an indoor 802.11
network to assess the ability of two physical layer functions, rate adaptation
and power control, in mitigating jamming. In the presence of a jammer we find
that: (a) the use of popular rate adaptation algorithms can significantly
degrade network performance and, (b) appropriate tuning of the carrier sensing
threshold allows a transmitter to send packets even when being jammed and
enables a receiver capture the desired signal. Based on our findings, we build
ARES, an Anti-jamming REinforcement System, which tunes the parameters of rate
adaptation and power control to improve the performance in the presence of
jammers. ARES ensures that operations under benign conditions are unaffected.
To demonstrate the effectiveness and generality of ARES, we evaluate it in
three wireless testbeds: (a) an 802.11n WLAN with MIMO nodes, (b) an 802.11a/g
mesh network with mobile jammers and (c) an 802.11a WLAN. We observe that ARES
improves the network throughput across all testbeds by up to 150%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3051</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3051</id><created>2009-06-17</created><authors><author><keyname>Holzer</keyname><forenames>Markus</forenames></author><author><keyname>Kutrib</keyname><forenames>Martin</forenames></author><author><keyname>Malcher</keyname><forenames>Andreas</forenames></author></authors><title>Multi-Head Finite Automata: Characterizations, Concepts and Open
  Problems</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 93-107</journal-ref><doi>10.4204/EPTCS.1.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-head finite automata were introduced in (Rabin, 1964) and (Rosenberg,
1966). Since that time, a vast literature on computational and descriptional
complexity issues on multi-head finite automata documenting the importance of
these devices has been developed. Although multi-head finite automata are a
simple concept, their computational behavior can be already very complex and
leads to undecidable or even non-semi-decidable problems on these devices such
as, for example, emptiness, finiteness, universality, equivalence, etc. These
strong negative results trigger the study of subclasses and alternative
characterizations of multi-head finite automata for a better understanding of
the nature of non-recursive trade-offs and, thus, the borderline between
decidable and undecidable problems. In the present paper, we tour a fragment of
this literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3056</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3056</id><created>2009-06-16</created><authors><author><keyname>Zhang</keyname><forenames>Chi</forenames></author><author><keyname>Wang</keyname><forenames>Gang</forenames></author><author><keyname>Liu</keyname><forenames>Xiaoguang</forenames></author><author><keyname>Liu</keyname><forenames>Jing</forenames></author></authors><title>Approximating Scheduling Machines with Capacity Constraints</title><categories>cs.DS</categories><comments>this is a correction of paper to appear at FAW2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Scheduling Machines with Capacity Constraints problem, we are given k
identical machines, each of which can process at most m_i jobs. M jobs are also
given, where job j has a non-negative processing time length t_j &gt;= 0. The task
is to find a schedule such that the makespan is minimized and the capacity
constraints are met. In this paper, we present a 3-approximation algorithm
using an extension of Iterative Rounding Method introduced by Jain. To the best
of the authors' knowledge, this is the first attempt to apply Iterative
Rounding Method to scheduling problem with capacity constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3065</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3065</id><created>2009-06-16</created><authors><author><keyname>Zhang</keyname><forenames>Zhihai</forenames></author><author><keyname>Fang</keyname><forenames>Tian</forenames></author><author><keyname>Xia</keyname><forenames>Bican</forenames></author></authors><title>Real Solution Isolation with Multiplicity of Zero-Dimensional Triangular
  Systems</title><categories>cs.SC cs.MS</categories><comments>12 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Existing algorithms for isolating real solutions of zero-dimensional
polynomial systems do not compute the multiplicities of the solutions. In this
paper, we define in a natural way the multiplicity of solutions of
zero-dimensional triangular polynomial systems and prove that our definition is
equivalent to the classical definition of local (intersection) multiplicity.
Then we present an effective and complete algorithm for isolating real
solutions with multiplicities of zero-dimensional triangular polynomial systems
using our definition. The algorithm is based on interval arithmetic and
square-free factorization of polynomials with real algebraic coefficients. The
computational results on some examples from the literature are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3068</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3068</id><created>2009-06-17</created><authors><author><keyname>Lachaud</keyname><forenames>Jacques-Olivier</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Taton</keyname><forenames>Benjamin</forenames><affiliation>LaBRI</affiliation></author></authors><title>Deformable Model with a Complexity Independent from Image Resolution</title><categories>cs.CV</categories><proxy>ccsd hal-00308195</proxy><journal-ref>Computer Vision and Image Understanding 99 (2005) 453-475</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a parametric deformable model which recovers image components with
a complexity independent from the resolution of input images. The proposed
model also automatically changes its topology and remains fully compatible with
the general framework of deformable models. More precisely, the image space is
equipped with a metric that expands salient image details according to their
strength and their curvature. During the whole evolution of the model, the
sampling of the contour is kept regular with respect to this metric. By this
way, the vertex density is reduced along most parts of the curve while a high
quality of shape representation is preserved. The complexity of the deformable
model is thus improved and is no longer influenced by feature-preserving
changes in the resolution of input images. Building the metric requires a prior
estimation of contour curvature. It is obtained using a robust estimator which
investigates the local variations in the orientation of image gradient.
Experimental results on both computer generated and biomedical images are
presented to illustrate the advantages of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3074</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3074</id><created>2009-06-17</created><authors><author><keyname>Song</keyname><forenames>Miao</forenames></author></authors><title>Feynman Algorithm Implementation for Comparison with Euler in a Uniform
  Elastic Two-Layer 2D and 3D Object Dynamic Deformation Framework in OpenGL
  with GUI</title><categories>cs.GR cs.DS cs.HC</categories><comments>28 pages, 15 figures; from June 2008; portions of this work have been
  subsequently published in conferences</comments><acm-class>I.3.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We implement for comparative purposes the Feynman algorithm within a
C++-based framework for two-layer uniform facet elastic object for real-time
softbody simulation based on physics modeling methods. To facilitate the
comparison, we implement initial timing measurements on the same hardware
against that of Euler integrator in the softbody framework by varying different
algorithm parameters. Due to a relatively large number of such variations we
implement a GLUI-based user-interface to allow for much more finer control over
the simulation process at real-time, which was lacking completely in the
previous versions of the framework. We show our currents results based on the
enhanced framework. The two-layered elastic object consists of inner and outer
elastic mass-spring surfaces and compressible internal pressure. The density of
the inner layer can be set differently from the density of the outer layer; the
motion of the inner layer can be opposite to the motion of the outer layer.
These special features, which cannot be achieved by a single layered object,
result in improved imitation of a soft body, such as tissue's liquid
non-uniform deformation. The inertial behavior of the elastic object is well
illustrated in environments with gravity and collisions with walls, ceiling,
and floor. The collision detection is defined by elastic collision penalty
method and the motion of the object is guided by the Ordinary Differential
Equation computation. Users can interact with the modeled objects, deform them,
and observe the response to their action in real-time and we provide an
extensible framework and its implementation for comparative studies of
different physical-based modeling and integration algorithm implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3083</identifier>
 <datestamp>2014-10-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3083</id><created>2009-06-17</created><updated>2014-10-01</updated><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Middelburg</keyname><forenames>C. A.</forenames></author></authors><title>Instruction sequence notations with probabilistic instructions</title><categories>cs.PL</categories><comments>15 pages, revised because arxiv:1409.6873v1 [cs.LO] has come out</comments><report-no>PRG0906</report-no><acm-class>D.1.4; F.1.1; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper concerns instruction sequences that contain probabilistic
instructions, i.e. instructions that are themselves probabilistic by nature. We
propose several kinds of probabilistic instructions, provide an informal
operational meaning for each of them, and discuss related work. On purpose, we
refrain from providing an ad hoc formal meaning for the proposed kinds of
instructions. We also discuss the approach of projection semantics, which was
introduced in earlier work on instruction sequences, in the light of
probabilistic instruction sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3084</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3084</id><created>2009-06-17</created><authors><author><keyname>Michel</keyname><forenames>Christine</forenames><affiliation>LIESP, Ictt</affiliation></author><author><keyname>George</keyname><forenames>Sebastien</forenames><affiliation>LIESP, Ictt</affiliation></author><author><keyname>Garrot</keyname><forenames>Elise</forenames><affiliation>LIESP, Ictt</affiliation></author></authors><title>Activit\'es collectives et instrumentation. \'Etude de pratiques dans
  l'enseignement sup\'erieur</title><categories>cs.CY</categories><proxy>ccsd hal-00279738</proxy><acm-class>K.3.1</acm-class><journal-ref>Distances et savoirs 5, 4 (2007) pp.527-546</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents the results of a study which concerns Instrumented
Collective Learning Situations (ICLS) used in higher education and according to
different actors's point of view (instructional designer and tutor). Considered
actors have been involved in ICLS conception or in their use with students. We
determine several forms of ICLS (in terms of scenario, tools, kind of activity)
and what educational approaches are adopted by educational actors in their
practices. We detail the results of our study, mainly by highlighting the
&quot;home-made&quot; approach of the actors, that is based on an opportunist and
pragmatic use of available tools in order to fit into the educational contexts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3085</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3085</id><created>2009-06-17</created><authors><author><keyname>Michel</keyname><forenames>Christine</forenames><affiliation>LIESP, Ictt</affiliation></author></authors><title>Poset representation and similarity comparisons os systems in IR</title><categories>cs.IR</categories><proxy>ccsd hal-00199597</proxy><journal-ref>26eme conf\'erence ACM SIGIR, Toronto - Ontario : Canada (2003)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we are using the poset representation to describe the complex
answers given by IR systems after a clustering and ranking processes. The
answers considered may be given by cartographical representations or by
thematic sub-lists of documents. The poset representation, with the graph
theory and the relational representation opens many perspectives in the
definition of new similarity measures capable of taking into account both the
clustering and ranking processes. We present a general method for constructing
new similarity measures and give several examples. These measures can be used
for semi-ordered partitions; moreover, in the comparison of two sets of
answers, the corresponding similarity indicator is an increasing function of
the ranks of presentation of common answers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3089</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3089</id><created>2009-06-17</created><authors><author><keyname>Lachaud</keyname><forenames>Jacques-Olivier</forenames><affiliation>LaBRI</affiliation></author><author><keyname>De Vieilleville</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LaBRI</affiliation></author></authors><title>Convex shapes and convergence speed of discrete tangent estimators</title><categories>cs.DM cs.CG cs.CY</categories><proxy>ccsd hal-00308337</proxy><journal-ref>Proc. Int. Symposium on Visual Computing (ISVC2006), Lake Tahoe,
  Nevada : \'Etats-Unis d'Am\'erique (2006)</journal-ref><doi>10.1007/11919629</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Discrete geometric estimators aim at estimating geometric characteristics of
a shape with only its digitization as input data. Such an estimator is
multigrid convergent when its estimates tend toward the geometric
characteristics of the shape as the digitization step h tends toward 0. This
paper studies the multigrid convergence of tangent estimators based on maximal
digital straight segment recognition. We show that such estimators are
multigrid convergent for some family of convex shapes and that their speed of
convergence is on average O(h^(2/3)). Experiments confirm this result and
suggest that the bound is tight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3101</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3101</id><created>2009-06-17</created><authors><author><keyname>Michel</keyname><forenames>Christine</forenames><affiliation>LIESP, ICTT</affiliation></author><author><keyname>Bobillier-Chaumon</keyname><forenames>Marc-Eric</forenames><affiliation>ICTT</affiliation></author><author><keyname>Tarpin-Bernard</keyname><forenames>Franck</forenames><affiliation>LIESP, ICTT</affiliation></author></authors><title>Fracture num\'erique chez les seniors du 4eme age. Observation d'une
  acculturation technique</title><categories>cs.CY</categories><proxy>ccsd hal-00369611</proxy><journal-ref>Les Cahiers du num\'erique 5, 1 (2009) 147-168</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Very old people accumulate the &quot;handicaps&quot;: social, physical, psychological
or cognitive. Various research thus developed to determine there waiting and
needs and also to see the benefit possibly produced by technologies (called
?gerontechnology?) on their living conditions. The object of this article is to
present the numerical service offer to very old perople and to see how it takes
part in a social justice according to the definition of Rawls (principle of
equal freedom, principle of equal opportunity in the access). The adoption, the
use and the benefit of technology are analyzed in a theoretical way through a
state of the art and in an experimental way through a qualitative and
quantitative investigation carried out with a population of very old people. We
propose to identify dynamic technological acceptance of old people according to
the TAM'S (Technology Acceptance Model) of Davis adapted by (Hamner and Qazi,
2008).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3112</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3112</id><created>2009-06-17</created><authors><author><keyname>Papadakos</keyname><forenames>Panagiotis</forenames></author><author><keyname>Theoharis</keyname><forenames>Yannis</forenames></author><author><keyname>Marketakis</keyname><forenames>Yannis</forenames></author><author><keyname>Armenatzoglou</keyname><forenames>Nikos</forenames></author><author><keyname>Tzitzikas</keyname><forenames>Yannis</forenames></author></authors><title>Object-Relational Database Representations for Text Indexing</title><categories>cs.IR cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the distinctive features of Information Retrieval systems comparing to
Database Management systems, is that they offer better compression for posting
lists, resulting in better I/O performance and thus faster query evaluation. In
this paper, we introduce database representations of the index that reduce the
size (and thus the disk I/Os) of the posting lists. This is not achieved by
redesigning the DBMS, but by exploiting the non 1NF features that existing
Object-Relational DBM systems (ORDBMS) already offer. Specifically, four
different database representations are described and detailed experimental
results for one million pages are reported. Three of these representations are
one order of magnitude more space efficient and faster (in query evaluation)
than the plain relational representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3119</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3119</id><created>2009-06-17</created><authors><author><keyname>Krassovitskiy</keyname><forenames>Alexander</forenames></author><author><keyname>Rogozhin</keyname><forenames>Yurii</forenames></author><author><keyname>Verlan</keyname><forenames>Sergey</forenames></author></authors><title>Computational Power of P Systems with Small Size Insertion and Deletion
  Rules</title><categories>cs.CC</categories><journal-ref>EPTCS 1, 2009, pp. 108-117</journal-ref><doi>10.4204/EPTCS.1.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recent investigations show insertion-deletion systems of small size that are
not complete and cannot generate all recursively enumerable languages. However,
if additional computational distribution mechanisms like P systems are added,
then the computational completeness is achieved in some cases. In this article
we take two insertion-deletion systems that are not computationally complete,
consider them in the framework of P systems and show that the computational
power is strictly increased by proving that any recursively enumerable language
can be generated. At the end some open problems are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3149</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3149</id><created>2009-06-17</created><authors><author><keyname>Tolpin</keyname><forenames>David</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author></authors><title>Semi-Myopic Sensing Plans for Value Optimization</title><categories>cs.AI</categories><comments>9 pages, 4 figures, presented at BISFAI 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following sequential decision problem. Given a set of items
of unknown utility, we need to select one of as high a utility as possible
(``the selection problem''). Measurements (possibly noisy) of item values prior
to selection are allowed, at a known cost. The goal is to optimize the overall
sequential decision process of measurements and selection.
  Value of information (VOI) is a well-known scheme for selecting measurements,
but the intractability of the problem typically leads to using myopic VOI
estimates. In the selection problem, myopic VOI frequently badly underestimates
the value of information, leading to inferior sensing plans. We relax the
strict myopic assumption into a scheme we term semi-myopic, providing a
spectrum of methods that can improve the performance of sensing plans. In
particular, we propose the efficiently computable method of ``blinkered'' VOI,
and examine theoretical bounds for special cases. Empirical evaluation of
``blinkered'' VOI in the selection problem with normally distributed item
values shows that is performs much better than pure myopic VOI.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3155</identifier>
 <datestamp>2010-09-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3155</id><created>2009-06-17</created><updated>2010-09-28</updated><authors><author><keyname>Tsuchida</keyname><forenames>Takayuki</forenames></author></authors><title>A systematic method for constructing time discretizations of integrable
  lattice systems: local equations of motion</title><categories>nlin.SI cs.NA math-ph math.MP</categories><comments>61 pages; (v2)(v3) many minor corrections</comments><report-no>OIQP-09-01</report-no><journal-ref>An abridged half-length version was published as J. Phys. A: Math.
  Theor. 43 (2010) 415202</journal-ref><doi>10.1088/1751-8113/43/41/415202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new method for discretizing the time variable in integrable
lattice systems while maintaining the locality of the equations of motion. The
method is based on the zero-curvature (Lax pair) representation and the
lowest-order &quot;conservation laws&quot;. In contrast to the pioneering work of
Ablowitz and Ladik, our method allows the auxiliary dependent variables
appearing in the stage of time discretization to be expressed locally in terms
of the original dependent variables. The time-discretized lattice systems have
the same set of conserved quantities and the same structures of the solutions
as the continuous-time lattice systems; only the time evolution of the
parameters in the solutions that correspond to the angle variables is
discretized. The effectiveness of our method is illustrated using examples such
as the Toda lattice, the Volterra lattice, the modified Volterra lattice, the
Ablowitz-Ladik lattice (an integrable semi-discrete nonlinear Schroedinger
system), and the lattice Heisenberg ferromagnet model. For the Volterra lattice
and modified Volterra lattice, we also present their ultradiscrete analogues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3162</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3162</id><created>2009-06-17</created><authors><author><keyname>Bilu</keyname><forenames>Yonatan</forenames></author><author><keyname>Linial</keyname><forenames>Nathan</forenames></author></authors><title>Are stable instances easy?</title><categories>cs.CC</categories><comments>14 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the notion of a stable instance for a discrete optimization
problem, and argue that in many practical situations only sufficiently stable
instances are of interest. The question then arises whether stable instances of
NP--hard problems are easier to solve. In particular, whether there exist
algorithms that solve correctly and in polynomial time all sufficiently stable
instances of some NP--hard problem. The paper focuses on the Max--Cut problem,
for which we show that this is indeed the case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3173</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3173</id><created>2009-06-16</created><updated>2009-06-18</updated><authors><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Kuppinger</keyname><forenames>Patrick</forenames></author><author><keyname>B&#xf6;lcskei</keyname><forenames>Helmut</forenames></author></authors><title>Compressed Sensing of Block-Sparse Signals: Uncertainty Relations and
  Efficient Recovery</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Trans. on Signal Processing, version 2 has
  updated figures</comments><doi>10.1109/TSP.2010.2044837</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider compressed sensing of block-sparse signals, i.e., sparse signals
that have nonzero coefficients occurring in clusters. An uncertainty relation
for block-sparse signals is derived, based on a block-coherence measure, which
we introduce. We then show that a block-version of the orthogonal matching
pursuit algorithm recovers block $k$-sparse signals in no more than $k$ steps
if the block-coherence is sufficiently small. The same condition on
block-coherence is shown to guarantee successful recovery through a mixed
$\ell_2/\ell_1$-optimization approach. This complements previous recovery
results for the block-sparse case which relied on small block-restricted
isometry constants. The significance of the results presented in this paper
lies in the fact that making explicit use of block-sparsity can provably yield
better reconstruction properties than treating the signal as being sparse in
the conventional sense, thereby ignoring the additional structure in the
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3183</identifier>
 <datestamp>2010-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3183</id><created>2009-06-17</created><updated>2010-11-19</updated><authors><author><keyname>Tian</keyname><forenames>Chao</forenames><affiliation>Shitz</affiliation></author><author><keyname>Diggavi</keyname><forenames>Suhas</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Approximate Characterizations for the Gaussian Source Broadcast
  Distortion Region</title><categories>cs.IT math.IT</categories><comments>revised version. to appear in Trans. IT</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the joint source-channel coding problem of sending a Gaussian
source on a K-user Gaussian broadcast channel with bandwidth mismatch. A new
outer bound to the achievable distortion region is derived using the technique
of introducing more than one additional auxiliary random variable, which was
previously used to derive sum-rate lower bound for the symmetric Gaussian
multiple description problem. By combining this outer bound with the
achievability result based on source-channel separation, we provide approximate
characterizations of the achievable distortion region within constant
multiplicative factors. Furthermore, we show that the results can be extended
to general broadcast channels, and the performance of the source-channel
separation based approach is also within the same constant multiplicative
factors of the optimum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3186</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3186</id><created>2009-06-17</created><authors><author><keyname>Moser</keyname><forenames>Philippe</forenames></author></authors><title>A General Notion of Useful Information</title><categories>cs.CC</categories><journal-ref>EPTCS 1, 2009, pp. 164-171</journal-ref><doi>10.4204/EPTCS.1.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce a general framework for defining the depth of a
sequence with respect to a class of observers. We show that our general
framework captures all depth notions introduced in complexity theory so far. We
review most such notions, show how they are particular cases of our general
depth framework, and review some classical results about the different depth
notions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3192</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3192</id><created>2009-06-17</created><authors><author><keyname>Kobayashi</keyname><forenames>Mari</forenames><affiliation>Shitz</affiliation></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>Secured Communication over Frequency-Selective Fading Channels: a
  practical Vandermonde precoding</title><categories>cs.IT math.IT</categories><comments>To appear in EURASIP journal on Wireless Communications and
  Networking, special issue on Wireless Physical Security, 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the frequency-selective broadcast channel with
confidential messages (BCC) in which the transmitter sends a confidential
message to receiver 1 and a common message to receivers 1 and 2. In the case of
a block transmission of N symbols followed by a guard interval of L symbols,
the frequency-selective channel can be modeled as a N * (N+L) Toeplitz matrix.
For this special type of multiple-input multiple-output (MIMO) channels, we
propose a practical Vandermonde precoding that consists of projecting the
confidential messages in the null space of the channel seen by receiver 2 while
superposing the common message. For this scheme, we provide the achievable rate
region, i.e. the rate-tuple of the common and confidential messages, and
characterize the optimal covariance inputs for some special cases of interest.
It is proved that the proposed scheme achieves the optimal degree of freedom
(d.o.f) region. More specifically, it enables to send l &lt;= L confidential
messages and N-l common messages simultaneously over a block of N+L symbols.
Interestingly, the proposed scheme can be applied to secured multiuser
scenarios such as the K+1-user frequency-selective BCC with K confidential
messages and the two-user frequency-selective BCC with two confidential
messages. For each scenario, we provide the achievable secrecy degree of
freedom (s.d.o.f.) region of the corresponding frequency-selective BCC and
prove the optimality of the Vandermonde precoding. One of the appealing
features of the proposed scheme is that it does not require any specific
secrecy encoding technique but can be applied on top of any existing powerful
encoding schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3194</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3194</id><created>2009-06-17</created><updated>2012-10-04</updated><authors><author><keyname>Nikitopoulos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Zhang</keyname><forenames>Dan</forenames></author><author><keyname>Lai</keyname><forenames>I-Wei</forenames></author><author><keyname>Ascheid</keyname><forenames>Gerd</forenames></author></authors><title>Complexity-Efficient Enumeration Techniques for Soft-Input, Soft-Output
  Sphere Decoding</title><categories>cs.NI</categories><comments>The final version of this work appears in IEEE Communications Letters</comments><journal-ref>Nikitopoulos, K., Dan Zhang, I-wei Lai;, Ascheid, G.
  &quot;Complexity-efficient enumeration techniques for soft-input, soft-output
  sphere decoding,&quot; IEEE Communications Letters, vol.14, no.4, pp.312-314, Apr.
  2010</journal-ref><doi>10.1109/LCOMM.2010.04.092230</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper two complexity efficient soft sphere-decoder modifications are
proposed for computing the max-log LLR values in iterative MIMO systems, which
avoid the costly, typically needed, full enumeration and sorting (FES)
procedure during the tree traversal without compromising the max-log
performance. It is shown that despite the resulting increase in the number of
expanded nodes, they can be more computationally efficient than the typical
soft sphere decoders by avoiding the unnecessary complexity of FES.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3197</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3197</id><created>2009-06-17</created><authors><author><keyname>Margenstern</keyname><forenames>Maurice</forenames></author></authors><title>On the injectivity of the global function of a cellular automaton in the
  hyperbolic plane (extended abstract)</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 153-163</journal-ref><doi>10.4204/EPTCS.1.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we look at the following question. We consider cellular
automata in the hyperbolic plane, (see Margenstern, 2000, 2007 and Margenstern,
Morita, 2001) and we consider the global function defined on all possible
configurations. Is the injectivity of this function undecidable? The problem
was answered positively in the case of the Euclidean plane by Jarkko Kari, in
1994. In the present paper, we show that the answer is also positive for the
hyperbolic plane: the problem is undecidable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3199</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3199</id><created>2009-06-17</created><authors><author><keyname>Kudlek</keyname><forenames>Manfred</forenames></author></authors><title>Some Considerations on Universality</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 118-122</journal-ref><doi>10.4204/EPTCS.1.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper puts into discussion the concept of universality, in particular for
structures not of the power of Turing computability. The question arises if for
such structures a universal structure of the same kind exists or not. For that
the construction of universal Turing machines and those with some constraints
are presented in some detail.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3200</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3200</id><created>2009-06-17</created><authors><author><keyname>Kobayashi</keyname><forenames>Mari</forenames></author><author><keyname>Liang</keyname><forenames>Yingbin</forenames></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author></authors><title>On the Compound MIMO Broadcast Channels with Confidential Messages</title><categories>cs.IT math.IT</categories><comments>To appear in Proc. IEEE Symposium on Information Theory (ISIT 2009)
  June 28 - July 3, 2009, Seoul, Korea</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the compound multi-input multi-output (MIMO) broadcast channel with
confidential messages (BCC), where one transmitter sends a common message to
two receivers and two confidential messages respectively to each receiver. The
channel state may take one of a finite set of states, and the transmitter knows
the state set but does not know the realization of the state. We study
achievable rates with perfect secrecy in the high SNR regime by characterizing
an achievable secrecy degree of freedom (s.d.o.f.) region for two models, the
Gaussian MIMO-BCC and the ergodic fading multi-input single-output (MISO)-BCC
without a common message. We show that by exploiting an additional temporal
dimension due to state variation in the ergodic fading model, the achievable
s.d.o.f. region can be significantly improved compared to the Gaussian model
with a constant state, although at the price of a larger delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3202</identifier>
 <datestamp>2009-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3202</id><created>2009-06-17</created><updated>2009-10-19</updated><authors><author><keyname>Goldenberg</keyname><forenames>Jacob</forenames></author><author><keyname>Levy</keyname><forenames>Moshe</forenames></author></authors><title>Distance Is Not Dead: Social Interaction and Geographical Distance in
  the Internet Era</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Internet revolution has made long-distance communication dramatically
faster, easier, and cheaper than ever before. This, it has been argued, has
decreased the importance of geographic proximity in social interactions,
transforming our world into a global village with a borderless society. We
argue for the opposite: while technology has undoubtedly increased the overall
level of communication, this increase has been most pronounced for local social
ties. We show that the volume of electronic communications is inversely
proportional to geographic distance, following a Power Law. We directly study
the importance of physical proximity in social interactions by analyzing the
spatial dissemination of new baby names. Counter-intuitively, and in line with
the above argument, the importance of geographic proximity has dramatically
increased with the internet revolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3208</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3208</id><created>2009-06-17</created><authors><author><keyname>Okhotin</keyname><forenames>Alexander</forenames></author></authors><title>Representing a P-complete problem by small trellis automata</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 185-198</journal-ref><doi>10.4204/EPTCS.1.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A restricted case of the Circuit Value Problem known as the Sequential NOR
Circuit Value Problem was recently used to obtain very succinct examples of
conjunctive grammars, Boolean grammars and language equations representing
P-complete languages (Okhotin, http://dx.doi.org/10.1007/978-3-540-74593-8_23
&quot;A simple P-complete problem and its representations by language equations&quot;,
MCU 2007). In this paper, a new encoding of the same problem is proposed, and a
trellis automaton (one-way real-time cellular automaton) with 11 states solving
this problem is constructed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3213</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3213</id><created>2009-06-17</created><authors><author><keyname>Ollinger</keyname><forenames>Nicolas</forenames></author></authors><title>Intrinsically Universal Cellular Automata</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 199-204</journal-ref><doi>10.4204/EPTCS.1.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This talk advocates intrinsic universality as a notion to identify simple
cellular automata with complex computational behavior. After an historical
introduction and proper definitions of intrinsic universality, which is
discussed with respect to Turing and circuit universality, we discuss
construction methods for small intrinsically universal cellular automata before
discussing techniques for proving non universality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3220</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3220</id><created>2009-06-17</created><authors><author><keyname>Rampersad</keyname><forenames>Narad</forenames></author><author><keyname>Shallit</keyname><forenames>Jeffrey</forenames></author></authors><title>Detecting patterns in finite regular and context-free languages</title><categories>cs.FL</categories><comments>9 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider variations on the following problem: given an NFA M and a pattern
p, does there exist an x in L(M) such that p matches x? We consider the
restricted problem where M only accepts a finite language. We also consider the
variation where the pattern p is required only to match a factor of x. We show
that both of these problems are NP-complete. We also consider the same problems
for context-free grammars; in this case the problems become PSPACE-complete.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3224</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3224</id><created>2009-06-17</created><authors><author><keyname>Andreyev</keyname><forenames>Sergey</forenames></author></authors><title>Personal applications, based on moveable / resizable elements</title><categories>cs.HC cs.GR</categories><comments>14 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  All the modern day applications have the interface, absolutely defined by the
developers. The use of adaptive interface or dynamic layout allows some
variations, but even all of them are predetermined on the design stage, because
the best reaction (from designer's view) on any possible users' movement was
hardcoded. But there is a different world of applications, totally constructed
on moveable / resizable elements; such applications turn the full control to
the users. The crucial thing in such programs is that not something but
everything must become moveable and resizable. This article describes the
features of such applications and the algorithm behind their design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3225</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3225</id><created>2009-06-17</created><authors><author><keyname>Durand-Lose</keyname><forenames>J&#xe9;r&#xf4;me</forenames></author></authors><title>Small Turing universal signal machines</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 70-80</journal-ref><doi>10.4204/EPTCS.1.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article aims at providing signal machines as small as possible able to
perform any computation (in the classical understanding). After presenting
signal machines, it is shown how to get universal ones from Turing machines,
cellular-automata and cyclic tag systems. Finally a halting universal signal
machine with 13 meta-signals and 21 collision rules is presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3227</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3227</id><created>2009-06-17</created><authors><author><keyname>Ollinger</keyname><forenames>Nicolas</forenames></author><author><keyname>Richard</keyname><forenames>Ga&#xe9;tan</forenames></author></authors><title>A Particular Universal Cellular Automaton</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 205-214</journal-ref><doi>10.4204/EPTCS.1.20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signals are a classical tool used in cellular automata constructions that
proved to be useful for language recognition or firing-squad synchronisation.
Particles and collisions formalize this idea one step further, describing
regular nets of colliding signals. In the present paper, we investigate the use
of particles and collisions for constructions involving an infinite number of
interacting particles. We obtain a high-level construction for a new smallest
intrinsically universal cellular automaton with 4 states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3228</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3228</id><created>2009-06-17</created><authors><author><keyname>Sutner</keyname><forenames>Klaus</forenames></author></authors><title>Computational Processes and Incompleteness</title><categories>cs.CC cs.LO</categories><journal-ref>EPTCS 1, 2009, pp. 226-234</journal-ref><doi>10.4204/EPTCS.1.22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a formal definition of Wolfram's notion of computational process
based on cellular automata, a physics-like model of computation. There is a
natural classification of these processes into decidable, intermediate and
complete. It is shown that in the context of standard finite injury priority
arguments one cannot establish the existence of an intermediate computational
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3231</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3231</id><created>2009-06-17</created><authors><author><keyname>Verlan</keyname><forenames>Sergey</forenames></author><author><keyname>Rogozhin</keyname><forenames>Yurii</forenames></author></authors><title>New Choice for Small Universal Devices: Symport/Antiport P Systems</title><categories>cs.CC</categories><journal-ref>EPTCS 1, 2009, pp. 235-242</journal-ref><doi>10.4204/EPTCS.1.23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symport/antiport P systems provide a very simple machinery inspired by
corresponding operations in the living cell. It turns out that systems of small
descriptional complexity are needed to achieve the universality by these
systems. This makes them a good candidate for small universal devices replacing
register machines for different simulations, especially when a simulating
parallel machinery is involved. This article contains survey of these systems
and presents different trade-offs between parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3234</identifier>
 <datestamp>2015-01-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3234</id><created>2009-06-17</created><updated>2011-10-08</updated><authors><author><keyname>Rangan</keyname><forenames>Sundeep</forenames></author><author><keyname>Fletcher</keyname><forenames>Alyson K.</forenames></author><author><keyname>Goyal</keyname><forenames>Vivek K</forenames></author></authors><title>Asymptotic Analysis of MAP Estimation via the Replica Method and
  Applications to Compressed Sensing</title><categories>cs.IT math.IT</categories><comments>22 pages; added details on the replica symmetry assumption</comments><journal-ref>IEEE Trans. on Information Theory, vol. 58, no. 3, pp. 1903-1923,
  March 2012</journal-ref><doi>10.1109/TIT.2011.2177575</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The replica method is a non-rigorous but well-known technique from
statistical physics used in the asymptotic analysis of large, random, nonlinear
problems. This paper applies the replica method, under the assumption of
replica symmetry, to study estimators that are maximum a posteriori (MAP) under
a postulated prior distribution. It is shown that with random linear
measurements and Gaussian noise, the replica-symmetric prediction of the
asymptotic behavior of the postulated MAP estimate of an n-dimensional vector
&quot;decouples&quot; as n scalar postulated MAP estimators. The result is based on
applying a hardening argument to the replica analysis of postulated posterior
mean estimators of Tanaka and of Guo and Verdu.
  The replica-symmetric postulated MAP analysis can be readily applied to many
estimators used in compressed sensing, including basis pursuit, lasso, linear
estimation with thresholding, and zero norm-regularized estimation. In the case
of lasso estimation the scalar estimator reduces to a soft-thresholding
operator, and for zero norm-regularized estimation it reduces to a
hard-threshold. Among other benefits, the replica method provides a
computationally-tractable method for precisely predicting various performance
metrics including mean-squared error and sparsity pattern recovery probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3235</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3235</id><created>2009-06-17</created><authors><author><keyname>Calude</keyname><forenames>Cristian S.</forenames></author></authors><title>Simplicity via Provability for Universal Prefix-free Turing Machines</title><categories>cs.IT cs.LO math.IT</categories><journal-ref>EPTCS 1, 2009, pp. 16-21</journal-ref><doi>10.4204/EPTCS.1.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Universality is one of the most important ideas in computability theory.
There are various criteria of simplicity for universal Turing machines.
Probably the most popular one is to count the number of states/symbols. This
criterion is more complex than it may appear at a first glance. In this note we
review recent results in Algorithmic Information Theory and propose three new
criteria of simplicity for universal prefix-free Turing machines. These
criteria refer to the possibility of proving various natural properties of such
a machine (its universality, for example) in a formal theory, PA or ZFC. In all
cases some, but not all, machines are simple.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3240</identifier>
 <datestamp>2009-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3240</id><created>2009-06-17</created><authors><author><keyname>Fogel</keyname><forenames>Efi</forenames></author></authors><title>Minkowski Sum Construction and other Applications of Arrangements of
  Geodesic Arcs on the Sphere</title><categories>cs.CG cs.DS</categories><comments>A Ph.D. thesis carried out at the Tel-Aviv university. 134 pages
  long. The advisor was Prof. Dan Halperin</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present two exact implementations of efficient output-sensitive algorithms
that compute Minkowski sums of two convex polyhedra in 3D. We do not assume
general position. Namely, we handle degenerate input, and produce exact
results. We provide a tight bound on the exact maximum complexity of Minkowski
sums of polytopes in 3D in terms of the number of facets of the summand
polytopes. The algorithms employ variants of a data structure that represents
arrangements embedded on two-dimensional parametric surfaces in 3D, and they
make use of many operations applied to arrangements in these representations.
We have developed software components that support the arrangement
data-structure variants and the operations applied to them. These software
components are generic, as they can be instantiated with any number type.
However, our algorithms require only (exact) rational arithmetic. These
software components together with exact rational-arithmetic enable a robust,
efficient, and elegant implementation of the Minkowski-sum constructions and
the related applications. These software components are provided through a
package of the Computational Geometry Algorithm Library (CGAL) called
Arrangement_on_surface_2. We also present exact implementations of other
applications that exploit arrangements of arcs of great circles embedded on the
sphere. We use them as basic blocks in an exact implementation of an efficient
algorithm that partitions an assembly of polyhedra in 3D with two hands using
infinite translations. This application distinctly shows the importance of
exact computation, as imprecise computation might result with dismissal of
valid partitioning-motions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3245</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3245</id><created>2009-06-17</created><authors><author><keyname>Cachero</keyname><forenames>Cristina</forenames></author><author><keyname>Pardillo</keyname><forenames>Jes&#xfa;s</forenames></author></authors><title>Goal-oriented Data Warehouse Quality Measurement</title><categories>cs.SE</categories><comments>11 pages</comments><acm-class>D.2.1; D.3.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Requirements engineering is known to be a key factor for the success of
software projects. Inside this discipline, goal-oriented requirements
engineering approaches have shown specially suitable to deal with projects
where it is necessary to capture the alignment between system requirements and
stakeholders' needs, as is the case of data-warehousing projects. However, the
mere alignment of data-warehouse system requirements with business goals is not
enough to assure better data-warehousing products; measures and techniques are
also needed to assure the data-warehouse quality. In this paper, we provide a
modelling framework for data-warehouse quality measurement (i*DWQM). This
framework, conceived as an i* extension, provides support for the definition of
data-warehouse requirements analysis models that include quantifiable quality
scenarios, defined in terms of well-formed measures. This extension has been
defined by means of a UML profiling architecture. The resulting framework has
been implemented in the Eclipse development platform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3248</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3248</id><created>2009-06-17</created><authors><author><keyname>Cook</keyname><forenames>Matthew</forenames></author></authors><title>A Concrete View of Rule 110 Computation</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 31-55</journal-ref><doi>10.4204/EPTCS.1.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rule 110 is a cellular automaton that performs repeated simultaneous updates
of an infinite row of binary values. The values are updated in the following
way: 0s are changed to 1s at all positions where the value to the right is a 1,
while 1s are changed to 0s at all positions where the values to the left and
right are both 1. Though trivial to define, the behavior exhibited by Rule 110
is surprisingly intricate, and in (Cook, 2004) we showed that it is capable of
emulating the activity of a Turing machine by encoding the Turing machine and
its tape into a repeating left pattern, a central pattern, and a repeating
right pattern, which Rule 110 then acts on. In this paper we provide an
explicit compiler for converting a Turing machine into a Rule 110 initial
state, and we present a general approach for proving that such constructions
will work as intended. The simulation was originally assumed to require
exponential time, but surprising results of Neary and Woods (2006) have shown
that in fact, only polynomial time is required. We use the methods of Neary and
Woods to exhibit a direct simulation of a Turing machine by a tag system in
polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3251</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3251</id><created>2009-06-17</created><authors><author><keyname>Doty</keyname><forenames>David</forenames></author><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Summers</keyname><forenames>Scott M.</forenames></author></authors><title>Limitations of Self-Assembly at Temperature One (extended abstract)</title><categories>cs.CC</categories><journal-ref>EPTCS 1, 2009, pp. 67-69</journal-ref><doi>10.4204/EPTCS.1.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that if a subset X of the integer Cartesian plane weakly
self-assembles at temperature 1 in a deterministic (Winfree) tile assembly
system satisfying a natural condition known as *pumpability*, then X is a
finite union of doubly periodic sets. This shows that only the most simple of
infinite shapes and patterns can be constructed using pumpable temperature 1
tile assembly systems, and gives strong evidence for the thesis that
temperature 2 or higher is required to carry out general-purpose computation in
a tile assembly system. Finally, we show that general-purpose computation is
possible at temperature 1 if negative glue strengths are allowed in the tile
assembly model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3256</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3256</id><created>2009-06-17</created><authors><author><keyname>Bournez</keyname><forenames>Olivier</forenames></author><author><keyname>Chalopin</keyname><forenames>J&#xe9;r&#xe9;mie</forenames></author><author><keyname>Cohen</keyname><forenames>Johanne</forenames></author><author><keyname>Koegler</keyname><forenames>Xavier</forenames></author></authors><title>Playing With Population Protocols</title><categories>cs.GT</categories><journal-ref>EPTCS 1, 2009, pp. 3-15</journal-ref><doi>10.4204/EPTCS.1.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Population protocols have been introduced as a model of sensor networks
consisting of very limited mobile agents with no control over their own
movement: A collection of anonymous agents, modeled by finite automata,
interact in pairs according to some rules.
  Predicates on the initial configurations that can be computed by such
protocols have been characterized under several hypotheses.
  We discuss here whether and when the rules of interactions between agents can
be seen as a game from game theory. We do so by discussing several basic
protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3257</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3257</id><created>2009-06-17</created><authors><author><keyname>Lafitte</keyname><forenames>Gr&#xe9;gory</forenames></author></authors><title>Busy beavers gone wild</title><categories>cs.LO</categories><journal-ref>EPTCS 1, 2009, pp. 123-129</journal-ref><doi>10.4204/EPTCS.1.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show some incompleteness results a la Chaitin using the busy beaver
functions. Then, with the help of ordinal logics, we show how to obtain a
theory in which the values of the busy beaver functions can be provably
established and use this to reveal a structure on the provability of the values
of these functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3282</identifier>
 <datestamp>2010-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3282</id><created>2009-06-17</created><updated>2009-10-27</updated><authors><author><keyname>Lingasubramanian</keyname><forenames>Karthikeyan</forenames></author><author><keyname>Alam</keyname><forenames>Syed M.</forenames></author><author><keyname>Bhanja</keyname><forenames>Sanjukta</forenames></author></authors><title>Maximum Error Modeling for Fault-Tolerant Computation using Maximum a
  posteriori (MAP) Hypothesis</title><categories>cs.IT cs.GL math.IT</categories><journal-ref>Microelectronics Reliability, 2010</journal-ref><doi>10.1016/j.microrel.2010.07.156</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The application of current generation computing machines in safety-centric
applications like implantable biomedical chips and automobile safety has
immensely increased the need for reviewing the worst-case error behavior of
computing devices for fault-tolerant computation. In this work, we propose an
exact probabilistic error model that can compute the maximum error over all
possible input space in a circuit specific manner and can handle various types
of structural dependencies in the circuit. We also provide the worst-case input
vector, which has the highest probability to generate an erroneous output, for
any given logic circuit. We also present a study of circuit-specific error
bounds for fault-tolerant computation in heterogeneous circuits using the
maximum error computed for each circuit. We model the error estimation problem
as a maximum a posteriori (MAP) estimate, over the joint error probability
function of the entire circuit, calculated efficiently through an intelligent
search of the entire input space using probabilistic traversal of a binary join
tree using Shenoy-Shafer algorithm. We demonstrate this model using MCNC and
ISCAS benchmark circuits and validate it using an equivalent HSpice model. Both
results yield the same worst-case input vectors and the highest % difference of
our error model over HSpice is just 1.23%. We observe that the maximum error
probabilities are significantly larger than the average error probabilities,
and provides a much tighter error bounds for fault-tolerant computation. We
also find that the error estimates depend on the specific circuit structure and
the maximum error probabilities are sensitive to the individual gate failure
probabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3284</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3284</id><created>2009-06-17</created><authors><author><keyname>Goles</keyname><forenames>Eric</forenames></author><author><keyname>Meunier</keyname><forenames>Pierre-Etienne</forenames></author><author><keyname>Rapaport</keyname><forenames>Ivan</forenames></author><author><keyname>Theyssier</keyname><forenames>Guillaume</forenames></author></authors><title>Communications in cellular automata</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 81-92</journal-ref><doi>10.4204/EPTCS.1.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The goal of this paper is to show why the framework of communication
complexity seems suitable for the study of cellular automata. Researchers have
tackled different algorithmic problems ranging from the complexity of
predicting to the decidability of different dynamical properties of cellular
automata. But the difference here is that we look for communication protocols
arising in the dynamics itself. Our work is guided by the following idea: if we
are able to give a protocol describing a cellular automaton, then we can
understand its behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3286</identifier>
 <datestamp>2009-06-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3286</id><created>2009-06-17</created><authors><author><keyname>Lunnon</keyname><forenames>Fred</forenames></author></authors><title>The Pagoda Sequence: a Ramble through Linear Complexity, Number Walls,
  D0L Sequences, Finite State Automata, and Aperiodic Tilings</title><categories>cs.DM</categories><journal-ref>EPTCS 1, 2009, pp. 130-148</journal-ref><doi>10.4204/EPTCS.1.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the concept of the number wall as an alternative to the traditional
linear complexity profile (LCP), and sketch the relationship to other topics
such as linear feedback shift-register (LFSR) and context-free Lindenmayer
(D0L) sequences. A remarkable ternary analogue of the Thue-Morse sequence is
introduced having deficiency 2 modulo 3, and this property verified via the
re-interpretation of the number wall as an aperiodic plane tiling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3306</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3306</id><created>2009-06-17</created><authors><author><keyname>Patitz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Summers</keyname><forenames>Scott M.</forenames></author></authors><title>Self-Assembly of Infinite Structures</title><categories>cs.CC</categories><journal-ref>EPTCS 1, 2009, pp. 215-225</journal-ref><doi>10.4204/EPTCS.1.21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review some recent results related to the self-assembly of infinite
structures in the Tile Assembly Model. These results include impossibility
results, as well as novel tile assembly systems in which shapes and patterns
that represent various notions of computation self-assemble. Several open
questions are also presented and motivated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3313</identifier>
 <datestamp>2010-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3313</id><created>2009-06-18</created><updated>2009-07-23</updated><authors><author><keyname>Ramakrishnan</keyname><forenames>Venkatesh</forenames><affiliation>Institute for Integrated Signal Processing Systems, RWTH Aachen University, Germany</affiliation></author><author><keyname>Witte</keyname><forenames>Ernst M.</forenames><affiliation>Institute for Integrated Signal Processing Systems, RWTH Aachen University, Germany</affiliation></author><author><keyname>Kempf</keyname><forenames>Torsten</forenames><affiliation>Institute for Integrated Signal Processing Systems, RWTH Aachen University, Germany</affiliation></author><author><keyname>Kammler</keyname><forenames>David</forenames><affiliation>Institute for Integrated Signal Processing Systems, RWTH Aachen University, Germany</affiliation></author><author><keyname>Ascheid</keyname><forenames>Gerd</forenames><affiliation>Institute for Integrated Signal Processing Systems, RWTH Aachen University, Germany</affiliation></author><author><keyname>Meyr</keyname><forenames>Heinrich</forenames><affiliation>Institute for Integrated Signal Processing Systems, RWTH Aachen University, Germany</affiliation></author><author><keyname>Adrat</keyname><forenames>Marc</forenames><affiliation>Research Establishment for Applied Science</affiliation></author><author><keyname>Antweiler</keyname><forenames>Markus</forenames><affiliation>Research Establishment for Applied Science</affiliation></author></authors><title>Efficient And Portable SDR Waveform Development: The Nucleus Concept</title><categories>cs.IT cs.NI math.IT</categories><comments>To Appear in 2009 IEEE Military Communications Conference (MILCOM
  2009)</comments><doi>10.1109/MILCOM.2009.5379897</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Future wireless communication systems should be flexible to support different
waveforms (WFs) and be cognitive to sense the environment and tune themselves.
This has lead to tremendous interest in software defined radios (SDRs).
Constraints like throughput, latency and low energy demand high implementation
efficiency. The tradeoff of going for a highly efficient implementation is the
increase of porting effort to a new hardware (HW) platform. In this paper, we
propose a novel concept for WF development, the Nucleus concept, that exploits
the common structure in various wireless signal processing algorithms and
provides a way for efficient and portable implementation. Tool assisted WF
mapping and exploration is done efficiently by propagating the implementation
and interface properties of Nuclei. The Nucleus concept aims at providing
software flexibility with high level programmability, but at the same time
limiting HW flexibility to maximize area and energy efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3323</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3323</id><created>2009-06-17</created><authors><author><keyname>Myronenko</keyname><forenames>Andriy</forenames></author><author><keyname>Song</keyname><forenames>Xubo</forenames></author></authors><title>Adaptive Regularization of Ill-Posed Problems: Application to Non-rigid
  Image Registration</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an adaptive regularization approach. In contrast to conventional
Tikhonov regularization, which specifies a fixed regularization operator, we
estimate it simultaneously with parameters. From a Bayesian perspective we
estimate the prior distribution on parameters assuming that it is close to some
given model distribution. We constrain the prior distribution to be a
Gauss-Markov random field (GMRF), which allows us to solve for the prior
distribution analytically and provides a fast optimization algorithm. We apply
our approach to non-rigid image registration to estimate the spatial
transformation between two images. Our evaluation shows that the adaptive
regularization approach significantly outperforms standard variational methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3327</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3327</id><created>2009-06-17</created><authors><author><keyname>Murphy</keyname><forenames>Niall</forenames></author><author><keyname>Woods</keyname><forenames>Damien</forenames></author></authors><title>On acceptance conditions for membrane systems: characterisations of L
  and NL</title><categories>cs.CC cs.DM</categories><journal-ref>EPTCS 1, 2009, pp. 172-184</journal-ref><doi>10.4204/EPTCS.1.17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate the affect of various acceptance conditions on
recogniser membrane systems without dissolution. We demonstrate that two
particular acceptance conditions (one easier to program, the other easier to
prove correctness) both characterise the same complexity class, NL. We also
find that by restricting the acceptance conditions we obtain a characterisation
of L. We obtain these results by investigating the connectivity properties of
dependency graphs that model membrane system computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3329</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3329</id><created>2009-06-17</created><authors><author><keyname>De Mol</keyname><forenames>Liesbeth</forenames></author></authors><title>On the boundaries of solvability and unsolvability in tag systems.
  Theoretical and Experimental Results</title><categories>cs.CC cs.DM cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 56-66</journal-ref><doi>10.4204/EPTCS.1.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several older and more recent results on the boundaries of solvability and
unsolvability in tag systems are surveyed. Emphasis will be put on the
significance of computer experiments in research on very small tag systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3332</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3332</id><created>2009-06-17</created><authors><author><keyname>Cavaliere</keyname><forenames>Matteo</forenames></author><author><keyname>Leupold</keyname><forenames>Peter</forenames></author></authors><title>Complexity through the Observation of Simple Systems</title><categories>cs.CC cs.DM cs.FL</categories><journal-ref>EPTCS 1, 2009, pp. 22-30</journal-ref><doi>10.4204/EPTCS.1.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey work on the paradigm called &quot;computing by observing.&quot; Its central
feature is that one considers the behavior of an evolving system as the result
of a computation. To this end an observer records this behavior. It has turned
out that the observed behavior of computationally simple systems can be very
complex, when an appropriate observer is used. For example, a restricted
version of context-free grammars with regular observers suffices to obtain
computational completeness. As a second instantiation presented here, we apply
an observer to sticker systems. Finally, some directions for further research
are proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3352</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3352</id><created>2009-06-18</created><authors><author><keyname>Buzzi</keyname><forenames>Stefano</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author><author><keyname>Zappone</keyname><forenames>Alessio</forenames></author></authors><title>Spreading Code and Widely-Linear Receiver Design: Non-Cooperative Games
  for Wireless CDMA Networks</title><categories>cs.IT cs.GT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The issue of non-cooperative transceiver optimization in the uplink of a
multiuser wireless code division multiple access data network with
widely-linear detection at the receiver is considered. While previous work in
this area has focused on a simple real signal model, in this paper a baseband
complex representation of the data is used, so as to properly take into account
the I and Q components of the received signal. For the case in which the
received signal is improper, a widely-linear reception structure, processing
separately the data and their complex conjugates, is considered. Several
non-cooperative resource allocation games are considered for this new scenario,
and the performance gains granted by the use of widely-linear detection are
assessed through theoretical analysis. Numerical results confirm the validity
of the theoretical findings, and show that exploiting the improper nature of
the data in non-cooperative resource allocation brings remarkable performance
improvements in multiuser wireless systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3394</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3394</id><created>2009-06-18</created><authors><author><keyname>Nekovee</keyname><forenames>Maziar</forenames></author></authors><title>Quantifying the Availability of TV White Spaces for Cognitive Radio
  Operation in the UK</title><categories>cs.NI cs.DC</categories><comments>Extended version is available from the author</comments><journal-ref>In Proc. IEEE ICC joint Workshop Cognitive Wireless Networks and
  Systems, Dresden, Germany, June 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cognitive radio is being intensively researched for opportunistic access to
the so-called TV White Spaces (TVWS): large portions of the VHF/UHF TV bands
which become available on a geographical basis after the digital switchover.
Using accurate digital TV (DTV) coverage maps together with a database of DTV
transmitters, we develop a methodology for identifying TVWS frequencies at any
given location in the United Kingdom. We use our methodology to investigate
variations in TVWS as a function of the location and transmit power of
cognitive radios, and examine how constraints on adjacent channel interference
imposed by regulators may affect the results. Our analysis provides a realistic
view on the spectrum opportunity associated with cognitive devices, and
presents the first quantitative study of the availability and frequency
composition of TWVS outside the United States.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3410</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3410</id><created>2009-06-18</created><authors><author><keyname>Spagnol</keyname><forenames>Christian</forenames></author><author><keyname>Rossi</keyname><forenames>Marta</forenames></author><author><keyname>Sala</keyname><forenames>Massimiliano</forenames></author></authors><title>Quasi-cyclic LDPC codes with high girth</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a class of quasi-cyclic LDPC codes. We provide precise conditions
guaranteeing high girth in their Tanner graph. Experimentally, the codes we
propose perform no worse than random LDPC codes with their same parameters,
which is a significant achievement for algebraic codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3423</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3423</id><created>2009-06-18</created><authors><author><keyname>Hen-Tov</keyname><forenames>Atzmon</forenames></author><author><keyname>Lorenz</keyname><forenames>David H.</forenames></author><author><keyname>Schachter</keyname><forenames>Lior</forenames></author></authors><title>ModelTalk: A Framework for Developing Domain Specific Executable Models</title><categories>cs.SE cs.PL</categories><acm-class>D.2.6; D.3.2</acm-class><journal-ref>Proc. 8th Ann. OOPSLA Workshop on Domain-Specific Modeling
  (DSM08), Nashville, Tennessee, USA, October 19-20, 2008</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Developing and maintaining complex, large-scale, product line of highly
customized software systems is difficult and costly. Part of the difficulty is
due to the need to communicate business knowledge between domain experts and
application programmers. Domain specific model driven development (MDD)
addresses this difficulty by providing domain experts and developers with
domain specific abstractions for communicating designs. Most MDD
implementations take a generative approach. In contrast, we adopt an
interpretive approach to domain specific model driven development. We present a
framework, named ModelTalk, that integrates MDD, dependency injection and
meta-modeling to form an interpretive, domain specific modeling framework. The
framework is complemented by tool support that provides developers with the
same advanced level of usability for modeling as they are accustomed to in
programming environments. ModelTalk is used in a commercial setting for
developing a product line of Telco grade business support systems (BSS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3424</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3424</id><created>2009-06-18</created><authors><author><keyname>Wang</keyname><forenames>Ziyuan</forenames></author><author><keyname>Kulik</keyname><forenames>Lars</forenames></author><author><keyname>Ramamohanarao</keyname><forenames>Kotagiri</forenames></author></authors><title>Decentralized Traffic Management Strategies for Sensor-Enabled Cars</title><categories>cs.DC</categories><report-no>SUM-06-07</report-no><acm-class>C.2.1; C.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic Congestions and accidents are major concerns in today's
transportation systems. This thesis investigates how to optimize traffic flow
on highways, in particular for merging situations such as intersections where a
ramp leads onto the highway. In our work, cars are equipped with sensors that
can detect distance to neighboring cars, and communicate their velocity and
acceleration readings with one another. Sensor-enabled cars can locally
exchange sensed information about the traffic and adapt their behavior much
earlier than regular cars.
  We propose proactive algorithms for merging different streams of
sensor-enabled cars into a single stream. A proactive merging algorithm
decouples the decision point from the actual merging point. Sensor-enabled cars
allow us to decide where and when a car merges before it arrives at the actual
merging point. This leads to a significant improvement in traffic flow as
velocities can be adjusted appropriately. We compare proactive merging
algorithms against the conventional priority-based merging algorithm in a
controlled simulation environment. Experiment results show that proactive
merging algorithms outperform the priority-based merging algorithm in terms of
flow and delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3461</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3461</id><created>2009-06-18</created><authors><author><keyname>Drozda</keyname><forenames>Martin</forenames></author><author><keyname>Schaust</keyname><forenames>Sven</forenames></author><author><keyname>Szczerbicka</keyname><forenames>Helena</forenames></author></authors><title>AIS for Misbehavior Detection in Wireless Sensor Networks: Performance
  and Design Principles</title><categories>cs.NI cs.AI cs.CR cs.PF</categories><comments>16 pages, 20 figures, a full version of our IEEE CEC 2007 paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A sensor network is a collection of wireless devices that are able to monitor
physical or environmental conditions. These devices (nodes) are expected to
operate autonomously, be battery powered and have very limited computational
capabilities. This makes the task of protecting a sensor network against
misbehavior or possible malfunction a challenging problem. In this document we
discuss performance of Artificial immune systems (AIS) when used as the
mechanism for detecting misbehavior.
  We show that (i) mechanism of the AIS have to be carefully applied in order
to avoid security weaknesses, (ii) the choice of genes and their interaction
have a profound influence on the performance of the AIS, (iii) randomly created
detectors do not comply with limitations imposed by communications protocols
and (iv) the data traffic pattern seems not to impact significantly the overall
performance.
  We identified a specific MAC layer based gene that showed to be especially
useful for detection; genes measure a network's performance from a node's
viewpoint. Furthermore, we identified an interesting complementarity property
of genes; this property exploits the local nature of sensor networks and moves
the burden of excessive communication from normally behaving nodes to
misbehaving nodes. These results have a direct impact on the design of AIS for
sensor networks and on engineering of sensor networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3469</identifier>
 <datestamp>2015-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3469</id><created>2009-06-18</created><authors><author><keyname>Giannopoulos</keyname><forenames>Panos</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author><author><keyname>Rote</keyname><forenames>Gunter</forenames></author><author><keyname>Werner</keyname><forenames>Daniel</forenames></author></authors><title>The parameterized complexity of some geometric problems in unbounded
  dimension</title><categories>cs.CG cs.CC</categories><acm-class>F.2.2</acm-class><journal-ref>Proc. 4th Int. Workshop on Parameterized and Exact
  Computation-IWPEC 2009, Copenhagen, September 2009, Herausgeber: Jianer Chen
  und Fedor V. Fomin, Lecture Notes in Computer Science, 5917, Springer-Verlag,
  2009, pp. 198-209</journal-ref><doi>10.1007/978-3-642-11269-0_16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the parameterized complexity of the following fundamental geometric
problems with respect to the dimension $d$: i) Given $n$ points in $\Rd$,
compute their minimum enclosing cylinder. ii) Given two $n$-point sets in
$\Rd$, decide whether they can be separated by two hyperplanes. iii) Given a
system of $n$ linear inequalities with $d$ variables, find a maximum-size
feasible subsystem. We show that (the decision versions of) all these problems
are W[1]-hard when parameterized by the dimension $d$. %and hence not solvable
in ${O}(f(d)n^c)$ time, for any computable function $f$ and constant $c$
%(unless FPT=W[1]). Our reductions also give a $n^{\Omega(d)}$-time lower bound
(under the Exponential Time Hypothesis).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3483</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3483</id><created>2009-06-18</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Tapus</keyname><forenames>Nicolae</forenames></author></authors><title>Efficient Offline Algorithmic Techniques for Several Packet Routing
  Problems in Distributed Systems</title><categories>cs.DS cs.DC cs.DM</categories><acm-class>F.2.2; G.2.1</acm-class><journal-ref>Acta Universitatis Apulensis - Mathematics-Informatics, no. 18,
  pp. 111-128, 2009. (ISSN: 1582-5329)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider several problems concerning packet routing in
distributed systems. Each problem is formulated using terms from Graph Theory
and for each problem we present efficient, novel, algorithmic techniques for
computing optimal solutions. We address topics like: bottleneck paths (trees),
optimal paths with non-linear costs, optimal paths with multiple optimization
objectives, maintaining aggregate connectivity information under a sequence of
network link failures, and several others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3490</identifier>
 <datestamp>2009-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3490</id><created>2009-06-18</created><authors><author><keyname>Andreica</keyname><forenames>Mugurel Ionut</forenames></author><author><keyname>Andreica</keyname><forenames>Madalina Ecaterina</forenames></author><author><keyname>Visan</keyname><forenames>Costel</forenames></author></authors><title>Optimal Constrained Resource Allocation Strategies under Low Risk
  Circumstances</title><categories>cs.DS cs.CG cs.GT</categories><acm-class>F.2.2; G.2.1; G.2.2</acm-class><journal-ref>Metalurgia International, vol. 14, special issue no. 8, pp.
  143-154, 2009. (ISSN: 1582-2214)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider multiple constrained resource allocation problems,
where the constraints can be specified by formulating activity dependency
restrictions or by using game-theoretic models. All the problems are focused on
generic resources, with a few exceptions which consider financial resources in
particular. The problems consider low-risk circumstances and the values of the
uncertain variables which are used by the algorithms are the expected values of
the variables. For each of the considered problems we propose novel algorithmic
solutions for computing optimal resource allocation strategies. The presented
solutions are optimal or near-optimal from the perspective of their time
complexity. The considered problems have applications in a broad range of
domains, like workflow scheduling in industry (e.g. in the mining and
metallurgical industry) or the financial sector, motion planning, facility
location and data transfer or job scheduling and resource management in Grids,
clouds or other distributed systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3499</identifier>
 <datestamp>2011-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3499</id><created>2009-06-18</created><updated>2010-12-29</updated><authors><author><keyname>Goldfarb</keyname><forenames>Donald</forenames></author><author><keyname>Ma</keyname><forenames>Shiqian</forenames></author></authors><title>Convergence of fixed-point continuation algorithms for matrix rank
  minimization</title><categories>math.OC cs.IT math.IT</categories><comments>Conditions on RIP constant for an approximate recovery are improved</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The matrix rank minimization problem has applications in many fields such as
system identification, optimal control, low-dimensional embedding, etc. As this
problem is NP-hard in general, its convex relaxation, the nuclear norm
minimization problem, is often solved instead. Recently, Ma, Goldfarb and Chen
proposed a fixed-point continuation algorithm for solving the nuclear norm
minimization problem. By incorporating an approximate singular value
decomposition technique in this algorithm, the solution to the matrix rank
minimization problem is usually obtained. In this paper, we study the
convergence/recoverability properties of the fixed-point continuation algorithm
and its variants for matrix rank minimization. Heuristics for determining the
rank of the matrix when its true rank is not known are also proposed. Some of
these algorithms are closely related to greedy algorithms in compressed
sensing. Numerical results for these algorithms for solving affinely
constrained matrix rank minimization problems are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3527</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3527</id><created>2009-06-18</created><authors><author><keyname>Gaspers</keyname><forenames>Serge</forenames></author><author><keyname>Sorkin</keyname><forenames>Gregory B.</forenames></author></authors><title>A universally fastest algorithm for Max 2-Sat, Max 2-CSP, and everything
  in between</title><categories>cs.DS cs.DM</categories><comments>40 pages, a preliminary version appeared in the proceedings of SODA
  2009</comments><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce &quot;hybrid&quot; Max 2-CSP formulas consisting of &quot;simple
clauses&quot;, namely conjunctions and disjunctions of pairs of variables, and
general 2-variable clauses, which can be any integer-valued functions of pairs
of boolean variables. This allows an algorithm to use both efficient reductions
specific to AND and OR clauses, and other powerful reductions that require the
general CSP setting. We use new reductions introduced here, and recent
reductions such as &quot;clause-learning&quot; and &quot;2-reductions&quot; generalized to our
setting's mixture of simple and general clauses.
  Parametrizing an instance by the fraction p of non-simple clauses, we give an
exact (exponential-time) algorithm that is the fastest known polynomial-space
algorithm for p=0 (which includes the well-studied Max 2-Sat problem but also
instances with arbitrary mixtures of AND and OR clauses); the only efficient
algorithm for mixtures of AND, OR, and general integer-valued clauses; and tied
for fastest for general Max 2-CSP (p=1). Since a pure 2-Sat input instance may
be transformed to a general CSP instance in the course of being solved, the
algorithm's efficiency and generality go hand in hand.
  Our algorithm analysis and optimization are a variation on the familiar
measure-and-conquer approach, resulting in an optimizing mathematical program
that is convex not merely quasi-convex, and thus can be solved efficiently and
with a certificate of optimality. We produce a family of running-time
upper-bound formulas, each optimized for instances with a particular value of p
but valid for all instances.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3554</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3554</id><created>2009-06-18</created><updated>2010-08-11</updated><authors><author><keyname>Zenil</keyname><forenames>Hector</forenames></author><author><keyname>Delahaye</keyname><forenames>Jean-Paul</forenames></author></authors><title>On the Algorithmic Nature of the World</title><categories>cs.CC cs.IT math.IT</categories><comments>Book chapter in Gordana Dodig-Crnkovic and Mark Burgin (eds.)
  Information and Computation by World Scientific, 2010.
  (http://www.idt.mdh.se/ECAP-2005/INFOCOMPBOOK/). Paper website:
  http://www.mathrix.org/experimentalAIT/</comments><journal-ref>Gordana Dodig-Crnkovic and Mark Burgin (eds.) Information and
  Computation by World Scientific, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a test based on the theory of algorithmic complexity and an
experimental evaluation of Levin's universal distribution to identify evidence
in support of or in contravention of the claim that the world is algorithmic in
nature. To this end we have undertaken a statistical comparison of the
frequency distributions of data from physical sources on the one
hand--repositories of information such as images, data stored in a hard drive,
computer programs and DNA sequences--and the frequency distributions generated
by purely algorithmic means on the other--by running abstract computing devices
such as Turing machines, cellular automata and Post Tag systems. Statistical
correlations were found and their significance measured.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3558</identifier>
 <datestamp>2011-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3558</id><created>2009-06-18</created><updated>2011-03-15</updated><authors><author><keyname>Simkin</keyname><forenames>M. V.</forenames></author><author><keyname>Roychowdhury</keyname><forenames>V. P.</forenames></author></authors><title>Estimating achievement from fame</title><categories>physics.soc-ph cs.CY physics.hist-ph stat.AP</categories><journal-ref>Significance 8 (2011) 22-26</journal-ref><doi>10.1111/j.1740-9713.2011.00473.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We report a method for estimating people's achievement based on their fame.
Earlier we discovered (cond-mat/0310049) that fame of fighter pilot aces
(measured as number of Google hits) grows exponentially with their achievement
(number of victories). We hypothesize that the same functional relation between
achievement and fame holds for other professions. This allows us to estimate
achievement for professions where an unquestionable and universally accepted
measure of achievement does not exist. We apply the method to Nobel Prize
winners in Physics. For example, we obtain that Paul Dirac, who is hundred
times less famous than Einstein contributed to physics only two times less. We
compare our results with Landau's ranking.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3585</identifier>
 <datestamp>2010-03-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3585</id><created>2009-06-19</created><authors><author><keyname>Singh</keyname><forenames>Vishwakarma</forenames></author><author><keyname>Bhattacharya</keyname><forenames>Arnab</forenames></author><author><keyname>Singh</keyname><forenames>Ambuj K.</forenames></author></authors><title>Finding Significant Subregions in Large Image Databases</title><categories>cs.DB cs.CV cs.IR</categories><comments>16 pages, 48 figures</comments><acm-class>H.2.4</acm-class><journal-ref>Extending Database Technology (EDBT) 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Images have become an important data source in many scientific and commercial
domains. Analysis and exploration of image collections often requires the
retrieval of the best subregions matching a given query. The support of such
content-based retrieval requires not only the formulation of an appropriate
scoring function for defining relevant subregions but also the design of new
access methods that can scale to large databases. In this paper, we propose a
solution to this problem of querying significant image subregions. We design a
scoring scheme to measure the similarity of subregions. Our similarity measure
extends to any image descriptor. All the images are tiled and each alignment of
the query and a database image produces a tile score matrix. We show that the
problem of finding the best connected subregion from this matrix is NP-hard and
develop a dynamic programming heuristic. With this heuristic, we develop two
index based scalable search strategies, TARS and SPARS, to query patterns in a
large image repository. These strategies are general enough to work with other
scoring schemes and heuristics. Experimental results on real image datasets
show that TARS saves more than 87% query time on small queries, and SPARS saves
up to 52% query time on large queries as compared to linear search. Qualitative
tests on synthetic and real datasets achieve precision of more than 80%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3643</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3643</id><created>2009-06-19</created><authors><author><keyname>Aziz</keyname><forenames>Haris</forenames></author><author><keyname>Lachish</keyname><forenames>Oded</forenames></author><author><keyname>Paterson</keyname><forenames>Mike</forenames></author><author><keyname>Savani</keyname><forenames>Rahul</forenames></author></authors><title>Spanning connectivity games</title><categories>cs.GT cs.CC</categories><comments>AAIM 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Banzhaf index, Shapley-Shubik index and other voting power indices
measure the importance of a player in a coalitional game. We consider a simple
coalitional game called the spanning connectivity game (SCG) based on an
undirected, unweighted multigraph, where edges are players. We examine the
computational complexity of computing the voting power indices of edges in the
SCG. It is shown that computing Banzhaf values and Shapley-Shubik indices is
#P-complete for SCGs. Interestingly, Holler indices and Deegan-Packel indices
can be computed in polynomial time. Among other results, it is proved that
Banzhaf indices can be computed in polynomial time for graphs with bounded
treewidth. It is also shown that for any reasonable representation of a simple
game, a polynomial time algorithm to compute the Shapley-Shubik indices implies
a polynomial time algorithm to compute the Banzhaf indices. As a corollary,
computing the Shapley value is #P-complete for simple games represented by the
set of minimal winning coalitions, Threshold Network Flow Games, Vertex
Connectivity Games and Coalitional Skill Games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3667</identifier>
 <datestamp>2010-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3667</id><created>2009-06-19</created><updated>2010-10-24</updated><authors><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Silverstein</keyname><forenames>Jack W.</forenames></author></authors><title>A Deterministic Equivalent for the Analysis of Correlated MIMO Multiple
  Access Channels</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, novel deterministic equivalents for the Stieltjes transform
and the Shannon transform of a class of large dimensional random matrices are
provided. These results are used to characterise the ergodic rate region of
multiple antenna multiple access channels, when each point-to-point propagation
channel is modelled according to the Kronecker model. Specifically, an
approximation of all rates achieved within the ergodic rate region is derived
and an approximation of the linear precoders that achieve the boundary of the
rate region as well as an iterative water-filling algorithm to obtain these
precoders are provided. An original feature of this work is that the proposed
deterministic equivalents are proved valid even for strong correlation patterns
at both communication sides. The above results are validated by Monte Carlo
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3682</identifier>
 <datestamp>2012-09-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3682</id><created>2009-06-19</created><updated>2012-02-03</updated><authors><author><keyname>Wagner</keyname><forenames>Sebastian</forenames></author><author><keyname>Couillet</keyname><forenames>Romain</forenames></author><author><keyname>Debbah</keyname><forenames>Merouane</forenames></author><author><keyname>Slock</keyname><forenames>Dirk. T. M.</forenames></author></authors><title>Large System Analysis of Linear Precoding in Correlated MISO Broadcast
  Channels under Limited Feedback</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 58, no. 7, pp. 4509 - 4537, Jul.
  2012</journal-ref><doi>10.1109/TIT.2012.2191700</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the sum rate performance of zero-forcing (ZF) and
regularized ZF (RZF) precoding in large MISO broadcast systems under the
assumptions of imperfect channel state information at the transmitter and
per-user channel transmit correlation. Our analysis assumes that the number of
transmit antennas $M$ and the number of single-antenna users $K$ are large
while their ratio remains bounded. We derive deterministic approximations of
the empirical signal-to-interference plus noise ratio (SINR) at the receivers,
which are tight as $M,K\to\infty$. In the course of this derivation, the
per-user channel correlation model requires the development of a novel
deterministic equivalent of the empirical Stieltjes transform of large
dimensional random matrices with generalized variance profile. The
deterministic SINR approximations enable us to solve various practical
optimization problems. Under sum rate maximization, we derive (i) for RZF the
optimal regularization parameter, (ii) for ZF the optimal number of users,
(iii) for ZF and RZF the optimal power allocation scheme and (iv) the optimal
amount of feedback in large FDD/TDD multi-user systems. Numerical simulations
suggest that the deterministic approximations are accurate even for small
$M,K$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3722</identifier>
 <datestamp>2009-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3722</id><created>2009-06-19</created><authors><author><keyname>Bouaynaya</keyname><forenames>Nidhal</forenames></author><author><keyname>Zielinski</keyname><forenames>Jerzy</forenames></author><author><keyname>Schonfeld</keyname><forenames>Dan</forenames></author></authors><title>Two-Dimensional ARMA Modeling for Breast Cancer Detection and
  Classification</title><categories>cs.AI cs.CV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new model-based computer-aided diagnosis (CAD) system for tumor
detection and classification (cancerous v.s. benign) in breast images.
Specifically, we show that (x-ray, ultrasound and MRI) images can be accurately
modeled by two-dimensional autoregressive-moving average (ARMA) random fields.
We derive a two-stage Yule-Walker Least-Squares estimates of the model
parameters, which are subsequently used as the basis for statistical inference
and biophysical interpretation of the breast image. We use a k-means classifier
to segment the breast image into three regions: healthy tissue, benign tumor,
and cancerous tumor. Our simulation results on ultrasound breast images
illustrate the power of the proposed approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3736</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3736</id><created>2009-06-19</created><updated>2009-09-25</updated><authors><author><keyname>Jakovetic</keyname><forenames>Dusan</forenames></author><author><keyname>Xavier</keyname><forenames>Joao</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author></authors><title>Weight Optimization for Consensus Algorithms with Correlated Switching
  Topology</title><categories>cs.IT math.IT</categories><comments>30 pages, 5 figures, submitted to IEEE Transactions On Signal
  Processing</comments><doi>10.1109/TSP.2010.2046635</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design the weights in consensus algorithms with spatially correlated
random topologies. These arise with: 1) networks with spatially correlated
random link failures and 2) networks with randomized averaging protocols. We
show that the weight optimization problem is convex for both symmetric and
asymmetric random graphs. With symmetric random networks, we choose the
consensus mean squared error (MSE) convergence rate as optimization criterion
and explicitly express this rate as a function of the link formation
probabilities, the link formation spatial correlations, and the consensus
weights. We prove that the MSE convergence rate is a convex, nonsmooth function
of the weights, enabling global optimization of the weights for arbitrary link
formation probabilities and link correlation structures. We extend our results
to the case of asymmetric random links. We adopt as optimization criterion the
mean squared deviation (MSdev) of the nodes states from the current average
state. We prove that MSdev is a convex function of the weights. Simulations
show that significant performance gain is achieved with our weight design
method when compared with methods available in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3737</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3737</id><created>2009-06-21</created><authors><author><keyname>Choi</keyname><forenames>Sang Won</forenames></author><author><keyname>Jafar</keyname><forenames>Syed A.</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>On the Beamforming Design for Efficient Interference Alignment</title><categories>cs.IT math.IT</categories><comments>3 pages, 1 figure, submitted to IEEE Comm. Letters, Mar. 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient interference alignment (IA) scheme is developed for $K$-user
single-input single-output frequency selective fading interference channels.
The main idea is to steer the transmit beamforming matrices such that at each
receiver the subspace dimensions occupied by interference-free desired streams
are asymptotically the same as those occupied by all interferences. Our
proposed scheme achieves a higher multiplexing gain at any given number of
channel realizations in comparison with the original IA scheme, which is known
to achieve the optimal multiplexing gain asymptotically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3741</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3741</id><created>2009-06-20</created><authors><author><keyname>Danescu-Niculescu-Mizil</keyname><forenames>Cristian</forenames></author><author><keyname>Kossinets</keyname><forenames>Gueorgi</forenames></author><author><keyname>Kleinberg</keyname><forenames>Jon</forenames></author><author><keyname>Lee</keyname><forenames>Lillian</forenames></author></authors><title>How opinions are received by online communities: A case study on
  Amazon.com helpfulness votes</title><categories>cs.CL cs.IR physics.data-an physics.soc-ph</categories><journal-ref>Proceedings of WWW, pp. 141--150, 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many on-line settings in which users publicly express opinions. A
number of these offer mechanisms for other users to evaluate these opinions; a
canonical example is Amazon.com, where reviews come with annotations like &quot;26
of 32 people found the following review helpful.&quot; Opinion evaluation appears in
many off-line settings as well, including market research and political
campaigns. Reasoning about the evaluation of an opinion is fundamentally
different from reasoning about the opinion itself: rather than asking, &quot;What
did Y think of X?&quot;, we are asking, &quot;What did Z think of Y's opinion of X?&quot; Here
we develop a framework for analyzing and modeling opinion evaluation, using a
large-scale collection of Amazon book reviews as a dataset. We find that the
perceived helpfulness of a review depends not just on its content but also but
also in subtle ways on how the expressed evaluation relates to other
evaluations of the same product. As part of our approach, we develop novel
methods that take advantage of the phenomenon of review &quot;plagiarism&quot; to control
for the effects of text in opinion evaluation, and we provide a simple and
natural mathematical model consistent with our findings. Our analysis also
allows us to distinguish among the predictions of competing theories from
sociology and social psychology, and to discover unexpected differences in the
collective opinion-evaluation behavior of user populations from different
countries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3765</identifier>
 <datestamp>2012-09-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3765</id><created>2009-06-19</created><updated>2012-09-20</updated><authors><author><keyname>Monroe</keyname><forenames>Hunter</forenames></author></authors><title>Speedup for Natural Problems and Noncomputability</title><categories>cs.CC</categories><comments>8 pages</comments><acm-class>F.1.3</acm-class><journal-ref>Theor. Comput. Sci. 412 (2011) 478-481</journal-ref><doi>10.1016/j.tcs.2010.09.029</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A resource-bounded version of the statement &quot;no algorithm recognizes all
non-halting Turing machines&quot; is equivalent to an infinitely often (i.o.)
superpolynomial speedup for the time required to accept any coNP-complete
language and also equivalent to a superpolynomial speedup in proof length in
propositional proof systems for tautologies, each of which implies P!=NP. This
suggests a correspondence between the properties 'has no algorithm at all' and
'has no best algorithm' which seems relevant to open problems in computational
and proof complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3768</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3768</id><created>2009-06-19</created><updated>2009-06-23</updated><authors><author><keyname>Stankovic</keyname><forenames>Srdjan</forenames></author><author><keyname>Simic</keyname><forenames>Dejan</forenames></author></authors><title>Defense Strategies Against Modern Botnets</title><categories>cs.CR</categories><comments>7 pages, International Journal of Computer Science and Information
  Security</comments><journal-ref>IJCSIS, June 2009, Vol. 2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Botnets are networks of compromised computers with malicious code which are
remotely controlled and which are used for starting distributed denial of
service (DDoS) attacks, sending enormous number of e-mails (SPAM) and other
sorts of attacks. Defense against modern Botnets is a real challenge. This
paper offers several strategies for defense against Botnets with a list and
description of measures and activities which should be carried out in order to
establish successful defense. The paper also offers parallel preview of the
strategies with their advantages and disadvantages considered in accordance
with various criteria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3769</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3769</id><created>2009-06-19</created><authors><author><keyname>Liu</keyname><forenames>C. H.</forenames></author><author><keyname>Lin</keyname><forenames>Y. F.</forenames></author><author><keyname>Chen</keyname><forenames>Jason J. Y.</forenames></author></authors><title>Using Agent to Coordinate Web Services</title><categories>cs.CR</categories><comments>7 pages, International Journal of Computer Science and Information
  Security</comments><journal-ref>IJCSIS, June 2009, Vol. 2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, agent and web service are two separate research areas. We
figure that, through agent communication, agent is suitable to coordinate web
services. However, there exist agent communication problems due to the lack of
uniform, cross-platform vocabulary. Fortunately, ontology defines a vocabulary.
We thus propose a new agent communication layer and present the web ontology
language (OWL)-based operational ontologies that provides a declarative
description. It can be accessed by various engines to facilitate agent
communication. Further, in our operational ontologies, we define the mental
attitudes of agents that can be shared among other agents. Our architecture
enhanced the 3APL agent platform, and it is implemented as an agent
communication framework. Finally, we extended the framework to be compatible
with the web ontology language for service (OWL-S), and then develop a movie
recommendation system with four OWL-S semantic web services on the framework.
The benefits of this work are: 1) dynamic web service coordination, 2)
ontological reasoning through uniform representation, namely, the declarative
description, and 3) easy reuse and extension of both ontology and engine
through extending ontology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3770</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3770</id><created>2009-06-19</created><authors><author><keyname>Rahaman</keyname><forenames>G. M. Atiqur</forenames></author><author><keyname>Hossain</keyname><forenames>Md. Mobarak</forenames></author></authors><title>Automatic Defect Detection and Classification Technique from Image: A
  Special Case Using Ceramic Tiles</title><categories>cs.CV</categories><comments>9 pages, International Journal of Computer Science and Information
  Security</comments><journal-ref>IJCSIS, June 2009, Vol. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quality control is an important issue in the ceramic tile industry. On the
other hand maintaining the rate of production with respect to time is also a
major issue in ceramic tile manufacturing. Again, price of ceramic tiles also
depends on purity of texture, accuracy of color, shape etc. Considering this
criteria, an automated defect detection and classification technique has been
proposed in this report that can have ensured the better quality of tiles in
manufacturing process as well as production rate. Our proposed method plays an
important role in ceramic tiles industries to detect the defects and to control
the quality of ceramic tiles. This automated classification method helps us to
acquire knowledge about the pattern of defect within a very short period of
time and also to decide about the recovery process so that the defected tiles
may not be mixed with the fresh tiles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3771</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3771</id><created>2009-06-19</created><authors><author><keyname>Mohammed</keyname><forenames>Abd El Naser A.</forenames></author><author><keyname>Rashed</keyname><forenames>Ahmed Nabih Zaki</forenames></author><author><keyname>Abyad</keyname><forenames>Gaber E. S. M. El</forenames></author><author><keyname>Saad</keyname><forenames>Abd El Fattah A.</forenames></author></authors><title>High Transmission Bit Rate of A thermal Arrayed Waveguide Grating (AWG)
  Module in Passive Optical Networks</title><categories>cs.NI</categories><comments>9 pages, International Journal of Computer Science and Information
  Security</comments><journal-ref>IJCSIS, May 2009, Vol. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present paper, high transmission bit rate of a thermal arrayed
waveguide grating (AWG) which is composed of lithium niobate
(LiNbO3)/polymethyl metha acrylate (PMMA) hybrid materials on a silicon
substrate in Passive Optical Networks (PONs) has parametrically analyzed and
investigated over wide range of the affecting parameters. We have theoretically
investigated the temperature dependent wavelength shift of the arrayed
waveguide grating (AWG) depends on the refractive-indices of the materials and
the size of the waveguide. A thermalization of the AWG can be realized by
selecting proper values of the material and structural parameters of the
device. Moreover, we have analyzed the data transmission bit rate of a thermal
AWG in passsive optical networks (PONs) based on Maximum Time Division
Multiplexing (MTDM) technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3772</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3772</id><created>2009-06-19</created><authors><author><keyname>Liu</keyname><forenames>Baolong</forenames></author><author><keyname>Lu</keyname><forenames>Joan</forenames></author><author><keyname>Yip</keyname><forenames>Jim</forenames></author></authors><title>XML Data Integrity Based on Concatenated Hash Function</title><categories>cs.SE cs.PL</categories><comments>10 pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS, May 2009, Vol. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data integrity is the fundamental for data authentication. A major problem
for XML data authentication is that signed XML data can be copied to another
document but still keep signature valid. This is caused by XML data integrity
protecting. Through investigation, the paper discovered that besides data
content integrity, XML data integrity should also protect element location
information, and context referential integrity under fine-grained security
situation. The aim of this paper is to propose a model for XML data integrity
considering XML data features. The paper presents an XML data integrity model
named as CSR (content integrity, structure integrity, context referential
integrity) based on a concatenated hash function. XML data content integrity is
ensured using an iterative hash process, structure integrity is protected by
hashing an absolute path string from root node, and context referential
integrity is ensured by protecting context-related elements. Presented XML data
integrity model can satisfy integrity requirements under situation of
fine-grained security, and compatible with XML signature. Through evaluation,
the integrity model presented has a higher efficiency on digest
value-generation than the Merkle hash tree-based integrity model for XML data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3778</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3778</id><created>2009-06-22</created><authors><author><keyname>Sarwate</keyname><forenames>Dilip V.</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Modified Euclidean Algorithms for Decoding Reed-Solomon Codes</title><categories>cs.IT math.IT</categories><comments>This paper is a corrected version of a paper with the same title that
  will appear in the Proceedings of the 2009 IEEE International Symposium on
  Information Theory. The major change is in Algorithm II of Section IV</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The extended Euclidean algorithm (EEA) for polynomial greatest common
divisors is commonly used in solving the key equation in the decoding of
Reed-Solomon (RS) codes, and more generally in BCH decoding. For this
particular application, the iterations in the EEA are stopped when the degree
of the remainder polynomial falls below a threshold. While determining the
degree of a polynomial is a simple task for human beings, hardware
implementation of this stopping rule is more complicated. This paper describes
a modified version of the EEA that is specifically adapted to the RS decoding
problem. This modified algorithm requires no degree computation or comparison
to a threshold, and it uses a fixed number of iterations. Another advantage of
this modified version is in its application to the errors-and-erasures decoding
problem for RS codes where significant hardware savings can be achieved via
seamless computation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3782</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3782</id><created>2009-06-20</created><authors><author><keyname>Ganesan</keyname><forenames>Ashwin</forenames></author></authors><title>On some sufficient conditions for distributed Quality-of-Service support
  in wireless networks</title><categories>cs.IT math.IT</categories><comments>Submitted to First Workshop on Applications of Graph Theory in
  Wireless Ad hoc Networks and Sensor Networks (GRAPH-HOC 09)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a wireless network where some pairs of communication links interfere
with each other, we study sufficient conditions for determining whether a given
set of minimum bandwidth Quality of Service (QoS) requirements can be
satisfied. We are especially interested in algorithms which have low
communication overhead and low processing complexity. The interference in the
network is modeled using a conflict graph whose vertices are the communication
links in the network. Two links are adjacent in this graph if and only if they
interfere with each other due to being in the same vicinity and hence cannot be
simultaneously active. The problem of scheduling the transmission of the
various links is then essentially a fractional, weighted vertex coloring
problem, for which upper bounds on the fractional chromatic number are sought
using only localized information. We present some distributed algorithms for
this problem, and discuss their worst-case performance. These algorithms are
seen to be within a bounded factor away from optimal for some well known
classes of networks and interference models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3815</identifier>
 <datestamp>2010-12-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3815</id><created>2009-06-20</created><authors><author><keyname>Drabent</keyname><forenames>W.</forenames></author><author><keyname>Maluszynski</keyname><forenames>J.</forenames></author></authors><title>Hybrid Rules with Well-Founded Semantics</title><categories>cs.LO cs.AI cs.PL</categories><journal-ref>Knowledge and Information Systems, 25:137-168, 2010</journal-ref><doi>10.1007/s10115-010-0300-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A general framework is proposed for integration of rules and external first
order theories. It is based on the well-founded semantics of normal logic
programs and inspired by ideas of Constraint Logic Programming (CLP) and
constructive negation for logic programs. Hybrid rules are normal clauses
extended with constraints in the bodies; constraints are certain formulae in
the language of the external theory. A hybrid program is a pair of a set of
hybrid rules and an external theory. Instances of the framework are obtained by
specifying the class of external theories, and the class of constraints. An
example instance is integration of (non-disjunctive) Datalog with ontologies
formalized as description logics.
  The paper defines a declarative semantics of hybrid programs and a
goal-driven formal operational semantics. The latter can be seen as a
generalization of SLS-resolution. It provides a basis for hybrid
implementations combining Prolog with constraint solvers. Soundness of the
operational semantics is proven. Sufficient conditions for decidability of the
declarative semantics, and for completeness of the operational semantics are
given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3816</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3816</id><created>2009-06-20</created><authors><author><keyname>Panayirci</keyname><forenames>E.</forenames></author><author><keyname>Kocian</keyname><forenames>A.</forenames></author><author><keyname>Poor</keyname><forenames>H. V.</forenames></author><author><keyname>Ruggieri</keyname><forenames>M.</forenames></author></authors><title>A Monte-Carlo Implementation of the SAGE Algorithm for Joint Soft
  Multiuser and Channel Parameter Estimation</title><categories>cs.IT math.IT</categories><comments>5 pages, 3 figures, 10th IEEE International Workshop on Signal
  Processing Advances in Wireless Communications (SPAWC) 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient, joint transmission delay and channel parameter estimation
algorithm is proposed for uplink asynchronous direct-sequence code-division
multiple access (DS-CDMA) systems based on the space-alternating generalized
expectation maximization (SAGE) framework. The marginal likelihood of the
unknown parameters, averaged over the data sequence, as well as the expectation
and maximization steps of the SAGE algorithm are derived analytically. To
implement the proposed algorithm, a Markov Chain Monte Carlo (MCMC) technique,
called Gibbs sampling, is employed to compute the {\em a posteriori}
probabilities of data symbols in a computationally efficient way. Computer
simulations show that the proposed algorithm has excellent estimation
performance. This so-called MCMC-SAGE receiver is guaranteed to converge in
likelihood.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3821</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3821</id><created>2009-06-20</created><authors><author><keyname>Gunduz</keyname><forenames>D.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Simeone</keyname><forenames>O.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Goldsmith</keyname><forenames>A.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. V.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>S.</forenames><affiliation>Shitz</affiliation></author></authors><title>Relaying Simultaneous Multicast Messages</title><categories>cs.IT math.IT</categories><comments>This paper was presented at the IEEE Information Theory Workshop,
  Volos, Greece, June 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of multicasting multiple messages with the help of a relay, which
may also have an independent message of its own to multicast, is considered. As
a first step to address this general model, referred to as the compound
multiple access channel with a relay (cMACr), the capacity region of the
multiple access channel with a &quot;cognitive&quot; relay is characterized, including
the cases of partial and rate-limited cognition. Achievable rate regions for
the cMACr model are then presented based on decode-and-forward (DF) and
compress-and-forward (CF) relaying strategies. Moreover, an outer bound is
derived for the special case in which each transmitter has a direct link to one
of the receivers while the connection to the other receiver is enabled only
through the relay terminal. Numerical results for the Gaussian channel are also
provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3832</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3832</id><created>2009-06-20</created><authors><author><keyname>Shiyanovskii</keyname><forenames>Y.</forenames></author><author><keyname>Wolff</keyname><forenames>F.</forenames></author><author><keyname>Papachristou</keyname><forenames>C.</forenames></author><author><keyname>Weyer</keyname><forenames>D.</forenames></author><author><keyname>Clay</keyname><forenames>W.</forenames></author></authors><title>Hardware Trojan by Hot Carrier Injection</title><categories>cs.AR</categories><comments>6 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses how hot carrier injection (HCI) can be exploited to
create a trojan that will cause hardware failures. The trojan is produced not
via additional logic circuitry but by controlled scenarios that maximize and
accelerate the HCI effect in transistors. These scenarios range from
manipulating the manufacturing process to varying the internal voltage
distribution. This new type of trojan is difficult to test due to its gradual
hardware degradation mechanism. This paper describes the HCI effect, detection
techniques and discusses the possibility for maliciously induced HCI trojans.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3834</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3834</id><created>2009-06-20</created><authors><author><keyname>Shiyanovskii</keyname><forenames>Y.</forenames></author><author><keyname>Wolff</keyname><forenames>F.</forenames></author><author><keyname>Papachristou</keyname><forenames>C.</forenames></author><author><keyname>Weyer</keyname><forenames>D.</forenames></author><author><keyname>Clay</keyname><forenames>W.</forenames></author></authors><title>Exploiting Semiconductor Properties for Hardware Trojans</title><categories>cs.AR</categories><comments>6 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper discusses the possible introduction of hidden reliability defects
during CMOS foundry fabrication processes that may lead to accelerated wearout
of the devices. These hidden defects or hardware Trojans can be created by
deviation from foundry design rules and processing parameters. The Trojans are
produced by exploiting time-based wearing mechanisms (HCI, NBTI, TDDB and EM)
and/or condition-based triggers (ESD, Latchup and Softerror). This class of
latent damage is difficult to test due to its gradual degradation nature. The
paper describes life-time expectancy results for various Trojan induced
scenarios. Semiconductor properties, processing and design parameters critical
for device reliability and Trojan creation are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3843</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3843</id><created>2009-06-21</created><authors><author><keyname>Faizal</keyname><forenames>M. A.</forenames></author><author><keyname>Zaki</keyname><forenames>M. Mohd</forenames></author><author><keyname>Shahrin</keyname><forenames>S.</forenames></author><author><keyname>Robiah</keyname><forenames>Y.</forenames></author><author><keyname>Rahayu</keyname><forenames>S. Siti</forenames></author><author><keyname>Nazrulazhar</keyname><forenames>B.</forenames></author></authors><title>Threshold Verification Technique for Network Intrusion Detection System</title><categories>cs.CR cs.NI</categories><comments>8 Pages, International Journal of Computer Science and Information
  Security</comments><journal-ref>IJCSIS Vol.2, No.1, June 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet has played a vital role in this modern world, the possibilities and
opportunities offered are limitless. Despite all the hype, Internet services
are liable to intrusion attack that could tamper the confidentiality and
integrity of important information. An attack started with gathering the
information of the attack target, this gathering of information activity can be
done as either fast or slow attack. The defensive measure network administrator
can take to overcome this liability is by introducing Intrusion Detection
Systems (IDSs) in their network. IDS have the capabilities to analyze the
network traffic and recognize incoming and on-going intrusion. Unfortunately
the combination of both modules in real time network traffic slowed down the
detection process. In real time network, early detection of fast attack can
prevent any further attack and reduce the unauthorized access on the targeted
machine. The suitable set of feature selection and the correct threshold value,
add an extra advantage for IDS to detect anomalies in the network. Therefore
this paper discusses a new technique for selecting static threshold value from
a minimum standard features in detecting fast attack from the victim
perspective. In order to increase the confidence of the threshold value the
result is verified using Statistical Process Control (SPC). The implementation
of this approach shows that the threshold selected is suitable for identifying
the fast attack in real time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3846</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3846</id><created>2009-06-21</created><authors><author><keyname>Wang</keyname><forenames>Yi</forenames></author><author><keyname>Schapira</keyname><forenames>Michael</forenames></author><author><keyname>Rexford</keyname><forenames>Jennifer</forenames></author></authors><title>Neighbor-Specific BGP: More Flexible Routing Policies While Improving
  Global Stability</title><categories>cs.NI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Please Note: This document was written to summarize and facilitate discussion
regarding (1) the benefits of changing the way BGP selects routes to selecting
the most preferred route allowed by export policies, or more generally, to
selecting BGP routes on a per-neighbor basis, (2) the safety condition that
guarantees global routing stability under the Neighbor-Specific BGP model, and
(3) ways of deploying this model in practice. A paper presenting the formal
model and proof of the stability conditions was published at SIGMETRICS 2009
and is available online.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3849</identifier>
 <datestamp>2010-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3849</id><created>2009-06-21</created><authors><author><keyname>Yu</keyname><forenames>Yaming</forenames></author></authors><title>Squeezing the Arimoto-Blahut algorithm for faster convergence</title><categories>cs.IT math.IT stat.CO</categories><journal-ref>IEEE Trans. Inform. Theory 56 (2010) 3149-3157</journal-ref><doi>10.1109/TIT.2010.2048452</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Arimoto--Blahut algorithm for computing the capacity of a discrete
memoryless channel is revisited. A so-called ``squeezing'' strategy is used to
design algorithms that preserve its simplicity and monotonic convergence
properties, but have provably better rates of convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3853</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3853</id><created>2009-06-21</created><authors><author><keyname>Almeida</keyname><forenames>Marco</forenames></author><author><keyname>Moreira</keyname><forenames>Nelma</forenames></author><author><keyname>Reis</keyname><forenames>Rog&#xe9;rio</forenames></author></authors><title>Aspects of enumeration and generation with a string automata
  representation</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In general, the representation of combinatorial objects is decisive for the
feasibility of several enumerative tasks. In this work, we show how a (unique)
string representation for (complete) initially-connected deterministic automata
(ICDFAs) with n states over an alphabet of k symbols can be used for counting,
exact enumeration, sampling and optimal coding, not only the set of ICDFAs but,
to some extent, the set of regular languages. An exact generation algorithm can
be used to partition the set of ICDFAs in order to parallelize the counting of
minimal automata (and thus of regular languages). We present also a uniform
random generator for ICDFAs that uses a table of pre-calculated values. Based
on the same table it is also possible to obtain an optimal coding for ICDFAs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3857</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3857</id><created>2009-06-21</created><authors><author><keyname>Adler</keyname><forenames>Isolde</forenames></author></authors><title>Games for width parameters and monotonicity</title><categories>cs.DM cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a search game for two players played on a &quot;scenario&quot; consisting
of a ground set together with a collection of feasible partitions. This general
setting allows us to obtain new characterisations of many width parameters such
as rank-width and carving-width of graphs, matroid tree-width and
GF(4)-rank-width. We show that the monotone game variant corresponds to a tree
decomposition of the ground set along feasible partitions. Our framework also
captures many other decompositions into &quot;simple&quot; subsets of the ground set,
such as decompositions into planar subgraphs.
  Within our general framework, we take a step towards characterising monotone
search games. We exhibit a large class of &quot;monotone&quot; scenarios, i.e. of
scenarios where the game and its monotone variant coincide. As a consequence,
determining the winner is in NP for these games. This result implies
monotonicity for all our search games, that are equivalent to branch-width of a
submodular function.
  Finally, we include a proof showing that the matroid tree-width of a graphic
matroid is not larger than the tree-width of the corresponding graph. This
proof is considerably shorter than the original proof and it is purely graph
theoretic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3864</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3864</id><created>2009-06-21</created><authors><author><keyname>Somekh</keyname><forenames>O.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Simeone</keyname><forenames>O.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Poor</keyname><forenames>H. V.</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>S.</forenames><affiliation>Shitz</affiliation></author></authors><title>The Two-Tap Input-Erasure Gaussian Channel and its Application to
  Cellular Communications</title><categories>cs.IT math.IT</categories><comments>Presented at the Forty-Sixth Annual Allerton Conference on
  Communication, Control, and Computing, Sep. 2008, Monticello, Illinois</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the input-erasure Gaussian channel. In contrast to the
output-erasure channel where erasures are applied to the output of a linear
time-invariant (LTI) system, here erasures, known to the receiver, are applied
to the inputs of the LTI system. Focusing on the case where the input symbols
are independent and identically distributed (i.i.d)., it is shown that the two
channels (input- and output-erasure) are equivalent. Furthermore, assuming that
the LTI system consists of a two-tap finite impulse response (FIR) filter, and
using simple properties of tri-diagonal matrices, an achievable rate expression
is presented in the form of an infinite sum. The results are then used to study
the benefits of joint multicell processing (MCP) over single-cell processing
(SCP) in a simple linear cellular uplink, where each mobile terminal is
received by only the two nearby base-stations (BSs). Specifically, the analysis
accounts for ergodic shadowing that simultaneously blocks the mobile terminal
(MT) signal from being received by the two BS. It is shown that the resulting
ergodic per-cell capacity with optimal MCP is equivalent to that of the two-tap
input-erasure channel. Finally, the same cellular uplink is addressed by
accounting for dynamic user activity, which is modelled by assuming that each
MT is randomly selected to be active or to remain silent throughout the whole
transmission block. For this alternative model, a similar equivalence results
to the input-erasure channel are reported.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3883</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3883</id><created>2009-06-21</created><authors><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Wang</keyname><forenames>Qingyun</forenames></author></authors><title>Diversity Analysis of Peaky FSK Signaling in Fading Channels</title><categories>cs.IT math.IT</categories><comments>to appear in the IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Error performance of noncoherent detection of on-off frequency shift keying
(OOFSK) modulation over fading channels is analyzed when the receiver is
equipped with multiple antennas. The analysis is conducted for two cases: 1)
the case in which the receiver has the channel distribution knowledge only; and
2) the case in which the receiver perfectly knows the fading magnitudes. For
both cases, the maximum a posteriori probability (MAP) detection rule is
derived and analytical probability of error expressions are obtained. Numerical
and simulation results indicate that for sufficiently low duty cycle values,
lower error probabilities with respect to FSK signaling are achieved.
Equivalently, when compared to FSK modulation, OOFSK with low duty cycle
requires less energy to achieve the same probability of error, which renders
this modulation a more energy efficient transmission technique. Also, through
numerical results, the impact of number of antennas, antenna correlation, duty
cycle values, and unknown channel fading on the performance are investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3887</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3887</id><created>2009-06-21</created><authors><author><keyname>Chen</keyname><forenames>Qing</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Energy-Efficient Modulation Design for Reliable Communication in
  Wireless Networks</title><categories>cs.IT math.IT</categories><comments>appeared at CISS 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have considered the optimization of the $M$-ary quadrature
amplitude modulation (MQAM) constellation size to minimize the bit energy
consumption under average bit error rate (BER) constraints. In the computation
of the energy expenditure, the circuit, transmission, and retransmission
energies are taken into account. A combined log-normal shadowing and Rayleigh
fading model is employed to model the wireless channel. The link reliabilities
and retransmission probabilities are determined through the outage
probabilities under log-normal shadowing effects. Both single-hop and multi-hop
transmissions are considered. Through numerical results, the optimal
constellation sizes are identified. Several interesting observations with
practical implications are made. It is seen that while large constellations are
preferred at small transmission distances, constellation size should be
decreased as the distance increases. Similar trends are observed in both fixed
and variable transmit power scenarios. We have noted that variable power
schemes can attain higher energy-efficiencies. The analysis of energy-efficient
modulation design is also conducted in multi-hop linear networks. In this case,
the modulation size and routing paths are jointly optimized, and the analysis
of both the bit energy and delay experienced in the linear network is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3888</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3888</id><created>2009-06-21</created><authors><author><keyname>Akin</keyname><forenames>Sami</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author></authors><title>Effective Capacity Analysis of Cognitive Radio Channels for Quality of
  Service Provisioning</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, cognitive transmission under quality of service (QoS)
constraints is studied. In the cognitive radio channel model, it is assumed
that the secondary transmitter sends the data at two different average power
levels, depending on the activity of the primary users, which is determined by
channel sensing performed by the secondary users. A state-transition model is
constructed for this cognitive transmission channel. Statistical limitations on
the buffer lengths are imposed to take into account the QoS constraints. The
maximum throughput under these statistical QoS constraints is identified by
finding the effective capacity of the cognitive radio channel. This analysis is
conducted for fixed-power/fixed-rate, fixed-power/variable-rate, and
variable-power/variable-rate transmission schemes under different assumptions
on the availability of channel side information (CSI) at the transmitter. The
impact upon the effective capacity of several system parameters, including
channel sensing duration, detection threshold, detection and false alarm
probabilities, QoS parameters, and transmission rates, is investigated. The
performances of fixed-rate and variable-rate transmission methods are compared
in the presence of QoS limitations. It is shown that variable schemes
outperform fixed-rate transmission techniques if the detection probabilities
are high. Performance gains through adapting the power and rate are quantified
and it is shown that these gains diminish as the QoS limitations become more
stringent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3889</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3889</id><created>2009-06-21</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Energy Efficiency in the Low-SNR Regime under Queueing Constraints and
  Channel Uncertainty</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Energy efficiency of fixed-rate transmissions is studied in the presence of
queueing constraints and channel uncertainty. It is assumed that neither the
transmitter nor the receiver has channel side information prior to
transmission. The channel coefficients are estimated at the receiver via
minimum mean-square-error (MMSE) estimation with the aid of training symbols.
It is further assumed that the system operates under statistical queueing
constraints in the form of limitations on buffer violation probabilities. The
optimal fraction of power allocated to training is identified. Spectral
efficiency--bit energy tradeoff is analyzed in the low-power and wideband
regimes by employing the effective capacity formulation. In particular, it is
shown that the bit energy increases without bound in the low-power regime as
the average power vanishes. A similar conclusion is reached in the wideband
regime if the number of noninteracting subchannels grow without bound with
increasing bandwidth. On the other hand, it is proven that if the number of
resolvable independent paths and hence the number of noninteracting subchannels
remain bounded as the available bandwidth increases, the bit energy diminishes
to its minimum value in the wideband regime. For this case, expressions for the
minimum bit energy and wideband slope are derived. Overall, energy costs of
channel uncertainty and queueing constraints are identified, and the impact of
multipath richness and sparsity is determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3895</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3895</id><created>2009-06-21</created><authors><author><keyname>Margasinski</keyname><forenames>Igor</forenames></author></authors><title>A Parallelism-Based Approach to Network Anonymization</title><categories>cs.CR cs.NI</categories><comments>16 pages, 9 figures</comments><acm-class>C.2.0; C.2.1; C.2.3; C.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Considering topologies of anonymous networks we used to organizing anonymous
communication into hard to trace paths hiding its origin or destination. In
anonymity the company is crucial, however the serial transportation imposes a
costly tradeoff between a level of privacy and a speed of communication.
  This paper introduces a framework of a novel architecture for anonymous
networks that hides initiators of communications by parallelization of
anonymous links. The new approach, which is based on the grounds of the
anonymous P2P network called P2Priv, does not require content forwarding via a
chain of proxy nodes to assure high degree of anonymity. Contrary to P2Priv,
the new architecture can be suited to anonymization of various network
communications, including anonymous access to distributed as well as
client-server services. In particular, it can be considered as an anonymization
platform for these network applications where both privacy and low delays are
required.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3896</identifier>
 <datestamp>2015-02-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3896</id><created>2009-06-21</created><authors><author><keyname>Giannopoulos</keyname><forenames>Panos</forenames></author><author><keyname>Knauer</keyname><forenames>Christian</forenames></author><author><keyname>Rote</keyname><forenames>Gunter</forenames></author><author><keyname>Werner</keyname><forenames>Daniel</forenames></author></authors><title>Fixed-parameter tractability and lower bounds for stabbing problems</title><categories>cs.CG</categories><comments>Based on the MSc. Thesis of Daniel Werner, Free University Berlin,
  Berlin, Germany</comments><acm-class>F.2.2</acm-class><journal-ref>Computational Geometry, Theory and Applications 46 (2013),
  839-860. Special issue for the 25th European Workshop on Computational
  Geometry (EuroCG'09)</journal-ref><doi>10.1016/j.comgeo.2011.06.005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the following general stabbing problem from a parameterized
complexity point of view: Given a set $\mathcal S$ of $n$ translates of an
object in $\Rd$, find a set of $k$ lines with the property that every object in
$\mathcal S$ is ''stabbed'' (intersected) by at least one line.
  We show that when $S$ consists of axis-parallel unit squares in $\Rtwo$ the
(decision) problem of stabbing $S$ with axis-parallel lines is W[1]-hard with
respect to $k$ (and thus, not fixed-parameter tractable unless FPT=W[1]) while
it becomes fixed-parameter tractable when the squares are disjoint. We also
show that the problem of stabbing a set of disjoint unit squares in $\Rtwo$
with lines of arbitrary directions is W[1]--hard with respect to $k$. Several
generalizations to other types of objects and lines with arbitrary directions
are also presented. Finally, we show that deciding whether a set of unit balls
in $\Rd$ can be stabbed by one line is W[1]--hard with respect to the dimension
$d$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3911</identifier>
 <datestamp>2010-07-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3911</id><created>2009-06-21</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author></authors><title>Using the General Intensional Programming System (GIPSY) for Evaluation
  of Higher-Order Intensional Logic (HOIL) Expressions</title><categories>cs.PL</categories><comments>14 pages; 8 figures</comments><acm-class>D.2.11; D.3.4</acm-class><doi>10.1109/SERA.2010.23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The General Intensional Programming System (GIPSY) has been built around the
Lucid family of intensional programming languages that rely on the higher-order
intensional logic (HOIL) to provide context-oriented multidimensional reasoning
of intensional expressions. HOIL combines functional programming with various
intensional logics to allow explicit context expressions to be evaluated as
first-class values that can be passed as parameters to functions and return as
results with an appropriate set of operators defined on contexts. GIPSY's
frameworks are implemented in Java as a collection of replaceable components
for the compilers of various Lucid dialects and the demand-driven eductive
evaluation engine that can run distributively. GIPSY provides support for
hybrid programming models that couple intensional and imperative languages for
a variety of needs. Explicit context expressions limit the scope of evaluation
of math expressions (effectively a Lucid program is a mathematics or physics
expression constrained by the context) in tensor physics, regular math in
multiple dimensions, etc., and for cyberforensic reasoning as one of the
use-cases of interest. Thus, GIPSY is a support testbed for HOIL-based
languages some of which enable such reasoning, as in formal cyberforensic case
analysis with event reconstruction. In this paper we discuss the GIPSY
architecture, its evaluation engine and example use-cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3916</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3916</id><created>2009-06-21</created><authors><author><keyname>Patrizi</keyname><forenames>Fabio</forenames></author></authors><title>An Introduction to Simulation-Based Techniques for Automated Service
  Composition</title><categories>cs.SE</categories><journal-ref>EPTCS 2, 2009, pp. 37-49</journal-ref><doi>10.4204/EPTCS.2.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work is an introduction to the author's contributions to the SOC area,
resulting from his PhD research activity. It focuses on the problem of
automatically composing a desired service, given a set of available ones and a
target specification. As for description, services are represented as
finite-state transition systems, so to provide an abstract account of their
behavior, seen as the set of possible conversations with external clients. In
addition, the presence of a finite shared memory is considered, that services
can interact with and which provides a basic form of communication. Rather than
describing technical details, we offer an informal overview of the whole work,
and refer the reader to the original papers, referenced throughout this work,
for all details.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3919</identifier>
 <datestamp>2009-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3919</id><created>2009-06-22</created><authors><author><keyname>Mokhov</keyname><forenames>Serguei A.</forenames></author><author><keyname>Paquet</keyname><forenames>Joey</forenames></author></authors><title>A Type System Theory for Higher-Order Intensional Logic Support for
  Variable Bindings in Hybrid Intensional-Imperative Programs in GIPSY</title><categories>cs.LO cs.PL</categories><comments>12 pages, 1 table; 2 figures</comments><acm-class>D.3.3; D.3.2; D.3.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a type system for a platform called the General Intensional
Programming System (GIPSY), designed to support intensional programming
languages built upon intensional logic and their imperative counter-parts for
the intensional execution model. In GIPSY, the type system glues the static and
dynamic typing between intensional and imperative languages in its compiler and
run-time environments to support the intensional evaluation of expressions
written in various dialects of the intensional programming language Lucid. The
intensionality makes expressions to explicitly take into the account a
multidimensional context of evaluation with the context being a first-class
value that serves a number of applications that need the notion of context to
proceed. We describe and discuss the properties of such a type system and the
related type theory as well as particularities of the semantics, design and
implementation of the GIPSY type system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3920</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3920</id><created>2009-06-22</created><authors><author><keyname>Guidi</keyname><forenames>Claudio</forenames></author><author><keyname>Montesi</keyname><forenames>Fabrizio</forenames></author></authors><title>Reasoning About a Service-oriented Programming Paradigm</title><categories>cs.PL cs.DC</categories><journal-ref>EPTCS 2, 2009, pp. 67-81</journal-ref><doi>10.4204/EPTCS.2.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is about a new way for programming distributed applications: the
service-oriented one. It is a concept paper based upon our experience in
developing a theory and a language for programming services. Both the
theoretical formalization and the language interpreter showed us the evidence
that a new programming paradigm exists. In this paper we illustrate the basic
features it is characterized by.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3921</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3921</id><created>2009-06-22</created><authors><author><keyname>Bistarelli</keyname><forenames>Stefano</forenames></author><author><keyname>Campli</keyname><forenames>Paola</forenames></author></authors><title>Fairness as a QoS Measure for Web Services</title><categories>cs.SE</categories><journal-ref>EPTCS 2, 2009, pp. 115-127</journal-ref><doi>10.4204/EPTCS.2.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service Oriented Architectures (SOAs) are component-based architectures,
characterized by reusability, modularization and composition, usually offered
by HTTP (web services) and often equipped with a Quality of Services (QoS)
measure. In order to guarantee the fairness property to each client requesting
a service, we propose a fair version of the (Soft) Concurrent Constraint
language to deal with the negotiation phases of the Service Level Agreement
(SLA) protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3923</identifier>
 <datestamp>2009-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3923</id><created>2009-06-22</created><updated>2009-12-02</updated><authors><author><keyname>Koizumi</keyname><forenames>Daiki</forenames></author><author><keyname>Matsushima</keyname><forenames>Toshiyasu</forenames></author><author><keyname>Hirasawa</keyname><forenames>Shigeichi</forenames></author></authors><title>Bayesian Forecasting of WWW Traffic on the Time Varying Poisson Model</title><categories>cs.NI cs.LG</categories><comments>8 pages, 6 figures. This paper was published in Proceeding of The
  2009 International Conference on Parallel and Distributed Processing
  Techniques and Applications (PDPTA'09) in July, 2009. In version of v4,
  research grants are included in acknowledgment</comments><acm-class>D.4.8; G.3; C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traffic forecasting from past observed traffic data with small calculation
complexity is one of important problems for planning of servers and networks.
Focusing on World Wide Web (WWW) traffic as fundamental investigation, this
paper would deal with Bayesian forecasting of network traffic on the time
varying Poisson model from a viewpoint from statistical decision theory. Under
this model, we would show that the estimated forecasting value is obtained by
simple arithmetic calculation and expresses real WWW traffic well from both
theoretical and empirical points of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3924</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3924</id><created>2009-06-22</created><authors><author><keyname>Kov&#xe1;cs</keyname><forenames>L&#xe1;szl&#xf3;</forenames></author><author><keyname>M&#xe1;t&#xe9;telki</keyname><forenames>P&#xe9;ter</forenames></author><author><keyname>Pataki</keyname><forenames>Bal&#xe1;zs</forenames></author></authors><title>Service-oriented Context-aware Framework</title><categories>cs.SE</categories><journal-ref>EPTCS 2, 2009, pp. 15-26</journal-ref><doi>10.4204/EPTCS.2.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Location- and context-aware services are emerging technologies in mobile and
desktop environments, however, most of them are difficult to use and do not
seem to be beneficial enough. Our research focuses on designing and creating a
service-oriented framework that helps location- and context-aware,
client-service type application development and use. Location information is
combined with other contexts such as the users' history, preferences and
disabilities. The framework also handles the spatial model of the environment
(e.g. map of a room or a building) as a context. The framework is built on a
semantic backend where the ontologies are represented using the OWL description
language. The use of ontologies enables the framework to run inference tasks
and to easily adapt to new context types. The framework contains a
compatibility layer for positioning devices, which hides the technical
differences of positioning technologies and enables the combination of location
data of various sources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3925</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3925</id><created>2009-06-22</created><authors><author><keyname>Pathan</keyname><forenames>Kamran Taj</forenames></author><author><keyname>Reiff-Marganiec</keyname><forenames>Stephan</forenames></author></authors><title>Towards Activity Context using Software Sensors</title><categories>cs.OH</categories><journal-ref>EPTCS 2, 2009, pp. 27-35</journal-ref><doi>10.4204/EPTCS.2.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service-Oriented Computing delivers the promise of configuring and
reconfiguring software systems to address user's needs in a dynamic way.
Context-aware computing promises to capture the user's needs and hence the
requirements they have on systems. The marriage of both can deliver ad-hoc
software solutions relevant to the user in the most current fashion. However,
here it is a key to gather information on the users' activity (that is what
they are doing). Traditionally any context sensing was conducted with hardware
sensors. However, software can also play the same role and in some situations
will be more useful to sense the activity of the user. Furthermore they can
make use of the fact that Service-oriented systems exchange information through
standard protocols. In this paper we discuss our proposed approach to sense the
activity of the user making use of software.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3926</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3926</id><created>2009-06-22</created><authors><author><keyname>Bistarelli</keyname><forenames>Stefano</forenames></author><author><keyname>Santini</keyname><forenames>Francesco</forenames></author></authors><title>Soft Constraints for Quality Aspects in Service Oriented Architectures</title><categories>cs.AI cs.PL</categories><journal-ref>EPTCS 2, 2009, pp. 51-65</journal-ref><doi>10.4204/EPTCS.2.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose the use of Soft Constraints as a natural way to model Service
Oriented Architecture. In the framework, constraints are used to model
components and connectors and constraint aggregation is used to represent their
interactions. The &quot;quality of a service&quot; is measured and considered when
performing queries to service providers. Some examples consist in the levels of
cost, performance and availability required by clients. In our framework, the
QoS scores are represented by the softness level of the constraint and the
measure of complex (web) services is computed by combining the levels of the
components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3930</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3930</id><created>2009-06-22</created><authors><author><keyname>Petrova-Antonova</keyname><forenames>Dessislava</forenames></author><author><keyname>Ilieva</keyname><forenames>Sylvia</forenames></author></authors><title>Towards a Unifying View of QoS-Enhanced Web Service Description and
  Discovery Approaches</title><categories>cs.SE</categories><journal-ref>EPTCS 2, 2009, pp. 99-113</journal-ref><doi>10.4204/EPTCS.2.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of web services increased vastly in the last years. Various
providers offer web services with the same functionality, so for web service
consumers it is getting more complicated to select the web service, which best
fits their requirements. That is why a lot of the research efforts point to
discover semantic means for describing web services taking into account not
only functional characteristics of services, but also the quality of service
(QoS) properties such as availability, reliability, response time, trust, etc.
This motivated us to research current approaches presenting complete solutions
for QoS enabled web service description, publication and discovery. In this
paper we present comparative analysis of these approaches according to their
common principals. Based on such analysis we extract the essential aspects from
them and propose a pattern for the development of QoS-aware service-oriented
architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3946</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3946</id><created>2009-06-22</created><authors><author><keyname>Li</keyname><forenames>Xueliang</forenames></author><author><keyname>Sun</keyname><forenames>Yuefang</forenames></author></authors><title>The rainbow $k$-connectivity of two classes of graphs</title><categories>math.CO cs.DM</categories><comments>9 pages</comments><msc-class>05C15; 05C40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A path in an edge-colored graph $G$, where adjacent edges may be colored the
same, is called a rainbow path if no two edges of $G$ are colored the same. For
a $\kappa$-connected graph $G$ and an integer $k$ with $1\leq k\leq \kappa$,
the rainbow $k$-connectivity $rc_k(G)$ of $G$ is defined as the minimum integer
$j$ for which there exists a $j$-edge-coloring of $G$ such that every two
distinct vertices of $G$ are connected by $k$ internally disjoint rainbow
paths. Let $G$ be a complete $(\ell+1)$-partite graph with $\ell$ parts of size
$r$ and one part of size $p$ where $0\leq p &lt;r$ (in the case $p=0$, $G$ is a
complete $\ell$-partite graph with each part of size $r$). This paper is to
investigate the rainbow $k$-connectivity of $G$. We show that for every pair of
integers $k\geq 2$ and $r\geq 1$, there is an integer $f(k,r)$ such that if
$\ell\geq f(k,r)$, then $rc_k(G)=2$. As a consequence, we improve the upper
bound of $f(k)$ from $(k+1)^2$ to $ck^{{3/2}}+C$, where $0&lt;c&lt;1$,
$C=o(k^{{3/2}})$, and $f(k)$ is the integer such that if $n \geq f(k)$ then
$rc_k(K_n)=2$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3956</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3956</id><created>2009-06-22</created><authors><author><keyname>M.</keyname><forenames>Joe Prathap P</forenames></author><author><keyname>Vasudevan</keyname><forenames>V.</forenames></author></authors><title>Analysis of the various key management algorithms and new proposal in
  the secure multicast communications</title><categories>cs.CR</categories><comments>8 pages, International Journal of Computer Science and Information
  Security</comments><journal-ref>IJCSIS 2009, June Issue, Vol.2. No.1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the evolution of the Internet, multicast communications seem
particularly well adapted for large scale commercial distribution applications,
for example, the pay TV channels and secure videoconferencing. Key management
for multicast remains an open topic in secure Communications today. Key
management mainly has to do with the distribution and update of keying material
during the group life. Several key tree based approach has been proposed by
various authors to create and distribute the multicast group key in effective
manner. There are different key management algorithms that facilitate efficient
distribution and rekeying of the group key. These protocols normally add
communication overhead as well as computation overhead at the group key
controller and at the group members. This paper explores the various algorithms
along with the performances and derives an improved method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3966</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3966</id><created>2009-06-22</created><authors><author><keyname>Kumar</keyname><forenames>K Pradheep</forenames></author><author><keyname>Shanthi</keyname><forenames>A P</forenames></author></authors><title>Application of non-uniform laxity to EDF for aperiodic tasks to improve
  task utilisation on multicore platforms</title><categories>cs.PF cs.DS</categories><comments>7 pages, Journal of Computer Science and Information Security</comments><journal-ref>IJCSIS 2009, June Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new scheduler applying the concept of non-uniform
laxity to Earliest deadline first (EDF) approach for aperiodic tasks. This
scheduler improves task utilisation (Execution time / deadline) and also
increases the number of tasks that are being scheduled. Laxity is a measure of
the spare time permitted for the task before it misses its deadline, and is
computed using the expression (deadline - (current time + execution time)).
Weight decides the priority of the task and is defined by the expression
(quantum slice time / allocated time)*total core time for the task. Quantum
slice time is the time actually used, allocated time is the time allocated by
the scheduler, and total core time is the time actually reserved by the core
for execution of one quantum of the task. Non-uniform laxity enables scheduling
of tasks that have higher priority before the normal execution of other tasks
and is computed by multiplying the weight of the task with its laxity. The
algorithm presented in the paper has been simulated on Cheddar, a real time
scheduling tool and also on SESC, an architectural simulator for multicore
platforms, for upto 5000 random task sets, and upto 5000 cores. This scheduler
improves task utilisation by 35% and the number of tasks being scheduled by
36%, compared to conventional EDF.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3988</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3988</id><created>2009-06-22</created><authors><author><keyname>Gezici</keyname><forenames>Sinan</forenames></author><author><keyname>Celebi</keyname><forenames>Hasari</forenames></author><author><keyname>Arslan</keyname><forenames>Huseyin</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Theoretical Limits on Time Delay Estimation for Ultra-Wideband Cognitive
  Radios</title><categories>cs.IT math.IT</categories><comments>IEEE ICUWB 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, theoretical limits on time delay estimation are studied for
ultra-wideband (UWB) cognitive radio systems. For a generic UWB spectrum with
dispersed bands, the Cramer-Rao lower bound (CRLB) is derived for unknown
channel coefficients and carrier-frequency offsets (CFOs). Then, the effects of
unknown channel coefficients and CFOs are investigated for linearly and
non-linearly modulated training signals by obtaining specific CRLB expressions.
It is shown that for linear modulations with a constant envelope, the effects
of the unknown parameters can be mitigated. Finally, numerical results, which
support the theoretical analysis, are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.3994</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.3994</id><created>2009-06-22</created><authors><author><keyname>Beffara</keyname><forenames>Emmanuel</forenames><affiliation>IML</affiliation></author></authors><title>Quantitative testing semantics for non-interleaving</title><categories>cs.LO</categories><proxy>ccsd hal-00397551</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a non-interleaving denotational semantics for the
?-calculus. The basic idea is to define a notion of test where the outcome is
not only whether a given process passes a given test, but also in how many
different ways it can pass it. More abstractly, the set of possible outcomes
for tests forms a semiring, and the set of process interpretations appears as a
module over this semiring, in which basic syntactic constructs are affine
operators. This notion of test leads to a trace semantics in which traces are
partial orders, in the style of Mazurkiewicz traces, extended with readiness
information. Our construction has standard may- and must-testing as special
cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4008</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4008</id><created>2009-06-22</created><authors><author><keyname>Ozadam</keyname><forenames>Hakan</forenames></author><author><keyname>Ozbudak</keyname><forenames>Ferruh</forenames></author></authors><title>Two generalizations on the minimum Hamming distance of repeated-root
  constacyclic codes</title><categories>cs.IT math.IT</categories><comments>We do not plan to publish the results of this paper on their own. We
  have put this paper for referring purposes</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study constacyclic codes, of length $np^s$ and $2np^s$, that are generated
by the polynomials $(x^n + \gamma)^{\ell}$ and $(x^n - \xi)^i(x^n + \xi)^j$\
respectively, where $x^n + \gamma$, $x^n - \xi$ and $x^n + \xi$ are irreducible
over the alphabet $\F_{p^a}$. We generalize the results of [5], [6] and [7] by
computing the minimum Hamming distance of these codes. As a particular case, we
determine the minimum Hamming distance of cyclic and negacyclic codes, of
length $2p^s$, over a finite field of characteristic $p$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4012</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4012</id><created>2009-06-22</created><authors><author><keyname>Pun</keyname><forenames>Man-On</forenames></author><author><keyname>Kim</keyname><forenames>Kyeong Jin</forenames></author><author><keyname>Iltis</keyname><forenames>Ronald</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Reduced-Feedback Opportunistic Scheduling and Beamforming with GMD for
  MIMO-OFDMA</title><categories>cs.IT math.IT</categories><comments>Proc. Asilomar Conference on Signals, Systems, and Computers, Pacific
  Grove, CA, Nov. 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Opportunistic scheduling and beamforming schemes have been proposed
previously by the authors for reduced-feedback MIMO-OFDMA downlink systems
where the MIMO channel of each subcarrier is decomposed into layered spatial
subchannels. It has been demonstrated that significant feedback reduction can
be achieved by returning information about only one beamforming matrix (BFM)
for all subcarriers from each MT, compared to one BFM for each subcarrier in
the conventional schemes. However, since the previously proposed channel
decomposition was derived based on singular value decomposition, the resulting
system performance is impaired by the subchannels associated with the smallest
singular values. To circumvent this obstacle, this work proposes improved
opportunistic scheduling and beamforming schemes based on geometric mean
decomposition-based channel decomposition. In addition to the inherent
advantage in reduced feedback, the proposed schemes can achieve improved system
performance by decomposing the MIMO channels into spatial subchannels with more
evenly distributed channel gains. Numerical results confirm the effectiveness
of the proposed opportunistic scheduling and beamforming schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4019</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4019</id><created>2009-06-22</created><authors><author><keyname>Lariviere</keyname><forenames>Vincent</forenames></author><author><keyname>Gingras</keyname><forenames>Yves</forenames></author></authors><title>On the prevalence and scientific impact of duplicate publications in
  different scientific fields (1980-2007)</title><categories>physics.soc-ph cs.DL</categories><comments>13 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The issue of duplicate publications has received a lot of attention in the
medical literature, but much less in the information science community. This
paper aims at analyzing the prevalence and scientific impact of duplicate
publications across all fields of research between 1980 and 2007, using a
definition of duplicate papers based on their metadata. It shows that in all
fields combined, the prevalence of duplicates is one out of two-thousand
papers, but is higher in the natural and medical sciences than in the social
sciences and humanities. A very high proportion (&gt;85%) of these papers are
published the same year or one year apart, which suggest that most duplicate
papers were submitted simultaneously. Furthermore, duplicate papers are
generally published in journals with impact factors below the average of their
field and obtain a lower number of citations. This paper provides clear
evidence that the prevalence of duplicate papers is low and, more importantly,
that the scientific impact of such papers is below average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4026</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4026</id><created>2009-06-22</created><updated>2009-06-23</updated><authors><author><keyname>Piwowarski</keyname><forenames>B.</forenames></author><author><keyname>Lalmas</keyname><forenames>M.</forenames></author></authors><title>A Quantum-based Model for Interactive Information Retrieval (extended
  version)</title><categories>cs.IR cs.DL</categories><comments>14 pages, 1 figure</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Even the best information retrieval model cannot always identify the most
useful answers to a user query. This is in particular the case with web search
systems, where it is known that users tend to minimise their effort to access
relevant information. It is, however, believed that the interaction between
users and a retrieval system, such as a web search engine, can be exploited to
provide better answers to users. Interactive Information Retrieval (IR)
systems, in which users access information through a series of interactions
with the search system, are concerned with building models for IR, where
interaction plays a central role. There are many possible interactions between
a user and a search system, ranging from query (re)formulation to relevance
feedback. However, capturing them within a single framework is difficult and
previously proposed approaches have mostly focused on relevance feedback. In
this paper, we propose a general framework for interactive IR that is able to
capture the full interaction process in a principled way. Our approach relies
upon a generalisation of the probability framework of quantum physics, whose
strong geometric component can be a key towards a successful interactive IR
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4032</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4032</id><created>2009-06-22</created><authors><author><keyname>Borgwardt</keyname><forenames>Karsten M.</forenames></author><author><keyname>Ghahramani</keyname><forenames>Zoubin</forenames></author></authors><title>Bayesian two-sample tests</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present two classes of Bayesian approaches to the
two-sample problem. Our first class of methods extends the Bayesian t-test to
include all parametric models in the exponential family and their conjugate
priors. Our second class of methods uses Dirichlet process mixtures (DPM) of
such conjugate-exponential distributions as flexible nonparametric priors over
the unknown distributions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4036</identifier>
 <datestamp>2009-06-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4036</id><created>2009-06-22</created><updated>2009-06-30</updated><authors><author><keyname>Lu</keyname><forenames>Hongyu</forenames></author><author><keyname>Bao</keyname><forenames>Shanglian</forenames></author></authors><title>Physical Modeling Techniques in Active Contours for Image Segmentation</title><categories>cs.CV cs.GR</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Physical modeling method, represented by simulation and visualization of the
principles in physics, is introduced in the shape extraction of the active
contours. The objectives of adopting this concept are to address the several
major difficulties in the application of Active Contours. Primarily, a
technique is developed to realize the topological changes of Parametric Active
Contours (Snakes). The key strategy is to imitate the process of a balloon
expanding and filling in a closed space with several objects. After removing
the touched balloon surfaces, the objects can be identified by surrounded
remaining balloon surfaces. A burned region swept by Snakes is utilized to
trace the contour and to give a criterion for stopping the movement of Snake
curve. When the Snakes terminates evolution totally, through ignoring this
criterion, it can form a connected area by evolving the Snakes again and
continuing the region burning. The contours extracted from the boundaries of
the burned area can represent the child snake of each object respectively.
Secondly, a novel scheme is designed to solve the problems of leakage of the
contour from the large gaps, and the segmentation error in Geometric Active
Contours (GAC). It divides the segmentation procedure into two processing
stages. By simulating the wave propagating in the isotropic substance at the
final stage, it can significantly enhance the effect of image force in GAC
based on Level Set and give the satisfied solutions to the two problems.
Thirdly, to support the physical models for active contours above, we introduce
a general image force field created on a template plane over the image plane.
This force is more adaptable to noisy images with complicated geometric shapes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4044</identifier>
 <datestamp>2009-06-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4044</id><created>2009-06-22</created><authors><author><keyname>Conry</keyname><forenames>Don</forenames></author><author><keyname>Koren</keyname><forenames>Yehuda</forenames></author><author><keyname>Ramakrishnan</keyname><forenames>Naren</forenames></author></authors><title>Recommender Systems for the Conference Paper Assignment Problem</title><categories>cs.IR cs.AI</categories><comments>8 pages, 5 figures, submitted to the ACM Conference on Recommender
  Systems 2009</comments><acm-class>H.4.2; J.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Conference paper assignment, i.e., the task of assigning paper submissions to
reviewers, presents multi-faceted issues for recommender systems research.
Besides the traditional goal of predicting `who likes what?', a conference
management system must take into account aspects such as: reviewer capacity
constraints, adequate numbers of reviews for papers, expertise modeling,
conflicts of interest, and an overall distribution of assignments that balances
reviewer preferences with conference objectives. Among these, issues of
modeling preferences and tastes in reviewing have traditionally been studied
separately from the optimization of paper-reviewer assignment. In this paper,
we present an integrated study of both these aspects. First, due to the paucity
of data per reviewer or per paper (relative to other recommender systems
applications) we show how we can integrate multiple sources of information to
learn paper-reviewer preference models. Second, our models are evaluated not
just in terms of prediction accuracy but in terms of the end-assignment
quality. Using a linear programming-based assignment optimization formulation,
we show how our approach better explores the space of unsupplied assignments to
maximize the overall affinities of papers assigned to reviewers. We demonstrate
our results on real reviewer preference data from the IEEE ICDM 2007
conference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4096</identifier>
 <datestamp>2009-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4096</id><created>2009-06-22</created><updated>2009-06-22</updated><authors><author><keyname>Ashish</keyname><forenames>Naveen</forenames></author><author><keyname>Kalashnikov</keyname><forenames>Dmitri</forenames></author><author><keyname>Mehrotra</keyname><forenames>Sharad</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Nalini</forenames></author></authors><title>An Event Based Approach To Situational Representation</title><categories>cs.DB cs.AI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Many application domains require representing interrelated real-world
activities and/or evolving physical phenomena. In the crisis response domain,
for instance, one may be interested in representing the state of the unfolding
crisis (e.g., forest fire), the progress of the response activities such as
evacuation and traffic control, and the state of the crisis site(s). Such a
situation representation can then be used to support a multitude of
applications including situation monitoring, analysis, and planning. In this
paper, we make a case for an event based representation of situations where
events are defined to be domain-specific significant occurrences in space and
time. We argue that events offer a unifying and powerful abstraction to
building situational awareness applications. We identify challenges in building
an Event Management System (EMS) for which traditional data and knowledge
management systems prove to be limited and suggest possible directions and
technologies to address the challenges.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4121</identifier>
 <datestamp>2015-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4121</id><created>2009-06-22</created><authors><author><keyname>Giesbrecht</keyname><forenames>Mark</forenames></author><author><keyname>Kim</keyname><forenames>Myung Sub</forenames></author></authors><title>On computing the Hermite form of a matrix of differential polynomials</title><categories>cs.SC cs.MS</categories><doi>10.1007/978-3-642-04103-7_12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given an n x n matrix over the ring of differential polynomials
F(t)[\D;\delta], we show how to compute the Hermite form H of A, and a
unimodular matrix U such that UA=H. The algorithm requires a polynomial number
of operations in terms of n, deg_D(A), and deg_t(A). When F is the field of
rational numbers, it also requires time polynomial in the bit-length of the
coefficients.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4125</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4125</id><created>2009-06-22</created><authors><author><keyname>Cherubini</keyname><forenames>Mauro</forenames></author><author><keyname>Oliver</keyname><forenames>Nuria</forenames></author></authors><title>A Refined Experience Sampling Method to Capture Mobile User Experience</title><categories>cs.HC</categories><comments>Cherubini, M., and Oliver, N. A refined experience sampling method to
  capture mobile user experience. In Presented at the International Workshop of
  Mobile User Experience Research part of CHI'2009 (Boston, MA, USA, April 4-9
  2009), Y. Nakhimovsky, D. Eckles, and J. Riegelsberger, Eds. 12 pages, 5
  figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews research methods used to understand the user experience of
mobile technology. The paper presents an improvement of the Experience Sampling
Method and case studies supporting its design. The paper concludes with an
agenda of future work for improving research in this field.
  Keywords: Research methods, topology, case study, contrasting graph,
Experience Sampling Method
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4131</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4131</id><created>2009-06-22</created><updated>2009-06-23</updated><authors><author><keyname>Rao</keyname><forenames>Josna</forenames></author><author><keyname>Hamarneh</keyname><forenames>Ghassan</forenames></author><author><keyname>Abugharbieh</keyname><forenames>Rafeef</forenames></author></authors><title>Automatic Spatially-Adaptive Balancing of Energy Terms for Image
  Segmentation</title><categories>cs.CV</categories><comments>12 pages, 7 figures</comments><acm-class>I.4.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Image segmentation techniques are predominately based on parameter-laden
optimization. The objective function typically involves weights for balancing
competing image fidelity and segmentation regularization cost terms. Setting
these weights suitably has been a painstaking, empirical process. Even if such
ideal weights are found for a novel image, most current approaches fix the
weight across the whole image domain, ignoring the spatially-varying properties
of object shape and image appearance. We propose a novel technique that
autonomously balances these terms in a spatially-adaptive manner through the
incorporation of image reliability in a graph-based segmentation framework. We
validate on synthetic data achieving a reduction in mean error of 47% (p-value
&lt;&lt; 0.05) when compared to the best fixed parameter segmentation. We also
present results on medical images (including segmentations of the corpus
callosum and brain tissue in MRI data) and on natural images.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4149</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4149</id><created>2009-06-22</created><authors><author><keyname>de Leoni</keyname><forenames>Massimiliano</forenames></author></authors><title>Adaptive Process Management in Highly Dynamic and Pervasive Scenarios</title><categories>cs.SE</categories><journal-ref>EPTCS 2, 2009, pp. 83-97</journal-ref><doi>10.4204/EPTCS.2.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Process Management Systems (PMSs) are currently more and more used as a
supporting tool for cooperative processes in pervasive and highly dynamic
situations, such as emergency situations, pervasive healthcare or domotics/home
automation. But in all such situations, designed processes can be easily
invalidated since the execution environment may change continuously due to
frequent unforeseeable events. This paper aims at illustrating the theoretical
framework and the concrete implementation of SmartPM, a PMS that features a set
of sound and complete techniques to automatically cope with unplanned
exceptions. PMS SmartPM is based on a general framework which adopts the
Situation Calculus and Indigolog.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4154</identifier>
 <datestamp>2009-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4154</id><created>2009-06-22</created><authors><author><keyname>Obst</keyname><forenames>Oliver</forenames></author></authors><title>Distributed Fault Detection in Sensor Networks using a Recurrent Neural
  Network</title><categories>cs.NE cs.DC</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In long-term deployments of sensor networks, monitoring the quality of
gathered data is a critical issue. Over the time of deployment, sensors are
exposed to harsh conditions, causing some of them to fail or to deliver less
accurate data. If such a degradation remains undetected, the usefulness of a
sensor network can be greatly reduced. We present an approach that learns
spatio-temporal correlations between different sensors, and makes use of the
learned model to detect misbehaving sensors by using distributed computation
and only local communication between nodes. We introduce SODESN, a distributed
recurrent neural network architecture, and a learning method to train SODESN
for fault detection in a distributed scenario. Our approach is evaluated using
data from different types of sensors and is able to work well even with
less-than-perfect link qualities and more than 50% of failed nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4162</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4162</id><created>2009-06-23</created><authors><author><keyname>Lutz</keyname><forenames>Jack H.</forenames></author></authors><title>A Divergence Formula for Randomness and Dimension (Short Version)</title><categories>cs.CC cs.IT math.IT</categories><journal-ref>EPTCS 1, 2009, pp. 149-152</journal-ref><doi>10.4204/EPTCS.1.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  If $S$ is an infinite sequence over a finite alphabet $\Sigma$ and $\beta$ is
a probability measure on $\Sigma$, then the {\it dimension} of $ S$ with
respect to $\beta$, written $\dim^\beta(S)$, is a constructive version of
Billingsley dimension that coincides with the (constructive Hausdorff)
dimension $\dim(S)$ when $\beta$ is the uniform probability measure. This paper
shows that $\dim^\beta(S)$ and its dual $\Dim^\beta(S)$, the {\it strong
dimension} of $S$ with respect to $\beta$, can be used in conjunction with
randomness to measure the similarity of two probability measures $\alpha$ and
$\beta$ on $\Sigma$. Specifically, we prove that the {\it divergence formula}
$$\dim^\beta(R) = \Dim^\beta(R) =\CH(\alpha) / (\CH(\alpha) + \D(\alpha ||
\beta))$$ holds whenever $\alpha$ and $\beta$ are computable, positive
probability measures on $\Sigma$ and $R \in \Sigma^\infty$ is random with
respect to $\alpha$. In this formula, $\CH(\alpha)$ is the Shannon entropy of
$\alpha$, and $\D(\alpha||\beta)$ is the Kullback-Leibler divergence between
$\alpha$ and $\beta$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4172</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4172</id><created>2009-06-23</created><authors><author><keyname>Pandey</keyname><forenames>Anjana</forenames></author><author><keyname>Pardasani</keyname><forenames>K. R.</forenames></author></authors><title>Rough Set Model for Discovering Hybrid Association Rules</title><categories>cs.DB cs.LG</categories><comments>5 pages, International Journal of Computer Science and Information
  Security</comments><journal-ref>IJCSIS June 2009 Issue, Vol. 2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the mining of hybrid association rules with rough set approach
is investigated as the algorithm RSHAR.The RSHAR algorithm is constituted of
two steps mainly. At first, to join the participant tables into a general table
to generate the rules which is expressing the relationship between two or more
domains that belong to several different tables in a database. Then we apply
the mapping code on selected dimension, which can be added directly into the
information system as one certain attribute. To find the association rules,
frequent itemsets are generated in second step where candidate itemsets are
generated through equivalence classes and also transforming the mapping code in
to real dimensions. The searching method for candidate itemset is similar to
apriori algorithm. The analysis of the performance of algorithm has been
carried out.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4173</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4173</id><created>2009-06-23</created><authors><author><keyname>Blanqui</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames><affiliation>LIAMA</affiliation></author><author><keyname>Roux</keyname><forenames>Cody</forenames><affiliation>INRIA Lorraine - LORIA</affiliation></author></authors><title>On the relation between size-based termination and semantic labelling</title><categories>cs.LO</categories><proxy>ccsd inria-00397689</proxy><journal-ref>18th EACSL Annual Conference on Computer Science Logic (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the relationship between two independently developed
termination techniques. On the one hand, sized-types based termination (SBT)
uses types annotated with size expressions and Girard's reducibility
candidates, and applies on systems using constructor matching only. On the
other hand, semantic labelling transforms a rewrite system by annotating each
function symbol with the semantics of its arguments, and applies to any rewrite
system. First, we introduce a simplified version of SBT for the simply-typed
lambda-calculus. Then, we give new proofs of the correctness of SBT using
semantic labelling, both in the first and in the higher-order case. As a
consequence, we show that SBT can be extended to systems using matching on
defined symbols (e.g. associative functions).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4216</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4216</id><created>2009-06-23</created><authors><author><keyname>Kuchibhotla</keyname><forenames>Venkata Rao</forenames></author><author><keyname>Kasturi</keyname><forenames>Viswanath</forenames></author></authors><title>On the Definition of Non-deterministic Mechanisms</title><categories>cs.LO cs.CC</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present here three different approaches to the problem of modeling
mathematically the concept of a non-deterministic mechanism. Each of these
three approaches leads to a mathematical definition. We then show that all the
three mathematical concepts are equivalent to one another. This insight gives
us the option of approaching the wp-formalism of Dijkstra from a different
viewpoint that is easier to understand and to teach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4217</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4217</id><created>2009-06-23</created><authors><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>A Performance Analysis of HICCUPS - a Steganographic System for WLAN</title><categories>cs.CR cs.PF</categories><comments>5 pages, 5 figures, 3 tables. Submitted to the First International
  Workshop on Network Steganography - IWNS 2009, November 18-20, 2009, Wuhan
  (China)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents an analysis of performance features of the HICCUPS (HIdden
Communication system for CorrUPted networkS) including the efficiency and the
cost of the system in WLANs (Wireless Local Area Networks). The analysis relies
on the original CSMA/CA (Carrier Sense Multiple Access with Collision
Avoidance) 802.11 Markov chain-based model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4228</identifier>
 <datestamp>2009-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4228</id><created>2009-06-23</created><updated>2009-09-17</updated><authors><author><keyname>Meier</keyname><forenames>Michael</forenames></author><author><keyname>Schmidt</keyname><forenames>Michael</forenames></author><author><keyname>Lausen</keyname><forenames>Georg</forenames></author></authors><title>On Chase Termination Beyond Stratification</title><categories>cs.DB cs.AI</categories><comments>Technical Report of VLDB 2009 conference version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the termination problem of the chase algorithm, a central tool in
various database problems such as the constraint implication problem,
Conjunctive Query optimization, rewriting queries using views, data exchange,
and data integration. The basic idea of the chase is, given a database instance
and a set of constraints as input, to fix constraint violations in the database
instance. It is well-known that, for an arbitrary set of constraints, the chase
does not necessarily terminate (in general, it is even undecidable if it does
or not). Addressing this issue, we review the limitations of existing
sufficient termination conditions for the chase and develop new techniques that
allow us to establish weaker sufficient conditions. In particular, we introduce
two novel termination conditions called safety and inductive restriction, and
use them to define the so-called T-hierarchy of termination conditions. We then
study the interrelations of our termination conditions with previous conditions
and the complexity of checking our conditions. This analysis leads to an
algorithm that checks membership in a level of the T-hierarchy and accounts for
the complexity of termination conditions. As another contribution, we study the
problem of data-dependent chase termination and present sufficient termination
conditions w.r.t. fixed instances. They might guarantee termination although
the chase does not terminate in the general case. As an application of our
techniques beyond those already mentioned, we transfer our results into the
field of query answering over knowledge bases where the chase on the underlying
database may not terminate, making existing algorithms applicable to broader
classes of constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4291</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4291</id><created>2009-06-23</created><authors><author><keyname>Sherstov</keyname><forenames>Alexander A.</forenames></author></authors><title>The Pattern Matrix Method (Journal Version)</title><categories>cs.CC quant-ph</categories><comments>Revised and expanded version of the STOC'08 article. To appear in
  SIAM J. Comput., 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a novel and powerful technique for communication lower bounds, the
pattern matrix method. Specifically, fix an arbitrary function f:{0,1}^n-&gt;{0,1}
and let A_f be the matrix whose columns are each an application of f to some
subset of the variables x_1,x_2,...,x_{4n}. We prove that A_f has bounded-error
communication complexity Omega(d), where d is the approximate degree of f. This
result remains valid in the quantum model, regardless of prior entanglement. In
particular, it gives a new and simple proof of Razborov's breakthrough quantum
lower bounds for disjointness and other symmetric predicates. We further
characterize the discrepancy, approximate rank, and approximate trace norm of
A_f in terms of well-studied analytic properties of f, broadly generalizing
several recent results on small-bias communication and agnostic learning. The
method of this paper has recently enabled important progress in multiparty
communication complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4302</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4302</id><created>2009-06-23</created><authors><author><keyname>Mihoob</keyname><forenames>Ahmed</forenames><affiliation>School Of Computing Science, University Of Newcastle, UK</affiliation></author><author><keyname>Molina-Jimenez</keyname><forenames>Carlos</forenames><affiliation>School Of Computing Science, University Of Newcastle, UK</affiliation></author></authors><title>A Peer to Peer Protocol for Online Dispute Resolution over Storage
  Consumption</title><categories>cs.DC</categories><comments>12 pages, 7 figures</comments><journal-ref>EPTCS 2, 2009, pp. 3-14</journal-ref><doi>10.4204/EPTCS.2.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In bilateral accounting of resource consumption both the consumer and
provider independently measure the amount of resources consumed by the
consumer. The problem here is that potential disparities between the provider's
and consumer's accountings, might lead to conflicts between the two parties
that need to be resolved. We argue that with the proper mechanisms available,
most of these conflicts can be solved online, as opposite to in court
resolution; the design of such mechanisms is still a research topic; to help
cover the gap, in this paper we propose a peer--to--peer protocol for online
dispute resolution over storage consumption. The protocol is peer--to--peer and
takes into consideration the possible causes (e.g, transmission delays,
unsynchronized metric collectors, etc.) of the disparity between the provider's
and consumer's accountings to make, if possible, the two results converge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4315</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4315</id><created>2009-06-23</created><updated>2011-05-19</updated><authors><author><keyname>Bickford</keyname><forenames>Mark</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Constable</keyname><forenames>Robert</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Halpern</keyname><forenames>Joseph</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Petride</keyname><forenames>Sabina</forenames><affiliation>Cornell University</affiliation></author></authors><title>Knowledge-Based Synthesis of Distributed Systems Using Event Structures</title><categories>cs.LO</categories><comments>A preliminary version of this paper appeared in Proceedings of the
  11th International Conference on Logic for Programming, Artificial
  Intelligence, and Reasoning LPAR 2004, pp. 449-465</comments><proxy>LMCS</proxy><acm-class>F.3.1, F.3.2, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 2 (May 21,
  2011) lmcs:804</journal-ref><doi>10.2168/LMCS-7(2:14)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To produce a program guaranteed to satisfy a given specification one can
synthesize it from a formal constructive proof that a computation satisfying
that specification exists. This process is particularly effective if the
specifications are written in a high-level language that makes it easy for
designers to specify their goals. We consider a high-level specification
language that results from adding knowledge to a fragment of Nuprl specifically
tailored for specifying distributed protocols, called event theory. We then
show how high-level knowledge-based programs can be synthesized from the
knowledge-based specifications using a proof development system such as Nuprl.
Methods of Halpern and Zuck then apply to convert these knowledge-based
protocols to ordinary protocols. These methods can be expressed as heuristic
transformation tactics in Nuprl.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4316</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4316</id><created>2009-06-23</created><authors><author><keyname>Blume</keyname><forenames>Lawrence</forenames></author><author><keyname>Easley</keyname><forenames>David</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Constructive Decision Theory</title><categories>cs.GT cs.AI</categories><comments>A preliminary version of paper, with the title &quot;Redoing the
  Foundations of Decision Theory&quot; appeared in the Tenth International
  Conference on Principles of Knowledge Representation and Reasoning</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In most contemporary approaches to decision making, a decision problem is
described by a sets of states and set of outcomes, and a rich set of acts,
which are functions from states to outcomes over which the decision maker (DM)
has preferences. Most interesting decision problems, however, do not come with
a state space and an outcome space. Indeed, in complex problems it is often far
from clear what the state and outcome spaces would be. We present an
alternative foundation for decision making, in which the primitive objects of
choice are syntactic programs. A representation theorem is proved in the spirit
of standard representation theorems, showing that if the DM's preference
relation on objects of choice satisfies appropriate axioms, then there exist a
set S of states, a set O of outcomes, a way of interpreting the objects of
choice as functions from S to O, a probability on S, and a utility function on
O, such that the DM prefers choice a to choice b if and only if the expected
utility of a is higher than that of b. Thus, the state space and outcome space
are subjective, just like the probability and utility; they are not part of the
description of the problem. In principle, a modeler can test for SEU behavior
without having access to states or outcomes. We illustrate the power of our
approach by showing that it can capture decision makers who are subject to
framing effects.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4321</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4321</id><created>2009-06-23</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Rego</keyname><forenames>Leandro</forenames></author></authors><title>Reasoning About Knowledge of Unawareness Revisited</title><categories>cs.AI cs.GT cs.LO</categories><comments>In Proceedings of Twelfth Conference on Theoretical Aspects of
  Rationality and Knowledge, 2009, pp. 166-173</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In earlier work, we proposed a logic that extends the Logic of General
Awareness of Fagin and Halpern [1988] by allowing quantification over primitive
propositions. This makes it possible to express the fact that an agent knows
that there are some facts of which he is unaware. In that logic, it is not
possible to model an agent who is uncertain about whether he is aware of all
formulas. To overcome this problem, we keep the syntax of the earlier paper,
but allow models where, with each world, a possibly different language is
associated. We provide a sound and complete axiomatization for this logic and
show that, under natural assumptions, the quantifier-free fragment of the logic
is characterized by exactly the same axioms as the logic of Heifetz, Meier, and
Schipper [2008].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4326</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4326</id><created>2009-06-23</created><authors><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author><author><keyname>Pass</keyname><forenames>Rafael</forenames></author></authors><title>A Logical Characterization of Iterated Admissibility</title><categories>cs.AI cs.GT cs.LO</categories><comments>In Proceedings of Twelfth Conference on Theoretical Aspects of
  Rationality and Knowledge, 2009, pp. 146-155</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Brandenburger, Friedenberg, and Keisler provide an epistemic characterization
of iterated admissibility (i.e., iterated deletion of weakly dominated
strategies) where uncertainty is represented using LPSs (lexicographic
probability sequences). Their characterization holds in a rich structure called
a complete structure, where all types are possible. Here, a logical
charaacterization of iterated admisibility is given that involves only standard
probability and holds in all structures, not just complete structures. A
stronger notion of strong admissibility is then defined. Roughly speaking,
strong admissibility is meant to capture the intuition that &quot;all the agent
knows&quot; is that the other agents satisfy the appropriate rationality
assumptions. Strong admissibility makes it possible to relate admissibility,
canonical structures (as typically considered in completeness proofs in modal
logic), complete structures, and the notion of ``all I know''.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4327</identifier>
 <datestamp>2009-06-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4327</id><created>2009-06-23</created><authors><author><keyname>Bisaria</keyname><forenames>Jigyasa</forenames></author><author><keyname>Shrivastava</keyname><forenames>Namita</forenames></author><author><keyname>Pardasani</keyname><forenames>K. R.</forenames></author></authors><title>A Rough Sets Partitioning Model for Mining Sequential Patterns with Time
  Constraint</title><categories>cs.DB</categories><comments>9 pages, International Journal of Computer Science and Information
  Security, IJCSIS 2009</comments><journal-ref>IJCSIS, June 2009 Issue, Vol. 2, No.1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Now a days, data mining and knowledge discovery methods are applied to a
variety of enterprise and engineering disciplines to uncover interesting
patterns from databases. The study of Sequential patterns is an important data
mining problem due to its wide applications to real world time dependent
databases. Sequential patterns are inter-event patterns ordered over a
time-period associated with specific objects under study. Analysis and
discovery of frequent sequential patterns over a predetermined time-period are
interesting data mining results, and can aid in decision support in many
enterprise applications. The problem of sequential pattern mining poses
computational challenges as a long frequent sequence contains enormous number
of frequent subsequences. Also useful results depend on the right choice of
event window. In this paper, we have studied the problem of sequential pattern
mining through two perspectives, one the computational aspect of the problem
and the other is incorporation and adjustability of time constraint. We have
used Indiscernibility relation from theory of rough sets to partition the
search space of sequential patterns and have proposed a novel algorithm that
allows previsualization of patterns and allows adjustment of time constraint
prior to execution of mining task. The algorithm Rough Set Partitioning is at
least ten times faster than the naive time constraint based sequential pattern
mining algorithm GSP. Besides this an additional knowledge of time interval of
sequential patterns is also determined with the method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4332</identifier>
 <datestamp>2014-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4332</id><created>2009-06-23</created><updated>2014-08-09</updated><authors><author><keyname>Grove</keyname><forenames>Adam J.</forenames></author><author><keyname>Halpern</keyname><forenames>Joseph Y.</forenames></author></authors><title>Updating Sets of Probabilities</title><categories>cs.AI</categories><comments>In Proceedings of the Fourteenth Conference on Uncertainty in AI,
  1998, pp. 173-182</comments><proxy>Martijn de Jongh</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are several well-known justifications for conditioning as the
appropriate method for updating a single probability measure, given an
observation. However, there is a significant body of work arguing for sets of
probability measures, rather than single measures, as a more realistic model of
uncertainty. Conditioning still makes sense in this context--we can simply
condition each measure in the set individually, then combine the results--and,
indeed, it seems to be the preferred updating procedure in the literature. But
how justified is conditioning in this richer setting? Here we show, by
considering an axiomatic account of conditioning given by van Fraassen, that
the single-measure and sets-of-measures cases are very different. We show that
van Fraassen's axiomatization for the former case is nowhere near sufficient
for updating sets of measures. We give a considerably longer (and not as
compelling) list of axioms that together force conditioning in this setting,
and describe other update methods that are allowed once any of these axioms is
dropped.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4377</identifier>
 <datestamp>2009-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4377</id><created>2009-06-23</created><authors><author><keyname>Jeronimo</keyname><forenames>Gabriela</forenames></author><author><keyname>Perrucci</keyname><forenames>Daniel</forenames></author></authors><title>On the minimum of a positive polynomial over the standard simplex</title><categories>math.AG cs.SC</categories><msc-class>14P10; 13P10; 26C99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new positive lower bound for the minimum value taken by a
polynomial P with integer coefficients in k variables over the standard simplex
of R^k, assuming that P is positive on the simplex. This bound depends only on
the number of variables, the degree and the bitsize of the coefficients of P
and improves all previous bounds for arbitrary polynomials which are positive
over the simplex.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4415</identifier>
 <datestamp>2009-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4415</id><created>2009-06-24</created><authors><author><keyname>Bhatnagar</keyname><forenames>Gaurav</forenames></author><author><keyname>Raman</keyname><forenames>Balasubramanian</forenames></author></authors><title>Robust Watermarking in Multiresolution Walsh-Hadamard Transform</title><categories>cs.CR cs.IT cs.MM math.IT</categories><comments>6 Pages, 16 Figure, 2 Tables</comments><journal-ref>Proc. of IEEE International Advance Computing Conference (IACC
  2009), Patiala, India, 6-7 March 2009, pp. 894-899</journal-ref><doi>10.1109/IADCC.2009.4809134</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a newer version of Walsh-Hadamard Transform namely
multiresolution Walsh-Hadamard Transform (MR-WHT) is proposed for images.
Further, a robust watermarking scheme is proposed for copyright protection
using MRWHT and singular value decomposition. The core idea of the proposed
scheme is to decompose an image using MR-WHT and then middle singular values of
high frequency sub-band at the coarsest and the finest level are modified with
the singular values of the watermark. Finally, a reliable watermark extraction
scheme is developed for the extraction of the watermark from the distorted
image. The experimental results show better visual imperceptibility and
resiliency of the proposed scheme against intentional or un-intentional variety
of attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4431</identifier>
 <datestamp>2011-03-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4431</id><created>2009-06-24</created><updated>2011-02-26</updated><authors><author><keyname>Binkele-Raible</keyname><forenames>Daniel</forenames></author><author><keyname>Erd&#xe9;lyi</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Fernau</keyname><forenames>Henning</forenames></author><author><keyname>Goldsmith</keyname><forenames>Judy</forenames></author><author><keyname>Mattei</keyname><forenames>Nicholas</forenames></author><author><keyname>Rothe</keyname><forenames>J&#xf6;rg</forenames></author></authors><title>The Complexity of Probabilistic Lobbying</title><categories>cs.CC</categories><comments>35 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose models for lobbying in a probabilistic environment, in which an
actor (called &quot;The Lobby&quot;) seeks to influence voters' preferences of voting for
or against multiple issues when the voters' preferences are represented in
terms of probabilities. In particular, we provide two evaluation criteria and
two bribery methods to formally describe these models, and we consider the
resulting forms of lobbying with and without issue weighting. We provide a
formal analysis for these problems of lobbying in a stochastic environment, and
determine their classical and parameterized complexity depending on the given
bribery/evaluation criteria and on various natural parameterizations.
Specifically, we show that some of these problems can be solved in polynomial
time, some are NP-complete but fixed-parameter tractable, and some are
W[2]-complete. Finally, we provide approximability and inapproximability
results for these problems and several variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4454</identifier>
 <datestamp>2009-09-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4454</id><created>2009-06-24</created><authors><author><keyname>Coquillard</keyname><forenames>Patrick</forenames><affiliation>IBSV</affiliation></author><author><keyname>Muzy</keyname><forenames>Alexandre</forenames><affiliation>LISA</affiliation></author><author><keyname>Wajnberg</keyname><forenames>Eric</forenames><affiliation>IBSV</affiliation></author></authors><title>Activatability for simulation tractability of NP problems: Application
  to Ecology</title><categories>q-bio.QM cs.CE</categories><comments>Complex Systems: Activity-Based Modeling and Simulation, Cargese
  Interdisciplinary Seminar, Corsica, France., France (2009)</comments><proxy>ccsd hal-00398181</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dynamics of biological-ecological systems is strongly depending on spatial
dimensions. Most of powerful simulators in ecology take into account for system
spatiality thus embedding stochastic processes. Due to the difficulty of
researching particular trajectories, biologists and computer scientists aim at
predicting the most probable trajectories of systems under study. Doing that,
they considerably reduce computation times. However, because of the largeness
of space, the execution time remains usually polynomial in time. In order to
reduce execution times we propose an activatability-based search cycle through
the process space. This cycle eliminates the redundant processes on a
statistical basis (Generalized Linear Model), and converges to the minimal
number of processes required to match simulation objectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4474</identifier>
 <datestamp>2009-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4474</id><created>2009-06-24</created><updated>2009-06-25</updated><authors><author><keyname>Sneyers</keyname><forenames>Jon</forenames></author><author><keyname>Van Weert</keyname><forenames>Peter</forenames></author><author><keyname>Schrijvers</keyname><forenames>Tom</forenames></author><author><keyname>De Koninck</keyname><forenames>Leslie</forenames></author></authors><title>As time goes by: Constraint Handling Rules - A survey of CHR research
  from 1998 to 2007</title><categories>cs.PL</categories><comments>49 pages. To appear in Theory and Practice of Logic Programming</comments><acm-class>D.1.3; D.1.6; D.3.0; F.3.2; J.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Constraint Handling Rules (CHR) is a high-level programming language based on
multi-headed multiset rewrite rules. Originally designed for writing
user-defined constraint solvers, it is now recognized as an elegant general
purpose language. CHR-related research has surged during the decade following
the previous survey by Fruehwirth. Covering more than 180 publications, this
new survey provides an overview of recent results in a wide range of research
areas, from semantics and analysis to systems, extensions and applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4481</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4481</id><created>2009-06-24</created><updated>2009-07-01</updated><authors><author><keyname>Kohli</keyname><forenames>Pankaj</forenames></author></authors><title>Coarse-grained Dynamic Taint Analysis for Defeating Control and
  Non-control Data Attacks</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Memory corruption attacks remain the primary threat for computer security.
Information flow tracking or taint analysis has been proven to be effective
against most memory corruption attacks. However, there are two shortcomings
with current taint analysis based techniques. First, these techniques cause
application slowdown by about 76% thereby limiting their practicality. Second,
these techniques cannot handle non-control data attacks i.e., attacks that do
not overwrite control data such as return address, but instead overwrite
critical application configuration data or user identity data. In this work, to
address these problems, we describe a coarse-grained taint analysis technique
that uses information flow tracking at the level of application data objects.
We propagate a one-bit taint over each application object that is modified by
untrusted data thereby reducing the taint management overhead considerably. We
performed extensive experimental evaluation of our approach and show that it
can detect all critical attacks such as buffer overflows, and format string
attacks, including non-control data attacks. Unlike the currently known
approaches that can detect such a wide range of attacks, our approach does not
require the source code or any hardware extensions. Run-time performance
overhead evaluation shows that, on an average, our approach causes application
slowdown by only 37% which is an order of magnitude improvement over existing
approaches. Finally, since our approach performs run-time binary
instrumentation, it is easier to integrate it with existing applications and
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4492</identifier>
 <datestamp>2009-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4492</id><created>2009-06-24</created><authors><author><keyname>Cimatti</keyname><forenames>Alessandro</forenames></author><author><keyname>Griggio</keyname><forenames>Alberto</forenames></author><author><keyname>Sebastiani</keyname><forenames>Roberto</forenames></author></authors><title>Efficient Generation of Craig Interpolants in Satisfiability Modulo
  Theories</title><categories>cs.LO</categories><comments>submitted to ACM Transactions on Computational Logic (TOCL)</comments><acm-class>F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of computing Craig Interpolants has recently received a lot of
interest. In this paper, we address the problem of efficient generation of
interpolants for some important fragments of first order logic, which are
amenable for effective decision procedures, called Satisfiability Modulo Theory
solvers.
  We make the following contributions.
  First, we provide interpolation procedures for several basic theories of
interest: the theories of linear arithmetic over the rationals, difference
logic over rationals and integers, and UTVPI over rationals and integers.
  Second, we define a novel approach to interpolate combinations of theories,
that applies to the Delayed Theory Combination approach.
  Efficiency is ensured by the fact that the proposed interpolation algorithms
extend state of the art algorithms for Satisfiability Modulo Theories. Our
experimental evaluation shows that the MathSAT SMT solver can produce
interpolants with minor overhead in search, and much more efficiently than
other competitor solvers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4539</identifier>
 <datestamp>2010-05-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4539</id><created>2009-06-24</created><updated>2010-05-10</updated><authors><author><keyname>Mahoney</keyname><forenames>Michael W.</forenames></author><author><keyname>Narayanan</keyname><forenames>Hariharan</forenames></author></authors><title>Learning with Spectral Kernels and Heavy-Tailed Data</title><categories>cs.LG cs.DS</categories><comments>21 pages. Substantially revised and extended relative to the first
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two ubiquitous aspects of large-scale data analysis are that the data often
have heavy-tailed properties and that diffusion-based or spectral-based methods
are often used to identify and extract structure of interest. Perhaps
surprisingly, popular distribution-independent methods such as those based on
the VC dimension fail to provide nontrivial results for even simple learning
problems such as binary classification in these two settings. In this paper, we
develop distribution-dependent learning methods that can be used to provide
dimension-independent sample complexity bounds for the binary classification
problem in these two popular settings. In particular, we provide bounds on the
sample complexity of maximum margin classifiers when the magnitude of the
entries in the feature vector decays according to a power law and also when
learning is performed with the so-called Diffusion Maps kernel. Both of these
results rely on bounding the annealed entropy of gap-tolerant classifiers in a
Hilbert space. We provide such a bound, and we demonstrate that our proof
technique generalizes to the case when the margin is measured with respect to
more general Banach space norms. The latter result is of potential interest in
cases where modeling the relationship between data elements as a dot product in
a Hilbert space is too restrictive.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4560</identifier>
 <datestamp>2010-11-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4560</id><created>2009-06-24</created><updated>2010-11-09</updated><authors><author><keyname>Cohen</keyname><forenames>Edith</forenames></author><author><keyname>Kaplan</keyname><forenames>Haim</forenames></author><author><keyname>Sen</keyname><forenames>Subhabrata</forenames></author></authors><title>Coordinated Weighted Sampling for Estimating Aggregates Over Multiple
  Weight Assignments</title><categories>cs.DB cs.NI</categories><comments>This is an updated full version of the PVLDB 2009 conference version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many data sources are naturally modeled by multiple weight assignments over a
set of keys: snapshots of an evolving database at multiple points in time,
measurements collected over multiple time periods, requests for resources
served at multiple locations, and records with multiple numeric attributes.
Over such vector-weighted data we are interested in aggregates with respect to
one set of weights, such as weighted sums, and aggregates over multiple sets of
weights such as the $L_1$ difference.
  Sample-based summarization is highly effective for data sets that are too
large to be stored or manipulated. The summary facilitates approximate
processing queries that may be specified after the summary was generated.
  Current designs, however, are geared for data sets where a single {\em
scalar} weight is associated with each key.
  We develop a sampling framework based on {\em coordinated weighted samples}
that is suited for multiple weight assignments and obtain estimators that are
{\em orders of magnitude tighter} than previously possible.
  We demonstrate the power of our methods through an extensive empirical
evaluation on diverse data sets ranging from IP network to stock quotes data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4567</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4567</id><created>2009-06-24</created><authors><author><keyname>Wang</keyname><forenames>P.</forenames></author><author><keyname>Gonzalez</keyname><forenames>M.</forenames></author><author><keyname>Hidalgo</keyname><forenames>C. A.</forenames></author><author><keyname>Barabasi</keyname><forenames>A. -L.</forenames></author></authors><title>Understanding the spreading patterns of mobile phone viruses</title><categories>physics.data-an cs.NI physics.soc-ph</categories><comments>13 pages, 4 figures</comments><journal-ref>Science 324, 1071-1076 (2009)</journal-ref><doi>10.1126/science.1167053</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We model the mobility of mobile phone users to study the fundamental
spreading patterns characterizing a mobile virus outbreak. We find that while
Bluetooth viruses can reach all susceptible handsets with time, they spread
slowly due to human mobility, offering ample opportunities to deploy antiviral
software. In contrast, viruses utilizing multimedia messaging services could
infect all users in hours, but currently a phase transition on the underlying
call graph limits them to only a small fraction of the susceptible users. These
results explain the lack of a major mobile virus breakout so far and predict
that once a mobile operating system's market share reaches the phase transition
point, viruses will pose a serious threat to mobile communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4570</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4570</id><created>2009-06-25</created><authors><author><keyname>Barletta</keyname><forenames>Michele</forenames></author><author><keyname>Ranise</keyname><forenames>Silvio</forenames></author><author><keyname>Vigan&#xf2;</keyname><forenames>Luca</forenames></author></authors><title>Verifying the Interplay of Authorization Policies and Workflow in
  Service-Oriented Architectures (Full version)</title><categories>cs.CR cs.LO</categories><comments>16 pages, 4 figures, full version of paper at Symposium on Secure
  Computing (SecureCom09)</comments><acm-class>C.2.2; D.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A widespread design approach in distributed applications based on the
service-oriented paradigm, such as web-services, consists of clearly separating
the enforcement of authorization policies and the workflow of the applications,
so that the interplay between the policy level and the workflow level is
abstracted away. While such an approach is attractive because it is quite
simple and permits one to reason about crucial properties of the policies under
consideration, it does not provide the right level of abstraction to specify
and reason about the way the workflow may interfere with the policies, and vice
versa. For example, the creation of a certificate as a side effect of a
workflow operation may enable a policy rule to fire and grant access to a
certain resource; without executing the operation, the policy rule should
remain inactive. Similarly, policy queries may be used as guards for workflow
transitions.
  In this paper, we present a two-level formal verification framework to
overcome these problems and formally reason about the interplay of
authorization policies and workflow in service-oriented architectures. This
allows us to define and investigate some verification problems for SO
applications and give sufficient conditions for their decidability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4582</identifier>
 <datestamp>2010-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4582</id><created>2009-06-24</created><authors><author><keyname>Belabbas</keyname><forenames>Mohamed-Ali</forenames></author><author><keyname>Wolfe</keyname><forenames>Patrick J.</forenames></author></authors><title>On landmark selection and sampling in high-dimensional data analysis</title><categories>stat.ML cs.CV cs.LG</categories><comments>18 pages, 6 figures, submitted for publication</comments><journal-ref>Philosophical Transactions of the Royal Society, Series A, vol.
  367, pp. 4295-4312, 2009</journal-ref><doi>10.1098/rsta.2009.0161</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years, the spectral analysis of appropriately defined kernel
matrices has emerged as a principled way to extract the low-dimensional
structure often prevalent in high-dimensional data. Here we provide an
introduction to spectral methods for linear and nonlinear dimension reduction,
emphasizing ways to overcome the computational limitations currently faced by
practitioners with massive datasets. In particular, a data subsampling or
landmark selection process is often employed to construct a kernel based on
partial information, followed by an approximate spectral analysis termed the
Nystrom extension. We provide a quantitative framework to analyse this
procedure, and use it to demonstrate algorithmic performance bounds on a range
of practical approaches designed to optimize the landmark selection process. We
compare the practical implications of these bounds by way of real-world
examples drawn from the field of computer vision, whereby low-dimensional
manifold structure is shown to emerge from high-dimensional video data streams.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4589</identifier>
 <datestamp>2010-02-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4589</id><created>2009-06-24</created><updated>2010-02-26</updated><authors><author><keyname>Huang</keyname><forenames>Dong</forenames></author><author><keyname>Shen</keyname><forenames>Zhiqi</forenames></author><author><keyname>Miao</keyname><forenames>Chunyan</forenames></author><author><keyname>Man</keyname><forenames>Zhihong</forenames></author><author><keyname>Leung</keyname><forenames>Cyril</forenames></author></authors><title>Further Analysis on Resource Allocation in Wireless Communications Under
  Imperfect Channel State Information</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the author due to some errors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4597</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4597</id><created>2009-06-24</created><updated>2010-03-12</updated><authors><author><keyname>Sadiq</keyname><forenames>Bilal</forenames></author><author><keyname>de Veciana</keyname><forenames>Gustavo</forenames></author></authors><title>Large deviations sum-queue optimality of a radial sum-rate monotone
  opportunistic scheduler</title><categories>cs.IT math.IT</categories><comments>Revised version. Major changes include addition of
  details/intermediate steps in various proofs, a summary of technical steps in
  Table 1, and correction of typos.</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A centralized wireless system is considered that is serving a fixed set of
users with time varying channel capacities. An opportunistic scheduling rule in
this context selects a user (or users) to serve based on the current channel
state and user queues. Unless the user traffic is symmetric and/or the
underlying capacity region a polymatroid, little is known concerning how
performance optimal schedulers should tradeoff &quot;maximizing current service
rate&quot; (being opportunistic) versus &quot;balancing unequal queues&quot; (enhancing
user-diversity to enable future high service rate opportunities). By contrast
with currently proposed opportunistic schedulers, e.g., MaxWeight and Exp Rule,
a radial sum-rate monotone (RSM) scheduler de-emphasizes queue-balancing in
favor of greedily maximizing the system service rate as the queue-lengths are
scaled up linearly. In this paper it is shown that an RSM opportunistic
scheduler, p-Log Rule, is not only throughput-optimal, but also maximizes the
asymptotic exponential decay rate of the sum-queue distribution for a two-queue
system. The result complements existing optimality results for opportunistic
scheduling and point to RSM schedulers as a good design choice given the need
for robustness in wireless systems with both heterogeneity and high degree of
uncertainty.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4602</identifier>
 <datestamp>2010-12-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4602</id><created>2009-06-25</created><updated>2010-05-26</updated><authors><author><keyname>Kuijper</keyname><forenames>M.</forenames></author><author><keyname>Schindelar</keyname><forenames>K.</forenames></author></authors><title>Minimal Gr\&quot;obner bases and the predictable leading monomial property</title><categories>cs.IT math.IT</categories><comments>14 pages, submitted, shortened version</comments><journal-ref>Linear Algebra and its Applications, vol. 434, pages 104-116, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on Gr\&quot;obner bases for modules of univariate polynomial vectors over
a ring. We identify a useful property, the &quot;predictable leading monomial (PLM)
property&quot; that is shared by minimal Gr\&quot;{o}bner bases of modules in F[x]^q, no
matter what positional term order is used. The PLM property is useful in a
range of applications and can be seen as a strengthening of the wellknown
predictable degree property (= row reducedness), a terminology introduced by
Forney in the 70's. Because of the presence of zero divisors, minimal
Gr\&quot;{o}bner bases over a finite ring of the type Z_p^r (where p is a prime
integer and r is an integer &gt;1) do not necessarily have the PLM property. In
this paper we show how to derive, from an ordered minimal Gr\&quot;{o}bner basis, a
so-called &quot;minimal Gr\&quot;{o}bner p-basis&quot; that does have a PLM property. We
demonstrate that minimal Gr\&quot;obner p-bases lend themselves particularly well to
derive minimal realization parametrizations over Z_p^r. Applications are in
coding and sequences over Z_p^r.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4607</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4607</id><created>2009-06-25</created><authors><author><keyname>Kugali</keyname><forenames>Sandeep.</forenames></author><author><keyname>Manvi</keyname><forenames>S. S.</forenames></author><author><keyname>Sutagundar</keyname><forenames>A. V.</forenames></author></authors><title>A Bandwidth Characterization Tool For MPEG-2 File</title><categories>cs.MM</categories><comments>10 pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS, June 2009 Issue, Vol. 2, No. 1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes the design and development of MPEG 2 Video Decoder to
offer flexible and effective utilization of bandwidth services. The decoder is
capable of decoding the MPEG 2 bit stream on a single host machine. The present
decoder is designed to be simple, but yet effectively reconstruct the video
from MPEG 2 bit stream.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4609</identifier>
 <datestamp>2011-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4609</id><created>2009-06-25</created><updated>2009-06-30</updated><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>Critical independent sets and Konig--Egervary graphs</title><categories>math.CO cs.DM</categories><comments>8 pages, 5 figures</comments><msc-class>05C69, 05C70 (Primary); 05C75 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let alpha(G) be the cardinality of a independence set of maximum size in the
graph G, while mu(G) is the size of a maximum matching. G is a Konig--Egervary
graph if its order equals alpha(G) + mu(G). The set core(G) is the intersection
of all maximum independent sets of G (Levit &amp; Mandrescu, 2002). The number
def(G)=|V(G)|-2*mu(G) is the deficiency of G (Lovasz &amp; Plummer, 1986). The
number d(G)=max{|S|-|N(S)|:S in Ind(G)} is the critical difference of G. An
independent set A is critical if |A|-|N(A)|=d(G), where N(S) is the
neighborhood of S (Zhang, 1990). In 2009, Larson showed that G is
Konig--Egervary graph if and only if there exists a maximum independent set
that is critical as well. In this paper we prove that: (i)
d(G)=|core(G)|-|N(core(G))|=alpha(G)-mu(G)=def(G) for every Konig--Egervary
graph G; (ii) G is Konig--Egervary graph if and only if every maximum
independent set of G is critical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4612</identifier>
 <datestamp>2009-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4612</id><created>2009-06-25</created><authors><author><keyname>Neary</keyname><forenames>Turlough</forenames></author><author><keyname>Woods</keyname><forenames>Damien</forenames></author><author><keyname>Seda</keyname><forenames>Anthony K.</forenames></author><author><keyname>Murphy</keyname><forenames>Niall</forenames></author></authors><title>Proceedings International Workshop on The Complexity of Simple Programs</title><categories>cs.CC cs.FL</categories><journal-ref>EPTCS 1, 2009</journal-ref><doi>10.4204/EPTCS.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is the first volume of Electronic Proceedings in Theoretical Computer
Science (EPTCS), a free international refereed open access venue for the rapid
electronic publication of the proceedings of workshops and conferences, and of
festschriften, etc, in the general area of theoretical computer science,
broadly construed.
  It contains the proceedings of the International Workshop on The Complexity
of Simple Programs, which was hosted at University College Cork on the 6th and
7th of December, 2008. All speakers were invited and all of the papers went
through a thorough peer-review process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4615</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4615</id><created>2009-06-25</created><updated>2010-12-10</updated><authors><author><keyname>Yuksel</keyname><forenames>Melda</forenames></author><author><keyname>Erkip</keyname><forenames>Elza</forenames></author></authors><title>Diversity-Multiplexing Tradeoff for the Multiple-Antenna Wire-tap
  Channel</title><categories>cs.IT math.IT</categories><comments>10 pages, 4 figures, to appear in IEEE Transactions on Wireless
  Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the fading multiple antenna (MIMO) wire-tap channel is
investigated under short term power constraints. The secret diversity gain and
the secret multiplexing gain are defined. Using these definitions, the secret
diversitymultiplexing tradeoff (DMT) is calculated analytically for no
transmitter side channel state information (CSI) and for full CSI. When there
is no CSI at the transmitter, under the assumption of Gaussian codebooks, it is
shown that the eavesdropper steals both transmitter and receiver antennas, and
the secret DMT depends on the remaining degrees of freedom. When CSI is
available at the transmitter (CSIT), the eavesdropper steals only transmitter
antennas. This dependence on the availability of CSI is unlike the DMT results
without secrecy constraints, where the DMT remains the same for no CSI and full
CSI at the transmitter under short term power constraints. A zero-forcing type
scheme is shown to achieve the secret DMT when CSIT is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4618</identifier>
 <datestamp>2010-06-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4618</id><created>2009-06-25</created><updated>2010-06-20</updated><authors><author><keyname>Peris-Lopez</keyname><forenames>Pedro</forenames></author><author><keyname>Hernandez-Castro</keyname><forenames>Julio C.</forenames></author><author><keyname>Dimitrakakis</keyname><forenames>Christos</forenames></author><author><keyname>Mitrokotsa</keyname><forenames>Aikaterini</forenames></author><author><keyname>Tapiador</keyname><forenames>Juan M. E.</forenames></author></authors><title>Shedding Light on RFID Distance Bounding Protocols and Terrorist Fraud
  Attacks</title><categories>cs.CR</categories><comments>31 pages, 10 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The vast majority of RFID authentication protocols assume the proximity
between readers and tags due to the limited range of the radio channel.
However, in real scenarios an intruder can be located between the prover (tag)
and the verifier (reader) and trick this last one into thinking that the prover
is in close proximity. This attack is generally known as a relay attack in
which scope distance fraud, mafia fraud and terrorist attacks are included.
Distance bounding protocols represent a promising countermeasure to hinder
relay attacks. Several protocols have been proposed during the last years but
vulnerabilities of major or minor relevance have been identified in most of
them. In 2008, Kim et al. [1] proposed a new distance bounding protocol with
the objective of being the best in terms of security, privacy, tag
computational overhead and fault tolerance. In this paper, we analyze this
protocol and we present a passive full disclosure attack, which allows an
adversary to discover the long-term secret key of the tag. The presented attack
is very relevant, since no security objectives are met in Kim et al.'s
protocol. Then, design guidelines are introduced with the aim of facilitating
protocol designers the stimulating task of designing secure and efficient
schemes against relay attacks. Finally a new protocol, named Hitomi and
inspired by [1], is designed conforming the guidelines proposed previously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4643</identifier>
 <datestamp>2009-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4643</id><created>2009-06-25</created><updated>2009-10-05</updated><authors><author><keyname>Bross</keyname><forenames>Shraga</forenames></author><author><keyname>Lapidoth</keyname><forenames>Amos</forenames></author><author><keyname>Wang</keyname><forenames>Ligong</forenames></author></authors><title>The Poisson Channel with Side Information</title><categories>cs.IT math.IT</categories><comments>Final version to appear in the proceedings of Allerton 2009</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The continuous-time, peak-limited, infinite-bandwidth Poisson channel with
spurious counts is considered. It is shown that if the times at which the
spurious counts occur are known noncausally to the transmitter but not to the
receiver, then the capacity is equal to that of the Poisson channel with no
spurious counts. Knowing the times at which the spurious counts occur only
causally at the transmitter does not increase capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:0906.4663</identifier>
 <datestamp>2009-06-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>0906.4663</id><created>2009-06-25</created><authors><author><keyname>Amin</keyname><forenames>Hafeez Ullah</forenames></author><author><keyname>Khan</keyname><forenames>Abdur Rashid</forenames></author></authors><title>Acquiring Knowledge for Evaluation of Teachers Performance in Higher
  Education using a Questionnaire</title><categories>cs.LG</categories><comments>7 pages, International Journal of Computer Science and Information
  Security (IJCSIS)</comments><journal-ref>IJCSIS, June 2009 Issue, Vol. 2, No.1</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the step by step knowledge acquisition process by
choosing a structured method through using a questionnaire as a knowledge
acquisition tool. Here we want to depict the problem domain as, how to evaluate
teachers performance in higher education through the use of expert system
technology. The problem is how to acquire the specific knowledge for a selected
problem efficiently and effectively from human experts and encode it in the
suitable computer format. Acquiring knowledge from human experts in the process
of expert systems development is one of the most common problems cited till
yet. This questionnaire was sent to 87 domain experts within all public and
private universities in Pakistani. Among them 25 domain experts sent their
valuable opinions. Most of the domain experts were highly qualified, well
experienced and highly responsible persons. The whole questionnaire was divided
into 15 main groups of factors, which were further divided into 99 individual
questions. These facts were analyzed further to give a final shape to the
questionnaire. This knowledge acquisition technique may be used as a learning
tool for further research work.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="7000" completeListSize="102538">1122234|8001</resumptionToken>
</ListRecords>
</OAI-PMH>
