<?xml version="1.0" encoding="UTF-8"?>
<OAI-PMH xmlns="http://www.openarchives.org/OAI/2.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.openarchives.org/OAI/2.0/ http://www.openarchives.org/OAI/2.0/OAI-PMH.xsd">
<responseDate>2016-03-09T00:52:07Z</responseDate>
<request verb="ListRecords" resumptionToken="1122234|23001">http://export.arxiv.org/oai2</request>
<ListRecords>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3047</identifier>
 <datestamp>2012-01-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3047</id><created>2011-07-15</created><updated>2012-01-17</updated><authors><author><keyname>Abyaneh</keyname><forenames>Mohammad Reza Sohizadeh</forenames></author></authors><title>Security Analysis of two Distance-Bounding Protocols</title><categories>cs.CR</categories><comments>This paper is withdrwan due to duplication in DBLP site</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we analyze the security of two recently proposed distance
bounding protocols called the Hitomi and the NUS protocols. Our results show
that the claimed security of both protocols has been overestimated. Namely, we
show that the Hitomi protocol is susceptible to a full secret key disclosure
attack which not only results in violating the privacy of the protocol but also
can be exploited for further attacks such as impersonation, ma?a fraud and
terrorist fraud attacks. Our results also demonstrates that the probability of
success in a distance fraud attack against the NUS protocol can be increased up
to (3/4)^n and even slightly more, if the adversary is furnished with some
computational capabilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3059</identifier>
 <datestamp>2014-02-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3059</id><created>2011-07-15</created><updated>2014-02-10</updated><authors><author><keyname>Karbasi</keyname><forenames>Amin</forenames></author><author><keyname>Ioannidis</keyname><forenames>Stratis</forenames></author><author><keyname>Massoulie</keyname><forenames>Laurent</forenames></author></authors><title>From Small-World Networks to Comparison-Based Search</title><categories>cs.LG cs.DS cs.IT cs.SI math.IT stat.ML</categories><comments>42 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of content search through comparisons has recently received
considerable attention. In short, a user searching for a target object
navigates through a database in the following manner: the user is asked to
select the object most similar to her target from a small list of objects. A
new object list is then presented to the user based on her earlier selection.
This process is repeated until the target is included in the list presented, at
which point the search terminates. This problem is known to be strongly related
to the small-world network design problem.
  However, contrary to prior work, which focuses on cases where objects in the
database are equally popular, we consider here the case where the demand for
objects may be heterogeneous. We show that, under heterogeneous demand, the
small-world network design problem is NP-hard. Given the above negative result,
we propose a novel mechanism for small-world design and provide an upper bound
on its performance under heterogeneous demand. The above mechanism has a
natural equivalent in the context of content search through comparisons, and we
establish both an upper bound and a lower bound for the performance of this
mechanism. These bounds are intuitively appealing, as they depend on the
entropy of the demand as well as its doubling constant, a quantity capturing
the topology of the set of target objects. They also illustrate interesting
connections between comparison-based search to classic results from information
theory. Finally, we propose an adaptive learning algorithm for content search
that meets the performance guarantees achieved by the above mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3068</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3068</id><created>2011-07-15</created><updated>2011-10-06</updated><authors><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author><author><keyname>Wahlstr&#xf6;m</keyname><forenames>Magnus</forenames></author></authors><title>Compression via Matroids: A Randomized Polynomial Kernel for Odd Cycle
  Transversal</title><categories>cs.DS cs.DM</categories><comments>Minor changes to agree with SODA 2012 version of the paper</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Odd Cycle Transversal problem (OCT) asks whether a given graph can be
made bipartite by deleting at most $k$ of its vertices. In a breakthrough
result Reed, Smith, and Vetta (Operations Research Letters, 2004) gave a
$\BigOh(4^kkmn)$ time algorithm for it, the first algorithm with polynomial
runtime of uniform degree for every fixed $k$. It is known that this implies a
polynomial-time compression algorithm that turns OCT instances into equivalent
instances of size at most $\BigOh(4^k)$, a so-called kernelization. Since then
the existence of a polynomial kernel for OCT, i.e., a kernelization with size
bounded polynomially in $k$, has turned into one of the main open questions in
the study of kernelization.
  This work provides the first (randomized) polynomial kernelization for OCT.
We introduce a novel kernelization approach based on matroid theory, where we
encode all relevant information about a problem instance into a matroid with a
representation of size polynomial in $k$. For OCT, the matroid is built to
allow us to simulate the computation of the iterative compression step of the
algorithm of Reed, Smith, and Vetta, applied (for only one round) to an
approximate odd cycle transversal which it is aiming to shrink to size $k$. The
process is randomized with one-sided error exponentially small in $k$, where
the result can contain false positives but no false negatives, and the size
guarantee is cubic in the size of the approximate solution. Combined with an
$\BigOh(\sqrt{\log n})$-approximation (Agarwal et al., STOC 2005), we get a
reduction of the instance to size $\BigOh(k^{4.5})$, implying a randomized
polynomial kernelization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3085</identifier>
 <datestamp>2011-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3085</id><created>2011-07-15</created><authors><author><keyname>Piancastelli</keyname><forenames>Luca</forenames></author><author><keyname>Frizziero</keyname><forenames>Leonardo</forenames></author><author><keyname>Marcoppido</keyname><forenames>Simone</forenames></author><author><keyname>Pezzuti</keyname><forenames>Eugenio</forenames></author></authors><title>Applying whole system design in a sportscar factory</title><categories>nlin.AO cs.SE</categories><comments>The world crisis had accelerated the necessity to make innovation;
  innovation must be realized into new products; new innovative products can be
  thought only new deisgn process</comments><msc-class>97K70</msc-class><acm-class>A.m</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Basing on a paper which explores the adoption of a whole system approach to a
more sustainable and innovative design, the present paper wants to apply the
same approach to a real case, inside of a famous Italian sportscar factory. A
case study in this factory was developed and decodified gaining improved
understanding of whole system design and those factors that substantially
influence its success. All the factors mentioned above (such as dynamics of
flattened hierarchy, the need to identify relationship between parts of the
system) are used, into the application presented in this paper, to achieve an
ultimate optimization of the whole.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3087</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3087</id><created>2011-07-15</created><authors><author><keyname>L&#xfc;bben</keyname><forenames>Ralf</forenames></author><author><keyname>Fidler</keyname><forenames>Markus</forenames></author></authors><title>Non-equilibrium Information Envelopes and the
  Capacity-Delay-Error-Tradeoff of Source Coding</title><categories>cs.PF cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper develops an envelope-based approach to establish a link between
information and queueing theory. Unlike classical, equilibrium information
theory, information envelopes focus on the dynamics of sources and coders,
using functions of time that bound the number of bits generated. In the limit
the information envelopes converge to the average behavior and recover the
entropy of a source, respectively, the average codeword length of a coder. In
contrast, on short time scales and for sources with memory it is shown that
large deviations from known equilibrium results occur with non-negligible
probability. These can cause significant network delays. Compared to well-known
traffic models from queueing theory, information envelopes consider the
functioning of information sources and coders, avoiding a priori assumptions,
such as exponential traffic, or empirical, trace-based traffic models. Using
results from the stochastic network calculus, the envelopes yield a
characterization of the operating points of source coders by the triplet of
capacity, delay, and error. In the limit, assuming an optimal coder the
required capacity approaches the entropy with arbitrarily small probability of
error if infinitely large delays are permitted. We derive a corresponding
characterization of channels and prove that the model has the desirable
property of additivity, that allows analyzing coders and channels separately.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3090</identifier>
 <datestamp>2012-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3090</id><created>2011-07-15</created><updated>2012-10-04</updated><authors><author><keyname>Vlassis</keyname><forenames>Nikos</forenames></author><author><keyname>Littman</keyname><forenames>Michael L.</forenames></author><author><keyname>Barber</keyname><forenames>David</forenames></author></authors><title>On the Computational Complexity of Stochastic Controller Optimization in
  POMDPs</title><categories>cs.CC cs.LG cs.SY math.OC</categories><comments>Corrected error in the proof of Theorem 2, and revised Section 5</comments><acm-class>F.2.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that the problem of finding an optimal stochastic 'blind' controller
in a Markov decision process is an NP-hard problem. The corresponding decision
problem is NP-hard, in PSPACE, and SQRT-SUM-hard, hence placing it in NP would
imply breakthroughs in long-standing open problems in computer science. Our
result establishes that the more general problem of stochastic controller
optimization in POMDPs is also NP-hard. Nonetheless, we outline a special case
that is convex and admits efficient global solutions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3099</identifier>
 <datestamp>2011-07-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3099</id><created>2011-07-15</created><authors><author><keyname>Wardi</keyname><forenames>Yorai</forenames></author><author><keyname>Egerstedt</keyname><forenames>Magnus</forenames></author></authors><title>Algorithm for Optimal Mode Scheduling in Switched Systems</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the problem of computing the schedule of modes in a
switched dynamical system, that minimizes a cost functional defined on the
trajectory of the system's continuous state variable. A recent approach to such
optimal control problems consists of algorithms that alternate between
computing the optimal switching times between modes in a given sequence, and
updating the mode-sequence by inserting to it a finite number of new modes.
  These algorithms have an inherent inefficiency due to their sparse update of
the mode-sequences, while spending most of the computing times on optimizing
with respect to the switching times for a given mode-sequence. This paper
proposes an algorithm that operates directly in the schedule space without
resorting to the timing optimization problem. It is based on the Armijo step
size along certain Gateaux derivatives of the performance functional, thereby
avoiding some of the computational difficulties associated with discrete
scheduling parameters. Its convergence to local minima as well as its rate of
convergence are proved, and a simulation example on a nonlinear system exhibits
quite a fast convergence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3119</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3119</id><created>2011-07-15</created><updated>2011-07-22</updated><authors><author><keyname>Grefenstette</keyname><forenames>Edward</forenames></author><author><keyname>Sadrzadeh</keyname><forenames>Mehrnoosh</forenames></author></authors><title>Experimenting with Transitive Verbs in a DisCoCat</title><categories>cs.CL math.CT</categories><comments>5 pages, to be presented at GEMS 2011, as part of EMNLP'11 workshops</comments><msc-class>68T50</msc-class><acm-class>G.1.3; H.3.1; H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Formal and distributional semantic models offer complementary benefits in
modeling meaning. The categorical compositional distributional (DisCoCat) model
of meaning of Coecke et al. (arXiv:1003.4394v1 [cs.CL]) combines aspected of
both to provide a general framework in which meanings of words, obtained
distributionally, are composed using methods from the logical setting to form
sentence meaning. Concrete consequences of this general abstract setting and
applications to empirical data are under active study (Grefenstette et al.,
arxiv:1101.0309; Grefenstette and Sadrzadeh, arXiv:1106.4058v1 [cs.CL]). . In
this paper, we extend this study by examining transitive verbs, represented as
matrices in a DisCoCat. We discuss three ways of constructing such matrices,
and evaluate each method in a disambiguation task developed by Grefenstette and
Sadrzadeh (arXiv:1106.4058v1 [cs.CL]).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3127</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3127</id><created>2011-07-15</created><authors><author><keyname>Impagliazzo</keyname><forenames>Russell</forenames></author><author><keyname>Matthews</keyname><forenames>William</forenames></author><author><keyname>Paturi</keyname><forenames>Ramamohan</forenames></author></authors><title>A Satisfiability Algorithm for AC$^0$</title><categories>cs.CC cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of efficiently enumerating the satisfying assignments
to $\AC^0$ circuits. We give a zero-error randomized algorithm which takes an
$\AC^0$ circuit as input and constructs a set of restrictions which partition
$\{0,1\}^n$ so that under each restriction the value of the circuit is
constant. Let $d$ denote the depth of the circuit and $cn$ denote the number of
gates. This algorithm runs in time $|C| 2^{n(1-\mu_{c.d})}$ where $|C|$ is the
size of the circuit for $\mu_{c,d} \ge 1/\bigO[\lg c + d \lg d]^{d-1}$ with
probability at least $1-2^{-n}$.
  As a result, we get improved exponential time algorithms for $\AC^0$ circuit
satisfiability and for counting solutions. In addition, we get an improved
bound on the correlation of $\AC^0$ circuits with parity.
  As an important component of our analysis, we extend the H{\aa}stad Switching
Lemma to handle multiple $\kcnf$s and $\kdnf$s.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3129</identifier>
 <datestamp>2011-12-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3129</id><created>2011-07-15</created><authors><author><keyname>Oggier</keyname><forenames>Frederique</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author></authors><title>Homomorphic Self-repairing Codes for Agile Maintenance of Distributed
  Storage Systems</title><categories>cs.DC</categories><comments>arXiv admin note: significant text overlap with arXiv:1008.0064</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed data storage systems are essential to deal with the need to store
massive volumes of data. In order to make such a system fault-tolerant, some
form of redundancy becomes crucial, incurring various overheads - most
prominently in terms of storage space and maintenance bandwidth requirements.
Erasure codes, originally designed for communication over lossy channels,
provide a storage efficient alternative to replication based redundancy,
however entailing high communication overhead for maintenance, when some of the
encoded fragments need to be replenished in news ones after failure of some
storage devices. We propose as an alternative a new family of erasure codes
called self-repairing codes (SRC) taking into account the peculiarities of
distributed storage systems, specifically the maintenance process. SRC has the
following salient features: (a) encoded fragments can be repaired directly from
other subsets of encoded fragments by downloading less data than the size of
the complete object, ensuring that (b) a fragment is repaired from a fixed
number of encoded fragments, the number depending only on how many encoded
blocks are missing and independent of which specific blocks are missing. This
paper lays the foundations by defining the novel self-repairing codes,
elaborating why the defined characteristics are desirable for distributed
storage systems. Then homomorphic self-repairing codes (HSRC) are proposed as a
concrete instance, whose various aspects and properties are studied and
compared - quantitatively or qualitatively with respect to other codes
including traditional erasure codes as well as other recent codes designed
specifically for storage applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3133</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3133</id><created>2011-07-15</created><updated>2011-09-05</updated><authors><author><keyname>Kim</keyname><forenames>JooSeuk</forenames></author><author><keyname>Scott</keyname><forenames>Clayton D.</forenames></author></authors><title>Robust Kernel Density Estimation</title><categories>stat.ML cs.LG stat.ME</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a method for nonparametric density estimation that exhibits
robustness to contamination of the training sample. This method achieves
robustness by combining a traditional kernel density estimator (KDE) with ideas
from classical $M$-estimation. We interpret the KDE based on a radial, positive
semi-definite kernel as a sample mean in the associated reproducing kernel
Hilbert space. Since the sample mean is sensitive to outliers, we estimate it
robustly via $M$-estimation, yielding a robust kernel density estimator (RKDE).
  An RKDE can be computed efficiently via a kernelized iteratively re-weighted
least squares (IRWLS) algorithm. Necessary and sufficient conditions are given
for kernelized IRWLS to converge to the global minimizer of the $M$-estimator
objective function. The robustness of the RKDE is demonstrated with a
representer theorem, the influence function, and experimental results for
density estimation and anomaly detection.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3166</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3166</id><created>2011-07-15</created><authors><author><keyname>O&#x11f;uz</keyname><forenames>Barlas</forenames></author><author><keyname>Anantharam</keyname><forenames>Venkat</forenames></author><author><keyname>Norros</keyname><forenames>Ilkka</forenames></author></authors><title>Stable, scalable, decentralized P2P file sharing with non-altruistic
  peers</title><categories>cs.NI cs.DC cs.SI cs.SY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  P2P systems provide a scalable solution for distributing large files in a
network. The file is split into many chunks, and peers contact other peers to
collect missing chunks to eventually complete the entire file. The so-called
`rare chunk' phenomenon, where a single chunk becomes rare and prevents peers
from completing the file, is a threat to the stability of such systems.
Practical systems such as BitTorrent overcome this issue by requiring a global
search for the rare chunk, which necessitates a centralized mechanism. We
demonstrate a new system based on an approximate rare-chunk rule, allowing for
completely distributed file sharing while retaining scalability and stability.
We assume non-altruistic peers and the seed is required to make only a minimal
contribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3172</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3172</id><created>2011-07-15</created><updated>2012-07-30</updated><authors><author><keyname>WenBin</keyname><forenames>Hsieh</forenames></author><author><keyname>Jenq-Shiou</keyname><forenames>Leu</forenames></author></authors><title>Use of Hamiltonian Cycles in Cryptograph</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the authors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper has been withdrawn by the authors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3174</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3174</id><created>2011-07-15</created><authors><author><keyname>Nurdin</keyname><forenames>H. I.</forenames></author><author><keyname>Petersen</keyname><forenames>I. R.</forenames></author><author><keyname>James</keyname><forenames>M. R.</forenames></author></authors><title>On the infeasibility of entanglement generation in Gaussian quantum
  systems via classical control</title><categories>cs.SY math.OC quant-ph</categories><comments>6 pages, 3 figures. To appear in IEEE Transactions on Automatic
  Control, 2011</comments><journal-ref>IEEE Transactions on Automatic Control, 57(1), pp. 198-203,
  January 2012</journal-ref><doi>10.1109/TAC.2011.2162888</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper uses a system theoretic approach to show that classical linear
time invariant controllers cannot generate steady state entanglement in a
bipartite Gaussian quantum system which is initialized in a Gaussian state. The
paper also shows that the use of classical linear controllers cannot generate
entanglement in a finite time from a bipartite system initialized in a
separable Gaussian state. The approach reveals connections between system
theoretic concepts and the well known physical principle that local operations
and classical communications cannot generate entangled states starting from
separable states.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3177</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3177</id><created>2011-07-15</created><authors><author><keyname>Jian</keyname><forenames>Yung-Yih</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author></authors><title>Convergence of Weighted Min-Sum Decoding Via Dynamic Programming on
  Trees</title><categories>cs.IT math.IT</categories><comments>43 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applying the max-product (and belief-propagation) algorithms to loopy graphs
is now quite popular for best assignment problems. This is largely due to their
low computational complexity and impressive performance in practice. Still,
there is no general understanding of the conditions required for convergence
and/or the optimality of converged solutions. This paper presents an analysis
of both attenuated max-product (AMP) decoding and weighted min-sum (WMS)
decoding for LDPC codes which guarantees convergence to a fixed point when a
weight parameter, {\beta}, is sufficiently small. It also shows that, if the
fixed point satisfies some consistency conditions, then it must be both the
linear-programming (LP) and maximum-likelihood (ML) solution.
  For (dv,dc)-regular LDPC codes, the weight must satisfy {\beta}(dv-1) \leq 1
whereas the results proposed by Frey and Koetter require instead that
{\beta}(dv-1)(dc-1) &lt; 1. A counterexample which shows a fixed point might not
be the ML solution if {\beta}(dv-1) &gt; 1 is also given. Finally, connections are
explored with recent work by Arora et al. on the threshold of LP decoding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3193</identifier>
 <datestamp>2014-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3193</id><created>2011-07-15</created><updated>2014-08-20</updated><authors><author><keyname>Wang</keyname><forenames>Chengpu</forenames></author></authors><title>Type Expressiveness and Its Application in Separation of Behavior
  Programming and Data Management Programming</title><categories>cs.PL</categories><comments>13 pages, 10 figures</comments><acm-class>D.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A new behavior descriptive entity type called spec is proposed, which
combines the traditional interface with test rules and test cases, to
completely specify the desired behavior of each method, and to enforce the
behavior-wise correctness of all compiled units. Using spec, a new programming
paradigm is proposed, which allows the separation programming space into 1) a
behavior domain to aggregate all behavior programming in the format of specs,
2) a object domain to bind each concrete spec to its data representation in a
particular address space, and 3) a realization domain to connect the behavior
domain and the object domain. Such separation guarantees the strictness of
behavior satisfaction at compile time, while allows flexibility of dynamical
binding of actual implementation at runtime. A new convention call type
expressiveness to allow data exchange between different programming languages
and between different software environments is also proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3194</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3194</id><created>2011-07-15</created><authors><author><keyname>Thai</keyname><forenames>Le Hoang</forenames></author><author><keyname>Tam</keyname><forenames>Ha Nhat</forenames></author></authors><title>Fingerprint recognition using standardized fingerprint model</title><categories>cs.CV</categories><comments>7 pages, 16 figures, 3 tables, IJCSI International Journal of
  Computer Science Issues, Vol. 7, Issue 3, No 7, May 2010</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 7,
  Issue 3, No 7, May 2010, ISSN (Online): 1694-0784, ISSN (Print): 1694-0814</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fingerprint recognition is one of most popular and accuracy Biometric
technologies. Nowadays, it is used in many real applications. However,
recognizing fingerprints in poor quality images is still a very complex
problem. In recent years, many algorithms, models...are given to improve the
accuracy of recognition system. This paper discusses on the standardized
fingerprint model which is used to synthesize the template of fingerprints. In
this model, after pre-processing step, we find the transformation between
templates, adjust parameters, synthesize fingerprint, and reduce noises. Then,
we use the final fingerprint to match with others in FVC2004 fingerprint
database (DB4) to show the capability of the model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3195</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3195</id><created>2011-07-15</created><authors><author><keyname>Le</keyname><forenames>Thai</forenames></author><author><keyname>Tat</keyname><forenames>Phat</forenames></author><author><keyname>Tran</keyname><forenames>Hai</forenames></author></authors><title>Facial Expression Classification Based on Multi Artificial Neural
  Network and Two Dimensional Principal Component Analysis</title><categories>cs.CV</categories><comments>8 pages, 16 figures, IJCSI International Journal of Computer Science
  Issues, Vol. 8, Issue 3, No. 1, May 2011</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 3, No. 1, May 2011, ISSN (Online): 1694-0814, www.IJCSI.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Facial expression classification is a kind of image classification and it has
received much attention, in recent years. There are many approaches to solve
these problems with aiming to increase efficient classification. One of famous
suggestions is described as first step, project image to different spaces;
second step, in each of these spaces, images are classified into responsive
class and the last step, combine the above classified results into the final
result. The advantages of this approach are to reflect fulfill and multiform of
image classified. In this paper, we use 2D-PCA and its variants to project the
pattern or image into different spaces with different grouping strategies. Then
we develop a model which combines many Neural Networks applied for the last
step. This model evaluates the reliability of each space and gives the final
classification conclusion. Our model links many Neural Networks together, so we
call it Multi Artificial Neural Network (MANN). We apply our proposal model for
6 basic facial expressions on JAFFE database consisting 213 images posed by 10
Japanese female models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3197</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3197</id><created>2011-07-16</created><authors><author><keyname>Lekeas</keyname><forenames>Paraskevas V.</forenames></author><author><keyname>Stamatopoulos</keyname><forenames>Giorgos</forenames></author></authors><title>Cooperative oligopoly games: a probabilistic approach</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the core of a cooperative Cournot game. We assume that when
contemplating a deviation, the members of a coalition assign positive
probability over all possible coalition structures that the non-members can
form. We show that when the number of firms in the market is sufficiently large
then the core of the underlying cooperative game is non-empty. Moreover, we
show that the core of our game is a subset of the \gamma - core.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3198</identifier>
 <datestamp>2012-07-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3198</id><created>2011-07-16</created><updated>2012-02-09</updated><authors><author><keyname>Lekeas</keyname><forenames>Paraskevas V.</forenames></author><author><keyname>Stamatopoulos</keyname><forenames>Giorgos</forenames></author></authors><title>Strategic delegation in a sequential model with multiple stages</title><categories>cs.GT</categories><comments>To appear in International Game Theory Review (IGTR), Vol. 13, No. 3
  (2011) 1-12</comments><doi>10.1142/S0219198911003039</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze strategic delegation in a Stackelberg model with an arbitrary
number, n, of firms. We show that the n-1 last movers delegate their production
decisions to managers whereas the first mover does not. Equilibrium incentive
rates are increasing in the order with which managers select quantities.
Letting u_i^* denote the equilibrium payoff of the firm whose manager moves in
the i-th place, we show that u_n^*&gt;u_{n-1}^*&gt;...&gt;u_2^*&gt;u_1^*. We also compare
the delegation outcome of our game with that of a Cournot oligopoly and show
that the late (early) moving firms choose higher (lower) incentive rates than
the Cournot firms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3199</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3199</id><created>2011-07-16</created><authors><author><keyname>Li</keyname><forenames>Bo</forenames></author><author><keyname>Boyaci</keyname><forenames>Cem</forenames></author><author><keyname>Xia</keyname><forenames>Ye</forenames></author></authors><title>Performance Guarantee under Longest-Queue-First Schedule in Wireless
  Networks</title><categories>cs.IT math.IT</categories><comments>27 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient link scheduling in a wireless network is challenging. Typical
optimal algorithms require solving an NP-hard sub-problem. To meet the
challenge, one stream of research focuses on finding simpler sub-optimal
algorithms that have low complexity but high efficiency in practice. In this
paper, we study the performance guarantee of one such scheduling algorithm, the
Longest-Queue-First (LQF) algorithm. It is known that the LQF algorithm
achieves the full capacity region, $\Lambda$, when the interference graph
satisfies the so-called local pooling condition. For a general graph $G$, LQF
achieves (i.e., stabilizes) a part of the capacity region, $\sigma^*(G)
\Lambda$, where $\sigma^*(G)$ is the overall local pooling factor of the
interference graph $G$ and $\sigma^*(G) \leq 1$. It has been shown later that
LQF achieves a larger rate region, $\Sigma^*(G) \Lambda$, where $\Sigma^ (G)$
is a diagonal matrix. The contribution of this paper is to describe three new
achievable rate regions, which are larger than the previously-known regions. In
particular, the new regions include all the extreme points of the capacity
region and are not convex in general. We also discover a counter-intuitive
phenomenon in which increasing the arrival rate may sometime help to stabilize
the network. This phenomenon can be well explained using the theory developed
in the paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3201</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3201</id><created>2011-07-16</created><authors><author><keyname>Nair</keyname><forenames>T. R. Gopalakrishnan</forenames></author><author><keyname>V</keyname><forenames>Suma.</forenames></author></authors><title>Estimation of Characteristics of a Software Team for Implementing
  Effective Inspection Process through Inspection Performance Metric</title><categories>cs.SE</categories><comments>24 pages, 13 figures</comments><journal-ref>American Society for Quality (ASQ) Journal, Software Quality
  Professional, Volume 13, Issue 2, March 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The continued existence of any software industry depends on its capability to
develop nearly zero-defect product, which is achievable through effective
defect management. Inspection has proven to be one of the promising techniques
of defect management. Introductions of metrics like, Depth of Inspection (DI, a
process metric) and Inspection Performance Metric (IPM, a people metric) enable
one to have an appropriate measurement of inspection technique. This article
elucidates a mathematical approach to estimate the IPM value without depending
on shop floor defect count at every time. By applying multiple linear
regression models, a set of characteristic coefficients of the team is
evaluated. These coefficients are calculated from the empirical projects that
are sampled from the teams of product-based and service-based IT industries. A
sample of three verification projects indicates a close match between the IPM
values obtained from the defect count (IPMdc) and IPM values obtained using the
team coefficients using the mathematical model (IPMtc). The IPM values observed
onsite and IPM values produced by our model which are strongly matching,
support the predictive capability of IPM through team coefficients. Having
finalized the value of IPM that a company should achieve for a project, it can
tune the inspection influencing parameters to realize the desired quality level
of IPM. Evaluation of team coefficients resolves several defect-associated
issues, which are related to the management, stakeholders, outsourcing agents
and customers. In addition, the coefficient vector will further aid the
strategy of PSP and TSP
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3205</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3205</id><created>2011-07-16</created><authors><author><keyname>Li</keyname><forenames>Wei</forenames></author><author><keyname>Gao</keyname><forenames>Xiao-Shan</forenames></author></authors><title>Differential Chow Form for Projective Differential Variety</title><categories>math.AG cs.SC</categories><comments>17 pages</comments><msc-class>Primary 12H05, 14C05, Secondary 14C17, 14Q99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a generic intersection theorem in projective differential
algebraic geometry is presented. Precisely, the intersection of an irreducible
projective differential variety of dimension d&gt;0 and order h with a generic
projective differential hyperplane is shown to be an irreducible projective
differential variety of dimension d-1 and order h. Based on the generic
intersection theorem, the Chow form for an irreducible projective differential
variety is defined and most of the properties of the differential Chow form in
affine differential case are established for its projective differential
counterpart. Finally, we apply the differential Chow form to a result of linear
dependence over projective varieties given by Kolchin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3209</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3209</id><created>2011-07-16</created><authors><author><keyname>Alama</keyname><forenames>Jesse</forenames></author><author><keyname>Brink</keyname><forenames>Kasper</forenames></author><author><keyname>Mamane</keyname><forenames>Lionel</forenames></author><author><keyname>Urban</keyname><forenames>Josef</forenames></author></authors><title>Large Formal Wikis: Issues and Solutions</title><categories>cs.DL</categories><comments>To appear in The Conference of Intelligent Computer Mathematics: CICM
  2011</comments><journal-ref>Intelligent Computer Mathematics 2011, LNCS 6824, pp. 149-165</journal-ref><doi>10.1007/978-3-642-22673-1_11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present several steps towards large formal mathematical wikis. The Coq
proof assistant together with the CoRN repository are added to the pool of
systems handled by the general wiki system described in
\cite{DBLP:conf/aisc/UrbanARG10}. A smart re-verification scheme for the large
formal libraries in the wiki is suggested for Mizar/MML and Coq/CoRN, based on
recently developed precise tracking of mathematical dependencies. We propose to
use features of state-of-the-art filesystems to allow real-time cloning and
sandboxing of the entire libraries, allowing also to extend the wiki to a true
multi-user collaborative area. A number of related issues are discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3212</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3212</id><created>2011-07-16</created><authors><author><keyname>Alama</keyname><forenames>Jesse</forenames></author><author><keyname>Kohlhase</keyname><forenames>Michael</forenames></author><author><keyname>Naumowicz</keyname><forenames>Adam</forenames></author><author><keyname>Rudnicki</keyname><forenames>Piotr</forenames></author><author><keyname>Urban</keyname><forenames>Josef</forenames></author><author><keyname>Mamane</keyname><forenames>Lionel</forenames></author></authors><title>Licensing the Mizar Mathematical Library</title><categories>cs.DL cs.MS</categories><comments>To appear in The Conference of Intelligent Computer Mathematics: CICM
  2011</comments><journal-ref>Intelligent Computer Mathematics 2011, LNCS 6824, pp. 133-148</journal-ref><doi>10.1007/978-3-642-22673-1_10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Mizar Mathematical Library (MML) is a large corpus of formalised
mathematical knowledge. It has been constructed over the course of many years
by a large number of authors and maintainers. Yet the legal status of these
efforts of the Mizar community has never been clarified. In 2010, after many
years of loose deliberations, the community decided to investigate the issue of
licensing the content of the MML, thereby clarifying and crystallizing the
status of the texts, the text's authors, and the library's long-term
maintainers. The community has settled on a copyright and license policy that
suits the peculiar features of Mizar and its community. In this paper we
discuss the copyright and license solutions. We offer our experience in the
hopes that the communities of other libraries of formalised mathematical
knowledge might take up the legal and scientific problems that we addressed for
Mizar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3217</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3217</id><created>2011-07-16</created><authors><author><keyname>Lamba</keyname><forenames>Harjit Singh</forenames></author><author><keyname>Singh</keyname><forenames>Gurdev</forenames></author></authors><title>Cloud Computing Future Framework for e-management of NGO's</title><categories>cs.OH</categories><comments>Eight pages,Three figures</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Cloud computing is an emerging new computing paradigm for delivering
computing services. This computing approach relies on a number of existing
technologies, e.g., the Internet, virtualization, grid computing, Web services,
etc. Cloud Computing aims to provide scalable and inexpensive on-demand
computing infrastructures with good quality of service levels. It represents a
shift away from computing as a product that is purchased, to computing as a
service that is delivered to consumers from the cloud. It helps an organization
in saving costs and creating new business opportunities.This paper provides a
framework, Education Cloud for the e- management of NGO's. The Education Cloud
can transform a nonprofit, or an entire sector of nonprofits, achieves its
mission and creates lasting impact in its communities. This paper also presents
the case study of Kalgidhar trust, Baru Sahib, Himachal Pradesh, NGO which is
using the education as the tool to solve the social issues.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3225</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3225</id><created>2011-07-16</created><authors><author><keyname>de Santa-Eulalia</keyname><forenames>Luis Antonio</forenames></author><author><keyname>D'Amours</keyname><forenames>Sophie</forenames></author><author><keyname>Frayret</keyname><forenames>Jean-Marc</forenames></author></authors><title>An Agent-based Strategy for Deploying Analysis Models into Specification
  and Design for Distributed APS Systems</title><categories>cs.MA</categories><comments>In: International Journal of Computer Science Issues, Volume 8, Issue
  3, May 2011, p.7-18, ISSN 1694-0814</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Despite the extensive use of the agent technology in the Supply Chain
Management field, its integration with Advanced Planning and Scheduling (APS)
tools still represents a promising field with several open research questions.
Specifically, the literature falls short in providing an integrated framework
to analyze, specify, design and implement simulation experiments covering the
whole simulation cycle. Thus, this paper proposes an agent-based strategy to
convert the 'analysis' models into 'specification' and 'design' models
combining two existing methodologies proposed in the literature. The first one
is a recent and unique approach dedicated to the 'analysis' of agent-based APS
systems. The second one is a well-established methodological framework to
'specify' and 'design' agent-based supply chain systems. The proposed
conversion strategy is original and is the first one allowing simulation
analysts to integrate the whole simulation development process in the domain of
distributed APS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3226</identifier>
 <datestamp>2011-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3226</id><created>2011-07-16</created><updated>2011-12-05</updated><authors><author><keyname>Zheng</keyname><forenames>Huimin</forenames></author><author><keyname>Hu</keyname><forenames>HaiXing</forenames></author><author><keyname>Wu</keyname><forenames>Nan</forenames></author><author><keyname>Song</keyname><forenames>Fangmin</forenames></author></authors><title>On Measurement and Computation</title><categories>physics.comp-ph cs.CC</categories><comments>40 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Inspired by the work of Feynman, Deutsch, We formally propose the theory of
physical computability and accordingly, the physical complexity theory. To
achieve this, a framework that can evaluate almost all forms of computation
using various physical mechanisms is discussed. Here, we focus on using it to
review the theory of Quantum Computation. As a preliminary study on more
general problems, some examples of other physical mechanism are also given in
this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3229</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3229</id><created>2011-07-16</created><authors><author><keyname>Pr&#xe9;vost</keyname><forenames>David</forenames><affiliation>LURPA</affiliation></author><author><keyname>Lavernhe</keyname><forenames>Sylvain</forenames><affiliation>LURPA</affiliation></author><author><keyname>Lartigue</keyname><forenames>Claire</forenames><affiliation>LURPA</affiliation></author><author><keyname>Dumur</keyname><forenames>Didier</forenames></author></authors><title>Feed drive modelling for the simulation of tool path tracking in
  multi-axis High Speed Machining</title><categories>cs.OH</categories><proxy>ccsd</proxy><journal-ref>International Journal of Mechatronics and Manufacturing Systems 4,
  3-4 (2011) 266-284</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Within the context of High Speed Machining, it is essential to manage the
trajectory generation to achieve both high surface quality and high
productivity. As feed drives are one part of the set Machine tool - Numerical
Controller, it is necessary to improve their performances to optimize feed
drive dynamics during trajectory follow up. Hence, this paper deals with the
modelling of the feed drive in the case of multi axis machining. This model can
be used for the simulation of axis dynamics and tool-path tracking to tune
parameters and optimize new frameworks of command strategies. A procedure of
identification based on modern NC capabilities is presented and applied to
industrial HSM centres. Efficiency of this modelling is assessed by
experimental verifications on various representative trajectories. After
implementing a Generalized Predictive Control, reliable simulations are
performed thanks to the model. These simulations can then be used to tune
parameters of this new framework according to the tool-path geometry.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3231</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3231</id><created>2011-07-16</created><authors><author><keyname>Friggeri</keyname><forenames>Adrien</forenames><affiliation>ENS / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme / INRIA Grenoble Rh&#xf4;ne-Alpes, IXXI</affiliation></author><author><keyname>Chelius</keyname><forenames>Guillaume</forenames><affiliation>ENS / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme / INRIA Grenoble Rh&#xf4;ne-Alpes, IXXI</affiliation></author><author><keyname>Fleury</keyname><forenames>Eric</forenames><affiliation>ENS / LIP Laboratoire de l'Informatique du Parall&#xe9;lisme / INRIA Grenoble Rh&#xf4;ne-Alpes, IXXI</affiliation></author></authors><title>Triangles to Capture Social Cohesion</title><categories>cs.SI physics.soc-ph</categories><proxy>ccsd</proxy><report-no>RR-7686</report-no><journal-ref>N&amp;deg; RR-7686 (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although community detection has drawn tremendous amount of attention across
the sciences in the past decades, no formal consensus has been reached on the
very nature of what qualifies a community as such. In this article we take an
orthogonal approach by introducing a novel point of view to the problem of
overlapping communities. Instead of quantifying the quality of a set of
communities, we choose to focus on the intrinsic community-ness of one given
set of nodes. To do so, we propose a general metric on graphs, the cohesion,
based on counting triangles and inspired by well established sociological
considerations. The model has been validated through a large-scale online
experiment called Fellows in which users were able to compute their social
groups on Face- book and rate the quality of the obtained groups. By observing
those ratings in relation to the cohesion we assess that the cohesion is a
strong indicator of users subjective perception of the community-ness of a set
of people.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3245</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3245</id><created>2011-07-16</created><updated>2011-07-19</updated><authors><author><keyname>Frackiewicz</keyname><forenames>Piotr</forenames></author></authors><title>Quantum information approach to normal representation of extensive games</title><categories>cs.GT</categories><msc-class>81P68, 91A18, 91A80</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We modify the concept of quantum strategic game to make it useful for
extensive form games. We prove that our modification allows to consider the
normal representation of any finite extensive game using the fundamental
concepts of quantum information. The Selten's Horse game and the general form
of two-stage extensive game with perfect information are studied to illustrate
a potential application of our idea. In both examples we use
Eisert-Wilkens-Lewenstein approach as well as Marinatto-Weber approach to
quantization of games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3246</identifier>
 <datestamp>2011-10-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3246</id><created>2011-07-16</created><updated>2011-10-01</updated><authors><author><keyname>Cannarsa</keyname><forenames>Piermarco</forenames></author><author><keyname>Tort</keyname><forenames>Jacques</forenames></author><author><keyname>Yamamoto</keyname><forenames>Masahiro</forenames></author></authors><title>Unique continuation and approximate controllability for a degenerate
  parabolic equation</title><categories>math.AP cs.SY math.OC</categories><comments>for the special issue of Applicable Analysis on PDE and Inverse
  Problems (Guest Editors: R. Triggiani, A. Favini and A. Lorenzi)</comments><msc-class>35K65, 93B05, 35A23, 93C20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies unique continuation for weakly degenerate parabolic
equations in one space dimension. A new Carleman estimate of local type is
obtained to deduce that all solutions that vanish on the degeneracy set,
together with their conormal derivative, are identically equal to zero. An
approximate controllability result for weakly degenerate parabolic equations
under Dirichlet boundary condition is deduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3253</identifier>
 <datestamp>2011-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3253</id><created>2011-07-16</created><updated>2011-10-10</updated><authors><author><keyname>Nguyen</keyname><forenames>Phong S.</forenames></author><author><keyname>Yedla</keyname><forenames>Arvind</forenames></author><author><keyname>Pfister</keyname><forenames>Henry D.</forenames></author><author><keyname>Narayanan</keyname><forenames>Krishna R.</forenames></author></authors><title>Spatially-Coupled Codes and Threshold Saturation on
  Intersymbol-Interference Channels</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been observed that terminated low-density-parity-check
(LDPC) convolutional codes (or spatially-coupled codes) appear to approach
capacity universally across the class of binary memoryless channels. This is
facilitated by the &quot;threshold saturation&quot; effect whereby the belief-propagation
(BP) threshold of the spatially-coupled ensemble is boosted to the maximum
a-posteriori (MAP) threshold of the underlying constituent ensemble.
  In this paper, we consider the universality of spatially-coupled codes over
intersymbol-interference (ISI) channels under joint iterative decoding. More
specifically, we empirically show that threshold saturation also occurs for the
considered problem. This can be observed by first identifying the EXIT curve
for erasure noise and the GEXIT curve for general noise that naturally obey the
general area theorem. From these curves, the corresponding MAP and the BP
thresholds are then numerically obtained. With the fact that regular LDPC codes
can achieve the symmetric information rate (SIR) under MAP decoding,
spatially-coupled codes with joint iterative decoding can universally approach
the SIR of ISI channels. For the dicode erasure channel, Kudekar and Kasai
recently reported very similar results based on EXIT-like curves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3258</identifier>
 <datestamp>2012-02-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3258</id><created>2011-07-16</created><authors><author><keyname>Jalali</keyname><forenames>Ali</forenames></author><author><keyname>Johnson</keyname><forenames>Chris</forenames></author><author><keyname>Ravikumar</keyname><forenames>Pradeep</forenames></author></authors><title>On Learning Discrete Graphical Models Using Greedy Methods</title><categories>cs.LG math.ST stat.ML stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of learning the structure of a pairwise
graphical model from samples in a high-dimensional setting. Our first main
result studies the sparsistency, or consistency in sparsity pattern recovery,
properties of a forward-backward greedy algorithm as applied to general
statistical models. As a special case, we then apply this algorithm to learn
the structure of a discrete graphical model via neighborhood estimation. As a
corollary of our general result, we derive sufficient conditions on the number
of samples n, the maximum node-degree d and the problem size p, as well as
other conditions on the model parameters, so that the algorithm recovers all
the edges with high probability. Our result guarantees graph selection for
samples scaling as n = Omega(d^2 log(p)), in contrast to existing
convex-optimization based algorithms that require a sample complexity of
\Omega(d^3 log(p)). Further, the greedy algorithm only requires a restricted
strong convexity condition which is typically milder than irrepresentability
assumptions. We corroborate these results using numerical simulations at the
end.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3263</identifier>
 <datestamp>2012-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3263</id><created>2011-07-16</created><updated>2012-03-25</updated><authors><author><keyname>Lipowska</keyname><forenames>Dorota</forenames></author><author><keyname>Lipowski</keyname><forenames>Adam</forenames></author></authors><title>Naming Game on Adaptive Weighted Networks</title><categories>cond-mat.stat-mech cs.CL physics.soc-ph</categories><comments>22 pages, accepted in Artificial Life</comments><journal-ref>Artificial Life vol. 18, 311-323 (2012)</journal-ref><doi>10.1162/artl_a_00067</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine a naming game on an adaptive weighted network. A weight of
connection for a given pair of agents depends on their communication success
rate and determines the probability with which the agents communicate. In some
cases, depending on the parameters of the model, the preference toward
successfully communicating agents is basically negligible and the model behaves
similarly to the naming game on a complete graph. In particular, it quickly
reaches a single-language state, albeit some details of the dynamics are
different from the complete-graph version. In some other cases, the preference
toward successfully communicating agents becomes much more relevant and the
model gets trapped in a multi-language regime. In this case gradual coarsening
and extinction of languages lead to the emergence of a dominant language,
albeit with some other languages still being present. A comparison of
distribution of languages in our model and in the human population is
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3268</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3268</id><created>2011-07-16</created><updated>2012-04-01</updated><authors><author><keyname>Li</keyname><forenames>Yuan</forenames></author><author><keyname>Kan</keyname><forenames>Haibin</forenames></author></authors><title>Complex Orthogonal Designs with Forbidden $2 \times 2$ Submatrices</title><categories>cs.IT cs.DM math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Complex orthogonal designs (CODs) are used to construct space-time block
codes. COD $\mathcal{O}_z$ with parameter $[p, n, k]$ is a $p \times n$ matrix,
where nonzero entries are filled by $\pm z_i$ or $\pm z^*_i$, $i = 1, 2,...,
k$, such that $\mathcal{O}^H_z \mathcal{O}_z =
(|z_1|^2+|z_2|^2+...+|z_k|^2)I_{n \times n}$. Define $\mathcal{O}_z$ a first
type COD if and only if $\mathcal{O}_z$ does not contain submatrix {\pm z_j &amp;
0; \ 0 &amp; \pm z^*_j}$ or ${\pm z^*_j &amp; 0; \ 0 &amp; \pm z_j}$. It is already known
that, all CODs with maximal rate, i.e., maximal $k/p$, are of the first type.
  In this paper, we determine all achievable parameters $[p, n, k]$ of first
type COD, as well as all their possible structures. The existence of parameters
is proved by explicit-form constructions. New CODs with parameters
$[p,n,k]=[\binom{n}{w-1}+\binom{n}{w+1}, n, \binom{n}{w}], $ for $0 \le w \le
n$, are constructed, which demonstrate the possibility of sacrificing code rate
to reduce decoding delay. It's worth mentioning that all maximal rate, minimal
delay CODs are contained in our constructions, and their uniqueness under
equivalence operation is proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3271</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3271</id><created>2011-07-16</created><authors><author><keyname>Dhillon</keyname><forenames>Vikram</forenames></author></authors><title>On the Simulation of Adaptive Measurements via Postselection</title><categories>cs.CC quant-ph</categories><comments>3 pgs</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this note we address the question of whether any any quantum computational
model that allows adaptive measurements can be simulated by a model that allows
postselected measurements. We argue in the favor of this question and prove
that adaptive measurements can be simulated by postselection. We also discuss
some potentially stunning consequences of this result such as the ability to
solve #P problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3275</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3275</id><created>2011-07-17</created><authors><author><keyname>Sobkowicz</keyname><forenames>Pawel</forenames></author><author><keyname>Sobkowicz</keyname><forenames>Antoni</forenames></author></authors><title>Hate networks revisited: time and user interface dependence study of
  user emotions in political forum</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents analysis of time evolution within am Internet political
forum, characterized by large political differences and high levels of
emotions. The study compares samples of discussions gathered at three periods
separated by important events. We focus on statistical aspects related to
emotional content of communication and changes brought by technologies that
increase or decrease the direct one-to-one discussions. We discuss implications
of user interface aspects on promoting communication across a political divide.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3279</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3279</id><created>2011-07-17</created><updated>2013-11-19</updated><authors><author><keyname>Gilbert</keyname><forenames>Jesse</forenames></author></authors><title>Probabilistic Methods on Erdos Problems</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The study of perfect numbers dates back to Euler and Mersenne. A perfect
number is a number that is equal to the sum of its proper divisors which are
said to include the multiplicative unit 1. The following theorem is a classical
number theory result. All even numbers are of the form $2^k(2^k-1)$ where
$2^k-1$ is a Mersenne prime, that is, a prime where $k=P$ and the number $P$ is
prime. One interesting conjecture is that there are no odd perfect numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3294</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3294</id><created>2011-07-17</created><authors><author><keyname>Prabhakar</keyname><forenames>T. V</forenames></author><author><keyname>Nambi</keyname><forenames>S. N Akshay Uttama</forenames></author><author><keyname>Jamadagni</keyname><forenames>H. S</forenames></author></authors><title>E-DTN : A Multi-Interface Energy DTN Gateway</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To overcome the problem of unavailability of grid power in rural India, we
explore the possibility of powering WSN gateways using a bicycle dynamo. The
&quot;Data mule&quot; bicycle generates its own power to ensure a self sustainable data
transfer for information dissemination to small and marginal farmers. Our
multi-interface WSN gateway is equipped with Bluetooth, Wi-Fi and GPRS
technologies. To achieve our goal, we exploit the DTN stack in the energy sense
and introduce necessary modifications to its configuration.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3297</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3297</id><created>2011-07-17</created><authors><author><keyname>Amdouni</keyname><forenames>Soumaya</forenames></author><author><keyname>Karaa</keyname><forenames>Wahiba Ben Abdessalem</forenames></author><author><keyname>Bouabid</keyname><forenames>Sondes</forenames></author></authors><title>Semantic annotation of requirements for automatic UML class diagram
  generation</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The increasing complexity of software engineering requires effective methods
and tools to support requirements analysts' activities. While much of a
company's knowledge can be found in text repositories, current content
management systems have limited capabilities for structuring and interpreting
documents. In this context, we propose a tool for transforming text documents
describing users' requirements to an UML model. The presented tool uses Natural
Language Processing (NLP) and semantic rules to generate an UML class diagram.
The main contribution of our tool is to provide assistance to designers
facilitating the transition from a textual description of user requirements to
their UML diagrams based on GATE (General Architecture of Text) by formulating
necessary rules that generate new semantic annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3298</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3298</id><created>2011-07-17</created><authors><author><keyname>De Loor</keyname><forenames>Pierre</forenames><affiliation>LISYC, CERV</affiliation></author><author><keyname>Pierre-Alexandre</keyname><forenames>Favier</forenames><affiliation>LISYC</affiliation></author></authors><title>From decision to action : intentionality, a guide for the specification
  of intelligent agents' behaviour</title><categories>cs.AI cs.MA</categories><proxy>ccsd</proxy><journal-ref>International Journal of Image and Graphics 6, 1 (2006) 87-99</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article introduces a reflexion about behavioural specification for
interactive and participative agent-based simulation in virtual reality. Within
this context, it is neces sary to reach a high level of expressivness in order
to enforce interactions between the designer and the behavioural model during
the in-line prototyping. This requires to consider the need of semantic very
early in the design process. The Intentional agent model is here exposed as a
possible answer. It relies on a mixed imperative and declarative approach which
focuses on the link between decision and action. The design of a tool able to
simulate virtual environment implying agents based on this model is discuss
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3302</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3302</id><created>2011-07-17</created><authors><author><keyname>Mahdaoui</keyname><forenames>Rafik</forenames></author><author><keyname>Mouss</keyname><forenames>Leila Hayet</forenames></author><author><keyname>Mouss</keyname><forenames>Mohamed Djamel</forenames></author><author><keyname>Chouhal</keyname><forenames>Ouahiba</forenames></author></authors><title>A Temporal Neuro-Fuzzy Monitoring System to Manufacturing Systems</title><categories>cs.AI</categories><comments>10 pages, 11 figures, IJCSI International Journal of Computer Science
  Issues, Vol. 8, Issue 3, No. 1, May 2011 ISSN (Online): 1694-0814
  www.IJCSI.org</comments><report-no>IJCSI-8-3-1-237-246.pdf</report-no><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 3, No. 1, May 2011 ISSN (Online): 1694-0814 www.IJCSI.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fault diagnosis and failure prognosis are essential techniques in improving
the safety of many manufacturing systems. Therefore, on-line fault detection
and isolation is one of the most important tasks in safety-critical and
intelligent control systems. Computational intelligence techniques are being
investigated as extension of the traditional fault diagnosis methods. This
paper discusses the Temporal Neuro-Fuzzy Systems (TNFS) fault diagnosis within
an application study of a manufacturing system. The key issues of finding a
suitable structure for detecting and isolating ten realistic actuator faults
are described. Within this framework, data-processing interactive software of
simulation baptized NEFDIAG (NEuro Fuzzy DIAGnosis) version 1.0 is developed.
  This software devoted primarily to creation, training and test of a
classification Neuro-Fuzzy system of industrial process failures. NEFDIAG can
be represented like a special type of fuzzy perceptron, with three layers used
to classify patterns and failures. The system selected is the workshop of
SCIMAT clinker, cement factory in Algeria.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3313</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3313</id><created>2011-07-17</created><authors><author><keyname>Yu</keyname><forenames>F. Richard</forenames></author><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Xiao</keyname><forenames>Weidong</forenames></author><author><keyname>Choudhury</keyname><forenames>Paul</forenames></author></authors><title>Communication Systems for Grid Integration of Renewable Energy Resources</title><categories>cs.IT math.IT</categories><comments>to appear in IEEE Network, Sept. 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is growing interest in renewable energy around the world. Since most
renewable sources are intermittent in nature, it is a challenging task to
integrate renewable energy resources into the power grid infrastructure. In
this grid integration, communication systems are crucial technologies, which
enable the accommodation of distributed renewable energy generation and play
extremely important role in monitoring, operating, and protecting both
renewable energy generators and power systems. In this paper, we review some
communication technologies available for grid integration of renewable energy
resources. Then, we present the communication systems used in a real renewable
energy project, Bear Mountain Wind Farm (BMW) in British Columbia, Canada. In
addition, we present the communication systems used in Photovoltaic Power
Systems (PPS). Finally, we outline some research challenges and possible
solutions about the communication systems for grid integration of renewable
energy resources.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3326</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3326</id><created>2011-07-17</created><authors><author><keyname>De Loor</keyname><forenames>Pierre</forenames><affiliation>LISYC, CERV</affiliation></author><author><keyname>B&#xe9;nard</keyname><forenames>Romain</forenames><affiliation>LISYC</affiliation></author><author><keyname>Pierre</keyname><forenames>Chevaillier</forenames><affiliation>LISYC, CERV</affiliation></author></authors><title>Real-time retrieval for case-based reasoning in interactive
  multiagent-based simulations</title><categories>cs.AI cs.IR cs.MA</categories><proxy>ccsd</proxy><journal-ref>Expert Systems with Applications 38, 5 (2011) 5145-5153</journal-ref><doi>10.1016/j.eswa.2010.10.048</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to present the principles and results about
case-based reasoning adapted to real- time interactive simulations, more
precisely concerning retrieval mechanisms. The article begins by introducing
the constraints involved in interactive multiagent-based simulations. The
second section pre- sents a framework stemming from case-based reasoning by
autonomous agents. Each agent uses a case base of local situations and, from
this base, it can choose an action in order to interact with other auton- omous
agents or users' avatars. We illustrate this framework with an example
dedicated to the study of dynamic situations in football. We then go on to
address the difficulties of conducting such simulations in real-time and
propose a model for case and for case base. Using generic agents and adequate
case base structure associated with a dedicated recall algorithm, we improve
retrieval performance under time pressure compared to classic CBR techniques.
We present some results relating to the performance of this solution. The
article concludes by outlining future development of our project.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3342</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3342</id><created>2011-07-17</created><updated>2011-07-20</updated><authors><author><keyname>Ganzfried</keyname><forenames>Sam</forenames></author></authors><title>Oracular Form and Computing Strong Game-Theoretic Jotto Strategies</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop a new approach that computes approximate equilibrium strategies in
Jotto, a popular word game. Jotto is an extremely large two-player game of
imperfect information; its game tree has many orders of magnitude more states
than games previously studied, including no-limit Texas Hold'em poker. To
address the fact that the game is so large, we propose a novel strategy
representation called oracular form, in which we do not explicitly represent a
strategy, but rather appeal to an oracle that quickly outputs a sample move
from the strategy's distribution. Our overall approach is based on an extension
of the fictitious play algorithm to this oracular setting. We make several
interesting observations from the computed strategies and demonstrate the
superiority of our algorithm over a benchmark algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3348</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3348</id><created>2011-07-17</created><updated>2011-07-19</updated><authors><author><keyname>Al-Wassai</keyname><forenames>Firouz Abdullah</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author><author><keyname>Al-Zuky</keyname><forenames>Ali A.</forenames></author></authors><title>Arithmetic and Frequency Filtering Methods of Pixel-Based Image Fusion
  Techniques</title><categories>cs.CV</categories><comments>Image Fusion, Pixel-Based Fusion, Brovey Transform, Color Normalized,
  High-Pass Filter, Modulation, Wavelet transform</comments><journal-ref>Journal-ref: International Journal of Advanced Research in
  Computer Science,Volume 2, No. 5, Sept-Oct 2011,www.ijarcs.info</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In remote sensing, image fusion technique is a useful tool used to fuse high
spatial resolution panchromatic images (PAN) with lower spatial resolution
multispectral images (MS) to create a high spatial resolution multispectral of
image fusion (F) while preserving the spectral information in the multispectral
image (MS).There are many PAN sharpening techniques or Pixel-Based image fusion
techniques that have been developed to try to enhance the spatial resolution
and the spectral property preservation of the MS. This paper attempts to
undertake the study of image fusion, by using two types of pixel-based image
fusion techniques i.e. Arithmetic Combination and Frequency Filtering Methods
of Pixel-Based Image Fusion Techniques. The first type includes Brovey
Transform (BT), Color Normalized Transformation (CN) and Multiplicative Method
(MLT). The second type include High-Pass Filter Additive Method (HPFA),
High-Frequency-Addition Method (HFA) High Frequency Modulation Method (HFM) and
The Wavelet transform-based fusion method (WT). This paper also devotes to
concentrate on the analytical techniques for evaluating the quality of image
fusion (F) by using various methods including Standard Deviation (SD),
Entropy(En), Correlation Coefficient (CC), Signal-to Noise Ratio (SNR),
Normalization Root Mean Square Error (NRMSE) and Deviation Index (DI) to
estimate the quality and degree of information improvement of a fused image
quantitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3350</identifier>
 <datestamp>2011-11-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3350</id><created>2011-07-17</created><authors><author><keyname>Li</keyname><forenames>Yang D.</forenames></author><author><keyname>Zhang</keyname><forenames>Zhenjie</forenames></author><author><keyname>Winslett</keyname><forenames>Marianne</forenames></author><author><keyname>Yang</keyname><forenames>Yin</forenames></author></authors><title>Compressive Mechanism: Utilizing Sparse Representation in Differential
  Privacy</title><categories>cs.DS cs.CR cs.DB</categories><comments>20 pages, 6 figures</comments><journal-ref>WPES '11 Proceedings of the 10th annual ACM workshop on Privacy in
  the electronic society ACM New York, NY, USA (2011), pages 177-182</journal-ref><doi>10.1145/2046556.2046581</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Differential privacy provides the first theoretical foundation with provable
privacy guarantee against adversaries with arbitrary prior knowledge. The main
idea to achieve differential privacy is to inject random noise into statistical
query results. Besides correctness, the most important goal in the design of a
differentially private mechanism is to reduce the effect of random noise,
ensuring that the noisy results can still be useful.
  This paper proposes the \emph{compressive mechanism}, a novel solution on the
basis of state-of-the-art compression technique, called \emph{compressive
sensing}. Compressive sensing is a decent theoretical tool for compact synopsis
construction, using random projections. In this paper, we show that the amount
of noise is significantly reduced from $O(\sqrt{n})$ to $O(\log(n))$, when the
noise insertion procedure is carried on the synopsis samples instead of the
original database. As an extension, we also apply the proposed compressive
mechanism to solve the problem of continual release of statistical results.
Extensive experiments using real datasets justify our accuracy claims.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3360</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3360</id><created>2011-07-18</created><authors><author><keyname>Suri</keyname><forenames>Dr. Pushpa R.</forenames></author><author><keyname>Taneja</keyname><forenames>Harmunish</forenames></author></authors><title>Object Oriented Information Computing over WWW</title><categories>cs.IR</categories><comments>4 pages, 1 table, IJCSI International Journal of Computer Science
  Issues, Vol. 7, Issue 3, No 7, May 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditional search engines on World Wide Web (WWW) focus essentially on
relevance ranking at the page level. But this lead to missing innumerable
structured information about real-world objects embedded in static Web pages
and online Web databases. Page-level information retrieval (IR) can
unfortunately lead to highly inaccurate relevance ranking in answering
object-oriented queries. On the other hand, Object Oriented Information
Computing (OOIC) is promising and greatly reduces the complexity of the system
while improving reusability and manageability. The most distinguishing
requirement of today's complex heterogeneous systems is the need of the
computing system to instantly adapt to vigorously changing conditions. OOIC
allows reflecting the dynamic characteristics of the applications by
instantiating objects dynamically. In this paper, major challenges of OOIC as
well as its rudiments are recapped. The review includes the insight to PopRank
Model and comparison analysis of conventional page rank based IR with OOIC
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3363</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3363</id><created>2011-07-18</created><authors><author><keyname>Nath</keyname><forenames>Rajender</forenames></author><author><keyname>Sehgal</keyname><forenames>Pankaj Kumar</forenames></author></authors><title>SD-AODV: A Protocol for Secure and Dynamic Data Dissemination in Mobile
  Ad Hoc Network</title><categories>cs.NI</categories><comments>8 pages, 11 figures, 1 table, IJCSI International Journal of Computer
  Science Issues, Vol. 7, Issue 6, November 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Security remains as a major concern in the mobile ad hoc networks. This paper
presents a new protocol SD-AODV, which is an extension of the exiting protocol
AODV. The proposed protocol is made secure and dynamic against three main types
of routing attacks- wormhole attack, byzantine attack and blackhole attack.
SD-AODV protocol was evaluated through simulation experiments done on Glomosim
and performance of the network was measured in terms of packet delivery
fraction, average end-to-end delay, global throughput and route errors of a
mobile ad hoc network where a defined percentage of nodes behave maliciously.
Experimentally it was found that the performance of the network did not degrade
in the presence of the above said attacks indicating that the proposed protocol
was secure against these attacks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3372</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3372</id><created>2011-07-18</created><authors><author><keyname>Yehezkeally</keyname><forenames>Yonatan</forenames></author><author><keyname>Schwartz</keyname><forenames>Moshe</forenames></author></authors><title>Snake-in-the-Box Codes for Rank Modulation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the rank-modulation scheme with applications to flash memory, we
consider Gray codes capable of detecting a single error, also known as
snake-in-the-box codes. We study two error metrics: Kendall's $\tau$-metric,
which applies to charge-constrained errors, and the $\ell_\infty$-metric, which
is useful in the case of limited magnitude errors. In both cases we construct
snake-in-the-box codes with rate asymptotically tending to 1. We also provide
efficient successor-calculation functions, as well as ranking and unranking
functions. Finally, we also study bounds on the parameters of such codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3380</identifier>
 <datestamp>2014-03-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3380</id><created>2011-07-18</created><updated>2014-03-06</updated><authors><author><keyname>Meunier</keyname><forenames>Fr&#xe9;d&#xe9;ric</forenames></author><author><keyname>Deza</keyname><forenames>Antoine</forenames></author></authors><title>A further generalization of the colourful Carath\'eodory theorem</title><categories>cs.CG cs.DM math.CO</categories><comments>12 pages, 4 figures</comments><msc-class>52C45, 52A35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given $d+1$ sets, or colours, $S_1, S_2,...,S_{d+1}$ of points in
$\mathbb{R}^d$, a {\em colourful} set is a set $S\subseteq\bigcup_i S_i$ such
that $|S\cap S_i|\leq 1$ for $i=1,...,d+1$. The convex hull of a colourful set
$S$ is called a {\em colourful simplex}. B\'ar\'any's colourful Carath\'eodory
theorem asserts that if the origin 0 is contained in the convex hull of $S_i$
for $i=1,...,d+1$, then there exists a colourful simplex containing 0. The
sufficient condition for the existence of a colourful simplex containing 0 was
generalized to 0 being contained in the convex hull of $S_i\cup S_j$ for $1\leq
i&lt; j \leq d+1$ by Arocha et al. and by Holmsen et al. We further generalize the
sufficient condition and obtain new colourful Carath\'eodory theorems. We also
give an algorithm to find a colourful simplex containing 0 under the
generalized condition. In the plane an alternative, and more general, proof
using graphs is given. In addition, we observe that any condition implying the
existence of a colourful simplex containing 0 actually implies the existence of
$\min_i|S_i|$ such simplices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3383</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3383</id><created>2011-07-18</created><authors><author><keyname>nLukac</keyname><forenames>Maarti</forenames></author><author><keyname>Perkowski</keyname><forenames>Marek</forenames></author><author><keyname>Kameyama</keyname><forenames>Michitaka</forenames></author></authors><title>Evolutionary Quantum Logic Synthesis of Boolean Reversible Logic
  Circuits Embedded in Ternary Quantum Space using Heuristics</title><categories>quant-ph cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been experimentally proven that realizing universal quantum gates
using higher-radices logic is practically and technologically possible. We
developed a Parallel Genetic Algorithm that synthesizes Boolean reversible
circuits realized with a variety of quantum gates on qudits with various
radices. In order to allow synthesizing circuits of medium sizes in the higher
radix quantum space we performed the experiments using a GPU accelerated
Genetic Algorithm. Using the accelerated GA we compare heuristic improvements
to the mutation process based on cost minimization, on the adaptive cost of the
primitives and improvements due to Baldwinian vs. Lamarckian GA. We also
describe various fitness function formulations that allowed for various
realizations of well known universal Boolean reversible or
quantum-probabilistic circuits.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3385</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3385</id><created>2011-07-18</created><authors><author><keyname>Gast</keyname><forenames>Nicolas</forenames></author></authors><title>Computing hitting times via fluid approximation: application to the
  coupon collector problem</title><categories>math.PR cs.DM math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show how to use stochastic approximation to compute hitting
time of a stochastic process, based on the study of the time for a fluid
approximation of this process to be at distance 1/N of its fixed point.
  This approach is developed to study a generalized version of the coupon
collector problem. The system is composed by N independent identical Markov
chains. At each time step, one Markov chain is picked at random and performs
one transition. We show that the time at which all chains have hit the same
state is bounded by a N log N + b N log log N + O(N) where a and b are two
constants depending on eigenvalues of the Markov chain.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3396</identifier>
 <datestamp>2013-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3396</id><created>2011-07-18</created><authors><author><keyname>Romero</keyname><forenames>Ana</forenames></author><author><keyname>Rubio</keyname><forenames>Julio</forenames></author></authors><title>Computing the homology of groups: the geometric way</title><categories>math.AT cs.SC math.GR</categories><journal-ref>Journal of Symbolic Computation 47 (2012) 752-770</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present several algorithms related with the computation of
the homology of groups, from a geometric perspective (that is to say, carrying
out the calculations by means of simplicial sets and using techniques of
Algebraic Topology). More concretely, we have developed some algorithms which,
making use of the effective homology method, construct the homology groups of
Eilenberg-MacLane spaces K(G,1) for different groups G, allowing one in
particular to determine the homology groups of G.
  Our algorithms have been programmed as new modules for the Kenzo system,
enhancing it with the following new functionalities:
  - construction of the effective homology of K(G,1) from a given finite free
resolution of the group G;
  - construction of the effective homology of K(A,1) for every finitely
generated Abelian group A (as a consequence, the effective homology of K(A,n)
is also available in Kenzo, for all n);
  - computation of homology groups of some 2-types;
  - construction of the effective homology for central extensions.
  In addition, an inverse problem is also approached in this work: given a
group G such that K(G,1) has effective homology, can a finite free resolution
of the group G be obtained? We provide some algorithms to solve this problem,
based on a notion of norm of a group, allowing us to control the convergence of
the process when building such a resolution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3407</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3407</id><created>2011-07-18</created><authors><author><keyname>Boizumault</keyname><forenames>Patrice</forenames></author><author><keyname>Cr&#xe9;milleux</keyname><forenames>Bruno</forenames></author><author><keyname>Khiari</keyname><forenames>Mehdi</forenames></author><author><keyname>Loudni</keyname><forenames>Samir</forenames></author><author><keyname>M&#xe9;tivier</keyname><forenames>Jean-Philippe</forenames></author></authors><title>Discovering Knowledge using a Constraint-based Language</title><categories>cs.LG</categories><comments>12 pages</comments><report-no>DPA-11201</report-no><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Discovering pattern sets or global patterns is an attractive issue from the
pattern mining community in order to provide useful information. By combining
local patterns satisfying a joint meaning, this approach produces patterns of
higher level and thus more useful for the data analyst than the usual local
patterns, while reducing the number of patterns. In parallel, recent works
investigating relationships between data mining and constraint programming (CP)
show that the CP paradigm is a nice framework to model and mine such patterns
in a declarative and generic way. We present a constraint-based language which
enables us to define queries addressing patterns sets and global patterns. The
usefulness of such a declarative approach is highlighted by several examples
coming from the clustering based on associations. This language has been
implemented in the CP framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3421</identifier>
 <datestamp>2012-05-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3421</id><created>2011-07-18</created><updated>2012-05-02</updated><authors><author><keyname>Bukh</keyname><forenames>Boris</forenames></author><author><keyname>Nivasch</keyname><forenames>Gabriel</forenames></author></authors><title>Upper bounds for centerlines</title><categories>cs.CG math.CO</categories><comments>This paper (without the appendix) has been published in Journal of
  Computational Geometry 3:20--30, 2012. 17 pages; 10 figures</comments><msc-class>52C35, 52A30, 68U05</msc-class><journal-ref>Journal of Computational Geometry 3:20--30, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2008, Bukh, Matousek, and Nivasch conjectured that for every n-point set S
in R^d and every k, 0 &lt;= k &lt;= d-1, there exists a k-flat f in R^d (a
&quot;centerflat&quot;) that lies at &quot;depth&quot; (k+1) n / (k+d+1) - O(1) in S, in the sense
that every halfspace that contains f contains at least that many points of S.
This claim is true and tight for k=0 (this is Rado's centerpoint theorem), as
well as for k = d-1 (trivial). Bukh et al. showed the existence of a (d-2)-flat
at depth (d-1) n / (2d-1) - O(1) (the case k = d-2).
  In this paper we concentrate on the case k=1 (the case of &quot;centerlines&quot;), in
which the conjectured value for the leading constant is 2/(d+2). We prove that
2/(d+2) is an *upper bound* for the leading constant. Specifically, we show
that for every fixed d and every n there exists an n-point set in R^d for which
no line in R^d lies at depth larger than 2n/(d+2) + o(n). This point set is the
&quot;stretched grid&quot;---a set which has been previously used by Bukh et al. for
other related purposes.
  Hence, in particular, the conjecture is now settled for R^3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3430</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3430</id><created>2011-07-18</created><updated>2011-09-20</updated><authors><author><keyname>Eickmeyer</keyname><forenames>Kord</forenames><affiliation>Humboldt-Universit&#xe4;t Berlin</affiliation></author><author><keyname>Grohe</keyname><forenames>Martin</forenames><affiliation>Humboldt-Universit&#xe4;t Berlin</affiliation></author></authors><title>Randomisation and Derandomisation in Descriptive Complexity Theory</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.4.1, F.1.2</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 3 (September
  21, 2011) lmcs:714</journal-ref><doi>10.2168/LMCS-7(3:14)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study probabilistic complexity classes and questions of derandomisation
from a logical point of view. For each logic L we introduce a new logic BPL,
bounded error probabilistic L, which is defined from L in a similar way as the
complexity class BPP, bounded error probabilistic polynomial time, is defined
from PTIME. Our main focus lies on questions of derandomisation, and we prove
that there is a query which is definable in BPFO, the probabilistic version of
first-order logic, but not in Cinf, finite variable infinitary logic with
counting. This implies that many of the standard logics of finite model theory,
like transitive closure logic and fixed-point logic, both with and without
counting, cannot be derandomised. Similarly, we present a query on ordered
structures which is definable in BPFO but not in monadic second-order logic,
and a query on additive structures which is definable in BPFO but not in FO.
The latter of these queries shows that certain uniform variants of AC0
(bounded-depth polynomial sized circuits) cannot be derandomised. These results
are in contrast to the general belief that most standard complexity classes can
be derandomised. Finally, we note that BPIFP+C, the probabilistic version of
fixed-point logic with counting, captures the complexity class BPP, even on
unordered structures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3438</identifier>
 <datestamp>2012-06-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3438</id><created>2011-07-18</created><authors><author><keyname>Beelen</keyname><forenames>Peter</forenames></author><author><keyname>Ghorpade</keyname><forenames>Sudhir R.</forenames></author><author><keyname>Hoeholdt</keyname><forenames>Tom</forenames></author></authors><title>Duals of Affine Grassmann Codes and their Relatives</title><categories>cs.IT math.IT</categories><comments>20 pages</comments><msc-class>94B05, 94B27, 14M15</msc-class><journal-ref>IEEE Transactions on Information Theory, Vol. 58, No. 6 (2012),
  pp. 3843-3855</journal-ref><doi>10.1109/TIT.2012.2187171</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Affine Grassmann codes are a variant of generalized Reed-Muller codes and are
closely related to Grassmann codes. These codes were introduced in a recent
work [2]. Here we consider, more generally, affine Grassmann codes of a given
level. We explicitly determine the dual of an affine Grassmann code of any
level and compute its minimum distance. Further, we ameliorate the results of
[2] concerning the automorphism group of affine Grassmann codes. Finally, we
prove that affine Grassmann codes and their duals have the property that they
are linear codes generated by their minimum-weight codewords. This provides a
clean analogue of a corresponding result for generalized Reed-Muller codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3441</identifier>
 <datestamp>2014-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3441</id><created>2011-07-18</created><updated>2011-11-15</updated><authors><author><keyname>Laarhoven</keyname><forenames>Thijs</forenames></author><author><keyname>de Weger</keyname><forenames>Benne</forenames></author></authors><title>Optimal symmetric Tardos traitor tracing schemes</title><categories>cs.CR</categories><comments>16 pages, 1 figure</comments><msc-class>68P30, 94B60</msc-class><journal-ref>Designs, Codes and Cryptography, vol. 71, no. 1, pp. 83-103, 2014</journal-ref><doi>10.1007/s10623-012-9718-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the Tardos traitor tracing scheme, we show that by combining the
symbol-symmetric accusation function of Skoric et al. with the improved
analysis of Blayer and Tassa we get further improvements. Our construction
gives codes that are up to 4 times shorter than Blayer and Tassa's, and up to 2
times shorter than the codes from Skoric et al. Asymptotically, we achieve the
theoretical optimal codelength for Tardos' distribution function and the
symmetric score function. For large coalitions, our codelengths are
asymptotically about 4.93% of Tardos' original codelengths, which also improves
upon results from Nuida et al.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3474</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3474</id><created>2011-07-18</created><authors><author><keyname>Chen</keyname><forenames>Po-Ning</forenames></author><author><keyname>Alajaji</keyname><forenames>Fady</forenames></author></authors><title>A Generalized Poor-Verdu Error Bound for Multihypothesis Testing and the
  Channel Reliability Function</title><categories>cs.IT math.IT</categories><comments>Parts of this technical report will appear in the IEEE Transactions
  on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A lower bound on the minimum error probability for multihypothesis testing is
established. The bound, which is expressed in terms of the cumulative
distribution function of the tilted posterior hypothesis distribution given the
observation with tilting parameter theta larger than or equal to 1, generalizes
an earlier bound due the Poor and Verdu (1995). A sufficient condition is
established under which the new bound (minus a multiplicative factor) provides
the exact error probability in the limit of theta going to infinity. Examples
illustrating the new bound are also provided.
  The application of this generalized Poor-Verdu bound to the channel
reliability function is next carried out, resulting in two information-spectrum
upper bounds. It is observed that, for a class of channels including the
finite-input memoryless Gaussian channel, one of the bounds is tight and gives
a multi-letter asymptotic expression for the reliability function, albeit its
determination or calculation in single-letter form remains an open challenging
problem. Numerical examples regarding the other bound are finally presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3498</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3498</id><created>2011-07-18</created><authors><author><keyname>Khor</keyname><forenames>Susan</forenames></author></authors><title>What can we learn from slow self-avoiding adaptive walks by an infinite
  radius search algorithm?</title><categories>cs.NE cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Slow self-avoiding adaptive walks by an infinite radius search algorithm
(Limax) are analyzed as themselves, and as the network they form. The study is
conducted on several NK problems and two HIFF problems. We find that
examination of such &quot;slacker&quot; walks and networks can indicate relative search
difficulty within a family of problems, help identify potential local optima,
and detect presence of structure in fitness landscapes. Hierarchical walks are
used to differentiate rugged landscapes which are hierarchical (e.g. HIFF) from
those which are anarchic (e.g. NK). The notion of node viscidity as a measure
of local optimum potential is introduced and found quite successful although
more work needs to be done to improve its accuracy on problems with larger K.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3499</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3499</id><created>2011-07-18</created><authors><author><keyname>Corrie</keyname><forenames>Robert</forenames></author><author><keyname>Ninomiya</keyname><forenames>Yoshiki</forenames></author><author><keyname>Aitchison</keyname><forenames>Jonathan</forenames></author></authors><title>Applying Advanced Spaceborne Thermal Emission and Reflection Radiometer
  (ASTER) spectral indices for geological mapping and mineral identification on
  the Tibetan Plateau</title><categories>physics.geo-ph cs.CV</categories><comments>6 pages, 4 figures, 2 tables, Published in the International Archives
  of the Photogrammetry, Remote Sensing, and Spatial Information Science,
  Volume XXXVIII, pp. 464-469. For associated web page, see
  http://www.isprs.org/proceedings/XXXVIII/part8/headline/PS-1%20Interactive%20PresentationWG%20VIII5.html</comments><journal-ref>International Archives of the Photogrammetry, Remote Sensing, and
  Spatial Information Science, XXXVIII (2010) 464-469</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Tibetan Plateau holds clues to understanding the dynamics and mechanisms
associated with continental growth. Part of the region is characterized by
zones of ophiolitic melange believed to represent the remnants of ancient
oceanic crust and underlying upper mantle emplaced during oceanic closures.
However, due to the remoteness of the region and the inhospitable terrain many
areas have not received detailed investigation. Increased spatial and spectral
resolution of satellite sensors have made it possible to map in greater detail
the mineralogy and lithology than in the past. Recent work by Yoshiki Ninomiya
of the Geological Survey of Japan has pioneered the use of several spectral
indices for the mapping of quartzose, carbonate, and silicate rocks using
Advanced Spaceborne Thermal Emission and Reflection Radiometer (ASTER) thermal
infrared (TIR) data. In this study, ASTER TIR indices have been applied to a
region in western-central Tibet for the purposes of assessing their
effectiveness for differentiating ophiolites and other lithologies. The results
agree well with existing geological maps and other published data. The study
area was chosen due to its diverse range of rock types, including an ophiolitic
melange, associated with the Bangong-Nujiang suture (BNS) that crops out on the
northern shores of Lagkor Tso and Dong Tso (&quot;Tso&quot; is Tibetan for lake). The
techniques highlighted in this paper could be applied to other geographical
regions where similar geological questions need to be resolved. The results of
this study aim to show the utility of ASTER TIR imagery for geological mapping
in semi-arid and sparsely vegetated areas on the Tibetan Plateau.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3506</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3506</id><created>2011-07-18</created><updated>2013-06-10</updated><authors><author><keyname>Morris</keyname><forenames>Ian D.</forenames></author><author><keyname>Sidorov</keyname><forenames>Nikita</forenames></author></authors><title>On a Devil's staircase associated to the joint spectral radii of a
  family of pairs of matrices</title><categories>math.OC cs.DM math.DS math.OA</categories><comments>40 pages</comments><msc-class>Primary 15A18, 15A60, secondary 37B10, 65K10, 68R15</msc-class><journal-ref>J. Eur. Math. Soc. (JEMS) 15 (2013), 1747-1782</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The joint spectral radius of a finite set of real d x d matrices is defined
to be the maximum possible exponential rate of growth of products of matrices
drawn from that set. In previous work with K. G. Hare and J. Theys we showed
that for a certain one-parameter family of pairs of matrices, this maximum
possible rate of growth is attained along Sturmian sequences with a certain
characteristic ratio which depends continuously upon the parameter. In this
paper we answer some open questions from that paper by showing that the
dependence of the ratio function upon the parameter takes the form of a Devil's
staircase. We show in particular that this Devil's staircase attains every
rational value strictly between 0 and 1 on some interval, and attains
irrational values only in a set of Hausdorff dimension zero. This result
generalises to include certain one-parameter families considered by other
authors. We also give explicit formulas for the preimages of both rational and
irrational numbers under the ratio function, thereby establishing a large
family of pairs of matrices for which the joint spectral radius may be
calculated exactly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3522</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3522</id><created>2011-07-18</created><authors><author><keyname>Yu</keyname><forenames>Louis</forenames></author><author><keyname>Asur</keyname><forenames>Sitaram</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author></authors><title>What Trends in Chinese Social Media</title><categories>cs.CY cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been a tremendous rise in the growth of online social networks all
over the world in recent times. While some networks like Twitter and Facebook
have been well documented, the popular Chinese microblogging social network
Sina Weibo has not been studied. In this work, we examine the key topics that
trend on Sina Weibo and contrast them with our observations on Twitter. We find
that there is a vast difference in the content shared in China, when compared
to a global social network such as Twitter. In China, the trends are created
almost entirely due to retweets of media content such as jokes, images and
videos, whereas on Twitter, the trends tend to have more to do with current
global events and news stories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3534</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3534</id><created>2011-07-18</created><updated>2012-07-01</updated><authors><author><keyname>Liu</keyname><forenames>Yanpei</forenames></author><author><keyname>Draper</keyname><forenames>Stark C.</forenames></author><author><keyname>Sayeed</keyname><forenames>Akbar M.</forenames></author></authors><title>Exploiting Channel Diversity in Secret Key Generation from Multipath
  Fading Randomness</title><categories>cs.CR cs.IT math.IT</categories><doi>10.1109/TIFS.2012.2206385</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design and analyze a method to extract secret keys from the randomness
inherent to wireless channels. We study a channel model for multipath wireless
channel and exploit the channel diversity in generating secret key bits. We
compare the key extraction methods based both on entire channel state
information (CSI) and on single channel parameter such as the received signal
strength indicators (RSSI). Due to the reduction in the degree-of-freedom when
going from CSI to RSSI, the rate of key extraction based on CSI is far higher
than that based on RSSI. This suggests that exploiting channel diversity and
making CSI information available to higher layers would greatly benefit the
secret key generation. We propose a key generation system based on low-density
parity-check (LDPC) codes and describe the design and performance of two
systems: one based on binary LDPC codes and the other (useful at higher
signal-to-noise ratios) based on four-ary LDPC codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3539</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3539</id><created>2011-07-18</created><authors><author><keyname>Van Horn</keyname><forenames>David</forenames></author><author><keyname>Might</keyname><forenames>Matthew</forenames></author></authors><title>Systematic Abstraction of Abstract Machines</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a derivational approach to abstract interpretation that yields
novel and transparently sound static analyses when applied to well-established
abstract machines for higher-order and imperative programming languages. To
demonstrate the technique and support our claim, we transform the CEK machine
of Felleisen and Friedman, a lazy variant of Krivine's machine, and the
stack-inspecting CM machine of Clements and Felleisen into abstract
interpretations of themselves. The resulting analyses bound temporal ordering
of program events; predict return-flow and stack-inspection behavior; and
approximate the flow and evaluation of by-need parameters. For all of these
machines, we find that a series of well-known concrete machine refactorings,
plus a technique of store-allocated continuations, leads to machines that
abstract into static analyses simply by bounding their stores. We demonstrate
that the technique scales up uniformly to allow static analysis of realistic
language features, including tail calls, conditionals, side effects,
exceptions, first-class continuations, and even garbage collection. In order to
close the gap between formalism and implementation, we provide translations of
the mathematics as running Haskell code for the initial development of our
method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3541</identifier>
 <datestamp>2011-07-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3541</id><created>2011-07-18</created><authors><author><keyname>Andolfatto</keyname><forenames>Lo&#xef;c</forenames><affiliation>LURPA</affiliation></author><author><keyname>Lavernhe</keyname><forenames>Sylvain</forenames><affiliation>LURPA</affiliation></author><author><keyname>Mayer</keyname><forenames>Ren&#xe9;</forenames><affiliation>LRFV</affiliation></author></authors><title>Evaluation of servo, geometric and dynamic error sources on five axis
  high-speed machine tool</title><categories>cs.OH</categories><comments>13 pages; International Journal of Machine Tools and Manufacture
  (2011) pp XX-XX</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many sources of errors exist in the manufacturing process of complex shapes.
Some approximations occur at each step from the design geometry to the machined
part. The aim of the paper is to present a method to evaluate the effect of
high speed and high dynamic load on volumetric errors at the tool center point.
The interpolator output signals and the machine encoder signals are recorded
and compared to evaluate the contouring errors resulting from each axis
follow-up error. The machine encoder signals are also compared to the actual
tool center point position as recorded with a non-contact measuring instrument
called CapBall to evaluate the total geometric errors. The novelty of the work
lies in the method that is proposed to decompose the geometric errors in two
categories: the quasi-static geometric errors independent from the speed of the
trajectory and the dynamic geometric errors, dependent on the programmed feed
rate and resulting from the machine structure deflection during the
acceleration of its axes. The evolution of the respective contributions for
contouring errors, quasi-static geometric errors and dynamic geomet- ric errors
is experimentally evaluated and a relation between programmed feed rate and
dynamic errors is highlighted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3584</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3584</id><created>2011-07-18</created><authors><author><keyname>Manathara</keyname><forenames>Joel George</forenames></author><author><keyname>Dukkipati</keyname><forenames>Ambedkar</forenames></author><author><keyname>Ghose</keyname><forenames>Debasish</forenames></author></authors><title>On Consensus under Polynomial Protocols</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we explore the possibility of using computational algebraic
methods to analyze a class of consensus protocols. We state some necessary
conditions for convergence under consensus protocols that are polynomials.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3593</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3593</id><created>2011-07-18</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Baldi</keyname><forenames>Pierre</forenames></author></authors><title>Privacy-Enhanced Methods for Comparing Compressed DNA Sequences</title><categories>cs.CR cs.DS</categories><comments>17 pages, 2 figures</comments><acm-class>F.2.0; K.6.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study methods for improving the efficiency and privacy of
compressed DNA sequence comparison computations, under various querying
scenarios. For instance, one scenario involves a querier, Bob, who wants to
test if his DNA string, $Q$, is close to a DNA string, $Y$, owned by a data
owner, Alice, but Bob does not want to reveal $Q$ to Alice and Alice is willing
to reveal $Y$ to Bob \emph{only if} it is close to $Q$. We describe a
privacy-enhanced method for comparing two compressed DNA sequences, which can
be used to achieve the goals of such a scenario. Our method involves a
reduction to set differencing, and we describe a privacy-enhanced protocol for
set differencing that achieves absolute privacy for Bob (in the information
theoretic sense), and a quantifiable degree of privacy protection for Alice.
One of the important features of our protocols, which makes them ideally suited
to privacy-enhanced DNA sequence comparison problems, is that the communication
complexity of our solutions is proportional to a threshold that bounds the
cardinality of the set differences that are of interest, rather than the
cardinality of the sets involved (which correlates to the length of the DNA
sequences). Moreover, in our protocols, the querier, Bob, can easily compute
the set difference only if its cardinality is close to or below a specified
threshold.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3600</identifier>
 <datestamp>2011-09-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3600</id><created>2011-07-18</created><updated>2011-09-26</updated><authors><author><keyname>Kramer</keyname><forenames>Oliver</forenames></author></authors><title>Unsupervised K-Nearest Neighbor Regression</title><categories>stat.ML cs.LG</categories><comments>4 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many scientific disciplines structures in high-dimensional data have to be
found, e.g., in stellar spectra, in genome data, or in face recognition tasks.
In this work we present a novel approach to non-linear dimensionality
reduction. It is based on fitting K-nearest neighbor regression to the
unsupervised regression framework for learning of low-dimensional manifolds.
Similar to related approaches that are mostly based on kernel methods,
unsupervised K-nearest neighbor (UNN) regression optimizes latent variables
w.r.t. the data space reconstruction error employing the K-nearest neighbor
heuristic. The problem of optimizing latent neighborhoods is difficult to
solve, but the UNN formulation allows the design of efficient strategies that
iteratively embed latent points to fixed neighborhood topologies. UNN is well
appropriate for sorting of high-dimensional data. The iterative variants are
analyzed experimentally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3602</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3602</id><created>2011-07-18</created><authors><author><keyname>Jo</keyname><forenames>Han-Shin</forenames></author><author><keyname>Sang</keyname><forenames>Young Jin</forenames></author><author><keyname>Xia</keyname><forenames>Ping</forenames></author><author><keyname>Andrews</keyname><forenames>Jeffrey G.</forenames></author></authors><title>Heterogeneous Cellular Networks with Flexible Cell Association: A
  Comprehensive Downlink SINR Analysis</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Wireless Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we develop a tractable framework for SINR analysis in downlink
heterogeneous cellular networks (HCNs) with flexible cell association policies.
The HCN is modeled as a multi-tier cellular network where each tier's base
stations (BSs) are randomly located and have a particular transmit power, path
loss exponent, spatial density, and bias towards admitting mobile users. For
example, as compared to macrocells, picocells would usually have lower transmit
power, higher path loss exponent (lower antennas), higher spatial density (many
picocells per macrocell), and a positive bias so that macrocell users are
actively encouraged to use the more lightly loaded picocells. In the present
paper we implicitly assume all base stations have full queues; future work
should relax this. For this model, we derive the outage probability of a
typical user in the whole network or a certain tier, which is equivalently the
downlink SINR cumulative distribution function. The results are accurate for
all SINRs, and their expressions admit quite simple closed-forms in some
plausible special cases. We also derive the \emph{average ergodic rate} of the
typical user, and the \emph{minimum average user throughput} -- the smallest
value among the average user throughputs supported by one cell in each tier. We
observe that neither the number of BSs or tiers changes the outage probability
or average ergodic rate in an interference-limited full-loaded HCN with
unbiased cell association (no biasing), and observe how biasing alters the
various metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3606</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3606</id><created>2011-07-18</created><updated>2012-02-01</updated><authors><author><keyname>Kimura</keyname><forenames>Hideaki</forenames></author><author><keyname>Coffrin</keyname><forenames>Carleton</forenames></author><author><keyname>Rasin</keyname><forenames>Alexander</forenames></author><author><keyname>Zdonik</keyname><forenames>Stanley B.</forenames></author></authors><title>Optimizing Index Deployment Order for Evolving OLAP (Extended Version)</title><categories>cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Query workloads and database schemas in OLAP applications are becoming
increasingly complex. Moreover, the queries and the schemas have to continually
\textit{evolve} to address business requirements. During such repetitive
transitions, the \textit{order} of index deployment has to be considered while
designing the physical schemas such as indexes and MVs.
  An effective index deployment ordering can produce (1) a prompt query runtime
improvement and (2) a reduced total deployment time. Both of these are
essential qualities of design tools for quickly evolving databases, but
optimizing the problem is challenging because of complex index interactions and
a factorial number of possible solutions.
  We formulate the problem in a mathematical model and study several techniques
for solving the index ordering problem. We demonstrate that Constraint
Programming (CP) is a more flexible and efficient platform to solve the problem
than other methods such as mixed integer programming and A* search. In addition
to exact search techniques, we also studied local search algorithms to find
near optimal solution very quickly.
  Our empirical analysis on the TPC-H dataset shows that our pruning techniques
can reduce the size of the search space by tens of orders of magnitude. Using
the TPC-DS dataset, we verify that our local search algorithm is a highly
scalable and stable method for quickly finding a near-optimal solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3614</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3614</id><created>2011-07-18</created><authors><author><keyname>Mounir</keyname><forenames>Zahid</forenames></author></authors><title>New construction of APN quaratic</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The purpose of this paper is to detail the article of Carlet. Along the way I
recall some interesting results in the theory of finite fields, I give (new)
proofs of some known results, and then I generalize the construction of a
family of APN function. The reference precedes each result, and in the absence
of reference the proof is due to the author.
  Keywords: boolean, bent, APN
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3622</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3622</id><created>2011-07-19</created><authors><author><keyname>Sundararajan</keyname><forenames>Kiran Kumar</forenames></author><author><keyname>Pal</keyname><forenames>Mita</forenames></author><author><keyname>Chakraborty</keyname><forenames>Soubhik</forenames></author><author><keyname>Mahanti</keyname><forenames>N. C.</forenames></author></authors><title>K-sort: A new sorting algorithm that beats Heap sort for n &lt;= 70 lakhs!</title><categories>cs.DS</categories><comments>9 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sundararajan and Chakraborty (2007) introduced a new version of Quick sort
removing the interchanges. Khreisat (2007) found this algorithm to be competing
well with some other versions of Quick sort. However, it uses an auxiliary
array thereby increasing the space complexity. Here, we provide a second
version of our new sort where we have removed the auxiliary array. This second
improved version of the algorithm, which we call K-sort, is found to sort
elements faster than Heap sort for an appreciably large array size (n &lt;=
70,00,000) for uniform U[0, 1] inputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3630</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3630</id><created>2011-07-19</created><authors><author><keyname>Kanakaris</keyname><forenames>Venetis</forenames></author><author><keyname>Ndzi</keyname><forenames>David</forenames></author><author><keyname>Ovaliadis</keyname><forenames>Kyriakos</forenames></author></authors><title>Improving AODV Performance using Dynamic Density Driven Route Request
  Forwarding</title><categories>cs.NI</categories><comments>11 pages, 2 tables, 4 figures</comments><journal-ref>International Journal of Wireless &amp; Mobile Networks, Vol. 3, Is.
  3, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ad-hoc routing protocols use a number of algorithms for route discovery. Some
use flooding in which a route request packet (RREQ) is broadcasted from a
source node to other nodes in the network. This often leads to unnecessary
retransmissions, causing congestion and packet collisions in the network, a
phenomenon called a broadcast storm. This paper presents a RREQ message
forwarding scheme for AODV that reduces routing overheads. This has been called
AODV_EXT. Its performance is compared to that of AODV, DSDV, DSR and OLSR
protocols. Simulation results show that AODV_EXT achieves 3% energy efficiency,
19.5% improvement in data throughput and 69.5% reduction in the number of
dropped packets for a network of 50 nodes. Greater efficiency is achieved in
high density network and marginal improvement in networks with a small number
of nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3631</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3631</id><created>2011-07-19</created><authors><author><keyname>Afreen</keyname><forenames>Rahat</forenames></author><author><keyname>Mehrotra</keyname><forenames>S. C.</forenames></author></authors><title>A Review on Elliptic Curve Cryptography for Embedded Systems</title><categories>cs.CR</categories><comments>Review Article</comments><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT), Vol 3, No 3, June 2011, Pp 84-103</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Importance of Elliptic Curves in Cryptography was independently proposed by
Neal Koblitz and Victor Miller in 1985.Since then, Elliptic curve cryptography
or ECC has evolved as a vast field for public key cryptography (PKC) systems.
In PKC system, we use separate keys to encode and decode the data. Since one of
the keys is distributed publicly in PKC systems, the strength of security
depends on large key size. The mathematical problems of prime factorization and
discrete logarithm are previously used in PKC systems. ECC has proved to
provide same level of security with relatively small key sizes. The research in
the field of ECC is mostly focused on its implementation on application
specific systems. Such systems have restricted resources like storage,
processing speed and domain specific CPU architecture.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3636</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3636</id><created>2011-07-19</created><authors><author><keyname>Li</keyname><forenames>Xiao</forenames></author><author><keyname>Rueetschi</keyname><forenames>Andrea</forenames></author><author><keyname>Eldar</keyname><forenames>Yonina C.</forenames></author><author><keyname>Scaglione</keyname><forenames>Anna</forenames></author></authors><title>GPS Signal Acquisition via Compressive Multichannel Sampling</title><categories>cs.IT math.IT</categories><comments>25 pages, 7 figures, submitted to Physical Communication, Elsevier,
  Special Issue on Compressive Sensing in Communications</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we propose an efficient acquisition scheme for GPS receivers.
It is shown that GPS signals can be effectively sampled and detected using a
bank of randomized correlators with much fewer chip-matched filters than those
used in existing GPS signal acquisition algorithms. The latter use correlations
with all possible shifted replicas of the satellite-specific C/A code and an
exhaustive search for peaking signals over the delay-Doppler space. Our scheme
is based on the recently proposed analog compressed sensing framework, and
consists of a multichannel sampling structure with far fewer correlators.
  The compressive multichannel sampler outputs are linear combinations of a
vector whose support tends to be sparse; by detecting its support one can
identify the strongest satellite signals in the field of view and pinpoint the
correct code-phase and Doppler shifts for finer resolution during tracking. The
analysis in this paper demonstrates that GPS signals can be detected and
acquired via the proposed structure at a lower cost in terms of number of
correlations that need to be computed in the coarse acquisition phase, which in
current GPS technology scales like the product of the number of all possible
delays and Doppler shifts. In contrast, the required number of correlators in
our compressive multichannel scheme scales as the number of satellites in the
field of view of the device times the logarithm of number of delay-Doppler bins
explored, as is typical for compressed sensing methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3645</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3645</id><created>2011-07-19</created><updated>2011-08-10</updated><authors><author><keyname>Kharlampovich</keyname><forenames>Olga</forenames></author><author><keyname>Khoussainov</keyname><forenames>Bakhadyr</forenames></author><author><keyname>Miasnikov</keyname><forenames>Alexei</forenames></author></authors><title>From automatic structures to automatic groups</title><categories>math.GR cs.FL math.LO</categories><comments>Added references, corrected typos</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we introduce the concept of a Cayley graph automatic group (CGA
group or graph automatic group, for short) which generalizes the standard
notion of an automatic group. Like the usual automatic groups graph automatic
ones enjoy many nice properties: these group are invariant under the change of
generators, they are closed under direct and free products, certain types of
amalgamated products, and finite extensions. Furthermore, the Word Problem in
graph automatic groups is decidable in quadratic time. However, the class of
graph automatic groups is much wider then the class of automatic groups. For
example, we prove that all finitely generated 2-nilpotent groups and
Baumslag-Solitar groups B(1,n) are graph automatic, as well as many other
metabelian groups.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3656</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3656</id><created>2011-07-19</created><authors><author><keyname>Amnai</keyname><forenames>Mohamed</forenames></author><author><keyname>Fakhri</keyname><forenames>Youssef</forenames></author><author><keyname>Abouchabaka</keyname><forenames>Jaafar</forenames></author></authors><title>QoS Routing and Performance Evaluation for Mobile Ad Hoc Networks using
  OLSR Protocol</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad-Hoc network is a collection of mobile nodes in communication
without using infrastructure. As the real-time applications used in today's
wireless network grow, we need some schemes to provide more suitable service
for them. We know that most of actual schemes do not perform well on traffic
which is not strictly CBR. Therefore, in this paper we have studied the impact,
respectively, of mobility models and the density of nodes on the performances
(End-to-End Delay, Throughput and Packet Delivery ratio) of routing protocol
(Optimized Link State Routing) OLSR by using in the first a real-time VBR
(MPEG-4) and secondly the Constant Bit Rate (CBR) traffic. Finally we compare
the performance on both cases. Experimentally, we considered the three mobility
models as follows Random Waypoint, Random Direction and Mobgen Steady State.
The experimental results illustrate that the behavior of OLSR change according
to the model and the used traffics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3658</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3658</id><created>2011-07-19</created><authors><author><keyname>Jansen</keyname><forenames>Bart M. P.</forenames></author><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author></authors><title>On Polynomial Kernels for Structural Parameterizations of Odd Cycle
  Transversal</title><categories>cs.DS</categories><comments>Accepted to IPEC 2011, Saarbrucken</comments><msc-class>05C85</msc-class><acm-class>G.2.2; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Odd Cycle Transversal problem (OCT) asks whether a given graph can be
made bipartite (i.e., 2-colorable) by deleting at most l vertices. We study
structural parameterizations of OCT with respect to their polynomial
kernelizability, i.e., whether instances can be efficiently reduced to a size
polynomial in the chosen parameter. It is a major open problem in parameterized
complexity whether Odd Cycle Transversal admits a polynomial kernel when
parameterized by l. On the positive side, we show a polynomial kernel for OCT
when parameterized by the vertex deletion distance to the class of bipartite
graphs of treewidth at most w (for any constant w); this generalizes the
parameter feedback vertex set number (i.e., the distance to a forest).
Complementing this, we exclude polynomial kernels for OCT parameterized by the
distance to outerplanar graphs, conditioned on the assumption that NP \not
\subseteq coNP/poly. Thus the bipartiteness requirement for the treewidth w
graphs is necessary. Further lower bounds are given for parameterization by
distance from cluster and co-cluster graphs respectively, as well as for
Weighted OCT parameterized by the vertex cover number (i.e., the distance from
an independent set).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3663</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3663</id><created>2011-07-19</created><authors><author><keyname>Bordes</keyname><forenames>Antoine</forenames></author><author><keyname>Glorot</keyname><forenames>Xavier</forenames></author><author><keyname>Weston</keyname><forenames>Jason</forenames></author><author><keyname>Bengio</keyname><forenames>Yoshua</forenames></author></authors><title>Towards Open-Text Semantic Parsing via Multi-Task Learning of Structured
  Embeddings</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Open-text (or open-domain) semantic parsers are designed to interpret any
statement in natural language by inferring a corresponding meaning
representation (MR). Unfortunately, large scale systems cannot be easily
machine-learned due to lack of directly supervised data. We propose here a
method that learns to assign MRs to a wide range of text (using a dictionary of
more than 70,000 words, which are mapped to more than 40,000 entities) thanks
to a training scheme that combines learning from WordNet and ConceptNet with
learning from raw text. The model learns structured embeddings of words,
entities and MRs via a multi-task training process operating on these diverse
sources of data that integrates all the learnt knowledge into a single system.
This work ends up combining methods for knowledge acquisition, semantic
parsing, and word-sense disambiguation. Experiments on various tasks indicate
that our approach is indeed successful and can form a basis for future more
sophisticated systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3667</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3667</id><created>2011-07-19</created><authors><author><keyname>Goze</keyname><forenames>Nicolas</forenames></author><author><keyname>Goze</keyname><forenames>Michel</forenames></author><author><keyname>Kenoufi</keyname><forenames>Abdel</forenames></author><author><keyname>Remm</keyname><forenames>Elisabeth</forenames></author></authors><title>A new algebraic and arithmetic framework for interval computations</title><categories>cs.NA math.NA</categories><comments>23 pages, 9 figures</comments><msc-class>65G40</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose some very promissing results in interval arithmetics
which permit to build well-defined arithmetics including distributivity of
multiplication and division according addition and substraction. Thus, it
allows to build all algebraic operations and functions on intervals. This will
avoid completely the wrapping effects and data dependance. Some simple
applications for matrix eigenvalues calculations, inversion of symmetric
matrices and finally optimization are exhibited in the object-oriented
programming language python.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3671</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3671</id><created>2011-07-19</created><authors><author><keyname>Bala</keyname><forenames>Kranti</forenames></author><author><keyname>Ahuja</keyname><forenames>Kiran</forenames></author></authors><title>Impact of Mobility On QoS of Mobile WiMax Network With CBR Application</title><categories>cs.NI</categories><comments>Total 7 Pages, 5 Figures and 1 table</comments><journal-ref>International Journal of Advancements in Technology , Vol. 2, No.
  3, July 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The issue of mobility is important in wireless network because internet
connectivity can only be effective if it's available during the movement of
node. To enhance mobility, wireless access systems are designed such as IEEE
802.16e to operate on the move without any disruption of services. In this
paper we are analyzing the impact of mobility on the QoS parameters
(Throughput, Average Jitter and Average end to end Delay) of a mobile WiMAX
network (IEEE 802.16e) with CBR application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3674</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3674</id><created>2011-07-19</created><updated>2011-08-02</updated><authors><author><keyname>M</keyname><forenames>Venkatesh.</forenames></author><author><keyname>Kumar</keyname><forenames>K.</forenames></author><author><keyname>V</keyname><forenames>Srinivas.</forenames></author></authors><title>Autonomous Traffic Control System Using Agent Based Technology</title><categories>cs.MA</categories><comments>This paper has been withdrawn by the authors. Total Pages 8 and 3
  Figures, Author wishes to withdraw for some major changes and corrections</comments><journal-ref>International Journal of Advancements in Technology, Vol.2, No. 3,
  July 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The way of analyzing, designing and building of real-time projects has been
changed due to the rapid growth of internet, mobile technologies and
intelligent applications. Most of these applications are intelligent, tiny and
distributed components called as agent. Agent works like it takes the input
from numerous real-time sources and gives back the real-time response. In this
paper how these agents can be implemented in vehicle traffic management
especially in large cities and identifying various challenges when there is a
rapid growth of population and vehicles. In this paper our proposal gives a
solution for using autonomous or agent based technology. These autonomous or
intelligent agents have the capability to observe, act and learn from their
past experience. This system uses the knowledge flow of precedent signal or
data to identify the incoming flow of forthcoming signal. Our architecture
involves the video analysis and exploration using some Intelligence learning
algorithm to estimate and identify the flow of traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3680</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3680</id><created>2011-07-19</created><authors><author><keyname>Moloo</keyname><forenames>Raj Kishen</forenames></author><author><keyname>Dawood</keyname><forenames>Muhammad Ajmal Sheik</forenames></author><author><keyname>Auleear</keyname><forenames>Abu Salmaan</forenames></author></authors><title>3-Phase Recognition Approach to Pseudo 3D Building Generation from 2D
  Floor Plan</title><categories>cs.GR cs.CV</categories><comments>15 pages,12 figures, 2 tables, International Journal of Computer
  Graphics &amp; Animation (IJCGA) Vol.1, No.2, June 2011</comments><journal-ref>International Journal of Computer Graphics &amp; Animation (IJCGA)
  Vol.1, No.2, June 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays three dimension (3D) architectural visualisation has become a
powerful tool in the conceptualisation, design and presentation of
architectural products in the construction industry, providing realistic
interaction and walkthrough on engineering products. Traditional ways of
implementing 3D models involves the use of specialised 3D authoring tools along
with skilled 3D designers with blueprints of the model and this is a slow and
laborious process. The aim of this paper is to automate this process by simply
analyzing the blueprint document and generating the 3D scene automatically. For
this purpose we have devised a 3-Phase recognition approach to pseudo 3D
building generation from 2D floor plan and developed a software accordingly.
Our 3-phased 3D building system has been implemented using C, C++ and OpenCV
library [24] for the Image Processing module; The Save Module generated an XML
file for storing the processed floor plan objects attributes; while the
Irrlitch [14] game engine was used to implement the Interactive 3D module.
Though still at its infancy, our proposed system gave commendable results. We
tested our system on 6 floor plans with complexities ranging from low to high
and the results seems to be very promising with an average processing time of
around 3s and a 3D generation in 4s. In addition the system provides an
interactive walk-though and allows users to modify components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3682</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3682</id><created>2011-07-19</created><authors><author><keyname>Wu</keyname><forenames>Jun</forenames></author><author><keyname>Shimamoto</keyname><forenames>Shigeru</forenames></author></authors><title>Context-Capture Multi-Valued Decision Fusion With Fault Tolerant
  Capability For Wireless Sensor Networks</title><categories>cs.DC cs.NI</categories><comments>13 pages, 7 figures</comments><msc-class>Information and Communication, circuits</msc-class><acm-class>I.4.8</acm-class><doi>10.5121/ijwmn.2011.3310</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) are usually utilized to perform decision
fusion of event detection. Current decision fusion schemes are based on binary
valued decision and do not consider bursty contextcapture. However, bursty
context and multi-valued data are important characteristics of WSNs. One on
hand, the local decisions from sensors usually have bursty and contextual
characteristics. Fusion center must capture the bursty context information from
the sensors. On the other hand, in practice, many applications need to process
multi-valued data, such as temperature and reflection level used for lightening
prediction. To address these challenges, the Markov modulated Poisson process
(MMPP) and multi-valued logic are introduced into WSNs to perform
context-capture multi-valued decision fusion. The overall decision fusion is
decomposed into two parts. The first part is the context-capture model for WSNs
using superposition MMPP. Through this procedure, the fusion center has a
higher probability to get useful local decisions from sensors. The second one
is focused on multi-valued decision fusion. Fault detection can also be
performed based on MVL. Once the fusion center detects the faulty nodes, all
their local decisions are removed from the computation of the likelihood
ratios. Finally, we evaluate the capability of context-capture and fault
tolerant. The result supports the usefulness of our scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3689</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3689</id><created>2011-07-19</created><updated>2012-02-09</updated><authors><author><keyname>Sumi</keyname><forenames>R&#xf3;bert</forenames></author><author><keyname>Yasseri</keyname><forenames>Taha</forenames></author><author><keyname>Rung</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Kornai</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author></authors><title>Edit wars in Wikipedia</title><categories>stat.ML cs.DL physics.data-an physics.soc-ph</categories><comments>4 pages, 2 figures, 3 tables. The current version is shortened to be
  published in SocialCom 2011</comments><journal-ref>Privacy, Security, Risk and Trust (PASSAT), 2011 IEEE Third
  International Conference on and 2011 IEEE Third International Confernece on
  Social Computing (SocialCom), 9-11 Oct. 2011, 724-727, Boston, MA, USA, ISBN:
  978-1-4577-1931-8</journal-ref><doi>10.1109/PASSAT/SocialCom.2011.47</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new, efficient method for automatically detecting severe
conflicts `edit wars' in Wikipedia and evaluate this method on six different
language WPs. We discuss how the number of edits, reverts, the length of
discussions, the burstiness of edits and reverts deviate in such pages from
those following the general workflow, and argue that earlier work has
significantly over-estimated the contentiousness of the Wikipedia editing
process.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3695</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3695</id><created>2011-07-19</created><authors><author><keyname>Bourouis</keyname><forenames>Abderrahim</forenames></author><author><keyname>Feham</keyname><forenames>Mohamed</forenames></author><author><keyname>Bouchachia</keyname><forenames>Abdelhamid</forenames></author></authors><title>Ubiquitous Mobile Health Monitoring System for Elderly (UMHMSE)</title><categories>cs.NI</categories><comments>9 pages,5 figures</comments><journal-ref>International Journal of Computer Science &amp; Information Technology
  (IJCSIT), Vol 3, No 3, June 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Recent research in ubiquitous computing uses technologies of Body Area
Networks (BANs) to monitor the person's kinematics and physiological
parameters. In this paper we propose a real time mobile health system for
monitoring elderly patients from indoor or outdoor environments. The system
uses a bio- signal sensor worn by the patient and a Smartphone as a central
node. The sensor data is collected and transmitted to the intelligent server
through GPRS/UMTS to be analyzed. The prototype (UMHMSE) monitors the elderly
mobility, location and vital signs such as Sp02 and Heart Rate. Remote users
(family and medical personnel) might have a real time access to the collected
information through a web application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3704</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3704</id><created>2011-07-19</created><updated>2011-12-13</updated><authors><author><keyname>Kratsch</keyname><forenames>Stefan</forenames></author></authors><title>Co-nondeterminism in compositions: A kernelization lower bound for a
  Ramsey-type problem</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Until recently, techniques for obtaining lower bounds for kernelization were
one of the most sought after tools in the field of parameterized complexity.
Now, after a strong influx of techniques, we are in the fortunate situation of
having tools available that are even stronger than what has been required in
their applications so far. Based on a result of Fortnow and Santhanam (JCSS
2011), Bodlaender et al. (JCSS 2009) showed that, unless NP \subseteq
coNP/poly, the existence of a deterministic polynomial-time composition
algorithm, i.e., an algorithm which outputs an instance of bounded parameter
value which is yes if and only if one of t input instances is yes, rules out
the existence of polynomial kernels for a problem. Dell and van Melkebeek (STOC
2010) continued this line of research and, amongst others, were able to rule
out kernels of size O(k^d-eps) for certain problems, assuming NP !\subseteq
coNP/poly. Their work implies that even the existence of a co-nondeterministic
composition rules out polynomial kernels.
  In this work we present the first example of how co-nondeterminism can help
to make a composition algorithm. We study a Ramsey-type problem: Given a graph
G and an integer k, the question is whether G contains an independent set or a
clique of size at least k. It was asked by Rod Downey whether this problem
admits a polynomial kernelization. We provide a co-nondeterministic composition
based on embedding t instances into a single host graph H. The crux is that the
host graph H needs to observe a bound of L \in O(log t) on both its maximum
independent set and maximum clique size, while also having a cover of its
vertex set by independent sets and cliques all of size L; the
co-nondeterministic composition is build around the search for such graphs.
Thus we show that, unless NP \subseteq coNP/poly, the problem does not admit a
kernelization with polynomial size guarantee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3706</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3706</id><created>2011-07-19</created><authors><author><keyname>Xu</keyname><forenames>Wenyan</forenames></author><author><keyname>Liu</keyname><forenames>Sanyang</forenames></author></authors><title>The countable versus uncountable branching recurrences in computability
  logic</title><categories>cs.LO</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new simplified version of the countable branching
recurrence of Computability Logic, proves its equivalence to the old one, and
shows that the basic logic induced by it is a proper superset of the basic
logic induced by the uncountable branching recurrence. A further result of this
paper is showing that the countable branching recurrence is strictly weaker
than the uncountable branching recurrence in the sense that the latter
logically implies the former but not vice versa.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3707</identifier>
 <datestamp>2012-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3707</id><created>2011-07-19</created><updated>2012-02-15</updated><authors><author><keyname>Petersen</keyname><forenames>Alexander M.</forenames></author><author><keyname>Tenenbaum</keyname><forenames>Joel</forenames></author><author><keyname>Havlin</keyname><forenames>Shlomo</forenames></author><author><keyname>Stanley</keyname><forenames>H. Eugene</forenames></author></authors><title>Statistical Laws Governing Fluctuations in Word Use from Word Birth to
  Word Death</title><categories>physics.soc-ph cs.CL cs.IR nlin.AO physics.pop-ph</categories><comments>Version 1: 31 pages, 17 figures, 3 tables. Version 2 is streamlined,
  eliminates substantial material and incorporates referee comments: 19 pages,
  14 figures, 3 tables</comments><journal-ref>Scientific Reports 2, 313 (2012)</journal-ref><doi>10.1038/srep00313</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the dynamic properties of 10^7 words recorded in English, Spanish
and Hebrew over the period 1800--2008 in order to gain insight into the
coevolution of language and culture. We report language independent patterns
useful as benchmarks for theoretical models of language evolution. A
significantly decreasing (increasing) trend in the birth (death) rate of words
indicates a recent shift in the selection laws governing word use. For new
words, we observe a peak in the growth-rate fluctuations around 40 years after
introduction, consistent with the typical entry time into standard dictionaries
and the human generational timescale. Pronounced changes in the dynamics of
language during periods of war shows that word correlations, occurring across
time and between words, are largely influenced by coevolutionary social,
technological, and political factors. We quantify cultural memory by analyzing
the long-term correlations in the use of individual words using detrended
fluctuation analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3715</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3715</id><created>2011-07-19</created><updated>2014-04-28</updated><authors><author><keyname>Helmling</keyname><forenames>Michael</forenames></author><author><keyname>Ruzika</keyname><forenames>Stefan</forenames></author><author><keyname>Tanatmis</keyname><forenames>Akin</forenames></author></authors><title>Mathematical Programming Decoding of Binary Linear Codes: Theory and
  Algorithms</title><categories>cs.IT math.IT</categories><comments>17 pages, submitted to the IEEE Transactions on Information Theory.
  Published July 2012</comments><acm-class>E.4</acm-class><doi>10.1109/TIT.2012.2191697</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mathematical programming is a branch of applied mathematics and has recently
been used to derive new decoding approaches, challenging established but often
heuristic algorithms based on iterative message passing. Concepts from
mathematical programming used in the context of decoding include linear,
integer, and nonlinear programming, network flows, notions of duality as well
as matroid and polyhedral theory. This survey article reviews and categorizes
decoding methods based on mathematical programming approaches for binary linear
codes over binary-input memoryless symmetric channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3724</identifier>
 <datestamp>2013-11-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3724</id><created>2011-07-19</created><authors><author><keyname>Pirola</keyname><forenames>Yuri</forenames></author><author><keyname>Della Vedova</keyname><forenames>Gianluca</forenames></author><author><keyname>Biffani</keyname><forenames>Stefano</forenames></author><author><keyname>Stella</keyname><forenames>Alessandra</forenames></author><author><keyname>Bonizzoni</keyname><forenames>Paola</forenames></author></authors><title>Haplotype Inference on Pedigrees with Recombinations, Errors, and
  Missing Genotypes via SAT solvers</title><categories>cs.DS q-bio.PE</categories><comments>14 pages, 1 figure, 4 tables, the associated software reHCstar is
  available at http://www.algolab.eu/reHCstar</comments><acm-class>F.2.2</acm-class><journal-ref>IEEE/ACM Trans. on Computational Biology and Bioinformatics 9.6
  (2012) 1582-1594</journal-ref><doi>10.1109/TCBB.2012.100</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Minimum-Recombinant Haplotype Configuration problem (MRHC) has been
highly successful in providing a sound combinatorial formulation for the
important problem of genotype phasing on pedigrees. Despite several algorithmic
advances and refinements that led to some efficient algorithms, its
applicability to real datasets has been limited by the absence of some
important characteristics of these data in its formulation, such as mutations,
genotyping errors, and missing data.
  In this work, we propose the Haplotype Configuration with Recombinations and
Errors problem (HCRE), which generalizes the original MRHC formulation by
incorporating the two most common characteristics of real data: errors and
missing genotypes (including untyped individuals). Although HCRE is
computationally hard, we propose an exact algorithm for the problem based on a
reduction to the well-known Satisfiability problem. Our reduction exploits
recent progresses in the constraint programming literature and, combined with
the use of state-of-the-art SAT solvers, provides a practical solution for the
HCRE problem. Biological soundness of the phasing model and effectiveness (on
both accuracy and performance) of the algorithm are experimentally demonstrated
under several simulated scenarios and on a real dairy cattle population.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3729</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3729</id><created>2011-07-19</created><authors><author><keyname>Bordas</keyname><forenames>Stephane PA</forenames></author><author><keyname>Natarajan</keyname><forenames>Sundararajan</forenames></author></authors><title>On the approximation in the smoothed finite element method (SFEM)</title><categories>cs.NA math.NA</categories><comments>14 pages, 9 figures, 1 table; International Journal for Numerical
  Methods in Engineering, 2010</comments><doi>10.1002/nme.2713</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This letter aims at resolving the issues raised in the recent short
communication [1] and answered by [2] by proposing a systematic approximation
scheme based on non-mapped shape functions, which both allows to fully exploit
the unique advantages of the smoothed finite element method (SFEM) [3, 4, 5, 6,
7, 8, 9] and resolve the existence, linearity and positivity deficiencies
pointed out in [1]. We show that Wachspress interpolants [10] computed in the
physical coordinate system are very well suited to the SFEM, especially when
elements are heavily distorted (obtuse interior angles). The proposed
approximation leads to results which are almost identical to those of the SFEM
initially proposed in [3]. These results that the proposed approximation scheme
forms a strong and rigorous basis for construction of smoothed finite element
methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3731</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3731</id><created>2011-07-19</created><updated>2011-07-24</updated><authors><author><keyname>Gupta</keyname><forenames>Anupam</forenames></author><author><keyname>Roth</keyname><forenames>Aaron</forenames></author><author><keyname>Ullman</keyname><forenames>Jonathan</forenames></author></authors><title>Iterative Constructions and Private Data Release</title><categories>cs.DS cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the problem of approximately releasing the cut
function of a graph while preserving differential privacy, and give new
algorithms (and new analyses of existing algorithms) in both the interactive
and non-interactive settings.
  Our algorithms in the interactive setting are achieved by revisiting the
problem of releasing differentially private, approximate answers to a large
number of queries on a database. We show that several algorithms for this
problem fall into the same basic framework, and are based on the existence of
objects which we call iterative database construction algorithms. We give a new
generic framework in which new (efficient) IDC algorithms give rise to new
(efficient) interactive private query release mechanisms. Our modular analysis
simplifies and tightens the analysis of previous algorithms, leading to
improved bounds. We then give a new IDC algorithm (and therefore a new private,
interactive query release mechanism) based on the Frieze/Kannan low-rank matrix
decomposition. This new release mechanism gives an improvement on prior work in
a range of parameters where the size of the database is comparable to the size
of the data universe (such as releasing all cut queries on dense graphs).
  We also give a non-interactive algorithm for efficiently releasing private
synthetic data for graph cuts with error O(|V|^{1.5}). Our algorithm is based
on randomized response and a non-private implementation of the SDP-based,
constant-factor approximation algorithm for cut-norm due to Alon and Naor.
Finally, we give a reduction based on the IDC framework showing that an
efficient, private algorithm for computing sufficiently accurate rank-1 matrix
approximations would lead to an improved efficient algorithm for releasing
private synthetic data for graph cuts. We leave finding such an algorithm as
our main open problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3734</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3734</id><created>2011-07-19</created><authors><author><keyname>Tchiboukdjian</keyname><forenames>Marc</forenames></author><author><keyname>Gast</keyname><forenames>Nicolas</forenames></author><author><keyname>Trystram</keyname><forenames>Denis</forenames></author></authors><title>Decentralized List Scheduling</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classical list scheduling is a very popular and efficient technique for
scheduling jobs in parallel and distributed platforms. It is inherently
centralized. However, with the increasing number of processors, the cost for
managing a single centralized list becomes too prohibitive. A suitable approach
to reduce the contention is to distribute the list among the computational
units: each processor has only a local view of the work to execute. Thus, the
scheduler is no longer greedy and standard performance guarantees are lost.
  The objective of this work is to study the extra cost that must be paid when
the list is distributed among the computational units. We first present a
general methodology for computing the expected makespan based on the analysis
of an adequate potential function which represents the load unbalance between
the local lists. We obtain an equation on the evolution of the potential by
computing its expected decrease in one step of the schedule. Our main theorem
shows how to solve such equations to bound the makespan. Then, we apply this
method to several scheduling problems, namely, for unit independent tasks, for
weighted independent tasks and for tasks with precendence constraints. More
precisely, we prove that the time for scheduling a global workload W composed
of independent unit tasks on m processors is equal to W/m plus an additional
term proportional to log_2 W. We provide a lower bound which shows that this is
optimal up to a constant. This result is extended to the case of weighted
independent tasks. In the last setting, precedence task graphs, our analysis
leads to an improvement on the bound of Arora et al. We finally provide some
experiments using a simulator. The distribution of the makespan is shown to fit
existing probability laws. The additive term is shown by simulation to be
around 3 \log_2 W confirming the tightness of our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3746</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3746</id><created>2011-07-19</created><authors><author><keyname>Tadaki</keyname><forenames>Kohtaro</forenames></author></authors><title>A Computational Complexity-Theoretic Elaboration of Weak Truth-Table
  Reducibility</title><categories>math.LO cs.CC cs.IT math.IT</categories><comments>25 pages, LaTeX2e, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The notion of weak truth-table reducibility plays an important role in
recursion theory. In this paper, we introduce an elaboration of this notion,
where a computable bound on the use function is explicitly specified. This
elaboration enables us to deal with the notion of asymptotic behavior in a
manner like in computational complexity theory, while staying in computability
theory. We apply the elaboration to sets which appear in the statistical
mechanical interpretation of algorithmic information theory. We demonstrate the
power of the elaboration by revealing a critical phenomenon, i.e., a phase
transition, in the statistical mechanical interpretation, which cannot be
captured by the original notion of weak truth-table reducibility.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3759</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3759</id><created>2011-07-19</created><authors><author><keyname>Munjin</keyname><forenames>Dejan</forenames></author><author><keyname>Morin</keyname><forenames>Jean-Henry</forenames></author></authors><title>User Empowerment in the Internet of Things</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper focuses on the characteristics of two big triggers that
facilitated wide user adoption of the Internet: Web 2.0 and online social
networks. We detect brakes for reproduction of these events in Internet of
things. To support our hypothesis we first compare the difference between the
ways of use of the Internet with the future scenarios of Internet of things. We
detect barriers that could slow down apparition of this kind of social events
during user adoption of Internet of Things and we propose a conceptual
framework to solve these problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3765</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3765</id><created>2011-07-19</created><authors><author><keyname>Zhai</keyname><forenames>Ke</forenames></author><author><keyname>Boyd-Graber</keyname><forenames>Jordan</forenames></author><author><keyname>Asadi</keyname><forenames>Nima</forenames></author></authors><title>Using Variational Inference and MapReduce to Scale Topic Modeling</title><categories>cs.AI cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Latent Dirichlet Allocation (LDA) is a popular topic modeling technique for
exploring document collections. Because of the increasing prevalence of large
datasets, there is a need to improve the scalability of inference of LDA. In
this paper, we propose a technique called ~\emph{MapReduce LDA} (Mr. LDA) to
accommodate very large corpus collections in the MapReduce framework. In
contrast to other techniques to scale inference for LDA, which use Gibbs
sampling, we use variational inference. Our solution efficiently distributes
computation and is relatively simple to implement. More importantly, this
variational implementation, unlike highly tuned and specialized
implementations, is easily extensible. We demonstrate two extensions of the
model possible with this scalable framework: informed priors to guide topic
discovery and modeling topics from a multilingual corpus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3767</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3767</id><created>2011-07-19</created><authors><author><keyname>Jim&#xe9;nez</keyname><forenames>Andrea</forenames></author><author><keyname>Kiwi</keyname><forenames>Marcos</forenames></author></authors><title>Computational Hardness of Enumerating Satisfying Spin-Assignments in
  Triangulations</title><categories>cs.CC</categories><comments>20 pages,25 figures</comments><acm-class>F.1.3; J.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Satisfying spin-assignments in triangulations of a surface are states of
minimum energy of the antiferromagnetic Ising model on triangulations which
correspond (via geometric duality) to perfect matchings in cubic bridgeless
graphs. In this work we show that it is NP-complete to decide whether or not a
surface triangulation admits a satisfying spin-assignment, and that it is
#P-complete to determine the number of such assignments. Both results are
derived via an elaborate (and atypical) reduction that maps a Boolean formula
in 3-conjunctive normal form into a triangulation of an orientable closed
surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3784</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3784</id><created>2011-07-19</created><authors><author><keyname>Mivule</keyname><forenames>Kato</forenames></author><author><keyname>Turner</keyname><forenames>Claude</forenames></author></authors><title>Applying Data Privacy Techniques on Tabular Data in Uganda</title><categories>cs.CR cs.DB</categories><comments>10 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growth of Information Technology(IT) in Africa has led to an increase in
the utilization of communication networks for data transaction across the
continent. A growing number of entities in the private sector, academia, and
government, have deployed the Internet as a medium to transact in data,
routinely posting statistical and non statistical data online and thereby
making many in Africa increasingly dependent on the Internet for data
transactions. In the country of Uganda, exponential growth in data transaction
has presented a new challenge: What is the most efficient way to implement data
privacy. This article discusses data privacy challenges faced by the country of
Uganda and implementation of data privacy techniques for published tabular
data. We make the case for data privacy, survey concepts of data privacy, and
implementations that could be employed to provide data privacy in Uganda.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3785</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3785</id><created>2011-07-19</created><authors><author><keyname>Tregub</keyname><forenames>Vladimir Vasilich</forenames></author></authors><title>Teaching Introductory Electrical Engineering Course to CS Students in a
  Russian University</title><categories>cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article is about the author's experience with developing and teaching an
introductory electrical engineering course for students of Faculty (department)
of Information Technology of a Russian university. The curriculum of this
department conforms to typical computer science curricula of US engineering
schools with a noticeable omission of comparable electrical engineering
courses. When developing the course, I did my best to pay attention to learning
preferences of the department's student body. I also hoped to contribute to a
degree to meeting labor market demands for developers of electrical engineering
CAD software. As for inspiration, I was enchanted with ideas of the Mead &amp;
Conway revolution, albeit indirectly related to my enterprise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3792</identifier>
 <datestamp>2011-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3792</id><created>2011-07-19</created><authors><author><keyname>Seshadhri</keyname><forenames>C.</forenames></author><author><keyname>Vorobeychik</keyname><forenames>Yevgeniy</forenames></author><author><keyname>Mayo</keyname><forenames>Jackson R.</forenames></author><author><keyname>Armstrong</keyname><forenames>Robert C.</forenames></author><author><keyname>Ruthruff</keyname><forenames>Joseph R.</forenames></author></authors><title>Influence and Dynamic Behavior in Random Boolean Networks</title><categories>cond-mat.dis-nn cs.DM nlin.AO</categories><comments>To appear as a Letter in Physical Review Letters 8 pages, 4 figures</comments><journal-ref>Phys. Rev. Lett. 107, 108701 (2011)</journal-ref><doi>10.1103/PhysRevLett.107.108701</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a rigorous mathematical framework for analyzing dynamics of a
broad class of Boolean network models. We use this framework to provide the
first formal proof of many of the standard critical transition results in
Boolean network analysis, and offer analogous characterizations for novel
classes of random Boolean networks. We precisely connect the short-run dynamic
behavior of a Boolean network to the average influence of the transfer
functions. We show that some of the assumptions traditionally made in the more
common mean-field analysis of Boolean networks do not hold in general.
  For example, we offer some evidence that imbalance, or expected internal
inhomogeneity, of transfer functions is a crucial feature that tends to drive
quiescent behavior far more strongly than previously observed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3793</identifier>
 <datestamp>2012-05-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3793</id><created>2011-07-19</created><updated>2012-05-18</updated><authors><author><keyname>Busaryev</keyname><forenames>Oleksiy</forenames></author><author><keyname>Cabello</keyname><forenames>Sergio</forenames></author><author><keyname>Chen</keyname><forenames>Chao</forenames></author><author><keyname>Dey</keyname><forenames>Tamal K.</forenames></author><author><keyname>Wang</keyname><forenames>Yusu</forenames></author></authors><title>Annotating Simplices with a Homology Basis and Its Applications</title><categories>cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $K$ be a simplicial complex and $g$ the rank of its $p$-th homology group
$H_p(K)$ defined with $Z_2$ coefficients. We show that we can compute a basis
$H$ of $H_p(K)$ and annotate each $p$-simplex of $K$ with a binary vector of
length $g$ with the following property: the annotations, summed over all
$p$-simplices in any $p$-cycle $z$, provide the coordinate vector of the
homology class $[z]$ in the basis $H$. The basis and the annotations for all
simplices can be computed in $O(n^{\omega})$ time, where $n$ is the size of $K$
and $\omega&lt;2.376$ is a quantity so that two $n\times n$ matrices can be
multiplied in $O(n^{\omega})$ time. The pre-computation of annotations permits
answering queries about the independence or the triviality of $p$-cycles
efficiently.
  Using annotations of edges in 2-complexes, we derive better algorithms for
computing optimal basis and optimal homologous cycles in 1-dimensional
homology. Specifically, for computing an optimal basis of $H_1(K)$, we improve
the time complexity known for the problem from $O(n^4)$ to
$O(n^{\omega}+n^2g^{\omega-1})$. Here $n$ denotes the size of the 2-skeleton of
$K$ and $g$ the rank of $H_1(K)$. Computing an optimal cycle homologous to a
given 1-cycle is NP-hard even for surfaces and an algorithm taking
$2^{O(g)}n\log n$ time is known for surfaces. We extend this algorithm to work
with arbitrary 2-complexes in $O(n^{\omega})+2^{O(g)}n^2\log n$ time using
annotations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3794</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3794</id><created>2011-07-19</created><authors><author><keyname>Zhu</keyname><forenames>Tao</forenames></author><author><keyname>Bronk</keyname><forenames>Christopher</forenames></author><author><keyname>Wallach</keyname><forenames>Dan S.</forenames></author></authors><title>An Analysis of Chinese Search Engine Filtering</title><categories>cs.CR</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The imposition of government mandates upon Internet search engine operation
is a growing area of interest for both computer science and public policy.
Users of these search engines often observe evidence of censorship, but the
government policies that impose this censorship are not generally public. To
better understand these policies, we conducted a set of experiments on major
search engines employed by Internet users in China, issuing queries against a
variety of different words: some neutral, some with names of important people,
some political, and some pornographic. We conducted these queries, in Chinese,
against Baidu, Google (including google.cn, before it was terminated), Yahoo!,
and Bing. We found remarkably aggressive filtering of pornographic terms, in
some cases causing non-pornographic terms which use common characters to also
be filtered. We also found that names of prominent activists and organizers as
well as top political and military leaders, were also filtered in whole or in
part. In some cases, we found search terms which we believe to be
&quot;blacklisted&quot;. In these cases, the only results that appeared, for any of them,
came from a short &quot;whitelist&quot; of sites owned or controlled directly by the
Chinese government. By repeating observations over a long observation period,
we also found that the keyword blocking policies of the Great Firewall of China
vary over time. While our results don't offer any fundamental insight into how
to defeat or work around Chinese internet censorship, they are still helpful to
understand the structure of how censorship duties are shared between the Great
Firewall and Chinese search engines.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3818</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3818</id><created>2011-07-19</created><authors><author><keyname>Hartigan</keyname><forenames>John</forenames></author><author><keyname>Pollard</keyname><forenames>David</forenames></author><author><keyname>Tatikonda</keyname><forenames>Sekhar</forenames></author></authors><title>Conditioned Poisson distributions and the concentration of chromatic
  numbers</title><categories>cs.DM math.ST stat.TH</categories><comments>Unpublished paper from June 2008</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper provides a simpler method for proving a delicate inequality that
was used by Achlioptis and Naor to establish asymptotic concentration for
chromatic numbers of Erdos-Renyi random graphs. The simplifications come from
two new ideas. The first involves a sharpened form of a piece of statistical
folklore regarding goodness-of-fit tests for two-way tables of Poisson counts
under linear conditioning constraints. The second idea takes the form of a new
inequality that controls the extreme tails of the distribution of a quadratic
form in independent Poissons random variables.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3823</identifier>
 <datestamp>2011-07-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3823</id><created>2011-07-19</created><authors><author><keyname>Heess</keyname><forenames>Nicolas</forenames><affiliation>Informatics</affiliation></author><author><keyname>Roux</keyname><forenames>Nicolas Le</forenames><affiliation>INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Winn</keyname><forenames>John</forenames></author></authors><title>Weakly Supervised Learning of Foreground-Background Segmentation using
  Masked RBMs</title><categories>cs.LG cs.CV</categories><proxy>ccsd</proxy><journal-ref>International Conference on Artificial Neural Networks (2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an extension of the Restricted Boltzmann Machine (RBM) that allows
the joint shape and appearance of foreground objects in cluttered images to be
modeled independently of the background. We present a learning scheme that
learns this representation directly from cluttered images with only very weak
supervision. The model generates plausible samples and performs
foreground-background segmentation. We demonstrate that representing foreground
objects independently of the background can be beneficial in recognition tasks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3857</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3857</id><created>2011-07-19</created><authors><author><keyname>Cloud</keyname><forenames>Jason</forenames></author><author><keyname>Zeger</keyname><forenames>Linda</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>MAC Centered Cooperation - Synergistic Design of Network Coding,
  Multi-Packet Reception, and Improved Fairness to Increase Network Throughput</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We design a cross-layer approach to aid in develop- ing a cooperative
solution using multi-packet reception (MPR), network coding (NC), and medium
access (MAC). We construct a model for the behavior of the IEEE 802.11 MAC
protocol and apply it to key small canonical topology components and their
larger counterparts. The results obtained from this model match the available
experimental results with fidelity. Using this model, we show that fairness
allocation by the IEEE 802.11 MAC can significantly impede performance; hence,
we devise a new MAC that not only substantially improves throughput, but
provides fairness to flows of information rather than to nodes. We show that
cooperation between NC, MPR, and our new MAC achieves super-additive gains of
up to 6.3 times that of routing with the standard IEEE 802.11 MAC. Furthermore,
we extend the model to analyze our MAC's asymptotic and throughput behaviors as
the number of nodes increases or the MPR capability is limited to only a single
node. Finally, we show that although network performance is reduced under
substantial asymmetry or limited implementation of MPR to a central node, there
are some important practical cases, even under these conditions, where MPR, NC,
and their combination provide significant gains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3862</identifier>
 <datestamp>2011-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3862</id><created>2011-07-19</created><updated>2011-09-12</updated><authors><author><keyname>Huh</keyname><forenames>Hoon</forenames></author><author><keyname>Caire</keyname><forenames>Giuseppe</forenames></author><author><keyname>Papadopoulos</keyname><forenames>Haralabos C.</forenames></author><author><keyname>Ramprashad</keyname><forenames>Sean A.</forenames></author></authors><title>Achieving &quot;Massive MIMO&quot; Spectral Efficiency with a Not-so-Large Number
  of Antennas</title><categories>cs.IT math.IT</categories><comments>Full version with appendice (proofs of theorems). A shortened version
  without appendice was submitted to IEEE Trans. on Wireless Commun. Appendix B
  was revised after submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main focus and contribution of this paper is a novel network-MIMO TDD
architecture that achieves spectral efficiencies comparable with &quot;Massive
MIMO&quot;, with one order of magnitude fewer antennas per active user per cell. The
proposed architecture is based on a family of network-MIMO schemes defined by
small clusters of cooperating base stations, zero-forcing multiuser MIMO
precoding with suitable inter-cluster interference constraints, uplink pilot
signals reuse across cells, and frequency reuse. The key idea consists of
partitioning the users population into geographically determined &quot;bins&quot;, such
that all users in the same bin are statistically equivalent, and use the
optimal network-MIMO architecture in the family for each bin. A scheduler takes
care of serving the different bins on the time-frequency slots, in order to
maximize a desired network utility function that captures some desired notion
of fairness. This results in a mixed-mode network-MIMO architecture, where
different schemes, each of which is optimized for the served user bin, are
multiplexed in time-frequency. In order to carry out the performance analysis
and the optimization of the proposed architecture in a clean and
computationally efficient way, we consider the large-system regime where the
number of users, the number of antennas, and the channel coherence block length
go to infinity with fixed ratios. The performance predicted by the large-system
asymptotic analysis matches very well the finite-dimensional simulations.
Overall, the system spectral efficiency obtained by the proposed architecture
is similar to that achieved by &quot;Massive MIMO&quot;, with a 10-fold reduction in the
number of antennas at the base stations (roughly, from 500 to 50 antennas).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3863</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3863</id><created>2011-07-19</created><updated>2012-12-18</updated><authors><author><keyname>Das</keyname><forenames>Anupam</forenames></author><author><keyname>Borisov</keyname><forenames>Nikita</forenames></author></authors><title>Securing Tor Tunnels under the Selective-DoS Attack</title><categories>cs.CR cs.NI</categories><acm-class>C.2.0; C.2.4</acm-class><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Anonymous communication systems are subject to selective denial-of-service
(DoS) attacks. Selective DoS attacks lower anonymity as they force paths to be
rebuilt multiple times to ensure delivery which increases the opportunity for
more attack. In this paper we present a detection algorithm that filters out
compromised communication channels for one of the most widely used anonymity
networks, Tor. Our detection algorithm uses two levels of probing to filter out
potentially compromised tunnels. We perform probabilistic analysis and
extensive simulation to show the robustness of our detection algorithm. We also
analyze the overhead of our detection algorithm and show that we can achieve
satisfactory security guarantee for reasonable communication overhead (5% of
the total available Tor bandwidth in the worst case). Real world experiments
reveal that our detection algorithm provides good defense against selective DoS
attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3876</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3876</id><created>2011-07-19</created><authors><author><keyname>Goyal</keyname><forenames>Navin</forenames></author><author><keyname>Rademacher</keyname><forenames>Luis</forenames></author></authors><title>Lower Bounds for the Average and Smoothed Number of Pareto Optima</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smoothed analysis of multiobjective 0-1 linear optimization has drawn
considerable attention recently. The number of Pareto-optimal solutions (i.e.,
solutions with the property that no other solution is at least as good in all
the coordinates and better in at least one) for multiobjective optimization
problems is the central object of study. In this paper, we prove several lower
bounds for the expected number of Pareto optima. Our basic result is a lower
bound of \Omega_d(n^(d-1)) for optimization problems with d objectives and n
variables under fairly general conditions on the distributions of the linear
objectives. Our proof relates the problem of lower bounding the number of
Pareto optima to results in geometry connected to arrangements of hyperplanes.
We use our basic result to derive (1) To our knowledge, the first lower bound
for natural multiobjective optimization problems. We illustrate this for the
maximum spanning tree problem with randomly chosen edge weights. Our technique
is sufficiently flexible to yield such lower bounds for other standard
objective functions studied in this setting (such as, multiobjective shortest
path, TSP tour, matching). (2) Smoothed lower bound of min {\Omega_d(n^(d-1.5)
\phi^{(d-log d) (1-\Theta(1/\phi))}), 2^{\Theta(n)}}$ for the 0-1 knapsack
problem with d profits for phi-semirandom distributions for a version of the
knapsack problem. This improves the recent lower bound of Brunsch and Roeglin.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3879</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3879</id><created>2011-07-19</created><authors><author><keyname>Zhu</keyname><forenames>Weiping</forenames></author></authors><title>Fitting a Model to Data in Loss Tomography</title><categories>cs.NI</categories><comments>10 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Loss tomography has received considerable attention in recent years and a
number of estimators have been proposed. Although most of the estimators claim
to be the maximum likelihood estimators, the claim is only partially true since
the maximum likelihood estimate can be obtained at most for a class of data
sets. Unfortunately, few people are aware of this restriction that leads to a
misconception that an estimator is applicable to all data sets as far as it
returns a unique solution. To correct this, we in this paper point out the risk
of this misconception and illustrate the inconsistency between data and model
in the most influential estimators. To ensure the model used in estimation
consistent with the data collected from an experiment, the data sets used in
estimation are divided into 4 classes according to the characteristics of
observations. Based on the classification, the validity of an estimator is
defined and the validity of the most influential estimators is evaluated. In
addition, a number of estimators are proposed, one for a class of data sets
that have been overlooked. Further, a general estimator is proposed that is
applicable to all data classes. The discussion starts from the tree topology
and end at the general topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3893</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3893</id><created>2011-07-20</created><authors><author><keyname>Farooq</keyname><forenames>Umer</forenames></author><author><keyname>Iqbal</keyname><forenames>M. Aqeel</forenames></author><author><keyname>Nazir</keyname><forenames>Sohail</forenames></author></authors><title>A Glance into the Future of Human Computer Interaction</title><categories>cs.HC</categories><comments>16 pages, seven figures, 1 table, 2 flow charts, published in
  International Journal of Computer Science, Engineering and Applications
  (IJCSEA) Vol.1, No.3, June 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computers have a direct impact on our lives nowadays. Human's interaction
with the computer has modified with the passage of time as improvement in
technology occurred the better the human computer interaction became. Today we
are facilitated by the operating system that has reduced all the complexity of
hardware and we undergo our computation in a very convenient way irrespective
of the process occurring at the hardware level. Though the human computer
interaction has improved but it's not done yet. If we come to the future the
computer's role in our lives would be a lot more rather our life would be of
the artificial intelligence. In our future the biggest resource would be
component of time and wasting time for a key board entry or a mouse input would
be unbearable so the need would be of the computer interaction environment that
along with the complexity reduction also minimizes the time wastage in the
human computer interaction. Accordingly in our future the computation would
also be increased it would not be a simple operating system limited to a
computer it would be computers managing our entire life activities hence fall
out of domain of present computers electronic based architecture .In this
research paper we propose a model that shall be meeting the future human
computer interaction needs possessing linguistic human computer interference
environment based on surface technology, automation and photonic computing,
which would be reliable, efficient and quicker satisfying all the future
artificial intelligence pre requisites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3894</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3894</id><created>2011-07-20</created><updated>2011-07-27</updated><authors><author><keyname>Khoa</keyname><forenames>Nguyen Lu Dang</forenames></author><author><keyname>Chawla</keyname><forenames>Sanjay</forenames></author></authors><title>Online Anomaly Detection Systems Using Incremental Commute Time</title><categories>cs.AI</categories><comments>11 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commute Time Distance (CTD) is a random walk based metric on graphs. CTD has
found widespread applications in many domains including personalized search,
collaborative filtering and making search engines robust against manipulation.
Our interest is inspired by the use of CTD as a metric for anomaly detection.
It has been shown that CTD can be used to simultaneously identify both global
and local anomalies. Here we propose an accurate and efficient approximation
for computing the CTD in an incremental fashion in order to facilitate
real-time applications. An online anomaly detection algorithm is designed where
the CTD of each new arriving data point to any point in the current graph can
be estimated in constant time ensuring a real-time response. Moreover, the
proposed approach can also be applied in many other applications that utilize
commute time distance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3924</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3924</id><created>2011-07-20</created><authors><author><keyname>zhou</keyname><forenames>Rigui</forenames></author><author><keyname>shi</keyname><forenames>Yang</forenames></author><author><keyname>Zhang</keyname><forenames>Manqun</forenames></author></authors><title>Reversible arithmetic logic unit</title><categories>cs.AR</categories><comments>11 pages, 3 figures, 1 table</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Quantum computer requires quantum arithmetic. The sophisticated design of a
reversible arithmetic logic unit (reversible ALU) for quantum arithmetic has
been investigated in this letter. We provide explicit construction of
reversible ALU effecting basic arithmetic operations. By provided the
corresponding control unit, the proposed reversible ALU can combine the
classical arithmetic and logic operation in a reversible integrated system.
This letter provides actual evidence to prove the possibility of the
realization of reversible Programmable Logic Device (RPLD) using reversible
ALU.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3942</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3942</id><created>2011-07-20</created><authors><author><keyname>Tumminello</keyname><forenames>Michele</forenames></author><author><keyname>Lillo</keyname><forenames>Fabrizio</forenames></author><author><keyname>Piilo</keyname><forenames>Jyrki</forenames></author><author><keyname>Mantegna</keyname><forenames>Rosario N.</forenames></author></authors><title>Identification of clusters of investors from their real trading activity
  in a financial market</title><categories>q-fin.TR cs.SI physics.soc-ph</categories><comments>25 pages, 5 figures</comments><doi>10.1088/1367-2630/14/1/013041</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We use statistically validated networks, a recently introduced method to
validate links in a bipartite system, to identify clusters of investors trading
in a financial market. Specifically, we investigate a special database allowing
to track the trading activity of individual investors of the stock Nokia. We
find that many statistically detected clusters of investors show a very high
degree of synchronization in the time when they decide to trade and in the
trading action taken. We investigate the composition of these clusters and we
find that several of them show an over-expression of specific categories of
investors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3944</identifier>
 <datestamp>2012-11-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3944</id><created>2011-07-20</created><updated>2011-11-23</updated><authors><author><keyname>Rosseel</keyname><forenames>Eveline</forenames></author><author><keyname>Wells</keyname><forenames>Garth N.</forenames></author></authors><title>Optimal control with stochastic PDE constraints and uncertain controls</title><categories>math.OC cs.NA cs.SY</categories><msc-class>49N45, 60H35, 65C30, 65K10, 93E20</msc-class><journal-ref>Computer Methods in Applied Mechanics and Engineering 213-216,
  (2012), pp. 152-167</journal-ref><doi>10.1016/j.cma.2011.11.026</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The optimal control of problems that are constrained by partial differential
equations with uncertainties and with uncertain controls is addressed. The
Lagrangian that defines the problem is postulated in terms of stochastic
functions, with the control function possibly decomposed into an unknown
deterministic component and a known zero-mean stochastic component. The extra
freedom provided by the stochastic dimension in defining cost functionals is
explored, demonstrating the scope for controlling statistical aspects of the
system response. One-shot stochastic finite element methods are used to find
approximate solutions to control problems. It is shown that applying the
stochastic collocation finite element to the formulated problem leads to a
coupling between stochastic collocation points when a deterministic optimal
control is considered or when moments are included in the cost functional,
thereby obviating the primary advantage of the collocation method over the
stochastic Galerkin method for the considered problem. The application of the
presented methods is demonstrated through a number of numerical examples. The
presented framework is sufficiently general to also consider a class of inverse
problems, and numerical examples of this type are also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3977</identifier>
 <datestamp>2013-09-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3977</id><created>2011-07-20</created><updated>2013-09-06</updated><authors><author><keyname>Charbit</keyname><forenames>Pierre</forenames></author><author><keyname>Habib</keyname><forenames>Michel</forenames></author><author><keyname>Trotignon</keyname><forenames>Nicolas</forenames></author><author><keyname>Vu\vskovi&#x107;</keyname><forenames>Kristina</forenames></author></authors><title>Detecting 2-joins faster</title><categories>cs.DS</categories><msc-class>05C85</msc-class><journal-ref>P. Charbit, M. Habib, N. Trotignon and K. Vuskovic. Detecting
  2-joins faster. Journal of Discrete Algorithms, 17:60-66, 2012</journal-ref><doi>10.1016/j.jda.2012.11.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  2-joins are edge cutsets that naturally appear in the decomposition of
several classes of graphs closed under taking induced subgraphs, such as
balanced bipartite graphs, even-hole-free graphs, perfect graphs and claw-free
graphs. Their detection is needed in several algorithms, and is the slowest
step for some of them. The classical method to detect a 2-join takes $O(n^3m)$
time where $n$ is the number of vertices of the input graph and $m$ the number
of its edges. To detect \emph{non-path} 2-joins (special kinds of 2-joins that
are needed in all of the known algorithms that use 2-joins), the fastest known
method takes time $O(n^4m)$. Here, we give an $O(n^2m)$-time algorithm for both
of these problems. A consequence is a speed up of several known algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3979</identifier>
 <datestamp>2011-11-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3979</id><created>2011-07-20</created><updated>2011-11-17</updated><authors><author><keyname>Frasca</keyname><forenames>Paolo</forenames></author></authors><title>Continuous-time quantized consensus: convergence of Krasowskii solutions</title><categories>math.OC cs.SY</categories><comments>12 pages, 1 figure; to appear. This version (v3) is a minor revision
  of v2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note studies a network of agents having continuous-time dynamics with
quantized interactions and time-varying directed topology. Due to the
discontinuity of the dynamics, solutions of the resulting ODE system are
intended in the sense of Krasovskii. A limit connectivity graph is defined,
which encodes persistent interactions between nodes: if such graph has a
globally reachable node, Krasovskii solutions reach consensus (up to the
quantizer precision) after a finite time. Under the additional assumption of a
time-invariant topology, the convergence time is upper bounded by a quantity
which depends on the network size and the quantizer precision. It is observed
that the convergence time can be very large for solutions which stay on a
discontinuity surface.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.3995</identifier>
 <datestamp>2012-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.3995</id><created>2011-07-20</created><updated>2012-06-06</updated><authors><author><keyname>Mukherjee</keyname><forenames>Amitav</forenames></author><author><keyname>Swindlehurst</keyname><forenames>A. Lee</forenames></author></authors><title>Prescient Precoding in Heterogeneous DSA Networks with Both Underlay and
  Interweave MIMO Cognitive Radios</title><categories>cs.IT math.IT</categories><comments>23 pages; Submitted to IEEE Trans. Wireless Commun</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work examines a novel heterogeneous dynamic spectrum access network
where the primary users (PUs) coexist with both underlay and interweave
cognitive radios (ICRs); all terminals being potentially equipped with multiple
antennas. Underlay cognitive transmitters (UCTs) are allowed to transmit
concurrently with PUs subject to interference constraints, while the ICRs
employ spectrum sensing and are permitted to access the shared spectrum only
when both PUs and UCTs are absent. We investigate the design of MIMO precoding
algorithms for the UCT that increase the detection probability at the ICRs,
while simultaneously meeting a desired Quality-of-Service target to the
underlay cognitive receivers (UCRs) and constraining interference leaked to
PUs. The objective of such a proactive approach, referred to as prescient
precoding, is to minimize the probability of interference from ICRs to the UCRs
and primary receivers due to imperfect spectrum sensing. We begin with downlink
prescient precoding algorithms for multiple single-antenna UCRs and
multi-antenna PUs/ICRs. We then present prescient block-diagonalization
algorithms for the MIMO underlay downlink where spatial multiplexing is
performed for a plurality of multi-antenna UCRs. Numerical experiments
demonstrate that prescient precoding by UCTs provides a pronounced performance
gain compared to conventional underlay precoding strategies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4009</identifier>
 <datestamp>2012-02-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4009</id><created>2011-07-20</created><updated>2012-02-08</updated><authors><author><keyname>Grabowicz</keyname><forenames>Przemyslaw A.</forenames></author><author><keyname>Ramasco</keyname><forenames>Jose J.</forenames></author><author><keyname>Moro</keyname><forenames>Esteban</forenames></author><author><keyname>Pujol</keyname><forenames>Josep</forenames></author><author><keyname>Eguiluz</keyname><forenames>Victor M.</forenames></author></authors><title>Social features of online networks: the strength of intermediary ties in
  online social media</title><categories>physics.soc-ph cs.SI</categories><comments>14 pages, 18 figures</comments><journal-ref>PLoS ONE 7, e29358 (2012)</journal-ref><doi>10.1371/journal.pone.0029358</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An increasing fraction of today social interactions occur using online social
media as communication channels. Recent worldwide events, such as social
movements in Spain or revolts in the Middle East, highlight their capacity to
boost people coordination. Online networks display in general a rich internal
structure where users can choose among different types and intensity of
interactions. Despite of this, there are still open questions regarding the
social value of online interactions. For example, the existence of users with
millions of online friends sheds doubts on the relevance of these relations. In
this work, we focus on Twitter, one of the most popular online social networks,
and find that the network formed by the basic type of connections is organized
in groups. The activity of the users conforms to the landscape determined by
such groups. Furthermore, Twitter's distinction between different types of
interactions allows us to establish a parallelism between online and offline
social networks: personal interactions are more likely to occur on internal
links to the groups (the weakness of strong ties), events transmitting new
information go preferentially through links connecting different groups (the
strength of weak ties) or even more through links connecting to users belonging
to several groups that act as brokers (the strength of intermediary ties).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4016</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4016</id><created>2011-07-20</created><authors><author><keyname>Miranskyy</keyname><forenames>Andriy V.</forenames></author><author><keyname>Davison</keyname><forenames>Matthew</forenames></author><author><keyname>Reesor</keyname><forenames>Mark</forenames></author></authors><title>Metrics of Risk Associated with Defects Rediscovery</title><categories>cs.SE stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software defects rediscovered by a large number of customers affect various
stakeholders and may: 1) hint at gaps in a software manufacturer's Quality
Assurance (QA) processes, 2) lead to an over-load of a software manufacturer's
support and maintenance teams, and 3) consume customers' resources, leading to
a loss of reputation and a decrease in sales.
  Quantifying risk associated with the rediscovery of defects can help all of
these stake-holders. In this chapter we present a set of metrics needed to
quantify the risks. The metrics are designed to help: 1) the QA team to assess
their processes; 2) the support and maintenance teams to allocate their
resources; and 3) the customers to assess the risk associated with using the
software product. The paper includes a validation case study which applies the
risk metrics to industrial data. To calculate the metrics we use mathematical
instruments like the heavy-tailed Kappa distribution and the G/M/k queuing
model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4021</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4021</id><created>2011-07-20</created><authors><author><keyname>Singh</keyname><forenames>Arun</forenames></author><author><keyname>Elia</keyname><forenames>Petros</forenames></author><author><keyname>Jalden</keyname><forenames>Joakim</forenames></author></authors><title>Achieving a vanishing SNR-gap to exact lattice decoding at a
  subexponential complexity</title><categories>cs.IT cs.CC math.IT</categories><comments>16 pages - submission for IEEE Trans. Inform. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The work identifies the first lattice decoding solution that achieves, in the
general outage-limited MIMO setting and in the high-rate and high-SNR limit,
both a vanishing gap to the error-performance of the (DMT optimal) exact
solution of preprocessed lattice decoding, as well as a computational
complexity that is subexponential in the number of codeword bits. The proposed
solution employs lattice reduction (LR)-aided regularized (lattice) sphere
decoding and proper timeout policies. These performance and complexity
guarantees hold for most MIMO scenarios, all reasonable fading statistics, all
channel dimensions and all full-rate lattice codes.
  In sharp contrast to the above manageable complexity, the complexity of other
standard preprocessed lattice decoding solutions is shown here to be extremely
high. Specifically the work is first to quantify the complexity of these
lattice (sphere) decoding solutions and to prove the surprising result that the
complexity required to achieve a certain rate-reliability performance, is
exponential in the lattice dimensionality and in the number of codeword bits,
and it in fact matches, in common scenarios, the complexity of ML-based
solutions. Through this sharp contrast, the work was able to, for the first
time, rigorously quantify the pivotal role of lattice reduction as a special
complexity reducing ingredient.
  Finally the work analytically refines transceiver DMT analysis which
generally fails to address potentially massive gaps between theory and
practice. Instead the adopted vanishing gap condition guarantees that the
decoder's error curve is arbitrarily close, given a sufficiently high SNR, to
the optimal error curve of exact solutions, which is a much stronger condition
than DMT optimality which only guarantees an error gap that is subpolynomial in
SNR, and can thus be unbounded and generally unacceptable in practical
settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4035</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4035</id><created>2011-07-20</created><updated>2011-07-21</updated><authors><author><keyname>Poole</keyname><forenames>David</forenames></author><author><keyname>Bacchus</keyname><forenames>Fahiem</forenames></author><author><keyname>Kisynski</keyname><forenames>Jacek</forenames></author></authors><title>Towards Completely Lifted Search-based Probabilistic Inference</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The promise of lifted probabilistic inference is to carry out probabilistic
inference in a relational probabilistic model without needing to reason about
each individual separately (grounding out the representation) by treating the
undistinguished individuals as a block. Current exact methods still need to
ground out in some cases, typically because the representation of the
intermediate results is not closed under the lifted operations. We set out to
answer the question as to whether there is some fundamental reason why lifted
algorithms would need to ground out undifferentiated individuals. We have two
main results: (1) We completely characterize the cases where grounding is
polynomial in a population size, and show how we can do lifted inference in
time polynomial in the logarithm of the population size for these cases. (2)
For the case of no-argument and single-argument parametrized random variables
where the grounding is not polynomial in a population size, we present lifted
inference which is polynomial in the population size whereas grounding is
exponential. Neither of these cases requires reasoning separately about the
individuals that are not explicitly mentioned.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4042</identifier>
 <datestamp>2015-01-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4042</id><created>2011-07-20</created><updated>2015-01-29</updated><authors><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Optimal Adaptive Learning in Uncontrolled Restless Bandit Problems</title><categories>math.OC cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of learning the optimal policy for
uncontrolled restless bandit problems. In an uncontrolled restless bandit
problem, there is a finite set of arms, each of which when pulled yields a
positive reward. There is a player who sequentially selects one of the arms at
each time step. The goal of the player is to maximize its undiscounted reward
over a time horizon T. The reward process of each arm is a finite state Markov
chain, whose transition probabilities are unknown by the player. State
transitions of each arm is independent of the selection of the player. We
propose a learning algorithm with logarithmic regret uniformly over time with
respect to the optimal finite horizon policy. Our results extend the optimal
adaptive learning of MDPs to POMDPs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4054</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4054</id><created>2011-07-20</created><authors><author><keyname>Ramachandran</keyname><forenames>Sumalatha</forenames></author><author><keyname>Sridhar</keyname><forenames>Uttara</forenames></author><author><keyname>Srinivasan</keyname><forenames>Vidhya</forenames></author><author><keyname>Jothi</keyname><forenames>J. Jaya</forenames></author></authors><title>Data Aggregation and Privacy for Police Patrols</title><categories>cs.CR</categories><comments>12 pages, 5 figures</comments><journal-ref>International Journal of Ad hoc, Sensor &amp; Ubiquitous Computing
  (IJASUC) Vol.2, No.2, June 2011, 51-62</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  With a widespread growth in the potential applications of Wireless Sensor
Networks, the need for reliable security mechanisms for them has increased
manifold. This paper proposes a scheme, Privacy for Police Patrols (PPP), to
provide secure data aggregation that relies on multilevel routing. Privacy
factors have been identified and implemented. Aggregates are prepared and the
summary of information is gathered and stored in a repository. The above
defined approaches are integrated in police patrol applications and preliminary
results are obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4057</identifier>
 <datestamp>2011-10-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4057</id><created>2011-07-20</created><authors><author><keyname>Loghmani</keyname><forenames>Nick Mehrdad</forenames></author></authors><title>The Harmonic Theory; A mathematical framework to build intelligent
  contextual and adaptive computing, cognition and sensory system</title><categories>cs.AI cs.IT math.IT</categories><comments>16 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Harmonic theory provides a mathematical framework to describe the structure,
behavior, evolution and emergence of harmonic systems. A harmonic system is
context aware, contains elements that manifest characteristics either
collaboratively or independently according to system's expression and can
interact with its environment. This theory provides a fresh way to analyze
emergence and collaboration of &quot;ad-hoc&quot; and complex systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4062</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4062</id><created>2011-07-20</created><authors><author><keyname>Bialczak</keyname><forenames>Piotr</forenames></author><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Sending Hidden Data via Google Suggest</title><categories>cs.CR</categories><comments>11 pages, 17 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Google Suggest is a service incorporated within Google Web Search which was
created to help user find the right search phrase by proposing the
autocompleting popular phrases while typing. The paper presents a new network
steganography method called StegSuggest which utilizes suggestions generated by
Google Suggest as a hidden data carrier. The detailed description of the
method's idea is backed up with the analysis of the network traffic generated
by the Google Suggest to prove its feasibility. The traffic analysis was also
performed to discover the occurrence of two TCP options: Window Scale and
Timestamp which StegSuggest uses to operate. Estimation of method
steganographic bandwidth proves that it is possible to insert 100 bits of
steganogram into every suggestions list sent by Google Suggest service.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4065</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4065</id><created>2011-07-20</created><authors><author><keyname>Fraczek</keyname><forenames>Wojciech</forenames></author><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>How Hidden Can Be Even More Hidden?</title><categories>cs.CR</categories><comments>5 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents Deep Hiding Techniques (DHTs) that define general
techniques that can be applied to every network steganography method to improve
its undetectability and make steganogram extraction harder to perform. We
define five groups of techniques that can make steganogram less susceptible to
detection and extraction. For each of the presented group, examples of the
usage are provided based on existing network steganography methods. To authors'
best knowledge presented approach is the first attempt in the state of the art
to systematically describe general solutions that can make steganographic
communication more hidden and steganogram extraction harder to perform.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4067</identifier>
 <datestamp>2013-04-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4067</id><created>2011-07-20</created><updated>2012-03-17</updated><authors><author><keyname>Vats</keyname><forenames>Divyanshu</forenames></author><author><keyname>Moura</keyname><forenames>Jos&#xe9; M. F.</forenames></author></authors><title>Finding Non-overlapping Clusters for Generalized Inference Over
  Graphical Models</title><categories>stat.ML cs.IT math.IT</categories><comments>Extended the previous version to include extensive numerical
  simulations. See http://www.ima.umn.edu/~dvats/GeneralizedInference.html for
  code and data</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 60, no. 12, pp
  6368-6381, Dec 2012</journal-ref><doi>10.1109/TSP.2012.2214216</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graphical models use graphs to compactly capture stochastic dependencies
amongst a collection of random variables. Inference over graphical models
corresponds to finding marginal probability distributions given joint
probability distributions. In general, this is computationally intractable,
which has led to a quest for finding efficient approximate inference
algorithms. We propose a framework for generalized inference over graphical
models that can be used as a wrapper for improving the estimates of approximate
inference algorithms. Instead of applying an inference algorithm to the
original graph, we apply the inference algorithm to a block-graph, defined as a
graph in which the nodes are non-overlapping clusters of nodes from the
original graph. This results in marginal estimates of a cluster of nodes, which
we further marginalize to get the marginal estimates of each node. Our proposed
block-graph construction algorithm is simple, efficient, and motivated by the
observation that approximate inference is more accurate on graphs with longer
cycles. We present extensive numerical simulations that illustrate our
block-graph framework with a variety of inference algorithms (e.g., those in
the libDAI software package). These simulations show the improvements provided
by our framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4076</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4076</id><created>2011-07-20</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author></authors><title>Lost Audio Packets Steganography: The First Practical Evaluation</title><categories>cs.CR cs.MM</categories><comments>13 pages, 6 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents first experimental results for an IP telephony-based
steganographic method called LACK (Lost Audio PaCKets steganography). This
method utilizes the fact that in typical multimedia communication protocols
like RTP (Real-Time Transport Protocol), excessively delayed packets are not
used for the reconstruction of transmitted data at the receiver, i.e. these
packets are considered useless and discarded. The results presented in this
paper were obtained basing on a functional LACK prototype and show the method's
impact on the quality of voice transmission. Achievable steganographic
bandwidth for the different IP telephony codecs is also calculated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4077</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4077</id><created>2011-07-20</created><authors><author><keyname>Mazurczyk</keyname><forenames>Wojciech</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Is Cloud Computing Steganography-proof?</title><categories>cs.CR</categories><comments>2 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper focuses on characterisation of information hiding possibilities in
Cloud Computing. After general introduction to cloud computing and its security
we move to brief description of steganography. In particular we introduce
classification of steganographic communication scenarios in cloud computing
which is based on location of the steganograms receiver. These scenarios as
well as the threats that steganographic methods can cause must be taken into
account when designing secure cloud computing services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4080</identifier>
 <datestamp>2011-07-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4080</id><created>2011-07-20</created><authors><author><keyname>Srebro</keyname><forenames>Nathan</forenames></author><author><keyname>Sridharan</keyname><forenames>Karthik</forenames></author><author><keyname>Tewari</keyname><forenames>Ambuj</forenames></author></authors><title>On the Universality of Online Mirror Descent</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that for a general class of convex online learning problems, Mirror
Descent can always achieve a (nearly) optimal regret guarantee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4104</identifier>
 <datestamp>2013-12-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4104</id><created>2011-07-18</created><authors><author><keyname>Zhang</keyname><forenames>Jiapu</forenames></author><author><keyname>Gao</keyname><forenames>David Y.</forenames></author><author><keyname>Yearwood</keyname><forenames>Johh</forenames></author></authors><title>A novel canonical dual computational approach for prion AGAAAAGA amyloid
  fibril molecular modeling</title><categories>q-bio.BM cs.CE math-ph math.MP math.OC</categories><journal-ref>J Theor Biol 284 (1) 149-157 (2011); selected by Protein
  Crystallography Newsletter Volume 3, No. 9, September 2011, Crystallography
  Times; Prions Research Today Volume 7 Issue 7, July 2011, p.14; the 18th of
  the Top 25 Hottest Articles (picked up from papers of Jul 2011 to Sept 2011
  of J Theor Biol)</journal-ref><doi>10.1016/j.jtbi.2011.06.024</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Many experimental studies have shown that the prion AGAAAAGA palindrome
hydrophobic region (113-120) has amyloid fibril forming properties and plays an
important role in prion diseases. However, due to the unstable, noncrystalline
and insoluble nature of the amyloid fibril, to date structural information on
AGAAAAGA region (113-120) has been very limited. This region falls just within
the N-terminal unstructured region PrP (1-123) of prion proteins. Traditional
X-ray crystallography and nuclear magnetic resonance (NMR) spectroscopy
experimental methods cannot be used to get its structural information. Under
this background, this paper introduces a novel approach of the canonical dual
theory to address the 3D atomic-resolution structure of prion AGAAAAGA amyloid
fibrils. The novel and powerful canonical dual computational approach
introduced in this paper is for the molecular modeling of prion AGAAAAGA
amyloid fibrils, and that the optimal atomic-resolution structures of prion
AGAAAAGA amyloid fibils presented in this paper are useful for the drive to
find treatments for prion diseases in the field of medicinal chemistry.
Overall, this paper presents an important method and provides useful
information for treatments of prion diseases. Overall, this paper could be of
interest to the general readership of Theoretical Biology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4110</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4110</id><created>2011-07-20</created><authors><author><keyname>Astudillo</keyname><forenames>Carlos A.</forenames></author><author><keyname>Calder&#xf3;n</keyname><forenames>Oscar J.</forenames></author><author><keyname>Ortiz</keyname><forenames>Jes&#xfa;s H.</forenames></author></authors><title>PM2PLS: An Integration of Proxy Mobile IPv6 and MPLS</title><categories>cs.NI</categories><comments>9 Pages, 8 Figures, 9 Tables</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 3, No. 1, May 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a handover scheme supporting Multi-Protocol Label
Switching (MPLS) in a Proxy Mobile IPv6 (PMIPv6) domain that improves the
mobility and gives Quality of Service (QoS) and Traffic Engineering (TE)
capabilities in wireless access networks. The proposed scheme takes advantages
of both PMIPv6 and MPLS. PMIPv6 was designed to provide NETwork-based Localized
Mobility Management (NETLMM) support to a Mobile Node (MN); therefore, the MN
does not perform any mobility related signaling, while MPLS is used as an
alternative tunneling technology between the Mobile Access Gateway (MAG) and
the Local Mobility Anchor (LMA) replacing the IP-in-IP tunnels with Label
Switched Path (LSP) tunnels. It can also be integrated with other QoS
architectures such as Differentiated Services (DiffServ) and/or Integrated
Services (IntServ). In this study, we used MATLAB to perform an analysis to
evaluate the impact of introducing MPLS technology in PMIPv6 domain based on
handover latency, operational overhead and packet loss during the handover.
This was compared with PMIPv6, and a PMIPv6/MPLS integration. We proved that
the proposed scheme can give better performance than other schemes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4113</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4113</id><created>2011-07-20</created><updated>2011-08-02</updated><authors><author><keyname>Eschenfeldt</keyname><forenames>Patrick</forenames></author><author><keyname>Gross</keyname><forenames>Ben</forenames></author><author><keyname>Pippenger</keyname><forenames>Nicholas</forenames></author></authors><title>Stochastic Service Systems, Random Interval Graphs and Search Algorithms</title><categories>math.PR cs.CC math.CO</categories><comments>i+21 pp</comments><msc-class>60K26, 90B22</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider several stochastic service systems, and study the asymptotic
behavior of the moments of various quantities that have application to models
for random interval graphs and algorithms for searching for an idle server or
empty waiting station. In two cases the moments turn out to involve Lambert
series for the generating functions for the sums of powers of divisors of
positive integers. For these cases we are able to obtain complete asymptotic
expansions for the moments of the quantities in question.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4118</identifier>
 <datestamp>2013-01-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4118</id><created>2011-07-20</created><updated>2012-03-25</updated><authors><author><keyname>Law</keyname><forenames>K. J. H.</forenames></author><author><keyname>Stuart</keyname><forenames>A. M.</forenames></author></authors><title>Evaluating Data Assimilation Algorithms</title><categories>physics.data-an cs.SY math.OC math.PR physics.ao-ph</categories><journal-ref>Monthly Weather Review, Volume 140, Issue 11 (2012) pp. 3757-3782</journal-ref><doi>10.1175/MWR-D-11-00257.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data assimilation leads naturally to a Bayesian formulation in which the
posterior probability distribution of the system state, given the observations,
plays a central conceptual role. The aim of this paper is to use this Bayesian
posterior probability distribution as a gold standard against which to evaluate
various commonly used data assimilation algorithms.
  A key aspect of geophysical data assimilation is the high dimensionality and
low predictability of the computational model. With this in mind, yet with the
goal of allowing an explicit and accurate computation of the posterior
distribution, we study the 2D Navier-Stokes equations in a periodic geometry.
We compute the posterior probability distribution by state-of-the-art
statistical sampling techniques. The commonly used algorithms that we evaluate
against this accurate gold standard, as quantified by comparing the relative
error in reproducing its moments, are 4DVAR and a variety of sequential
filtering approximations based on 3DVAR and on extended and ensemble Kalman
filters.
  The primary conclusions are that: (i) with appropriate parameter choices,
approximate filters can perform well in reproducing the mean of the desired
probability distribution; (ii) however they typically perform poorly when
attempting to reproduce the covariance; (iii) this poor performance is
compounded by the need to modify the covariance, in order to induce stability.
Thus, whilst filters can be a useful tool in predicting mean behavior, they
should be viewed with caution as predictors of uncertainty. These conclusions
are intrinsic to the algorithms and will not change if the model complexity is
increased, for example by employing a smaller viscosity, or by using a detailed
NWP model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4127</identifier>
 <datestamp>2011-12-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4127</id><created>2011-07-20</created><authors><author><keyname>Metz</keyname><forenames>F. L.</forenames></author><author><keyname>Neri</keyname><forenames>I.</forenames></author><author><keyname>Boll&#xe9;</keyname><forenames>D.</forenames></author></authors><title>Spectra of sparse regular graphs with loops</title><categories>cond-mat.stat-mech cond-mat.dis-nn cs.SI math-ph math.MP physics.soc-ph</categories><comments>4 pages, 4 figures</comments><journal-ref>Phys. Rev. E 84, 055101(R) (2011)</journal-ref><doi>10.1103/PhysRevE.84.055101</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive exact equations that determine the spectra of undirected and
directed sparsely connected regular graphs containing loops of arbitrary
length. The implications of our results to the structural and dynamical
properties of networks are discussed by showing how loops influence the size of
the spectral gap and the propensity for synchronization. Analytical formulas
for the spectrum are obtained for specific length of the loops.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4132</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4132</id><created>2011-07-20</created><updated>2011-07-24</updated><authors><author><keyname>Apraiz</keyname><forenames>J.</forenames></author><author><keyname>Escauriaza</keyname><forenames>L.</forenames></author></authors><title>Null-Control and Measurable Sets</title><categories>math.OC cs.SY</categories><comments>Two remarks added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove the interior and boundary null-controllability of some parabolic
evolutions with controls acting over measurable sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4138</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4138</id><created>2011-07-20</created><updated>2011-07-22</updated><authors><author><keyname>Geeraerts</keyname><forenames>Gilles</forenames></author><author><keyname>Raskin</keyname><forenames>Jean-Fran&#xe7;ois</forenames></author><author><keyname>Sznajder</keyname><forenames>Nathalie</forenames></author></authors><title>Event-Clock Automata: From Theory to Practice</title><categories>cs.LO</categories><comments>Full version of the FORMATS 2011 version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Event clock automata (ECA) are a model for timed languages that has been
introduced by Alur, Fix and Henzinger as an alternative to timed automata, with
better theoretical properties (for instance, ECA are determinizable while timed
automata are not). In this paper, we revisit and extend the theory of ECA. We
first prove that no finite time abstract language equivalence exists for ECA,
thereby disproving a claim in the original work on ECA. This means in
particular that regions do not form a time abstract bisimulation. Nevertheless,
we show that regions can still be used to build a finite automaton recognizing
the untimed language of an ECA. Then, we extend the classical notions of zones
and DBMs to let them handle event clocks instead of plain clocks (as in timed
automata) by introducing event zones and Event DBMs (EDBMs). We discuss
algorithms to handle event zones represented as EDBMs, as well as (semi-)
algorithms based on EDBMs to decide language emptiness of ECA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4142</identifier>
 <datestamp>2013-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4142</id><created>2011-07-20</created><updated>2013-01-23</updated><authors><author><keyname>Borkar</keyname><forenames>Vivek S.</forenames></author><author><keyname>Sundaresan</keyname><forenames>Rajesh</forenames></author></authors><title>Asymptotics of the Invariant Measure in Mean Field Models with Jumps</title><categories>math.PR cs.IT cs.SY math.IT math.OC</categories><comments>58 pages, reorganised to get quickly to the main results on invariant
  measure; Stochastic Systems, volume 2, 2012</comments><doi>10.1214/12-SSY64</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the asymptotics of the invariant measure for the process of the
empirical spatial distribution of $N$ coupled Markov chains in the limit of a
large number of chains. Each chain reflects the stochastic evolution of one
particle. The chains are coupled through the dependence of the transition rates
on this spatial distribution of particles in the various states. Our model is a
caricature for medium access interactions in wireless local area networks. It
is also applicable to the study of spread of epidemics in a network. The
limiting process satisfies a deterministic ordinary differential equation
called the McKean-Vlasov equation. When this differential equation has a unique
globally asymptotically stable equilibrium, the spatial distribution
asymptotically concentrates on this equilibrium. More generally, its limit
points are supported on a subset of the $\omega$-limit sets of the
McKean-Vlasov equation. Using a control-theoretic approach, we examine the
question of large deviations of the invariant measure from this limit.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4148</identifier>
 <datestamp>2013-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4148</id><created>2011-07-20</created><updated>2013-10-10</updated><authors><author><keyname>Chou</keyname><forenames>Tzu-Han</forenames></author><author><keyname>Tan</keyname><forenames>Vincent Y. F.</forenames></author><author><keyname>Draper</keyname><forenames>Stark C.</forenames></author></authors><title>The Sender-Excited Secret Key Agreement Model: Capacity, Reliability and
  Secrecy Exponents</title><categories>cs.IT cs.CR math.IT</categories><comments>18 pages, 8 figures; Submitted to the IEEE Transactions on
  Information Theory; Revised in Oct 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the secret key generation problem when sources are randomly
excited by the sender and there is a noiseless public discussion channel. Our
setting is thus similar to recent works on channels with action-dependent
states where the channel state may be influenced by some of the parties
involved. We derive single-letter expressions for the secret key capacity
through a type of source emulation analysis. We also derive lower bounds on the
achievable reliability and secrecy exponents, i.e., the exponential rates of
decay of the probability of decoding error and of the information leakage.
These exponents allow us to determine a set of strongly-achievable secret key
rates. For degraded eavesdroppers the maximum strongly-achievable rate equals
the secret key capacity; our exponents can also be specialized to previously
known results.
  In deriving our strong achievability results we introduce a coding scheme
that combines wiretap coding (to excite the channel) and key extraction (to
distill keys from residual randomness). The secret key capacity is naturally
seen to be a combination of both source- and channel-type randomness. Through
examples we illustrate a fundamental interplay between the portion of the
secret key rate due to each type of randomness. We also illustrate inherent
tradeoffs between the achievable reliability and secrecy exponents. Our new
scheme also naturally accommodates rate limits on the public discussion. We
show that under rate constraints we are able to achieve larger rates than those
that can be attained through a pure source emulation strategy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4150</identifier>
 <datestamp>2015-01-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4150</id><created>2011-07-20</created><authors><author><keyname>Huang</keyname><forenames>Wenqi</forenames></author><author><keyname>He</keyname><forenames>Kun</forenames></author></authors><title>Analysis on the computability over the efficient utilization problem of
  the four-dimensional space-time</title><categories>cs.CC</categories><comments>13 pages, 3 figures</comments><msc-class>03D15, 03D78, 52C17, 90B35</msc-class><journal-ref>Theoretical Computer Science, vol. 501(27): 1-10, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper formally proposes a problem about the efficient utilization of the
four dimensional space-time. Given a cuboid container, a finite number of rigid
cuboid items, and the time length that each item should be continuous baked in
the container, the problem asks to arrange the starting time for each item
being placed into the container and to arrange the position and orientation for
each item at each instant during its continuous baking period such that the
total time length the container be utilized is as short as possible. Here all
side dimensions of the container and of the items are positive real numbers
arbitrarily given. Differs from the classical packing problems, the position
and orientation of each item in the container could be changed over time.
Therefore, according to above mathematical model, the four-dimensional
space-time can be utilized more truly and more fully. This paper then proves
that there exists an exact algorithm that could solve the problem by finite
operations, so we say this problem is weak computable. Based on the
understanding of this computability proof, it is expected to design effective
approximate algorithms in the near future. A piggyback work completed is a
strict proof on the weak computability over general and natural case of the
three-dimensional cuboid packing decision problem that all parameters are
positive real numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4153</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4153</id><created>2011-07-21</created><authors><author><keyname>Tekin</keyname><forenames>Cem</forenames></author><author><keyname>Liu</keyname><forenames>Mingyan</forenames></author></authors><title>Performance and Convergence of Multi-user Online Learning</title><categories>cs.MA cs.LG</categories><journal-ref>in Proceedings of GAMENETS 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of allocating multiple users to a set of wireless
channels in a decentralized manner when the channel quali- ties are
time-varying and unknown to the users, and accessing the same channel by
multiple users leads to reduced quality due to interference. In such a setting
the users not only need to learn the inherent channel quality and at the same
time the best allocations of users to channels so as to maximize the social
welfare. Assuming that the users adopt a certain online learning algorithm, we
investigate under what conditions the socially optimal allocation is
achievable. In particular we examine the e?ect of di?erent levels of knowledge
the users may have and the amount of communications and cooperation. The
general conclusion is that when the cooperation of users decreases and the
uncertainty about channel payoffs increases it becomes harder to achieve the
socially opti- mal allocation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4157</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4157</id><created>2011-07-21</created><authors><author><keyname>Gasilov</keyname><forenames>Nizami</forenames></author><author><keyname>Amrahov</keyname><forenames>&#x15e;ahin Emrah</forenames></author><author><keyname>Fatullayev</keyname><forenames>Afet Golayo&#x11f;lu</forenames></author></authors><title>Linear Differential Equations with Fuzzy Boundary Values</title><categories>cs.NA cs.CE math.DS math.NA</categories><comments>5 pages, 2 figures</comments><msc-class>03E72, 34B05, 65L10</msc-class><acm-class>G.1.7; F.4.1; G.1.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this study, we consider a linear differential equation with fuzzy boundary
values. We express the solution of the problem in terms of a fuzzy set of crisp
real functions. Each real function from the solution set satisfies differential
equation, and its boundary values belong to intervals, determined by the
corresponding fuzzy numbers. The least possibility among possibilities of
boundary values in corresponding fuzzy sets is defined as the possibility of
the real function in the fuzzy solution. In order to find the fuzzy solution we
propose a method based on the properties of linear transformations. We show
that, if the corresponding crisp problem has a unique solution then the fuzzy
problem has unique solution too. We also prove that if the boundary values are
triangular fuzzy numbers, then the value of the solution at any time is also a
triangular fuzzy number. We find that the fuzzy solution determined by our
method is the same as the one that is obtained from solution of crisp problem
by the application of the extension principle. We present two examples
describing the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4160</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4160</id><created>2011-07-21</created><authors><author><keyname>Beffara</keyname><forenames>Emmanuel</forenames><affiliation>IML</affiliation></author></authors><title>Functions as proofs as processes</title><categories>cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a logical approach to the translation of functional
calculi into concurrent process calculi. The starting point is a type system
for the {\pi}-calculus closely related to linear logic. Decompositions of
intuitionistic and classical logics into this system provide type-preserving
translations of the \lambda- and \lambda\mu-calculus, both for call-by-name and
call-by-value evaluation strategies. Previously known encodings of the
\lam-calculus are shown to correspond to particular cases of this logical
embedding. The realisability interpretation of types in the \pi-calculus
provides systematic soundness arguments for these translations and allows for
the definition of type-safe extensions of functional calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4161</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4161</id><created>2011-07-21</created><authors><author><keyname>Daolio</keyname><forenames>Fabio</forenames><affiliation>ISI</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames><affiliation>ISI</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author></authors><title>Local Optima Networks of the Quadratic Assignment Problem</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>IEEE world conference on computational intelligence (WCCI - CEC),
  Barcelona : Spain (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using a recently proposed model for combinatorial landscapes, Local Optima
Networks (LON), we conduct a thorough analysis of two types of instances of the
Quadratic Assignment Problem (QAP). This network model is a reduction of the
landscape in which the nodes correspond to the local optima, and the edges
account for the notion of adjacency between their basins of attraction. The
model was inspired by the notion of 'inherent network' of potential energy
surfaces proposed in physical-chemistry. The local optima networks extracted
from the so called uniform and real-like QAP instances, show features clearly
distinguishing these two types of instances. Apart from a clear confirmation
that the search difficulty increases with the problem dimension, the analysis
provides new confirming evidence explaining why the real-like instances are
easier to solve exactly using heuristic search, while the uniform instances are
easier to solve approximately. Although the local optima network model is still
under development, we argue that it provides a novel view of combinatorial
landscapes, opening up the possibilities for new analytical tools and
understanding of problem difficulty in combinatorial optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4162</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4162</id><created>2011-07-21</created><authors><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>INRIA Lille - Nord Europe</affiliation></author><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames><affiliation>ISI</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author></authors><title>Local Optima Networks of NK Landscapes with Neutrality</title><categories>cs.AI</categories><comments>IEEE Transactions on Evolutionary Computation volume 14, 6 (2010) to
  appear</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In previous work we have introduced a network-based model that abstracts many
details of the underlying landscape and compresses the landscape information
into a weighted, oriented graph which we call the local optima network. The
vertices of this graph are the local optima of the given fitness landscape,
while the arcs are transition probabilities between local optima basins. Here
we extend this formalism to neutral fitness landscapes, which are common in
difficult combinatorial search spaces. By using two known neutral variants of
the NK family (i.e. NKp and NKq) in which the amount of neutrality can be tuned
by a parameter, we show that our new definitions of the optima networks and the
associated basins are consistent with the previous definitions for the
non-neutral case. Moreover, our empirical study and statistical analysis show
that the features of neutral landscapes interpolate smoothly between landscapes
with maximum neutrality and non-neutral ones. We found some unknown structural
differences between the two studied families of neutral landscapes. But
overall, the network features studied confirmed that neutrality, in landscapes
with percolating neutral networks, may enhance heuristic search. Our current
methodology requires the exhaustive enumeration of the underlying search space.
Therefore, sampling techniques should be developed before this analysis can
have practical implications. We argue, however, that the proposed model offers
a new perspective into the problem difficulty of combinatorial optimization
problems and may inspire the design of more effective search heuristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4163</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4163</id><created>2011-07-21</created><authors><author><keyname>Simoncini</keyname><forenames>David</forenames></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames></author><author><keyname>Collard</keyname><forenames>Philippe</forenames></author><author><keyname>Clergue</keyname><forenames>Manuel</forenames></author></authors><title>Centric selection: a way to tune the exploration/exploitation trade-off</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>GECCO'09, Montreal : Canada (2009)</journal-ref><doi>10.1145/1569901.1570023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the exploration / exploitation trade-off in cellular
genetic algorithms. We define a new selection scheme, the centric selection,
which is tunable and allows controlling the selective pressure with a single
parameter. The equilibrium model is used to study the influence of the centric
selection on the selective pressure and a new model which takes into account
problem dependent statistics and selective pressure in order to deal with the
exploration / exploitation trade-off is proposed: the punctuated equilibria
model. Performances on the quadratic assignment problem and NK-Landscapes put
in evidence an optimal exploration / exploitation trade-off on both of the
classes of problems. The punctuated equilibria model is used to explain these
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4164</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4164</id><created>2011-07-21</created><authors><author><keyname>Vanneschi</keyname><forenames>Leonardo</forenames><affiliation>DISCo</affiliation></author><author><keyname>Verel</keyname><forenames>S&#xe9;bastien</forenames><affiliation>ISI</affiliation></author><author><keyname>Collard</keyname><forenames>Philippe</forenames><affiliation>ISI</affiliation></author><author><keyname>Tomassini</keyname><forenames>Marco</forenames><affiliation>ISI</affiliation></author></authors><title>NK landscapes difficulty and Negative Slope Coefficient: How Sampling
  Influences the Results</title><categories>cs.AI</categories><proxy>ccsd</proxy><journal-ref>evoNum workshop of evostar conference, Tubingen : Germany (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Negative Slope Coefficient is an indicator of problem hardness that has been
introduced in 2004 and that has returned promising results on a large set of
problems. It is based on the concept of fitness cloud and works by partitioning
the cloud into a number of bins representing as many different regions of the
fitness landscape. The measure is calculated by joining the bins centroids by
segments and summing all their negative slopes. In this paper, for the first
time, we point out a potential problem of the Negative Slope Coefficient: we
study its value for different instances of the well known NK-landscapes and we
show how this indicator is dramatically influenced by the minimum number of
points contained into a bin. Successively, we formally justify this behavior of
the Negative Slope Coefficient and we discuss pros and cons of this measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4171</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4171</id><created>2011-07-21</created><authors><author><keyname>Farooq</keyname><forenames>Umer</forenames></author><author><keyname>Iqbal</keyname><forenames>M. Aqeel</forenames></author></authors><title>Next Generation High Speed Computing Using Photonic Based Technolog</title><categories>cs.ET</categories><comments>8 pages, 9 figures, published in (IJCSE) International Journal on
  Computer Science and Engineering Vol. 02, No. 05, 2010, 1496-1503</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the present era of technology computer has facilitated the human life up
to a great extent. The speed of computation has raised to astonish level but
the pace of development of other technologies which have core dependency over
computers have raised relatively exponentially huge, though the computer speed
of computation is very fast with respect to human abilities but still it has to
be increased a lot more to meet the future requirements. We have pushed
electrons to their maximum limit to a stage that nothing further could be
expected from electrons. Alternately one can use photon to replace the
relatively sluggish electrons. An alternate that posses all feature that an
electron holds but only millions of time faster and with a far more reliability
in one way or the other stretching the computers speed to a stage that no one
would have ever even wonder. In this research paper the photonics
implementations in computation industry have been presented along with its
scope as an alternate to electron with comparative study of electron and photon
under the computation perspective, generalized working of silicon based optical
computers, the application of photons and their crucial role in the upcoming
times. Keywords: Photonic Technology, H
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4185</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4185</id><created>2011-07-21</created><authors><author><keyname>Gudi</keyname><forenames>Anandthirtha B.</forenames></author><author><keyname>Shreedhar</keyname><forenames>H. K.</forenames></author><author><keyname>Nagaraj</keyname><forenames>H. C.</forenames></author></authors><title>Estimation of Severity of Speech Disability through Speech Envelope</title><categories>cs.SD</categories><comments>8 pages,4 Figures,Signal &amp; Image Processing Journal AIRCC</comments><journal-ref>Signal &amp; Image Processing : An International Journal (SIPIJ)
  Vol.2, No.2, June 2011</journal-ref><doi>10.5121/sipij.2011.2203</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, envelope detection of speech is discussed to distinguish the
pathological cases of speech disabled children. The speech signal samples of
children of age between five to eight years are considered for the present
study. These speech signals are digitized and are used to determine the speech
envelope. The envelope is subjected to ratio mean analysis to estimate the
disability. This analysis is conducted on ten speech signal samples which are
related to both place of articulation and manner of articulation. Overall
speech disability of a pathological subject is estimated based on the results
of above analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4189</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4189</id><created>2011-07-21</created><authors><author><keyname>Sharma</keyname><forenames>Annapurna</forenames></author><author><keyname>Zaynidinov</keyname><forenames>Hakimjon</forenames></author><author><keyname>Lee</keyname><forenames>Hoon Jae</forenames></author></authors><title>Development and Modelling of High-Efficiency Computing Structure for
  Digital Signal Processing</title><categories>cs.NA</categories><comments>4 Pages, 5 figures, IEEE International Conference on Multimedia,
  Signal Processing and Communication Technologies, 2009. IMPACT '09</comments><doi>10.1109/MSPCT.2009.5164207</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper is devoted to problem of spline approximation. A new method of
nodes location for curves and surfaces computer construction by means of
B-splines and results of simulink-modeling is presented. The advantages of this
paper is that we comprise the basic spline with classical polynomials both on
accuracy, as well as degree of paralleling calculations are also shown.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4196</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4196</id><created>2011-07-21</created><updated>2012-10-20</updated><authors><author><keyname>Vontobel</keyname><forenames>Pascal O.</forenames></author></authors><title>The Bethe Permanent of a Non-Negative Matrix</title><categories>cs.IT cs.CC math-ph math.CO math.IT math.MP</categories><comments>Accepted for IEEE Transactions on Information Theory. Manuscript
  received July 21, 2011; date of current version October 20, 2012. Changes
  compared to v1: see v2. Changes compared to v2: changed t to \tau in Section
  IV in order to distinguish it from iteration number t in Section V. Fixed
  some typos</comments><journal-ref>IEEE Trans. Inf. Theory, vol. 59, pp. 1866-1901, Mar. 2013</journal-ref><doi>10.1109/TIT.2012.2227109</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has recently been observed that the permanent of a non-negative square
matrix, i.e., of a square matrix containing only non-negative real entries, can
very well be approximated by solving a certain Bethe free energy function
minimization problem with the help of the sum-product algorithm. We call the
resulting approximation of the permanent the Bethe permanent. In this paper we
give reasons why this approach to approximating the permanent works well.
Namely, we show that the Bethe free energy function is convex and that the
sum-product algorithm finds its minimum efficiently. We then discuss the fact
that the permanent is lower bounded by the Bethe permanent, and we comment on
potential upper bounds on the permanent based on the Bethe permanent. We also
present a combinatorial characterization of the Bethe permanent in terms of
permanents of so-called lifted versions of the matrix under consideration.
Moreover, we comment on possibilities to modify the Bethe permanent so that it
approximates the permanent even better, and we conclude the paper with some
observations and conjectures about permanent-based pseudo-codewords and
permanent-based kernels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4199</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4199</id><created>2011-07-21</created><authors><author><keyname>Pijcke</keyname><forenames>Benoit</forenames></author><author><keyname>Zwingelstein-Colin</keyname><forenames>Marie</forenames></author><author><keyname>Gazalet</keyname><forenames>Marc</forenames></author><author><keyname>Gharbi</keyname><forenames>Mohamed</forenames></author><author><keyname>Corlay</keyname><forenames>Patrick</forenames></author></authors><title>An Analytical Model for the Intercell Interference Power in the Downlink
  of Wireless Cellular Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>36 pages, 17 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a methodology for estimating the statistics of the
intercell interference power in the downlink of a multicellular network. We
first establish an analytical expression for the probability law of the
interference power when only Rayleigh multipath fading is considered. Next,
focusing on a propagation environment where small-scale Rayleigh fading as well
as large-scale effects, including attenuation with distance and lognormal
shadowing, are taken into consideration, we elaborate a semi-analytical method
to build up the histogram of the interference power distribution. From the
results obtained for this combined small- and large-scale fading context, we
then develop a statistical model for the interference power distribution. The
interest of this model lies in the fact that it can be applied to a large range
of values of the shadowing parameter. The proposed methods can also be easily
extended to other types of networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4212</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4212</id><created>2011-07-21</created><updated>2011-07-27</updated><authors><author><keyname>Cerami</keyname><forenames>Marco</forenames></author><author><keyname>Straccia</keyname><forenames>Umberto</forenames></author></authors><title>On the Undecidability of Fuzzy Description Logics with GCIs with
  Lukasiewicz t-norm</title><categories>cs.LO cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently there have been some unexpected results concerning Fuzzy Description
Logics (FDLs) with General Concept Inclusions (GCIs). They show that, unlike
the classical case, the DL ALC with GCIs does not have the finite model
property under Lukasiewicz Logic or Product Logic and, specifically, knowledge
base satisfiability is an undecidable problem for Product Logic. We complete
here the analysis by showing that knowledge base satisfiability is also an
undecidable problem for Lukasiewicz Logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4217</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4217</id><created>2011-07-21</created><authors><author><keyname>Farooq</keyname><forenames>Umer</forenames></author><author><keyname>Iqbal</keyname><forenames>M. Aqeel</forenames></author><author><keyname>Nazir</keyname><forenames>Sohail</forenames></author></authors><title>A Glance into the Future of Human Computer Interactions</title><categories>cs.HC</categories><comments>16 Pages 7 Figures International Journal</comments><journal-ref>International Journal of Computer Science, Engineering and
  Applications (IJCSEA) Vol.1, No.3, June 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computers have a direct impact on our lives nowadays. Human's interaction
with the computer has modified with the passage of time as improvement in
technology occurred the better the human computer interaction became. Today we
are facilitated by the operating system that has reduced all the complexity of
hardware and we undergo our computation in a very convenient way irrespective
of the process occurring at the hardware level. Though the human computer
interaction has improved but it's not done yet. If we come to the future the
computer's role in our lives would be a lot more rather our life would be of
the artificial intelligence. In our future the biggest resource would be
component of time and wasting time for a key board entry or a mouse input would
be unbearable so the need would be of the computer interaction environment that
along with the complexity reduction also minimizes the time wastage in the
human computer interaction. Accordingly in our future the computation would
also be increased it would not be a simple operating system limited to a
computer it would be computers managing our entire life activities hence fall
out of domain of present computers electronic based architecture .In this
research paper we propose a model that shall be meeting the future human
computer interaction needs possessing linguistic human computer interference
environment based on surface technology, automation and photonic computing,
which would be reliable, efficient and quicker satisfying all the future
artificial intelligence pre requisites.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4218</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4218</id><created>2011-07-21</created><authors><author><keyname>Serva</keyname><forenames>Maurizio</forenames></author></authors><title>The settlement of Madagascar: what dialects and languages can tell</title><categories>cs.CL q-bio.PE</categories><comments>We find out the area and the modalities of the settlement of
  Madagascar by Indonesian colonizers around 650 CE. Results are obtained
  comparing 23 Malagasy dialects with Malay and Maanyan languages</comments><doi>10.1371/journal.pone.0030666</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The dialects of Madagascar belong to the Greater Barito East group of the
Austronesian family and it is widely accepted that the Island was colonized by
Indonesian sailors after a maritime trek which probably took place around 650
CE. The language most closely related to Malagasy dialects is Maanyan but also
Malay is strongly related especially for what concerns navigation terms. Since
the Maanyan Dayaks live along the Barito river in Kalimantan (Borneo) and they
do not possess the necessary skill for long maritime navigation, probably they
were brought as subordinates by Malay sailors.
  In a recent paper we compared 23 different Malagasy dialects in order to
determine the time and the landing area of the first colonization. In this
research we use new data and new methods to confirm that the landing took place
on the south-east coast of the Island. Furthermore, we are able to state here
that it is unlikely that there were multiple settlements and, therefore,
colonization consisted in a single founding event.
  To reach our goal we find out the internal kinship relations among all the 23
Malagasy dialects and we also find out the different kinship degrees of the 23
dialects versus Malay and Maanyan. The method used is an automated version of
the lexicostatistic approach. The data concerning Madagascar were collected by
the author at the beginning of 2010 and consist of Swadesh lists of 200 items
for 23 dialects covering all areas of the Island. The lists for Maanyan and
Malay were obtained from published datasets integrated by author's interviews.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4222</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4222</id><created>2011-07-21</created><authors><author><keyname>Aslanyan</keyname><forenames>Hakob</forenames></author></authors><title>Interference minimization in physical model of wireless networks</title><categories>cs.DS cs.IT math.IT</categories><journal-ref>International Journal of Information Theories and Applications,
  2010. ITHEA2010: Volume 17, Number 3, 221-232</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interference minimization problem in wireless sensor and ad-hoc networks is
considered. That is to assign a transmission power to each node of a network
such that the network is connected and at the same time the maximum of
accumulated signal straight on network nodes is minimum. Previous works on
interference minimization in wireless networks mainly consider the disk graph
model of network. For disk graph model two approximation algorithms with
$O(\sqrt{n})$ and $O((opt\ln{n})^{2})$ upper bounds of maximum interference are
known, where $n$ is the number of nodes and $opt$ is the minimal interference
of a given network. In current work we consider more general interference
model, the physical interference model, where sender nodes' signal straight on
a given node is a function of a sender/receiver node pair and sender nodes'
transmission power. For this model we give a polynomial time approximation
algorithm which finds a connected network with at most
$O((opt\ln{n})^{2}/\beta)$ interference, where $\beta \geq 1$ is the minimum
signal straight necessary on receiver node for successfully receiving a
message.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4223</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4223</id><created>2011-07-21</created><authors><author><keyname>Aslanyan</keyname><forenames>Hakob</forenames></author></authors><title>Sorting Algorithms with Restrictions</title><categories>cs.DS</categories><journal-ref>International Conference on Computer Science and Information
  Technologies. CSIT2005: 125-127, Yerevan, Armenia 2005</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sorting is one of the most used and well investigated algorithmic problem
[1]. Traditional postulation supposes the sorting data archived, and the
elementary operation as comparisons of two numbers. In a view of appearance of
new processors and applied problems with data streams, sorting changed its
face. This changes and generalizations are the subject of investigation in the
research below.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4224</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4224</id><created>2011-07-21</created><authors><author><keyname>Aslanyan</keyname><forenames>Hakob</forenames></author></authors><title>Greedy Set Cover Estimations</title><categories>cs.DM</categories><journal-ref>International Conference on Computer Science and Information
  Technologies. CSIT2003: 143-144, Yerevan, Armenia 2003</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  More precise estimation of the greedy algorithm complexity for a special case
of the set cover problem is given in this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4230</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4230</id><created>2011-07-21</created><authors><author><keyname>Zielinska</keyname><forenames>Elzbieta</forenames></author><author><keyname>Szczypiorski</keyname><forenames>Krzysztof</forenames></author></authors><title>Direct Sequence Spread Spectrum Steganographic Scheme for IEEE 802.15.4</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work addresses the issues related to network steganography in IEEE
802.15.4 Wireless Personal Area Networks (WPAN). The proposed communication
scheme employs illicit Direct Sequence Spread Spectrum code sequences for the
transmission of steganographic data. The presented approach is a compromise
between minimising the probability of covert channel disclosure and providing
robustness against random errors and a high steganographic data rate. The
conducted analyses show that it is possible to create a covert channel with a
data rate comparable to the raw data rate of IEEE 802.15.4 without much impact
on the perceived receiver sensitivity, the Chip Error Rate and the Bit Error
Rate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4246</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4246</id><created>2011-07-21</created><authors><author><keyname>Manin</keyname><forenames>Yuri I.</forenames></author></authors><title>A computability challenge: asymptotic bounds and isolated
  error-correcting codes</title><categories>cs.IT math.IT math.NA</categories><comments>11 pages</comments><msc-class>94 B27</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the set of all error--correcting block codes over a fixed alphabet
with $q$ letters. It determines a recursively enumerable set of points in the
unit square with coordinates $(R,\delta)$:= {\it (relative transmission rate,
relative minimal distance).} Limit points of this set form a closed subset,
defined by $R\le \alpha_q(\delta)$, where $\alpha_q(\delta)$ is a continuous
decreasing function called {\it asymptotic bound.} Its existence was proved by
the author in 1981, but all attempts to find an explicit formula for it so far
failed.
  In this note I consider the question whether this function is computable in
the sense of constructive mathematics, and discuss some arguments suggesting
that the answer might be negative.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4251</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4251</id><created>2011-07-21</created><authors><author><keyname>M&#xe9;riaux</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Hayel</keyname><forenames>Yezekael</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Garnaev</keyname><forenames>Andrey</forenames></author></authors><title>Long-Term Energy Constraints and Power Control in Cognitive Radio
  Networks</title><categories>cs.NI</categories><comments>DSP 2011: 17th International Conference on Digital Signal Processing,
  July 2011, Corfu, Greece</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When a long-term energy constraint is imposed to a transmitter, the average
energy-efficiency of a transmitter is, in general, not maximized by always
transmitting. In a cognitive radio context, this means that a secondary link
can re-exploit the non-used time-slots. In the case where the secondary link is
imposed to generate no interference on the primary link, a relevant issue is
therefore to know the fraction of time-slots available to the secondary
transmitter, depending on the system parameters. On the other hand, if the
secondary transmitter is modeled as a selfish and free player choosing its
power control policy to maximize its average energy-efficiency, resulting
primary and secondary signals are not necessarily orthogonal and studying the
corresponding Stackelberg game is relevant to know the outcome of this
interactive situation in terms of power control policies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4255</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4255</id><created>2011-07-21</created><authors><author><keyname>Mabrok</keyname><forenames>Mohamed A.</forenames></author><author><keyname>Kallapur</keyname><forenames>Abhijit G.</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author><author><keyname>Lanzon</keyname><forenames>Alexander</forenames></author></authors><title>A New Stability Result for the Feedback Interconnection of Negative
  Imaginary Systems with a Pole at the Origin</title><categories>math.OC cs.SY</categories><comments>50th IEEE Conference on Decision and Control and European Control
  Conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with stability conditions for the positive feedback
interconnection of negative imaginary systems. A generalization of the negative
imaginary lemma is derived, which remains true even if the transfer function
has poles on the imaginary axis including the origin. A sufficient condition
for the internal stability of a feedback interconnection for NI systems
including a pole at the origin is given and an illustrative example is
presented to support the result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4258</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4258</id><created>2011-07-21</created><authors><author><keyname>M&#xe9;riaux</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Treust</keyname><forenames>Ma&#xeb;l Le</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Kieffer</keyname><forenames>Michel</forenames></author></authors><title>A Stochastic Game Formulation of Energy-Efficient Power Control:
  Equilibrium Utilities and Practical Strategies</title><categories>cs.GT</categories><comments>DSP 2011: 17th International Conference on Digital Signal Processing,
  July 2011, Corfu, Greece</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Frequency non-selective time-selective multiple access channels in which
transmitters can freely choose their power control policy are considered. The
individual objective of the transmitters is to maximize their averaged
energy-efficiency. For this purpose, a transmitter has to choose a power
control policy that is, a sequence of power levels adapted to the channel
variations. This problem can be formulated as a stochastic game with
discounting for which there exists a theorem characterizing all the equilibrium
utilities (equilibrium utility region). As in its general formulation, this
theorem relies on global channel state information (CSI), it is shown that some
points of the utility region can be reached with individual CSI. Interestingly,
time-sharing based solutions, which are usually considered for centralized
policies, appear to be part of the equilibrium solutions. This analysis is
illustrated by numerical results providing further insights to the problem
under investigation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4264</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4264</id><created>2011-07-21</created><updated>2011-08-01</updated><authors><author><keyname>Clark</keyname><forenames>M. A.</forenames></author><author><keyname>La Plante</keyname><forenames>P. C.</forenames></author><author><keyname>Greenhill</keyname><forenames>L. J.</forenames></author></authors><title>Accelerating Radio Astronomy Cross-Correlation with Graphics Processing
  Units</title><categories>astro-ph.IM cs.CE</categories><comments>Submitted to the International Journal of High Performance Computing
  Applications (IJHPCA). 36 pages and 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a highly parallel implementation of the cross-correlation of
time-series data using graphics processing units (GPUs), which is scalable to
hundreds of independent inputs and suitable for the processing of signals from
&quot;Large-N&quot; arrays of many radio antennas. The computational part of the
algorithm, the X-engine, is implementated efficiently on Nvidia's Fermi
architecture, sustaining up to 79% of the peak single precision floating-point
throughput. We compare performance obtained for hardware- and software-managed
caches, observing significantly better performance for the latter. The high
performance reported involves use of a multi-level data tiling strategy in
memory and use of a pipelined algorithm with simultaneous computation and
transfer of data from host to device memory. The speed of code development,
flexibility, and low cost of the GPU implementations compared to ASIC and FPGA
implementations have the potential to greatly shorten the cycle of correlator
development and deployment, for cases where some power consumption penalty can
be tolerated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4269</identifier>
 <datestamp>2012-05-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4269</id><created>2011-07-21</created><updated>2011-10-26</updated><authors><author><keyname>Gerdt</keyname><forenames>Vladimir P.</forenames></author></authors><title>Consistency Analysis of Finite Difference Approximations to PDE Systems</title><categories>math.AP cs.SC math.NA math.RA</categories><comments>15 pages</comments><msc-class>65N06 (Primary) 13P10, 68W30 (Secondary)</msc-class><journal-ref>Lect. Notes Comput. Sc. 7125, Springer, Heidelberg, 2012, pp.
  28-43</journal-ref><doi>10.1007/978-3-642-28212-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the given paper we consider finite difference approximations to systems of
polynomially-nonlinear partial differential equations whose coefficients are
rational functions over rationals in the independent variables. The notion of
strong consistency which we introduced earlier for linear systems is extended
to nonlinear ones. For orthogonal and uniform grids we describe an algorithmic
procedure for verification of strong consistency based on computation of
difference standard bases. The concepts and algorithmic methods of the present
paper are illustrated by two finite difference approximations to the
two-dimensional Navier-Stokes equations. One of these approximations is
strongly consistent and another is not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4303</identifier>
 <datestamp>2014-04-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4303</id><created>2011-07-20</created><updated>2014-04-27</updated><authors><author><keyname>Shchekotykhin</keyname><forenames>Kostyantyn</forenames></author><author><keyname>Friedrich</keyname><forenames>Gerhard</forenames></author><author><keyname>Fleiss</keyname><forenames>Philipp</forenames></author><author><keyname>Rodler</keyname><forenames>Patrick</forenames></author></authors><title>Interactive ontology debugging: two query strategies for efficient fault
  localization</title><categories>cs.AI</categories><comments>Published in Web Semantics: Science, Services and Agents on the World
  Wide Web. arXiv admin note: substantial text overlap with arXiv:1004.5339</comments><journal-ref>Journal of Web Semantics 12 (2012) 88-103</journal-ref><doi>10.1016/j.websem.2011.12.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Effective debugging of ontologies is an important prerequisite for their
broad application, especially in areas that rely on everyday users to create
and maintain knowledge bases, such as the Semantic Web. In such systems
ontologies capture formalized vocabularies of terms shared by its users.
However in many cases users have different local views of the domain, i.e. of
the context in which a given term is used. Inappropriate usage of terms
together with natural complications when formulating and understanding logical
descriptions may result in faulty ontologies. Recent ontology debugging
approaches use diagnosis methods to identify causes of the faults. In most
debugging scenarios these methods return many alternative diagnoses, thus
placing the burden of fault localization on the user. This paper demonstrates
how the target diagnosis can be identified by performing a sequence of
observations, that is, by querying an oracle about entailments of the target
ontology. To identify the best query we propose two query selection strategies:
a simple &quot;split-in-half&quot; strategy and an entropy-based strategy. The latter
allows knowledge about typical user errors to be exploited to minimize the
number of queries. Our evaluation showed that the entropy-based method
significantly reduces the number of required queries compared to the
&quot;split-in-half&quot; approach. We experimented with different probability
distributions of user errors and different qualities of the a-priori
probabilities. Our measurements demonstrated the superiority of entropy-based
query selection even in cases where all fault probabilities are equal, i.e.
where no information about typical user errors is available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4346</identifier>
 <datestamp>2011-07-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4346</id><created>2011-07-21</created><authors><author><keyname>Qiao</keyname><forenames>Deli</forenames></author><author><keyname>Gursoy</keyname><forenames>Mustafa Cenk</forenames></author><author><keyname>Velipasalar</keyname><forenames>Senem</forenames></author></authors><title>Effective Capacity of Two-Hop Wireless Communication Systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A two-hop wireless communication link in which a source sends data to a
destination with the aid of an intermediate relay node is studied. It is
assumed that there is no direct link between the source and the destination,
and the relay forwards the information to the destination by employing the
decode-and-forward scheme. Both the source and intermediate relay nodes are
assumed to operate under statistical quality of service (QoS) constraints
imposed as limitations on the buffer overflow probabilities. The maximum
constant arrival rates that can be supported by this two-hop link in the
presence of QoS constraints are characterized by determining the effective
capacity of such links as a function of the QoS parameters and signal-to-noise
ratios at the source and relay, and the fading distributions of the links. The
analysis is performed for both full-duplex and half-duplex relaying. Through
this study, the impact upon the throughput of having buffer constraints at the
source and intermediate relay nodes is identified. The interactions between the
buffer constraints in different nodes and how they affect the performance are
studied. The optimal time-sharing parameter in half-duplex relaying is
determined, and performance with half-duplex relaying is investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4376</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4376</id><created>2011-07-20</created><updated>2011-07-25</updated><authors><author><keyname>Noguera</keyname><forenames>Maria Teresa</forenames></author></authors><title>Enhancing Knowledge Sharing Between Educational Portals</title><categories>cs.CY</categories><comments>27 pages. Typos corrected</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Information and knowledge in exchange in public networks is a crucial
challenge that needs to be overcome in order to consolidate the benefits
associated with such structures. We study the impact of the nature of the
information exchanged over the possibilities of success of this process, basing
ourselves on the analysis of the information produced by the members of the
Network of National Educational Portals. One of the main challenges that the
Network of National Educational Portals faces consists in finding effective
ways of sharing information that can promote knowledge transfer between members
of the network. We argue that a key factor that prevents information sharing is
the use of performance metrics by portal responsibles to evaluate the results
of their decisions. These metrics are highly sensitive, context-dependent, and
produced through non-standardized methods, all of which reduce the willingness
of knowledge sharing. We present a different approach: based on the Network of
National Educational Portals case, we propose creating a comprehensive
information system aimed at providing reliable and timely information in a
systematic fashion. We believe that adopting standardized procedures and
indicators of less sensitive nature, we can produce information for all
partners without the shortcomings of the usual practices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4378</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4378</id><created>2011-07-21</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Hirschberg</keyname><forenames>Daniel S.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Thaler</keyname><forenames>Justin</forenames></author></authors><title>Fully De-Amortized Cuckoo Hashing for Cache-Oblivious Dictionaries and
  Multimaps</title><categories>cs.DS</categories><comments>27 pages, 1 table</comments><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A dictionary (or map) is a key-value store that requires all keys be unique,
and a multimap is a key-value store that allows for multiple values to be
associated with the same key. We design hashing-based indexing schemes for
dictionaries and multimaps that achieve worst-case optimal performance for
lookups and updates, with a small or negligible probability the data structure
will require a rehash operation, depending on whether we are working in the the
external-memory (I/O) model or one of the well-known versions of the Random
Access Machine (RAM) model. One of the main features of our constructions is
that they are \emph{fully de-amortized}, meaning that their performance bounds
hold without one having to tune their constructions with certain performance
parameters, such as the constant factors in the exponents of failure
probabilities or, in the case of the external-memory model, the size of blocks
or cache lines and the size of internal memory (i.e., our external-memory
algorithms are cache oblivious). Our solutions are based on a fully
de-amortized implementation of cuckoo hashing, which may be of independent
interest. This hashing scheme uses two cuckoo hash tables, one &quot;nested&quot; inside
the other, with one serving as a primary structure and the other serving as an
auxiliary supporting queue/stash structure that is super-sized with respect to
traditional auxiliary structures but nevertheless adds negligible storage to
our scheme. This auxiliary structure allows the success probability for cuckoo
hashing to be very high, which is useful in cryptographic or data-intensive
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4382</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4382</id><created>2011-07-21</created><authors><author><keyname>M&#xe9;riaux</keyname><forenames>Fran&#xe7;ois</forenames></author><author><keyname>Treust</keyname><forenames>Ma&#xeb;l Le</forenames></author><author><keyname>Lasaulce</keyname><forenames>Samson</forenames></author><author><keyname>Kieffer</keyname><forenames>Michel</forenames></author></authors><title>Jeux stochastiques et contr\^ole de puissance distribu\'e</title><categories>cs.GT cs.NI</categories><comments>Gretsi 2011, September 2011, Bordeaux, France</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Transmitters of a multiple access channel are assumed to freely choose their
power control strategy in order to be energy-efficient. We show that in a
stochastic game framework, we can develop energy-efficient distributed control
strategies which only require partial knowledge of the entire system.
Achievable utility equilibrium region is characterized and based on
time-sharing, an explicit power control strategy is proposed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4386</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4386</id><created>2011-07-21</created><authors><author><keyname>Candogan</keyname><forenames>Ozan</forenames></author><author><keyname>Ozdaglar</keyname><forenames>Asuman</forenames></author><author><keyname>Parrilo</keyname><forenames>Pablo A.</forenames></author></authors><title>Dynamics in Near-Potential Games</title><categories>cs.GT</categories><comments>42 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Except for special classes of games, there is no systematic framework for
analyzing the dynamical properties of multi-agent strategic interactions.
Potential games are one such special but restrictive class of games that allow
for tractable dynamic analysis. Intuitively, games that are &quot;close&quot; to a
potential game should share similar properties. In this paper, we formalize and
develop this idea by quantifying to what extent the dynamic features of
potential games extend to &quot;near-potential&quot; games. We study convergence of three
commonly studied classes of adaptive dynamics: discrete-time better/best
response, logit response, and discrete-time fictitious play dynamics. For
better/best response dynamics, we focus on the evolution of the sequence of
pure strategy profiles and show that this sequence converges to a (pure)
approximate equilibrium set, whose size is a function of the &quot;distance&quot; from a
close potential game. We then study logit response dynamics and provide a
characterization of the stationary distribution of this update rule in terms of
the distance of the game from a close potential game and the corresponding
potential function. We further show that the stochastically stable strategy
profiles are pure approximate equilibria. Finally, we turn attention to
fictitious play, and establish that the sequence of empirical frequencies of
player actions converges to a neighborhood of (mixed) equilibria of the game,
where the size of the neighborhood increases with distance of the game to a
potential game. Thus, our results suggest that games that are close to a
potential game inherit the dynamical properties of potential games. Since a
close potential game to a given game can be found by solving a convex
optimization problem, our approach also provides a systematic framework for
studying convergence behavior of adaptive learning dynamics in arbitrary finite
strategic form games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4396</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4396</id><created>2011-07-19</created><updated>2011-07-25</updated><authors><author><keyname>Al-Wassai</keyname><forenames>Firouz Abdullah</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author><author><keyname>Al-Zuky</keyname><forenames>Ali A.</forenames></author></authors><title>The IHS Transformations Based Image Fusion</title><categories>cs.CV</categories><comments>Image Fusion, Color Models, IHS, HSV, HSL, YIQ, transformations</comments><journal-ref>Journal-ref: International Journal of Advanced Research in
  Computer Science,Volume 2, No. 5, Sept-Oct 2011,www.ijarcs.info</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The IHS sharpening technique is one of the most commonly used techniques for
sharpening. Different transformations have been developed to transfer a color
image from the RGB space to the IHS space. Through literature, it appears that,
various scientists proposed alternative IHS transformations and many papers
have reported good results whereas others show bad ones as will as not those
obtained which the formula of IHS transformation were used. In addition to
that, many papers show different formulas of transformation matrix such as IHS
transformation. This leads to confusion what is the exact formula of the IHS
transformation?. Therefore, the main purpose of this work is to explore
different IHS transformation techniques and experiment it as IHS based image
fusion. The image fusion performance was evaluated, in this study, using
various methods to estimate the quality and degree of information improvement
of a fused image quantitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4407</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4407</id><created>2011-07-21</created><updated>2012-01-20</updated><authors><author><keyname>Godinez</keyname><forenames>Humberto C.</forenames></author><author><keyname>Reisner</keyname><forenames>Jon M.</forenames></author><author><keyname>Fierro</keyname><forenames>Alexandre O.</forenames></author><author><keyname>Guimond</keyname><forenames>Stephen R.</forenames></author><author><keyname>Kao</keyname><forenames>Jim</forenames></author></authors><title>Determining Key Model Parameters of Rapidly Intensifying Hurricane
  Guillermo(1997) using the Ensemble Kalman Filter</title><categories>physics.geo-ph cs.SY math.OC</categories><comments>35 pages, 15 figures in draft mode using the American Meteorological
  Society package. Submitted to Journal of Atmospheric Sciences for publication</comments><msc-class>86A10, 86A22, 35R30</msc-class><doi>10.1175/JAS-D-12-022.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we determine key model parameters for rapidly intensifying
Hurricane Guillermo (1997) using the Ensemble Kalman Filter (EnKF). The
approach is to utilize the EnKF as a tool to only estimate the parameter values
of the model for a particular data set. The assimilation is performed using
dual-Doppler radar observations obtained during the period of rapid
intensification of Hurricane Guillermo. A unique aspect of Guillermo was that
during the period of radar observations strong convective bursts, attributable
to wind shear, formed primarily within the eastern semicircle of the eyewall.
To reproduce this observed structure within a hurricane model, background wind
shear of some magnitude must be specified; as well as turbulence and surface
parameters appropriately specified so that the impact of the shear on the
simulated hurricane vortex can be realized. To identify the complex nonlinear
interactions induced by changes in these parameters, an ensemble of model
simulations have been conducted in which individual members were formulated by
sampling the parameters within a certain range via a Latin hypercube approach.
The ensemble and the data, derived latent heat and horizontal winds from the
dual-Doppler radar observations, are utilized in the EnKF to obtain varying
estimates of the model parameters. The parameters are estimated at each time
instance, and a final parameter value is obtained by computing the average over
time. Individual simulations were conducted using the estimates, with the
simulation using latent heat parameter estimates producing the lowest overall
model forecast error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4414</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4414</id><created>2011-07-22</created><authors><author><keyname>Sharma</keyname><forenames>Annapurna</forenames></author><author><keyname>Purwar</keyname><forenames>Amit</forenames></author><author><keyname>Chung</keyname><forenames>Young-Dong Lee Young-Sook Lee Wan-Young</forenames></author></authors><title>Frequency based Classification of Activities using Accelerometer Data</title><categories>cs.NE</categories><comments>IEEE International Conference on Multisensor Fusion and Integration
  for Intelligent Systems, 2008. MFI 2008</comments><doi>10.1109/MFI.2008.4648056</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work presents, the classification of user activities such as Rest, Walk
and Run, on the basis of frequency component present in the acceleration data
in a wireless sensor network environment. As the frequencies of the above
mentioned activities differ slightly for different person, so it gives a more
accurate result. The algorithm uses just one parameter i.e. the frequency of
the body acceleration data of the three axes for classifying the activities in
a set of data. The algorithm includes a normalization step and hence there is
no need to set a different value of threshold value for magnitude for different
test person. The classification is automatic and done on a block by block
basis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4417</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4417</id><created>2011-07-22</created><authors><author><keyname>Chung</keyname><forenames>Wan-Young</forenames></author><author><keyname>Purwar</keyname><forenames>Amit</forenames></author><author><keyname>Sharma</keyname><forenames>Annapurna</forenames></author></authors><title>Frequency Domain Approach for Activity Classification using
  Accelerometer</title><categories>cs.ET</categories><comments>30th Annual International IEEE EMBS Conference, Vancouver, British
  Columbia, Canada, August 20-24, 2008</comments><doi>10.1109/IEMBS.2008.4649357</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Activity classification was performed using MEMS accelerometer and wireless
sensor node for wireless sensor network environment. Three axes MEMS
accelerometer measures body's acceleration and transmits measured data with the
help of sensor node to base station attached to PC. On the PC, real time
accelerometer data is processed for movement classifications. In this paper,
Rest, walking and running are the classified activities of the person. Both
time and frequency analysis was performed to classify running and walking. The
classification of rest and movement is done using Signal magnitude area (SMA).
The classification accuracy for rest and movement is 100%. For the
classification of walk and Run two parameters i.e. SMA and Median frequency
were used. The classification accuracy for walk and running was detected as
81.25% in the experiments performed by the test persons.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4422</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4422</id><created>2011-07-22</created><updated>2011-09-01</updated><authors><author><keyname>Deshmukh</keyname><forenames>Jyotirmoy</forenames><affiliation>University of Texas at Austin</affiliation></author><author><keyname>Ramalingam</keyname><forenames>G.</forenames><affiliation>Microsoft Research India</affiliation></author><author><keyname>Ranganath</keyname><forenames>Venkatesh-Prasad</forenames><affiliation>Microsoft Research India</affiliation></author><author><keyname>Vaswani</keyname><forenames>Kapil</forenames><affiliation>Microsoft Research India</affiliation></author></authors><title>Logical Concurrency Control from Sequential Proofs</title><categories>cs.PL cs.LO cs.SE</categories><proxy>LMCS</proxy><acm-class>D.1.3, D.2.4, F.3.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 3 (September
  2, 2011) lmcs:986</journal-ref><doi>10.2168/LMCS-7(3:10)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We are interested in identifying and enforcing the isolation requirements of
a concurrent program, i.e., concurrency control that ensures that the program
meets its specification. The thesis of this paper is that this can be done
systematically starting from a sequential proof, i.e., a proof of correctness
of the program in the absence of concurrent interleavings. We illustrate our
thesis by presenting a solution to the problem of making a sequential library
thread-safe for concurrent clients. We consider a sequential library annotated
with assertions along with a proof that these assertions hold in a sequential
execution. We show how we can use the proof to derive concurrency control that
ensures that any execution of the library methods, when invoked by concurrent
clients, satisfies the same assertions. We also present an extension to
guarantee that the library methods are linearizable or atomic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4429</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4429</id><created>2011-07-22</created><authors><author><keyname>Sharma</keyname><forenames>Annapurna</forenames></author><author><keyname>Lee</keyname><forenames>Young-Dong</forenames></author><author><keyname>Chung</keyname><forenames>Wan-Young</forenames></author></authors><title>High Accuracy Human Activity Monitoring using Neural network</title><categories>cs.NE</categories><comments>6 pages, 4 figures, 4 Tables, International Conference on Convergence
  Information Technology, pp. 430-435, 2008 Third International Conference on
  Convergence and Hybrid Information Technology, 2008</comments><doi>10.1109/ICCIT.2008.394</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents the designing of a neural network for the classification
of Human activity. A Triaxial accelerometer sensor, housed in a chest worn
sensor unit, has been used for capturing the acceleration of the movements
associated. All the three axis acceleration data were collected at a base
station PC via a CC2420 2.4GHz ISM band radio (zigbee wireless compliant),
processed and classified using MATLAB. A neural network approach for
classification was used with an eye on theoretical and empirical facts. The
work shows a detailed description of the designing steps for the classification
of human body acceleration data. A 4-layer back propagation neural network,
with Levenberg-marquardt algorithm for training, showed best performance among
the other neural network training algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4452</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4452</id><created>2011-07-22</created><authors><author><keyname>Banchs</keyname><forenames>Albert</forenames></author><author><keyname>Garcia-Saavedra</keyname><forenames>Andres</forenames></author><author><keyname>Serrano</keyname><forenames>Pablo</forenames></author><author><keyname>Widmer</keyname><forenames>Joerg</forenames></author></authors><title>A Game Theoretic Approach to Distributed Opportunistic Scheduling</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Opportunistic Scheduling (DOS) is inherently harder than
conventional opportunistic scheduling due to the absence of a central entity
that has knowledge of all the channel states. With DOS, stations contend for
the channel using random access; after a successful contention, they measure
the channel conditions and only transmit in case of a good channel, while
giving up the transmission opportunity when the channel conditions are poor.
The distributed nature of DOS systems makes them vulnerable to selfish users:
by deviating from the protocol and using more transmission opportunities, a
selfish user can gain a greater share of the wireless resources at the expense
of the well-behaved users. In this paper, we address the selfishness problem in
DOS from a game theoretic standpoint. We propose an algorithm that satisfies
the following properties: (i) when all stations implement the algorithm, the
wireless network is driven to the optimal point of operation, and (ii) one or
more selfish stations cannot gain any profit by deviating from the algorithm.
The key idea of the algorithm is to react to a selfish station by using a more
aggressive configuration that (indirectly) punishes this station. We build on
multivariable control theory to design a mechanism for punishment that on the
one hand is sufficiently severe to prevent selfish behavior while on the other
hand is light enough to guarantee that, in the absence of selfish behavior, the
system is stable and converges to the optimum point of operation. We conduct a
game theoretic analysis based on repeated games to show the algorithm's
effectiveness against selfish stations. These results are confirmed by
extensive simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4463</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4463</id><created>2011-07-22</created><authors><author><keyname>Huang</keyname><forenames>Wenqi</forenames></author><author><keyname>Ye</keyname><forenames>Tao</forenames></author><author><keyname>Chen</keyname><forenames>Duanbing</forenames></author></authors><title>Bottom-Left Placement Theorem for Rectangle Packing</title><categories>cs.DM cs.CG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proves a bottom-left placement theorem for the rectangle packing
problem, stating that if it is possible to orthogonally place n arbitrarily
given rectangles into a rectangular container without overlapping, then we can
achieve a feasible packing by successively placing a rectangle onto a
bottom-left corner in the container. This theorem shows that even for the
real-parameter rectangle packing problem, we can solve it after finite times of
bottom-left placement actions. Based on this theorem, we might develop
efficient heuristic algorithms for solving the rectangle packing problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4466</identifier>
 <datestamp>2011-10-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4466</id><created>2011-07-22</created><updated>2011-10-14</updated><authors><author><keyname>Bj&#xf6;rklund</keyname><forenames>Andreas</forenames></author></authors><title>Counting Perfect Matchings as Fast as Ryser</title><categories>cs.DS</categories><comments>To appear at SIAM-ACM SODA 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that there is a polynomial space algorithm that counts the number of
perfect matchings in an $n$-vertex graph in $O^*(2^{n/2})\subset O(1.415^n)$
time. ($O^*(f(n))$ suppresses functions polylogarithmic in $f(n)$).The
previously fastest algorithms for the problem was the exponential space
$O^*(((1+\sqrt{5})/2)^n) \subset O(1.619^n)$ time algorithm by Koivisto, and
for polynomial space, the $O(1.942^n)$ time algorithm by Nederlof. Our new
algorithm's runtime matches up to polynomial factors that of Ryser's 1963
algorithm for bipartite graphs. We present our algorithm in the more general
setting of computing the hafnian over an arbitrary ring, analogously to Ryser's
algorithm for permanent computation.
  We also give a simple argument why the general exact set cover counting
problem over a slightly superpolynomial sized family of subsets of an $n$
element ground set cannot be solved in $O^*(2^{(1-\epsilon_1)n})$ time for any
$\epsilon_1&gt;0$ unless there are $O^*(2^{(1-\epsilon_2)n})$ time algorithms for
computing an $n\times n$ 0/1 matrix permanent, for some $\epsilon_2&gt;0$
depending only on $\epsilon_1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4470</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4470</id><created>2011-07-22</created><authors><author><keyname>Urfalioglu</keyname><forenames>Onay</forenames></author><author><keyname>Arikan</keyname><forenames>Orhan</forenames></author></authors><title>Symmetry Breaking in Neuroevolution: A Technical Report</title><categories>cs.NE</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Artificial Neural Networks (ANN) comprise important symmetry properties,
which can influence the performance of Monte Carlo methods in Neuroevolution.
The problem of the symmetries is also known as the competing conventions
problem or simply as the permutation problem. In the literature, symmetries are
mainly addressed in Genetic Algoritm based approaches. However, investigations
in this direction based on other Evolutionary Algorithms (EA) are rare or
missing. Furthermore, there are different and contradictionary reports on the
efficacy of symmetry breaking. By using a novel viewpoint, we offer a possible
explanation for this issue. As a result, we show that a strategy which is
invariant to the global optimum can only be successfull on certain problems,
whereas it must fail to improve the global convergence on others. We introduce
the \emph{Minimum Global Optimum Proximity} principle as a generalized and
adaptive strategy to symmetry breaking, which depends on the location of the
global optimum. We apply the proposed principle to Differential Evolution (DE)
and Covariance Matrix Adaptation Evolution Strategies (CMA-ES), which are two
popular and conceptually different global optimization methods. Using a wide
range of feedforward ANN problems, we experimentally illustrate significant
improvements in the global search efficiency by the proposed symmetry breaking
technique.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4478</identifier>
 <datestamp>2012-01-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4478</id><created>2011-07-22</created><updated>2012-01-03</updated><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Di Giamberardino</keyname><forenames>Paolo</forenames></author></authors><title>Soft Session Types (Long Version)</title><categories>cs.LO cs.PL</categories><comments>24 pages</comments><acm-class>F.3.2; F.4.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how systems of sessions types can enforce interactions to be bounded
for all typable processes. The type system we propose is based on Lafont's soft
linear logic and is strongly inspired by recent works about session types as
intuitionistic linear logic formulas. Our main result is the existence, for
every typable process, of a polynomial bound on the length of any reduction
sequence starting from it and on the size of any of its reducts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4491</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4491</id><created>2011-07-22</created><updated>2012-04-13</updated><authors><author><keyname>Cimini</keyname><forenames>Giulio</forenames></author><author><keyname>Chen</keyname><forenames>Duanbing</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Lu</keyname><forenames>Linyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Enhancing topology adaptation in information-sharing social networks</title><categories>physics.soc-ph cs.SI</categories><journal-ref>Phys. Rev. E 85, 046108 (2012)</journal-ref><doi>10.1103/PhysRevE.85.046108</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The advent of Internet and World Wide Web has led to unprecedent growth of
the information available. People usually face the information overload by
following a limited number of sources which best fit their interests. It has
thus become important to address issues like who gets followed and how to allow
people to discover new and better information sources. In this paper we conduct
an empirical analysis on different on-line social networking sites, and draw
inspiration from its results to present different source selection strategies
in an adaptive model for social recommendation. We show that local search rules
which enhance the typical topological features of real social communities give
rise to network configurations that are globally optimal. These rules create
networks which are effective in information diffusion and resemble structures
resulting from real social systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4496</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4496</id><created>2011-07-22</created><authors><author><keyname>Pashkevich</keyname><forenames>Anatoly</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Klimchik</keyname><forenames>Alexandr</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Caro</keyname><forenames>St&#xe9;phane</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Cartesian stiffness matrix of manipulators with passive joints:
  analytical approach</title><categories>cs.RO</categories><comments>IEEE/RSJ International Conference on Intelligent Robots and Systems,
  San Franisco : United States (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper focuses on stiffness matrix computation for manipulators with
passive joints. It proposes both explicit analytical expressions and an
efficient recursive procedure that are applicable in general case and allow
obtaining the desired matrix either in analytical or numerical form. Advantages
of the developed technique and its ability to produce both singular and
non-singular stiffness matrices are illustrated by application examples that
deal with stiffness modeling of two Stewart-Gough platforms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4498</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4498</id><created>2011-07-22</created><authors><author><keyname>Coste</keyname><forenames>Michel</forenames><affiliation>IRMAR</affiliation></author><author><keyname>Wenger</keyname><forenames>Philippe</forenames><affiliation>IRCCyN</affiliation></author><author><keyname>Chablat</keyname><forenames>Damien</forenames><affiliation>IRCCyN</affiliation></author></authors><title>Singular surfaces and cusps in symmetric planar 3-RPR manipulators</title><categories>cs.RO</categories><comments>IEEE/RSJ International Conference on Intelligent Robots and Systems,
  San Franisco : United States (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study in this paper a class of 3-RPR manipulators for which the direct
kinematic problem (DKP) is split into a cubic problem followed by a quadratic
one. These manipulators are geometrically characterized by the fact that the
moving triangle is the image of the base triangle by an indirect isometry. We
introduce a specific coordinate system adapted to this geometric feature and
which is also well adapted to the splitting of the DKP. This allows us to
obtain easily precise descriptions of the singularities and of the cusp edges.
These latter second order singularities are important for nonsingular assembly
mode changing. We show how to sort assembly modes and use this sorting for
motion planning in the joint space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4500</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4500</id><created>2011-07-22</created><authors><author><keyname>Altenbach</keyname><forenames>Fabian</forenames></author><author><keyname>B&#xf6;cherer</keyname><forenames>Georg</forenames></author><author><keyname>Mathar</keyname><forenames>Rudolf</forenames></author></authors><title>Short Huffman Codes Producing 1s Half of the Time</title><categories>cs.IT math.IT</categories><comments>submitted to ICSPCS 2011, Honolulu</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The design of the channel part of a digital communication system (e.g., error
correction, modulation) is heavily based on the assumption that the data to be
transmitted forms a fair bit stream. However, simple source encoders such as
short Huffman codes generate bit streams that poorly match this assumption. As
a result, the channel input distribution does not match the original design
criteria. In this work, a simple method called half Huffman coding (halfHc) is
developed. halfHc transforms a Huffman code into a source code whose output is
more similar to a fair bit stream. This is achieved by permuting the codewords
such that the frequency of 1s at the output is close to 0.5. The permutations
are such that the optimality in terms of achieved compression ratio is
preserved. halfHc is applied in a practical example, and the resulting overall
system performs better than when conventional Huffman coding is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4502</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4502</id><created>2011-07-22</created><authors><author><keyname>Scharffe</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>LIRMM</affiliation></author><author><keyname>Euzenat</keyname><forenames>J&#xe9;r&#xf4;me</forenames><affiliation>INRIA Grenoble Rh&#xf4;ne-Alpes / LIG Laboratoire d'Informatique de Grenoble</affiliation></author></authors><title>MeLinDa: an interlinking framework for the web of data</title><categories>cs.AI</categories><comments>N&amp;deg; RR-7691 (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The web of data consists of data published on the web in such a way that they
can be interpreted and connected together. It is thus critical to establish
links between these data, both for the web of data and for the semantic web
that it contributes to feed. We consider here the various techniques developed
for that purpose and analyze their commonalities and differences. We propose a
general framework and show how the diverse techniques fit in the framework.
From this framework we consider the relation between data interlinking and
ontology matching. Although, they can be considered similar at a certain level
(they both relate formal entities), they serve different purposes, but would
find a mutual benefit at collaborating. We thus present a scheme under which it
is possible for data linking tools to take advantage of ontology alignments.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4524</identifier>
 <datestamp>2012-05-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4524</id><created>2011-07-22</created><updated>2012-05-07</updated><authors><author><keyname>Reid</keyname><forenames>Fergal</forenames></author><author><keyname>Harrigan</keyname><forenames>Martin</forenames></author></authors><title>An Analysis of Anonymity in the Bitcoin System</title><categories>physics.soc-ph cs.SI</categories><comments>28 pages, 14 Figures. Updated with further related work, additional
  technical details. Format changed to author prepared book chapter preprint.
  Supporting code, additional discussion:
  http://anonymity-in-bitcoin.blogspot.com/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Anonymity in Bitcoin, a peer-to-peer electronic currency system, is a
complicated issue. Within the system, users are identified by public-keys only.
An attacker wishing to de-anonymize its users will attempt to construct the
one-to-many mapping between users and public-keys and associate information
external to the system with the users. Bitcoin tries to prevent this attack by
storing the mapping of a user to his or her public-keys on that user's node
only and by allowing each user to generate as many public-keys as required. In
this chapter we consider the topological structure of two networks derived from
Bitcoin's public transaction history. We show that the two networks have a
non-trivial topological structure, provide complementary views of the Bitcoin
system and have implications for anonymity. We combine these structures with
external information and techniques such as context discovery and flow analysis
to investigate an alleged theft of Bitcoins, which, at the time of the theft,
had a market value of approximately half a million U.S. dollars.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4526</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4526</id><created>2011-07-22</created><authors><author><keyname>Gaito</keyname><forenames>Sabrina</forenames></author><author><keyname>Maggiorini</keyname><forenames>Dario</forenames></author><author><keyname>Rossi</keyname><forenames>Gian Paolo</forenames></author></authors><title>Leveraging Bus Mobility to Enable Communications in Urban Areas</title><categories>cs.NI</categories><comments>14 pages, 13 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper shows that the deployment of an opportunistic network on any
public transportation system leads to obtain a scalable and efficient urban
communication platform. We use the term Bus Switched Networks (BSNs) to
indicate this urban backbone that complements the services of 3G networks and
enables to meet the application level requirements for a large class of
applications by ensuring high delivery ratio and acceptable delays under
different conditions of packet load. We sustain these arguments by providing
three contributions. The first contribution is a novel and lightweight
probabilistic routing protocol for BSN which we prove to be highly effective in
satisfying the loose QoS required by urban-wide delay-tolerant information
services. The second contribution is the proposal of URBeS, an analysis
platform that, given a specific city served by public transportation, produces
real bus mobility traces and traffic analysis for any given routing protocol.
The last contribution is an extensive benchmark analysis on three real cities
which have been selected to explore geo and structural diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4530</identifier>
 <datestamp>2011-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4530</id><created>2011-07-22</created><updated>2011-09-12</updated><authors><author><keyname>Little</keyname><forenames>John B.</forenames></author></authors><title>Remarks on generalized toric codes</title><categories>cs.IT math.AG math.IT</categories><comments>14 pages, 4 figures Version 2 corrects some typos, adds a new
  reference</comments><msc-class>94B27, 11T71, 14G50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note presents some new information on how the minimum distance of the
generalized toric code corresponding to a fixed set of integer lattice points S
in R^2 varies with the base field. The main results show that in some cases,
over sufficiently large fields, the minimum distance of the code corresponding
to a set S will be the same as that of the code corresponding to the convex
hull of S. In an example, we will also discuss a [49,12,28] generalized toric
code over GF(8), better than any previously known code according to M. Grassl's
online tables, as of July 2011.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4537</identifier>
 <datestamp>2014-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4537</id><created>2011-07-22</created><updated>2014-10-14</updated><authors><author><keyname>Auletta</keyname><forenames>Vincenzo</forenames></author><author><keyname>Ferraioli</keyname><forenames>Diodato</forenames></author><author><keyname>Pasquale</keyname><forenames>Francesco</forenames></author><author><keyname>Persiano</keyname><forenames>Giuseppe</forenames></author></authors><title>Metastability of Logit Dynamics for Coordination Games</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logit Dynamics [Blume, Games and Economic Behavior, 1993] are randomized best
response dynamics for strategic games: at every time step a player is selected
uniformly at random and she chooses a new strategy according to a probability
distribution biased toward strategies promising higher payoffs. This process
defines an ergodic Markov chain, over the set of strategy profiles of the game,
whose unique stationary distribution is the long-term equilibrium concept for
the game. However, when the mixing time of the chain is large (e.g.,
exponential in the number of players), the stationary distribution loses its
appeal as equilibrium concept, and the transient phase of the Markov chain
becomes important. In several cases it happens that on a time-scale shorter
than mixing time the chain is &quot;metastable&quot;, i.e. it stays close to some small
set of the state space, while in a time-scale multiple of the mixing time it
jumps from one metastable configuration to another.
  In this paper we give a quantitative definition of &quot;metastable probability
distributions&quot; for a Markov chain and we study the metastability of the logit
dynamics for some classes of coordination games. We first consider a pure
n-player coordination game that highlights the distinctive features of our
metastability notion based on distributions. Then, we study no-risk-dominant
coordination games on the clique (which is equivalent to the well-known Glauber
dynamics for the Curie-Weiss model) and coordination games on a ring (both the
risk-dominant and no-risk-dominant case).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4540</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4540</id><created>2011-07-22</created><authors><author><keyname>Chan</keyname><forenames>Chun Lam</forenames></author><author><keyname>Che</keyname><forenames>Pak Hou</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Saligrama</keyname><forenames>Venkatesh</forenames></author></authors><title>Non-adaptive probabilistic group testing with noisy measurements:
  Near-optimal bounds with efficient algorithms</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of detecting a small subset of defective items from a
large set via non-adaptive &quot;random pooling&quot; group tests. We consider both the
case when the measurements are noiseless, and the case when the measurements
are noisy (the outcome of each group test may be independently faulty with
probability q). Order-optimal results for these scenarios are known in the
literature. We give information-theoretic lower bounds on the query complexity
of these problems, and provide corresponding computationally efficient
algorithms that match the lower bounds up to a constant factor. To the best of
our knowledge this work is the first to explicitly estimate such a constant
that characterizes the gap between the upper and lower bounds for these
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4553</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4553</id><created>2011-07-22</created><authors><author><keyname>de la Tour</keyname><forenames>Thierry Boy</forenames></author><author><keyname>Echenim</keyname><forenames>Mnacho</forenames></author></authors><title>Solving Linear Constraints in Elementary Abelian p-Groups of Symmetries</title><categories>cs.AI</categories><comments>18 pages</comments><acm-class>I.2.8; F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Symmetries occur naturally in CSP or SAT problems and are not very difficult
to discover, but using them to prune the search space tends to be very
challenging. Indeed, this usually requires finding specific elements in a group
of symmetries that can be huge, and the problem of their very existence is
NP-hard. We formulate such an existence problem as a constraint problem on one
variable (the symmetry to be used) ranging over a group, and try to find
restrictions that may be solved in polynomial time. By considering a simple
form of constraints (restricted by a cardinality k) and the class of groups
that have the structure of Fp-vector spaces, we propose a partial algorithm
based on linear algebra. This polynomial algorithm always applies when k=p=2,
but may fail otherwise as we prove the problem to be NP-hard for all other
values of k and p. Experiments show that this approach though restricted should
allow for an efficient use of at least some groups of symmetries. We conclude
with a few directions to be explored to efficiently solve this problem on the
general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4557</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4557</id><created>2011-07-22</created><authors><author><keyname>Ott</keyname><forenames>Myle</forenames></author><author><keyname>Choi</keyname><forenames>Yejin</forenames></author><author><keyname>Cardie</keyname><forenames>Claire</forenames></author><author><keyname>Hancock</keyname><forenames>Jeffrey T.</forenames></author></authors><title>Finding Deceptive Opinion Spam by Any Stretch of the Imagination</title><categories>cs.CL cs.CY</categories><comments>11 pages, 5 tables, data available at:
  http://www.cs.cornell.edu/~myleott</comments><acm-class>I.2.7; J.4; K.4.2</acm-class><journal-ref>Proceedings of ACL 2011: HLT, pp. 309-319</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consumers increasingly rate, review and research products online.
Consequently, websites containing consumer reviews are becoming targets of
opinion spam. While recent work has focused primarily on manually identifiable
instances of opinion spam, in this work we study deceptive opinion
spam---fictitious opinions that have been deliberately written to sound
authentic. Integrating work from psychology and computational linguistics, we
develop and compare three approaches to detecting deceptive opinion spam, and
ultimately develop a classifier that is nearly 90% accurate on our
gold-standard opinion spam dataset. Based on feature analysis of our learned
models, we additionally make several theoretical contributions, including
revealing a relationship between deceptive opinions and imaginative writing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4563</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4563</id><created>2011-07-22</created><authors><author><keyname>Auil</keyname><forenames>Fernando</forenames></author></authors><title>An Algorithm to Generate Square-Free Numbers and to Compute the Moebius
  Function</title><categories>math.NT cs.DS</categories><comments>16 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an algorithm that iteratively produces a sequence of natural
numbers k_i and functions b_i. The number k_(i+1) arises as the first point of
discontinuity of b_i above k_i. We derive a set of properties of both
sequences, suggesting that (1) the algorithm produces square-free numbers k_i,
(2) all the square-free numbers are generated as the output of the algorithm,
and (3) the value of the Moebius function mu(k_i) can be evaluated as
b_i(k_(i+1)) - b_i(k_i). The logical equivalence of these properties is
rigorously proved. The question remains open if one of these properties can be
derived from the definition of the algorithm. Numerical evidence, limited to
5x10^6, seems to support this conjecture, and shows a total running time linear
or quadratic, depending on the implementation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4566</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4566</id><created>2011-07-22</created><authors><author><keyname>Chandramouli</keyname><forenames>Shyam S</forenames></author><author><keyname>Sethuraman</keyname><forenames>Jay</forenames></author></authors><title>Groupstrategyproofness of the Egalitarian Mechanism for Constrained
  Rationing Problems</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The key contribution of the paper is a comprehensive study of the egalitarian
mechanism with respect to manipulation by a coalition of agents. Our main
result is that the egalitarian mechanism is, in fact, peak group strategyproof
: no coalition of agents can (weakly) benefit from jointly misreporting their
peaks. Furthermore, we show that the egalitarian mechanism cannot be
manipulated by any coalition of suppliers (or any coalition of demanders) in
the model where both the suppliers and demanders are agents. Our proofs shed
light on the structure of the two models and simpify some of the earlier proofs
of strategyproofness in the earlier papers. An implication of our results is
that the well known algorithm of Megiddo to compute a lexicographically optimal
flow in a network is group strategyproof with respect to the source capacities
(or sink capacities).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4570</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4570</id><created>2011-07-22</created><updated>2011-10-07</updated><authors><author><keyname>Manna</keyname><forenames>Marco</forenames></author><author><keyname>Ricca</keyname><forenames>Francesco</forenames></author><author><keyname>Terracina</keyname><forenames>Giorgio</forenames></author></authors><title>Consistent Query Answering via ASP from Different Perspectives: Theory
  and Practice</title><categories>cs.DB cs.AI</categories><msc-class>68P15 (Primary), 68T27 (Secondary)</msc-class><acm-class>H.2.4; I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A data integration system provides transparent access to different data
sources by suitably combining their data, and providing the user with a unified
view of them, called global schema. However, source data are generally not
under the control of the data integration process, thus integrated data may
violate global integrity constraints even in presence of locally-consistent
data sources. In this scenario, it may be anyway interesting to retrieve as
much consistent information as possible. The process of answering user queries
under global constraint violations is called consistent query answering (CQA).
Several notions of CQA have been proposed, e.g., depending on whether
integrated information is assumed to be sound, complete, exact or a variant of
them. This paper provides a contribution in this setting: it uniforms solutions
coming from different perspectives under a common ASP-based core, and provides
query-driven optimizations designed for isolating and eliminating
inefficiencies of the general approach for computing consistent answers.
Moreover, the paper introduces some new theoretical results enriching existing
knowledge on decidability and complexity of the considered problems. The
effectiveness of the approach is evidenced by experimental results.
  To appear in Theory and Practice of Logic Programming (TPLP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4573</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4573</id><created>2011-07-22</created><authors><author><keyname>Turney</keyname><forenames>Peter D.</forenames><affiliation>National Research Council of Canada</affiliation></author></authors><title>Analogy perception applied to seven tests of word comprehension</title><categories>cs.AI cs.CL cs.LG</categories><comments>related work available at http://purl.org/peter.turney/</comments><acm-class>H.3.1; I.2.6; I.2.7</acm-class><journal-ref>Journal of Experimental &amp; Theoretical Artificial Intelligence
  (JETAI), 2011, Volume 23, Issue 3, pages 343-362</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It has been argued that analogy is the core of cognition. In AI research,
algorithms for analogy are often limited by the need for hand-coded high-level
representations as input. An alternative approach is to use high-level
perception, in which high-level representations are automatically generated
from raw data. Analogy perception is the process of recognizing analogies using
high-level perception. We present PairClass, an algorithm for analogy
perception that recognizes lexical proportional analogies using representations
that are automatically generated from a large corpus of raw textual data. A
proportional analogy is an analogy of the form A:B::C:D, meaning &quot;A is to B as
C is to D&quot;. A lexical proportional analogy is a proportional analogy with
words, such as carpenter:wood::mason:stone. PairClass represents the semantic
relations between two words using a high-dimensional feature vector, in which
the elements are based on frequencies of patterns in the corpus. PairClass
recognizes analogies by applying standard supervised machine learning
techniques to the feature vectors. We show how seven different tests of word
comprehension can be framed as problems of analogy perception and we then apply
PairClass to the seven resulting sets of analogy perception problems. We
achieve competitive results on all seven tests. This is the first time a
uniform approach has handled such a range of tests of word comprehension.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4581</identifier>
 <datestamp>2012-09-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4581</id><created>2011-07-22</created><updated>2012-09-23</updated><authors><author><keyname>Skachek</keyname><forenames>Vitaly</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author><author><keyname>Nedic</keyname><forenames>Angelia</forenames></author></authors><title>Hybrid Noncoherent Network Coding</title><categories>cs.IT math.IT</categories><comments>15 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a novel extension of subspace codes for noncoherent networks,
suitable for use when the network is viewed as a communication system that
introduces both dimension and symbol errors. We show that when symbol erasures
occur in a significantly large number of different basis vectors transmitted
through the network and when the min-cut of the networks is much smaller then
the length of the transmitted codewords, the new family of codes outperforms
their subspace code counterparts.
  For the proposed coding scheme, termed hybrid network coding, we derive two
upper bounds on the size of the codes. These bounds represent a variation of
the Singleton and of the sphere-packing bound. We show that a simple
concatenated scheme that represents a combination of subspace codes and
Reed-Solomon codes is asymptotically optimal with respect to the Singleton
bound. Finally, we describe two efficient decoding algorithms for concatenated
subspace codes that in certain cases have smaller complexity than subspace
decoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4588</identifier>
 <datestamp>2011-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4588</id><created>2011-07-22</created><updated>2011-11-28</updated><authors><author><keyname>Ye</keyname><forenames>Mao</forenames></author><author><keyname>Wang</keyname><forenames>Chunyan</forenames></author><author><keyname>Aperjis</keyname><forenames>Christina</forenames></author><author><keyname>Huberman</keyname><forenames>Bernardo A.</forenames></author><author><keyname>Sandholm</keyname><forenames>Thomas</forenames></author></authors><title>Collective Attention and the Dynamics of Group Deals</title><categories>cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a study of the group purchasing behavior of daily deals in Groupon
and LivingSocial and introduce a predictive dynamic model of collective
attention for group buying behavior. In our model, the aggregate number of
purchases at a given time comprises two types of processes: random discovery
and social propagation. We find that these processes are very clearly separated
by an inflection point. Using large data sets from both Groupon and
LivingSocial we show how the model is able to predict the success of group
deals as a function of time. We find that Groupon deals are easier to predict
accurately earlier in the deal lifecycle than LivingSocial deals due to the
final number of deal purchases saturating quicker. One possible explanation for
this is that the incentive to socially propagate a deal is based on an
individual threshold in LivingSocial, whereas in Groupon it is based on a
collective threshold, which is reached very early. Furthermore, the personal
benefit of propagating a deal is also greater in LivingSocial.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4600</identifier>
 <datestamp>2011-07-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4600</id><created>2011-07-22</created><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Tuninetti</keyname><forenames>Daniela</forenames></author><author><keyname>Devroye</keyname><forenames>Natasha</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>On the Capacity of the Interference Channel with a Cognitive Relay</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The InterFerence Channel with a Cognitive Relay (IFC-CR) consists of the
classical interference channel with two independent source-destination pairs
whose communication is aided by an additional node, referred to as the
cognitive relay, that has a priori knowledge of both sources' messages. This a
priori message knowledge is termed cognition and idealizes the relay learning
the messages of the two sources from their transmissions over a wireless
channel. This paper presents new inner and outer bounds for the capacity region
of the general memoryless IFC-CR that are shown to be tight for a certain class
of channels. The new outer bound follows from arguments originally devised for
broadcast channels among which Sato's observation that the capacity region of
channels with non-cooperative receivers only depends on the channel output
conditional marginal distributions. The new inner bound is shown to include all
previously proposed coding schemes and it is thus the largest known achievable
rate region to date. The new inner and outer bounds coincide for a subset of
channel satisfying a strong interference condition. For these channels there is
no loss in optimality if both destinations decode both messages. This result
parallels analogous results for the classical IFC and for the cognitive IFC and
is the first known capacity result for the general IFC-CR. Numerical
evaluations of the proposed inner and outer bounds are presented for the
Gaussian noise case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4606</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4606</id><created>2011-07-22</created><updated>2012-07-29</updated><authors><author><keyname>Fairbank</keyname><forenames>Michael</forenames></author><author><keyname>Alonso</keyname><forenames>Eduardo</forenames></author></authors><title>The Divergence of Reinforcement Learning Algorithms with Value-Iteration
  and Function Approximation</title><categories>cs.LG</categories><comments>8 pages, 4 figures. In Proceedings of the IEEE International Joint
  Conference on Neural Networks, June 2012, Brisbane (IEEE IJCNN 2012), pp.
  3070--3077</comments><journal-ref>In Proceedings of the IEEE International Joint Conference on
  Neural Networks, June 2012, Brisbane (IEEE IJCNN 2012), pp. 3070--3077</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives specific divergence examples of value-iteration for several
major Reinforcement Learning and Adaptive Dynamic Programming algorithms, when
using a function approximator for the value function. These divergence examples
differ from previous divergence examples in the literature, in that they are
applicable for a greedy policy, i.e. in a &quot;value iteration&quot; scenario. Perhaps
surprisingly, with a greedy policy, it is also possible to get divergence for
the algorithms TD(1) and Sarsa(1). In addition to these divergences, we also
achieve divergence for the Adaptive Dynamic Programming algorithms HDP, DHP and
GDHP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4613</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4613</id><created>2011-07-22</created><updated>2012-08-13</updated><authors><author><keyname>Sarkar</keyname><forenames>Amites</forenames></author><author><keyname>Haenggi</keyname><forenames>Martin</forenames></author></authors><title>Percolation in the Secrecy Graph</title><categories>math.PR cs.IT math.IT</categories><comments>22 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secrecy graph is a random geometric graph which is intended to model the
connectivity of wireless networks under secrecy constraints. Directed edges in
the graph are present whenever a node can talk to another node securely in the
presence of eavesdroppers, which, in the model, is determined solely by the
locations of the nodes and eavesdroppers. In the case of infinite networks, a
critical parameter is the maximum density of eavesdroppers that can be
accommodated while still guaranteeing an infinite component in the network,
i.e., the percolation threshold. We focus on the case where the locations of
the nodes and eavesdroppers are given by Poisson point processes, and present
bounds for different types of percolation, including in-, out- and undirected
percolation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4617</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4617</id><created>2011-07-22</created><updated>2011-09-08</updated><authors><author><keyname>Chaudhury</keyname><forenames>Kunal Narayan</forenames></author></authors><title>Constant-time filtering using shiftable kernels</title><categories>cs.CV cs.DS</categories><comments>Accepted in IEEE Signal Processing Letters</comments><acm-class>B.2.4; G.1.2</acm-class><journal-ref>IEEE Signal Processing Letters, vol. 18(11), pp. 651 - 654, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was recently demonstrated in [5] that the non-linear bilateral filter [14]
can be efficiently implemented using a constant-time or O(1) algorithm. At the
heart of this algorithm was the idea of approximating the Gaussian range kernel
of the bilateral filter using trigonometric functions. In this letter, we
explain how the idea in [5] can be extended to few other linear and non-linear
filters [14, 17, 2]. While some of these filters have received a lot of
attention in recent years, they are known to be computationally intensive. To
extend the idea in [5], we identify a central property of trigonometric
functions, called shiftability, that allows us to exploit the redundancy
inherent in the filtering operations. In particular, using shiftable kernels,
we show how certain complex filtering can be reduced to simply that of
computing the moving sum of a stack of images. Each image in the stack is
obtained through an elementary pointwise transform of the input image. This has
a two-fold advantage. First, we can use fast recursive algorithms for computing
the moving sum [15, 6], and, secondly, we can use parallel computation to
further speed up the computation. We also show how shiftable kernels can also
be used to approximate the (non-shiftable) Gaussian kernel that is ubiquitously
used in image filtering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4619</identifier>
 <datestamp>2013-07-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4619</id><created>2011-07-22</created><authors><author><keyname>Chaudhury</keyname><forenames>Kunal Narayan</forenames></author><author><keyname>Unser</keyname><forenames>Michael</forenames></author></authors><title>On the Hilbert transform of wavelets</title><categories>math.FA cs.CV</categories><comments>Appears in IEEE Transactions on Signal Processing, vol. 59, no. 4,
  pp. 1890-1894, 2011</comments><journal-ref>IEEE Transactions on Signal Processing, vol. 19(11), pp. 1890 -
  1894, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wavelet is a localized function having a prescribed number of vanishing
moments. In this correspondence, we provide precise arguments as to why the
Hilbert transform of a wavelet is again a wavelet. In particular, we provide
sharp estimates of the localization, vanishing moments, and smoothness of the
transformed wavelet. We work in the general setting of non-compactly supported
wavelets. Our main result is that, in the presence of some minimal smoothness
and decay, the Hilbert transform of a wavelet is again as smooth and
oscillating as the original wavelet, whereas its localization is controlled by
the number of vanishing moments of the original wavelet. We motivate our
results using concrete examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4623</identifier>
 <datestamp>2013-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4623</id><created>2011-07-22</created><updated>2012-06-26</updated><authors><author><keyname>Bahmani</keyname><forenames>Sohail</forenames></author><author><keyname>Raj</keyname><forenames>Bhiksha</forenames></author></authors><title>A Unifying Analysis of Projected Gradient Descent for
  $\ell_p$-constrained Least Squares</title><categories>math.NA cs.IT math.IT math.OC stat.ML</categories><comments>16 pages, 3 Figures</comments><journal-ref>Applied and Computational Harmonic Analysis, 34(3):366-378, 2013</journal-ref><doi>10.1016/j.acha.2012.07.004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the performance of the Projected Gradient Descent(PGD)
algorithm for $\ell_{p}$-constrained least squares problems that arise in the
framework of Compressed Sensing. Relying on the Restricted Isometry Property,
we provide convergence guarantees for this algorithm for the entire range of
$0\leq p\leq1$, that include and generalize the existing results for the
Iterative Hard Thresholding algorithm and provide a new accuracy guarantee for
the Iterative Soft Thresholding algorithm as special cases. Our results suggest
that in this group of algorithms, as $p$ increases from zero to one, conditions
required to guarantee accuracy become stricter and robustness to noise
deteriorates.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4624</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4624</id><created>2011-07-22</created><updated>2011-08-12</updated><authors><author><keyname>Johnson</keyname><forenames>Matthew P.</forenames></author><author><keyname>Sarioz</keyname><forenames>Deniz</forenames></author></authors><title>Computing the obstacle number of a plane graph</title><categories>cs.CG cs.DM cs.DS math.CO</categories><comments>7 pages, 3 figures</comments><msc-class>68R10, 05C10, 05C62, 65D18</msc-class><acm-class>F.2.2; G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An obstacle representation of a plane graph G is V(G) together with a set of
opaque polygonal obstacles such that G is the visibility graph on V(G)
determined by the obstacles. We investigate the problem of computing an
obstacle representation of a plane graph (ORPG) with a minimum number of
obstacles. We call this minimum size the obstacle number of G.
  First, we show that ORPG is NP-hard by reduction from planar vertex cover,
resolving a question posed by [8]. Second, we give a reduction from ORPG to
maximum degree 3 planar vertex cover. Since this reduction preserves solution
values, it follows that ORPG is fixed parameter tractable (FPT) and admits a
polynomial-time approximation scheme (PTAS).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4628</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4628</id><created>2011-06-20</created><authors><author><keyname>Safei</keyname><forenames>Suhailan</forenames></author><author><keyname>Amin</keyname><forenames>Mat Atar Mat</forenames></author><author><keyname>Rose</keyname><forenames>Ahmad Nazari Mohd</forenames></author><author><keyname>Rahman</keyname><forenames>Mohd Nordin Abdul</forenames></author></authors><title>Instant e-Teaching Framework Model for Live Online Teaching</title><categories>cs.CY</categories><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 2, March 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Instant e-Teaching is a new concept that supplements e-Teaching and
e-Learning environment in providing a full and comprehensive modern education
styles. The e-Learning technology depicts the concept of enabling self-learning
among students on a certain subject using online reference and materials. While
the instant e-teaching requires 'face-to-face' characteristic between teacher
and student to simultaneously execute actions and gain instant responses. The
word instant enhances the e- Teaching with the concept of real time teaching.
The challenge to exercise online and instant teaching is not just merely
relying on the technologies and system efficiency, but it needs to satisfy the
usability and friendliness of the system as to replicate the traditional class
environment during the deliveries of the class. For this purpose, an instant
e-Teaching framework is been developed that will emulate a dedicated virtual
classroom, and primarily designed for synchronous and live sharing of current
teaching notes. The model has been demonstrated using a teaching Arabic
recitation prototype and evaluated from the professional user profession's
perspectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4637</identifier>
 <datestamp>2014-03-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4637</id><created>2011-07-22</created><updated>2011-09-04</updated><authors><author><keyname>Papandreou</keyname><forenames>George</forenames></author><author><keyname>Yuille</keyname><forenames>Alan</forenames></author></authors><title>Efficient variational inference in large-scale Bayesian compressed
  sensing</title><categories>cs.CV cs.IT math.IT stat.ML</categories><comments>8 pages, 3 figures, appears in Proc. IEEE Workshop on Information
  Theory in Computer Vision and Pattern Recognition (in conjunction with
  ICCV-11), Barcelona, Spain, Nov. 2011</comments><journal-ref>Proc. IEEE Workshop on Information Theory in Computer Vision and
  Pattern Recognition (in conjunction with ICCV-11), pp. 1332-1339, Barcelona,
  Spain, Nov. 2011</journal-ref><doi>10.1109/ICCVW.2011.6130406</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study linear models under heavy-tailed priors from a probabilistic
viewpoint. Instead of computing a single sparse most probable (MAP) solution as
in standard deterministic approaches, the focus in the Bayesian compressed
sensing framework shifts towards capturing the full posterior distribution on
the latent variables, which allows quantifying the estimation uncertainty and
learning model parameters using maximum likelihood. The exact posterior
distribution under the sparse linear model is intractable and we concentrate on
variational Bayesian techniques to approximate it. Repeatedly computing
Gaussian variances turns out to be a key requisite and constitutes the main
computational bottleneck in applying variational techniques in large-scale
problems. We leverage on the recently proposed Perturb-and-MAP algorithm for
drawing exact samples from Gaussian Markov random fields (GMRF). The main
technical contribution of our paper is to show that estimating Gaussian
variances using a relatively small number of such efficiently drawn random
samples is much more effective than alternative general-purpose variance
estimation techniques. By reducing the problem of variance estimation to
standard optimization primitives, the resulting variational algorithms are
fully scalable and parallelizable, allowing Bayesian computations in extremely
large-scale problems with the same memory and time complexity requirements as
conventional point estimation techniques. We illustrate these ideas with
experiments in image deblurring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4649</identifier>
 <datestamp>2012-02-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4649</id><created>2011-07-22</created><updated>2012-02-13</updated><authors><author><keyname>Ren</keyname><forenames>Xue-Zao</forenames></author><author><keyname>Yang</keyname><forenames>Zimo</forenames></author><author><keyname>Wang</keyname><forenames>Bing-Hong</forenames></author><author><keyname>Zhou</keyname><forenames>Tao</forenames></author></authors><title>Mandelbrot Law of Evolving Networks</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>5 pages, 3 figures</comments><journal-ref>Chinese Physics Letters 29 (2012) 038904</journal-ref><doi>10.1088/0256-307X/29/3/038904</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Degree distributions of many real networks are known to follow the Mandelbrot
law, which can be considered as an extension of the power law and is determined
by not only the power-law exponent, but also the shifting coefficient. Although
the shifting coefficient highly affects the shape of distribution, it receives
less attention in the literature and in fact, mainstream analytical method
based on backward or forward difference will lead to considerable deviations to
its value. In this Letter, we show that the degree distribution of a growing
network with linear preferential attachment approximately follows the
Mandelbrot law. We propose an analytical method based on a recursive formula
that can obtain a more accurate expression of the shifting coefficient.
Simulations demonstrate the advantages of our method. This work provides a
possible mechanism leading to the Mandelbrot law of evolving networks, and
refines the mainstream analytical methods for the shifting coefficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4651</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4651</id><created>2011-07-22</created><authors><author><keyname>Kerdprasop</keyname><forenames>Nittaya</forenames></author><author><keyname>Kerdprasop</keyname><forenames>Kittisak</forenames></author></authors><title>Higher Order Programming to Mine Knowledge for a Modern Medical Expert
  System</title><categories>cs.LO cs.AI</categories><comments>9 pages</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 3, May 2011 ISSN (Online): 1694-0814 www.IJCSI.org</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Knowledge mining is the process of deriving new and useful knowledge from
vast volumes of data and background knowledge. Modern healthcare organizations
regularly generate huge amount of electronic data stored in the databases.
These data are a valuable resource for mining useful knowledge to help medical
practitioners making appropriate and accurate decision on the diagnosis and
treatment of diseases. In this paper, we propose the design of a novel medical
expert system based on a logic-programming framework. The proposed system
includes a knowledge-mining component as a repertoire of tools for discovering
useful knowledge. The implementation of classification and association mining
tools based on the higher order and meta-level programming schemes using Prolog
has been presented to express the power of logic-based language. Such language
also provides a pattern matching facility, which is an essential function for
the development of knowledge-intensive tasks. Besides the major goal of medical
decision support, the knowledge discovered by our logic-based knowledge-mining
component can also be deployed as background knowledge to pre-treatment data
from other sources as well as to guard the data repositories against constraint
violation. A framework for knowledge deployment is also presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4652</identifier>
 <datestamp>2012-03-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4652</id><created>2011-07-22</created><updated>2012-03-01</updated><authors><author><keyname>Ma</keyname><forenames>Yanjun</forenames></author><author><keyname>Li</keyname><forenames>Jiandong</forenames></author><author><keyname>Chen</keyname><forenames>Rui</forenames></author><author><keyname>Liu</keyname><forenames>Qin</forenames></author></authors><title>On the Achievability of Interference Alignment for Three-Cell Constant
  Cellular Interfering Networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a three-cell constant cellular interfering network, a new property of
alignment is identified, i.e., interference alignment (IA) solution obtained in
an user-cooperation scenario can also be applied in a non-cooperation
environment. By using this property, an algorithm is proposed by jointly
designing transmit and receive beamforming matrices. Analysis and numerical
results show that more degree of freedom (DoF) can be achieved compared with
conventional schemes in most cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4660</identifier>
 <datestamp>2013-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4660</id><created>2011-07-23</created><updated>2013-04-18</updated><authors><author><keyname>Mill&#xe1;n</keyname><forenames>V&#xed;ctor L&#xf3;pez</forenames></author><author><keyname>Cholvi</keyname><forenames>Vicent</forenames></author><author><keyname>L&#xf3;pez</keyname><forenames>Luis</forenames></author><author><keyname>Anta</keyname><forenames>Antonio Fern&#xe1;ndez</forenames></author></authors><title>Reducing Search Lengths with Locally Precomputed Partial Random Walks</title><categories>cs.NI cs.DC physics.comp-ph</categories><comments>The contents in this articule have suffered major changes. It has
  been replaced by &quot;Improving Resource Location with Locally Precomputed
  Partial Random Walks&quot;</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Random walks can be used to search a complex networks for a desired resource.
To reduce the number of hops necessary to find the resource, we propose a
search mechanism based on building random walks connecting together partial
walks that have been precomputed at each network node in an initial stage. The
resources found in each partial walk are registered in its associated Bloom
filter. Searches can then jump over partial nodes in which the resource is not
located, significantly reducing search length. However, additional unnecessary
hops come from false positives at the Bloom filters. The analytic model
provided predicts the expected search length of this mechanism, the optimal
size of the partial walks and the corresponding optimal (shortest) expected
search length. Simulation experiments are used to validate these predictions
and to assess the impact of the number of partial walks precomputed in each
node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4661</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4661</id><created>2011-07-23</created><authors><author><keyname>Zaytsev</keyname><forenames>Vadim</forenames></author></authors><title>MediaWiki Grammar Recovery</title><categories>cs.MM</categories><comments>47 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The paper describes in detail the recovery effort of one of the official
MediaWiki grammars. Over two hundred grammar transformation steps are reported
and annotated, leading to delivery of a level 2 grammar, semi-automatically
extracted from a community created semi-formal text using at least five
different syntactic notations, several non-enforced naming conventions,
multiple misspellings, obsolete parsing technology idiosyncrasies and other
problems commonly encountered in grammars that were not engineered properly.
Having a quality grammar will allow to test and validate it further, without
alienating the community with a separately developed grammar.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4667</identifier>
 <datestamp>2011-12-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4667</id><created>2011-07-23</created><updated>2011-12-18</updated><authors><author><keyname>Thirumalai</keyname><forenames>Vijayaraghavan</forenames></author><author><keyname>Frossard</keyname><forenames>Pascal</forenames></author></authors><title>Correlation Estimation from Compressed Images</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of correlation estimation in sets of
compressed images. We consider a framework where images are represented under
the form of linear measurements due to low complexity sensing or security
requirements. We assume that the images are correlated through the displacement
of visual objects due to motion or viewpoint change and the correlation is
effectively represented by optical flow or motion field models. The correlation
is estimated in the compressed domain by jointly processing the linear
measurements. We first show that the correlated images can be efficiently
related using a linear operator. Using this linear relationship we then
describe the dependencies between images in the compressed domain. We further
cast a regularized optimization problem where the correlation is estimated in
order to satisfy both data consistency and motion smoothness objectives with a
Graph Cut algorithm. We analyze in detail the correlation estimation
performance and quantify the penalty due to image compression. Extensive
experiments in stereo and video imaging applications show that our novel
solution stays competitive with methods that implement complex image
reconstruction steps prior to correlation estimation. We finally use the
estimated correlation in a novel joint image reconstruction scheme that is
based on an optimization problem with sparsity priors on the reconstructed
images. Additional experiments show that our correlation estimation algorithm
leads to an effective reconstruction of pairs of images in distributed image
coding schemes that outperform independent reconstruction algorithms by 2 to 4
dB.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4684</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4684</id><created>2011-07-23</created><authors><author><keyname>Bergstra</keyname><forenames>J. A.</forenames></author><author><keyname>Delen</keyname><forenames>G. P. A. J.</forenames></author><author><keyname>van Vlijmen</keyname><forenames>S. F. M.</forenames></author></authors><title>Introducing Sourcements</title><categories>cs.SE cs.GL</categories><acm-class>K.6.0; J.4; H.4.0; D.0</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sourcing processes are discussed at a high abstraction level. A dedicated
terminology is developed concerning general aspects of sourcing. The term
sourcement is coined to denote a building block for sourcing. No- tions of
allocation, functional architecture and allocational architecture, equilibrium,
and configuration are discussed. Limitations of the concept of outsourcing are
outlined. This theoretical work is meant to serve as a point of departure for
the subsequent development of a detailed theory of sourcing and sourcing
transformations, which can be a tool for dealing with practical applica- tions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4687</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4687</id><created>2011-07-23</created><updated>2011-10-07</updated><authors><author><keyname>Quesada</keyname><forenames>Luis</forenames></author><author><keyname>Berzal</keyname><forenames>Fernando</forenames></author><author><keyname>Cortijo</keyname><forenames>Francisco J.</forenames></author></authors><title>Fence - An Efficient Parser with Ambiguity Support for Model-Driven
  Language Specification</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Model-based language specification has applications in the implementation of
language processors, the design of domain-specific languages, model-driven
software development, data integration, text mining, natural language
processing, and corpus-based induction of models. Model-based language
specification decouples language design from language processing and, unlike
traditional grammar-driven approaches, which constrain language designers to
specific kinds of grammars, it needs general parser generators able to deal
with ambiguities. In this paper, we propose Fence, an efficient bottom-up
parsing algorithm with lexical and syntactic ambiguity support that enables the
use of model-based language specification in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4705</identifier>
 <datestamp>2015-06-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4705</id><created>2011-07-23</created><updated>2015-06-14</updated><authors><author><keyname>Rini</keyname><forenames>Stefano</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea</forenames></author></authors><title>A unified graphical approach to random coding for multi-terminal
  networks</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A unified approach to the derivation of rate regions for single-hop
memoryless networks is presented. A general transmission scheme for any
memoryless, single-hop, k-user channel with or without common information, is
defined through two steps. The first step is user virtualization: each user is
divided into multiple virtual sub-users according to a chosen rate-splitting
strategy which preserves the rates of the original messages. This results in an
enhanced channel with a possibly larger number of users for which more coding
possibilities are available. Moreover, user virtualization provides a simple
mechanism to encode common messages to any subset of users. Following user
virtualization, the message of each user in the enhanced model is coded using a
chosen combination of coded time-sharing, superposition coding and joint
binning. A graph is used to represent the chosen coding strategies: nodes in
the graph represent codewords while edges represent coding operations. This
graph is used to construct a graphical Markov model which illustrates the
statistical dependency among codewords that can be introduced by the
superposition coding or joint binning. Using this statistical representation of
the overall codebook distribution, the error probability of the code is shown
to vanish via a unified analysis. The rate bounds that define the achievable
rate region are obtained by linking the error analysis to the properties of the
graphical Markov model. This proposed framework makes it possible to
numerically obtain an achievable rate region by specifying a user
virtualization strategy and describing a set of coding operations. The largest
achievable rate region can be obtained by considering all the possible
rate-splitting strategies and taking the union over all the possible ways to
superimpose or bin codewords.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4709</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4709</id><created>2011-07-23</created><authors><author><keyname>Cheraghchi</keyname><forenames>Mahdi</forenames></author></authors><title>Applications of Derandomization Theory in Coding</title><categories>cs.DM cs.CC cs.IT math.IT</categories><comments>EPFL Phd Thesis</comments><report-no>EPFL PhD Thesis #4767</report-no><doi>10.5075/epfl-thesis-4767</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Randomized techniques play a fundamental role in theoretical computer science
and discrete mathematics, in particular for the design of efficient algorithms
and construction of combinatorial objects. The basic goal in derandomization
theory is to eliminate or reduce the need for randomness in such randomized
constructions. In this thesis, we explore some applications of the fundamental
notions in derandomization theory to problems outside the core of theoretical
computer science, and in particular, certain problems related to coding theory.
  First, we consider the wiretap channel problem which involves a communication
system in which an intruder can eavesdrop a limited portion of the
transmissions, and construct efficient and information-theoretically optimal
communication protocols for this model. Then we consider the combinatorial
group testing problem. In this classical problem, one aims to determine a set
of defective items within a large population by asking a number of queries,
where each query reveals whether a defective item is present within a specified
group of items. We use randomness condensers to explicitly construct optimal,
or nearly optimal, group testing schemes for a setting where the query outcomes
can be highly unreliable, as well as the threshold model where a query returns
positive if the number of defectives pass a certain threshold. Finally, we
design ensembles of error-correcting codes that achieve the
information-theoretic capacity of a large class of communication channels, and
then use the obtained ensembles for construction of explicit capacity achieving
codes.
  [This is a shortened version of the actual abstract in the thesis.]
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4711</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4711</id><created>2011-07-23</created><authors><author><keyname>Tassa</keyname><forenames>Tamir</forenames></author></authors><title>Finding All Allowed Edges in a Bipartite Graph</title><categories>cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding all allowed edges in a bipartite graph
$G=(V,E)$, i.e., all edges that are included in some maximum matching. We show
that given any maximum matching in the graph, it is possible to perform this
computation in linear time $O(n+m)$ (where $n=|V|$ and $m=|E|$). Hence, the
time complexity of finding all allowed edges reduces to that of finding a
single maximum matching, which is $O(n^{1/2}m)$ [Hopcroft and Karp 1973], or
$O((n/\log n)^{1/2}m)$ for dense graphs with $m=\Theta(n^2)$ [Alt et al. 1991].
This time complexity improves upon that of the best known algorithms for the
problem, which is $O(nm)$ ([Costa 1994] for bipartite graphs, and [Carvalho and
Cheriyan 2005] for general graphs). Other algorithms for solving that problem
are randomized algorithms due to [Rabin and Vazirani 1989] and [Cheriyan 1997],
the runtime of which is $\tilde{O}(n^{2.376})$. Our algorithm, apart from being
deterministic, improves upon that time complexity for bipartite graphs when
$m=O(n^r)$ and $r&lt;1.876$. In addition, our algorithm is elementary,
conceptually simple, and easy to implement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4721</identifier>
 <datestamp>2011-09-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4721</id><created>2011-07-24</created><updated>2011-09-19</updated><authors><author><keyname>Alama</keyname><forenames>Jesse</forenames></author></authors><title>mizar-items: Exploring fine-grained dependencies in the Mizar
  Mathematical Library</title><categories>cs.DL math.LO</categories><comments>Accepted at CICM 2011: Conferences in Intelligent Computer
  Mathematics, Track C: Systems and Projects</comments><msc-class>03B35</msc-class><acm-class>H.3.3</acm-class><journal-ref>Intelligent Computer Mathematics, Lecture Notes in Computer
  Science 6824, pp. 276-7, 2011</journal-ref><doi>10.1007/978-3-642-22673-1_19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Mizar Mathematical Library (MML) is a rich database of formalized
mathematical proofs (see http://mizar.org). Owing to its large size (it
contains more than 1100 &quot;articles&quot; summing to nearly 2.5 million lines of text,
expressing more than 50000 theorems and 10000 definitions using more than 7000
symbols), the nature of its contents (the MML is slanted toward pure
mathematics), and its classical foundations (first-order logic, set theory,
natural deduction), the MML is an especially attractive target for research on
foundations of mathematics. We have implemented a system, mizar-items, on which
a variety of such foundational experiements can be based. The heart of
mizar-items is a method for decomposing the contents of the MML into
fine-grained &quot;items&quot; (e.g., theorem, definition, notation, etc.) and computing
dependency relations among these items. mizar-items also comes equipped with a
website for exploring these dependencies and interacting with them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4722</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4722</id><created>2011-07-24</created><updated>2012-06-27</updated><authors><author><keyname>Bhalgat</keyname><forenames>Anand</forenames></author><author><keyname>Chakraborty</keyname><forenames>Tanmoy</forenames></author><author><keyname>Khanna</keyname><forenames>Sanjeev</forenames></author></authors><title>Mechanism Design and Risk Aversion</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop efficient algorithms to construct utility maximizing mechanisms in
the presence of risk averse players (buyers and sellers) in Bayesian settings.
We model risk aversion by a concave utility function, and players play
strategically to maximize their expected utility. Bayesian mechanism design has
usually focused on maximizing expected revenue in a {\em risk neutral}
environment, and no succinct characterization of expected utility maximizing
mechanisms is known even for single-parameter multi-unit auctions.
  We first consider the problem of designing optimal DSIC mechanism for a risk
averse seller in the case of multi-unit auctions, and we give a poly-time
computable SPM that is $(1-1/e-\eps)$-approximation to the expected utility of
the seller in an optimal DSIC mechanism. Our result is based on a novel
application of a correlation gap bound, along with {\em splitting} and {\em
merging} of random variables to redistribute probability mass across buyers.
This allows us to reduce our problem to that of checking feasibility of a small
number of distinct configurations, each of which corresponds to a covering LP.
A feasible solution to the LP gives us the distribution on prices for each
buyer to use in a randomized SPM.
  We next consider the setting when buyers as well as the seller are risk
averse, and the objective is to maximize the seller's expected utility. We
design a truthful-in-expectation mechanism whose utility is a $(1-1/e
-\eps)^3$-approximation to the optimal BIC mechanism under two mild
assumptions. Our mechanism consists of multiple rounds that processes each
buyer in a round with small probability. Lastly, we consider the problem of
revenue maximization for a risk neutral seller in presence of risk averse
buyers, and give a poly-time algorithm to design an optimal mechanism for the
seller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4723</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4723</id><created>2011-07-24</created><updated>2011-08-19</updated><authors><author><keyname>Haralambous</keyname><forenames>Yannis</forenames></author><author><keyname>Klyuev</keyname><forenames>Vitaly</forenames></author></authors><title>A Semantic Relatedness Measure Based on Combined Encyclopedic,
  Ontological and Collocational Knowledge</title><categories>cs.CL</categories><comments>6 pages, 6 figures, accepted for publication at IJCNLP2011 Conference</comments><msc-class>68T50</msc-class><acm-class>I.2.7</acm-class><journal-ref>Proceedings of the 5th International Joint Conference on Natural
  Language Processing, Chiang-Mai, Thailand, November 8-13, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a new semantic relatedness measure combining the Wikipedia-based
Explicit Semantic Analysis measure, the WordNet path measure and the mixed
collocation index. Our measure achieves the currently highest results on the
WS-353 test: a Spearman rho coefficient of 0.79 (vs. 0.75 in (Gabrilovich and
Markovitch, 2007)) when applying the measure directly, and a value of 0.87 (vs.
0.78 in (Agirre et al., 2009)) when using the prediction of a polynomial SVM
classifier trained on our measure.
  In the appendix we discuss the adaptation of ESA to 2011 Wikipedia data, as
well as various unsuccessful attempts to enhance ESA by filtering at word,
sentence, and section level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4724</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4724</id><created>2011-07-24</created><authors><author><keyname>de Guzm&#xe1;n</keyname><forenames>Pablo Chico</forenames></author><author><keyname>Casas</keyname><forenames>Amadeo</forenames></author><author><keyname>Carro</keyname><forenames>Manuel</forenames></author><author><keyname>Hermenegildo</keyname><forenames>Manuel V.</forenames></author></authors><title>Parallel Backtracking with Answer Memoing for Independent
  And-Parallelism</title><categories>cs.PL cs.DC</categories><comments>19 pages, 15 figures, uses tlp style</comments><journal-ref>Theory and Practice of Logic Programming (2011) volume 11, issue
  4-5, pages 555-574</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Goal-level Independent and-parallelism (IAP) is exploited by scheduling for
simultaneous execution two or more goals which will not interfere with each
other at run time. This can be done safely even if such goals can produce
multiple answers. The most successful IAP implementations to date have used
recomputation of answers and sequentially ordered backtracking. While in
principle simplifying the implementation, recomputation can be very inefficient
if the granularity of the parallel goals is large enough and they produce
several answers, while sequentially ordered backtracking limits parallelism.
And, despite the expected simplification, the implementation of the classic
schemes has proved to involve complex engineering, with the consequent
difficulty for system maintenance and extension, while still frequently running
into the well-known trapped goal and garbage slot problems. This work presents
an alternative parallel backtracking model for IAP and its implementation. The
model features parallel out-of-order (i.e., non-chronological) backtracking and
relies on answer memoization to reuse and combine answers. We show that this
approach can bring significant performance advantages. Also, it can bring some
simplification to the important engineering task involved in implementing the
backtracking mechanism of previous approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4730</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4730</id><created>2011-07-24</created><updated>2012-12-25</updated><authors><author><keyname>Sano</keyname><forenames>Yukie</forenames></author><author><keyname>Yamada</keyname><forenames>Kenta</forenames></author><author><keyname>Watanabe</keyname><forenames>Hayafumi</forenames></author><author><keyname>Takayasu</keyname><forenames>Hideki</forenames></author><author><keyname>Takayasu</keyname><forenames>Misako</forenames></author></authors><title>Empirical analysis of collective human behavior for extraordinary events
  in blogosphere</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>10 pages, 19 figures</comments><doi>10.1103/PhysRevE.87.012805</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To uncover underlying mechanism of collective human dynamics, we survey more
than 1.8 billion blog entries and observe the statistical properties of word
appearances. We focus on words that show dynamic growth and decay with a
tendency to diverge on a certain day. After careful pretreatment and fitting
method, we found power laws generally approximate the functional forms of
growth and decay with various exponents values between -0.1 and -2.5. We also
observe news words whose frequency increase suddenly and decay following power
laws. In order to explain these dynamics, we propose a simple model of posting
blogs involving a keyword, and its validity is checked directly from the data.
The model suggests that bloggers are not only responding to the latest number
of blogs but also suffering deadline pressure from the divergence day. Our
empirical results can be used for predicting the number of blogs in advance and
for estimating the period to return to the normal fluctuation level.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4734</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4734</id><created>2011-07-24</created><authors><author><keyname>Hssini</keyname><forenames>Mohamed</forenames></author><author><keyname>Lazrek</keyname><forenames>Azzeddine</forenames></author></authors><title>Design of Arabic Diacritical Marks</title><categories>cs.CL</categories><comments>10 pages, 24 figures; ISSN (Online): 1694-0814 http://www.IJCSI.org</comments><journal-ref>IJCSI International Journal of Computer Science Issues, Vol. 8,
  Issue 3, May 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Diacritical marks play a crucial role in meeting the criteria of usability of
typographic text, such as: homogeneity, clarity and legibility. To change the
diacritic of a letter in a word could completely change its semantic. The
situation is very complicated with multilingual text. Indeed, the problem of
design becomes more difficult by the presence of diacritics that come from
various scripts; they are used for different purposes, and are controlled by
various typographic rules. It is quite challenging to adapt rules from one
script to another. This paper aims to study the placement and sizing of
diacritical marks in Arabic script, with a comparison with the Latin's case.
The Arabic script is cursive and runs from right-to-left; its criteria and
rules are quite distinct from those of the Latin script. In the beginning, we
compare the difficulty of processing diacritics in both scripts. After, we will
study the limits of Latin resolution strategies when applied to Arabic. At the
end, we propose an approach to resolve the problem for positioning and resizing
diacritics. This strategy includes creating an Arabic font, designed in
OpenType format, along with suitable justification in TEX.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4747</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4747</id><created>2011-07-24</created><authors><author><keyname>Riguzzi</keyname><forenames>Fabrizio</forenames></author><author><keyname>Swift</keyname><forenames>Terrance</forenames></author></authors><title>The PITA System: Tabling and Answer Subsumption for Reasoning under
  Uncertainty</title><categories>cs.AI cs.LO cs.PL</categories><journal-ref>Theory and Practice of Logic Programming, 27th International
  Conference on Logic Programming (ICLP'11) Special Issue, 11(4-5), 433-449,
  2011</journal-ref><doi>10.1017/S147106841100010X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many real world domains require the representation of a measure of
uncertainty. The most common such representation is probability, and the
combination of probability with logic programs has given rise to the field of
Probabilistic Logic Programming (PLP), leading to languages such as the
Independent Choice Logic, Logic Programs with Annotated Disjunctions (LPADs),
Problog, PRISM and others. These languages share a similar distribution
semantics, and methods have been devised to translate programs between these
languages. The complexity of computing the probability of queries to these
general PLP programs is very high due to the need to combine the probabilities
of explanations that may not be exclusive. As one alternative, the PRISM system
reduces the complexity of query answering by restricting the form of programs
it can evaluate. As an entirely different alternative, Possibilistic Logic
Programs adopt a simpler metric of uncertainty than probability. Each of these
approaches -- general PLP, restricted PLP, and Possibilistic Logic Programming
-- can be useful in different domains depending on the form of uncertainty to
be represented, on the form of programs needed to model problems, and on the
scale of the problems to be solved. In this paper, we show how the PITA system,
which originally supported the general PLP language of LPADs, can also
efficiently support restricted PLP and Possibilistic Logic Programs. PITA
relies on tabling with answer subsumption and consists of a transformation
along with an API for library functions that interface with answer subsumption.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4751</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4751</id><created>2011-07-24</created><updated>2012-04-05</updated><authors><author><keyname>Ahrens</keyname><forenames>Benedikt</forenames><affiliation>University of Nice Sophia-Antipolis</affiliation></author></authors><title>Extended Initiality for Typed Abstract Syntax</title><categories>cs.LO cs.PL</categories><proxy>LMCS</proxy><acm-class>D.3.1, F.4.3</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 2 (April 6,
  2012) lmcs:1193</journal-ref><doi>10.2168/LMCS-8(2:1)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Initial Semantics aims at interpreting the syntax associated to a signature
as the initial object of some category of 'models', yielding induction and
recursion principles for abstract syntax. Zsid\'o proves an initiality result
for simply-typed syntax: given a signature S, the abstract syntax associated to
S constitutes the initial object in a category of models of S in monads.
However, the iteration principle her theorem provides only accounts for
translations between two languages over a fixed set of object types. We
generalize Zsid\'o's notion of model such that object types may vary, yielding
a larger category, while preserving initiality of the syntax therein. Thus we
obtain an extended initiality theorem for typed abstract syntax, in which
translations between terms over different types can be specified via the
associated category-theoretic iteration operator as an initial morphism. Our
definitions ensure that translations specified via initiality are type-safe,
i.e. compatible with the typing in the source and target language in the
obvious sense. Our main example is given via the propositions-as-types
paradigm: we specify propositions and inference rules of classical and
intuitionistic propositional logics through their respective typed signatures.
Afterwards we use the category--theoretic iteration operator to specify a
double negation translation from the former to the latter. A second example is
given by the signature of PCF. For this particular case, we formalize the
theorem in the proof assistant Coq. Afterwards we specify, via the
category-theoretic iteration operator, translations from PCF to the untyped
lambda calculus.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4763</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4763</id><created>2011-07-24</created><authors><author><keyname>Du</keyname><forenames>Jia</forenames></author><author><keyname>Goh</keyname><forenames>Alvina</forenames></author><author><keyname>Qiu</keyname><forenames>Anqi</forenames></author></authors><title>Diffeomorphic Metric Mapping of High Angular Resolution Diffusion
  Imaging based on Riemannian Structure of Orientation Distribution Functions</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose a novel large deformation diffeomorphic
registration algorithm to align high angular resolution diffusion images
(HARDI) characterized by orientation distribution functions (ODFs). Our
proposed algorithm seeks an optimal diffeomorphism of large deformation between
two ODF fields in a spatial volume domain and at the same time, locally
reorients an ODF in a manner such that it remains consistent with the
surrounding anatomical structure. To this end, we first review the Riemannian
manifold of ODFs. We then define the reorientation of an ODF when an affine
transformation is applied and subsequently, define the diffeomorphic group
action to be applied on the ODF based on this reorientation. We incorporate the
Riemannian metric of ODFs for quantifying the similarity of two HARDI images
into a variational problem defined under the large deformation diffeomorphic
metric mapping (LDDMM) framework. We finally derive the gradient of the cost
function in both Riemannian spaces of diffeomorphisms and the ODFs, and present
its numerical implementation. Both synthetic and real brain HARDI data are used
to illustrate the performance of our registration algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4785</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4785</id><created>2011-07-24</created><authors><author><keyname>Pal</keyname><forenames>Ranjan</forenames></author><author><keyname>Golubchik</keyname><forenames>Leana</forenames></author><author><keyname>Psounis</keyname><forenames>Konstantinos</forenames></author></authors><title>A Novel Cyber-Insurance for Internet Security</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Internet users such as individuals and organizations are subject to different
types of epidemic risks such as worms, viruses, and botnets. To reduce the
probability of risk, an Internet user generally invests in self-defense
mechanisms like antivirus and antispam software. However, such software does
not completely eliminate risk. Recent works have considered the problem of
residual risk elimination by proposing the idea of cyber-insurance. In reality,
an Internet user faces risks due to security attacks as well as risks due to
non-security related failures (e.g., reliability faults in the form of hardware
crash, buffer overflow, etc.) . These risk types are often indistinguishable by
a naive user. However, a cyber-insurance agency would most likely insure risks
only due to security attacks. In this case, it becomes a challenge for an
Internet user to choose the right type of cyber-insurance contract as standard
optimal contracts, i.e., contracts under security attacks only, might prove to
be sub-optimal for himself. In this paper, we address the problem of analyzing
cyber-insurance solutions when a user faces risks due to both, security as well
as non-security related failures. We propose \emph{Aegis}, a novel
cyber-insurance model in which the user accepts a fraction \emph{(strictly
positive)} of loss recovery on himself and transfers rest of the loss recovery
on the cyber-insurance agency. We mathematically show that given an option,
Internet users would prefer Aegis contracts to traditional cyber-insurance
contracts, under all premium types. This result firmly establishes the
non-existence of traditional cyber-insurance markets when Aegis contracts are
offered to users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4786</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4786</id><created>2011-07-24</created><authors><author><keyname>Golchay</keyname><forenames>Roya</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Mou&#xeb;l</keyname><forenames>Fr&#xe9;d&#xe9;ric Le</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Fr&#xe9;not</keyname><forenames>St&#xe9;phane</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author><author><keyname>Ponge</keyname><forenames>Julien</forenames><affiliation>CITI Insa Lyon / Inria Grenoble Rh&#xf4;ne-Alpes</affiliation></author></authors><title>Towards Bridging IoT and Cloud Services: Proposing Smartphones as Mobile
  and Autonomic Service Gateways</title><categories>cs.OS</categories><comments>Position Paper</comments><proxy>ccsd</proxy><journal-ref>UbiMob'2011 (2011) 45--48</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computing is currently getting at the same time incredibly in the small with
sensors/actuators embedded in our every- day objects and also greatly in the
large with data and ser- vice clouds accessible anytime, anywhere. This
Internet of Things is physically closed to the user but suffers from weak
run-time execution environments. Cloud Environments provide powerful data
storage and computing power but can not be easily accessed and integrate the
final-user context- awareness. We consider smartphones are set to become the
universal interface between these two worlds. In this position paper, we
propose a middleware approach where smartphones provide service gateways to
bridge the gap between IoT services and Cloud services. Since smartphones are
mobile gateways, they should be able to (re)configure themself according to
their place, things discovered around, and their own resources such battery.
Several issues are discussed: collaborative event-based context management,
adaptive and opportunistic service deployment and invocation, multi-criteria
(user- and performance-oriented) optimization decision algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4796</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4796</id><created>2011-07-24</created><authors><author><keyname>Jowharpour</keyname><forenames>Ali</forenames></author><author><keyname>dezfuli</keyname><forenames>Masha allah abbasi</forenames></author><author><keyname>Yektaee</keyname><forenames>Mohammad hosein</forenames></author></authors><title>Use Pronunciation by Analogy for text to speech system in Persian
  language</title><categories>cs.CL</categories><journal-ref>IJCSI Volume 8, Issue 3, May 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The interest in text to speech synthesis increased in the world .text to
speech have been developed formany popular languages such as English, Spanish
and French and many researches and developmentshave been applied to those
languages. Persian on the other hand, has been given little attentioncompared
to other languages of similar importance and the research in Persian is still
in its infancy.Persian language possess many difficulty and exceptions that
increase complexity of text to speechsystems. For example: short vowels is
absent in written text or existence of homograph words. in thispaper we propose
a new method for persian text to phonetic that base on pronunciations by
analogy inwords, semantic relations and grammatical rules for finding proper
phonetic. Keywords:PbA, text to speech, Persian language, FPbA
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4797</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4797</id><created>2011-07-24</created><authors><author><keyname>Schlegel</keyname><forenames>Christian</forenames></author><author><keyname>Truhachev</keyname><forenames>Dmitri</forenames></author></authors><title>Multiple Access Demodulation in the Lifted Signal Graph with Spatial
  Coupling</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Demodulation in a random multiple access channel is considered where the
signals are chosen uniformly randomly with unit energy, a model applicable to
several modern transmission systems. It is shown that by lifting (replicating)
the graph of this system and randomizing the graph connections, a simple
iterative cancellation demodulator can be constructed which achieves the same
performance as an optimal symbol-by-symbol detector of the original system. The
iterative detector has a complexity that is linear in the number of users,
while the direct optimal approach is known to be NP-hard. However, the maximal
system load of this lifted graph is limited to \alpha&lt;2.07, even for
signal-to-noise ratios going to infinity - the system is interference limited.
We then show that by introducing spatial coupling between subsequent lifted
graphs, and anchoring the initial graphs, this limitation can be avoided and
arbitrary system loads are achievable. Our results apply to several
well-documented system proposals, such as IDMA, partitioned spreading, and
certain forms of MIMO communications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4810</identifier>
 <datestamp>2013-01-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4810</id><created>2011-07-24</created><updated>2013-01-01</updated><authors><author><keyname>Caplan</keyname><forenames>Ronald M.</forenames></author><author><keyname>Carretero-Gonz&#xe1;lez</keyname><forenames>Ricardo</forenames></author></authors><title>Numerical Stability of Explicit Runge-Kutta Finite-Difference Schemes
  for the Nonlinear Schr\&quot;odinger Equation</title><categories>cs.NA</categories><comments>21 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linearized numerical stability bounds for solving the nonlinear
time-dependent Schr\&quot;odinger equation (NLSE) using explicit finite-differencing
are shown. The bounds are computed for the fourth-order Runge-Kutta scheme in
time and both second-order and fourth-order central differencing in space.
Results are given for Dirichlet, modulus-squared Dirichlet, Laplacian-zero, and
periodic boundary conditions for one, two, and three dimensions. Our approach
is to use standard Runge-Kutta linear stability theory, treating the
nonlinearity of the NLSE as a constant. The required bounds on the eigenvalues
of the scheme matrices are found analytically when possible, and otherwise
estimated using the Gershgorin circle theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4822</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4822</id><created>2011-07-24</created><authors><author><keyname>Samarasinghe</keyname><forenames>Tharaka</forenames></author><author><keyname>Inaltekin</keyname><forenames>Hazer</forenames></author><author><keyname>Evans</keyname><forenames>Jamie S.</forenames></author></authors><title>Optimal Selective Feedback Policies for Opportunistic Beamforming</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the structure of downlink sum-rate maximizing selective
decentralized feedback policies for opportunistic beamforming under finite
feedback constraints on the average number of mobile users feeding back.
Firstly, it is shown that any sum-rate maximizing selective decentralized
feedback policy must be a threshold feedback policy. This result holds for all
fading channel models with continuous distribution functions. Secondly, the
resulting optimum threshold selection problem is analyzed in detail. This is a
non-convex optimization problem over finite dimensional Euclidean spaces. By
utilizing the theory of majorization, an underlying Schur-concave structure in
the sum-rate function is identified, and the sufficient conditions for the
optimality of homogenous threshold feedback policies are obtained. Applications
of these results are illustrated for well known fading channel models such as
Rayleigh, Nakagami and Rician fading channels, along with various engineering
and design insights. Rather surprisingly, it is shown that using the same
threshold value at all mobile users is not always a rate-wise optimal feedback
strategy, even for a network with identical mobile users experiencing
statistically the same channel conditions. For the Rayleigh fading channel
model, on the other hand, homogenous threshold feedback policies are proven to
be rate-wise optimal if multiple orthonormal data carrying beams are used to
communicate with multiple mobile users simultaneously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4824</identifier>
 <datestamp>2013-02-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4824</id><created>2011-07-24</created><updated>2013-02-05</updated><authors><author><keyname>Kintali</keyname><forenames>Shiva</forenames></author><author><keyname>Kothari</keyname><forenames>Nishad</forenames></author><author><keyname>Kumar</keyname><forenames>Akash</forenames></author></authors><title>Approximation Algorithms for Digraph Width Parameters</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several problems that are NP-hard on general graphs are efficiently solvable
on graphs with bounded treewidth. Efforts have been made to generalize
treewidth and the related notion of pathwidth to digraphs. Directed treewidth,
DAG-width and Kelly-width are some such notions which generalize treewidth,
whereas directed pathwidth generalizes pathwidth. Each of these digraph width
measures have an associated decomposition structure.
  In this paper, we present approximation algorithms for all these digraph
width parameters. In particular, we give an O(sqrt{logn})-approximation
algorithm for directed treewidth, and an O({\log}^{3/2}{n})-approximation
algorithm for directed pathwidth, DAG-width and Kelly-width. Our algorithms
construct the corresponding decompositions whose widths are within the above
mentioned approximation factors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4829</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4829</id><created>2011-07-24</created><authors><author><keyname>Conlon</keyname><forenames>David</forenames></author><author><keyname>Fox</keyname><forenames>Jacob</forenames></author></authors><title>Bounds for graph regularity and removal lemmas</title><categories>math.CO cs.DM</categories><comments>62 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show, for any positive integer k, that there exists a graph in which any
equitable partition of its vertices into k parts has at least ck^2/\log^* k
pairs of parts which are not \epsilon-regular, where c,\epsilon&gt;0 are absolute
constants. This bound is tight up to the constant c and addresses a question of
Gowers on the number of irregular pairs in Szemer\'edi's regularity lemma.
  In order to gain some control over irregular pairs, another regularity lemma,
known as the strong regularity lemma, was developed by Alon, Fischer,
Krivelevich, and Szegedy. For this lemma, we prove a lower bound of
wowzer-type, which is one level higher in the Ackermann hierarchy than the
tower function, on the number of parts in the strong regularity lemma,
essentially matching the upper bound. On the other hand, for the induced graph
removal lemma, the standard application of the strong regularity lemma, we find
a different proof which yields a tower-type bound.
  We also discuss bounds on several related regularity lemmas, including the
weak regularity lemma of Frieze and Kannan and the recently established regular
approximation theorem. In particular, we show that a weak partition with
approximation parameter \epsilon may require as many as
2^{\Omega(\epsilon^{-2})} parts. This is tight up to the implied constant and
solves a problem studied by Lov\'asz and Szegedy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4838</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4838</id><created>2011-07-25</created><authors><author><keyname>Goto</keyname><forenames>Tatsuhiko</forenames></author><author><keyname>Hatanaka</keyname><forenames>Takeshi</forenames></author><author><keyname>Fujita</keyname><forenames>Masayuki</forenames></author></authors><title>Payoff-based Inhomogeneous Partially Irrational Play for Potential Game
  Theoretic Cooperative Control of Multi-agent Systems</title><categories>cs.SY math.OC</categories><comments>28 pages, 11 figures, submitted to IEEE TAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper handles a kind of strategic game called potential games and
develops a novel learning algorithm Payoff-based Inhomogeneous Partially
Irrational Play (PIPIP). The present algorithm is based on Distributed
Inhomogeneous Synchronous Learning (DISL) presented in an existing work but,
unlike DISL,PIPIP allows agents to make irrational decisions with a specified
probability, i.e. agents can choose an action with a low utility from the past
actions stored in the memory. Due to the irrational decisions, we can prove
convergence in probability of collective actions to potential function
maximizers. Finally, we demonstrate the effectiveness of the present algorithm
through experiments on a sensor coverage problem. It is revealed through the
demonstration that the present learning algorithm successfully leads agents to
around potential function maximizers even in the presence of undesirable Nash
equilibria. We also see through the experiment with a moving density function
that PIPIP has adaptability to environmental changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4850</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4850</id><created>2011-07-25</created><authors><author><keyname>Swain</keyname><forenames>Debabala</forenames></author><author><keyname>Panigrahi</keyname><forenames>S. P.</forenames></author><author><keyname>Routray</keyname><forenames>S. K.</forenames></author><author><keyname>Dash</keyname><forenames>P. K.</forenames></author><author><keyname>Mohanty</keyname><forenames>R. R.</forenames></author><author><keyname>Dash</keyname><forenames>S. K.</forenames></author></authors><title>WLAN location system: Background theories and future directions</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  This paper presents background theories and required steps towards
preparation of a WLAN location system. This paper targets on a software project
and intention behind this paper is to motivate the young researchers in the
area.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4851</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4851</id><created>2011-07-25</created><authors><author><keyname>Swain</keyname><forenames>Debabala</forenames></author><author><keyname>Paikaray</keyname><forenames>Bijay</forenames></author><author><keyname>Swain</keyname><forenames>Debabrata</forenames></author></authors><title>AWRP: Adaptive Weight Ranking Policy for Improving Cache Performance</title><categories>cs.PF cs.AR</categories><comments>6 pages; Journal of Computing, Volume 3, Issue 2, February 2011, ISSN
  2151-9617; http://www.journalofcomputing.org</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the huge difference in performance between the computer memory and
processor, the virtual memory management plays a vital role in system
performance. A Cache memory is the fast memory which is used to compensate the
speed difference between the memory and processor. This paper gives an adaptive
replacement policy over the traditional policy which has low overhead, better
performance and is easy to implement. Simulations show that our algorithm
performs better than Least-Recently-Used (LRU), First-In-First-Out (FIFO) and
Clock with Adaptive Replacement (CAR).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4865</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4865</id><created>2011-07-25</created><authors><author><keyname>Vennekens</keyname><forenames>Joost</forenames></author></authors><title>Actual Causation in CP-logic</title><categories>cs.AI</categories><msc-class>68T30</msc-class><acm-class>I.2.4</acm-class><journal-ref>Theory and Practice of Logic Programming, 27th Int'l. Conference
  on Logic Programming (ICLP'11) Special Issue, volume 11, issue 4-5,
  p.647-662, 2011</journal-ref><doi>10.1017/S1471068411000226</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a causal model of some domain and a particular story that has taken
place in this domain, the problem of actual causation is deciding which of the
possible causes for some effect actually caused it. One of the most influential
approaches to this problem has been developed by Halpern and Pearl in the
context of structural models. In this paper, I argue that this is actually not
the best setting for studying this problem. As an alternative, I offer the
probabilistic logic programming language of CP-logic. Unlike structural models,
CP-logic incorporates the deviant/default distinction that is generally
considered an important aspect of actual causation, and it has an explicitly
dynamic semantics, which helps to formalize the stories that serve as input to
an actual causation problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4873</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4873</id><created>2011-07-25</created><updated>2011-07-29</updated><authors><author><keyname>Xiang</keyname><forenames>Liu</forenames></author><author><keyname>Luo</keyname><forenames>Jun</forenames></author><author><keyname>Deng</keyname><forenames>Chenwei</forenames></author><author><keyname>Vasilakos</keyname><forenames>Athanasios V.</forenames></author><author><keyname>Lin</keyname><forenames>Weisi</forenames></author></authors><title>Dual-Level Compressed Aggregation: Recovering Fields of Physical
  Quantities from Incomplete Sensory Data</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Although wireless sensor networks (WSNs) are powerful in monitoring physical
events, the data collected from a WSN are almost always incomplete if the
surveyed physical event spreads over a wide area. The reason for this
incompleteness is twofold: i) insufficient network coverage and ii) data
aggregation for energy saving. Whereas the existing recovery schemes only
tackle the second aspect, we develop Dual-lEvel Compressed Aggregation (DECA)
as a novel framework to address both aspects. Specifically, DECA allows a high
fidelity recovery of a widespread event, under the situations that the WSN only
sparsely covers the event area and that an in-network data aggregation is
applied for traffic reduction. Exploiting both the low-rank nature of
real-world events and the redundancy in sensory data, DECA combines matrix
completion with a fine-tuned compressed sensing technique to conduct a
dual-level reconstruction process. We demonstrate that DECA can recover a
widespread event with less than 5% of the data, with respect to the dimension
of the event, being collected. Performance evaluation based on both synthetic
and real data sets confirms the recovery fidelity and energy efficiency of our
DECA framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4879</identifier>
 <datestamp>2015-12-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4879</id><created>2011-07-25</created><updated>2015-12-08</updated><authors><author><keyname>Mkrtchyan</keyname><forenames>Vahan V.</forenames></author><author><keyname>Vardanyan</keyname><forenames>Gagik N.</forenames></author></authors><title>On strongly spanning $k$-edge-colorable subgraphs</title><categories>cs.DM math.CO</categories><comments>12 pages, no figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A subgraph $H$ of a multigraph $G$ is called strongly spanning, if any vertex
of $G$ is not isolated in $H$, while it is called maximum $k$-edge-colorable,
if $H$ is proper $k$-edge-colorable and has the largest size. We introduce a
graph-parameter $sp(G)$, that coincides with the smallest $k$ that a graph $G$
has a strongly spanning maximum $k$-edge-colorable subgraph. Our first result
offers some alternative definitions of $sp(G)$. Next, we show that $\Delta(G)$
is an upper bound for $sp(G)$, and then we characterize the class of graphs $G$
that satisfy $sp(G)=\Delta(G)$. Finally, we prove some bounds for $sp(G)$ that
involve well-known graph-theoretic parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4890</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4890</id><created>2011-07-25</created><authors><author><keyname>Pawlewicz</keyname><forenames>Jakub</forenames></author></authors><title>Counting Square-Free Numbers</title><categories>math.NT cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main topic of this contribution is the problem of counting square-free
numbers not exceeding $n$. Before this work we were able to do it in time
(Comparing to the Big-O notation, Soft-O ($\softO$) ignores logarithmic
factors) $\softO(\sqrt{n})$. Here, the algorithm with time complexity
$\softO(n^{2/5})$ and with memory complexity $\softO(n^{1/5})$ is presented.
Additionally, a parallel version is shown, which achieves full scalability.
  As of now the highest computed value was for $n=10^{17}$. Using our
implementation we were able to calculate the value for $n=10^{36}$ on a
cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4893</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4893</id><created>2011-07-25</created><authors><author><keyname>Cohen</keyname><forenames>Nachshon</forenames></author><author><keyname>Nutov</keyname><forenames>Zeev</forenames></author></authors><title>Approximating minimum-power edge-multicovers</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a graph with edge costs, the {\em power} of a node is themaximum cost
of an edge incident to it, and the power of a graph is the sum of the powers of
its nodes. Motivated by applications in wireless networks, we consider the
following fundamental problem in wireless network design. Given a graph
$G=(V,E)$ with edge costs and degree bounds $\{r(v):v \in V\}$, the {\sf
Minimum-Power Edge-Multi-Cover} ({\sf MPEMC}) problem is to find a
minimum-power subgraph $J$ of $G$ such that the degree of every node $v$ in $J$
is at least $r(v)$. We give two approximation algorithms for {\sf MPEMC}, with
ratios $O(\log k)$ and $k+1/2$, where $k=\max_{v \in V} r(v)$ is the maximum
degree bound. This improves the previous ratios $O(\log n)$ and $k+1$, and
implies ratios $O(\log k)$ for the {\sf Minimum-Power $k$-Outconnected
Subgraph} and $O(\log k \log \frac{n}{n-k})$ for the {\sf Minimum-Power
$k$-Connected Subgraph} problems; the latter is the currently best known ratio
for the min-cost version of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4900</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4900</id><created>2011-07-25</created><authors><author><keyname>Uchikawa</keyname><forenames>Hironori</forenames></author><author><keyname>Kurkoski</keyname><forenames>Brian M.</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Threshold Improvement of Low-Density Lattice Codes via Spatial Coupling</title><categories>cs.IT math.IT</categories><comments>5 pages, 4 figures, submitted to ICNC2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spatially-coupled low-density lattice codes (LDLC) are constructed using
protographs. Using Monte Carlo density evolution using single-Gaussian
messages, we observe that the threshold of the spatially-coupled LDLC is within
0.22 dB of capacity of the unconstrained power channel. This is in contrast
with a 0.5 dB noise threshold for the conventional LDLC lattice construction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4918</identifier>
 <datestamp>2012-02-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4918</id><created>2011-07-25</created><updated>2012-02-21</updated><authors><author><keyname>Ghaffari</keyname><forenames>H. O.</forenames></author><author><keyname>Nasseri</keyname><forenames>M. H. B.</forenames></author><author><keyname>Young</keyname><forenames>R. P.</forenames></author></authors><title>Fluid Flow Complexity in Fracture Networks: Analysis with Graph Theory
  and LBM</title><categories>cs.CE</categories><comments>ARMA21012-ARMA 12-269</comments><report-no>ARMA 12-269</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Through this research, embedded synthetic fracture networks in rock masses
are studied. To analysis the fluid flow complexity in fracture networks with
respect to the variation of connectivity patterns, two different approaches are
employed, namely, the Lattice Boltzmann method and graph theory. The Lattice
Boltzmann method is used to show the sensitivity of the permeability and fluid
velocity distribution to synthetic fracture networks' connectivity patterns.
Furthermore, the fracture networks are mapped into the graphs, and the
characteristics of these graphs are compared to the main spatial fracture
networks. Among different characteristics of networks, we distinguish the
modularity of networks and sub-graphs distributions. We map the flow regimes
into the proper regions of the network's modularity space. Also, for each type
of fluid regime, corresponding motifs shapes are scaled. Implemented power law
distributions of fracture length in spatial fracture networks yielded the same
node's degree distribution in transformed networks. Two general spatial
networks are considered: random networks and networks with &quot;hubness&quot; properties
mimicking a spatial damage zone (both with power law distribution of fracture
length). In the first case, the fractures are embedded in uniformly distributed
fracture sets; the second case covers spatial fracture zones. We prove
numerically that the abnormal change (transition) in permeability is controlled
by the hub growth rate. Also, comparing LBM results with the characteristic
mean length of transformed networks' links shows a reverse relationship between
the aforementioned parameters. In addition, the abnormalities in advection
through nodes are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4922</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4922</id><created>2011-07-25</created><authors><author><keyname>Di Renzo</keyname><forenames>Marco</forenames></author><author><keyname>De Leonardis</keyname><forenames>Dario</forenames></author><author><keyname>Graziosi</keyname><forenames>Fabio</forenames></author><author><keyname>Haas</keyname><forenames>Harald</forenames></author></authors><title>On the Performance of Space Shift Keying (SSK) Modulation with Imperfect
  Channel Knowledge</title><categories>cs.PF</categories><comments>IEEE GLOBECOM 2011 (to appear)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the sensitivity and robustness of Space Shift Keying
(SSK) modulation to imperfect channel knowledge at the receiver. Unlike the
common widespread belief, we show that SSK modulation is more robust to
imperfect channel knowledge than other state-of-the-art transmission
technologies, and only few training pilots are needed to get reliable enough
channel estimates for data detection. More precisely, we focus our attention on
the so-called Time-Orthogonal-Signal-Design (TOSD-) SSK modulation scheme,
which is an improved version of SSK modulation offering transmit-diversity
gains, and provide the following contributions: i) we develop a closed-form
analytical framework to compute the Average Bit Error Probability (ABEP) of a
mismatched detector for TOSD-SSK modulation, which can be used for arbitrary
transmit-antenna, receive-antenna, channel fading, and training pilots; ii) we
perform a comparative study of the performance of TOSD-SSK modulation and the
Alamouti code under the same imperfect channel knowledge, and show that
TOSD-SSK modulation is more robust to channel estimation errors; iii) we point
out that only few pilot pulses are required to get performance very close to
the perfect channel knowledge lower-bound; and iv) we verify that transmit- and
receive-diversity gains of TOSD-SSK modulation are preserved even for a
mismatched receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4924</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4924</id><created>2011-07-25</created><authors><author><keyname>Arvanitis</keyname><forenames>Anastasios</forenames></author><author><keyname>Deligiannakis</keyname><forenames>Antonios</forenames></author></authors><title>Discovering Attractive Products based on Influence Sets</title><categories>cs.DB</categories><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Skyline queries have been widely used as a practical tool for multi-criteria
decision analysis and for applications involving preference queries. For
example, in a typical online retail application, skyline queries can help
customers select the most interesting, among a pool of available, products.
Recently, reverse skyline queries have been proposed, highlighting the
manufacturer's perspective, i.e. how to determine the expected buyers of a
given product. In this work we develop novel algorithms for two important
classes of queries involving customer preferences. We first propose a novel
algorithm, termed as RSA, for answering reverse skyline queries. We then
introduce a new type of queries, namely the k-Most Attractive Candidates k-MAC
query. In this type of queries, given a set of existing product specifications
P, a set of customer preferences C and a set of new candidate products Q, the
k-MAC query returns the set of k candidate products from Q that jointly
maximizes the total number of expected buyers, measured as the cardinality of
the union of individual reverse skyline sets (i.e., influence sets). Applying
existing approaches to solve this problem would require calculating the reverse
skyline set for each candidate, which is prohibitively expensive for large data
sets. We, thus, propose a batched algorithm for this problem and compare its
performance against a branch-and-bound variant that we devise. Both of these
algorithms use in their core variants of our RSA algorithm. Our experimental
study using both synthetic and real data sets demonstrates that our proposed
algorithms outperform existing, or naive solutions to our studied classes of
queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4929</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4929</id><created>2011-07-25</created><authors><author><keyname>Baskent</keyname><forenames>Can</forenames></author></authors><title>Some Non-Classical Approaches to the Branderburger-Keisler Paradox</title><categories>cs.GT cs.LO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper, we discuss a well-known self-referential paradox in
foundational game theory, the Brandenburger - Keisler paradox. We approach the
paradox from two different perspectives: non-well-founded set theory and
paraconsistent logic. We show that the paradox persists in both frameworks for
category theoretical reasons, but, with different properties.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4931</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4931</id><created>2011-07-25</created><authors><author><keyname>Baskent</keyname><forenames>Can</forenames></author></authors><title>A Logic for Strategy Updates</title><categories>cs.GT cs.LO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Notion of strategy in game theory is static and presumably constructed before
the game play. The static, pre-determined notion of strategies falls short
analyzing perfect information games. Because, we, people, do not strategize as
such even in perfect information games - largely because we are not logically
omniscient, and we have limited computational power and bounded memory. In this
paper, we focus on what we call move updates where some moves become
unavailable during the game. Our goal here is to present a formal framework for
move based strategy restrictions extending strategy logic which was introduced
by Ramanujam and Simon. In this paper, we present a dynamic version of strategy
logic, prove its completeness and decidability along with the decidability of
the strategy logic which was an open problem so far. We also present an
analysis of centipede by using our logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4932</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4932</id><created>2011-07-25</created><authors><author><keyname>Baskent</keyname><forenames>Can</forenames></author></authors><title>Homotopies in Classical and Paraconsistent Modal Logics</title><categories>math.LO cs.LO</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Topological semantics for modal logics has recently gained new momentum in
many different branches of logic. In this paper, we will consider the
topological semantics of both classical and paraconsistent modal logics.
  This work is a new step in the research program that focuses on
paraconsistent systems from geometric and topological point of view. Here, we
discuss the functional transformations in paraconsistent and classical modal
cases: how to transform one classical or paraconsistent topological model to
another, how to transform one transformation to another in a validity
preserving way. Furthermore, we also suggest a measure to keep track of such
change.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4935</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4935</id><created>2011-07-25</created><updated>2011-08-18</updated><authors><author><keyname>Baskent</keyname><forenames>Can</forenames></author></authors><title>Public Announcement Logic in Geometric Frameworks</title><categories>cs.LO cs.GT cs.MA</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we introduce public announcement logic in different geometric
frameworks. First, we consider topological models, and then extend our
discussion to a more expressive model, namely, subset space models.
Furthermore, we prove the completeness of public announcement logic in those
frameworks. Moreover, we apply our results to different issues: announcement
stabilization, backward induction and persistence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4937</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4937</id><created>2011-07-25</created><authors><author><keyname>Echenim</keyname><forenames>Mnacho</forenames></author><author><keyname>Peltier</keyname><forenames>Nicolas</forenames></author></authors><title>Instantiation Schemes for Nested Theories</title><categories>cs.AI</categories><acm-class>I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates under which conditions instantiation-based proof
procedures can be combined in a nested way, in order to mechanically construct
new instantiation procedures for richer theories. Interesting applications in
the field of verification are emphasized, particularly for handling extensions
of the theory of arrays.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4939</identifier>
 <datestamp>2011-11-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4939</id><created>2011-07-25</created><updated>2011-11-10</updated><authors><author><keyname>Baskent</keyname><forenames>Can</forenames></author></authors><title>Paraconsistency and Topological Semantics</title><categories>cs.LO</categories><comments>arXiv admin note: substantial text overlap with arXiv:1107.4932</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  The well-studied notion of deductive explosion describes the situation where
any formula can be deduced from an inconsistent set of formulas. Paraconsistent
logic, on the other hand, is the umbrella term for logical systems where the
logical consequence relation is not explosive. In this work, we investigate the
relationship between some different topological spaces and paraconsistency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4940</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4940</id><created>2011-07-25</created><authors><author><keyname>Kovachev</keyname><forenames>Dejan</forenames></author><author><keyname>Cao</keyname><forenames>Yiwei</forenames></author><author><keyname>Klamma</keyname><forenames>Ralf</forenames></author></authors><title>Mobile Cloud Computing: A Comparison of Application Models</title><categories>cs.NI cs.DC cs.MM</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Cloud computing is an emerging concept combining many fields of computing.
The foundation of cloud computing is the delivery of services, software and
processing capacity over the Internet, reducing cost, increasing storage,
automating systems, decoupling of service delivery from underlying technology,
and providing flexibility and mobility of information. However, the actual
realization of these benefits is far from being achieved for mobile
applications and open many new research questions. In order to better
understand how to facilitate the building of mobile cloud-based applications,
we have surveyed existing work in mobile computing through the prism of cloud
computing principles. We give a definition of mobile cloud coputing and provide
an overview of the results from this review, in particular, models of mobile
cloud applications. We also highlight research challenges in the area of mobile
cloud computing. We conclude with recommendations for how this better
understanding of mobile cloud computing can help building more powerful mobile
applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4950</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4950</id><created>2011-07-25</created><authors><author><keyname>Rehmani</keyname><forenames>Mubashir Husain</forenames></author></authors><title>Data Dissemination in Cognitive Radio Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this report, we first describe the problem that we are dealing with i.e.
data dissemination in multi-hop cognitive radio networks. To address this
problem, we propose a channel selection strategy named 'SURF'. We evaluate the
proposed channel selection strategy in both single-hop and multi-hop scenarios
and compared it with relevant approaches. So far, one technical report and a
poster is published as part of this work, while two publications are under
review; one is in IEEE Communications Letters and the second one is in IEEE
WoWMoM conference. In on-going works sections, we first mention some possible
directions in the context of SURF. In addition to that, we mention different
research problems that we are planning to deal during the course of this PhD
dissertation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4958</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4958</id><created>2011-07-25</created><authors><author><keyname>Elboher</keyname><forenames>Elhanan</forenames></author><author><keyname>Werman</keyname><forenames>Michael</forenames></author></authors><title>Efficient and Accurate Gaussian Image Filtering Using Running Sums</title><categories>cs.CV</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a simple and efficient method to convolve an image with a
Gaussian kernel. The computation is performed in a constant number of
operations per pixel using running sums along the image rows and columns. We
investigate the error function used for kernel approximation and its relation
to the properties of the input signal. Based on natural image statistics we
propose a quadratic form kernel error function so that the output image l2
error is minimized. We apply the proposed approach to approximate the Gaussian
kernel by linear combination of constant functions. This results in very
efficient Gaussian filtering method. Our experiments show that the proposed
technique is faster than state of the art methods while preserving a similar
accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4965</identifier>
 <datestamp>2012-01-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4965</id><created>2011-07-25</created><updated>2012-01-24</updated><authors><author><keyname>Park</keyname><forenames>Woomyoung</forenames></author><author><keyname>Barg</keyname><forenames>Alexander</forenames></author></authors><title>Polar codes for q-ary channels, q=2^r</title><categories>cs.IT math.IT</categories><comments>This version appears under a new title. Complete proofs of
  polarization have been added. The preliminary draft (v2) was published in
  Proc. 49th Allerton Conference, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study polarization for nonbinary channels with input alphabet of size
q=2^r,r=2,3,... Using Arikan's polarizing kernel H_2, we prove that the virtual
channels that arise in the process of polarization converge to q-ary channels
with capacity 1,2,...,r bits, and that the total transmission rate approaches
the symmetric capacity of the channel. This leads to an explicit transmission
scheme for q-ary channels. The error probability of decoding using successive
cancellation behaves as exp(-N^\alpha), where N is the code length and {\alpha}
is any constant less than 0.5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4966</identifier>
 <datestamp>2011-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4966</id><created>2011-07-25</created><updated>2011-08-26</updated><authors><author><keyname>Mihalkova</keyname><forenames>Lilyana</forenames></author><author><keyname>Getoor</keyname><forenames>Lise</forenames></author></authors><title>Lifted Graphical Models: A Survey</title><categories>cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article presents a survey of work on lifted graphical models. We review
a general form for a lifted graphical model, a par-factor graph, and show how a
number of existing statistical relational representations map to this
formalism. We discuss inference algorithms, including lifted inference
algorithms, that efficiently compute the answers to probabilistic queries. We
also review work in learning lifted graphical models from data. It is our
belief that the need for statistical relational models (whether it goes by that
name or another) will grow in the coming decades, as we are inundated with data
which is a mix of structured and unstructured, with entities and relations
extracted in a noisy manner from text, and with the need to reason effectively
with this data. We hope that this synthesis of ideas from many different
research groups will provide an accessible starting point for new researchers
in this expanding field.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4967</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4967</id><created>2011-07-25</created><authors><author><keyname>Corapi</keyname><forenames>Domenico</forenames></author><author><keyname>Russo</keyname><forenames>Alessandra</forenames></author><author><keyname>De Vos</keyname><forenames>Marina</forenames></author><author><keyname>Padget</keyname><forenames>Julian</forenames></author><author><keyname>Satoh</keyname><forenames>Ken</forenames></author></authors><title>Normative design using inductive learning</title><categories>cs.LO cs.AI cs.LG</categories><comments>Theory and Practice of Logic Programming, 27th Int'l. Conference on
  Logic Programming (ICLP'11) Special Issue, volume 11, issue 4-5, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose a use-case-driven iterative design methodology for
normative frameworks, also called virtual institutions, which are used to
govern open systems. Our computational model represents the normative framework
as a logic program under answer set semantics (ASP). By means of an inductive
logic programming approach, implemented using ASP, it is possible to synthesise
new rules and revise the existing ones. The learning mechanism is guided by the
designer who describes the desired properties of the framework through use
cases, comprising (i) event traces that capture possible scenarios, and (ii) a
state that describes the desired outcome. The learning process then proposes
additional rules, or changes to current rules, to satisfy the constraints
expressed in the use cases. Thus, the contribution of this paper is a process
for the elaboration and revision of a normative framework by means of a
semi-automatic and iterative process driven from specifications of
(un)desirable behaviour. The process integrates a novel and general methodology
for theory revision based on ASP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4969</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4969</id><created>2011-07-25</created><authors><author><keyname>Ni</keyname><forenames>Yizhao</forenames></author><author><keyname>Mcvicar</keyname><forenames>Matt</forenames></author><author><keyname>Santos-Rodriguez</keyname><forenames>Raul</forenames></author><author><keyname>De Bie</keyname><forenames>Tijl</forenames></author></authors><title>An end-to-end machine learning system for harmonic analysis of music</title><categories>cs.SD cs.AI cs.MM</categories><comments>MIREX report and preparation of Journal submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a new system for simultaneous estimation of keys, chords, and bass
notes from music audio. It makes use of a novel chromagram representation of
audio that takes perception of loudness into account. Furthermore, it is fully
based on machine learning (instead of expert knowledge), such that it is
potentially applicable to a wider range of genres as long as training data is
available. As compared to other models, the proposed system is fast and memory
efficient, while achieving state-of-the-art performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4970</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4970</id><created>2011-07-25</created><authors><author><keyname>Fink</keyname><forenames>Martin</forenames></author><author><keyname>Haunert</keyname><forenames>Jan-Henrik</forenames></author><author><keyname>Mchedlidze</keyname><forenames>Tamara</forenames></author><author><keyname>Spoerhase</keyname><forenames>Joachim</forenames></author><author><keyname>Wolff</keyname><forenames>Alexander</forenames></author></authors><title>Drawing Graphs with Vertices at Specified Positions and Crossings at
  Large Angles</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Point-set embeddings and large-angle crossings are two areas of graph drawing
that independently have received a lot of attention in the past few years. In
this paper, we consider problems in the intersection of these two areas. Given
the point-set-embedding scenario, we are interested in how much we gain in
terms of computational complexity, curve complexity, and generality if we allow
large-angle crossings as compared to the planar case. We investigate two
drawing styles where only bends or both bends and edges must be drawn on an
underlying grid. We present various results for drawings with one, two, and
three bends per edge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4981</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4981</id><created>2011-07-25</created><authors><author><keyname>Tonoyan</keyname><forenames>Tigran</forenames></author></authors><title>On the Problem of Wireless Scheduling with Linear Power Levels</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of communication scheduling in wireless
networks with respect to the SINR(Signal to Interference plus Noise Ratio)
constraint in metric spaces. The nodes are assigned linear powers, i.e. for
each sender node the power is constant times the path loss between the sender
and corresponding receiver. This is the minimal power for a successful
transmission. We present a constant factor deterministic approximation
algorithm, which works for at least Euclidean fading metrics. Simultaneously we
obtain the approximate value of the optimal schedule length with error at most
a constant factor. To give an insight into the complexity of the problem, we
show that in some metric spaces the problem is NP-hard and cannot be
approximated within a factor less than 1.5.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.4985</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.4985</id><created>2011-07-25</created><authors><author><keyname>Damianou</keyname><forenames>Andreas C.</forenames></author><author><keyname>Titsias</keyname><forenames>Michalis K.</forenames></author><author><keyname>Lawrence</keyname><forenames>Neil D.</forenames></author></authors><title>Variational Gaussian Process Dynamical Systems</title><categories>stat.ML cs.AI cs.CV math.PR</categories><comments>16 pages, 19 figures</comments><msc-class>60G15 (Primary), 62-09, 58E30</msc-class><acm-class>G.3; G.1.2; I.2.6; I.5.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  High dimensional time series are endemic in applications of machine learning
such as robotics (sensor data), computational biology (gene expression data),
vision (video sequences) and graphics (motion capture data). Practical
nonlinear probabilistic approaches to this data are required. In this paper we
introduce the variational Gaussian process dynamical system. Our work builds on
recent variational approximations for Gaussian process latent variable models
to allow for nonlinear dimensionality reduction simultaneously with learning a
dynamical prior in the latent space. The approach also allows for the
appropriate dimensionality of the latent space to be automatically determined.
We demonstrate the model on a human motion capture data set and a series of
high resolution video sequences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5000</identifier>
 <datestamp>2011-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5000</id><created>2011-07-25</created><authors><author><keyname>Lopes</keyname><forenames>Fabr&#xed;cio Martins</forenames></author><author><keyname>Martins-Jr</keyname><forenames>David C.</forenames></author><author><keyname>Barrera</keyname><forenames>Junior</forenames></author><author><keyname>Cesar-Jr</keyname><forenames>Roberto M.</forenames></author></authors><title>An iterative feature selection method for GRNs inference by exploring
  topological properties</title><categories>cs.CV cs.AI cs.IT math.IT q-bio.MN</categories><comments>10 pages, 5 figures, SFFS search method based on scale-free network
  topology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An important problem in bioinformatics is the inference of gene regulatory
networks (GRN) from temporal expression profiles. In general, the main
limitations faced by GRN inference methods is the small number of samples with
huge dimensionalities and the noisy nature of the expression measurements. In
face of these limitations, alternatives are needed to get better accuracy on
the GRNs inference problem. This work addresses this problem by presenting an
alternative feature selection method that applies prior knowledge on its search
strategy, called SFFS-BA. The proposed search strategy is based on the
Sequential Floating Forward Selection (SFFS) algorithm, with the inclusion of a
scale-free (Barab\'asi-Albert) topology information in order to guide the
search process to improve inference. The proposed algorithm explores the
scale-free property by pruning the search space and using a power law as a
weight for reducing it. In this way, the search space traversed by the SFFS-BA
method combines a breadth-first search when the number of combinations is small
(&lt;k&gt; &lt;= 2) with a depth-first search when the number of combinations becomes
explosive (&lt;k&gt; &gt;= 3), being guided by the scale-free prior information.
Experimental results show that the SFFS-BA provides a better inference
similarities than SFS and SFFS, keeping the robustness of the SFS and SFFS
methods, thus presenting very good results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5030</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5030</id><created>2011-07-25</created><updated>2011-07-26</updated><authors><author><keyname>Areias</keyname><forenames>Miguel</forenames></author><author><keyname>Rocha</keyname><forenames>Ricardo</forenames></author></authors><title>On Combining Linear-Based Strategies for Tabled Evaluation of Logic
  Programs</title><categories>cs.LO</categories><comments>16 pages, 9 figures, International Conference on Logic Programming
  (ICLP 2011)</comments><acm-class>D.1.6</acm-class><journal-ref>Theory and Practice of Logic Programming, Volume 11, Special Issue
  4-5, July 2011, pp 681-696 Published Cambridge University Press 2011</journal-ref><doi>10.1017/S147106841100024X</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tabled evaluation is a recognized and powerful technique that overcomes some
limitations of traditional Prolog systems in dealing with recursion and
redundant sub-computations. We can distinguish two main categories of tabling
mechanisms: suspension-based tabling and linear tabling. While suspension-based
mechanisms are considered to obtain better results in general, they have more
memory space requirements and are more complex and harder to implement than
linear tabling mechanisms. Arguably, the SLDT and DRA strategies are the two
most successful extensions to standard linear tabled evaluation. In this work,
we propose a new strategy, named DRS, and we present a framework, on top of the
Yap system, that supports the combination of all these three strategies. Our
implementation shares the underlying execution environment and most of the data
structures used to implement tabling in Yap. We thus argue that all these
common features allows us to make a first and fair comparison between these
different linear tabling strategies and, therefore, better understand the
advantages and weaknesses of each, when used solely or combined with the
others.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5068</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5068</id><created>2011-07-25</created><authors><author><keyname>Basu</keyname><forenames>Amitabh</forenames></author><author><keyname>Hildebrand</keyname><forenames>Robert</forenames></author><author><keyname>K&#xf6;ppe</keyname><forenames>Matthias</forenames></author></authors><title>Algorithmic and Complexity Results for Cutting Planes Derived from
  Maximal Lattice-Free Convex Sets</title><categories>math.OC cs.DM</categories><comments>35 pages, 15 figures</comments><msc-class>90C11</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a mixed integer linear program with m integer variables and k
non-negative continuous variables in the form of the relaxation of the corner
polyhedron that was introduced by Andersen, Louveaux, Weismantel and Wolsey
[Inequalities from two rows of a simplex tableau, Proc. IPCO 2007, LNCS, vol.
4513, Springer, pp. 1--15]. We describe the facets of this mixed integer linear
program via the extreme points of a well-defined polyhedron. We then utilize
this description to give polynomial time algorithms to derive valid
inequalities with optimal l_p norm for arbitrary, but fixed m. For the case of
m=2, we give a refinement and a new proof of a characterization of the facets
by Cornuejols and Margot [On the facets of mixed integer programs with two
integer variables and two constraints, Math. Programming 120 (2009), 429--456].
The key point of our approach is that the conditions are much more explicit and
can be tested in a more direct manner, removing the need for a reduction
algorithm. These results allow us to show that the relaxed corner polyhedron
has only polynomially many facets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5087</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5087</id><created>2011-07-25</created><updated>2011-08-01</updated><authors><author><keyname>Wang</keyname><forenames>Han</forenames></author><author><keyname>Desbat</keyname><forenames>Laurent</forenames></author><author><keyname>Legoupil</keyname><forenames>Samuel</forenames></author></authors><title>Image representation by blob and its application in CT reconstruction
  from few projections</title><categories>cs.NA</categories><comments>This paper has been withdrawn by the author due to some errors in the
  demonstration of proposition 2.2</comments><msc-class>65T60, 65F10, 94A20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The localized radial symmetric function, or blob, is an ideal alternative to
the pixel basis for X-ray computed tomography (CT) image reconstruction. In
this paper we develop image representation models using blob, and propose
reconstruction methods for few projections data. The image is represented in a
shift invariant space generated by a Gaussian blob or a multiscale blob system
of different frequency selectivity, and the reconstruction is done through
minimizing the Total Variation or the 1 norm of blob coefficients. Some 2D
numerical results are presented, where we use GPU platform for accelerating the
X-ray projection and back-projection, the interpolation and the gradient
computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5092</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5092</id><created>2011-07-25</created><authors><author><keyname>Johnson</keyname><forenames>Will</forenames></author></authors><title>Combinatorial Game Theory, Well-Tempered Scoring Games, and a Knot Game</title><categories>math.CO cs.GT</categories><comments>too many pages, undergrad honors senior thesis for the University of
  Washington, preliminary version</comments><msc-class>91A46</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We begin by reviewing and proving the basic facts of combinatorial game
theory. We then consider scoring games (also known as Milnor games or
positional games), focusing on the &quot;fixed-length&quot; games for which all sequences
of play terminate after the same number of moves. The theory of fixed-length
scoring games is shown to have properties similar to the theory of loopy
combinatorial games, with operations similar to onsides and offsides. We give a
complete description of the structure of fixed-length scoring games in terms of
the class of short partizan games. We also consider fixed-length scoring games
taking values in the two-element boolean algebra, and classify these games up
to indistinguishability. We then apply these results to analyze some positions
in the knotting-unknotting game of Pechenik, Townsend, Henrich, MacNaughton,
and Silversmith.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5093</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5093</id><created>2011-07-25</created><authors><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>Mitzenmacher</keyname><forenames>Michael</forenames></author><author><keyname>Ohrimenko</keyname><forenames>Olga</forenames></author><author><keyname>Tamassia</keyname><forenames>Roberto</forenames></author></authors><title>Oblivious RAM Simulation with Efficient Worst-Case Access Overhead</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Oblivious RAM simulation is a method for achieving confidentiality and
privacy in cloud computing environments. It involves obscuring the access
patterns to a remote storage so that the manager of that storage cannot infer
information about its contents. Existing solutions typically involve small
amortized overheads for achieving this goal, but nevertheless involve
potentially huge variations in access times, depending on when they occur. In
this paper, we show how to de-amortize oblivious RAM simulations, so that each
access takes a worst-case bounded amount of time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5102</identifier>
 <datestamp>2012-07-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5102</id><created>2011-07-25</created><updated>2012-07-30</updated><authors><author><keyname>Dumitrescu</keyname><forenames>Adrian</forenames></author><author><keyname>T&#xf3;th</keyname><forenames>Csaba D.</forenames></author></authors><title>Packing anchored rectangles</title><categories>math.CO cs.CG</categories><comments>17 pages, 7 figures; updated references</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $S$ be a set of $n$ points in the unit square $[0,1]^2$, one of which is
the origin. We construct $n$ pairwise interior-disjoint axis-aligned empty
rectangles such that the lower left corner of each rectangle is a point in $S$,
and the rectangles jointly cover at least a positive constant area (about
0.09). This is a first step towards the solution of a longstanding conjecture
that the rectangles in such a packing can jointly cover an area of at least
1/2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5108</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5108</id><created>2011-07-25</created><authors><author><keyname>Hatanaka</keyname><forenames>Takeshi</forenames></author><author><keyname>Fujita</keyname><forenames>Masayuki</forenames></author></authors><title>Cooperative Estimation of 3D Target Motion via Networked Visual Motion
  Observer</title><categories>cs.SY math.OC</categories><comments>32 pages, 18 figures, submitted to IEEE TAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates cooperative estimation of 3D target object motion for
visual sensor networks. In particular, we consider the situation where multiple
smart vision cameras see a group of target objects. The objective here is to
meet two requirements simultaneously: averaging for static objects and tracking
to moving target objects. For this purpose, we present a cooperative estimation
mechanism called networked visual motion observer. We then derive an upper
bound of the ultimate error between the actual average and the estimates
produced by the present networked estimation mechanism. Moreover, we also
analyze the tracking performance of the estimates to moving target objects.
Finally the effectiveness of the networked visual motion observer is
demonstrated through simulation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5114</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5114</id><created>2011-07-26</created><updated>2011-07-29</updated><authors><author><keyname>Zhao</keyname><forenames>Xiaohan</forenames></author><author><keyname>Sala</keyname><forenames>Alessandra</forenames></author><author><keyname>Zheng</keyname><forenames>Haitao</forenames></author><author><keyname>Zhao</keyname><forenames>Ben Y.</forenames></author></authors><title>Fast and Scalable Analysis of Massive Social Graphs</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Graph analysis is a critical component of applications such as online social
networks, protein interactions in biological networks, and Internet traffic
analysis. The arrival of massive graphs with hundreds of millions of nodes,
e.g. social graphs, presents a unique challenge to graph analysis applications.
Most of these applications rely on computing distances between node pairs,
which for large graphs can take minutes to compute using traditional algorithms
such as breadth-first-search (BFS). In this paper, we study ways to enable
scalable graph processing on today's massive graphs. We explore the design
space of graph coordinate systems, a new approach that accurately approximates
node distances in constant time by embedding graphs into coordinate spaces. We
show that a hyperbolic embedding produces relatively low distortion error, and
propose Rigel, a hyperbolic graph coordinate system that lends itself to
efficient parallelization across a compute cluster. Rigel produces
significantly more accurate results than prior systems, and is naturally
parallelizable across compute clusters, allowing it to provide accurate results
for graphs up to 43 million nodes. Finally, we show that Rigel's functionality
can be easily extended to locate (near-) shortest paths between node pairs.
After a one- time preprocessing cost, Rigel answers node-distance queries in
10's of microseconds, and also produces shortest path results up to 18 times
faster than prior shortest-path systems with similar levels of accuracy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5123</identifier>
 <datestamp>2011-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5123</id><created>2011-07-26</created><updated>2011-10-17</updated><authors><author><keyname>Shah</keyname><forenames>Shahid M.</forenames></author><author><keyname>Kumar</keyname><forenames>Vireshwar</forenames></author><author><keyname>Sharma</keyname><forenames>Vinod</forenames></author></authors><title>Achievable Secrecy Sum-Rate in a Fading MAC-WT with Power Control and
  without CSI of Eavesdropper</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, Conference version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a two user fading Multiple Access Channel with a wire-tapper
(MAC-WT) where the transmitter has the channel state information (CSI) to the
intended receiver but not to the eavesdropper (eve). We provide an achievable
secrecy sum-rate with optimal power control. We next provide a secrecy sum-rate
with optimal power control and cooperative jamming (CJ). We then study an
achievable secrecy sum rate by employing an ON/OFF power control scheme which
is more easily computable. We also employ CJ over this power control scheme.
Results show that CJ boosts the secrecy sum-rate significantly even if we do
not know the CSI of the eve's channel. At high SNR, the secrecy sum-rate (with
CJ) without CSI of the eve exceeds the secrecy sum-rate (without CJ) with full
CSI of the eve.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5142</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5142</id><created>2011-07-26</created><authors><author><keyname>Lisitsa</keyname><forenames>Alexei</forenames></author></authors><title>Finite countermodels for safety verification of parameterized tree
  systems</title><categories>cs.LO</categories><comments>18 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we deal with verification of safety properties of parameterized
systems with a tree topology. The verification problem is translated to a
purely logical problem of finding a finite countermodel for a first-order
formula, which further resolved by a generic finite model finding procedure. A
finite countermodel method is shown is at least as powerful as regular tree
model checking and as the methods based on monotonic abstraction and backwards
symbolic reachability. The practical efficiency of the method is illustrated on
a set of examples taken from the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5152</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5152</id><created>2011-07-26</created><authors><author><keyname>Gutmann</keyname><forenames>Bernd</forenames></author><author><keyname>Thon</keyname><forenames>Ingo</forenames></author><author><keyname>Kimmig</keyname><forenames>Angelika</forenames></author><author><keyname>Bruynooghe</keyname><forenames>Maurice</forenames></author><author><keyname>De Raedt</keyname><forenames>Luc</forenames></author></authors><title>The Magic of Logical Inference in Probabilistic Programming</title><categories>cs.LO</categories><comments>17 pages, 2 figures, International Conference on Logic Programming
  (ICLP 2011)</comments><acm-class>D.1.6</acm-class><journal-ref>Theory and Practice of Logic Programming, Volume 11, Special Issue
  4-5, July 2011, pp 663-680. Cambridge University Press 2011</journal-ref><doi>10.1017/S1471068411000238</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, many different probabilistic programming languages exist and even more
inference mechanisms for these languages. Still, most logic programming based
languages use backward reasoning based on SLD resolution for inference. While
these methods are typically computationally efficient, they often can neither
handle infinite and/or continuous distributions, nor evidence. To overcome
these limitations, we introduce distributional clauses, a variation and
extension of Sato's distribution semantics. We also contribute a novel
approximate inference method that integrates forward reasoning with importance
sampling, a well-known technique for probabilistic inference. To achieve
efficiency, we integrate two logic programming techniques to direct forward
sampling. Magic sets are used to focus on relevant parts of the program, while
the integration of backward reasoning allows one to identify and avoid regions
of the sample space that are inconsistent with the evidence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5154</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5154</id><created>2011-07-26</created><authors><author><keyname>Jarry</keyname><forenames>Aubin</forenames></author><author><keyname>Huc</keyname><forenames>Florian</forenames></author><author><keyname>Leone</keyname><forenames>Pierre</forenames></author><author><keyname>Rolim</keyname><forenames>Jose</forenames></author></authors><title>Distributed Planarization and Local Routing Strategies in Sensor
  Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm which computes a planar 2-spanner from an Unit Disk
Graph when the node density is sufficient. The communication complexity in
terms of number of node's identifier sent by the algorithm is $6n$, while the
computational complexity is $O(n\Delta)$, with $\Delta$ the maximum degree of
the communication graph. Furthermore, we present a simple and efficient routing
algorithm dedicated to the computed graph.
  Last but not least, using traditional Euclidean coordinates, our algorithm
needs the broadcast of as few as $3n$ node's identifiers. Under the hypothesis
of sufficient node density, no broadcast at all is needed, reducing the
previous best known complexity of an algorithm to compute a planar spanner of
an Unit Disk Graph which was of $5n$ broadcasts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5186</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5186</id><created>2011-07-26</created><authors><author><keyname>Nes</keyname><forenames>Preben Gr&#xe5;berg</forenames></author></authors><title>Fast multi-scale edge-detection in medical ultrasound signals</title><categories>cs.CV physics.med-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we suggest a fast multi-scale edge-detection scheme for
medical ultrasound signals. The edge-detector is based on well-known properties
of the continuous wavelet trans- form. To achieve both good localization of
edges and detect only significant edges, we study the maxima-lines of the
wavelet transform. One can obtain the maxima-lines between two scales by
computing the wavelet transform at several intermediate scales. To reduce
computational effort and time we suggest a time-scale filtering procedure which
uses only few scales to connect modulus-maxima across time-scale plane. The
design of this procedure is based on a study of maxima-lines corresponding to
edges typical for medical ultrasound signals. This study allows us to construct
an algorithm for medical ultrasound signals which meets the demand for speed,
but not on expense of reliability. The edge-detection algorithm has been
applied to a large class of medical ultrasound sig- nals including tumour-,
liver- and artery-images. Our results show that the proposed algorithm
effectively detects major features in such signals, including edges with low
contrast.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5187</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5187</id><created>2011-07-26</created><authors><author><keyname>Sasane</keyname><forenames>Amol</forenames></author></authors><title>Solvability of the $H^\infty$ algebraic Riccati equation in Banach
  algebras</title><categories>math.OC cs.SY math.AP math.FA math.RA</categories><comments>7 pages, 0 figures, submitted for publication in a journal</comments><msc-class>Primary 46J05, Secondary 93D15, 58C15, 47N20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $R$ be a commutative complex unital semisimple Banach algebra with the
involution $\cdot ^\star$. Sufficient conditions are given for the existence of
a stabilizing solution to the $H^\infty$ Riccati equation when the matricial
data has entries from $R$. Applications to spatially distributed systems are
discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5194</identifier>
 <datestamp>2012-08-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5194</id><created>2011-07-26</created><updated>2011-10-06</updated><authors><author><keyname>Gillis</keyname><forenames>Nicolas</forenames></author><author><keyname>Glineur</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Accelerated Multiplicative Updates and Hierarchical ALS Algorithms for
  Nonnegative Matrix Factorization</title><categories>math.OC cs.NA math.NA</categories><comments>17 pages, 10 figures. New Section 4 about the convergence of the
  accelerated algorithms; Removed Section 5 about efficiency of HALS. Accepted
  in Neural Computation</comments><journal-ref>Neural Computation 24 (4), pp. 1085-1105, 2012</journal-ref><doi>10.1162/NECO_a_00256</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nonnegative matrix factorization (NMF) is a data analysis technique used in a
great variety of applications such as text mining, image processing,
hyperspectral data analysis, computational biology, and clustering. In this
paper, we consider two well-known algorithms designed to solve NMF problems,
namely the multiplicative updates of Lee and Seung and the hierarchical
alternating least squares of Cichocki et al. We propose a simple way to
significantly accelerate these schemes, based on a careful analysis of the
computational cost needed at each iteration, while preserving their convergence
properties. This acceleration technique can also be applied to other
algorithms, which we illustrate on the projected gradient method of Lin. The
efficiency of the accelerated algorithms is empirically demonstrated on image
and text datasets, and compares favorably with a state-of-the-art alternating
nonnegative least squares algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5203</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5203</id><created>2011-07-26</created><authors><author><keyname>Sun</keyname><forenames>Qiyu</forenames></author></authors><title>Sparse approximation property and stable recovery of sparse signals from
  noisy measurements</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Trans. Signal Processing, 2011</comments><doi>10.1109/TSP.2011.2161470</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a sparse approximation property of order $s$ for
a measurement matrix ${\bf A}$: $$\|{\bf x}_s\|_2\le D \|{\bf A}{\bf x}\|_2+
\beta \frac{\sigma_s({\bf x})}{\sqrt{s}} \quad {\rm for\ all} \ {\bf x},$$
where ${\bf x}_s$ is the best $s$-sparse approximation of the vector ${\bf x}$
in $\ell^2$, $\sigma_s({\bf x})$ is the $s$-sparse approximation error of the
vector ${\bf x}$ in $\ell^1$, and $D$ and $\beta$ are positive constants. The
sparse approximation property for a measurement matrix can be thought of as a
weaker version of its restricted isometry property and a stronger version of
its null space property. In this paper, we show that the sparse approximation
property is an appropriate condition on a measurement matrix to consider stable
recovery of any compressible signal from its noisy measurements. In particular,
we show that any compressible signalcan be stably recovered from its noisy
measurements via solving an $\ell^1$-minimization problem if the measurement
matrix has the sparse approximation property with $\beta\in (0,1)$, and
conversely the measurement matrix has the sparse approximation property with
$\beta\in (0,\infty)$ if any compressible signal can be stably recovered from
its noisy measurements via solving an $\ell^1$-minimization problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5204</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5204</id><created>2011-07-26</created><authors><author><keyname>Kamarianakis</keyname><forenames>Manos N.</forenames></author><author><keyname>Karavelas</keyname><forenames>Menelaos I.</forenames></author></authors><title>Analysis of the Incircle predicate for the Euclidean Voronoi diagram of
  axes-aligned line segments</title><categories>cs.CG</categories><comments>17 pages, 4 figures, work presented in the paper is part of M.
  Kamarianakis' M.S. thesis</comments><msc-class>65U05 (Primary) 65D18 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the most-demanding predicate for computing the
Euclidean Voronoi diagram of axes-aligned line segments, namely the Incircle
predicate. Our contribution is two-fold: firstly, we describe, in algorithmic
terms, how to compute the Incircle predicate for axes-aligned line segments,
and secondly we compute its algebraic degree. Our primary aim is to minimize
the algebraic degree, while, at the same time, taking into account the amount
of operations needed to compute our predicate of interest.
  In our predicate analysis we show that the Incircle predicate can be answered
by evaluating the signs of algebraic expressions of degree at most 6; this is
half the algebraic degree we get when we evaluate the Incircle predicate using
the current state-of-the-art approach. In the most demanding cases of our
predicate evaluation, we reduce the problem of answering the Incircle predicate
to the problem of computing the sign of the value of a linear polynomial (in
one variable), when evaluated at a known specific root of a quadratic
polynomial (again in one variable). Another important aspect of our approach is
that, from a geometric point of view, we answer the most difficult case of the
predicate via implicitly performing point locations on an appropriately defined
subdivision of the place induced by the Voronoi circle implicated in the
Incircle predicate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5221</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5221</id><created>2011-07-26</created><authors><author><keyname>Gravin</keyname><forenames>Nick</forenames></author><author><keyname>Lu</keyname><forenames>Pinyan</forenames></author></authors><title>Competitive Auctions for Markets with Positive Externalities</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In digital goods auctions, there is an auctioneer who sells an item with
unlimited supply to a set of potential buyers, and the objective is to design
truthful auction to maximize the total profit of the auctioneer. Motivated from
an observation that the values of buyers for the item could be interconnected
through social networks, we study digital goods auctions with positive
externalities among the buyers. This defines a multi-parameter auction design
problem where the private valuation of every buyer is a function of other
winning buyers. The main contribution of this paper is a truthful competitive
mechanism for subadditive valuations. Our competitive result is with respect to
a new solution benchmark $\mathcal{F}^{(3)}$; on the other hand, we show a
surprising impossibility result if comparing to the benchmark
$\mathcal{F}^{(2)}$, where the latter has been used quite successfully in
digital goods auctions without extenalities \cite{Goldberg2006}. Our results
from $\mathcal{F}^{(2)}$ to $\mathcal{F}^{(3)}$ could be considered as the loss
of optimal profit at the cost of externalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5228</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5228</id><created>2011-07-26</created><authors><author><keyname>Dennunzio</keyname><forenames>Alberto</forenames></author><author><keyname>Formenti</keyname><forenames>Enrico</forenames></author><author><keyname>Provillard</keyname><forenames>Julien</forenames></author></authors><title>Non-Uniform Cellular Automata: classes, dynamics, and decidability</title><categories>cs.FL math.DS nlin.CG</categories><comments>Paper submitted to an international journal on June 9, 2011. This is
  an extended and improved version of the conference paper: G. Cattaneo, A.
  Dennunzio, E. Formenti, and J. Provillard. &quot;Non-uniform cellular automata&quot;.
  In Proceedings of LATA 2009, volume 5457 of Lecture Notes in Computer
  Science, pages 302-313. Springer</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The dynamical behavior of non-uniform cellular automata is compared with the
one of classical cellular automata. Several differences and similarities are
pointed out by a series of examples. Decidability of basic properties like
surjectivity and injectivity is also established. The final part studies a
strong form of equicontinuity property specially suited for non-uniform
cellular automata.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5236</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5236</id><created>2011-07-26</created><updated>2011-08-23</updated><authors><author><keyname>Emara</keyname><forenames>Wael</forenames></author><author><keyname>Kantardzic</keyname><forenames>Mehmed</forenames></author></authors><title>Submodular Optimization for Efficient Semi-supervised Support Vector
  Machines</title><categories>cs.LG cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we present a quadratic programming approximation of the
Semi-Supervised Support Vector Machine (S3VM) problem, namely approximate
QP-S3VM, that can be efficiently solved using off the shelf optimization
packages. We prove that this approximate formulation establishes a relation
between the low density separation and the graph-based models of
semi-supervised learning (SSL) which is important to develop a unifying
framework for semi-supervised learning methods. Furthermore, we propose the
novel idea of representing SSL problems as submodular set functions and use
efficient submodular optimization algorithms to solve them. Using this new idea
we develop a representation of the approximate QP-S3VM as a maximization of a
submodular set function which makes it possible to optimize using efficient
greedy algorithms. We demonstrate that the proposed methods are accurate and
provide significant improvement in time complexity over the state of the art in
the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5241</identifier>
 <datestamp>2012-06-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5241</id><created>2011-07-26</created><updated>2012-06-27</updated><authors><author><keyname>Becchetti</keyname><forenames>Luca</forenames></author><author><keyname>Clementi</keyname><forenames>Andrea</forenames></author><author><keyname>Pasquale</keyname><forenames>Francesco</forenames></author><author><keyname>Resta</keyname><forenames>Giovanni</forenames></author><author><keyname>Santi</keyname><forenames>Paolo</forenames></author><author><keyname>Silvestri</keyname><forenames>Riccardo</forenames></author></authors><title>Flooding Time in Opportunistic Networks under Power Law and Exponential
  Inter-Contact Times</title><categories>cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Performance bounds for opportunistic networks have been derived in a number
of recent papers for several key quantities, such as the expected delivery time
of a unicast message, or the flooding time (a measure of how fast information
spreads). However, to the best of our knowledge, none of the existing results
is derived under a mobility model which is able to reproduce the power
law+exponential tail dichotomy of the pairwise node inter-contact time
distribution which has been observed in traces of several real opportunistic
networks.
  The contributions of this paper are two-fold: first, we present a simple
pairwise contact model -- called the Home-MEG model -- for opportunistic
networks based on the observation made in previous work that pairs of nodes in
the network tend to meet in very few, selected locations (home locations); this
contact model is shown to be able to faithfully reproduce the power
law+exponential tail dichotomy of inter-contact time. Second, we use the
Home-MEG model to analyze flooding time in opportunistic networks, presenting
asymptotic bounds on flooding time that assume different initial conditions for
the existence of opportunistic links.
  Finally, our bounds provide some analytical evidences that the speed of
information spreading in opportunistic networks can be much faster than that
predicted by simple geometric mobility models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5242</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5242</id><created>2011-07-26</created><authors><author><keyname>Drescher</keyname><forenames>Conrad</forenames></author><author><keyname>Thielscher</keyname><forenames>Michael</forenames></author></authors><title>ALPprolog --- A New Logic Programming Method for Dynamic Domains</title><categories>cs.LO cs.AI</categories><comments>16 pages</comments><journal-ref>Theory and Practice of Logic Programming, 11(4-5), 451-468, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Logic programming is a powerful paradigm for programming autonomous agents in
dynamic domains, as witnessed by languages such as Golog and Flux. In this work
we present ALPprolog, an expressive, yet efficient, logic programming language
for the online control of agents that have to reason about incomplete
information and sensing actions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5252</identifier>
 <datestamp>2015-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5252</id><created>2011-07-26</created><updated>2013-11-18</updated><authors><author><keyname>Ahrens</keyname><forenames>Benedikt</forenames></author></authors><title>Modules over relative monads for syntax and semantics</title><categories>cs.LO cs.PL</categories><comments>v2: - Abstract and Introduction completely rewritten - Addition of
  examples and remarks in Secs. 1 and 2 - Sec 3 now describes the
  implementation in proof assistant Coq of the main theorem v3: - final version
  for publication in MSCS</comments><journal-ref>Math. Struct. in Comp. Science 26 (2014) 3-37</journal-ref><doi>10.1017/S0960129514000103</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an algebraic characterization of the syntax and semantics of a class
of languages with variable binding.
  We introduce a notion of 2-signature: such a signature specifies not only the
terms of a language, but also reduction rules on those terms. To any
2-signature $S$ we associate a category of &quot;models&quot; of $S$. This category has
an initial object, which integrates the terms freely generated by $S$, and
which is equipped with reductions according to the inequations given in $S$. We
call this initial object the language generated by $S$. Models of a
2--signature are built from relative monads and modules over such monads.
Through the use of monads, the models---and in particular, the initial
model---come equipped with a substitution operation that is compatible with
reduction in a suitable sense.
  The initiality theorem is formalized in the proof assistant Coq, yielding a
machinery which, when fed with a 2-signature, provides the associated
programming language with reduction relation and certified substitution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5266</identifier>
 <datestamp>2012-04-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5266</id><created>2011-07-26</created><authors><author><keyname>Havemann</keyname><forenames>Frank</forenames></author><author><keyname>Gl&#xe4;ser</keyname><forenames>Jochen</forenames></author><author><keyname>Heinz</keyname><forenames>Michael</forenames></author><author><keyname>Struck</keyname><forenames>Alexander</forenames></author></authors><title>Identifying Overlapping and Hierarchical Thematic Structures in Networks
  of Scholarly Papers: A Comparison of Three Approaches</title><categories>physics.soc-ph cs.DL cs.SI</categories><comments>18 pages, 9 figures</comments><journal-ref>PLoS ONE 2012 7(3): e33255</journal-ref><doi>10.1371/journal.pone.0033255</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We implemented three recently proposed approaches to the identification of
overlapping and hierarchical substructures in graphs and applied the
corresponding algorithms to a network of 492 information-science papers coupled
via their cited sources. The thematic substructures obtained and overlaps
produced by the three hierarchical cluster algorithms were compared to a
content-based categorisation, which we based on the interpretation of titles
and keywords. We defined sets of papers dealing with three topics located on
different levels of aggregation: h-index, webometrics, and bibliometrics. We
identified these topics with branches in the dendrograms produced by the three
cluster algorithms and compared the overlapping topics they detected with one
another and with the three pre-defined paper sets. We discuss the advantages
and drawbacks of applying the three approaches to paper networks in research
fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5269</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5269</id><created>2011-07-26</created><authors><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author></authors><title>Univariate global optimization with multiextremal non-differentiable
  constraints without penalty functions</title><categories>math.OC cs.NA math.NA physics.comp-ph</categories><comments>19 pages, 5 figures, 3 tables</comments><msc-class>90C26, 90C56, 65K05, 49M37</msc-class><journal-ref>Computational Optimization and Applications, 34(2), 229-248 (2006)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a new algorithm for solving constrained global
optimization problems where both the objective function and constraints are
one-dimensional non-differentiable multiextremal Lipschitz functions.
Multiextremal constraints can lead to complex feasible regions being
collections of isolated points and intervals having positive lengths. The case
is considered where the order the constraints are evaluated is fixed by the
nature of the problem and a constraint $i$ is defined only over the set where
the constraint $i-1$ is satisfied. The objective function is defined only over
the set where all the constraints are satisfied. In contrast to traditional
approaches, the new algorithm does not use any additional parameter or
variable. All the constraints are not evaluated during every iteration of the
algorithm providing a significant acceleration of the search. The new algorithm
either finds lower and upper bounds for the global optimum or establishes that
the problem is infeasible. Convergence properties and numerical experiments
showing a nice performance of the new method in comparison with the penalty
approach are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5279</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5279</id><created>2011-07-26</created><authors><author><keyname>Shah</keyname><forenames>Nihar B.</forenames></author><author><keyname>Rashmi</keyname><forenames>K. V.</forenames></author><author><keyname>Kumar</keyname><forenames>P. Vijay</forenames></author></authors><title>Information-theoretically Secure Regenerating Codes for Distributed
  Storage</title><categories>cs.IT cs.DC cs.NI math.IT</categories><comments>Globecom 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Regenerating codes are a class of codes for distributed storage networks that
provide reliability and availability of data, and also perform efficient node
repair. Another important aspect of a distributed storage network is its
security. In this paper, we consider a threat model where an eavesdropper may
gain access to the data stored in a subset of the storage nodes, and possibly
also, to the data downloaded during repair of some nodes. We provide explicit
constructions of regenerating codes that achieve information-theoretic secrecy
capacity in this setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5280</identifier>
 <datestamp>2011-07-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5280</id><created>2011-07-26</created><authors><author><keyname>Sergeyev</keyname><forenames>Yaroslav D.</forenames></author><author><keyname>Kvasov</keyname><forenames>Dmitri E.</forenames></author><author><keyname>Khalaf</keyname><forenames>Falah M. H.</forenames></author></authors><title>A One-Dimensional Local Tuning Algorithm for Solving GO Problems with
  Partially Defined Constraints</title><categories>math.OC cs.NA math.NA physics.comp-ph</categories><comments>15 pages, 5 figures, 4 tables</comments><msc-class>90C26, 65K05, 49M37, 90C56</msc-class><journal-ref>Sergeyev Ya.D., Kvasov D.E., Khalaf F.M.H. (2007) A
  one-dimensional local tuning algorithm for solving GO problems with partially
  defined constraints, Optimization Letters, 1(1), 85-99</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lipschitz one-dimensional constrained global optimization (GO) problems where
both the objective function and constraints can be multiextremal and
non-differentiable are considered in this paper. Problems, where the
constraints are verified in an a priori given order fixed by the nature of the
problem are studied. Moreover, if a constraint is not satisfied at a point,
then the remaining constraints and the objective function can be undefined at
this point. The constrained problem is reduced to a discontinuous unconstrained
problem by the index scheme without introducing additional parameters or
variables. A new geometric method using adaptive estimates of local Lipschitz
constants is introduced. The estimates are calculated by using the local tuning
technique proposed recently. Numerical experiments show quite a satisfactory
performance of the new method in comparison with the penalty approach and a
method using a priori given Lipschitz constants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5329</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5329</id><created>2011-07-26</created><authors><author><keyname>Zenklusen</keyname><forenames>Rico</forenames></author></authors><title>Matroidal Degree-Bounded Minimum Spanning Trees</title><categories>cs.DS cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the minimum spanning tree (MST) problem under the restriction
that for every vertex v, the edges of the tree that are adjacent to v satisfy a
given family of constraints. A famous example thereof is the classical
degree-constrained MST problem, where for every vertex v, a simple upper bound
on the degree is imposed. Iterative rounding/relaxation algorithms became the
tool of choice for degree-bounded network design problems. A cornerstone for
this development was the work of Singh and Lau, who showed for the
degree-bounded MST problem how to find a spanning tree violating each degree
bound by at most one unit and with cost at most the cost of an optimal solution
that respects the degree bounds.
  However, current iterative rounding approaches face several limits when
dealing with more general degree constraints. In particular, when several
constraints are imposed on the edges adjacent to a vertex v, as for example
when a partition of the edges adjacent to v is given and only a fixed number of
elements can be chosen out of each set of the partition, current approaches
might violate each of the constraints by a constant, instead of violating all
constraints together by at most a constant number of edges. Furthermore, it is
also not clear how previous iterative rounding approaches can be used for
degree constraints where some edges are in a super-constant number of
constraints.
  We extend iterative rounding/relaxation approaches both on a conceptual level
as well as aspects involving their analysis to address these limitations. This
leads to an efficient algorithm for the degree-constrained MST problem where
for every vertex v, the edges adjacent to v have to be independent in a given
matroid. The algorithm returns a spanning tree T of cost at most OPT, such that
for every vertex v, it suffices to remove at most 8 edges from T to satisfy the
matroidal degree constraint at v.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5348</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5348</id><created>2011-07-26</created><authors><author><keyname>Baronov</keyname><forenames>Dimitar</forenames></author><author><keyname>Baillieul</keyname><forenames>John</forenames></author></authors><title>Decision Making for Rapid Information Acquisition in the Reconnaissance
  of Random Fields</title><categories>cs.SY math.OC</categories><comments>34 pages, 20 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Research into several aspects of robot-enabled reconnaissance of random
fields is reported. The work has two major components: the underlying theory of
information acquisition in the exploration of unknown fields and the results of
experiments on how humans use sensor-equipped robots to perform a simulated
reconnaissance exercise.
  The theoretical framework reported herein extends work on robotic exploration
that has been reported by ourselves and others. Several new figures of merit
for evaluating exploration strategies are proposed and compared. Using concepts
from differential topology and information theory, we develop the theoretical
foundation of search strategies aimed at rapid discovery of topological
features (locations of critical points and critical level sets) of a priori
unknown differentiable random fields. The theory enables study of efficient
reconnaissance strategies in which the tradeoff between speed and accuracy can
be understood. The proposed approach to rapid discovery of topological features
has led in a natural way to to the creation of parsimonious reconnaissance
routines that do not rely on any prior knowledge of the environment. The design
of topology-guided search protocols uses a mathematical framework that
quantifies the relationship between what is discovered and what remains to be
discovered. The quantification rests on an information theory inspired model
whose properties allow us to treat search as a problem in optimal information
acquisition. A central theme in this approach is that &quot;conservative&quot; and
&quot;aggressive&quot; search strategies can be precisely defined, and search decisions
regarding &quot;exploration&quot; vs. &quot;exploitation&quot; choices are informed by the rate at
which the information metric is changing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5349</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5349</id><created>2011-07-26</created><authors><author><keyname>Pinello</keyname><forenames>Luca</forenames></author></authors><title>Multi Layer Analysis</title><categories>cs.CV cs.DS cs.LG q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This thesis presents a new methodology to analyze one-dimensional signals
trough a new approach called Multi Layer Analysis, for short MLA. It also
provides some new insights on the relationship between one-dimensional signals
processed by MLA and tree kernels, test of randomness and signal processing
techniques. The MLA approach has a wide range of application to the fields of
pattern discovery and matching, computational biology and many other areas of
computer science and signal processing. This thesis includes also some
applications of this approach to real problems in biology and seismology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5354</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5354</id><created>2011-07-26</created><authors><author><keyname>Galstyan</keyname><forenames>Aram</forenames></author><author><keyname>Kianercy</keyname><forenames>Ardeshir</forenames></author><author><keyname>Allahverdyan</keyname><forenames>Armen</forenames></author></authors><title>Replicator Dynamics of Co-Evolving Networks</title><categories>cs.GT cs.SI q-bio.PE</categories><comments>AAAI Complex Adaptive System Symposium, 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple model of network co-evolution in a game-dynamical system
of interacting agents that play repeated games with their neighbors, and adapt
their behaviors and network links based on the outcome of those games. The
adaptation is achieved through a simple reinforcement learning scheme. We show
that the collective evolution of such a system can be described by
appropriately defined replicator dynamics equations. In particular, we suggest
an appropriate factorization of the agents' strategies that results in a
coupled system of equations characterizing the evolution of both strategies and
network structure, and illustrate the framework on two simple examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5355</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5355</id><created>2011-07-26</created><authors><author><keyname>Eslami</keyname><forenames>Ali</forenames></author><author><keyname>Pishro-Nik</keyname><forenames>Hossein</forenames></author></authors><title>A Practical Approach to Polar Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study polar codes from a practical point of view. In
particular, we study concatenated polar codes and rate-compatible polar codes.
First, we propose a concatenation scheme including polar codes and Low-Density
Parity-Check (LDPC) codes. We will show that our proposed scheme outperforms
conventional concatenation schemes formed by LDPC and Reed-Solomon (RS) codes.
We then study two rate-compatible coding schemes using polar codes. We will see
that polar codes can be designed as universally capacity achieving
rate-compatible codes over a set of physically degraded channels. We also study
the effect of puncturing on polar codes to design rate-compatible codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5370</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5370</id><created>2011-07-26</created><authors><author><keyname>Fernandes</keyname><forenames>Cristina G.</forenames></author><author><keyname>Thomas</keyname><forenames>Robin</forenames></author></authors><title>Edge-coloring series-parallel multigraphs</title><categories>cs.DS math.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a simpler proof of Seymour's Theorem on edge-coloring series-parallel
multigraphs and derive a linear-time algorithm to check whether a given
series-parallel multigraph can be colored with a given number of colors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5372</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5372</id><created>2011-07-26</created><authors><author><keyname>Jiang</keyname><forenames>Weirong</forenames></author><author><keyname>Le</keyname><forenames>Hoang</forenames></author><author><keyname>Prasanna</keyname><forenames>Viktor K.</forenames></author></authors><title>Bidirectional Pipelining for Scalable IP Lookup and Packet
  Classification</title><categories>cs.NI cs.DS</categories><comments>tech report</comments><report-no>Technical Report CENG-2008-3, University of Southern California,
  2008</report-no><msc-class>68M10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Both IP lookup and packet classification in IP routers can be implemented by
some form of tree traversal. SRAM-based Pipelining can improve the throughput
dramatically. However, previous pipelining schemes result in unbalanced memory
allocation over the pipeline stages. This has been identified as a major
challenge for scalable pipelined solutions. This paper proposes a flexible
bidirectional linear pipeline architecture based on widely-used dual-port
SRAMs. A search tree is partitioned, and then mapped onto pipeline stages by a
bidirectional fine-grained mapping scheme. We introduce the notion of inversion
factor and several heuristics to invert subtrees for memory balancing. Due to
its linear structure, the architecture maintains packet input order, and
supports non-blocking route updates. Our experiments show that, the
architecture can achieve a perfectly balanced memory distribution over the
pipeline stages, for both trie-based IP lookup and tree-based multi-dimensional
packet classification. For IP lookup, it can store a full backbone routing
table with 154419 entries using 2MB of memory, and sustain a high throughput of
1.87 billion packets per second (GPPS), i.e. 0.6 Tbps for the minimum size (40
bytes) packets. The throughput can be improved further to be 2.4 Tbps, by
employing caching to exploit the Internet traffic locality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5377</identifier>
 <datestamp>2015-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5377</id><created>2011-07-26</created><updated>2015-09-09</updated><authors><author><keyname>Ibrahimi</keyname><forenames>Morteza</forenames></author><author><keyname>Kanoria</keyname><forenames>Yash</forenames></author><author><keyname>Kraning</keyname><forenames>Matt</forenames></author><author><keyname>Montanari</keyname><forenames>Andrea</forenames></author></authors><title>The set of solutions of random XORSAT formulae</title><categories>cs.DM cond-mat.dis-nn math.PR</categories><comments>Published at http://dx.doi.org/10.1214/14-AAP1060 in the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP1060</report-no><journal-ref>Annals of Applied Probability 2015, Vol. 25, No. 5, 2743-2808</journal-ref><doi>10.1214/14-AAP1060</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The XOR-satisfiability (XORSAT) problem requires finding an assignment of $n$
Boolean variables that satisfy $m$ exclusive OR (XOR) clauses, whereby each
clause constrains a subset of the variables. We consider random XORSAT
instances, drawn uniformly at random from the ensemble of formulae containing
$n$ variables and $m$ clauses of size $k$. This model presents several
structural similarities to other ensembles of constraint satisfaction problems,
such as $k$-satisfiability ($k$-SAT), hypergraph bicoloring and graph coloring.
For many of these ensembles, as the number of constraints per variable grows,
the set of solutions shatters into an exponential number of well-separated
components. This phenomenon appears to be related to the difficulty of solving
random instances of such problems. We prove a complete characterization of this
clustering phase transition for random $k$-XORSAT. In particular, we prove that
the clustering threshold is sharp and determine its exact location. We prove
that the set of solutions has large conductance below this threshold and that
each of the clusters has large conductance above the same threshold. Our proof
constructs a very sparse basis for the set of solutions (or the subset within a
cluster). This construction is intimately tied to the construction of specific
subgraphs of the hypergraph associated with an instance of $k$-XORSAT. In order
to study such subgraphs, we establish novel local weak convergence results for
them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5387</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5387</id><created>2011-07-27</created><authors><author><keyname>Gulrez</keyname><forenames>Tauseef</forenames></author><author><keyname>Tognetti</keyname><forenames>Alessandro</forenames></author><author><keyname>Fishbach</keyname><forenames>Alon</forenames></author><author><keyname>Acosta</keyname><forenames>Santiago</forenames></author><author><keyname>Scharver</keyname><forenames>Christopher</forenames></author><author><keyname>De Rossi</keyname><forenames>Danilo</forenames></author><author><keyname>Mussa-Ivaldi</keyname><forenames>Ferdinando A.</forenames></author></authors><title>Controlling wheelchairs by body motions: A learning framework for the
  adaptive remapping of space</title><categories>cs.RO cs.AI cs.NE</categories><comments>This paper was published in the proceedings of Cognitive Systems
  2008, Karlsruhe, Germany</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Learning to operate a vehicle is generally accomplished by forming a new
cognitive map between the body motions and extrapersonal space. Here, we
consider the challenge of remapping movement-to-space representations in
survivors of spinal cord injury, for the control of powered wheelchairs. Our
goal is to facilitate this remapping by developing interfaces between residual
body motions and navigational commands that exploit the degrees of freedom that
disabled individuals are most capable to coordinate. We present a new framework
for allowing spinal cord injured persons to control powered wheelchairs through
signals derived from their residual mobility. The main novelty of this approach
lies in substituting the more common joystick controllers of powered
wheelchairs with a sensor shirt. This allows the whole upper body of the user
to operate as an adaptive joystick. Considerations about learning and risks
have lead us to develop a safe testing environment in 3D Virtual Reality. A
Personal Augmented Reality Immersive System (PARIS) allows us to analyse
learning skills and provide users with an adequate training to control a
simulated wheelchair through the signals generated by body motions in a safe
environment. We provide a description of the basic theory, of the development
phases and of the operation of the complete system. We also present preliminary
results illustrating the processing of the data and supporting of the
feasibility of this approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5397</identifier>
 <datestamp>2015-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5397</id><created>2011-07-27</created><authors><author><keyname>Headayetullah</keyname><forenames>Md.</forenames></author><author><keyname>Pradhan</keyname><forenames>G. K.</forenames></author><author><keyname>Biswas</keyname><forenames>Sanjay</forenames></author><author><keyname>Puthal</keyname><forenames>B.</forenames></author></authors><title>Proposed Information Sharing Security Approach for Security Personnels,
  Vertical Integration, Semantic Interoperability Architecture and Framework
  for Digital Government</title><categories>cs.CR</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper mainly depicts the conceptual overview of vertical integration,
semantic interoperability architecture such as Educational Sector Architectural
Framework (ESAF) for New Zealand government and different interoperability
framework solution for digital government. In this paper, we try to develop a
secure information sharing approach for digital government to improve home land
security. This approach is a role and cooperation based approach for security
personnel of different government departments. In order to run any successful
digital government of any country in the world, it is necessary to interact
with their citizen and to share secure information via different network among
the citizen or other government. Consequently, in order to smooth the progress
of users to cooperate with and share information without darkness and
flawlessly transversely different networks and databases universally, a safe
and trusted information-sharing environment has been renowned as a very
important requirement and to press forward homeland security endeavor. The key
incentive following this research is to put up a secure and trusted
information-sharing approach for government departments. This paper presents a
proficient function and teamwork based information sharing approach for safe
exchange of hush-hush and privileged information amid security personnels and
government departments inside the national boundaries by means of public key
cryptography. The expanded approach makes use of cryptographic hash function;
public key cryptosystem and a unique and complex mapping function for securely
swapping over secret information. Moreover, the projected approach facilitates
privacy preserving information sharing with probable restrictions based on the
rank of the security personnels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5399</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5399</id><created>2011-07-27</created><authors><author><keyname>Bi</keyname><forenames>Suzhi</forenames><affiliation>Angela</affiliation></author><author><keyname>Jun</keyname><forenames>Ying</forenames><affiliation>Angela</affiliation></author><author><keyname>Zhang</keyname></author></authors><title>TDMA Achieves the Optimal Diversity Gain in Relay-Assisted Cellular
  Networks</title><categories>cs.NI</categories><comments>26 pages, 8 figures</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In multi-access wireless networks, transmission scheduling is a key component
that determines the efficiency and fairness of wireless spectrum allocation. At
one extreme, greedy opportunistic scheduling that allocates airtime to the user
with the largest instantaneous channel gain achieves the optimal spectrum
efficiency and transmission reliability but the poorest user-level fairness. At
the other extreme, fixed TDMA scheduling achieves the fairest airtime
allocation but the lowest spectrum efficiency and transmission reliability. To
balance the two competing objectives, extensive research efforts have been
spent on designing opportunistic scheduling schemes that reach certain tradeoff
points between the two extremes. In this paper and in contrast to the
conventional wisdom, we find that in relay-assisted cellular networks, fixed
TDMA achieves the same optimal diversity gain as greedy opportunistic
scheduling. In addition, by incorporating very limited opportunism, a simple
relaxed-TDMA scheme asymptotically achieves the same optimal system reliability
in terms of outage probability as greedy opportunistic scheduling. This reveals
a surprising fact: transmission reliability and user fairness are no longer
contradicting each other in relay-assisted systems. They can be both achieved
by the simple TDMA schemes. For practical implementations, we further propose a
fully distributed algorithm to implement the relaxed-TDMA scheme. Our results
here may find applications in the design of next-generation wireless
communication systems with relay architectures such as LTE-advanced and WiMAX.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5408</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5408</id><created>2011-07-27</created><authors><author><keyname>Porto</keyname><forenames>Ant&#xf3;nio</forenames></author></authors><title>A structured alternative to Prolog with simple compositional semantics</title><categories>cs.PL</categories><comments>27th Int'l. Conference on Logic Programming (ICLP'11) Special Issue,
  2011</comments><acm-class>D.3.1; D.3.3; F.3.2</acm-class><journal-ref>Theory and Practice of Logic Programming 11(4-5), 611-627, 2011</journal-ref><doi>10.1017/S1471068411000202</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Prolog's very useful expressive power is not captured by traditional logic
programming semantics, due mainly to the cut and goal and clause order. Several
alternative semantics have been put forward, exposing operational details of
the computation state. We propose instead to redesign Prolog around structured
alternatives to the cut and clauses, keeping the expressive power and
computation model but with a compositional denotational semantics over much
simpler states-just variable bindings. This considerably eases reasoning about
programs, by programmers and tools such as a partial evaluator, with safe
unfolding of calls through predicate definitions. An if-then-else across
clauses replaces most uses of the cut, but the cut's full power is achieved by
an until construct. Disjunction, conjunction and until, along with unification,
are the primitive goal types with a compositional semantics yielding sequences
of variable-binding solutions. This extends to programs via the usual technique
of a least fixpoint construction. A simple interpreter for Prolog in the
alternative language, and a definition of until in Prolog, establish the
identical expressive power of the two languages. Many useful control constructs
are derivable from the primitives, and the semantic framework illuminates the
discussion of alternative ones. The formalisation rests on a term language with
variable abstraction as in the {\lambda}-calculus. A clause is an abstraction
on the call arguments, a continuation, and the local variables. It can be
inclusive or exclusive, expressing a local case bound to a continuation by
either a disjunction or an if-then-else. Clauses are open definitions, composed
(and closed) with simple functional application ({\beta}-reduction). This paves
the way for a simple account of flexible module composition mechanisms. Cube, a
concrete language with the exposed principles, has been implemented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5419</identifier>
 <datestamp>2011-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5419</id><created>2011-07-27</created><updated>2011-11-23</updated><authors><author><keyname>Gambs</keyname><forenames>Sebastien</forenames></author><author><keyname>Guerraoui</keyname><forenames>Rachid</forenames></author><author><keyname>Harkous</keyname><forenames>Hamza</forenames></author><author><keyname>Huc</keyname><forenames>Florian</forenames></author><author><keyname>Kermarrec</keyname><forenames>Anne-Marie</forenames></author></authors><title>Scalable and Secure Aggregation in Distributed Networks</title><categories>cs.DC cs.CC cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of computing an aggregation function in a
\emph{secure} and \emph{scalable} way. Whereas previous distributed solutions
with similar security guarantees have a communication cost of $O(n^3)$, we
present a distributed protocol that requires only a communication complexity of
$O(n\log^3 n)$, which we prove is near-optimal. Our protocol ensures perfect
security against a computationally-bounded adversary, tolerates
$(1/2-\epsilon)n$ malicious nodes for any constant $1/2 &gt; \epsilon &gt; 0$ (not
depending on $n$), and outputs the exact value of the aggregated function with
high probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5448</identifier>
 <datestamp>2012-02-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5448</id><created>2011-07-27</created><authors><author><keyname>Dupuis</keyname><forenames>Paul</forenames></author><author><keyname>Spiliopoulos</keyname><forenames>Konstantinos</forenames></author><author><keyname>Wang</keyname><forenames>Hui</forenames></author></authors><title>Importance Sampling for Multiscale Diffusions</title><categories>math.PR cs.SY math.OC</categories><msc-class>60F05, 60F10, 60G60</msc-class><journal-ref>SIAM Journal on Multiscale Modeling and Simulation , Vol. 12, No.
  1, 2012, pp. 1-27</journal-ref><doi>10.1137/110842545</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct importance sampling schemes for stochastic differential
equations with small noise and fast oscillating coefficients. Standard Monte
Carlo methods perform poorly for these problems in the small noise limit. With
multiscale processes there are additional complications, and indeed the
straightforward adaptation of methods for standard small noise diffusions will
not produce efficient schemes. Using the subsolution approach we construct
schemes and identify conditions under which the schemes will be asymptotically
optimal. Examples and simulation results are provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5462</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5462</id><created>2011-07-27</created><authors><author><keyname>Burke</keyname><forenames>Edmund</forenames></author><author><keyname>Curtois</keyname><forenames>Tim</forenames></author><author><keyname>Hyde</keyname><forenames>Matthew</forenames></author><author><keyname>Ochoa</keyname><forenames>Gabriela</forenames></author><author><keyname>Vazquez-Rodriguez</keyname><forenames>Jose A.</forenames></author></authors><title>HyFlex: A Benchmark Framework for Cross-domain Heuristic Search</title><categories>cs.AI</categories><comments>28 pages, 9 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automating the design of heuristic search methods is an active research field
within computer science, artificial intelligence and operational research. In
order to make these methods more generally applicable, it is important to
eliminate or reduce the role of the human expert in the process of designing an
effective methodology to solve a given computational search problem.
Researchers developing such methodologies are often constrained on the number
of problem domains on which to test their adaptive, self-configuring
algorithms; which can be explained by the inherent difficulty of implementing
their corresponding domain specific software components.
  This paper presents HyFlex, a software framework for the development of
cross-domain search methodologies. The framework features a common software
interface for dealing with different combinatorial optimisation problems, and
provides the algorithm components that are problem specific. In this way, the
algorithm designer does not require a detailed knowledge the problem domains,
and thus can concentrate his/her efforts in designing adaptive general-purpose
heuristic search algorithms. Four hard combinatorial problems are fully
implemented (maximum satisfiability, one dimensional bin packing, permutation
flow shop and personnel scheduling), each containing a varied set of instance
data (including real-world industrial applications) and an extensive set of
problem specific heuristics and search operators. The framework forms the basis
for the first International Cross-domain Heuristic Search Challenge (CHeSC),
and it is currently in use by the international research community. In summary,
HyFlex represents a valuable new benchmark of heuristic search generality, with
which adaptive cross-domain algorithms are being easily developed, and reliably
compared.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5468</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5468</id><created>2011-07-27</created><authors><author><keyname>Zarikoff</keyname><forenames>Brad W.</forenames></author><author><keyname>Leith</keyname><forenames>Douglas J.</forenames></author></authors><title>Measuring Pulsed Interference in 802.11 Links</title><categories>cs.NI</categories><comments>13 pages, submitted to IEEE/ACM Transactions on Networking</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless 802.11 links operate in unlicensed spectrum and so must accommodate
other unlicensed transmitters which generate pulsed interference. We propose a
new approach for detecting the presence of pulsed interference affecting 802.11
links, and for estimating temporal statistics of this interference. This
approach builds on recent work on distinguishing collision losses from noise
losses in 802.11 links. When the intervals between interference pulses are
i.i.d., the approach is not confined to estimating the mean and variance of
these intervals but can recover the complete probability distribution. The
approach is a transmitter-side technique that provides per-link information and
is compatible with standard hardware. We demonstrate the effectiveness of the
proposed approach using extensive experimental measurements. In addition to
applications to monitoring, management and diagnostics, the fundamental
information provided by our approach can potentially be used to adapt the frame
durations used in a network so as to increase capacity in the presence of
pulsed interference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5469</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5469</id><created>2011-07-27</created><authors><author><keyname>Wallace</keyname><forenames>Matthew L.</forenames></author><author><keyname>Larivi&#xe8;re</keyname><forenames>Vincent</forenames></author><author><keyname>Gingras</keyname><forenames>Yves</forenames></author></authors><title>A small world of citations? The influence of collaboration networks on
  citation practices</title><categories>physics.soc-ph cs.DL cs.SI</categories><doi>10.1371/journal.pone.0033339</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper examines the proximity of authors to those they cite using degrees
of separation in a co-author network, essentially using collaboration networks
to expand on the notion of self-citations. While the proportion of direct
self-citations (including co-authors of both citing and cited papers) is
relatively constant in time and across specialties in the natural sciences (10%
of citations) and the social sciences (20%), the same cannot be said for
citations to authors who are members of the co-author network. Differences
between fields and trends over time lie not only in the degree of co-authorship
which defines the large-scale topology of the collaboration network, but also
in the referencing practices within a given discipline, computed by defining a
propensity to cite at a given distance within the collaboration network.
Overall, there is little tendency to cite those nearby in the collaboration
network, excluding direct self-citations. By analyzing these social references,
we characterize the social capital of local collaboration networks in terms of
the knowledge production within scientific fields. These results have
implications for the long-standing debate over biases common to most types of
citation analysis, and for understanding citation practices across scientific
disciplines over the past 50 years. In addition, our findings have important
practical implications for the availability of 'arm's length' expert reviewers
of grant applications and manuscripts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5474</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5474</id><created>2011-07-27</created><updated>2011-08-04</updated><authors><author><keyname>Aranda-Corral</keyname><forenames>Gonzalo A.</forenames></author><author><keyname>Borrego-D&#xed;az</keyname><forenames>Joaqu&#xed;n</forenames></author><author><keyname>Gal&#xe1;n-P&#xe1;ez</keyname><forenames>Juan</forenames></author></authors><title>Selecting Attributes for Sport Forecasting using Formal Concept Analysis</title><categories>cs.AI</categories><comments>Paper 3 for the Complex Systems in Sports Workshop 2011 (CS-Sports
  2011)</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In order to address complex systems, apply pattern recongnition on their
evolution could play an key role to understand their dynamics. Global patterns
are required to detect emergent concepts and trends, some of them with
qualitative nature. Formal Concept Analysis (FCA) is a theory whose goal is to
discover and to extract Knowledge from qualitative data. It provides tools for
reasoning with implication basis (and association rules). Implications and
association rules are usefull to reasoning on previously selected attributes,
providing a formal foundation for logical reasoning. In this paper we analyse
how to apply FCA reasoning to increase confidence in sports betting, by means
of detecting temporal regularities from data. It is applied to build a
Knowledge-Based system for confidence reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5478</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5478</id><created>2011-07-27</created><authors><author><keyname>Dadush</keyname><forenames>Daniel</forenames></author><author><keyname>Vempala</keyname><forenames>Santosh</forenames></author></authors><title>Deterministic Construction of an Approximate M-Ellipsoid and its
  Application to Derandomizing Lattice Algorithms</title><categories>cs.CC math.FA</categories><msc-class>52C07, 68Q25</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a deterministic O(log n)^n algorithm for the {\em Shortest Vector
Problem (SVP)} of a lattice under {\em any} norm, improving on the previous
best deterministic bound of n^O(n) for general norms and nearly matching the
bound of 2^O(n) for the standard Euclidean norm established by Micciancio and
Voulgaris (STOC 2010). Our algorithm can be viewed as a derandomization of the
AKS randomized sieve algorithm, which can be used to solve SVP for any norm in
2^O(n) time with high probability. We use the technique of covering a convex
body by ellipsoids, as introduced for lattice problems in (Dadush et al., FOCS
2011).
  Our main contribution is a deterministic approximation of an M-ellipsoid of
any convex body. We achieve this via a convex programming formulation of the
optimal ellipsoid with the objective function being an n-dimensional integral
that we show can be approximated deterministically, a technique that appears to
be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5479</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5479</id><created>2011-07-27</created><authors><author><keyname>Vabishchevich</keyname><forenames>P.</forenames></author><author><keyname>Vasil'eva</keyname><forenames>M.</forenames></author></authors><title>Iterative methods for solving the pressure problem at multiphase
  filtration</title><categories>cs.NA</categories><msc-class>65F10, 65N22, 76S05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Applied problems of oil and gas recovery are studied numerically using the
mathematical models of multiphase fluid flows in porous media. The basic model
includes the continuity equations and the Darcy laws for each phase, as well as
the algebraic expression for the sum of saturations. Primary computational
algorithms are implemented for such problems using the pressure equation. In
this paper, we highlight the basic properties of the pressure problem and
discuss the necessity of their fulfillment at the discrete level. The resulting
elliptic problem for the pressure equation is characterized by a
non-selfadjoint operator. Possibilities of approximate solving the elliptic
problem are considered using the iterative methods. Special attention is given
to the numerical algorithms for calculating the pressure on parallel computers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5492</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5492</id><created>2011-07-27</created><authors><author><keyname>Salhi</keyname><forenames>Lotfi</forenames></author><author><keyname>Ouni</keyname><forenames>Kais</forenames></author></authors><title>Application of Gammachirp Auditory Filter as a Continuous Wavelet
  Analysis</title><categories>cs.SD</categories><comments>16 pages, 17 figures;
  http://airccse.org/journal/sipij/papers/2011sipij10.pdf</comments><doi>10.5121/sipij</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a new method on the use of the gammachirp auditory filter
based on a continuous wavelet analysis. The gammachirp auditory filter is
designed to provide a spectrum reflecting the spectral properties of the
cochlea, which is responsible for frequency analysis in the human auditory
system. The impulse response of the theoretical gammachirp auditory filter that
has been developed by Irino and Patterson can be used as the kernel for wavelet
transform which approximates the frequency response of the cochlea. This study
implements the gammachirp auditory filter described by Irino as an analytical
wavelet and examines its application to a different speech signals.
  The obtained results will be compared with those obtained by two other
predefined wavelet families that are Morlet and Mexican Hat. The results show
that the gammachirp wavelet family gives results that are comparable to ones
obtained by Morlet and Mexican Hat wavelet family.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5520</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5520</id><created>2011-07-27</created><authors><author><keyname>Sunehag</keyname><forenames>Peter</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Axioms for Rational Reinforcement Learning</title><categories>cs.LG</categories><comments>16 LaTeX pages</comments><journal-ref>Proc. 22nd International Conf. on Algorithmic Learning Theory
  (ALT-2011) pages 338-352</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a formal, simple and intuitive theory of rational decision making
including sequential decisions that affect the environment. The theory has a
geometric flavor, which makes the arguments easy to visualize and understand.
Our theory is for complete decision makers, which means that they have a
complete set of preferences. Our main result shows that a complete rational
decision maker implicitly has a probabilistic model of the environment. We have
a countable version of this result that brings light on the issue of countable
vs finite additivity by showing how it depends on the geometry of the space
which we have preferences over. This is achieved through fruitfully connecting
rationality with the Hahn-Banach Theorem. The theory presented here can be
viewed as a formalization and extension of the betting odds approach to
probability of Ramsey and De Finetti.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5523</identifier>
 <datestamp>2012-06-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5523</id><created>2011-07-27</created><updated>2012-06-06</updated><authors><author><keyname>Gorla</keyname><forenames>Elisa</forenames></author><author><keyname>Manganiello</keyname><forenames>Felice</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author></authors><title>An Algebraic Approach for Decoding Spread Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study spread codes: a family of constant-dimension codes for
random linear network coding. In other words, the codewords are full-rank
matrices of size (k x n) with entries in a finite field F_q. Spread codes are a
family of optimal codes with maximal minimum distance. We give a
minimum-distance decoding algorithm which requires O((n-k)k^3) operations over
an extension field F_{q^k}. Our algorithm is more efficient than the previous
ones in the literature, when the dimension k of the codewords is small with
respect to n. The decoding algorithm takes advantage of the algebraic structure
of the code, and it uses original results on minors of a matrix and on the
factorization of polynomials over finite fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5528</identifier>
 <datestamp>2014-07-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5528</id><created>2011-07-27</created><authors><author><keyname>Lattimore</keyname><forenames>Tor</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Time Consistent Discounting</title><categories>cs.AI cs.SY math.OC</categories><comments>17 LaTeX pages, 5 figures</comments><journal-ref>Proc. 22nd International Conf. on Algorithmic Learning Theory
  (ALT-2011) pages 383-397</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A possibly immortal agent tries to maximise its summed discounted rewards
over time, where discounting is used to avoid infinite utilities and encourage
the agent to value current rewards more than future ones. Some commonly used
discount functions lead to time-inconsistent behavior where the agent changes
its plan over time. These inconsistencies can lead to very poor behavior. We
generalise the usual discounted utility model to one where the discount
function changes with the age of the agent. We then give a simple
characterisation of time-(in)consistent discount functions and show the
existence of a rational policy for an agent that knows its discount function is
time-inconsistent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5531</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5531</id><created>2011-07-27</created><authors><author><keyname>Lattimore</keyname><forenames>Tor</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author><author><keyname>Gavane</keyname><forenames>Vaibhav</forenames></author></authors><title>Universal Prediction of Selected Bits</title><categories>cs.LG cs.IT math.IT</categories><comments>17 LaTeX pages</comments><journal-ref>Proc. 22nd International Conf. on Algorithmic Learning Theory
  (ALT-2011) pages 262-276</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many learning tasks can be viewed as sequence prediction problems. For
example, online classification can be converted to sequence prediction with the
sequence being pairs of input/target data and where the goal is to correctly
predict the target data given input data and previous input/target pairs.
Solomonoff induction is known to solve the general sequence prediction problem,
but only if the entire sequence is sampled from a computable distribution. In
the case of classification and discriminative learning though, only the targets
need be structured (given the inputs). We show that the normalised version of
Solomonoff induction can still be used in this case, and more generally that it
can detect any recursive sub-pattern (regularity) within an otherwise
completely unstructured sequence. It is also shown that the unnormalised
version can fail to predict very simple recursive sub-patterns.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5537</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5537</id><created>2011-07-27</created><authors><author><keyname>Lattimore</keyname><forenames>Tor</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Asymptotically Optimal Agents</title><categories>cs.AI cs.LG</categories><comments>21 LaTeX pages</comments><journal-ref>Proc. 22nd International Conf. on Algorithmic Learning Theory
  (ALT-2011) pages 368-382</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Artificial general intelligence aims to create agents capable of learning to
solve arbitrary interesting problems. We define two versions of asymptotic
optimality and prove that no agent can satisfy the strong version while in some
cases, depending on discounting, there does exist a non-computable weak
asymptotically optimal agent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5538</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5538</id><created>2011-07-27</created><authors><author><keyname>Sen</keyname><forenames>Jaydip</forenames></author></authors><title>An Anonymous Authentication and Communication Protocol for Wireless Mesh
  Networks</title><categories>cs.CR cs.NI</categories><comments>13 pages, 6 figures. First International Conference on Advances in
  Computing and Communication (ACC 2011), Kochi, India, July 22 - 24, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless mesh networks (WMNs) have emerged as a key technology for next
generation wireless broadband networks showing rapid progress and inspiring
numerous compelling applications. A WMN comprises of a set of mesh routers
(MRs) and mesh clients (MCs), where MRs are connected to the Internet backbone
through the Internet gateways (IGWs). The MCs are wireless devices and
communicate among themselves over possibly multi-hop paths with or without the
involvement of MRs. User privacy and security have been primary concerns in
WMNs due to their peer-to-peer network topology, shared wireless medium,
stringent resource constraints, and highly dynamic environment. Moreover, to
support real-time applications, WMNs must also be equipped with robust,
reliable and efficient communication protocols so as to minimize the end-to-end
latency and packet drops. Design of a secure and efficient communication
protocol for WMNs, therefore, is of paramount importance. In this paper, we
propose a security and privacy protocol that provides security and user
anonymity while maintaining communication efficiency in a WMN. The security
protocol ensures secure authentication and encryption in access and the
backbone networks. The user anonymity, authentication and data privacy is
achieved by application of a protocol that is based on Rivest's ring signature
scheme. Simulation results demonstrate that while the protocols have minimal
storage and communication overhead, they are robust and provide high level of
security and privacy to the users of the network services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5541</identifier>
 <datestamp>2011-07-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5541</id><created>2011-07-27</created><authors><author><keyname>Li</keyname><forenames>Jiangyuan</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina</forenames></author></authors><title>Closed Form Secrecy Capacity of MIMO Wiretap Channels with Two Transmit
  Antennas</title><categories>cs.IT math.IT</categories><comments>1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A Gaussian multiple-input multiple-output (MIMO) wiretap channel model is
considered. The input is a two-antenna transmitter, while the outputs are the
legitimate receiver and an eavesdropper, both equipped with multiple antennas.
All channels are assumed to be known. The problem of obtaining the optimal
input covariance matrix that achieves secrecy capacity subject to a power
constraint is addressed, and a closed-form expression for the secrecy capacity
is obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5543</identifier>
 <datestamp>2012-05-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5543</id><created>2011-07-27</created><updated>2012-05-21</updated><authors><author><keyname>Teng</keyname><forenames>Chun-Yuen</forenames></author><author><keyname>Gong</keyname><forenames>Liuling</forenames></author><author><keyname>Livne</keyname><forenames>Avishay</forenames></author><author><keyname>Brunetti</keyname><forenames>Celso</forenames></author><author><keyname>Adamic</keyname><forenames>Lada A.</forenames></author></authors><title>Coevolution of Network Structure and Content</title><categories>cs.SI physics.soc-ph</categories><comments>10 pages, 10 figures V2 includes a simulation model; Proc. 4th
  International Conference on Web Science (WebSci'11), 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As individuals communicate, their exchanges form a dynamic network. We
demonstrate, using time series analysis of communication in three online
settings, that network structure alone can be highly revealing of the diversity
and novelty of the information being communicated. Our approach uses both
standard and novel network metrics to characterize how unexpected a network
configuration is, and to capture a network's ability to conduct information. We
find that networks with a higher conductance in link structure exhibit higher
information entropy, while unexpected network configurations can be tied to
information novelty. We use a simulation model to explain the observed
correspondence between the evolution of a network's structure and the
information it carries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5550</identifier>
 <datestamp>2015-10-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5550</id><created>2011-07-27</created><updated>2015-10-09</updated><authors><author><keyname>Achlioptas</keyname><forenames>Dimitris</forenames></author><author><keyname>Molloy</keyname><forenames>Michael</forenames></author></authors><title>The solution space geometry of random linear equations</title><categories>cs.DS math.CO</categories><comments>Corrects an error from previous versions. Lemma 35(b) replaces
  Observation 5 in the journal publication</comments><journal-ref>Random Structures and Algorithms 46, 197-231 (2015)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider random systems of linear equations over GF(2) in which every
equation binds k variables. We obtain a precise description of the clustering
of solutions in such systems. In particular, we prove that with probability
that tends to 1 as the number of variables, n, grows: for every pair of
solutions \sigma, \tau, either there exists a sequence of solutions
\sigma,...,\tau, in which successive elements differ by O(log n) variables, or
every sequence of solutions \sigma,...,\tau, contains a step requiring the
simultaneous change of \Omega(n) variables. Furthermore, we determine precisely
which pairs of solutions are in each category. Our results are tight and highly
quantitative in nature. Moreover, our proof highlights the role of unique
extendability as the driving force behind the success of Low Density Parity
Check codes and our techniques also apply to the problem of so-called
pseudo-codewords in such codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5556</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5556</id><created>2011-07-27</created><authors><author><keyname>Cruz</keyname><forenames>Flavio</forenames></author><author><keyname>Rocha</keyname><forenames>Ricardo</forenames></author></authors><title>Efficient Instance Retrieval of Subgoals for Subsumptive Tabled
  Evaluation of Logic Programs</title><categories>cs.PL</categories><comments>Theory and Practice of Logic Programming, 27th Int'l. Conference on
  Logic Programming (ICLP 2011) Special Issue, volume 11, issue 4-5</comments><journal-ref>Theory and Practice of Logic Programming, Volume 11, Special Issue
  4-5, July 2011, pp 697-712 Published Cambridge University Press 2011</journal-ref><doi>10.1017/S1471068411000251</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Tabled evaluation is an implementation technique that solves some problems of
traditional Prolog systems in dealing with recursion and redundant
computations. Most tabling engines determine if a tabled subgoal will produce
or consume answers by using variant checks. A more refined method, named call
subsumption, considers that a subgoal A will consume from a subgoal B if A is
subsumed by (an instance of) B, thus allowing greater answer reuse. We recently
developed an extension, called Retroactive Call Subsumption, that improves upon
call subsumption by supporting bidirectional sharing of answers between
subsumed/subsuming subgoals. In this paper, we present both an algorithm and an
extension to the table space data structures to efficiently implement instance
retrieval of subgoals for subsumptive tabled evaluation of logic programs.
Experiments results using the YapTab tabling system show that our
implementation performs quite well on some complex benchmarks and is robust
enough to handle a large number of subgoals without performance degradation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5559</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5559</id><created>2011-07-27</created><updated>2011-08-03</updated><authors><author><keyname>Salek</keyname><forenames>Mahyar</forenames></author><author><keyname>Shayandeh</keyname><forenames>Shahin</forenames></author><author><keyname>Kempe</keyname><forenames>David</forenames></author></authors><title>You Share, I Share: Network Effects and Economic Incentives in P2P
  File-Sharing Systems</title><categories>cs.NI cs.DM</categories><comments>20 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the interaction between network effects and external incentives on
file sharing behavior in Peer-to-Peer (P2P) networks. Many current or
envisioned P2P networks reward individuals for sharing files, via financial
incentives or social recognition. Peers weigh this reward against the cost of
sharing incurred when others download the shared file. As a result, if other
nearby nodes share files as well, the cost to an individual node decreases.
Such positive network sharing effects can be expected to increase the rate of
peers who share files.
  In this paper, we formulate a natural model for the network effects of
sharing behavior, which we term the &quot;demand model.&quot; We prove that the model has
desirable diminishing returns properties, meaning that the network benefit of
increasing payments decreases when the payments are already high. This result
holds quite generally, for submodular objective functions on the part of the
network operator.
  In fact, we show a stronger result: the demand model leads to a &quot;coverage
process,&quot; meaning that there is a distribution over graphs such that
reachability under this distribution exactly captures the joint distribution of
nodes which end up sharing. The existence of such distributions has advantages
in simulating and estimating the performance of the system. We establish this
result via a general theorem characterizing which types of models lead to
coverage processes, and also show that all coverage processes possess the
desirable submodular properties. We complement our theoretical results with
experiments on several real-world P2P topologies. We compare our model
quantitatively against more na\&quot;ive models ignoring network effects. A main
outcome of the experiments is that a good incentive scheme should make the
reward dependent on a node's degree in the network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5594</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5594</id><created>2011-07-27</created><updated>2011-09-23</updated><authors><author><keyname>Askarov</keyname><forenames>Aslan</forenames><affiliation>Cornell University</affiliation></author><author><keyname>Myers</keyname><forenames>Andrew</forenames><affiliation>Cornell University</affiliation></author></authors><title>Attacker Control and Impact for Confidentiality and Integrity</title><categories>cs.PL cs.CR</categories><proxy>LMCS</proxy><acm-class>D.3.3, D.4.6</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 3 (September
  26, 2011) lmcs:987</journal-ref><doi>10.2168/LMCS-7(3:17)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Language-based information flow methods offer a principled way to enforce
strong security properties, but enforcing noninterference is too inflexible for
realistic applications. Security-typed languages have therefore introduced
declassification mechanisms for relaxing confidentiality policies, and
endorsement mechanisms for relaxing integrity policies. However, a continuing
challenge has been to define what security is guaranteed when such mechanisms
are used. This paper presents a new semantic framework for expressing security
policies for declassification and endorsement in a language-based setting. The
key insight is that security can be characterized in terms of the influence
that declassification and endorsement allow to the attacker. The new framework
introduces two notions of security to describe the influence of the attacker.
Attacker control defines what the attacker is able to learn from observable
effects of this code; attacker impact captures the attacker's influence on
trusted locations. This approach yields novel security conditions for checked
endorsements and robust integrity. The framework is flexible enough to recover
and to improve on the previously introduced notions of robustness and qualified
robustness. Further, the new security conditions can be soundly enforced by a
security type system. The applicability and enforcement of the new policies is
illustrated through various examples, including data sanitization and
authentication.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5605</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5605</id><created>2011-07-27</created><authors><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>Singular Perturbation Approximations for a Class of Linear Quantum
  Systems</title><categories>cs.SY math.OC quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the use of singular perturbation approximations for a
class of linear quantum systems arising in the area of linear quantum optics.
The paper presents results on the physical realizability properties of the
approximate system arising from singular perturbation model reduction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5607</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5607</id><created>2011-07-27</created><authors><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>Low Frequency Approximation for a class of Linear Quantum Systems using
  Cascade Cavity Realization</title><categories>cs.SY math.OC quant-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a method for approximating a class of complex transfer
function matrices corresponding to physically realizable complex linear quantum
systems. The class of linear quantum systems under consideration includes
interconnections of passive optical components such as cavities,
beam-splitters, phase-shifters and interferometers. This approximation method
builds on a previous result for cascade realization and gives good
approximations at low frequencies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5615</identifier>
 <datestamp>2013-06-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5615</id><created>2011-07-27</created><authors><author><keyname>Ouyang</keyname><forenames>Hua</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author><author><keyname>Ugrinovskii</keyname><forenames>Valery</forenames></author></authors><title>Lagrange Stabilization of Pendulum-like Systems: A Pseudo H-infinity
  Control Approach</title><categories>cs.SY math.OC</categories><journal-ref>IEEE TRANSACTIONS ON AUTOMATIC CONTROL, VOL. 57, NO. 3, MARCH 2012</journal-ref><doi>10.1109/TAC.2012.2185882</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the Lagrange stabilization of a class of nonlinear systems
whose linear part has a singular system matrix and which have multiple periodic
(in state) nonlinearities. Both state and output feedback Lagrange
stabilization problems are considered. The paper develops a pseudo H-infinity
control theory to solve these stabilization problems. In a similar fashion to
the Strict Bounded Real Lemma in classic H-infinity control theory, a Pseudo
Strict Bounded Real Lemma is established for systems with a single unstable
pole. Sufficient conditions for the synthesis of state feedback and output
feedback controllers are given to ensure that the closed-loop system is pseudo
strict bounded real. The pseudo H-infinity control approach is applied to solve
state feedback and output feedback Lagrange stabilization problems for
nonlinear systems with multiple nonlinearities. An example is given to
illustrate the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5620</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5620</id><created>2011-07-27</created><authors><author><keyname>Ciampaglia</keyname><forenames>Giovanni Luca</forenames></author></authors><title>A bounded confidence approach to understanding user participation in
  peer production systems</title><categories>physics.soc-ph cs.CY cs.SI</categories><comments>17 pages, 5 figures, accepted to SocInfo2011</comments><journal-ref>Social Informatics. Lecture Notes in Computer Science, 2011,
  Volume 6984, pp. 269-282</journal-ref><doi>10.1007/978-3-642-24704-0_29</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Commons-based peer production does seem to rest upon a paradox. Although
users produce all contents, at the same time participation is commonly on a
voluntary basis, and largely incentivized by achievement of project's goals.
This means that users have to coordinate their actions and goals, in order to
keep themselves from leaving. While this situation is easily explainable for
small groups of highly committed, like-minded individuals, little is known
about large-scale, heterogeneous projects, such as Wikipedia.
  In this contribution we present a model of peer production in a large online
community. The model features a dynamic population of bounded confidence users,
and an endogenous process of user departure. Using global sensitivity analysis,
we identify the most important parameters affecting the lifespan of user
participation. We find that the model presents two distinct regimes, and that
the shift between them is governed by the bounded confidence parameter. For low
values of this parameter, users depart almost immediately. For high values,
however, the model produces a bimodal distribution of user lifespan. These
results suggest that user participation to online communities could be
explained in terms of group consensus, and provide a novel connection between
models of opinion dynamics and commons-based peer production.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5637</identifier>
 <datestamp>2014-05-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5637</id><created>2011-07-28</created><updated>2014-05-15</updated><authors><author><keyname>Kurkoski</keyname><forenames>Brian M.</forenames></author><author><keyname>Yagi</keyname><forenames>Hideki</forenames></author></authors><title>Quantization of Binary-Input Discrete Memoryless Channels</title><categories>cs.IT math.IT</categories><comments>9 pages, 5 figures. Source code available at
  http://brian.kurkoski.org/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The quantization of the output of a binary-input discrete memoryless channel
to a smaller number of levels is considered. An algorithm which finds an
optimal quantizer, in the sense of maximizing mutual information between the
channel input and the quantizer output is given. This result holds for
arbitrary channels, in contrast to previous results for restricted channels or
a restricted number of quantizer outputs. In the worst case, the algorithm
complexity is cubic $M^3$ in the number of channel outputs $M$. Optimality is
proved using the theorem of Burshtein, Della Pietra, Kanevsky, and N\'adas for
mappings which minimize average impurity for classification and regression
trees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5638</identifier>
 <datestamp>2013-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5638</id><created>2011-07-28</created><updated>2013-04-27</updated><authors><author><keyname>Mari</keyname><forenames>Federico</forenames></author><author><keyname>Melatti</keyname><forenames>Igor</forenames></author><author><keyname>Salvo</keyname><forenames>Ivano</forenames></author><author><keyname>Tronci</keyname><forenames>Enrico</forenames></author></authors><title>Model Based Synthesis of Control Software from System Level Formal
  Specifications</title><categories>cs.SE cs.SY</categories><comments>Accepted for publication by ACM Transactions on Software Engineering
  and Methodology (TOSEM)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many Embedded Systems are indeed Software Based Control Systems, that is
control systems whose controller consists of control software running on a
microcontroller device. This motivates investigation on Formal Model Based
Design approaches for automatic synthesis of embedded systems control software.
  We present an algorithm, along with a tool QKS implementing it, that from a
formal model (as a Discrete Time Linear Hybrid System) of the controlled system
(plant), implementation specifications (that is, number of bits in the
Analog-to-Digital, AD, conversion) and System Level Formal Specifications (that
is, safety and liveness requirements for the closed loop system) returns
correct-by-construction control software that has a Worst Case Execution Time
(WCET) linear in the number of AD bits and meets the given specifications.
  We show feasibility of our approach by presenting experimental results on
using it to synthesize control software for a buck DC-DC converter, a widely
used mixed-mode analog circuit, and for the inverted pendulum.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5645</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5645</id><created>2011-07-28</created><authors><author><keyname>Yu</keyname><forenames>Quan</forenames></author><author><keyname>Shum</keyname><forenames>Kenneth W.</forenames></author><author><keyname>Sung</keyname><forenames>Chi Wan</forenames></author></authors><title>Minimization of Storage Cost in Distributed Storage Systems with Repair
  Consideration</title><categories>cs.IT cs.DC math.IT</categories><comments>5 pages, 4 figures, to appear in Proc. IEEE GLOBECOM, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a distributed storage system, the storage costs of different storage
nodes, in general, can be different. How to store a file in a given set of
storage nodes so as to minimize the total storage cost is investigated. By
analyzing the min-cut constraints of the information flow graph, the feasible
region of the storage capacities of the nodes can be determined. The storage
cost minimization can then be reduced to a linear programming problem, which
can be readily solved. Moreover, the tradeoff between storage cost and
repair-bandwidth is established.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5646</identifier>
 <datestamp>2011-11-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5646</id><created>2011-07-28</created><updated>2011-10-10</updated><authors><author><keyname>Kovanen</keyname><forenames>Lauri</forenames></author><author><keyname>Karsai</keyname><forenames>M&#xe1;rton</forenames></author><author><keyname>Kaski</keyname><forenames>Kimmo</forenames></author><author><keyname>Kert&#xe9;sz</keyname><forenames>J&#xe1;nos</forenames></author><author><keyname>Saram&#xe4;ki</keyname><forenames>Jari</forenames></author></authors><title>Temporal motifs in time-dependent networks</title><categories>physics.data-an cs.SI physics.soc-ph</categories><comments>18 pages, 8 figures; minor revisions</comments><journal-ref>J. Stat. Mech. (2011) P11005</journal-ref><doi>10.1088/1742-5468/2011/11/P11005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Temporal networks are commonly used to represent systems where connections
between elements are active only for restricted periods of time, such as
networks of telecommunication, neural signal processing, biochemical reactions
and human social interactions. We introduce the framework of temporal motifs to
study the mesoscale topological-temporal structure of temporal networks in
which the events of nodes do not overlap in time. Temporal motifs are classes
of similar event sequences, where the similarity refers not only to topology
but also to the temporal order of the events. We provide a mapping from event
sequences to colored directed graphs that enables an efficient algorithm for
identifying temporal motifs. We discuss some aspects of temporal motifs,
including causality and null models, and present basic statistics of temporal
motifs in a large mobile call network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5654</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5654</id><created>2011-07-28</created><authors><author><keyname>Groh</keyname><forenames>Georg</forenames></author><author><keyname>Brocco</keyname><forenames>Michele</forenames></author><author><keyname>Kleemann</keyname><forenames>Andreas</forenames></author></authors><title>Interest-Based vs. Social Person-Recommenders in Social Networking
  Platforms</title><categories>cs.SI cs.CY physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Social network based approaches to person recommendations are compared to
interest based approaches with the help of an empirical study on a large German
social networking platform. We assess and compare the performance of different
basic variants of the two approaches by precision / recall based performance
with respect to reproducing known friendship relations and by an empirical
questionnaire based study. In accordance to expectation, the results show that
interest based person recommenders are able to produce more novel
recommendations while performing less well with respect to friendship
reproduction. With respect to the user's assessment of recommendation quality
all approaches perform comparably well, while combined social-interest-based
variants are slightly ahead in performance. The overall results qualify those
combined approaches as a good compromise.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5661</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5661</id><created>2011-07-28</created><authors><author><keyname>Feldman</keyname><forenames>M.</forenames></author><author><keyname>Lempel</keyname><forenames>R.</forenames></author><author><keyname>Somekh</keyname><forenames>O.</forenames></author><author><keyname>Vornovitsky</keyname><forenames>K.</forenames></author></authors><title>On the Impact of Random Index-Partitioning on Index Compression</title><categories>cs.IR</categories><comments>9 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performance of processing search queries depends heavily on the stored
index size. Accordingly, considerable research efforts have been devoted to the
development of efficient compression techniques for inverted indexes. Roughly,
index compression relies on two factors: the ordering of the indexed documents,
which strives to position similar documents in proximity, and the encoding of
the inverted lists that result from the ordered stream of documents. Large
commercial search engines index tens of billions of pages of the ever growing
Web. The sheer size of their indexes dictates the distribution of documents
among thousands of servers in a scheme called local index-partitioning, such
that each server indexes only several millions pages. Due to engineering and
runtime performance considerations, random distribution of documents to servers
is common. However, random index-partitioning among many servers adversely
impacts the resulting index sizes, as it decreases the effectiveness of
document ordering schemes. We study the impact of random index-partitioning on
document ordering schemes. We show that index-partitioning decreases the
aggregated size of the inverted lists logarithmically with the number of
servers, when documents within each server are randomly reordered. On the other
hand, the aggregated partitioned index size increases logarithmically with the
number of servers, when state-of-the-art document ordering schemes, such as
lexical URL sorting and clustering with TSP, are applied. Finally, we justify
the common practice of randomly distributing documents to servers, as we
qualitatively show that despite its ill-effects on the ensuing compression, it
decreases key factors in distributed query evaluation time by an order of
magnitude as compared with partitioning techniques that compress better.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5665</identifier>
 <datestamp>2015-05-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5665</id><created>2011-07-28</created><authors><author><keyname>de Silva</keyname><forenames>Vin</forenames></author><author><keyname>Morozov</keyname><forenames>Dmitriy</forenames></author><author><keyname>Vejdemo-Johansson</keyname><forenames>Mikael</forenames></author></authors><title>Dualities in persistent (co)homology</title><categories>math.AT cs.CG</categories><comments>16 pages, 3 figures, submitted to the Inverse Problems special issue
  on Topological Data Analysis</comments><doi>10.1088/0266-5611/27/12/124003</doi><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We consider sequences of absolute and relative homology and cohomology groups
that arise naturally for a filtered cell complex. We establish algebraic
relationships between their persistence modules, and show that they contain
equivalent information. We explain how one can use the existing algorithm for
persistent homology to process any of the four modules, and relate it to a
recently introduced persistent cohomology algorithm. We present experimental
evidence for the practical efficiency of the latter algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5671</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5671</id><created>2011-07-28</created><authors><author><keyname>Ostrowski</keyname><forenames>Max</forenames></author><author><keyname>Schaub</keyname><forenames>Torsten</forenames></author><author><keyname>Durzinsky</keyname><forenames>Markus</forenames></author><author><keyname>Marwan</keyname><forenames>Wolfgang</forenames></author><author><keyname>Wagler</keyname><forenames>Annegret</forenames></author></authors><title>Automatic Network Reconstruction using ASP</title><categories>cs.LG</categories><journal-ref>Theory and Practice of Logic Programming, 27th Int'l. Conference
  on Logic Programming (ICLP'11) Special Issue, volume 11, issue 4-5, pages
  749-766, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building biological models by inferring functional dependencies from
experimental data is an im- portant issue in Molecular Biology. To relieve the
biologist from this traditionally manual process, various approaches have been
proposed to increase the degree of automation. However, available ap- proaches
often yield a single model only, rely on specific assumptions, and/or use
dedicated, heuris- tic algorithms that are intolerant to changing circumstances
or requirements in the view of the rapid progress made in Biotechnology. Our
aim is to provide a declarative solution to the problem by ap- peal to Answer
Set Programming (ASP) overcoming these difficulties. We build upon an existing
approach to Automatic Network Reconstruction proposed by part of the authors.
This approach has firm mathematical foundations and is well suited for ASP due
to its combinatorial flavor providing a characterization of all models
explaining a set of experiments. The usage of ASP has several ben- efits over
the existing heuristic algorithms. First, it is declarative and thus
transparent for biological experts. Second, it is elaboration tolerant and thus
allows for an easy exploration and incorporation of biological constraints.
Third, it allows for exploring the entire space of possible models. Finally,
our approach offers an excellent performance, matching existing,
special-purpose systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5676</identifier>
 <datestamp>2012-09-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5676</id><created>2011-07-28</created><updated>2012-09-07</updated><authors><author><keyname>Preciado</keyname><forenames>Victor M.</forenames></author><author><keyname>Jadbabaie</keyname><forenames>Ali</forenames></author><author><keyname>Verghese</keyname><forenames>George C.</forenames></author></authors><title>Structural Analysis of Laplacian Spectral Properties of Large-Scale
  Networks</title><categories>math.OC cs.CE cs.DM cs.SI cs.SY physics.data-an physics.soc-ph</categories><comments>IEEE Automatic Control, accepted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Using methods from algebraic graph theory and convex optimization, we study
the relationship between local structural features of a network and spectral
properties of its Laplacian matrix. In particular, we derive expressions for
the so-called spectral moments of the Laplacian matrix of a network in terms of
a collection of local structural measurements. Furthermore, we propose a series
of semidefinite programs to compute bounds on the spectral radius and the
spectral gap of the Laplacian matrix from a truncated sequence of Laplacian
spectral moments. Our analysis shows that the Laplacian spectral moments and
spectral radius are strongly constrained by local structural features of the
network. On the other hand, we illustrate how local structural features are
usually not enough to estimate the Laplacian spectral gap.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5708</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5708</id><created>2011-07-28</created><updated>2011-11-11</updated><authors><author><keyname>Etzion</keyname><forenames>Tuvi</forenames></author></authors><title>Perfect Codes for Uniform Chains Poset Metrics</title><categories>cs.IT math.CO math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The class of poset metrics is very large and contains some interesting
families of metrics. A family of metrics, based on posets which are formed from
disjoint chains which have the same size, is examined. A necessary and
sufficient condition, for the existence of perfect single-error-correcting
codes for such poset metrics, is proved.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5722</identifier>
 <datestamp>2011-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5722</id><created>2011-07-28</created><updated>2011-08-26</updated><authors><author><keyname>Cristescu</keyname><forenames>Ioana</forenames><affiliation>LIP</affiliation></author><author><keyname>Hirschkoff</keyname><forenames>Daniel</forenames><affiliation>LIP</affiliation></author></authors><title>Termination in a Pi-calculus with Subtyping</title><categories>cs.LO</categories><proxy>ccsd</proxy><journal-ref>18th International Workshop on Expressiveness in Concurrency,
  Aachen : Germany (2011)</journal-ref><doi>10.4204/EPTCS.64.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a type system to guarantee termination of pi-calculus processes
that exploits input/output capabilities and subtyping, as originally introduced
by Pierce and Sangiorgi, in order to analyse the usage of channels. We show
that our system improves over previously existing proposals by accepting more
processes as terminating. This increased expressiveness allows us to capture
sensible programming idioms. We demonstrate how our system can be extended to
handle the encoding of the simply typed lambda-calculus, and discuss questions
related to type inference.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5728</identifier>
 <datestamp>2011-10-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5728</id><created>2011-07-28</created><updated>2011-09-19</updated><authors><author><keyname>Vitali</keyname><forenames>Stefania</forenames></author><author><keyname>Glattfelder</keyname><forenames>James B.</forenames></author><author><keyname>Battiston</keyname><forenames>Stefano</forenames></author></authors><title>The network of global corporate control</title><categories>q-fin.GN cs.SI physics.soc-ph</categories><comments>Main Text (10 pages, 3 figures and 1 table) and Supporting
  Information (26 pages, 7 figures and 4 tables), 2nd version (with minor
  comments, typos removed, detailed acknowledgement, better referencing of
  Supporting Information)</comments><journal-ref>PLoS ONE 6(10), e25995 (2011)</journal-ref><doi>10.1371/journal.pone.0025995</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The structure of the control network of transnational corporations affects
global market competition and financial stability. So far, only small national
samples were studied and there was no appropriate methodology to assess control
globally. We present the first investigation of the architecture of the
international ownership network, along with the computation of the control held
by each global player. We find that transnational corporations form a giant
bow-tie structure and that a large portion of control flows to a small
tightly-knit core of financial institutions. This core can be seen as an
economic &quot;super-entity&quot; that raises new important issues both for researchers
and policy makers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5730</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5730</id><created>2011-07-28</created><authors><author><keyname>Reeves</keyname><forenames>Galen</forenames></author><author><keyname>Gastpar</keyname><forenames>Michael</forenames></author></authors><title>On the Role of Diversity in Sparsity Estimation</title><categories>cs.IT math.IT</categories><comments>Presented at the IEEE International Symposium on Information Theory
  (ISIT 2011), Saint Petersburg, Russia, August, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A major challenge in sparsity pattern estimation is that small modes are
difficult to detect in the presence of noise. This problem is alleviated if one
can observe samples from multiple realizations of the nonzero values for the
same sparsity pattern. We will refer to this as &quot;diversity&quot;. Diversity comes at
a price, however, since each new realization adds new unknown nonzero values,
thus increasing uncertainty. In this paper, upper and lower bounds on joint
sparsity pattern estimation are derived. These bounds, which improve upon
existing results even in the absence of diversity, illustrate key tradeoffs
between the number of measurements, the accuracy of estimation, and the
diversity. It is shown, for instance, that diversity introduces a tradeoff
between the uncertainty in the noise and the uncertainty in the nonzero values.
Moreover, it is shown that the optimal amount of diversity significantly
improves the behavior of the estimation problem for both optimal and
computationally efficient estimators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5742</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5742</id><created>2011-07-28</created><authors><author><keyname>Gebser</keyname><forenames>Martin</forenames></author><author><keyname>Kaminski</keyname><forenames>Roland</forenames></author><author><keyname>Schaub</keyname><forenames>Torsten</forenames></author></authors><title>Complex Optimization in Answer Set Programming</title><categories>cs.LO cs.AI</categories><comments>18 pages, 5 figures</comments><journal-ref>Theory and Practice of Logic Programming, 11(4-5), 821-839, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Preference handling and optimization are indispensable means for addressing
non-trivial applications in Answer Set Programming (ASP). However, their
implementation becomes difficult whenever they bring about a significant
increase in computational complexity. As a consequence, existing ASP systems do
not offer complex optimization capacities, supporting, for instance,
inclusion-based minimization or Pareto efficiency. Rather, such complex
criteria are typically addressed by resorting to dedicated modeling techniques,
like saturation. Unlike the ease of common ASP modeling, however, these
techniques are rather involved and hardly usable by ASP laymen. We address this
problem by developing a general implementation technique by means of
meta-programming, thus reusing existing ASP systems to capture various forms of
qualitative preferences among answer sets. In this way, complex preferences and
optimization capacities become readily available for ASP applications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5743</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5743</id><created>2011-07-28</created><authors><author><keyname>Jonnalagadda</keyname><forenames>Siddhartha</forenames></author><author><keyname>Topham</keyname><forenames>Philip</forenames></author></authors><title>NEMO: Extraction and normalization of organization names from PubMed
  affiliation strings</title><categories>cs.CL</categories><journal-ref>Siddhartha Jonnalagadda, Philip Topham. NEMO: Extraction and
  normalization of organization names from PubMed affiliation strings. Journal
  of Biomedical Discovery and Collaboration, 2010 Oct 4;5:50-75</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose NEMO, a system for extracting organization names in the
affiliation and normalizing them to a canonical organization name. Our parsing
process involves multi-layered rule matching with multiple dictionaries. The
system achieves more than 98% f-score in extracting organization names. Our
process of normalization that involves clustering based on local sequence
alignment metrics and local learning based on finding connected components. A
high precision was also observed in normalization. NEMO is the missing link in
associating each biomedical paper and its authors to an organization name in
its canonical form and the Geopolitical location of the organization. This
research could potentially help in analyzing large social networks of
organizations for landscaping a particular topic, improving performance of
author disambiguation, adding weak links in the co-author network of authors,
augmenting NLM's MARS system for correcting errors in OCR output of affiliation
field, and automatically indexing the PubMed citations with the normalized
organization name and country. Our system is available as a graphical user
interface available for download along with this paper.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5744</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5744</id><created>2011-07-28</created><authors><author><keyname>Jonnalagadda</keyname><forenames>Siddhartha</forenames></author><author><keyname>Gonzalez</keyname><forenames>Graciela</forenames></author></authors><title>BioSimplify: an open source sentence simplification engine to improve
  recall in automatic biomedical information extraction</title><categories>cs.CL</categories><journal-ref>Siddhartha Jonnalagadda, Graciela Gonzalez. BioSimplify: an open
  source sentence simplification engine to improve recall in automatic
  biomedical information extraction. In Annual Proceedings of AMIA 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BioSimplify is an open source tool written in Java that introduces and
facilitates the use of a novel model for sentence simplification tuned for
automatic discourse analysis and information extraction (as opposed to sentence
simplification for improving human readability). The model is based on a
&quot;shot-gun&quot; approach that produces many different (simpler) versions of the
original sentence by combining variants of its constituent elements. This tool
is optimized for processing biomedical scientific literature such as the
abstracts indexed in PubMed. We tested our tool on its impact to the task of
PPI extraction and it improved the f-score of the PPI tool by around 7%, with
an improvement in recall of around 20%. The BioSimplify tool and test corpus
can be downloaded from https://biosimplify.sourceforge.net.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5752</identifier>
 <datestamp>2011-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5752</id><created>2011-07-28</created><updated>2011-09-12</updated><authors><author><keyname>Jonnalagadda</keyname><forenames>Siddhartha</forenames></author></authors><title>An Effective Approach to Biomedical Information Extraction with Limited
  Training Data</title><categories>cs.CL</categories><comments>This paper has been withdrawn</comments><journal-ref>Jonnalagadda S. An effective approach to biomedical information
  extraction with limited training data (PhD Dissertation, Arizona State
  University). 2011;</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Overall, the two main contributions of this work include the application of
sentence simplification to association extraction as described above, and the
use of distributional semantics for concept extraction. The proposed work on
concept extraction amalgamates for the first time two diverse research areas
-distributional semantics and information extraction. This approach renders all
the advantages offered in other semi-supervised machine learning systems, and,
unlike other proposed semi-supervised approaches, it can be used on top of
different basic frameworks and algorithms.
http://gradworks.umi.com/34/49/3449837.html
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5766</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5766</id><created>2011-07-28</created><authors><author><keyname>Ortega</keyname><forenames>Pedro A.</forenames></author><author><keyname>Braun</keyname><forenames>Daniel A.</forenames></author></authors><title>Information, Utility &amp; Bounded Rationality</title><categories>cs.AI</categories><comments>10 pages. The original publication is available at
  www.springerlink.com</comments><journal-ref>The Fourth Conference on General Artificial Intelligence (AGI-11),
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Perfectly rational decision-makers maximize expected utility, but crucially
ignore the resource costs incurred when determining optimal actions. Here we
employ an axiomatic framework for bounded rational decision-making based on a
thermodynamic interpretation of resource costs as information costs. This leads
to a variational &quot;free utility&quot; principle akin to thermodynamical free energy
that trades off utility and information costs. We show that bounded optimal
control solutions can be derived from this variational principle, which leads
in general to stochastic policies. Furthermore, we show that risk-sensitive and
robust (minimax) control schemes fall out naturally from this framework if the
environment is considered as a bounded rational and perfectly rational
opponent, respectively. When resource costs are ignored, the maximum expected
utility principle is recovered.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5774</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5774</id><created>2011-07-28</created><updated>2013-05-03</updated><authors><author><keyname>Lu</keyname><forenames>Qi</forenames></author></authors><title>Carleman Estimate for Stochastic Parabolic Equations and Inverse
  Stochastic Parabolic Problems</title><categories>math.OC cs.SY</categories><comments>18 pages</comments><doi>10.1088/0266-5611/28/4/045008</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we establish a global Carleman estimate for stochastic
parabolic equations. Based on this estimate, we solve two inverse problems for
stochastic parabolic equations. One is concerned with a determination problem
of the history of a stochastic heat process through the observation at the
final time $T$, for which we obtain a conditional stability estimate. The other
is an inverse source problem with observation on the lateral boundary. We
derive the uniqueness of the source.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5778</identifier>
 <datestamp>2013-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5778</id><created>2011-07-28</created><updated>2013-12-20</updated><authors><author><keyname>Naveen</keyname><forenames>K P</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Relay Selection with Channel Probing in Sleep-Wake Cycling Wireless
  Sensor Networks</title><categories>cs.NI</categories><comments>20 pages, 8 figures, Conference version of this report was presented
  in WiOpt 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In geographical forwarding of packets in a large wireless sensor network
(WSN) with sleep-wake cycling nodes, we are interested in the local decision
problem faced by a node that has custody of a packet and has to choose one
among a set of next-hop relay nodes to forward the packet towards the sink.
Each relay is associated with a reward that summarizes the benefit of
forwarding the packet through that relay. We seek a solution to this local
problem, the idea being that such a solution, if adopted by every node, could
provide a reasonable heuristic for the end-to-end forwarding problem. Towards
this end, we propose a relay selection problem comprising a forwarding node and
a collection of relay nodes, with the relays waking up sequentially at random
times. At each relay wake-up instant the forwarder can choose to probe a relay
to learn its reward value, based on which the forwarder can then decide whether
to stop (and forward its packet to the chosen relay) or to continue to wait for
further relays to wake-up. The forwarder's objective is to select a relay so as
to minimize a combination of waiting-delay, reward and probing cost. Our
problem can be considered as a variant of the asset selling problem studied in
the operations research literature. We formulate our relay selection problem as
a Markov decision process (MDP) and obtain some interesting structural results
on the optimal policy (namely, the threshold and the stage-independence
properties). We also conduct simulation experiments and gain valuable insights
into the performance of our local forwarding-solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5782</identifier>
 <datestamp>2011-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5782</id><created>2011-07-28</created><authors><author><keyname>Marcolli</keyname><forenames>Matilde</forenames></author><author><keyname>Perez</keyname><forenames>Christopher</forenames></author></authors><title>Codes as fractals and noncommutative spaces</title><categories>cs.IT math.IT</categories><comments>18 pages LaTeX, one png figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the CSS algorithm relating self-orthogonal classical linear codes
to q-ary quantum stabilizer codes and we show that to such a pair of a
classical and a quantum code one can associate geometric spaces constructed
using methods from noncommutative geometry, arising from rational
noncommutative tori and finite abelian group actions on Cuntz algebras and
fractals associated to the classical codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5790</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5790</id><created>2011-07-28</created><authors><author><keyname>Rostami</keyname><forenames>Mohammad</forenames></author><author><keyname>Michailovich</keyname><forenames>Oleg</forenames></author><author><keyname>Wang</keyname><forenames>Zhou</forenames></author></authors><title>Image Deblurring Using Derivative Compressed Sensing for Optical Imaging
  Application</title><categories>cs.NA</categories><doi>10.1109/TIP.2012.2190610</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reconstruction of multidimensional signals from the samples of their partial
derivatives is known to be a standard problem in inverse theory. Such and
similar problems routinely arise in numerous areas of applied sciences,
including optical imaging, laser interferometry, computer vision, remote
sensing and control. Though being ill-posed in nature, the above problem can be
solved in a unique and stable manner, provided proper regularization and
relevant boundary conditions. In this paper, however, a more challenging setup
is addressed, in which one has to recover an image of interest from its noisy
and blurry version, while the only information available about the imaging
system at hand is the amplitude of the generalized pupil function (GPF) along
with partial observations of the gradient of GPF's phase. In this case, the
phase-related information is collected using a simplified version of the
Shack-Hartmann interferometer, followed by recovering the entire phase by means
of derivative compressed sensing. Subsequently, the estimated phase can be
combined with the amplitude of the GPF to produce an estimate of the point
spread function (PSF), whose knowledge is essential for subsequent image
deconvolution. In summary, the principal contribution of this work is twofold.
First, we demonstrate how to simplify the construction of the Shack-Hartmann
interferometer so as to make it less expensive and hence more accessible.
Second, it is shown by means of numerical experiments that the above
simplification and its associated solution scheme produce image reconstructions
of the quality comparable to those obtained using dense sampling of the GPF
phase.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5806</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5806</id><created>2011-07-28</created><updated>2012-10-11</updated><authors><author><keyname>Sefidgaran</keyname><forenames>Milad</forenames></author><author><keyname>Tchamkerten</keyname><forenames>Aslan</forenames></author></authors><title>On Computing a Function of Correlated Sources</title><categories>cs.IT math.IT</categories><comments>11 pages, Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A receiver wants to compute a function f of two correlated sources X and Y
and side information Z. What is the minimum number of bits that needs to be
communicated by each transmitter?
  In this paper, we derive inner and outer bounds to the rate region of this
problem which coincide in the cases where f is partially invertible and where
the sources are independent given the side information.
  These rate regions point to an important difference with the single source
case. Whereas for the latter it is sufficient to consider independent sets of
some suitable characteristic graph, for multiple sources such a restriction is
suboptimal and multisets are necessary.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5841</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5841</id><created>2011-07-28</created><authors><author><keyname>Quoc</keyname><forenames>Tran Dinh</forenames></author><author><keyname>Diehl</keyname><forenames>Moritz</forenames></author></authors><title>Sequential Convex Programming Methods for Solving Nonlinear Optimization
  Problems with DC constraints</title><categories>math.OC cs.SY</categories><comments>18 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the relation between sequential convex programming
(SCP) as, e.g., defined in [24] and DC (difference of two convex functions)
programming. We first present an SCP algorithm for solving nonlinear
optimization problems with DC constraints and prove its convergence. Then we
combine the proposed algorithm with a relaxation technique to handle
inconsistent linearizations. Numerical tests are performed to investigate the
behaviour of the class of algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5847</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5847</id><created>2011-07-28</created><authors><author><keyname>Mousavi</keyname><forenames>Mohammad Reza</forenames></author><author><keyname>Ravara</keyname><forenames>Antonio</forenames></author></authors><title>Proceedings 10th International Workshop on the Foundations of
  Coordination Languages and Software Architectures</title><categories>cs.SE cs.LO</categories><comments>EPTCS 58, 2011</comments><proxy>EPTCS</proxy><doi>10.4204/EPTCS.58</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Computation nowadays is becoming inherently concurrent, either because of
characteristics of the hardware (with multicore processors becoming
omnipresent) or due to the ubiquitous presence of distributed systems
(incarnated in the Internet). Computational systems are therefore typically
distributed, concurrent, mobile, and often involve composition of heterogeneous
components.
  To specify and reason about such systems and go beyond the functional
correctness proofs, e.g., by supporting reusability and improving
maintainability, approaches such as coordination languages and software
architecture are recognised as fundamental.
  The goal of the this workshop is to put together researchers and
practitioners of the aforementioned fields, to share and identify common
problems, and to devise general solutions in the context of coordination
languages and software architectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5850</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5850</id><created>2011-07-28</created><updated>2014-07-22</updated><authors><author><keyname>Topkaya</keyname><forenames>Ibrahim Saygin</forenames></author><author><keyname>Erdogan</keyname><forenames>Hakan</forenames></author></authors><title>Confidence-Based Dynamic Classifier Combination For Mean-Shift Tracking</title><categories>cs.CV</categories><comments>This paper has been withdrawn by the author due to an implementation
  issue</comments><acm-class>I.4.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a novel tracking technique which uses dynamic confidence-based
fusion of two different information sources for robust and efficient tracking
of visual objects. Mean-shift tracking is a popular and well known method used
in object tracking problems. Originally, the algorithm uses a similarity
measure which is optimized by shifting a search area to the center of a
generated weight image to track objects. Recent improvements on the original
mean-shift algorithm involves using a classifier that differentiates the object
from its surroundings. We adopt this classifier-based approach and propose an
application of a classifier fusion technique within this classifier-based
context in this work. We use two different classifiers, where one comes from a
background modeling method, to generate the weight image and we calculate
contributions of the classifiers dynamically using their confidences to
generate a final weight image to be used in tracking. The contributions of the
classifiers are calculated by using correlations between histograms of their
weight images and histogram of a defined ideal weight image in the previous
frame. We show with experiments that our dynamic combination scheme selects
good contributions for classifiers for different cases and improves tracking
accuracy significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5851</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5851</id><created>2011-07-28</created><authors><author><keyname>Venkatramanan</keyname><forenames>Srinivasan</forenames></author><author><keyname>Kumar</keyname><forenames>Anurag</forenames></author></authors><title>Co-evolution of Content Popularity and Delivery in Mobile P2P Networks</title><categories>cs.SI cs.MA</categories><comments>21 pages, 16 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile P2P technology provides a scalable approach to content delivery to a
large number of users on their mobile devices. In this work, we study the
dissemination of a \emph{single} content (e.g., an item of news, a song or a
video clip) among a population of mobile nodes. Each node in the population is
either a \emph{destination} (interested in the content) or a potential
\emph{relay} (not yet interested in the content). There is an interest
evolution process by which nodes not yet interested in the content (i.e.,
relays) can become interested (i.e., become destinations) on learning about the
popularity of the content (i.e., the number of already interested nodes). In
our work, the interest in the content evolves under the \emph{linear threshold
model}. The content is copied between nodes when they make random contact. For
this we employ a controlled epidemic spread model. We model the joint evolution
of the copying process and the interest evolution process, and derive the joint
fluid limit ordinary differential equations. We then study the selection of the
parameters under the content provider's control, for the optimization of
various objective functions that aim at maximizing content popularity and
efficient content delivery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5869</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5869</id><created>2011-07-29</created><updated>2011-08-18</updated><authors><author><keyname>Farhi</keyname><forenames>Nadir</forenames></author></authors><title>Piecewise linear car-following modeling</title><categories>math.OC cs.SY</categories><comments>19 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a traffic model that extends the linear car-following model as
well as the min-plus traffic model (a model based on the min-plus algebra). A
discrete-time car-dynamics describing the traffic on a 1-lane road without
passing is interpreted as a dynamic programming equation of a stochastic
optimal control problem of a Markov chain. This variational formulation permits
to characterize the stability of the car-dynamics and to calculte the
stationary regimes when they exist. The model is based on a piecewise linear
approximation of the fundamental traffic diagram.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5870</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5870</id><created>2011-07-29</created><authors><author><keyname>Abbasi</keyname><forenames>Alireza</forenames></author><author><keyname>Hossain</keyname><forenames>Liaquat</forenames></author><author><keyname>Uddin</keyname><forenames>Shahadat</forenames></author><author><keyname>Rasmussen</keyname><forenames>Kim J. R.</forenames></author></authors><title>Evolutionary Dynamics of Scientific Collaboration Networks: Multi-Levels
  and Cross-time Analysis</title><categories>cs.SI cs.DL physics.soc-ph</categories><comments>Accepted for publication in Scientometrics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several studies exist which use scientific literature for comparing
scientific activities (e.g., productivity, and collaboration). In this study,
using co-authorship data over the last 40 years, we present the evolutionary
dynamics of multi level (i.e., individual, institutional and national)
collaboration networks for exploring the emergence of collaborations in the
research field of &quot;steel structures&quot;. The collaboration network of scientists
in the field has been analyzed using author affiliations extracted from Scopus
between 1970 and 2009. We have studied collaboration distribution networks at
the micro-, meso- and macro-levels for the 40 years. We compared and analyzed a
number of properties of these networks (i.e., density, centrality measures, the
giant component and clustering coefficient) for presenting a longitudinal
analysis and statistical validation of the evolutionary dynamics of &quot;steel
structures&quot; collaboration networks. At all levels, the scientific
collaborations network structures were central considering the closeness
centralization while betweenness and degree centralization were much lower. In
general networks density, connectedness, centralization and clustering
coefficient were highest in marco-level and decreasing as the network size grow
to the lowest in micro-level. We also find that the average distance between
countries about two and institutes five and for authors eight meaning that only
about eight steps are necessary to get from one randomly chosen author to
another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5881</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5881</id><created>2011-07-29</created><authors><author><keyname>Gall</keyname><forenames>Fran&#xe7;ois Le</forenames></author></authors><title>Quantum Private Information Retrieval with Sublinear Communication
  Complexity</title><categories>quant-ph cs.CC cs.CR</categories><comments>4 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note presents a quantum protocol for private information retrieval, in
the single-server case and with information-theoretical privacy, that has
O(\sqrt{n})-qubit communication complexity, where n denotes the size of the
database. In comparison, it is known that any classical protocol must use
\Omega(n) bits of communication in this setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5886</identifier>
 <datestamp>2013-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5886</id><created>2011-07-29</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>Three Applications to Rational Relations of the High Undecidability of
  the Infinite Post Correspondence Problem in a Regular omega-Language</title><categories>cs.LO cs.CC math.LO</categories><comments>To appear in: Special Issue: Frontier Between Decidability and
  Undecidability and Related Problems, International Journal of Foundations of
  Computer Science</comments><proxy>ccsd</proxy><journal-ref>International Journal of Foundations of Computer Science 23, 7
  (2012) p. 1481-1497</journal-ref><doi>10.1142/S0129054112400606</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was noticed by Harel in [Har86] that &quot;one can define $\Sigma_1^1$-complete
versions of the well-known Post Correspondence Problem&quot;. We first give a
complete proof of this result, showing that the infinite Post Correspondence
Problem in a regular $\omega$-language is $\Sigma_1^1$-complete, hence located
beyond the arithmetical hierarchy and highly undecidable. We infer from this
result that it is $\Pi_1^1$-complete to determine whether two given infinitary
rational relations are disjoint. Then we prove that there is an amazing gap
between two decision problems about $\omega$-rational functions realized by
finite state B\&quot;uchi transducers. Indeed Prieur proved in [Pri01, Pri02] that
it is decidable whether a given $\omega$-rational function is continuous, while
we show here that it is $\Sigma_1^1$-complete to determine whether a given
$\omega$-rational function has at least one point of continuity. Next we prove
that it is $\Pi_1^1$-complete to determine whether the continuity set of a
given $\omega$-rational function is $\omega$-regular. This gives the exact
complexity of two problems which were shown to be undecidable in [CFS08].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5896</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5896</id><created>2011-07-29</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>Decision Problems for Recognizable Languages of Infinite Pictures</title><categories>math.LO cs.LO</categories><proxy>ccsd</proxy><journal-ref>28th Weak Arithmetic Days, Journ\'ees sur les Arithm\'etiques
  Faibles, Fontainebleau : France (2009)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Altenbernd, Thomas and W\&quot;ohrle have considered in [ATW02] acceptance of
languages of infinite two-dimensional words (infinite pictures) by finite
tiling systems, with the usual acceptance conditions, such as the B\&quot;uchi and
Muller ones, firstly used for infinite words. Many classical decision problems
are studied in formal language theory and in automata theory and arise now
naturally about recognizable languages of infinite pictures. We first review in
this paper some recent results of [Fin09b] where we gave the exact degree of
numerous undecidable problems for B\&quot;uchi-recognizable languages of infinite
pictures, which are actually located at the first or at the second level of the
analytical hierarchy, and &quot;highly undecidable&quot;. Then we prove here some more
(high) undecidability results. We first show that it is $\Pi_2^1$-complete to
determine whether a given B\&quot;uchi-recognizable languages of infinite pictures
is unambiguous. Then we investigate cardinality problems. Using recent results
of [FL09], we prove that it is $D_2(\Sigma_1^1)$-complete to determine whether
a given B\&quot;uchi-recognizable language of infinite pictures is countably
infinite, and that it is $\Sigma_1^1$-complete to determine whether a given
B\&quot;uchi-recognizable language of infinite pictures is uncountable. Next we
consider complements of recognizable languages of infinite pictures. Using some
results of Set Theory, we show that the cardinality of the complement of a
B\&quot;uchi-recognizable language of infinite pictures may depend on the model of
the axiomatic system ZFC. We prove that the problem to determine whether the
complement of a given B\&quot;uchi-recognizable language of infinite pictures is
countable (respectively, uncountable) is in the class $\Sigma_3^1 \setminus
(\Pi_2^1 \cup \Sigma_2^1)$ (respectively, in the class $\Pi_3^1 \setminus
(\Pi_2^1 \cup \Sigma_2^1)$).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5897</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5897</id><created>2011-07-29</created><authors><author><keyname>Ksystra</keyname><forenames>Katerina</forenames></author><author><keyname>Triantafyllou</keyname><forenames>Nikolaos</forenames></author><author><keyname>Stefaneas</keyname><forenames>Petros</forenames></author><author><keyname>Frangos</keyname><forenames>Panayiotis</forenames></author></authors><title>An Algebraic Specification of the Semantic Web</title><categories>cs.LO</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a formal specification of the Semantic Web, as an extension of the
World Wide Web using the well known algebraic specification language CafeOBJ.
Our approach allows the description of the key elements of the Semantic Web
technologies, in order to give a better understanding of the system, without
getting involved with their implementation details that might not yet be
standardized. This specification is part of our work in progress concerning the
modeling the Social Semantic Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5924</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5924</id><created>2011-07-29</created><authors><author><keyname>Brim</keyname><forenames>Lubos</forenames></author><author><keyname>Fabrikova</keyname><forenames>Jana</forenames></author><author><keyname>Drazan</keyname><forenames>Sven</forenames></author><author><keyname>Safranek</keyname><forenames>David</forenames></author></authors><title>Reachability in Biochemical Dynamical Systems by Quantitative Discrete
  Approximation</title><categories>cs.SY math.OC q-bio.QM</categories><comments>Full version of a paper accepted to COMPMOD 2011</comments><msc-class>68U20</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper a novel computational technique for finite discrete
approximation of continuous dynamical systems suitable for a significant class
of biochemical dynamical systems is introduced. The method is parameterized in
order to affect the imposed level of approximation provided that with
increasing parameter value the approximation converges to the original
continuous system. By employing this approximation technique, we present
algorithms solving the reachability problem for biochemical dynamical systems.
The presented method and algorithms are evaluated on several exemplary
biological models and on a real case study. This is a full version of the paper
published in the proceedings of CompMod 2011.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5928</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5928</id><created>2011-07-29</created><updated>2011-10-07</updated><authors><author><keyname>Sasane</keyname><forenames>Amol</forenames></author></authors><title>Extension of the $\nu$-metric for stabilizable plants over $H^\infty$</title><categories>math.OC cs.SY math.AP math.FA math.RA</categories><comments>12 pages</comments><msc-class>93B36, Secondary 93D15, 46J15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An abstract $\nu$-metric was introduced by Ball and Sasane, with a view
towards extending the classical $\nu$-metric of Vinnicombe from the case of
rational transfer functions to more general nonrational transfer function
classes of infinite-dimensional linear control systems. In this short note, we
give an important concrete special instance of the abstract $\nu$-metric, by
verifying that all the assumptions demanded in the abstract set-up are
satisfied when the ring of stable transfer functions is the Hardy algebra
$H^\infty$. This settles the open question implicit in \cite{BalSas2}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5930</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5930</id><created>2011-07-29</created><authors><author><keyname>Hern&#xe1;ndez-Orallo</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Flach</keyname><forenames>Peter</forenames></author><author><keyname>Ferri</keyname><forenames>C&#xe8;sar</forenames></author></authors><title>Technical Note: Towards ROC Curves in Cost Space</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  ROC curves and cost curves are two popular ways of visualising classifier
performance, finding appropriate thresholds according to the operating
condition, and deriving useful aggregated measures such as the area under the
ROC curve (AUC) or the area under the optimal cost curve. In this note we
present some new findings and connections between ROC space and cost space, by
using the expected loss over a range of operating conditions. In particular, we
show that ROC curves can be transferred to cost space by means of a very
natural way of understanding how thresholds should be chosen, by selecting the
threshold such that the proportion of positive predictions equals the operating
condition (either in the form of cost proportion or skew). We call these new
curves {ROC Cost Curves}, and we demonstrate that the expected loss as measured
by the area under these curves is linearly related to AUC. This opens up a
series of new possibilities and clarifies the notion of cost curve and its
relation to ROC analysis. In addition, we show that for a classifier that
assigns the scores in an evenly-spaced way, these curves are equal to the Brier
Curves. As a result, this establishes the first clear connection between AUC
and the Brier score.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5951</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5951</id><created>2011-07-29</created><authors><author><keyname>May</keyname><forenames>Dave A.</forenames></author><author><keyname>Knepley</keyname><forenames>Matthew G.</forenames></author></authors><title>Optimal, scalable forward models for computing gravity anomalies</title><categories>cs.CE cs.DC physics.geo-ph</categories><comments>38 pages, 13 figures; accepted by Geophysical Journal International</comments><journal-ref>Geophysical Journal International, 187(1):161-177, 2011</journal-ref><doi>10.1111/j.1365-246X.2011.05167.x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe three approaches for computing a gravity signal from a density
anomaly. The first approach consists of the classical &quot;summation&quot; technique,
whilst the remaining two methods solve the Poisson problem for the
gravitational potential using either a Finite Element (FE) discretization
employing a multilevel preconditioner, or a Green's function evaluated with the
Fast Multipole Method (FMM). The methods utilizing the PDE formulation
described here differ from previously published approaches used in gravity
modeling in that they are optimal, implying that both the memory and
computational time required scale linearly with respect to the number of
unknowns in the potential field. Additionally, all of the implementations
presented here are developed such that the computations can be performed in a
massively parallel, distributed memory computing environment. Through numerical
experiments, we compare the methods on the basis of their discretization error,
CPU time and parallel scalability. We demonstrate the parallel scalability of
all these techniques by running forward models with up to $10^8$ voxels on
1000's of cores.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5953</identifier>
 <datestamp>2012-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5953</id><created>2011-07-29</created><updated>2012-06-29</updated><authors><author><keyname>Dabhade</keyname><forenames>Indraneel</forenames></author></authors><title>Multivalued Subsets Under Information Theory</title><categories>cs.IT math.IT</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the fields of finance, engineering and sciences data mining/ machine
learning has held an eminent position in predictive analysis. Complex
algorithms and adaptive decision models have contributed towards streamlining
research as well as improve forecasting. Extensive study in areas surrounding
computation and mathematical sciences has primarily been responsible for the
field's development. Classification based modeling, which holds a prominent
position amongst the different rule-based algorithms, is one of the most widely
used decision making tool. The decision tree has a place of profound
significance in classification modeling. A number of heuristics have been
developed over the years to refine its decision making process. Most heuristics
applied to such tree-based learning algorithms derive their roots from
Shannon's 'Information Theory'. The current application of this theory is
directed towards individual assessment of the attribute-values. The proposed
study takes a look at the effects of combining these values with the aim to
improve the 'Information Gain'. A search-based heuristic tool is applied for
identifying the subsets sharing a better gain value than the ones presented in
the GID3 approach. An application towards the feature selection stage of the
mining process has been tested and presented with statistical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5968</identifier>
 <datestamp>2011-09-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5968</id><created>2011-07-29</created><updated>2011-09-09</updated><authors><author><keyname>De Tommasi</keyname><forenames>Gianmaria</forenames></author><author><keyname>Ambrosino</keyname><forenames>Roberto</forenames></author><author><keyname>Carannante</keyname><forenames>Giuseppe</forenames></author><author><keyname>Cosentino</keyname><forenames>Carlo</forenames></author><author><keyname>Pironti</keyname><forenames>Alfredo</forenames></author><author><keyname>Amato</keyname><forenames>Francesco</forenames></author></authors><title>Input-Output Finite-Time Stability</title><categories>cs.SY math.OC</categories><comments>14 pages, 9 figures, 2 tables. This paper has been accepted for
  presentation at AUTOMATICA.IT, Convegno Annuale dei Docenti e Ricercatori
  Italiani in Automatica, Pisa, Italy, September 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces the extension of Finite-Time Stability (FTS) to the
input-output case, namely the Input-Output FTS (IO-FTS). The main differences
between classic IO stability and IO-FTS are that the latter involves signals
defined over a finite time interval, does not necessarily require the inputs
and outputs to belong to the same class of signals, and that quantitative
bounds on both inputs and outputs must be specified. This paper revises some
recent results on IO-FTS, both in the context of linear systems and in the
context of switching systems. In the final example the proposed methodology is
used to minimize the maximum displacement and velocity of a building subject to
an earthquake of given magnitude.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5973</identifier>
 <datestamp>2015-03-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5973</id><created>2011-07-29</created><authors><author><keyname>Hedtke</keyname><forenames>Ivo</forenames></author></authors><title>Upgrading Subgroup Triple Product Property Triples</title><categories>math.GR cs.DM</categories><comments>12 pages, 1 figure, 4 tables, 7 algorithms</comments><journal-ref>ACM Journal of Experimental Algorithmics, Volume 20, March 2015,
  Article No. 1.1</journal-ref><doi>10.1145/2699877</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 2003 COHN and UMANS introduced a group-theoretic approach to fast matrix
multiplication. This involves finding large subsets of a group $G$ satisfying
the Triple Product Property (TPP) as a means to bound the exponent $\omega$ of
matrix multiplication. Recently, Hedtke and Murthy discussed several methods to
find TPP triples. Because the search space for subset triples is too large, it
is only possible to focus on subgroup triples.
  We present methods to upgrade a given TPP triple to a bigger TPP triple. If
no upgrade is possible we use reduction methods (based on random experiments
and heuristics) to create a smaller TPP triple that can be used as input for
the upgrade methods.
  If we apply the upgrade process for subset triples after one step with the
upgrade method for subgroup triples we achieve an enlargement of the triple
size of 100 % in the best case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.5980</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.5980</id><created>2011-07-29</created><authors><author><keyname>Codish</keyname><forenames>Michael</forenames></author><author><keyname>Gonopolskiy</keyname><forenames>Igor</forenames></author><author><keyname>Ben-Amram</keyname><forenames>Amir M.</forenames></author><author><keyname>Fuhs</keyname><forenames>Carsten</forenames></author><author><keyname>Giesl</keyname><forenames>J&#xfc;rgen</forenames></author></authors><title>SAT-Based Termination Analysis Using Monotonicity Constraints over the
  Integers</title><categories>cs.LO</categories><journal-ref>Theory and Practice of Logic Programming, 27th International
  Conference on Logic Programming (ICLP'11) Special Issue, volume 11, issue
  4-5, pages 503-520, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe an algorithm for proving termination of programs abstracted to
systems of monotonicity constraints in the integer domain. Monotonicity
constraints are a non-trivial extension of the well-known size-change
termination method. While deciding termination for systems of monotonicity
constraints is PSPACE complete, we focus on a well-defined and significant
subset, which we call MCNP, designed to be amenable to a SAT-based solution.
Our technique is based on the search for a special type of ranking function
defined in terms of bounded differences between multisets of integer values. We
describe the application of our approach as the back-end for the termination
analysis of Java Bytecode (JBC). At the front-end, systems of monotonicity
constraints are obtained by abstracting information, using two different
termination analyzers: AProVE and COSTA. Preliminary results reveal that our
approach provides a good trade-off between precision and cost of analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.6004</identifier>
 <datestamp>2015-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.6004</id><created>2011-07-29</created><updated>2015-09-30</updated><authors><author><keyname>Oikonomou</keyname><forenames>Kostas N.</forenames></author><author><keyname>Grunwald</keyname><forenames>Peter D.</forenames></author></authors><title>Explicit Bounds for Entropy Concentration under Linear Constraints</title><categories>cs.IT math.IT physics.data-an</categories><comments>1) An error affecting sec. 3 has been corrected: the parameters delta
  and theta cannot be chosen independently. Sec. 3 has been revised up to
  Theorem 3.15 in sec. 3.6. 2) Some minor updates in sec. 4. 3) Some proofs
  used in both sec. 3 and sec. 4 have been unified (This version to appear in
  IEEE Transactions on Information Theory, December 2015)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider the set of all sequences of $n$ outcomes, each taking one of $m$
values, that satisfy a number of linear constraints. If $m$ is fixed while $n$
increases, most sequences that satisfy the constraints result in frequency
vectors whose entropy approaches that of the maximum entropy vector satisfying
the constraints. This well-known &quot;entropy concentration&quot; phenomenon underlies
the maximum entropy method.
  Existing proofs of the concentration phenomenon are based on limits or
asymptotics and unrealistically assume that constraints hold precisely,
supporting maximum entropy inference more in principle than in practice. We
present, for the first time, non-asymptotic, explicit lower bounds on $n$ for a
number of variants of the concentration result to hold to any prescribed
accuracies, with the constraints holding up to any specified tolerance, taking
into account the fact that allocations of discrete units can satisfy
constraints only approximately. Again unlike earlier results, we measure
concentration not by deviation from the maximum entropy value, but by the
$\ell_1$ and $\ell_2$ distances from the maximum entropy-achieving frequency
vector. One of our results holds independently of the alphabet size $m$ and is
based on a novel proof technique using the multi-dimensional Berry-Esseen
theorem. We illustrate and compare our results using various detailed examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.6014</identifier>
 <datestamp>2011-08-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.6014</id><created>2011-07-29</created><authors><author><keyname>Cournier</keyname><forenames>Alain</forenames><affiliation>MIS</affiliation></author><author><keyname>Dubois</keyname><forenames>Swan</forenames><affiliation>LIP6</affiliation></author><author><keyname>Lamani</keyname><forenames>Anissa</forenames><affiliation>MIS</affiliation></author><author><keyname>Petit</keyname><forenames>Franck</forenames><affiliation>LIP6</affiliation></author><author><keyname>Villain</keyname><forenames>Vincent</forenames><affiliation>MIS</affiliation></author></authors><title>Snap-Stabilizing Message Forwarding Algorithm on Tree Topologies</title><categories>cs.DC</categories><comments>2011</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the message forwarding problem that consists in
managing the network resources that are used to forward messages. Previous
works on this problem provide solutions that either use a significant number of
buffers (that is n buffers per processor, where n is the number of processors
in the network) making the solution not scalable or, they reserve all the
buffers from the sender to the receiver to forward only one message %while
using D buffers (where D refers to the diameter of the network) . The only
solution that uses a constant number of buffers per link was introduced in [1].
However the solution works only on a chain networks. In this paper, we propose
a snap-stabilizing algorithm for the message forwarding problem that uses the
same complexity on the number of buffers as [1] and works on tree topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1107.6027</identifier>
 <datestamp>2012-02-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1107.6027</id><created>2011-07-29</created><updated>2012-02-27</updated><authors><author><keyname>Jiao</keyname><forenames>Jiantao</forenames></author><author><keyname>Zhang</keyname><forenames>Lin</forenames></author><author><keyname>Nowak</keyname><forenames>Robert</forenames></author></authors><title>Minimax-Optimal Bounds for Detectors Based on Estimated Prior
  Probabilities</title><categories>cs.IT math.IT stat.ML</categories><comments>Submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many signal detection and classification problems, we have knowledge of
the distribution under each hypothesis, but not the prior probabilities. This
paper is aimed at providing theory to quantify the performance of detection via
estimating prior probabilities from either labeled or unlabeled training data.
The error or {\em risk} is considered as a function of the prior probabilities.
We show that the risk function is locally Lipschitz in the vicinity of the true
prior probabilities, and the error of detectors based on estimated prior
probabilities depends on the behavior of the risk function in this locality. In
general, we show that the error of detectors based on the Maximum Likelihood
Estimate (MLE) of the prior probabilities converges to the Bayes error at a
rate of $n^{-1/2}$, where $n$ is the number of training data. If the behavior
of the risk function is more favorable, then detectors based on the MLE have
errors converging to the corresponding Bayes errors at optimal rates of the
form $n^{-(1+\alpha)/2}$, where $\alpha&gt;0$ is a parameter governing the
behavior of the risk function with a typical value $\alpha = 1$. The limit
$\alpha \rightarrow \infty$ corresponds to a situation where the risk function
is flat near the true probabilities, and thus insensitive to small errors in
the MLE; in this case the error of the detector based on the MLE converges to
the Bayes error exponentially fast with $n$. We show the bounds are achievable
no matter given labeled or unlabeled training data and are minimax-optimal in
labeled case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0007</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0007</id><created>2011-07-29</created><authors><author><keyname>Yi</keyname><forenames>Sheng</forenames></author><author><keyname>Krim</keyname><forenames>Hamid</forenames></author><author><keyname>Norris</keyname><forenames>Larry K.</forenames></author></authors><title>A Invertible Dimension Reduction of Curves on a Manifold</title><categories>cs.CV math.DG</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we propose a novel lower dimensional representation of a shape
sequence. The proposed dimension reduction is invertible and computationally
more efficient in comparison to other related works. Theoretically, the
differential geometry tools such as moving frame and parallel transportation
are successfully adapted into the dimension reduction problem of high
dimensional curves. Intuitively, instead of searching for a global flat
subspace for curve embedding, we deployed a sequence of local flat subspaces
adaptive to the geometry of both of the curve and the manifold it lies on. In
practice, the experimental results of the dimension reduction and
reconstruction algorithms well illustrate the advantages of the proposed
theoretical innovation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0013</identifier>
 <datestamp>2013-10-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0013</id><created>2011-07-29</created><updated>2013-10-30</updated><authors><author><keyname>Prasad</keyname><forenames>Narayan</forenames></author><author><keyname>Zhang</keyname><forenames>Honghai</forenames></author><author><keyname>Zhu</keyname><forenames>Hao</forenames></author><author><keyname>Rangarajan</keyname><forenames>Sampath</forenames></author></authors><title>Multi-User MIMO Scheduling in the Fourth Generation Cellular Uplink</title><categories>cs.NI</categories><comments>Updated technical details and fixed some errors; This version
  accepted, IEEE Transactions on Wireless Communications 2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider Multi-User MIMO (MU-MIMO) scheduling in the 3GPP LTE-Advanced
(3GPP LTE-A) cellular uplink. The 3GPP LTE-A uplink allows for precoded
multi-stream (precoded MIMO) transmission from each scheduled user and also
allows flexible multi-user (MU) scheduling wherein multiple users can be
assigned the same time-frequency resource. However, exploiting these features
is made challenging by certain practical constraints that have been imposed in
order to maintain a low signaling overhead. We show that while the scheduling
problem in the 3GPP LTE-A cellular uplink is NP-hard, it can be formulated as
the maximization of a submodular set function subject to one matroid and
multiple knapsack constraints. We then propose constant-factor polynomial-time
approximation algorithms and demonstrate their superior performance via
simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0017</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0017</id><created>2011-07-29</created><authors><author><keyname>Phillips</keyname><forenames>Jeff M.</forenames></author><author><keyname>Raman</keyname><forenames>Parasaran</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Generating a Diverse Set of High-Quality Clusterings</title><categories>cs.LG cs.DB</categories><comments>12 Pages, 5 Figures, 2nd MultiClust Workshop at ECML PKDD 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide a new framework for generating multiple good quality partitions
(clusterings) of a single data set. Our approach decomposes this problem into
two components, generating many high-quality partitions, and then grouping
these partitions to obtain k representatives. The decomposition makes the
approach extremely modular and allows us to optimize various criteria that
control the choice of representative partitions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0024</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0024</id><created>2011-07-29</created><authors><author><keyname>Haija</keyname><forenames>Ahmad Abu Al</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>Achievable Rates and Outer Bound for the Half-Duplex MAC with
  Generalized Feedback</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper provides comprehensive coding and outer bound for the half-duplex
multiple access channel with generalized feedback (MAC-GF). Two users
communicate with one destination over a discrete memoryless channel using time
division. Each transmission block is divided into 3 time slots with variable
durations: the destination is always in receive mode, while each user
alternatively transmits and receives during the first 2 time slots, then both
cooperate to send information during the last one. The paper proposes two
decode-forward based coding schemes, analyzes their rate regions, and also
derives two outer bounds with rate constraints similar to the achievable
regions. Both schemes requires no block Makovity, allowing the destination to
decode at the end of each block without any delay. In the first scheme, the
codewords in the third time slot are superimposed on the codewords of the first
two, whereas in the second scheme, these codewords are independent. While the
second scheme is simpler, the first scheme helps emphasize the importance of
joint decoding over separate decoding among multiple time slots at the
destination. For the Gaussian channel, the two schemes with joint decoding are
equivalent, as are the two outer bounds. For physically degraded Gaussian
channels, the proposed schemes achieve the capacity. Extension to the m-user
half-duplex MAC-GF are provided. Numerical results for the Gaussian channel
shows significant rate region improvement over the classical MAC and that the
outer bound becomes increasingly tight as the inter-user link quality increases
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0027</identifier>
 <datestamp>2011-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0027</id><created>2011-07-29</created><authors><author><keyname>Sala</keyname><forenames>Alessandra</forenames></author><author><keyname>Gaito</keyname><forenames>Sabrina</forenames></author><author><keyname>Rossi</keyname><forenames>Gian Paolo</forenames></author><author><keyname>Zheng</keyname><forenames>Haitao</forenames></author><author><keyname>Zhao</keyname><forenames>Ben Y.</forenames></author></authors><title>Revisiting Degree Distribution Models for Social Graph Analysis</title><categories>cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Degree distribution models are incredibly important tools for analyzing and
understanding the structure and formation of social networks, and can help
guide the design of efficient graph algorithms. In particular, the Power-law
degree distribution has long been used to model the structure of online social
networks, and is the basis for algorithms and heuristics in graph applications
such as influence maximization and social search. Along with recent measurement
results, our interest in this topic was sparked by our own experimental results
on social graphs that deviated significantly from those predicted by a
Power-law model. In this work, we seek a deeper understanding of these
deviations, and propose an alternative model with significant implications on
graph algorithms and applications. We start by quantifying this artifact using
a variety of real social graphs, and show that their structures cannot be
accurately modeled using elementary distributions including the Power-law.
Instead, we propose the Pareto-Lognormal (PLN) model, verify its
goodness-of-fit using graphical and statistical methods, and present an
analytical study of its asymptotical differences with the Power-law. To
demonstrate the quantitative benefits of the PLN model, we compare the results
of three wide-ranging graph applications on real social graphs against those on
synthetic graphs generated using the PLN and Power-law models. We show that
synthetic graphs generated using PLN are much better predictors of degree
distributions in real graphs, and produce experimental results with errors that
are orders-of-magnitude smaller than those produced by the Power-law model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0039</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0039</id><created>2011-07-30</created><updated>2011-10-12</updated><authors><author><keyname>Baydin</keyname><forenames>Atilim Gunes</forenames></author><author><keyname>de Mantaras</keyname><forenames>Ramon Lopez</forenames></author><author><keyname>Simoff</keyname><forenames>Simeon</forenames></author><author><keyname>Sierra</keyname><forenames>Carles</forenames></author></authors><title>CBR with Commonsense Reasoning and Structure Mapping: An Application to
  Mediation</title><categories>cs.AI cs.LG</categories><comments>15 pages, 3 figures; updated copyright notice</comments><msc-class>91E40, 68T05, 68T20, 68T30</msc-class><acm-class>I.2.6; I.2.1</acm-class><journal-ref>Case-Based Reasoning Research and Development, LNCS (LNAI), Volume
  6880 (2011), 378-392, Springer Berlin / Heidelberg, ISBN: 978-3-642-23290-9</journal-ref><doi>10.1007/978-3-642-23291-6_28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mediation is an important method in dispute resolution. We implement a case
based reasoning approach to mediation integrating analogical and commonsense
reasoning components that allow an artificial mediation agent to satisfy
requirements expected from a human mediator, in particular: utilizing
experience with cases in different domains; and structurally transforming the
set of issues for a better solution. We utilize a case structure based on
ontologies reflecting the perceptions of the parties in dispute. The analogical
reasoning component, employing the Structure Mapping Theory from psychology,
provides a flexibility to respond innovatively in unusual circumstances, in
contrast with conventional approaches confined into specialized problem
domains. We aim to build a mediation case base incorporating real world
instances ranging from interpersonal or intergroup disputes to international
conflicts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0047</identifier>
 <datestamp>2012-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0047</id><created>2011-07-30</created><updated>2012-08-14</updated><authors><author><keyname>Beretta</keyname><forenames>Stefano</forenames></author><author><keyname>Bonizzoni</keyname><forenames>Paola</forenames></author><author><keyname>Della Vedova</keyname><forenames>Gianluca</forenames></author><author><keyname>Rizzi</keyname><forenames>Raffaella</forenames></author></authors><title>Reconstructing Isoform Graphs from RNA-Seq data</title><categories>q-bio.GN cs.CE cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Next-generation sequencing (NGS) technologies allow new methodologies for
alternative splicing (AS) analysis. Current computational methods for AS from
NGS data are mainly focused on predicting splice site junctions or de novo
assembly of full-length transcripts. These methods are computationally
expensive and produce a huge number of full-length transcripts or splice
junctions, spanning the whole genome of organisms. Thus summarizing such data
into the different gene structures and AS events of the expressed genes is an
hard task.
  To face this issue in this paper we investigate the computational problem of
reconstructing from NGS data, in absence of the genome, a gene structure for
each gene that is represented by the isoform graph: we introduce such graph and
we show that it uniquely summarizes the gene transcripts. We define the
computational problem of reconstructing the isoform graph and provide some
conditions that must be met to allow such reconstruction.
  Finally, we describe an efficient algorithmic approach to solve this problem,
validating our approach with both a theoretical and an experimental analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0064</identifier>
 <datestamp>2011-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0064</id><created>2011-07-30</created><authors><author><keyname>B&#xed;lka</keyname><forenames>Ond&#x159;ej</forenames></author><author><keyname>Jir&#xe1;sek</keyname><forenames>Jozef</forenames></author><author><keyname>Klav&#xed;k</keyname><forenames>Pavel</forenames></author><author><keyname>Tancer</keyname><forenames>Martin</forenames></author><author><keyname>Volec</keyname><forenames>Jan</forenames></author></authors><title>On the Complexity of Planar Covering of Small Graphs</title><categories>math.CO cs.DM</categories><comments>Full version (including Appendix) of a paper from the conference WG
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem Cover(H) asks whether an input graph G covers a fixed graph H
(i.e., whether there exists a homomorphism G to H which locally preserves the
structure of the graphs). Complexity of this problem has been intensively
studied. In this paper, we consider the problem PlanarCover(H) which restricts
the input graph G to be planar.
  PlanarCover(H) is polynomially solvable if Cover(H) belongs to P, and it is
even trivially solvable if H has no planar cover. Thus the interesting cases
are when H admits a planar cover, but Cover(H) is NP-complete. This also
relates the problem to the long-standing Negami Conjecture which aims to
describe all graphs having a planar cover. Kratochvil asked whether there are
non-trivial graphs for which Cover(H) is NP-complete but PlanarCover(H) belongs
to P.
  We examine the first nontrivial cases of graphs H for which Cover(H) is
NP-complete and which admit a planar cover. We prove NP-completeness of
PlanarCover(H) in these cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0065</identifier>
 <datestamp>2013-01-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0065</id><created>2011-07-30</created><updated>2013-01-05</updated><authors><author><keyname>Chertkov</keyname><forenames>M.</forenames></author><author><keyname>Yedidia</keyname><forenames>A. B.</forenames></author></authors><title>Approximating the Permanent with Fractional Belief Propagation</title><categories>cs.DM cond-mat.stat-mech cs.CC cs.IT math.IT</categories><comments>42 pages, 14 figures</comments><report-no>LA-UR 11-04333</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss schemes for exact and approximate computations of permanents, and
compare them with each other. Specifically, we analyze the Belief Propagation
(BP) approach and its Fractional Belief Propagation (FBP) generalization for
computing the permanent of a non-negative matrix. Known bounds and conjectures
are verified in experiments, and some new theoretical relations, bounds and
conjectures are proposed. The Fractional Free Energy (FFE) functional is
parameterized by a scalar parameter $\gamma\in[-1;1]$, where $\gamma=-1$
corresponds to the BP limit and $\gamma=1$ corresponds to the exclusion
principle (but ignoring perfect matching constraints) Mean-Field (MF) limit.
FFE shows monotonicity and continuity with respect to $\gamma$. For every
non-negative matrix, we define its special value $\gamma_*\in[-1;0]$ to be the
$\gamma$ for which the minimum of the $\gamma$-parameterized FFE functional is
equal to the permanent of the matrix, where the lower and upper bounds of the
$\gamma$-interval corresponds to respective bounds for the permanent. Our
experimental analysis suggests that the distribution of $\gamma_*$ varies for
different ensembles but $\gamma_*$ always lies within the $[-1;-1/2]$ interval.
Moreover, for all ensembles considered the behavior of $\gamma_*$ is highly
distinctive, offering an emprirical practical guidance for estimating
permanents of non-negative matrices via the FFE approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0072</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0072</id><created>2011-07-30</created><authors><author><keyname>Jacquet</keyname><forenames>Philippe</forenames></author><author><keyname>Malik</keyname><forenames>Salman</forenames></author><author><keyname>Mans</keyname><forenames>Bernard</forenames></author><author><keyname>Silva</keyname><forenames>Alonso</forenames></author></authors><title>On the Throughput-Delay Trade-off in Georouting Networks</title><categories>cs.IT cs.NI math.IT</categories><comments>This work has been submitted to IEEE INFOCOM 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the scaling properties of a georouting scheme in a wireless
multi-hop network of $n$ mobile nodes. Our aim is to increase the network
capacity quasi linearly with $n$ while keeping the average delay bounded. In
our model, mobile nodes move according to an i.i.d. random walk with velocity
$v$ and transmit packets to randomly chosen destinations. The average packet
delivery delay of our scheme is of order $1/v$ and it achieves the network
capacity of order $\frac{n}{\log n\log\log n}$. This shows a practical
throughput-delay trade-off, in particular when compared with the seminal result
of Gupta and Kumar which shows network capacity of order $\sqrt{n/\log n}$ and
negligible delay and the groundbreaking result of Grossglausser and Tse which
achieves network capacity of order $n$ but with an average delay of order
$\sqrt{n}/v$. We confirm the generality of our analytical results using
simulations under various interference models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0100</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0100</id><created>2011-07-30</created><authors><author><keyname>Li</keyname><forenames>Jiangyuan</forenames></author><author><keyname>Petropulu</keyname><forenames>Athina P.</forenames></author></authors><title>Explicit Solution of Worst-Case Secrecy Rate for MISO Wiretap Channels
  with Spherical Uncertainty</title><categories>cs.IT math.IT</categories><comments>1 figures</comments><doi>10.1109/TSP.2012.2192111</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A multiple-input single-output (MISO) wiretap channel model is considered,
that includes a multi-antenna transmitter, a single-antenna legitimate receiver
and a single-antenna eavesdropper. For the scenario in which spherical
uncertainty for both the legitimate and the eavesdropper channels is included,
the problem of finding the optimal input covariance that maximizes the
worst-case secrecy rate subject to a power constraint, is considered, and an
explicit expression for the maximum worst-case secrecy rate is provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0128</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0128</id><created>2011-07-30</created><authors><author><keyname>Chen</keyname><forenames>Shiyao</forenames></author><author><keyname>Tong</keyname><forenames>Lang</forenames></author><author><keyname>Zhao</keyname><forenames>Qing</forenames></author></authors><title>Delay Optimal Multichannel Opportunistic Access</title><categories>math.OC cs.SY</categories><comments>9 pages, 6 figures, submitted to INFOCOM 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of minimizing queueing delay of opportunistic access of multiple
continuous time Markov channels is considered. A new access policy based on
myopic sensing and adaptive transmission (MS-AT) is proposed. Under the
framework of risk sensitive constrained Markov decision process with effective
bandwidth as a measure of queueing delay, it is shown that MS-AT achieves
simultaneously throughput and delay optimality. It is shown further that both
the effective bandwidth and the throughput of MS-AT are two-segment piece-wise
linear functions of the collision constraint (maximum allowable conditional
collision probability) with the effective bandwidth and throughput coinciding
in the regime of tight collision constraints. Analytical and simulations
comparisons with the myopic sensing and memoryless transmission (MS-MT) policy
which is throughput optimal but delay suboptimal in the regime of tight
collision constraints.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0129</identifier>
 <datestamp>2011-09-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0129</id><created>2011-07-30</created><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Identifiability and inference of non-parametric rates-across-sites
  models on large-scale phylogenies</title><categories>math.PR cs.CE cs.DS math.ST q-bio.PE stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mutation rate variation across loci is well known to cause difficulties,
notably identifiability issues, in the reconstruction of evolutionary trees
from molecular sequences. Here we introduce a new approach for estimating
general rates-across-sites models. Our results imply, in particular, that large
phylogenies are typically identifiable under rate variation. We also derive
sequence-length requirements for high-probability reconstruction.
  Our main contribution is a novel algorithm that clusters sites according to
their mutation rate. Following this site clustering step, standard
reconstruction techniques can be used to recover the phylogeny. Our results
rely on a basic insight: that, for large trees, certain site statistics
experience concentration-of-measure phenomena.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0141</identifier>
 <datestamp>2012-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0141</id><created>2011-07-31</created><authors><author><keyname>Savitha</keyname><forenames>K.</forenames></author><author><keyname>Chandrasekar</keyname><forenames>C.</forenames></author></authors><title>Trusted Network Selection using SAW and TOPSIS Algorithms for
  Heterogeneous Wireless Networks</title><categories>cs.NI cs.DC</categories><comments>arXiv admin note: substantial text overlap with arXiv:1106.2402</comments><doi>10.5120/3125-4300</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seamless continuity is the main goal in fourth generation Wireless networks
(FGWNs), to achieve this &quot;HANDOVER&quot; technique is used, when a mobile
terminal(MT) is in overlapping area for service continuity, Handover mechanism
are mainly used. In Heterogeneous wireless networks main challenge is continual
connection among the different networks like WiFi, WiMax, WLAN, WPAN etc. In
this paper, Vertical handover decision schemes are compared and Multi Attribute
Decision Making (MADM) is used to choose the best network from the available
Visitor networks (VTs) for the continuous connection by the mobile terminal. In
our work we mainly concentrated to the handover decision phase and to reduce
the processing delay in the period of handover. MADM algorithms SAW and TOPSIS
where compared to reduce the processing delay by using NS2 to evaluate the
parameters for processing delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0144</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0144</id><created>2011-07-31</created><authors><author><keyname>Silva</keyname><forenames>Alexandra</forenames></author><author><keyname>Bliudze</keyname><forenames>Simon</forenames></author><author><keyname>Bruni</keyname><forenames>Roberto</forenames></author><author><keyname>Carbone</keyname><forenames>Marco</forenames></author></authors><title>Proceedings Fourth Interaction and Concurrency Experience</title><categories>cs.LO</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 59, 2011</journal-ref><doi>10.4204/EPTCS.59</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the pre-proceedings of ICE'11, the 4th Interaction and
Concurrency Experience workshop, which was held in Reykjavik, Iceland on the
9th of June 2011 as a satellite event of DisCoTec'11.
  The topic of ICE'11 was Reliable and Contract-based Interaction. Reliable
interactions are, e.g., those enjoying suitable logical, behavioural, or
security properties, or adhering to certain QoS standards. Contract-based
interactions are, e.g., those where the interacting entities are committed to
give certain guarantees whenever certain assumptions are met by their operating
environment.
  The ICE procedure for paper selection allows for PC members to interact,
anonymously, with authors. During the review phase, each submitted paper is
published on a Wiki and associated with a discussion forum whose access is
restricted to the authors and to all the PC members not declaring a conflict of
interests. The PC members post comments and questions that the authors reply
to. Each paper was reviewed by four PC members, and altogether 8 papers (out of
12) were accepted for publication.
  We were proud to host three invited talks by Rocco De Nicola (joint with
PACO), Simon Gay and Prakash Panangaden, whose abstracts are included in this
volume together with the regular papers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0155</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0155</id><created>2011-07-31</created><authors><author><keyname>Schneider</keyname><forenames>Michael</forenames></author><author><keyname>Sutcliffe</keyname><forenames>Geoff</forenames></author></authors><title>Reasoning in the OWL 2 Full Ontology Language using First-Order
  Automated Theorem Proving</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  OWL 2 has been standardized by the World Wide Web Consortium (W3C) as a
family of ontology languages for the Semantic Web. The most expressive of these
languages is OWL 2 Full, but to date no reasoner has been implemented for this
language. Consistency and entailment checking are known to be undecidable for
OWL 2 Full. We have translated a large fragment of the OWL 2 Full semantics
into first-order logic, and used automated theorem proving systems to do
reasoning based on this theory. The results are promising, and indicate that
this approach can be applied in practice for effective OWL reasoning, beyond
the capabilities of current Semantic Web reasoners.
  This is an extended version of a paper with the same title that has been
published at CADE 2011, LNAI 6803, pp. 446-460. The extended version provides
appendices with additional resources that were used in the reported evaluation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0170</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0170</id><created>2011-07-31</created><authors><author><keyname>Roozbehani</keyname><forenames>Mardavij</forenames></author><author><keyname>Megretski</keyname><forenames>Alexandre</forenames></author><author><keyname>Feron</keyname><forenames>Eric</forenames></author></authors><title>Optimization of Lyapunov Invariants in Verification of Software Systems</title><categories>cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper proposes a control-theoretic framework for verification of
numerical software systems, and puts forward software verification as an
important application of control and systems theory. The idea is to transfer
Lyapunov functions and the associated computational techniques from control
systems analysis and convex optimization to verification of various software
safety and performance specifications. These include but are not limited to
absence of overflow, absence of division-by-zero, termination in finite time,
presence of dead-code, and certain user-specified assertions. Central to this
framework are Lyapunov invariants. These are properly constructed functions of
the program variables, and satisfy certain properties-resembling those of
Lyapunov functions-along the execution trace. The search for the invariants can
be formulated as a convex optimization problem. If the associated optimization
problem is feasible, the result is a certificate for the specification.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0186</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0186</id><created>2011-07-31</created><updated>2011-10-12</updated><authors><author><keyname>Hong</keyname><forenames>Yuan</forenames></author><author><keyname>Vaidya</keyname><forenames>Jaideep</forenames></author><author><keyname>Lu</keyname><forenames>Haibing</forenames></author><author><keyname>Wu</keyname><forenames>Mingrui</forenames></author></authors><title>Differentially Private Search Log Sanitization with Optimal Output
  Utility</title><categories>cs.DB</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web search logs contain extremely sensitive data, as evidenced by the recent
AOL incident. However, storing and analyzing search logs can be very useful for
many purposes (i.e. investigating human behavior). Thus, an important research
question is how to privately sanitize search logs. Several search log
anonymization techniques have been proposed with concrete privacy models.
However, in all of these solutions, the output utility of the techniques is
only evaluated rather than being maximized in any fashion. Indeed, for
effective search log anonymization, it is desirable to derive the optimal
(maximum utility) output while meeting the privacy standard. In this paper, we
propose utility-maximizing sanitization based on the rigorous privacy standard
of differential privacy, in the context of search logs. Specifically, we
utilize optimization models to maximize the output utility of the sanitization
for different applications, while ensuring that the production process
satisfies differential privacy. An added benefit is that our novel
randomization strategy ensures that the schema of the output is identical to
that of the input. A comprehensive evaluation on real search logs validates the
approach and demonstrates its robustness and scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0187</identifier>
 <datestamp>2013-12-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0187</id><created>2011-07-31</created><updated>2013-11-29</updated><authors><author><keyname>Xu</keyname><forenames>Yuedong</forenames></author><author><keyname>Altman</keyname><forenames>Eitan</forenames></author><author><keyname>El-Azouzi</keyname><forenames>Rachid</forenames></author><author><keyname>Haddad</keyname><forenames>Majed</forenames></author><author><keyname>Elayoubi</keyname><forenames>Salaheddine</forenames></author><author><keyname>Jimenez</keyname><forenames>Tania</forenames></author></authors><title>Analysis of Buffer Starvation with Application to Objective QoE
  Optimization of Streaming Services</title><categories>cs.PF cs.MM cs.NI</categories><comments>9 pages, 7 figures; IEEE Infocom 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Our purpose in this paper is to characterize buffer starvations for streaming
services. The buffer is modeled as an M/M/1 queue, plus the consideration of
bursty arrivals. When the buffer is empty, the service restarts after a certain
amount of packets are \emph{prefetched}. With this goal, we propose two
approaches to obtain the \emph{exact distribution} of the number of buffer
starvations, one of which is based on \emph{Ballot theorem}, and the other uses
recursive equations. The Ballot theorem approach gives an explicit result. We
extend this approach to the scenario with a constant playback rate using
T\`{a}kacs Ballot theorem. The recursive approach, though not offering an
explicit result, can obtain the distribution of starvations with
non-independent and identically distributed (i.i.d.) arrival process in which
an ON/OFF bursty arrival process is considered in this work. We further compute
the starvation probability as a function of the amount of prefetched packets
for a large number of files via a fluid analysis. Among many potential
applications of starvation analysis, we show how to apply it to optimize the
objective quality of experience (QoE) of media streaming, by exploiting the
tradeoff between startup/rebuffering delay and starvations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0190</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0190</id><created>2011-07-31</created><authors><author><keyname>Antoy</keyname><forenames>Sergio</forenames></author></authors><title>On the Correctness of Pull-Tabbing</title><categories>cs.PL</categories><journal-ref>Theory and Practice of Logic Programming, vol. 11, no. 4-5, pp.
  713-730, 2011</journal-ref><doi>10.1017/S1471068411000263</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Pull-tabbing is an evaluation approach for functional logic computations,
based on a graph transformation recently proposed, which avoids making
irrevocable non-deterministic choices that would jeopardize the completeness of
computations. In contrast to other approaches with this property, it does not
require an upfront cloning of a possibly large portion of the choice's context.
We formally define the pull-tab transformation, characterize the class of
programs for which the transformation is intended, extend the computations in
these programs to include the transformation, and prove the correctness of the
extended computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0192</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0192</id><created>2011-07-31</created><authors><author><keyname>Godfrey</keyname><forenames>P. Brighten</forenames></author></authors><title>BGP Stability is Precarious</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We note a fact which is simple, but may be useful for the networking research
community: essentially any change to BGP's decision process can cause
divergence --- or convergence when BGP would otherwise diverge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0194</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0194</id><created>2011-07-31</created><authors><author><keyname>Pappas</keyname><forenames>Nikolaos</forenames></author><author><keyname>Jeon</keyname><forenames>Jeongho</forenames></author><author><keyname>Ephremides</keyname><forenames>Anthony</forenames></author><author><keyname>Traganitis</keyname><forenames>Apostolos</forenames></author></authors><title>Optimal Utilization of a Cognitive Shared Channel with a Rechargeable
  Primary Source Node</title><categories>cs.IT math.IT</categories><comments>Submitted to JCN Special Issue on Energy Harvesting in Wireless
  Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the scenario in which a set of nodes share a common
channel. Some nodes have a rechargeable battery and the others are plugged to a
reliable power supply and, thus, have no energy limitations. We consider two
source-destination pairs and apply the concept of cognitive radio communication
in sharing the common channel. Specifically, we give high-priority to the
energy-constrained source-destination pair, i.e., primary pair, and
low-priority to the pair which is free from such constraint, i.e., secondary
pair. In contrast to the traditional notion of cognitive radio, in which the
secondary transmitter is required to relinquish the channel as soon as the
primary is detected, the secondary transmitter not only utilizes the idle slots
of primary pair but also transmits along with the primary transmitter with
probability $p$. This is possible because we consider the general multi-packet
reception model. Given the requirement on the primary pair's throughput, the
probability $p$ is chosen to maximize the secondary pair's throughput. To this
end, we obtain two-dimensional maximum stable throughput region which describes
the theoretical limit on rates that we can push into the network while
maintaining the queues in the network to be stable. The result is obtained for
both cases in which the capacity of the battery at the primary node is infinite
and also finite.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0223</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0223</id><created>2011-07-31</created><authors><author><keyname>Li</keyname><forenames>Yang D.</forenames></author></authors><title>BQP and PPAD</title><categories>cs.CC cs.GT quant-ph</categories><comments>18 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We initiate the study of the relationship between two complexity classes, BQP
(Bounded-Error Quantum Polynomial-Time) and PPAD (Polynomial Parity Argument,
Directed). We first give a conjecture that PPAD is contained in BQP, and show a
necessary and sufficient condition for the conjecture to hold. Then we prove
that the conjecture is not true under the oracle model. In the end, we raise
some interesting open problems/future directions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0228</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0228</id><created>2011-07-31</created><authors><author><keyname>Aceto</keyname><forenames>Luca</forenames><affiliation>Reykjavik University, Iceland</affiliation></author><author><keyname>Cimini</keyname><forenames>Matteo</forenames><affiliation>Reykjavik University, Iceland</affiliation></author><author><keyname>Ingolfsdottir</keyname><forenames>Anna</forenames><affiliation>Reykjavik University, Iceland</affiliation></author><author><keyname>Reynisson</keyname><forenames>Arni Hermann</forenames><affiliation>Reykjavik University, Iceland</affiliation></author><author><keyname>Sigurdarson</keyname><forenames>Steinar Hugi</forenames><affiliation>Reykjavik University, Iceland</affiliation></author><author><keyname>Sirjani</keyname><forenames>Marjan</forenames><affiliation>Reykjavik University, Iceland</affiliation></author></authors><title>Modelling and Simulation of Asynchronous Real-Time Systems using Timed
  Rebeca</title><categories>cs.SE</categories><comments>In Proceedings FOCLASA 2011, arXiv:1107.5847</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 58, 2011, pp. 1-19</journal-ref><doi>10.4204/EPTCS.58.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we propose an extension of the Rebeca language that can be used
to model distributed and asynchronous systems with timing constraints. We
provide the formal semantics of the language using Structural Operational
Semantics, and show its expressiveness by means of examples. We developed a
tool for automated translation from timed Rebeca to the Erlang language, which
provides a first implementation of timed Rebeca. We can use the tool to set the
parameters of timed Rebeca models, which represent the environment and
component variables, and use McErlang to run multiple simulations for different
settings. Timed Rebeca restricts the modeller to a pure asynchronous
actor-based paradigm, where the structure of the model represents the service
oriented architecture, while the computational model matches the network
infrastructure. Simulation is shown to be an effective analysis support,
specially where model checking faces almost immediate state explosion in an
asynchronous setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0229</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0229</id><created>2011-07-31</created><authors><author><keyname>Horne</keyname><forenames>Ross</forenames><affiliation>University of Southampton</affiliation></author><author><keyname>Sassone</keyname><forenames>Vladimiro</forenames><affiliation>University of Southampton</affiliation></author></authors><title>A Verified Algebra for Linked Data</title><categories>cs.LO cs.NI cs.PL</categories><comments>In Proceedings FOCLASA 2011, arXiv:1107.5847</comments><proxy>EPTCS</proxy><acm-class>F.1.2, F.3.2</acm-class><journal-ref>EPTCS 58, 2011, pp. 20-33</journal-ref><doi>10.4204/EPTCS.58.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A foundation is investigated for the application of loosely structured data
on the Web. This area is often referred to as Linked Data, due to the use of
URIs in data to establish links. This work focuses on emerging W3C standards
which specify query languages for Linked Data. The approach is to provide an
abstract syntax to capture Linked Data structures and queries, which are then
internalised in a process calculus. An operational semantics for the calculus
specifies how queries, data and processes interact. A labelled transition
system is shown to be sound with respect to the operational semantics.
Bisimulation over the labelled transition system is used to verify an algebra
over queries. The derived algebra is a contribution to the application domain.
For instance, the algebra may be used to rewrite a query to optimise its
distribution across a cluster of servers. The framework used to provide the
operational semantics is powerful enough to model related calculi for the Web.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0230</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0230</id><created>2011-07-31</created><authors><author><keyname>Ware</keyname><forenames>Simon</forenames></author><author><keyname>Malik</keyname><forenames>Robi</forenames></author></authors><title>A State-Based Characterisation of the Conflict Preorder</title><categories>cs.FL</categories><comments>In Proceedings FOCLASA 2011, arXiv:1107.5847</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 58, 2011, pp. 34-48</journal-ref><doi>10.4204/EPTCS.58.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes a way to effectively compare the potential of processes
to cause conflict. In discrete event systems theory, two concurrent systems are
said to be in conflict if they can get trapped in a situation where they are
both waiting or running endlessly, forever unable to complete their common
task. The conflict preorder is a process-algebraic pre-congruence that compares
two processes based on their possible conflicts in combination with other
processes. This paper improves on previous theoretical descriptions of the
conflict preorder by introducing less conflicting pairs as a concrete
state-based characterisation. Based on this characterisation, an effective
algorithm is presented to determine whether two processes are related according
to the conflict preorder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0231</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0231</id><created>2011-07-31</created><authors><author><keyname>Bodei</keyname><forenames>Chiara</forenames></author><author><keyname>Dinh</keyname><forenames>Viet Dung</forenames></author><author><keyname>Ferrari</keyname><forenames>Gian Luigi</forenames></author></authors><title>Predicting global usages of resources endowed with local policies</title><categories>cs.DC</categories><comments>In Proceedings FOCLASA 2011, arXiv:1107.5847</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 58, 2011, pp. 49-64</journal-ref><doi>10.4204/EPTCS.58.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effective usages of computational resources are a primary concern of
up-to-date distributed applications. In this paper, we present a methodology to
reason about resource usages (acquisition, release, revision, ...), and
therefore the proposed approach enables to predict bad usages of resources.
Keeping in mind the interplay between local and global information occurring in
the application-resource interactions, we model resources as entities with
local policies and global properties governing the overall interactions.
Formally, our model takes the shape of an extension of pi-calculus with
primitives to manage resources. We develop a Control Flow Analysis computing a
static approximation of process behaviour and therefore of the resource usages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0232</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0232</id><created>2011-07-31</created><authors><author><keyname>Proen&#xe7;a</keyname><forenames>Jos&#xe9;</forenames><affiliation>KUL</affiliation></author><author><keyname>Clarke</keyname><forenames>Dave</forenames><affiliation>KUL</affiliation></author><author><keyname>de Vink</keyname><forenames>Erik</forenames><affiliation>TUE</affiliation></author><author><keyname>Arbab</keyname><forenames>Farhad</forenames><affiliation>CWI</affiliation></author></authors><title>Decoupled execution of synchronous coordination models via behavioural
  automata</title><categories>cs.FL cs.LO cs.SE</categories><comments>In Proceedings FOCLASA 2011, arXiv:1107.5847</comments><proxy>EPTCS</proxy><acm-class>D.1.3; F.4.3</acm-class><journal-ref>EPTCS 58, 2011, pp. 65-79</journal-ref><doi>10.4204/EPTCS.58.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Synchronous coordination systems allow the exchange of data by logically
indivisible actions involving all coordinated entities. This paper introduces
behavioural automata, a logically synchronous coordination model based on the
Reo coordination language, which focuses on relevant aspects for the concurrent
evolution of these systems. We show how our automata model encodes the Reo and
Linda coordination models and how it introduces an explicit predicate that
captures the concurrent evolution, distinguishing local from global actions,
and lifting the need of most synchronous models to involve all entities at each
coordination step, paving the way to more scalable implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0239</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0239</id><created>2011-08-01</created><authors><author><keyname>Dai</keyname><forenames>Xiongping</forenames></author><author><keyname>Huang</keyname><forenames>Yu</forenames></author><author><keyname>Xiao</keyname><forenames>Mingqing</forenames></author></authors><title>Stability Criteria via Common Non-strict Lyapunov Matrix for
  Discrete-time Linear Switched Systems</title><categories>math.OC cs.SY math.DS</categories><comments>This is an improvement of the one submitted; 27 pages</comments><msc-class>93D20, 37N35</msc-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we consider the stability of discrete-time linear switched
systems with a common non-strict Lyapunov matrix.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0243</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0243</id><created>2011-08-01</created><authors><author><keyname>Bose</keyname><forenames>Mausumi</forenames></author><author><keyname>Dey</keyname><forenames>Aloke</forenames></author><author><keyname>Mukerjee</keyname><forenames>Rahul</forenames></author></authors><title>Key Predistribution Schemes for Distributed Sensor Networks</title><categories>cs.CR</categories><comments>Indian Statistical Institute Kolkata Tech., November 10, 2010
  (Revised version)</comments><report-no>ASD/2010/3</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Key predistribution schemes for distributed sensor networks have received
significant attention in the recent literature. In this paper we propose a new
construction method for these schemes based on combinations of duals of
standard block designs. Our method is a broad spectrum one which works for any
intersection threshold. By varying the initial designs, we can generate various
schemes and this makes the method quite flexible. We also obtain explicit
algebraic expressions for the metrics for local connectivity and resiliency.
These schemes are quite efficient with regard to connectivity and resiliency
and at the same time they allow a straightforward shared-key discovery.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0261</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0261</id><created>2011-08-01</created><authors><author><keyname>Cotta</keyname><forenames>Carlos</forenames></author><author><keyname>Mora</keyname><forenames>Antonio M.</forenames></author><author><keyname>Merelo-Molina</keyname><forenames>Cecilia</forenames></author><author><keyname>Merelo</keyname><forenames>Juan Juli&#xe1;n</forenames></author></authors><title>FIFA World Cup 2010: A Network Analysis of the Champion Team Play</title><categories>cs.SI physics.soc-ph</categories><comments>Paper 6 for the Complex Systems in Sports Workshop 2011 (CS-Sports
  2011)</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  We analyze the pass network among the players of the Spanish team (the world
champion in the FIFA World Cup 2010), with the objective of explaining the
results obtained from the behavior at the complex network level. The team is
considered a network with players as nodes and passes as (directed) edges, and
a temporal analysis of the resulting passes network is done, looking at the
number of passes, length of the chain of passes, and the centrality of players
in the turf. Results of the last three matches indicate that the clustering
coefficient of the pass network increases with time, and stays high, indicating
possession by Spanish players, which eventually leads to victory, even as the
density of the pass network decreases with time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0267</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0267</id><created>2011-08-01</created><authors><author><keyname>Ling</keyname><forenames>Amy Poh Ai</forenames></author><author><keyname>Masao</keyname><forenames>Mukaidono</forenames></author></authors><title>Grid Information Security Functional Requirement - Fulfilling
  Information Security of a Smart Grid System</title><categories>cs.NI</categories><comments>19 pages</comments><journal-ref>International Journal of Grid Computing &amp; Applications (IJGCA)
  Vol.2, No.2, June 2011, page 1-19</journal-ref><doi>10.5121/ijgca.2011.2201</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the background of smart information infrastructure and
the needs for smart grid information security. It introduces the conceptual
analysis to the methodology with the application of hermeneutic circle and
information security functional requirement identification. Information
security for the grid market cover matters includes automation and
communications industry that affects the operation of electric power systems
and the functioning of the utilities that manage them and its awareness of this
information infrastructure has become critical to the reliability of the power
system. Community benefits from of cost savings, flexibility and deployment
along with the establishment of wireless communications. However, concern
revolves around the security protections for easily accessible devices such as
the smart meter and the related communications hardware. On the other hand, the
changing points between traditional versus smart grid networking trend and the
information security importance on the communication field reflects the
criticality of grid information security functional requirement identification.
The goal of this paper is to identify the functional requirement and relate its
significance addresses to the consumer requirement of an information security
of a smart grid. Vulnerabilities may bring forth possibility for an attacker to
penetrate a network, make headway admission to control software, alter it to
load conditions that destabilize the grid in unpredictable ways. Focusing on
the grid information security functional requirement is stepping ahead in
developing consumer trust and satisfaction toward smart grid completeness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0286</identifier>
 <datestamp>2015-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0286</id><created>2011-08-01</created><updated>2011-09-05</updated><authors><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author><author><keyname>Harvey</keyname><forenames>David</forenames></author></authors><title>Fast computation of Bernoulli, Tangent and Secant numbers</title><categories>math.CO cs.DM cs.DS math.NT</categories><comments>16 pages. To appear in Computational and Analytical Mathematics
  (associated with the May 2011 workshop in honour of Jonathan Borwein's 60th
  birthday). For further information, see
  http://maths.anu.edu.au/~brent/pub/pub242.html</comments><msc-class>05A15 (Primary), 11B68, 11B83, 11-04, 11Y55, 11Y60, 65-04, 68R05
  (Secondary)</msc-class><acm-class>F.2.1</acm-class><journal-ref>Springer Proceedings in Mathematics and Statistics, Vol. 50, 2013,
  127-142</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the computation of Bernoulli, Tangent (zag), and Secant (zig or
Euler) numbers. In particular, we give asymptotically fast algorithms for
computing the first n such numbers in O(n^2.(log n)^(2+o(1))) bit-operations.
We also give very short in-place algorithms for computing the first n Tangent
or Secant numbers in O(n^2) integer operations. These algorithms are extremely
simple, and fast for moderate values of n. They are faster and use less space
than the algorithms of Atkinson (for Tangent and Secant numbers) and Akiyama
and Tanigawa (for Bernoulli numbers).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0294</identifier>
 <datestamp>2012-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0294</id><created>2011-08-01</created><updated>2012-03-11</updated><authors><author><keyname>Niu</keyname><forenames>Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Ce</forenames></author><author><keyname>R&#xe9;</keyname><forenames>Christopher</forenames></author><author><keyname>Shavlik</keyname><forenames>Jude</forenames></author></authors><title>Scaling Inference for Markov Logic with a Task-Decomposition Approach</title><categories>cs.AI cs.DB</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by applications in large-scale knowledge base construction, we
study the problem of scaling up a sophisticated statistical inference framework
called Markov Logic Networks (MLNs). Our approach, Felix, uses the idea of
Lagrangian relaxation from mathematical programming to decompose a program into
smaller tasks while preserving the joint-inference property of the original
MLN. The advantage is that we can use highly scalable specialized algorithms
for common tasks such as classification and coreference. We propose an
architecture to support Lagrangian relaxation in an RDBMS which we show enables
scalable joint inference for MLNs. We empirically validate that Felix is
significantly more scalable and efficient than prior approaches to MLN
inference by constructing a knowledge base from 1.8M documents as part of the
TAC challenge. We show that Felix scales and achieves state-of-the-art quality
numbers. In contrast, prior approaches do not scale even to a subset of the
corpus that is three orders of magnitude smaller.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0295</identifier>
 <datestamp>2012-04-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0295</id><created>2011-08-01</created><updated>2011-09-27</updated><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>Goldberg</keyname><forenames>Leslie Ann</forenames></author></authors><title>Adaptive Drift Analysis</title><categories>cs.DS</categories><comments>version 2 - fixed typos</comments><journal-ref>Algorithmica, 2012</journal-ref><doi>10.1007/s00453-011-9585-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that, for any c&gt;0, the (1+1) evolutionary algorithm using an
arbitrary mutation rate p_n = c/n finds the optimum of a linear objective
function over bit strings of length n in expected time Theta(n log n).
Previously, this was only known for c at most 1. Since previous work also shows
that universal drift functions cannot exist for c larger than a certain
constant, we instead define drift functions which depend crucially on the
relevant objective functions (and also on c itself). Using these
carefully-constructed drift functions, we prove that the expected optimisation
time is Theta(n log n). By giving an alternative proof of the multiplicative
drift theorem, we also show that our optimisation-time bound holds with high
probability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0307</identifier>
 <datestamp>2012-03-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0307</id><created>2011-08-01</created><updated>2012-03-15</updated><authors><author><keyname>Chigansky</keyname><forenames>Pavel</forenames></author><author><keyname>Klebaner</keyname><forenames>Fima C.</forenames></author></authors><title>The Euler-Maruyama approximation for the absorption time of the CEV
  diffusion</title><categories>math.PR cs.NA</categories><msc-class>60H10, 60H35, 60F17, 91G60</msc-class><journal-ref>DCDS-Ser B., Vol. 17 Issue 5 pp. 1455-1471 (2012)</journal-ref><doi>10.3934/dcdsb.2012.17.1455</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A standard convergence analysis of the simulation schemes for the hitting
times of diffusions typically requires non-degeneracy of their coefficients on
the boundary, which excludes the possibility of absorption. In this paper we
consider the CEV diffusion from the mathematical finance and show how a weakly
consistent approximation for the absorption time can be constructed, using the
Euler-Maruyama scheme.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0315</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0315</id><created>2011-08-01</created><authors><author><keyname>Ehlers</keyname><forenames>Ruediger</forenames></author></authors><title>Small witnesses, accepting lassos and winning strategies in
  omega-automata and games</title><categories>cs.LO cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Obtaining accepting lassos, witnesses and winning strategies in
omega-automata and games with omega-regular winning conditions is an integral
part of many formal methods commonly found in practice today. Despite the fact
that in most applications, the lassos, witnesses and strategies found should be
as small as possible, little is known about the hardness of obtaining small
such certificates. In this paper, we survey the known hardness results and
complete the complexity landscape for the cases not considered in the
literature so far. We pay particular attention to the approximation hardness of
the problems as approximate small solutions usually suffice in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0329</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0329</id><created>2011-08-01</created><authors><author><keyname>Haemmerl&#xe9;</keyname><forenames>R&#xe9;my</forenames></author></authors><title>Observational equivalences for linear logic CC languages</title><categories>cs.PL</categories><comments>17 pages</comments><acm-class>F.3.2; F.4.1</acm-class><journal-ref>Theory and Practice of Logic Programming, 11(4-5): 469-485, 2011</journal-ref><doi>10.1017/S1471068411000123</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linear logic Concurrent Constraint programming (LCC) is an extension of
concurrent constraint programming (CC) where the constraint system is based on
Girard's linear logic instead of the classical logic. In this paper we address
the problem of program equivalence for this programming framework. For this
purpose, we present a structural operational semantics for LCC based on a label
transition system and investigate different notions of observational
equivalences inspired by the state of art of process algebras. Then, we
demonstrate that the asynchronous \pi-calculus can be viewed as simple
syntactical restrictions of LCC. Finally we show LCC observational equivalences
can be transposed straightforwardly to classical Concurrent Constraint
languages and Constraint Handling Rules, and investigate the resulting
equivalences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0330</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0330</id><created>2011-08-01</created><authors><author><keyname>Haemmerl&#xe9;</keyname><forenames>R&#xe9;my</forenames></author></authors><title>(Co-)Inductive semantics for Constraint Handling Rules</title><categories>cs.LO cs.PL</categories><comments>17 pages</comments><acm-class>F.3.1; F.3.2; F.4.1</acm-class><journal-ref>Theory and Practice of Logic Programming, 11(4-5): 593-609, 2011</journal-ref><doi>10.1017/S1471068411000196</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we address the problem of defining a fixpoint semantics for
Constraint Handling Rules (CHR) that captures the behavior of both
simplification and propagation rules in a sound and complete way with respect
to their declarative semantics. Firstly, we show that the logical reading of
states with respect to a set of simplification rules can be characterized by a
least fixpoint over the transition system generated by the abstract operational
semantics of CHR. Similarly, we demonstrate that the logical reading of states
with respect to a set of propagation rules can be characterized by a greatest
fixpoint. Then, in order to take advantage of both types of rules without
losing fixpoint characterization, we present an operational semantics with
persistent. We finally establish that this semantics can be characterized by
two nested fixpoints, and we show the resulting language is an elegant
framework to program using coinductive reasoning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0333</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0333</id><created>2011-08-01</created><updated>2011-12-27</updated><authors><author><keyname>Panzieri</keyname><forenames>Stefano</forenames></author><author><keyname>Oliva</keyname><forenames>Gabriele</forenames></author><author><keyname>Setola</keyname><forenames>Roberto</forenames></author></authors><title>Fuzzy Consensus and Synchronization: Theory and Application to Critical
  Infrastructure Protection Problems</title><categories>cs.SY cs.MA math.OC</categories><comments>Sidra Automatica.it 2011 Conference, 7-9 September 2011, Pisa, Italy.
  in Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper the Distributed Consensus and Synchronization problems with
fuzzy-valued initial conditions are introduced, in order to obtain a shared
estimation of the state of a system based on partial and distributed
observations, in the case where such a state is affected by ambiguity and/or
vagueness. The Discrete-Time Fuzzy Systems (DFS) are introduced as an extension
of scalar fuzzy difference equations and some conditions for their stability
and representation are provided. The proposed framework is then applied in the
field of Critical Infrastructures; the consensus framework is used to represent
a scenario where human operators, each able to observe directly the state of a
given infrastructure (or of a given area considering vast and geographically
dispersed infrastructures), reach an agreement on the overall situation, whose
severity is expressed in a linguistic, fuzzy way; conversely synchronization is
used to provide a distributed interdependency estimation system, where an array
of interdependency models is synchronized via partial observation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0342</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0342</id><created>2011-08-01</created><authors><author><keyname>Doerr</keyname><forenames>Benjamin</forenames></author><author><keyname>K&#xf6;tzing</keyname><forenames>Timo</forenames></author><author><keyname>Lengler</keyname><forenames>Johannes</forenames></author><author><keyname>Winzen</keyname><forenames>Carola</forenames></author></authors><title>Black-Box Complexities of Combinatorial Problems</title><categories>cs.NE</categories><comments>26 pages. This is the full version of the one presented at the
  Genetic and Evolutionary Computation Conference (GECCO 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Black-box complexity is a complexity theoretic measure for how difficult a
problem is to be optimized by a general purpose optimization algorithm. It is
thus one of the few means trying to understand which problems are tractable for
genetic algorithms and other randomized search heuristics.
  Most previous work on black-box complexity is on artificial test functions.
In this paper, we move a step forward and give a detailed analysis for the two
combinatorial problems minimum spanning tree and single-source shortest paths.
Besides giving interesting bounds for their black-box complexities, our work
reveals that the choice of how to model the optimization problem is non-trivial
here. This in particular comes true where the search space does not consist of
bit strings and where a reasonable definition of unbiasedness has to be agreed
on.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0347</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0347</id><created>2011-08-01</created><authors><author><keyname>Ilic</keyname><forenames>Velimir M.</forenames></author></authors><title>Entropy Semiring Forward-backward Algorithm for HMM Entropy Computation</title><categories>cs.IT math.IT</categories><comments>submitted to Transactions on Advanced Research</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper presents Entropy Semiring Forwardbackward algorithm (ESRFB) and its
application for memory efficient computation of the subsequence constrained
entropy and state sequence entropy of a Hidden Markov Model (HMM) when an
observation sequence is given. ESRFB is based on forward-backward recursion
over the entropy semiring, having the lower memory requirement than the
algorithm developed by Mann and MacCallum, with the same time complexity.
Furthermore, when it is used with forward pass only, it is applicable for the
computation of HMM entropy for a given observation sequence, with the same time
and memory complexity as the previously developed algorithm by Hernando et al
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0353</identifier>
 <datestamp>2013-10-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0353</id><created>2011-08-01</created><updated>2013-10-12</updated><authors><author><keyname>Ilic</keyname><forenames>Velimir M.</forenames></author><author><keyname>Ciric</keyname><forenames>Miroslav D.</forenames></author><author><keyname>Stankovic</keyname><forenames>Miomir S.</forenames></author></authors><title>Cross-moments computation for stochastic context-free grammars</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider the problem of efficient computation of
cross-moments of a vector random variable represented by a stochastic
context-free grammar. Two types of cross-moments are discussed. The sample
space for the first one is the set of all derivations of the context-free
grammar, and the sample space for the second one is the set of all derivations
which generate a string belonging to the language of the grammar. In the past,
this problem was widely studied, but mainly for the cross-moments of scalar
variables and up to the second order. This paper presents new algorithms for
computing the cross-moments of an arbitrary order, and the previously developed
ones are derived as special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0355</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0355</id><created>2011-08-01</created><authors><author><keyname>O'Mullane</keyname><forenames>William</forenames></author><author><keyname>Luri</keyname><forenames>Xavier</forenames></author><author><keyname>Parsons</keyname><forenames>Paul</forenames></author><author><keyname>Lammers</keyname><forenames>Uwe</forenames></author><author><keyname>Hoar</keyname><forenames>John</forenames></author><author><keyname>Hernandez</keyname><forenames>Jose</forenames></author></authors><title>Using Java for distributed computing in the Gaia satellite data
  processing</title><categories>cs.CE astro-ph.IM cs.MS</categories><comments>Experimental Astronomy, August 2011</comments><doi>10.1007/s10686-011-9241-6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years Java has matured to a stable easy-to-use language with the
flexibility of an interpreter (for reflection etc.) but the performance and
type checking of a compiled language. When we started using Java for
astronomical applications around 1999 they were the first of their kind in
astronomy. Now a great deal of astronomy software is written in Java as are
many business applications.
  We discuss the current environment and trends concerning the language and
present an actual example of scientific use of Java for high-performance
distributed computing: ESA's mission Gaia. The Gaia scanning satellite will
perform a galactic census of about 1000 million objects in our galaxy. The Gaia
community has chosen to write its processing software in Java. We explore the
manifold reasons for choosing Java for this large science collaboration.
  Gaia processing is numerically complex but highly distributable, some parts
being embarrassingly parallel. We describe the Gaia processing architecture and
its realisation in Java. We delve into the astrometric solution which is the
most advanced and most complex part of the processing. The Gaia simulator is
also written in Java and is the most mature code in the system. This has been
successfully running since about 2005 on the supercomputer &quot;Marenostrum&quot; in
Barcelona. We relate experiences of using Java on a large shared machine.
  Finally we discuss Java, including some of its problems, for scientific
computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0363</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0363</id><created>2011-07-28</created><authors><author><keyname>Steeg</keyname><forenames>Fabian</forenames></author></authors><title>Typesafe Modeling in Text Mining</title><categories>cs.PL cs.IR</categories><comments>63 pages, in German</comments><acm-class>I.2.4; I.2.5; I.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Based on the concept of annotation-based agents, this report introduces tools
and a formal notation for defining and running text mining experiments using a
statically typed domain-specific language embedded in Scala. Using machine
learning for classification as an example, the framework is used to develop and
document text mining experiments, and to show how the concept of generic,
typesafe annotation corresponds to a general information model that goes beyond
text processing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0370</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0370</id><created>2011-08-01</created><authors><author><keyname>Markakis</keyname><forenames>Mihalis G.</forenames></author><author><keyname>Modiano</keyname><forenames>Eytan H.</forenames></author><author><keyname>Tsitsiklis</keyname><forenames>John N.</forenames></author></authors><title>Max-Weight Scheduling in Queueing Networks with Heavy-Tailed Traffic</title><categories>cs.NI math.PR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of packet scheduling in single-hop queueing networks,
and analyze the impact of heavy-tailed traffic on the performance of Max-Weight
scheduling. As a performance metric we use the delay stability of traffic
flows: a traffic flow is delay stable if its expected steady-state delay is
finite, and delay unstable otherwise. First, we show that a heavy-tailed
traffic flow is delay unstable under any scheduling policy. Then, we focus on
the celebrated Max-Weight scheduling policy, and show that a light-tailed flow
that conflicts with a heavy-tailed flow is also delay unstable. This is true
irrespective of the rate or the tail distribution of the light-tailed flow, or
other scheduling constraints in the network. Surprisingly, we show that a
light-tailed flow can be delay unstable, even when it does not conflict with
heavy-tailed traffic. Furthermore, delay stability in this case may depend on
the rate of the light-tailed flow. Finally, we turn our attention to the class
of Max-Weight-a scheduling policies; we show that if the a-parameters are
chosen suitably, then the sum of the a-moments of the steady-state queue
lengths is finite. We provide an explicit upper bound for the latter quantity,
from which we derive results related to the delay stability of traffic flows,
and the scaling of moments of steady-state queue lengths with traffic
intensity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0377</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0377</id><created>2011-08-01</created><authors><author><keyname>Le</keyname><forenames>Anh</forenames></author><author><keyname>Markopoulou</keyname><forenames>Athina</forenames></author></authors><title>On Detecting Pollution Attacks in Inter-Session Network Coding</title><categories>cs.NI cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dealing with pollution attacks in inter-session network coding is challenging
due to the fact that sources, in addition to intermediate nodes, can be
malicious. In this work, we precisely define corrupted packets in inter-session
pollution based on the commitment of the source packets. We then propose three
detection schemes: one hash-based and two MAC-based schemes: InterMacCPK and
SpaceMacPM. InterMacCPK is the first multi-source homomorphic MAC scheme that
supports multiple keys. Both MAC schemes can replace traditional MACs, e.g.,
HMAC, in networks that employ inter-session coding. All three schemes provide
in-network detection, are collusion-resistant, and have very low online
bandwidth and computation overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0388</identifier>
 <datestamp>2011-08-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0388</id><created>2011-08-01</created><authors><author><keyname>Li</keyname><forenames>Fei</forenames></author></authors><title>A Comprehensive Study of an Online Packet Scheduling Algorithm</title><categories>cs.DS</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the \emph{bounded-delay model} for Qualify-of-Service buffer
management. Time is discrete. There is a buffer. Unit-length jobs (also called
\emph{packets}) arrive at the buffer over time. Each packet has an integer
release time, an integer deadline, and a positive real value. A packet's
characteristics are not known to an online algorithm until the packet actually
arrives. In each time step, at most one packet can be sent out of the buffer.
The objective is to maximize the total value of the packets sent by their
respective deadlines in an online manner. An online algorithm's performance is
usually measured in terms of \emph{competitive ratio}, when this online
algorithm is compared with a clairvoyant algorithm achieving the best total
value. In this paper, we study a simple and intuitive online algorithm. We
analyze its performance in terms of competitive ratio for the general model and
a few important variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0391</identifier>
 <datestamp>2015-03-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0391</id><created>2011-08-01</created><updated>2012-09-14</updated><authors><author><keyname>Agrell</keyname><forenames>Erik</forenames></author></authors><title>The Channel Capacity Increases with Power</title><categories>cs.IT math.IT</categories><comments>This is the third and last version of &quot;The channel capacity increases
  with power.&quot; Future improvements, including results for multiuser channels,
  will be presented under the title &quot;On monotonic capacity-cost functions,&quot;
  http://arxiv.org/abs/1209.2820</comments><journal-ref>IEEE Trans. Commun., vol. 63, no. 3, pp. 738-748, Mar. 2015</journal-ref><doi>10.1109/TCOMM.2014.2381247</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is proved that for memoryless vector channels, maximizing the mutual
information over all source distributions with a certain average power or over
the larger set of source distributions with upperbounded average power yields
the same channel capacity in both cases. Hence, the channel capacity cannot
decrease with increasing average transmitted power, not even for channels with
severe nonlinear distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0404</identifier>
 <datestamp>2014-04-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0404</id><created>2011-08-01</created><updated>2014-04-25</updated><authors><author><keyname>Oliehoek</keyname><forenames>Frans A.</forenames></author><author><keyname>Whiteson</keyname><forenames>Shimon</forenames></author><author><keyname>Spaan</keyname><forenames>Matthijs T. J.</forenames></author></authors><title>Exploiting Agent and Type Independence in Collaborative Graphical
  Bayesian Games</title><categories>cs.AI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Efficient collaborative decision making is an important challenge for
multiagent systems. Finding optimal joint actions is especially challenging
when each agent has only imperfect information about the state of its
environment. Such problems can be modeled as collaborative Bayesian games in
which each agent receives private information in the form of its type. However,
representing and solving such games requires space and computation time
exponential in the number of agents. This article introduces collaborative
graphical Bayesian games (CGBGs), which facilitate more efficient collaborative
decision making by decomposing the global payoff function as the sum of local
payoff functions that depend on only a few agents. We propose a framework for
the efficient solution of CGBGs based on the insight that they posses two
different types of independence, which we call agent independence and type
independence. In particular, we present a factor graph representation that
captures both forms of independence and thus enables efficient solutions. In
addition, we show how this representation can provide leverage in sequential
tasks by using it to construct a novel method for decentralized partially
observable Markov decision processes. Experimental results in both random and
benchmark tasks demonstrate the improved scalability of our methods compared to
several existing alternatives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0408</identifier>
 <datestamp>2012-06-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0408</id><created>2011-07-30</created><updated>2012-05-31</updated><authors><author><keyname>Kardash</keyname><forenames>Sergey</forenames></author></authors><title>Algorithmic complexity of pair cleaning method for k-satisfiability
  problem. (draft version)</title><categories>cs.CC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The k-satisfiability problem is a well-known task in computational complexity
theory. In this paper approach for it's solving is introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0427</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0427</id><created>2011-08-01</created><authors><author><keyname>Soundararajan</keyname><forenames>Shvetha</forenames></author></authors><title>A Methodology for assessing Agile Software Development Approaches</title><categories>cs.SE</categories><comments>Research Proposal Document. 68 Pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Agile methods provide an organization or a team the flexibility to adopt a
selected subset of principles and practices based on their culture, their
values, and the types of systems that they develop. More specifically, every
organization or team implements a customized agile method, tailored to better
accommodate its needs. However, the extent to which a customized method
supports the organizational objectives, or rather the 'goodness' of that method
is questionable. Existing agile assessment approaches focus on a comparative
analysis, or are limited in scope and application. In this research, we propose
a structured, systematic and comprehensive approach to assess the 'goodness' of
agile methods. We examine an agile method based on (1) its adequacy, (2) the
capability of the organization to support the adopted principles and practices
specified by the method, and (3) the method's effectiveness. We propose the
Objectives, Principles and Practices (OPP) Framework to guide our assessment.
The Framework identifies (1) objectives of the agile philosophy, (2) principles
that support the objectives, (3) practices that are reflective of the
principles, (4) the linkages between the objectives, principles and practices,
and (5) indicators for each practice to assess the effectiveness of the
practice and the extent to which the organization supports its implementation.
In this document, we discuss our solution approach, preliminary results, and
future work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0442</identifier>
 <datestamp>2011-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0442</id><created>2011-08-01</created><authors><author><keyname>Wang</keyname><forenames>Feng</forenames></author><author><keyname>Wang</keyname><forenames>Haiyan</forenames></author><author><keyname>Xu</keyname><forenames>Kuai</forenames></author></authors><title>Diffusive Logistic Model Towards Predicting Information Diffusion in
  Online Social Networks</title><categories>cs.SI math.AP physics.soc-ph</categories><msc-class>35K20</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Online social networks have recently become an effective and innovative
channel for spreading information and influence among hundreds of millions of
end users. Many prior work have carried out empirical studies and proposed
diffusion models to understand the information diffusion process in online
social networks. However, most of these studies focus on the information
diffusion in temporal dimension, that is, how the information propagates over
time. Little attempt has been given on understanding information diffusion over
both temporal and spatial dimensions. In this paper, we propose a Partial
Differential Equation (PDE), specifically, a Diffusive Logistic (DL) equation
to model the temporal and spatial characteristics of information diffusion in
online social networks. To be more specific, we develop a PDE-based theoretical
framework to measure and predict the density of influenced users at a given
distance from the original information source after a time period. The density
of influenced users over time and distance provides valuable insight on the
actual information diffusion process. We present the temporal and spatial
patterns in a real dataset collected from Digg social news site, and validate
the proposed DL equation in terms of predicting the information diffusion
process. Our experiment results show that the DL model is indeed able to
characterize and predict the process of information propagation in online
social networks. For example, for the most popular news with 24,099 votes in
Digg, the average prediction accuracy of DL model over all distances during the
first 6 hours is 92.08%. To the best of our knowledge, this paper is the first
attempt to use PDE-based model to study the information diffusion process in
both temporal and spatial dimensions in online social networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0443</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0443</id><created>2011-08-01</created><authors><author><keyname>Wang</keyname><forenames>Meng</forenames></author><author><keyname>Xu</keyname><forenames>Weiyu</forenames></author><author><keyname>Mallada</keyname><forenames>Enrique</forenames></author><author><keyname>Tang</keyname><forenames>Ao</forenames></author></authors><title>Sparse Recovery with Graph Constraints: Fundamental Limits and
  Measurement Construction</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper addresses the problem of sparse recovery with graph constraints in
the sense that we can take additive measurements over nodes only if they induce
a connected subgraph. We provide explicit measurement constructions for several
special graphs. A general measurement construction algorithm is also proposed
and evaluated. For any given graph $G$ with $n$ nodes, we derive order optimal
upper bounds of the minimum number of measurements needed to recover any
$k$-sparse vector over $G$ ($M^G_{k,n}$). Our study suggests that $M^G_{k,n}$
may serve as a graph connectivity metric.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0454</identifier>
 <datestamp>2012-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0454</id><created>2011-08-01</created><authors><author><keyname>Kutyniok</keyname><forenames>Gitta</forenames></author><author><keyname>Lim</keyname><forenames>Wang-Q</forenames></author><author><keyname>Zhuang</keyname><forenames>Xiaosheng</forenames></author></authors><title>Digital Shearlet Transform</title><categories>math.NA cs.IT math.IT</categories><comments>arXiv admin note: substantial text overlap with arXiv:1106.2052</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past years, various representation systems which sparsely
approximate functions governed by anisotropic features such as edges in images
have been proposed. We exemplarily mention the systems of contourlets,
curvelets, and shearlets. Alongside the theoretical development of these
systems, algorithmic realizations of the associated transforms were provided.
However, one of the most common shortcomings of these frameworks is the lack of
providing a unified treatment of the continuum and digital world, i.e.,
allowing a digital theory to be a natural digitization of the continuum theory.
In fact, shearlet systems are the only systems so far which satisfy this
property, yet still deliver optimally sparse approximations of cartoon-like
images. In this chapter, we provide an introduction to digital shearlet theory
with a particular focus on a unified treatment of the continuum and digital
realm. In our survey we will present the implementations of two shearlet
transforms, one based on band-limited shearlets and the other based on
compactly supported shearlets. We will moreover discuss various quantitative
measures, which allow an objective comparison with other directional transforms
and an objective tuning of parameters. The codes for both presented transforms
as well as the framework for quantifying performance are provided in the Matlab
toolbox ShearLab.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0463</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0463</id><created>2011-08-01</created><authors><author><keyname>Hirschowitz</keyname><forenames>Tom</forenames><affiliation>CNRS, Chambery</affiliation></author><author><keyname>Pous</keyname><forenames>Damien</forenames><affiliation>CNRS, Grenoble</affiliation></author></authors><title>Innocent strategies as presheaves and interactive equivalences for CCS</title><categories>cs.LO</categories><comments>In Proceedings ICE 2011, arXiv:1108.0144</comments><proxy>EPTCS</proxy><acm-class>F.4; F.3.2</acm-class><journal-ref>EPTCS 59, 2011, pp. 2-24</journal-ref><doi>10.4204/EPTCS.59.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Seeking a general framework for reasoning about and comparing programming
languages, we derive a new view of Milner's CCS. We construct a category E of
plays, and a subcategory V of views. We argue that presheaves on V adequately
represent innocent strategies, in the sense of game semantics. We then equip
innocent strategies with a simple notion of interaction. This results in an
interpretation of CCS.
  Based on this, we propose a notion of interactive equivalence for innocent
strategies, which is close in spirit to Beffara's interpretation of testing
equivalences in concurrency theory. In this framework we prove that the
analogues of fair and must testing equivalences coincide, while they differ in
the standard setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0464</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0464</id><created>2011-08-01</created><authors><author><keyname>Ciancia</keyname><forenames>Vincenzo</forenames></author></authors><title>Interaction and observation, categorically</title><categories>cs.PL cs.LO</categories><comments>In Proceedings ICE 2011, arXiv:1108.0144</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 59, 2011, pp. 25-36</journal-ref><doi>10.4204/EPTCS.59.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper proposes to use dialgebras to specify the semantics of interactive
systems in a natural way. Dialgebras are a conservative extension of
coalgebras. In this categorical model, from the point of view that we provide,
the notions of observation and interaction are separate features. This is
useful, for example, in the specification of process equivalences, which are
obtained as kernels of the homomorphisms of dialgebras. As an example we
present the asynchronous semantics of the CCS.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0465</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0465</id><created>2011-08-01</created><authors><author><keyname>Dorman</keyname><forenames>Andrei</forenames><affiliation>Universit&#xe9; Paris 13</affiliation></author><author><keyname>Heindel</keyname><forenames>Tobias</forenames><affiliation>Universit&#xe9; Paris 13</affiliation></author></authors><title>Structured Operational Semantics for Graph Rewriting</title><categories>cs.LO cs.DC</categories><comments>In Proceedings ICE 2011, arXiv:1108.0144</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 59, 2011, pp. 37-51</journal-ref><doi>10.4204/EPTCS.59.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Process calculi and graph transformation systems provide models of reactive
systems with labelled transition semantics. While the semantics for process
calculi is compositional, this is not the case for graph transformation
systems, in general. Hence, the goal of this article is to obtain a
compositional semantics for graph transformation system in analogy to the
structural operational semantics (SOS) for Milner's Calculus of Communicating
Systems (CCS).
  The paper introduces an SOS style axiomatization of the standard labelled
transition semantics for graph transformation systems. The first result is its
equivalence with the so-called Borrowed Context technique. Unfortunately, the
axiomatization is not compositional in the expected manner as no rule captures
&quot;internal&quot; communication of sub-systems. The main result states that such a
rule is derivable if the given graph transformation system enjoys a certain
property, which we call &quot;complementarity of actions&quot;. Archetypal examples of
such systems are interaction nets. We also discuss problems that arise if
&quot;complementarity of actions&quot; is violated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0466</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0466</id><created>2011-08-01</created><authors><author><keyname>Bono</keyname><forenames>Viviana</forenames><affiliation>Torino, Italy</affiliation></author><author><keyname>Padovani</keyname><forenames>Luca</forenames><affiliation>Torino, Italy</affiliation></author></authors><title>Polymorphic Endpoint Types for Copyless Message Passing</title><categories>cs.PL cs.DC</categories><comments>In Proceedings ICE 2011, arXiv:1108.0144</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 59, 2011, pp. 52-67</journal-ref><doi>10.4204/EPTCS.59.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present PolySing#, a calculus that models process interaction based on
copyless message passing, in the style of Singularity OS. We equip the calculus
with a type system that accommodates polymorphic endpoint types, which are a
variant of polymorphic session types, and we show that well-typed processes are
free from faults, leaks, and communication errors. The type system is
essentially linear, although linearity alone may leave room for scenarios where
well-typed processes leak memory. We identify a condition on endpoint types
that prevents these leaks from occurring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0467</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0467</id><created>2011-08-01</created><authors><author><keyname>Garnier</keyname><forenames>Ilias</forenames><affiliation>CEA LIST</affiliation></author><author><keyname>Aussagu&#xe8;s</keyname><forenames>Christophe</forenames><affiliation>CEA LIST</affiliation></author><author><keyname>David</keyname><forenames>Vincent</forenames><affiliation>CEA LIST</affiliation></author><author><keyname>Vidal-Naquet</keyname><forenames>Guy</forenames><affiliation>SUPELEC Systems Sciences</affiliation></author></authors><title>On the reaction time of some synchronous systems</title><categories>cs.SE</categories><comments>In Proceedings ICE 2011, arXiv:1108.0144</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 59, 2011, pp. 69-83</journal-ref><doi>10.4204/EPTCS.59.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an investigation of the notion of reaction time in some
synchronous systems. A state-based description of such systems is given, and
the reaction time of such systems under some classic composition primitives is
studied. Reaction time is shown to be non-compositional in general. Possible
solutions are proposed, and applications to verification are discussed. This
framework is illustrated by some examples issued from studies on real-time
embedded systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0468</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0468</id><created>2011-08-01</created><authors><author><keyname>Jongmans</keyname><forenames>Sung-Shik T. Q.</forenames></author><author><keyname>Arbab</keyname><forenames>Farhad</forenames></author></authors><title>Correlating Formal Semantic Models of Reo Connectors: Connector Coloring
  and Constraint Automata</title><categories>cs.PL</categories><comments>In Proceedings ICE 2011, arXiv:1108.0144</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 59, 2011, pp. 84-103</journal-ref><doi>10.4204/EPTCS.59.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Over the past decades, coordination languages have emerged for the
specification and implementation of interaction protocols for communicating
software components. This class of languages includes Reo, a platform for
compositional construction of connectors. In recent years, various formalisms
for describing the behavior of Reo connectors have come to existence, each of
them serving its own purpose. Naturally, questions about how these models
relate to each other arise. From a theoretical point of view, answers to these
questions provide us with better insight into the fundamentals of Reo, while
from a more practical perspective, these answers broaden the applicability of
Reo's development tools. In this paper, we address one of these questions: we
investigate the equivalence between coloring models and constraint automata,
the two most dominant and practically relevant semantic models of Reo. More
specifically, we define operators that transform one model to the other (and
vice versa), prove their correctness, and show that they distribute over
composition. To ensure that the transformation operators map one-to-one
(instead of many-to-one), we extend coloring models with data constraints.
Though primarily a theoretical contribution, we sketch some potential
applications of our results: the broadening of the applicability of existing
tools for connector verification and animation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0469</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0469</id><created>2011-08-01</created><authors><author><keyname>Davidson</keyname><forenames>Timothy A. S.</forenames><affiliation>University of Warwick, UK</affiliation></author><author><keyname>Gay</keyname><forenames>Simon J.</forenames><affiliation>University of Glasgow, UK</affiliation></author><author><keyname>Nagarajan</keyname><forenames>Rajagopal</forenames><affiliation>University of Warwick, UK</affiliation></author></authors><title>Formal Analysis of Quantum Systems using Process Calculus</title><categories>cs.LO quant-ph</categories><comments>In Proceedings ICE 2011, arXiv:1108.0144</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 59, 2011, pp. 104-110</journal-ref><doi>10.4204/EPTCS.59.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Quantum communication and cryptographic protocols are well on the way to
becoming an important practical technology. Although a large amount of
successful research has been done on proving their correctness, most of this
work does not make use of familiar techniques from formal methods, such as
formal logics for specification, formal modelling languages, separation of
levels of abstraction, and compositional analysis. We argue that these
techniques will be necessary for the analysis of large-scale systems that
combine quantum and classical components, and summarize the results of initial
investigation using behavioural equivalence in process calculus. This paper is
a summary of Simon Gay's invited talk at ICE'11.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0470</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0470</id><created>2011-08-01</created><authors><author><keyname>Bocchi</keyname><forenames>Laura</forenames><affiliation>Department of Computer Science, University of Leicester</affiliation></author><author><keyname>Lange</keyname><forenames>Julien</forenames><affiliation>Department of Computer Science, University of Leicester</affiliation></author><author><keyname>Tuosto</keyname><forenames>Emilio</forenames><affiliation>Department of Computer Science, University of Leicester</affiliation></author></authors><title>Amending Contracts for Choreographies</title><categories>cs.DC cs.PL</categories><comments>In Proceedings ICE 2011, arXiv:1108.0144</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 59, 2011, pp. 111-129</journal-ref><doi>10.4204/EPTCS.59.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed interactions can be suitably designed in terms of choreographies.
Such abstractions can be thought of as global descriptions of the coordination
of several distributed parties. Global assertions define contracts for
choreographies by annotating multiparty session types with logical formulae to
validate the content of the exchanged messages. The introduction of such
constraints is a critical design issue as it may be hard to specify contracts
that allow each party to be able to progress without violating the contract. In
this paper, we propose three methods that automatically correct inconsistent
global assertions. The methods are compared by discussing their applicability
and the relationships between the amended global assertions and the original
(inconsistent) ones.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0471</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0471</id><created>2011-08-01</created><authors><author><keyname>Bartoletti</keyname><forenames>Massimo</forenames><affiliation>Dipartimento di Matematica e Informatica, Universita' degli Studi di Cagliari, Italy</affiliation></author><author><keyname>Tuosto</keyname><forenames>Emilio</forenames><affiliation>Department of Computer Science, University of Leicester, UK</affiliation></author><author><keyname>Zunino</keyname><forenames>Roberto</forenames><affiliation>DISI-Universita' degli Studi di Trento and COSBI, Italy</affiliation></author></authors><title>Contracts in distributed systems</title><categories>cs.PL cs.DC cs.LO cs.SE</categories><comments>In Proceedings ICE 2011, arXiv:1108.0144</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 59, 2011, pp. 130-147</journal-ref><doi>10.4204/EPTCS.59.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a parametric calculus for contract-based computing in distributed
systems. By abstracting from the actual contract language, our calculus
generalises both the contracts-as-processes and contracts-as-formulae
paradigms. The calculus features primitives for advertising contracts, for
reaching agreements, and for querying the fulfilment of contracts. Coordination
among principals happens via multi-party sessions, which are created once
agreements are reached. We present two instances of our calculus, by modelling
contracts as (i) processes in a variant of CCS, and (ii) as formulae in a
logic. With the help of a few examples, we discuss the primitives of our
calculus, as well as some possible variants.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0476</identifier>
 <datestamp>2015-12-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0476</id><created>2011-08-01</created><updated>2015-12-21</updated><authors><author><keyname>Perugini</keyname><forenames>Saverio</forenames></author></authors><title>Specifying and Staging Mixed-Initiative Dialogs with Program Generation
  and Transformation</title><categories>cs.PL cs.AI cs.HC</categories><comments>combined/reorganized some figures/tables from version 4, and
  corrected typos; 22 pages, 5 tables, 5 figures, and 5 listings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Specifying and implementing flexible human-computer dialogs, such as those
used in kiosks and smart phone apps, is challenging because of the numerous and
varied directions in which each user might steer a dialog. The objective of
this research is to improve dialog specification and implementation. To do so
we enriched a notation based on concepts from programming languages, especially
partial evaluation, for specifying a variety of unsolicited reporting,
mixed-initiative dialogs in a concise representation that serves as a design
for dialog implementation. We also built a dialog mining system that extracts a
specification in this notation from requirements. To demonstrate that such a
specification provides a design for dialog implementation, we built a system
that automatically generates an implementation of the dialog, called a stager,
from it. These two components constitute a dialog modeling toolkit that
automates dialog specification and implementation. These results provide a
proof of concept and demonstrate the study of dialog specification and
implementation from a programming languages perspective. The ubiquity of
dialogs in domains such as travel, education, and health care combined with the
demand for smart phone apps provide a landscape for further investigation of
these results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0477</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0477</id><created>2011-08-01</created><updated>2013-03-06</updated><authors><author><keyname>Maleki</keyname><forenames>Arian</forenames></author><author><keyname>Anitori</keyname><forenames>Laura</forenames></author><author><keyname>Yang</keyname><forenames>Zai</forenames></author><author><keyname>Baraniuk</keyname><forenames>Richard</forenames></author></authors><title>Asymptotic Analysis of Complex LASSO via Complex Approximate Message
  Passing (CAMP)</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recovering a sparse signal from an undersampled set of random linear
measurements is the main problem of interest in compressed sensing. In this
paper, we consider the case where both the signal and the measurements are
complex. We study the popular reconstruction method of $\ell_1$-regularized
least squares or LASSO. While several studies have shown that the LASSO
algorithm offers desirable solutions under certain conditions, the precise
asymptotic performance of this algorithm in the complex setting is not yet
known. In this paper, we extend the approximate message passing (AMP) algorithm
to the complex signals and measurements and obtain the complex approximate
message passing algorithm (CAMP). We then generalize the state evolution
framework recently introduced for the analysis of AMP, to the complex setting.
Using the state evolution, we derive accurate formulas for the phase transition
and noise sensitivity of both LASSO and CAMP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0486</identifier>
 <datestamp>2013-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0486</id><created>2011-08-02</created><authors><author><keyname>Nandapalan</keyname><forenames>Nimalan</forenames></author><author><keyname>Brent</keyname><forenames>Richard P.</forenames></author><author><keyname>Murray</keyname><forenames>Lawrence M.</forenames></author><author><keyname>Rendell</keyname><forenames>Alistair</forenames></author></authors><title>High-Performance Pseudo-Random Number Generation on Graphics Processing
  Units</title><categories>cs.DC math.NT stat.CO</categories><comments>10 pages, submitted to PPAM 2011 (Torun, Poland, 11-14 Sept. 2011).
  For further information, see http://maths.anu.edu.au/~brent/pub/pub241.html</comments><msc-class>11K45 (Primary) 65C10, 65Y05, 65Y10 (Secondary)</msc-class><acm-class>D.1.3; G.3; G.4; I.6.8</acm-class><journal-ref>Lecture Notes in Computer Science, Vol. 7203 (2012), 609-618</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work considers the deployment of pseudo-random number generators (PRNGs)
on graphics processing units (GPUs), developing an approach based on the
xorgens generator to rapidly produce pseudo-random numbers of high statistical
quality. The chosen algorithm has configurable state size and period, making it
ideal for tuning to the GPU architecture. We present a comparison of both speed
and statistical quality with other common parallel, GPU-based PRNGs,
demonstrating favourable performance of the xorgens-based approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0488</identifier>
 <datestamp>2013-04-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0488</id><created>2011-08-02</created><updated>2013-04-10</updated><authors><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author></authors><title>A Kalman Decomposition for Possibly Controllable Uncertain Linear
  Systems</title><categories>cs.SY math.OC</categories><comments>To appear in Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers the structure of uncertain linear systems building on
concepts of robust unobservability and possible controllability which were
introduced in previous papers. The paper presents a new geometric
characterization of the possibly controllable states. When combined with
previous geometric results on robust unobservability, the results of this paper
lead to a general Kalman type decomposition for uncertain linear systems which
can be applied to the problem of obtaining reduced order uncertain system
models.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0492</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0492</id><created>2011-08-02</created><authors><author><keyname>Aschner</keyname><forenames>Rom</forenames></author><author><keyname>Katz</keyname><forenames>Matthew J.</forenames></author><author><keyname>Morgenstern</keyname><forenames>Gila</forenames></author></authors><title>Symmetric Connectivity with Directional Antennas</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let P be a set of points in the plane, representing directional antennas of
angle a and range r. The coverage area of the antenna at point p is a circular
sector of angle a and radius r, whose orientation is adjustable. For a given
orientation assignment, the induced symmetric communication graph (SCG) of P is
the undirected graph that contains the edge (u,v) iff v lies in u's sector and
vice versa. In this paper we ask what is the smallest angle a for which there
exists an integer n=n(a), such that for any set P of n antennas of angle a and
unbounded range, one can orient the antennas so that the induced SCG is
connected, and the union of the corresponding wedges is the entire plane. We
show that the answer to this problem is a=\pi/2, for which n=4. Moreover, we
prove that if Q_1 and Q_2 are quadruplets of antennas of angle \pi/2 and
unbounded range, separated by a line, to which one applies the above
construction, independently, then the induced SCG of Q_1 \cup Q_2 is connected.
This latter result enables us to apply the construction locally, and to solve
the following two further problems.
  In the first problem, we are given a connected unit disk graph (UDG),
corresponding to a set P of omni-directional antennas of range 1, and the goal
is to replace these antennas by directional antennas of angle \pi/2 and range
r=O(1) and to orient them, such that the induced SCG is connected, and,
moreover, is an O(1)-spanner of the UDG, w.r.t. hop distance. In our solution r
= 14\sqrt{2} and the spanning ratio is 8. In the second problem, we are given a
set P of directional antennas of angle \pi/2 and adjustable range. The goal is
to assign to each antenna p, an orientation and a range r_p, such that the
resulting SCG is connected, and \sum_{p \in P} r_p^\beta is minimized, where
\beta \ge 1 is a constant. We present an O(1)-approximation algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0496</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0496</id><created>2011-08-02</created><authors><author><keyname>Aman</keyname><forenames>Bogdan</forenames></author></authors><title>Spatial Dynamic Structures and Mobility in Computation</title><categories>cs.DC math.DS</categories><comments>20 pages, 1 figure, PhD Thesis (Extended Abstract)</comments><report-no>FML-11-01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Membrane computing is a well-established and successful research field which
belongs to the more general area of molecular computing. Membrane computing
aims at defining parallel and non-deterministic computing models, called
membrane systems or P Systems, which abstract from the functioning and
structure of the cell. A membrane system consists of a spatial structure, a
hierarchy of membranes which do not intersect, with a distinguishable membrane
called skin surrounding all of them. A membrane without any other membranes
inside is elementary, while a non-elementary membrane is a composite membrane.
The membranes define demarcations between regions; for each membrane there is a
unique associated region. Since we have a one-to-one correspondence, we
sometimes use membrane instead of region, and vice-versa. The space outside the
skin membrane is called the environment.
  In this thesis we define and investigate variants of systems of mobile
membranes as models for molecular computing and as modelling paradigms for
biological systems. On one hand, we follow the standard approach of research in
membrane computing: defining a notion of computation for systems of mobile
membranes, and investigating the computational power of such computing devices.
Specifically, we address issues concerning the power of operations for
modifying the membrane structure of a system of mobile membranes by mobility:
endocytosis (moving a membrane inside a neighbouring membrane) and endocytosis
(moving a membrane outside the membrane where it is placed). On the other hand,
we relate systems of mobile membranes to process algebra (mobile ambients,
timed mobile ambients, pi-calculus, brane calculus) by providing some encodings
and adding some concepts inspired from process algebra in the framework of
mobile membrane computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0502</identifier>
 <datestamp>2015-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0502</id><created>2011-08-02</created><authors><author><keyname>Raheja</keyname><forenames>Jagdish Lal</forenames></author><author><keyname>Das</keyname><forenames>Karen</forenames></author><author><keyname>Chaudhary</keyname><forenames>Ankit</forenames></author></authors><title>An Efficient Real Time Method of Fingertip Detection</title><categories>cs.CV cs.AI cs.MM</categories><comments>This paper was published in the 7th International Conference on
  Trends in Industrial Measurements and Automation (TIMA 2011), CSIR Complex,
  Chennai, India, 6-8 Jan, 2011, pp. 447-450</comments><journal-ref>7th International Conference on Trends in Industrial Measurements
  and Automation (TIMA 2011), CSIR Complex, Chennai, India, 6-8 Jan, 2011, pp.
  447-450</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fingertips detection has been used in many applications, and it is very
popular and commonly used in the area of Human Computer Interaction these days.
This paper presents a novel time efficient method that will lead to fingertip
detection after cropping the irrelevant parts of input image. Binary silhouette
of the input image is generated using HSV color space based skin filter and
hand cropping done based on histogram of the hand image. The cropped image will
be used to figure out the fingertips.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0535</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0535</id><created>2011-08-02</created><authors><author><keyname>Aref</keyname><forenames>Vahid</forenames></author><author><keyname>Urbanke</keyname><forenames>R&#xfc;diger L.</forenames></author></authors><title>Universal Rateless Codes From Coupled LT Codes</title><categories>cs.IT math.IT</categories><comments>5 pages, to be presented at the 2011 IEEE Information Theory Workshop
  (ITW 2011), Paraty, Brazil, October, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It was recently shown that spatial coupling of individual low-density
parity-check codes improves the belief-propagation threshold of the coupled
ensemble essentially to the maximum a posteriori threshold of the underlying
ensemble. We study the performance of spatially coupled low-density
generator-matrix ensembles when used for transmission over binary-input
memoryless output-symmetric channels. We show by means of density evolution
that the threshold saturation phenomenon also takes place in this setting. Our
motivation for studying low-density generator-matrix codes is that they can
easily be converted into rateless codes. Although there are already several
classes of excellent rateless codes known to date, rateless codes constructed
via spatial coupling might offer some additional advantages. In particular, by
the very nature of the threshold phenomenon one expects that codes constructed
on this principle can be made to be universal, i.e., a single construction can
uniformly approach capacity over the class of binary-input memoryless
output-symmetric channels. We discuss some necessary conditions on the degree
distribution which universal rateless codes based on the threshold phenomenon
have to fulfill. We then show by means of density evolution and some simulation
results that indeed codes constructed in this way perform very well over a
whole range of channel types and channel conditions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0554</identifier>
 <datestamp>2012-04-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0554</id><created>2011-08-02</created><updated>2012-03-30</updated><authors><author><keyname>Hon</keyname><forenames>Wing-Kai</forenames></author><author><keyname>Shah</keyname><forenames>Rahul</forenames></author><author><keyname>Thankachan</keyname><forenames>Sharma V.</forenames></author></authors><title>Towards an Optimal Space-and-Query-Time Index for Top-k Document
  Retrieval</title><categories>cs.DS</categories><comments>12 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Let $\D = $$ \{d_1,d_2,...d_D\}$ be a given set of $D$ string documents of
total length $n$, our task is to index $\D$, such that the $k$ most relevant
documents for an online query pattern $P$ of length $p$ can be retrieved
efficiently. We propose an index of size $|CSA|+n\log D(2+o(1))$ bits and
$O(t_{s}(p)+k\log\log n+poly\log\log n)$ query time for the basic relevance
metric \emph{term-frequency}, where $|CSA|$ is the size (in bits) of a
compressed full text index of $\D$, with $O(t_s(p))$ time for searching a
pattern of length $p$ . We further reduce the space to $|CSA|+n\log D(1+o(1))$
bits, however the query time will be $O(t_s(p)+k(\log \sigma \log\log
n)^{1+\epsilon}+poly\log\log n)$, where $\sigma$ is the alphabet size and
$\epsilon &gt;0$ is any constant.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0556</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0556</id><created>2011-08-02</created><updated>2012-10-11</updated><authors><author><keyname>M&#xfc;ller</keyname><forenames>Fritz</forenames><affiliation>Saarland University</affiliation></author></authors><title>On Berry's conjectures about the stable order in PCF</title><categories>cs.LO</categories><comments>submitted to LMCS, 39 pages, 23 pstricks/pst-tree figures, main
  changes for this version: 4.1: proof of game term theorem corrected, 7.: the
  improved chain conjecture is made precise, more references added</comments><proxy>LMCS</proxy><acm-class>F.3.2; F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 8, Issue 4 (October
  12, 2012) lmcs:925</journal-ref><doi>10.2168/LMCS-8(4:7)2012</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PCF is a sequential simply typed lambda calculus language. There is a unique
order-extensional fully abstract cpo model of PCF, built up from equivalence
classes of terms. In 1979, G\'erard Berry defined the stable order in this
model and proved that the extensional and the stable order together form a
bicpo. He made the following two conjectures: 1) &quot;Extensional and stable order
form not only a bicpo, but a bidomain.&quot; We refute this conjecture by showing
that the stable order is not bounded complete, already for finitary PCF of
second-order types. 2) &quot;The stable order of the model has the syntactic order
as its image: If a is less than b in the stable order of the model, for finite
a and b, then there are normal form terms A and B with the semantics a, resp.
b, such that A is less than B in the syntactic order.&quot; We give counter-examples
to this conjecture, again in finitary PCF of second-order types, and also
refute an improved conjecture: There seems to be no simple syntactic
characterization of the stable order. But we show that Berry's conjecture is
true for unary PCF. For the preliminaries, we explain the basic fully abstract
semantics of PCF in the general setting of (not-necessarily complete) partial
order models (f-models.) And we restrict the syntax to &quot;game terms&quot;, with a
graphical representation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0574</identifier>
 <datestamp>2011-09-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0574</id><created>2011-08-02</created><updated>2011-09-03</updated><authors><author><keyname>Chen</keyname><forenames>Xihui</forenames></author><author><keyname>Lenzini</keyname><forenames>Gabriele</forenames></author><author><keyname>Mauw</keyname><forenames>Sjouke</forenames></author><author><keyname>Pang</keyname><forenames>Jun</forenames></author></authors><title>A Group Signature Based Electronic Toll Pricing System</title><categories>cs.CR cs.CY</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the prevalence and development of GNSS technologies, location-based
vehicle services (LBVS) have experienced a rapid growth in recent years.
However, location is a sensitive and private piece of information, so the
design and development of such services just take the clients' privacy concerns
into account. In this paper, we propose a new electronic toll pricing system
based on group signatures, which provides a strong guarantee for the clients'
anonymity within groups. Our system achieves a balance between privacy and the
communication overhead imposed upon the users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0599</identifier>
 <datestamp>2011-08-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0599</id><created>2011-08-02</created><authors><author><keyname>Picarzo</keyname><forenames>Tomas Ramirez</forenames></author><author><keyname>de Vega</keyname><forenames>Francisco Fernandez</forenames></author><author><keyname>Gonzalez</keyname><forenames>Daniel Lombrana</forenames></author></authors><title>Proposal for improvement in the transfer and execution of multiple
  instances of a virtual image</title><categories>cs.DC</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Virtualization technology allows currently any application run any
application complex and expensive computational (the scientific applications
are a good example) on heterogeneous distributed systems, which make regular
use of Grid and Cloud technologies, enabling significant savings in computing
time. This model is particularly interesting for the mass execution of
scientific simulations and calculations, allowing parallel execution of
applications using the same execution environment (unchanged) used by the
scientist as usual. However, the use and distribution of large virtual images
can be a problem (up to tens of GBytes), which is aggravated when attempting a
mass mailing on a large number of distributed computers. This work has as main
objective to present an analysis of how implementation and a proposal for the
improvement (reduction in size) of the virtual images pretending reduce
distribution time in distributed systems. This analysis is done very specific
requirements that need an operating system (guest OS) on some aspects of its
execution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0617</identifier>
 <datestamp>2013-01-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0617</id><created>2011-08-02</created><updated>2012-09-01</updated><authors><author><keyname>Gharibian</keyname><forenames>Sevag</forenames></author><author><keyname>Sikora</keyname><forenames>Jamie</forenames></author><author><keyname>Upadhyay</keyname><forenames>Sarvagya</forenames></author></authors><title>QMA variants with polynomially many provers</title><categories>quant-ph cs.CC</categories><comments>Minor changes. 22 pages, no figures</comments><journal-ref>Quantum Information &amp; Computation 13(1 &amp; 2):0135-0157, 2013</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study three variants of multi-prover quantum Merlin-Arthur proof systems.
We first show that the class of problems that can be efficiently verified using
polynomially many quantum proofs, each of logarithmic-size, is exactly MQA
(also known as QCMA), the class of problems which can be efficiently verified
via a classical proof and a quantum verifier. We then study the class
BellQMA(poly), characterized by a verifier who first applies unentangled,
nonadaptive measurements to each of the polynomially many proofs, followed by
an arbitrary but efficient quantum verification circuit on the resulting
measurement outcomes. We show that if the number of outcomes per nonadaptive
measurement is a polynomially-bounded function, then the expressive power of
the proof system is exactly QMA. Finally, we study a class equivalent to
QMA(m), denoted SepQMA(m), where the verifier's measurement operator
corresponding to outcome &quot;accept&quot; is a fully separable operator across the m
quantum proofs. Using cone programming duality, we give an alternate proof of a
result of Harrow and Montanaro [FOCS, pp. 633--642 (2010)] that shows a perfect
parallel repetition theorem for SepQMA(m) for any m.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0631</identifier>
 <datestamp>2014-09-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0631</id><created>2011-08-02</created><updated>2014-09-15</updated><authors><author><keyname>Romary</keyname><forenames>Laurent</forenames><affiliation>IDSL, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Zeldes</keyname><forenames>Amir</forenames><affiliation>IDSL, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Zipser</keyname><forenames>Florian</forenames><affiliation>IDSL, INRIA Saclay - Ile de France</affiliation></author></authors><title>Serialising the ISO SynAF Syntactic Object Model</title><categories>cs.CL</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces, an XML format developed to serialise the object model
defined by the ISO Syntactic Annotation Framework SynAF. Based on widespread
best practices we adapt a popular XML format for syntactic annotation,
TigerXML, with additional features to support a variety of syntactic phenomena
including constituent and dependency structures, binding, and different node
types such as compounds or empty elements. We also define interfaces to other
formats and standards including the Morpho-syntactic Annotation Framework MAF
and the ISOCat Data Category Registry. Finally a case study of the German
Treebank TueBa-D/Z is presented, showcasing the handling of constituent
structures, topological fields and coreference annotation in tandem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0679</identifier>
 <datestamp>2013-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0679</id><created>2011-08-02</created><updated>2012-10-07</updated><authors><author><keyname>Fujiwara</keyname><forenames>Yuichiro</forenames></author><author><keyname>Tonchev</keyname><forenames>Vladimir D.</forenames></author></authors><title>A characterization of entanglement-assisted quantum low-density
  parity-check codes</title><categories>cs.IT math.CO math.IT quant-ph</categories><comments>7 pages, no figures, final accepted version for publication in the
  IEEE Transactions on Information Theory</comments><msc-class>094B</msc-class><journal-ref>IEEE Transactions on Information Theory 59 (2013) 3347-3353</journal-ref><doi>10.1109/TIT.2013.2247461</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  As in classical coding theory, quantum analogues of low-density parity-check
(LDPC) codes have offered good error correction performance and low decoding
complexity by employing the Calderbank-Shor-Steane (CSS) construction. However,
special requirements in the quantum setting severely limit the structures such
quantum codes can have. While the entanglement-assisted stabilizer formalism
overcomes this limitation by exploiting maximally entangled states (ebits),
excessive reliance on ebits is a substantial obstacle to implementation. This
paper gives necessary and sufficient conditions for the existence of quantum
LDPC codes which are obtainable from pairs of identical LDPC codes and consume
only one ebit, and studies the spectrum of attainable code parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0716</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0716</id><created>2011-08-02</created><authors><author><keyname>Astudillo</keyname><forenames>Carlos A.</forenames></author><author><keyname>Gustin</keyname><forenames>Adriana M.</forenames></author><author><keyname>Calder&#xf3;n</keyname><forenames>Oscar J.</forenames></author></authors><title>Policy Creation Model for Policy-Based Management in Telecommunications
  Networks</title><categories>cs.NI</categories><comments>6 Pages, 2 Figures, 1 Table; In Proceedings of 2010 IEEE
  Latin-American Conference on Communications (LATINCOM). CD-ONLY</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Policy-based management (PBM) is being used as technological solution on the
managing and controlling complex networks and systems. One of the most
important issues involved in the life-cycle of PBM is the policies creation
because the future decisions made by the management system depend on this, and
therefore, the network behavior. In this paper we present a novel model for
creating management policies in telecommunications networks. We propose a model
which includes a Policy Creation Process, Actors, Policy Abstraction Levels and
a Procedure for Creating Policies. An implementation of the proposed model over
the Technology Division at University of Cauca is included.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0729</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0729</id><created>2011-08-02</created><authors><author><keyname>de Almeida</keyname><forenames>Eduardo Cunha</forenames></author></authors><title>Estudo de Viabilidade de uma Plataforma de Baixo Custo para Data
  Warehouse</title><categories>cs.DB</categories><comments>Masters dissertation, 90 pages, 2004. (Advisor: Marcos Sfair
  Suny\'e); Masters dissertation, Universidade Federal do Paran\'a, 2004</comments><acm-class>H.2.7</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Often corporations need tools to improve their decision making in a
competitive market. In general, these tools are based on data warehouse
platforms to mange and analyze large amounts of data. However, several of these
corporations do not have enough resources to buy such platforms because of the
high cost. This work is dedicated to a feasibility study of a low cost platform
to data warehouse. We consider as a low cost platform the use of open source
software like the PostgreSQL database system and the GNU/Linux operational
system. We verify the feasibility of this platform by executing two benchmarks
that simulate a data warehouse workload. The workload reproduces a multi-user
environment with the execution of complex queries, which executes:
aggregations, nested sub queries, multi joins, in-line views and more.
Considering the results we were able to highlight some problems on the
PostgreSQL database system, and discuss improvements in the context of data
warehouse.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0740</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0740</id><created>2011-08-03</created><authors><author><keyname>Munaga</keyname><forenames>Hazarath</forenames></author><author><keyname>Murthy</keyname><forenames>J. V. R.</forenames></author><author><keyname>Venkateswarlu</keyname><forenames>N. B.</forenames></author></authors><title>A Novel Trajectory Clustering technique for selecting cluster heads in
  Wireless Sensor Networks</title><categories>cs.NI</categories><journal-ref>International Journal of Recent Trends in Engineering, Issue. 1,
  Vol. 1, May 2009</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) suffers from the hot spot problem where the
sensor nodes closest to the base station are need to relay more packet than the
nodes farther away from the base station. Thus, lifetime of sensory network
depends on these closest nodes. Clustering methods are used to extend the
lifetime of a wireless sensor network. However, current clustering algorithms
usually utilize two techniques; selecting cluster heads with more residual
energy, and rotating cluster heads periodically to distribute the energy
consumption among nodes in each cluster and lengthen the network lifetime. Most
of the algorithms use random selection for selecting the cluster heads. Here,
we propose a novel trajectory clustering technique for selecting the cluster
heads in WSNs. Our algorithm selects the cluster heads based on traffic and
rotates periodically. It provides the first trajectory based clustering
technique for selecting the cluster heads and to extenuate the hot spot problem
by prolonging the network lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0741</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0741</id><created>2011-08-03</created><authors><author><keyname>Munaga</keyname><forenames>Hazarath</forenames><affiliation>Dr MHM Krishna Prasad</affiliation></author><author><keyname>Murthy</keyname><forenames>J. V. R.</forenames></author><author><keyname>Venkateswarlu</keyname><forenames>N. B.</forenames></author></authors><title>Enhanced User Authentication through Trajectory Clustering</title><categories>cs.CR</categories><comments>International Journal of Recent Trends in Engineering, Vol. 3, No. 1,
  2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Password authentication is the most commonly used technique to authenticate
the user validity. However, due to its simplicity, it is vulnerable to pseudo
attacks. It can be enhanced using various biometric techniques such as thumb
impression, finger movement, eye movement etc. In this paper, we concentrate on
the most economic technique, based on the user habitual rhythm pattern i.e. not
what they type but how they type is the measure for authenticating the user. We
consider the latency between key events as the trajectory, and trajectory
clustering is used to obtain the hidden patterns of the user. Obtained pattern
can be considered as a cluster of measurements that can be used to
differentiate from other users. We evaluated the proposed technique on the data
obtained from the 100 users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0742</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0742</id><created>2011-08-03</created><updated>2012-06-22</updated><authors><author><keyname>Watanabe</keyname><forenames>Takamitsu</forenames></author></authors><title>Rich-club network topology to minimize synchronization cost due to phase
  difference among frequency-synchronized oscillators</title><categories>nlin.CD cond-mat.stat-mech cs.NI physics.soc-ph</categories><comments>4 figures + one appendix figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Functions of some networks, such as power grids and large-scale brain
networks, rely on not only frequency synchronization, but also phase
synchronization. Nevertheless, even after the oscillators reach to
frequency-synchronized status, phase difference among oscillators often shows
non-zero constant values. Such phase difference potentially results in
inefficient transfer of power or information among oscillators, and avoid
proper and efficient functioning of the network. In the present study, we newly
define synchronization cost by the phase difference among the
frequency-synchronized oscillators, and investigate the optimal network
structure with the minimum synchronization cost through rewiring-based
optimization. By using the Kuramoto model, we demonstrate that the cost is
minimized in a network topology with rich-club organization, which comprises
the densely-connected center nodes and peripheral nodes connecting with the
center module. We also show that the network topology is characterized by its
bimodal degree distribution, which is quantified by Wolfson's polarization
index. Furthermore, we provide analytical interpretation on why the rich-club
network topology is related to the small amount of synchronization cost.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0743</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0743</id><created>2011-08-03</created><authors><author><keyname>Munaga</keyname><forenames>Hazarath</forenames><affiliation>Dr MHM Krishna Prasad</affiliation></author><author><keyname>Murthy</keyname><forenames>J. V. R.</forenames></author><author><keyname>Venkateswarlu</keyname><forenames>N. B.</forenames></author></authors><title>A Hybrid Trajectory Clustering for Predicting User Navigation</title><categories>cs.NI</categories><journal-ref>International Journal of Recent Trends in Engineering, Vol. 3, No.
  1, 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) suffers from the hot spot problem where the
sensor nodes closest to the base station are need to relay more packet than the
nodes farther away from the base station. Thus, lifetime of sensory network
depends on these closest nodes. Clustering methods are used to extend the
lifetime of a wireless sensor network. However, current clustering algorithms
usually utilize two techniques; selecting cluster heads with more residual
energy, and rotating cluster heads periodically to distribute the energy
consumption among nodes in each cluster and lengthen the network lifetime. Most
of the algorithms use random selection for selecting the cluster heads. Here,
we propose a novel trajectory clustering technique for selecting the cluster
heads in WSNs. Our algorithm selects the cluster heads based on traffic and
rotates periodically. It provides the first trajectory based clustering
technique for selecting the cluster heads and to extenuate the hot spot problem
by prolonging the network lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0747</identifier>
 <datestamp>2012-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0747</id><created>2011-08-03</created><authors><author><keyname>Munaga</keyname><forenames>Hazarath</forenames><affiliation>Dr MHM Krishna Prasad</affiliation></author><author><keyname>Murthy</keyname><forenames>J. V. R.</forenames></author><author><keyname>Venkateswarlu</keyname><forenames>N. B.</forenames></author></authors><title>A Fault Tolerant Trajectory Clustering (FTTC) for selecting cluster
  heads inWireless Sensor Networks</title><categories>cs.NI</categories><comments>arXiv admin note: substantial text overlap with arXiv:1108.0740</comments><journal-ref>International Journal of Computational Intelligence Research
  (IJCIR) Volume 6, Number 3 (2010)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor networks (WSNs) suffers from the hot spot problem where the
sensor nodes closest to the base station are need to relay more packet than the
nodes farther away from the base station. Thus, lifetime of sensory network
depends on these closest nodes. Clustering methods are used to extend the
lifetime of a wireless sensor network. However, current clustering algorithms
usually utilize two techniques; selecting cluster heads with more residual
energy, and rotating cluster heads periodically to distribute the energy
consumption among nodes in each cluster and lengthen the network lifetime. Most
of the algorithms use random selection for selecting the cluster heads. Here,
we propose a Fault Tolerant Trajectory Clustering (FTTC) technique for
selecting the cluster heads in WSNs. Our algorithm selects the cluster heads
based on traffic and rotates periodically. It provides the first Fault Tolerant
Trajectory based clustering technique for selecting the cluster heads and to
extenuate the hot spot problem by prolonging the network lifetime.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0748</identifier>
 <datestamp>2011-10-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0748</id><created>2011-08-03</created><updated>2011-09-30</updated><authors><author><keyname>Rathipriya</keyname><forenames>R.</forenames></author><author><keyname>Thangavel</keyname><forenames>K.</forenames></author><author><keyname>Bagyamani</keyname><forenames>J.</forenames></author></authors><title>Binary Particle Swarm Optimization based Biclustering of Web usage Data</title><categories>cs.IR cs.SY</categories><doi>10.5120/3001-4036</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web mining is the nontrivial process to discover valid, novel, potentially
useful knowledge from web data using the data mining techniques or methods. It
may give information that is useful for improving the services offered by web
portals and information access and retrieval tools. With the rapid development
of biclustering, more researchers have applied the biclustering technique to
different fields in recent years. When biclustering approach is applied to the
web usage data it automatically captures the hidden browsing patterns from it
in the form of biclusters. In this work, swarm intelligent technique is
combined with biclustering approach to propose an algorithm called Binary
Particle Swarm Optimization (BPSO) based Biclustering for Web Usage Data. The
main objective of this algorithm is to retrieve the global optimal bicluster
from the web usage data. These biclusters contain relationships between web
users and web pages which are useful for the E-Commerce applications like web
advertising and marketing. Experiments are conducted on real dataset to prove
the efficiency of the proposed algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0775</identifier>
 <datestamp>2011-11-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0775</id><created>2011-08-03</created><updated>2011-11-22</updated><authors><author><keyname>Bach</keyname><forenames>Francis</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Jenatton</keyname><forenames>Rodolphe</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Mairal</keyname><forenames>Julien</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author><author><keyname>Obozinski</keyname><forenames>Guillaume</forenames><affiliation>LIENS, INRIA Paris - Rocquencourt</affiliation></author></authors><title>Optimization with Sparsity-Inducing Penalties</title><categories>cs.LG math.OC stat.ML</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse estimation methods are aimed at using or obtaining parsimonious
representations of data or models. They were first dedicated to linear variable
selection but numerous extensions have now emerged such as structured sparsity
or kernel selection. It turns out that many of the related estimation problems
can be cast as convex optimization problems by regularizing the empirical risk
with appropriate non-smooth norms. The goal of this paper is to present from a
general perspective optimization tools and techniques dedicated to such
sparsity-inducing penalties. We cover proximal methods, block-coordinate
descent, reweighted $\ell_2$-penalized techniques, working-set and homotopy
methods, as well as non-convex formulations and extensions, and provide an
extensive set of experiments to compare various algorithms from a computational
point of view.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0779</identifier>
 <datestamp>2011-10-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0779</id><created>2011-08-03</created><updated>2011-10-20</updated><authors><author><keyname>Guerra</keyname><forenames>Yves de Sa&#xe1;</forenames></author><author><keyname>Gonz&#xe1;lez</keyname><forenames>Juan Manuel Mart&#xed;n</forenames></author><author><keyname>Montesdeoca</keyname><forenames>Samuel Sarmiento</forenames></author><author><keyname>Ruiz</keyname><forenames>David Rodr&#xed;guez</forenames></author><author><keyname>L&#xf3;pez</keyname><forenames>Nieves Arjonilla</forenames></author><author><keyname>Manso</keyname><forenames>Juan Manuel Garc&#xed;a</forenames></author></authors><title>Basketball scoring in NBA games: an example of complexity</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>Paper 1 for the Complex Systems in Sports Workshop 2011 (CS-Sports
  2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scoring in a basketball game is a process highly dynamic and non-linear type.
The level of NBA teams improve each season. They incorporate to their rosters
the best players in the world. These and other mechanisms, make the scoring in
the NBA basketball games be something exciting, where, on rare occasions, we
really know what will be the result at the end of the game. We analyzed all the
games of the 2005-06, 2006-07, 2007-08, 2008-09, 2009-10 NBA regular seasons
(6150 games). We have studied the evolution of the scoring and the time
intervals between points. These do not behave uniformly, but present more
predictable areas. In turn, we have analyzed the scoring in the games regarding
the differences in points. Exists different areas of behavior related with the
scorea and each zone has a different nature. There are point that we can
consider as tipping points. The presence of these critical points suggests that
there are phase transitions where the dynamic scoring of the games varies
significantly.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0786</identifier>
 <datestamp>2011-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0786</id><created>2011-08-03</created><authors><author><keyname>Pickl</keyname><forenames>Kristina</forenames></author><author><keyname>G&#xf6;tz</keyname><forenames>Jan</forenames></author><author><keyname>Iglberger</keyname><forenames>Klaus</forenames></author><author><keyname>Pande</keyname><forenames>Jayant</forenames></author><author><keyname>Mecke</keyname><forenames>Klaus</forenames></author><author><keyname>Smith</keyname><forenames>Ana-Suncana</forenames></author><author><keyname>R&#xfc;de</keyname><forenames>Ulrich</forenames></author></authors><title>All good things come in threes - Three beads learn to swim with lattice
  Boltzmann and a rigid body solver</title><categories>cs.CE cond-mat.soft physics.flu-dyn</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We simulate the self-propulsion of devices in a fluid in the regime of low
Reynolds numbers. Each device consists of three bodies (spheres or capsules)
connected with two damped harmonic springs. Sinusoidal driving forces compress
the springs which are resolved within a rigid body physics engine. The latter
is consistently coupled to a 3D lattice Boltzmann framework for the fluid
dynamics. In simulations of three-sphere devices, we find that the propulsion
velocity agrees well with theoretical predictions. In simulations where some or
all spheres are replaced by capsules, we find that the asymmetry of the design
strongly affects the propelling efficiency.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0809</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0809</id><created>2011-08-03</created><updated>2014-09-10</updated><authors><author><keyname>Augustine</keyname><forenames>John</forenames></author><author><keyname>Pandurangan</keyname><forenames>Gopal</forenames></author><author><keyname>Robinson</keyname><forenames>Peter</forenames></author><author><keyname>Upfal</keyname><forenames>Eli</forenames></author></authors><title>Distributed Agreement in Dynamic Peer-to-Peer Networks</title><categories>cs.DS cs.DC</categories><comments>to appear at the Journal of Computer and System Sciences; preliminary
  version appeared at SODA 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the need for robust and fast distributed computation in highly
dynamic Peer-to-Peer (P2P) networks, we study algorithms for the fundamental
distributed agreement problem. P2P networks are highly dynamic networks that
experience heavy node {\em churn}. Our goal is to design fast algorithms
(running in a small number of rounds) that guarantee, despite high node churn
rate, that almost all nodes reach a stable agreement. Our main contributions
are randomized distributed algorithms that guarantee {\em stable
almost-everywhere agreement} with high probability even under high adversarial
churn in a polylogarithmic number of rounds:
  1. An $O(\log^2 n)$-round ($n$ is the stable network size) randomized
algorithm that achieves almost-everywhere agreement with high probability under
up to {\em linear} churn {\em per round} (i.e., $\epsilon n$, for some small
constant $\epsilon &gt; 0$), assuming that the churn is controlled by an oblivious
adversary (that has complete knowledge and control of what nodes join and leave
and at what time and has unlimited computational power, but is oblivious to the
random choices made by the algorithm). Our algorithm requires only
polylogarithmic in $n$ bits to be processed and sent (per round) by each node.
  2. An $O(\log m\log^3 n)$-round randomized algorithm that achieves
almost-everywhere agreement with high probability under up to $\epsilon
\sqrt{n}$ churn per round (for some small $\epsilon &gt; 0$), where $m$ is the
size of the input value domain, that works even under an adaptive adversary
(that also knows the past random choices made by the algorithm). This algorithm
requires up to polynomial in $n$ bits (and up to $O(\log m)$ bits) to be
processed and sent (per round) by each node.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0810</identifier>
 <datestamp>2012-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0810</id><created>2011-08-03</created><updated>2012-06-29</updated><authors><author><keyname>Cygan</keyname><forenames>Marek</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Marcin</forenames></author><author><keyname>Pilipczuk</keyname><forenames>Micha&#x142;</forenames></author><author><keyname>Wojtaszczyk</keyname><forenames>Jakub Onufry</forenames></author></authors><title>Scheduling partially ordered jobs faster than 2^n</title><categories>cs.DS</categories><comments>full version of a paper accepted for ESA'11</comments><acm-class>F.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the SCHED problem we are given a set of n jobs, together with their
processing times and precedence constraints. The task is to order the jobs so
that their total completion time is minimized. SCHED is a special case of the
Traveling Repairman Problem with precedences. A natural dynamic programming
algorithm solves both these problems in 2^n n^O(1) time, and whether there
exists an algorithms solving SCHED in O(c^n) time for some constant c &lt; 2 was
an open problem posted in 2004 by Woeginger. In this paper we answer this
question positively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0831</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0831</id><created>2011-08-03</created><authors><author><keyname>Bisceglia</keyname><forenames>Pablo</forenames></author><author><keyname>Gomez</keyname><forenames>Leticia</forenames></author><author><keyname>Vaisman</keyname><forenames>Alejandro</forenames></author></authors><title>Towards Spatio-Temporal SOLAP</title><categories>cs.DB</categories><comments>11 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The integration of Geographic Information Systems (GIS) and On-Line
Analytical Processing (OLAP), denoted SOLAP, is aimed at exploring and
analyzing spatial data. In real-world SOLAP applications, spatial and
non-spatial data are subject to changes. In this paper we present a temporal
query language for SOLAP, called TPiet-QL, supporting so-called discrete
changes (for example, in land use or cadastral applications there are
situations where parcels are merged or split). TPiet-QL allows expressing
integrated GIS-OLAP queries in an scenario where spatial objects change across
time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0835</identifier>
 <datestamp>2013-09-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0835</id><created>2011-08-03</created><updated>2013-09-15</updated><authors><author><keyname>Abdullah</keyname><forenames>Amirali</forenames></author><author><keyname>Moeller</keyname><forenames>John</forenames></author><author><keyname>Venkatasubramanian</keyname><forenames>Suresh</forenames></author></authors><title>Approximate Bregman near neighbors in sublinear time: Beyond the
  triangle inequality</title><categories>cs.CG</categories><comments>42 pages, including appendices and bibliography. Accepted at SOCG
  2012; this version updated to remove typos and minor errata</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present the first provable approximate nearest-neighbor
(ANN) algorithms for Bregman divergences. Our first algorithm processes queries
in O(log^d n) time using O(n log^d n) space and only uses general properties of
the underlying distance function (which includes Bregman divergences as a
special case). The second algorithm processes queries in O(log n) time using
O(n) space and exploits structural constants associated specifically with
Bregman divergences. An interesting feature of our algorithms is that they
extend the ring-tree + quad-tree paradigm for ANN searching beyond Euclidean
distances and metrics of bounded doubling dimension to distances that might not
even be symmetric or satisfy a triangle inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0840</identifier>
 <datestamp>2011-11-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0840</id><created>2011-08-03</created><authors><author><keyname>Bocharova</keyname><forenames>Irina E.</forenames></author><author><keyname>Hug</keyname><forenames>Florian</forenames></author><author><keyname>Johannesson</keyname><forenames>Rolf</forenames></author><author><keyname>Kudryashov</keyname><forenames>Boris D.</forenames></author><author><keyname>Satyukov</keyname><forenames>Roman V.</forenames></author></authors><title>Searching for Voltage Graph-Based LDPC Tailbiting Codes with Large Girth</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory in February 2011</comments><doi>10.1109/TIT.2011.2176717</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The relation between parity-check matrices of quasi-cyclic (QC) low-density
parity-check (LDPC) codes and biadjacency matrices of bipartite graphs supports
searching for powerful LDPC block codes. Using the principle of tailbiting,
compact representations of bipartite graphs based on convolutional codes can be
found.
  Bounds on the girth and the minimum distance of LDPC block codes constructed
in such a way are discussed. Algorithms for searching iteratively for LDPC
block codes with large girth and for determining their minimum distance are
presented. Constructions based on all-ones matrices, Steiner Triple Systems,
and QC block codes are introduced. Finally, new QC regular LDPC block codes
with girth up to 24 are given.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0843</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0843</id><created>2011-08-03</created><updated>2011-11-01</updated><authors><author><keyname>Gregoriades</keyname><forenames>Vassilios</forenames><affiliation>Post-Doctoral Researcher TU Darmstadt</affiliation></author></authors><title>The descriptive set-theoretic complexity of the set of points of
  continuity of a multi-valued function</title><categories>math.LO cs.LO</categories><comments>22 pages</comments><proxy>LMCS</proxy><acm-class>F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 4 (November
  2, 2011) lmcs:887</journal-ref><doi>10.2168/LMCS-7(4:2)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we treat a notion of continuity for a multi-valued function
$F$ and we compute the descriptive set-theoretic complexity of the set of all
$x$ for which $F$ is continuous at $x$. We give conditions under which the
latter set is either a $G_\delta$ set or the countable union of $G_\delta$
sets. Also we provide a counterexample which shows that the latter result is
optimum under the same conditions. Moreover we prove that those conditions are
necessary in order to obtain that the set of points of continuity of $F$ is
Borel i.e., we show that if we drop some of the previous conditions then there
is a multi-valued function $F$ whose graph is a Borel set and the set of points
of continuity of $F$ is not a Borel set. Finally we give some analogous results
regarding a stronger notion of continuity for a multi-valued function. This
article is motivated by a question of M. Ziegler in [{\em Real Computation with
Least Discrete Advice: A Complexity Theory of Nonuniform Computability with
Applications to Linear Algebra}, {\sl submitted}].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0866</identifier>
 <datestamp>2015-03-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0866</id><created>2011-08-03</created><authors><author><keyname>Peczarski</keyname><forenames>Marcin</forenames></author></authors><title>Towards Optimal Sorting of 16 Elements</title><categories>cs.DS</categories><comments>10 pages, 7 figures, 2 tables. First submitted to IWOCA 2010, 21st
  International Workshop on Combinatorial Algorithms. Submission was rejected</comments><acm-class>G.2.1</acm-class><journal-ref>Acta Universitatis Sapientiae, Informatica, 4(2) (2012) 215-224</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the fundamental problem in the theory of sorting is to find the
pessimistic number of comparisons sufficient to sort a given number of
elements. Currently 16 is the lowest number of elements for which we do not
know the exact value. We know that 46 comparisons suffices and that 44 do not.
There is an open question if 45 comparisons are sufficient. We present an
attempt to resolve that problem by performing an exhaustive computer search. We
also present an algorithm for counting linear extensions which substantially
speeds up computations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0870</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0870</id><created>2011-08-03</created><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Noisy-Interference Sum-Rate Capacity for Vector Gaussian Interference
  Channels</title><categories>cs.IT math.IT</categories><comments>43 pages, 2 figures, submitted to IEEE trans. on Information Theory
  on May 13, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  New sufficient conditions for a vector Gaussian interference channel to
achieve the sum-rate capacity by treating interference as noise are derived,
which generalize the existing results. More concise conditions for
multiple-input-single-output, and single-input-multiple-output scenarios are
obtained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0894</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0894</id><created>2011-08-03</created><authors><author><keyname>Johnson</keyname><forenames>Matthew P.</forenames></author><author><keyname>Gutfraind</keyname><forenames>Alexander</forenames></author></authors><title>Evader Interdiction and Collateral Damage</title><categories>cs.SI</categories><comments>Proceedings of the 7th International Symposium on Algorithms for
  Sensor Systems, Wireless Ad Hoc Networks and Autonomous Mobile Entities
  (ALGOSENSORS) 2011</comments><report-no>LA-UR-11-10123</report-no><acm-class>E.1; F.2; G.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In network interdiction problems, evaders (e.g., hostile agents or data
packets) may be moving through a network towards targets and we wish to choose
locations for sensors in order to intercept the evaders before they reach their
destinations. The evaders might follow deterministic routes or Markov chains,
or they may be reactive}, i.e., able to change their routes in order to avoid
sensors placed to detect them. The challenge in such problems is to choose
sensor locations economically, balancing security gains with costs, including
the inconvenience sensors inflict upon innocent travelers. We study the
objectives of 1) maximizing the number of evaders captured when limited by a
budget on sensing cost and 2) capturing all evaders as cheaply as possible. We
give optimal sensor placement algorithms for several classes of special graphs
and hardness and approximation results for general graphs, including for
deterministic or Markov chain-based and reactive or oblivious evaders. In a
similar-sounding but fundamentally different problem setting posed by
Rubinstein and Glazer where both evaders and innocent travelers are reactive,
we again give optimal algorithms for special cases and hardness and
approximation results on general graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0895</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0895</id><created>2011-08-03</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author><author><keyname>Konig</keyname><forenames>Christian</forenames></author></authors><title>Accurate Estimators for Improving Minwise Hashing and b-Bit Minwise
  Hashing</title><categories>stat.ML cs.DB cs.IR cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Minwise hashing is the standard technique in the context of search and
databases for efficiently estimating set (e.g., high-dimensional 0/1 vector)
similarities. Recently, b-bit minwise hashing was proposed which significantly
improves upon the original minwise hashing in practice by storing only the
lowest b bits of each hashed value, as opposed to using 64 bits. b-bit hashing
is particularly effective in applications which mainly concern sets of high
similarities (e.g., the resemblance &gt;0.5). However, there are other important
applications in which not just pairs of high similarities matter. For example,
many learning algorithms require all pairwise similarities and it is expected
that only a small fraction of the pairs are similar. Furthermore, many
applications care more about containment (e.g., how much one object is
contained by another object) than the resemblance. In this paper, we show that
the estimators for minwise hashing and b-bit minwise hashing used in the
current practice can be systematically improved and the improvements are most
significant for set pairs of low resemblance and high containment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0901</identifier>
 <datestamp>2012-04-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0901</id><created>2011-08-02</created><updated>2011-08-13</updated><authors><author><keyname>Formato</keyname><forenames>Richard A.</forenames></author></authors><title>UWB Array Design Using Variable Zo Technology and Central Force
  Optimization</title><categories>cs.OH</categories><comments>Rev. 2 (added discussion, citation). arXiv admin note: substantial
  text overlap with arXiv:1107.1437, arXiv:1003.0221, arXiv:1103.5629,
  arXiv:1003.1039, arXiv:1002.2798, arXiv:1001.0317</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This note applies Variable Zo technology to the design of an Ultra Wideband
(UWB) Yagi-Uda array optimized using Central Force Optimization. Variable Zo is
a novel and proprietary approach to antenna design and optimization that treats
the feed system characteristic impedance, Zo, as a design variable instead of a
fixed design parameter as is traditionally done. Variable Zo is applicable to
any antenna design or optimization methodology, and using it will generally
produce better antenna designs across any user-specified set of performance
objectives.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0904</identifier>
 <datestamp>2011-08-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0904</id><created>2011-07-30</created><authors><author><keyname>Malik</keyname><forenames>Salman</forenames></author><author><keyname>Silva</keyname><forenames>Alonso</forenames></author><author><keyname>Kelif</keyname><forenames>Jean-Marc</forenames></author></authors><title>Optimal Base Station Placement: A Stochastic Method Using Interference
  Gradient In Downlink Case</title><categories>cs.NI</categories><comments>This work has been presented in the 5th International ICST Conference
  on Performance Evaluation Methodologies and Tools (Valuetools 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the optimal placement and optimal number of base
stations added to an existing wireless data network through the interference
gradient method. This proposed method considers a sub-region of the existing
wireless data network, hereafter called region of interest. In this region, the
provider wants to increase the network coverage and the users throughput. In
this aim, the provider needs to determine the optimal number of base stations
to be added and their optimal placement. The proposed approach is based on the
Delaunay triangulation of the region of interest and the gradient descent
method in each triangle to compute the minimum interference locations. We
quantify the increase of coverage and throughput.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0952</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0952</id><created>2011-08-03</created><authors><author><keyname>Payette</keyname><forenames>G. S.</forenames></author><author><keyname>Nakshatrala</keyname><forenames>K. B.</forenames></author><author><keyname>Reddy</keyname><forenames>J. N.</forenames></author></authors><title>On the performance of high-order finite elements with respect to maximum
  principles and the non-negative constraint for diffusion-type equations</title><categories>cs.NA math.NA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The main aim of this paper is to document the performance of $p$-refinement
with respect to maximum principles and the non-negative constraint. The model
problem is (steady-state) anisotropic diffusion with decay (which is a
second-order elliptic partial differential equation). We considered the
standard single-field formulation (which is based on the Galerkin formalism)
and two least-squares-based mixed formulations. We have employed non-uniform
Lagrange polynomials for altering the polynomial order in each element, and we
have used $p = 1, ..., 10$.
  It will be shown that the violation of the non-negative constraint will not
vanish with $p$-refinement for anisotropic diffusion. We shall illustrate the
performance of $p$-refinement using several representative problems. The
intended outcome of the paper is twofold. Firstly, this study will caution the
users of high-order approximations about its performance with respect to
maximum principles and the non-negative constraint. Secondly, this study will
help researchers to develop new methodologies for enforcing maximum principles
and the non-negative constraint under high-order approximations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0972</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0972</id><created>2011-08-03</created><authors><author><keyname>Kaewprapha</keyname><forenames>Phisan</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Li</keyname><forenames>Jing</forenames><affiliation>Tiffany</affiliation></author><author><keyname>Puttarak</keyname><forenames>Nattakan</forenames></author></authors><title>Network Localization on Unit Disk Graphs</title><categories>cs.DC</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of cooperative localization of a large network of nodes
in integer-coordinated unit disk graphs, a simplified but useful version of
general random graph. Exploiting the property that the radius $r$ sets clear
cut on the connectivity of two nodes, we propose an essential philosophy that
&quot;no connectivity is also useful information just like the information being
connected&quot; in unit disk graphs. Exercising this philosophy, we show that the
conventional network localization problem can be re-formulated to significantly
reduce the search space, and that global rigidity, a necessary and sufficient
condition for the existence of unique solution in general graphs, is no longer
necessary. While the problem is still NP-hard, we show that a (depth-first)
tree-search algorithm with memory O(N) ($N$ is the network size) can be
developed, and for practical setups, the search complexity and speed is very
manageable, and is magnitudes less than the conventional problem, especially
when the graph is sparse or when only very limited anchor nodes are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.0982</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.0982</id><created>2011-08-03</created><authors><author><keyname>Wang</keyname><forenames>Kun-Yu</forenames></author><author><keyname>So</keyname><forenames>Anthony Man-Cho</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-Hui</forenames></author><author><keyname>Ma</keyname><forenames>Wing-Kin</forenames></author><author><keyname>Chi</keyname><forenames>Chong-Yung</forenames></author></authors><title>Outage Constrained Robust Transmit Optimization for Multiuser MISO
  Downlinks: Tractable Approximations by Conic Optimization</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we consider a probabilistic signal-to-interference and-noise
ratio (SINR) constrained problem for transmit beamforming design in the
presence of imperfect channel state information (CSI), under a multiuser
multiple-input single-output (MISO) downlink scenario. In particular, we deal
with outage-based quality-of-service constraints, where the probability of each
user's SINR not satisfying a service requirement must not fall below a given
outage probability specification. The study of solution approaches to the
probabilistic SINR constrained problem is important because CSI errors are
often present in practical systems and they may cause substantial SINR outages
if not handled properly. However, a major technical challenge is how to process
the probabilistic SINR constraints. To tackle this, we propose a novel
relaxation- restriction (RAR) approach, which consists of two key
ingredients-semidefinite relaxation (SDR), and analytic tools for
conservatively approximating probabilistic constraints. The underlying goal is
to establish approximate probabilistic SINR constrained formulations in the
form of convex conic optimization problems, so that they can be readily
implemented by available solvers. Using either an intuitive worst-case argument
or specialized probabilistic results, we develop various conservative
approximation schemes for processing probabilistic constraints with quadratic
uncertainties. Consequently, we obtain several RAR alternatives for handling
the probabilistic SINR constrained problem. Our techniques apply to both
complex Gaussian CSI errors and i.i.d. bounded CSI errors with unknown
distribution. Moreover, results obtained from our extensive simulations show
that the proposed RAR methods significantly improve upon existing ones, both in
terms of solution quality and computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1012</identifier>
 <datestamp>2012-06-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1012</id><created>2011-08-04</created><updated>2012-06-01</updated><authors><author><keyname>Jeandel</keyname><forenames>Emmanuel</forenames><affiliation>LIF</affiliation></author><author><keyname>Vanier</keyname><forenames>Pascal</forenames><affiliation>LIF</affiliation></author></authors><title>Turing degrees of multidimensional SFTs</title><categories>cs.CC cs.DM</categories><comments>arXiv admin note: substantial text overlap with arXiv:1102.1189</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we are interested in computability aspects of subshifts and in
particular Turing degrees of 2-dimensional SFTs (i.e. tilings). To be more
precise, we prove that given any \pizu subset $P$ of $\{0,1\}^\NN$ there is a
SFT $X$ such that $P\times\ZZ^2$ is recursively homeomorphic to $X\setminus U$
where $U$ is a computable set of points. As a consequence, if $P$ contains a
recursive member, $P$ and $X$ have the exact same set of Turing degrees. On the
other hand, we prove that if $X$ contains only non-recursive members, some of
its members always have different but comparable degrees. This gives a fairly
complete study of Turing degrees of SFTs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1022</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1022</id><created>2011-08-04</created><authors><author><keyname>Baron</keyname><forenames>Dror</forenames></author></authors><title>Information Complexity and Estimation</title><categories>cs.IT math.IT</categories><comments>Appears at WITMSE 2011, The Fourth Workshop on Information Theoretic
  Methods in Science and Engineering, 7-10 August 2011, Helsinki, Finland. Note
  that the WITMSE version is 4 pages, owing to different formatting</comments><journal-ref>D. Baron, &quot;Information complexity and estimation,&quot; in Fourth
  Workshop Inf. Theoretic Methods Science Eng. (WITMSE 2011), Helsinki,
  Finland, Aug. 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider an input $x$ generated by an unknown stationary ergodic source
$X$ that enters a signal processing system $J$, resulting in $w=J(x)$. We
observe $w$ through a noisy channel, $y=z(w)$; our goal is to estimate x from
$y$, $J$, and knowledge of $f_{Y|W}$. This is universal estimation, because
$f_X$ is unknown. We provide a formulation that describes a trade-off between
information complexity and noise. Initial theoretical, algorithmic, and
experimental evidence is presented in support of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1042</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1042</id><created>2011-08-04</created><authors><author><keyname>Zilinskas</keyname><forenames>Antanas</forenames></author></authors><title>On strong homogeneity of two global optimization algorithms based on
  statistical models of multimodal objective functions</title><categories>cs.NA math.OC</categories><comments>11 pages, 1 figure</comments><msc-class>65C20</msc-class><acm-class>F.2.1</acm-class><doi>10.1016/j.amc.2011.07.051</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The implementation of global optimization algorithms, using the arithmetic of
in?nity, is considered. A relatively simple version of implementation is
proposed for the algorithms that possess the introduced property of strong
homogeneity. It is shown that the P-algorithm and the one-step Bayesian
algorithm are strongly homogeneous.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1045</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1045</id><created>2011-08-04</created><authors><author><keyname>T</keyname><forenames>Asha.</forenames></author><author><keyname>Natarajan</keyname><forenames>S.</forenames></author><author><keyname>Murthy</keyname><forenames>K. N. B.</forenames></author></authors><title>A Data Mining Approach to the Diagnosis of Tuberculosis by Cascading
  Clustering and Classification</title><categories>cs.AI cs.DB</categories><comments>8 pages</comments><journal-ref>Journal of computing, volume 3, issue 4,April 2011, ISSN 2151-9617</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a methodology for the automated detection and classification
of Tuberculosis(TB) is presented. Tuberculosis is a disease caused by
mycobacterium which spreads through the air and attacks low immune bodies
easily. Our methodology is based on clustering and classification that
classifies TB into two categories, Pulmonary Tuberculosis(PTB) and retroviral
PTB(RPTB) that is those with Human Immunodeficiency Virus (HIV) infection.
Initially K-means clustering is used to group the TB data into two clusters and
assigns classes to clusters. Subsequently multiple different classification
algorithms are trained on the result set to build the final classifier model
based on K-fold cross validation method. This methodology is evaluated using
700 raw TB data obtained from a city hospital. The best obtained accuracy was
98.7% from support vector machine (SVM) compared to other classifiers. The
proposed approach helps doctors in their diagnosis decisions and also in their
treatment planning procedures for different categories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1055</identifier>
 <datestamp>2012-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1055</id><created>2011-08-04</created><authors><author><keyname>Halldorsson</keyname><forenames>Magnus M.</forenames></author><author><keyname>Mitra</keyname><forenames>Pradipta</forenames></author></authors><title>Wireless Capacity With Arbitrary Gain Matrix</title><categories>cs.DS cs.NI</categories><comments>8 pages, to appear in ALGOSENSORS 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of wireless links, a fundamental problem is to find the largest
subset that can transmit simultaneously, within the SINR model of interference.
Significant progress on this problem has been made in recent years. In this
note, we study the problem in the setting where we are given a fixed set of
arbitrary powers each sender must use, and an arbitrary gain matrix defining
how signals fade. This variation of the problem appears immune to most
algorithmic approaches studied in the literature. Indeed it is very hard to
approximate since it generalizes the max independent set problem. Here, we
propose a simple semi-definite programming approach to the problem that yields
constant factor approximation, if the optimal solution is strictly larger than
half of the input size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1060</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1060</id><created>2011-08-04</created><authors><author><keyname>L&#xf3;pez-Presa</keyname><forenames>Jos&#xe9; Luis</forenames></author><author><keyname>Anta</keyname><forenames>Antonio Fern&#xe1;ndez</forenames></author><author><keyname>Chiroque</keyname><forenames>Luis N&#xfa;&#xf1;ez</forenames></author></authors><title>Conauto-2.0: Fast Isomorphism Testing and Automorphism Group Computation</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present an algorithm, called conauto-2.0, that can
efficiently compute a set of generators of the automorphism group of a graph,
and test whether two graphs are isomorphic, finding an isomorphism if they are.
This algorithm uses the basic individualization/refinement technique, and is an
improved version of the algorithm conauto, which has been shown to be very fast
for random graphs and several families of hard graphs. In this paper, it is
proved that, under some circumstances, it is not only possible to prune the
search space (using already found generators of the automorphism group), but
also to infer new generators without the need of explicitly finding an
automorphism of the graph. This result is especially suited for graphs with
regularly connected components, and can be applied in any isomorphism testing
and canonical labeling algorithm (that use the individualization/refinement
technique) to significantly improve its performance. Additionally, a dynamic
target cell selection function is used to adapt to different graphs. The
resulting algorithm preserves all the nice features of conauto, but reduces the
time for testing graphs with regularly connected components and other hard
graph families. We run extensive experiments, which show that the most popular
algorithms (namely, nauty, bliss, Traces, and saucy) are slower than
conauto-2.0, among others, for the graph families based on components.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1065</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1065</id><created>2011-08-04</created><updated>2011-08-10</updated><authors><author><keyname>Hristovski</keyname><forenames>Robert</forenames></author><author><keyname>Balague</keyname><forenames>Natalia</forenames></author><author><keyname>Juaneda</keyname><forenames>Josep</forenames></author><author><keyname>Vazquez</keyname><forenames>Pablo</forenames></author></authors><title>Onset of coherent attitude layers in a population of sports fans</title><categories>cs.SI</categories><comments>Paper 4 for the Complex Systems in Sports Workshop 2011 (CS-Sports
  2011) Adaptation and Self-Organizing Systems</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper was to empirically investigate the behavior of fans,
globally coupled to a common environmental source of information. The
environmental stimuli were given in a form of referee's decisions list. The
sample of fans had to respond on each stimulus by associating points signifying
his/her own opinion, emotion and action that referee's decisions provoke. Data
were fitted by the Brillouin function which was a solution of an adapted model
of quantum statistical physics to social phenomena. Correlation and a principal
component analysis were performed in order to detect any collective behavior of
the social ensemble of fans. Results showed that fans behaved as a system
subject to a phase transition where the neutral state in the opinion, emotional
and action space has been destabilized and a new stable state of coherent
attitudes was formed. The enhancement of fluctuations and the increase of
social susceptibility (responsiveness) to referee's decisions were connected to
the first few decisions. The subsequent reduction of values in these parameters
signified the onset of coherent layering within the attitude space of the
social ensemble of fans. In the space of opinions fan coherence was maximal as
only one layer of coherence emerged. In the emotional and action spaces the
number of coherent levels was 2 and 4 respectively. The principal component
analysis revealed a strong collective behavior and a high degree of integration
within and between the opinion, emotional and action spaces of the sample of
fans. These results point to one possible way of how different proto-groups,
violent and moderate, may be formed as a consequence of global coupling to a
common source of information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1066</identifier>
 <datestamp>2011-08-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1066</id><created>2011-08-04</created><authors><author><keyname>Nery</keyname><forenames>Bruno</forenames></author><author><keyname>Ventura</keyname><forenames>Rodrigo</forenames></author></authors><title>On the scalability and convergence of simultaneous parameter
  identification and synchronization of dynamical systems</title><categories>cs.SY math.DS math.OC nlin.CD</categories><comments>14 pages, 7 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The synchronization of dynamical systems is a method that allows two systems
to have identical state trajectories, appart from an error converging to zero.
This method consists in an appropriate unidirectional coupling from one system
(drive) to the other (response). This requires that the response system shares
the same dynamical model with the drive. For the cases where the drive is
unknown, Chen proposed in 2002 a method to adapt the response system such that
synchronization is achieved, provided that (1) the response dynamical model is
linear with a vector of parameters, and (2) there is a parameter vector that
makes both system dynamics identical. However, this method has two limitations:
first, it does not scale well for complex parametric models (e.g., if the
number of parameters is greater than the state dimension), and second, the
model parameters are not guaranteed to converge, namely as the synchronization
error approaches zero. This paper presents an adaptation law addressing these
two limitations. Stability and convergence proofs, using Lyapunov's second
method, support the proposed adaptation law. Finally, numerical simulations
illustrate the advantages of the proposed method, namely showing cases where
the Chen's method fail, while the proposed one does not.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1067</identifier>
 <datestamp>2014-04-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1067</id><created>2011-08-04</created><updated>2014-04-17</updated><authors><author><keyname>Wehmuth</keyname><forenames>Klaus</forenames></author><author><keyname>Gomes</keyname><forenames>Antonio Tadeu A.</forenames></author><author><keyname>Ziviani</keyname><forenames>Artur</forenames></author></authors><title>DANCE: A Framework for the Distributed Assessment of Network
  Centralities</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of large-scale complex networks is a major challenge in the Big
Data domain. Given the large-scale of the complex networks researchers commonly
deal with nowadays, the use of localized information (i.e. restricted to a
limited neighborhood around each node of the network) for centrality-based
analysis is gaining momentum in the recent literature. In this context, we
propose a framework for the Distributed Assessment of Network Centralities
(DANCE) in complex networks. DANCE offers a single environment that allows the
use of different localized centrality proposals, which can be tailored to
specific applications. This environment can be thus useful given the vast
potential applicability of centrality-based analysis on large-scale complex
networks found in different areas, such as Biology, Physics, Sociology, or
Computer Science. Since the localized centrality proposals DANCE implements
employ only localized information, DANCE can easily benefit from parallel
processing environments and run on different computing architectures. To
illustrate this, we present a parallel implementation of DANCE and show how it
can be applied to the analysis of large-scale complex networks using different
kinds of network centralities. This implementation is made available to complex
network researchers and practitioners interested in using it through a
scientific web portal.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1068</identifier>
 <datestamp>2013-08-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1068</id><created>2011-08-04</created><updated>2011-08-17</updated><authors><author><keyname>Wei</keyname><forenames>Yi</forenames></author><author><keyname>Roth</keyname><forenames>Hannes</forenames></author><author><keyname>Furia</keyname><forenames>Carlo A.</forenames></author><author><keyname>Pei</keyname><forenames>Yu</forenames></author><author><keyname>Horton</keyname><forenames>Alexander</forenames></author><author><keyname>Steindorfer</keyname><forenames>Michael</forenames></author><author><keyname>Nordio</keyname><forenames>Martin</forenames></author><author><keyname>Meyer</keyname><forenames>Bertrand</forenames></author></authors><title>Stateful Testing: Finding More Errors in Code and Contracts</title><categories>cs.SE</categories><comments>11 pages, 3 figures</comments><journal-ref>Proceedings of the 26th IEEE/ACM International Conference on
  Automated Software Engineering (ASE'11). Pgg. 440--443, ACM, November 2011</journal-ref><doi>10.1109/ASE.2011.6100094</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Automated random testing has shown to be an effective approach to finding
faults but still faces a major unsolved issue: how to generate test inputs
diverse enough to find many faults and find them quickly. Stateful testing, the
automated testing technique introduced in this article, generates new test
cases that improve an existing test suite. The generated test cases are
designed to violate the dynamically inferred contracts (invariants)
characterizing the existing test suite. As a consequence, they are in a good
position to detect new errors, and also to improve the accuracy of the inferred
contracts by discovering those that are unsound. Experiments on 13 data
structure classes totalling over 28,000 lines of code demonstrate the
effectiveness of stateful testing in improving over the results of long
sessions of random testing: stateful testing found 68.4% new errors and
improved the accuracy of automatically inferred contracts to over 99%, with
just a 7% time overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1108</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1108</id><created>2011-08-04</created><authors><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author><author><keyname>Levandovskyy</keyname><forenames>Viktor</forenames></author><author><keyname>Motsak</keyname><forenames>Oleksandr</forenames></author></authors><title>On Two-generated Non-commutative Algebras Subject to the Affine Relation</title><categories>cs.SC math.RA</categories><comments>13 pages, 5 tables</comments><journal-ref>Proceedings of CASC 2011, by Vladimir Gerdt, Wolfram Koepf, Ernst
  W. Mayr, and Evgenii Vorozhtsov (eds.), Lecture Notes in Computer Science,
  vol. 6885, ISBN 978-3-642-23567-2</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider algebras over a field K, generated by two variables x and y
subject to the single relation yx = qxy + ax + by + c for q in K^* and a, b, c
in K. We prove, that among such algebras there are precisely five isomorphism
classes. The representatives of these classes, which are ubiquitous operator
algebras, are called model algebras. We derive explicit multiplication formulas
for y^m*x^n in terms of standard monomials x^i*y^j for many algebras of the
considered type. Such formulas are used in establishing formulas of binomial
type and in implementing non-commutative multiplication in a computer algebra
system. By using the formulas we also study centers and ring-theoretic
properties of the non-commutative model algebras.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1121</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1121</id><created>2011-08-04</created><authors><author><keyname>Tilli</keyname><forenames>Andrea</forenames></author><author><keyname>Marconi</keyname><forenames>Lorenzo</forenames></author><author><keyname>Conficoni</keyname><forenames>Christian</forenames></author></authors><title>Analysis, Dimensioning and Robust Control of Shunt Active Filter for
  Harmonic Currents Compensation in Electrical Mains</title><categories>cs.SY math.OC</categories><comments>Paper presented at the AUTOMATICA_IT 2011 conference, Pisa, Italy,
  September 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this chapter some results related to Shunt Active Filters (SAFs) and
obtained by the authors and some coauthors are reported. SAFs are complex power
electronics equipments adopted to compensate for cur-rent harmonic pollution in
electric mains, due to nonlinear loads. By using a proper &quot;floating&quot; capacitor
as energy reservoir, the SAF purpose is to inject in the line grid currents
canceling the polluting har-monics. Control algorithms play a key role for such
devices and, in general, in many power electronics applications. Moreover,
systems theory is crucial, since it is the mathematical tool that enables a
deep understanding of the involved dynamics of such systems, allowing a correct
dimensioning, beside an effective control. As a matter of facts, current
injection objective can be straightforwardly formulated as an output tracking
control problem. In this fashion, the structural and insidious
marginally-stable internal/zero dynamics of SAFs can be immediately highlighted
and characterized in terms of sizing and control issues. For what concerns the
control design strictly, time-scale separation among output and internal
dynamics can be effectively exploited to split the control design in different
stages that can be later aggregated, by using singular perturbation analysis.
In addition, for robust asymptotic output tracking the Internal Model Principle
is adopted.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1122</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1122</id><created>2011-08-04</created><authors><author><keyname>Taigman</keyname><forenames>Yaniv</forenames></author><author><keyname>Wolf</keyname><forenames>Lior</forenames></author></authors><title>Leveraging Billions of Faces to Overcome Performance Barriers in
  Unconstrained Face Recognition</title><categories>cs.CV</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We employ the face recognition technology developed in house at face.com to a
well accepted benchmark and show that without any tuning we are able to
considerably surpass state of the art results. Much of the improvement is
concentrated in the high-valued performance point of zero false positive
matches, where the obtained recall rate almost doubles the best reported result
to date. We discuss the various components and innovations of our system that
enable this significant performance gap. These components include extensive
utilization of an accurate 3D reconstructed shape model dealing with challenges
arising from pose and illumination. In addition, discriminative models based on
billions of faces are used in order to overcome aging and facial expression as
well as low light and overexposure. Finally, we identify a challenging set of
identification queries that might provide useful focus for future research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1130</identifier>
 <datestamp>2011-10-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1130</id><created>2011-08-04</created><updated>2011-10-04</updated><authors><author><keyname>Mucha</keyname><forenames>Marcin</forenames></author></authors><title>13/9-approximation for Graphic TSP</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Travelling Salesman Problem is one the most fundamental and most studied
problems in approximation algorithms. For more than 30 years, the best
algorithm known for general metrics has been Christofides's algorithm with
approximation factor of 3/2, even though the so-called Held-Karp LP relaxation
of the problem is conjectured to have the integrality gap of only 4/3. Very
recently, significant progress has been made for the important special case of
graphic metrics, first by Oveis Gharan et al., and then by Momke and Svensson.
In this paper, we provide an improved analysis for the approach introduced by
Momke and Svensson yielding a bound of 13/9 on the approximation factor, as
well as a bound of 19/12+epsilon for any epsilon&gt;0 for a more general
Travelling Salesman Path Problem in graphic metrics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1136</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1136</id><created>2011-08-04</created><authors><author><keyname>Shang</keyname><forenames>Xiaohu</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Capacity Region of Vector Gaussian Interference Channels with Generally
  Strong Interference</title><categories>cs.IT math.IT</categories><comments>50 pages, 11 figures, submitted to IEEE trans. on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An interference channel is said to have strong interference if for all input
distributions, the receivers can fully decode the interference. This definition
of strong interference applies to discrete memoryless, scalar and vector
Gaussian interference channels. However, there exist vector Gaussian
interference channels that may not satisfy the strong interference condition
but for which the capacity can still be achieved by jointly decoding the signal
and the interference. This kind of interference is called generally strong
interference. Sufficient conditions for a vector Gaussian interference channel
to have generally strong interference are derived. The sum-rate capacity and
the boundary points of the capacity region are also determined.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1152</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1152</id><created>2011-08-04</created><authors><author><keyname>Adeniran</keyname><forenames>Oluwaranti</forenames></author><author><keyname>Philip</keyname><forenames>Achimugu</forenames></author></authors><title>Development and Deployment of Fixed Wireless Access in South West
  Nigeria: Performance and Evaluation</title><categories>cs.CY</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-7-issue-2-june-2011</comments><journal-ref>Journal of Computer Science and Engineering, Volume 7, Issue 2,
  p51-57, June 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Fixed Wireless Access (FWA) involves the use of wireless technology to
replace copper to connect subscribers to the telephone network. It is a variant
of wireless broadband which provides an alternative in the so-called 'last
mile' connectivity between the subscriber and the fixed telecommunications
network. FWA could either be narrowband or broadband and it is predominantly
deployed using the Code Division Multiple Access (CDMA) technology. In
assessing the extent of development and deployment of FWA, the perspective of
the operators and users was elicited primarily through the use of
questionnaires. Issues like setup cost, tax, Government incentive, availability
of infrastructure and manpower applied to the operators while on the users'
part factors like quality of service, signal strength as well as call rate were
considered. The South western zone of Nigeria is regarded as one of the most
urbanized regions in the south of Sahara, this is not out of place considering
the fact that Lagos which is the nation's commercial nerve centre and a
mega-city is located within this region. The scope of this research covered
this very lively part of the country. The relationship between the parameters
or variables considered was established using an appropriate statistical
method: The Regression analysis. In terms of users' preference, Global System
of Mobile communication (GSM) was compared with FWA. Results were interpreted
and suitable conclusions were drawn to wrap up a quite revealing work.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1153</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1153</id><created>2011-08-04</created><authors><author><keyname>Oluwatolani</keyname><forenames>Oluwagbemi</forenames></author><author><keyname>Joshua</keyname><forenames>Abah</forenames></author><author><keyname>Philip</keyname><forenames>Achimugu</forenames></author></authors><title>The Impact of Information Technology in Nigeria's Banking Industry</title><categories>cs.OH</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-7-issue-2-june-2011</comments><journal-ref>Journal of Computer Science and Engineering, Volume 7, Issue 2,
  p63-67, June 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Today, information technology (IT) has become a key element in economic
development and a backbone of knowledge-based economies in terms of operations,
quality delivery of services and productivity of services. Therefore, taking
advantage of information technologies (IT) is an increasing challenge for
developing countries. There is now growing evidence that Knowledge-driven
innovation is a decisive factor in the competitiveness of nations, industries,
organizations and firms. Organizations like the banking sector have benefited
substantially from e-banking, which is one among the IT applications for
strengthening the competitiveness. This paper presents the current trend in the
application of IT in the banking industries in Nigeria and gives an insight
into how quality banking has been enhanced via IT. The paper further reveals
that the deployment of IT facilities in the Nigerian Banking industry has
brought about fundamental changes in the content and quality of banking
business in the country. This analysis and clarification of how Nigerian Banks
have used IT to reengineer their operations is detailed through literature
review and observation. Three categories of variables that relate to the use
and implementation of information technology devices were considered in this
paper. These include the nature and degree of adoption of innovative
technologies; degree of utilization of the identified technologies; and the
impact of the adoption of IT devices on the bank operations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1154</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1154</id><created>2011-08-04</created><authors><author><keyname>Philip</keyname><forenames>Achimugu</forenames></author><author><keyname>Oluwatolani</keyname><forenames>Oluwagbemi</forenames></author><author><keyname>Joshua</keyname><forenames>Abah</forenames></author></authors><title>Development of a Window Based Security System for Electronic Data
  Interchange</title><categories>cs.CR</categories><comments>Submitted to Journal of Computer Science and Engineering, see
  http://sites.google.com/site/jcseuk/volume-7-issue-2-june-2011</comments><journal-ref>Journal of Computer Science and Engineering, Volume 7, Issue 2,
  p68-77, June 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Electronic Data Interchange (EDI) is the exchange of standardized
documents between computer systems for business use. The objective of this
study is to make Electronic Data Interchange secure to use and to eliminate
human intervention in the transfer of data between business partners so that
productivity and efficiency can be improved and also promote its usage between
two or more trading organizations. This paper provides an overview of EDI by
describing the traditional problems of exchanging information in business
environments and how the EDI solves those problems and gives benefits to the
company that makes use of EDI. This paper also introduces the common EDI
Standards and explains how it works, how it is used over the internet and the
security measures implemented. The system was executed on both local area
network and wide area network after a critical study of the existing EDI
methods and also implemented using VB.Net programming language. Finally, an
interactive program was developed that handles the transfer of files, with
special attention to the security of the items that are being transferred from
one computer workstation to another.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1161</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1161</id><created>2011-08-04</created><authors><author><keyname>Ahlswede</keyname><forenames>Rudolf</forenames></author><author><keyname>Aydinian</keyname><forenames>Harout</forenames></author></authors><title>On generic erasure correcting sets and related problems</title><categories>cs.IT math.IT</categories><comments>9 pages, to appear in IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by iterative decoding techniques for the binary erasure channel
Hollmann and Tolhuizen introduced and studied the notion of generic erasure
correcting sets for linear codes. A generic $(r,s)$--erasure correcting set
generates for all codes of codimension $r$ a parity check matrix that allows
iterative decoding of all correctable erasure patterns of size $s$ or less. The
problem is to derive bounds on the minimum size $F(r,s)$ of generic erasure
correcting sets and to find constructions for such sets. In this paper we
continue the study of these sets. We derive better lower and upper bounds.
Hollmann and Tolhuizen also introduced the stronger notion of $(r,s)$--sets and
derived bounds for their minimum size $G(r,s)$. Here also we improve these
bounds. We observe that these two conceps are closely related to so called
$s$--wise intersecting codes, an area, in which $G(r,s)$ has been studied
primarily with respect to ratewise performance. We derive connections. Finally,
we observed that hypergraph covering can be used for both problems to derive
good upper bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1169</identifier>
 <datestamp>2011-08-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1169</id><created>2011-08-04</created><authors><author><keyname>Gregor</keyname><forenames>Karol</forenames></author><author><keyname>LeCun</keyname><forenames>Yann</forenames></author></authors><title>Learning Representations by Maximizing Compression</title><categories>cs.CV</categories><comments>8 pages, 3 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an algorithm that learns a representation of data through
compression. The algorithm 1) predicts bits sequentially from those previously
seen and 2) has a structure and a number of computations similar to an
autoencoder. The likelihood under the model can be calculated exactly, and
arithmetic coding can be used directly for compression. When training on digits
the algorithm learns filters similar to those of restricted boltzman machines
and denoising autoencoders. Independent samples can be drawn from the model by
a single sweep through the pixels. The algorithm has a good compression
performance when compared to other methods that work under random ordering of
pixels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1170</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1170</id><created>2011-08-04</created><updated>2011-12-27</updated><authors><author><keyname>Jaggi</keyname><forenames>Martin</forenames></author></authors><title>Convex Optimization without Projection Steps</title><categories>math.OC cs.AI cs.SY</categories><msc-class>90C22, 90C20, 90C25</msc-class><acm-class>F.2.2; I.5.1; G.1.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For the general problem of minimizing a convex function over a compact convex
domain, we will investigate a simple iterative approximation algorithm based on
the method by Frank &amp; Wolfe 1956, that does not need projection steps in order
to stay inside the optimization domain. Instead of a projection step, the
linearized problem defined by a current subgradient is solved, which gives a
step direction that will naturally stay in the domain. Our framework
generalizes the sparse greedy algorithm of Frank &amp; Wolfe and its primal-dual
analysis by Clarkson 2010 (and the low-rank SDP approach by Hazan 2008) to
arbitrary convex domains. We give a convergence proof guaranteeing
{\epsilon}-small duality gap after O(1/{\epsilon}) iterations.
  The method allows us to understand the sparsity of approximate solutions for
any l1-regularized convex optimization problem (and for optimization over the
simplex), expressed as a function of the approximation quality. We obtain
matching upper and lower bounds of {\Theta}(1/{\epsilon}) for the sparsity for
l1-problems. The same bounds apply to low-rank semidefinite optimization with
bounded trace, showing that rank O(1/{\epsilon}) is best possible here as well.
As another application, we obtain sparse matrices of O(1/{\epsilon}) non-zero
entries as {\epsilon}-approximate solutions when optimizing any convex function
over a class of diagonally dominant symmetric matrices.
  We show that our proposed first-order method also applies to nuclear norm and
max-norm matrix optimization problems. For nuclear norm regularized
optimization, such as matrix completion and low-rank recovery, we demonstrate
the practical efficiency and scalability of our algorithm for large matrix
problems, as e.g. the Netflix dataset. For general convex optimization over
bounded matrix max-norm, our algorithm is the first with a convergence
guarantee, to the best of our knowledge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1176</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1176</id><created>2011-08-04</created><authors><author><keyname>Hajiaghayi</keyname><forenames>MohammadTaghi</forenames></author><author><keyname>Khandekar</keyname><forenames>Rohit</forenames></author><author><keyname>Kortsarz</keyname><forenames>Guy</forenames></author><author><keyname>Nutov</keyname><forenames>Zeev</forenames></author></authors><title>Combinatorial Algorithms for Capacitated Network Design</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We focus on designing combinatorial algorithms for the Capacitated Network
Design problem (Cap-SNDP). The Cap-SNDP is the problem of satisfying
connectivity requirements when edges have costs and hard capacities. We begin
by showing that the Group Steiner tree problem (GST) is a special case of
Cap-SNDP even when there is connectivity requirement between only one
source-sink pair. This implies the first poly-logarithmic lower bound for the
Cap-SNDP. We next provide combinatorial algorithms for several special cases of
this problem. The Cap-SNDP is equivalent to its special case when every edge
has either zero cost or infinite capacity. We consider a special case, called
Connected Cap-SNDP, where all infinite-capacity edges in the solution are
required to form a connected component containing the sinks. This problem is
motivated by its similarity to the Connected Facility Location problem
[G+01,SW04]. We solve this problem by reducing it to Submodular tree cover
problem, which is a common generalization of Connected Cap-SNDP and Group
Steiner tree problem. We generalize the recursive greedy algorithm [CEK]
achieving a poly-logarithmic approximation algorithm for Submodular tree cover
problem. This result is interesting in its own right and gives the first
poly-logarithmic approximation algorithms for Connected hard capacities set
multi-cover and Connected source location.
  We then study another special case of Cap-SNDP called Unbalanced
point-to-point connection problem. Besides its practical applications to shift
design problems [EKS], it generalizes many problems such as k-MST, Steiner
Forest and Point-to-Point Connection. We give a combinatorial logarithmic
approximation algorithm for this problem by reducing it to degree-bounded SNDP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1228</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1228</id><created>2011-08-04</created><updated>2011-08-15</updated><authors><author><keyname>Tsang</keyname><forenames>Dominic</forenames></author><author><keyname>Chawla</keyname><forenames>Sanjay</forenames></author></authors><title>An index for regular expression queries: Design and implementation</title><categories>cs.DB cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The like regular expression predicate has been part of the SQL standard since
at least 1989. However, despite its popularity and wide usage, database vendors
provide only limited indexing support for regular expression queries which
almost always require a full table scan.
  In this paper we propose a rigorous and robust approach for providing
indexing support for regular expression queries. Our approach consists of
formulating the indexing problem as a combinatorial optimization problem. We
begin with a database, abstracted as a collection of strings. From this data
set we generate a query workload. The input to the optimization problem is the
database and the workload. The output is a set of multigrams (substrings) which
can be used as keys to records which satisfy the query workload. The multigrams
can then be integrated with the data structure (like B+ trees) to provide
indexing support for the queries. We provide a deterministic and a randomized
approximation algorithm (with provable guarantees) to solve the optimization
problem. Extensive experiments on synthetic data sets demonstrate that our
approach is accurate and efficient.
  We also present a case study on PROSITE patterns - which are complex regular
expression signatures for classes of proteins. Again, we are able to
demonstrate the utility of our indexing approach in terms of accuracy and
efficiency. Thus, perhaps for the first time, there is a robust and practical
indexing mechanism for an important class of database queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1233</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1233</id><created>2011-08-04</created><updated>2011-08-12</updated><authors><author><keyname>Azad</keyname><forenames>Amar Prakash</forenames></author><author><keyname>Musacchio</keyname><forenames>John</forenames></author></authors><title>Unilateral Altruism in Network Routing Games with Atomic Players</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study a routing game in which one of the players unilaterally acts
altruistically by taking into consideration the latency cost of other players
as well as his own. By not playing selfishly, a player can not only improve the
other players' equilibrium utility but also improve his own equilibrium
utility. To quantify the effect, we define a metric called the Value of
Unilateral Altruism (VoU) to be the ratio of the equilibrium utility of the
altruistic user to the equilibrium utility he would have received in Nash
equilibrium if he were selfish. We show by example that the VoU, in a game with
nonlinear latency functions and atomic players, can be arbitrarily large. Since
the Nash equilibrium social welfare of this example is arbitrarily far from
social optimum, this example also has a Price of Anarchy (PoA) that is
unbounded. The example is driven by there being a small number of players since
the same example with non-atomic players yields a Nash equilibrium that is
fully efficient.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1235</identifier>
 <datestamp>2011-09-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1235</id><created>2011-08-04</created><updated>2011-09-07</updated><authors><author><keyname>Bolborici</keyname><forenames>Valentin</forenames></author><author><keyname>Dawson</keyname><forenames>Francis P.</forenames></author><author><keyname>Pugh</keyname><forenames>Mary C.</forenames></author></authors><title>Technical Report: Modeling of Composite Piezoelectric Structures with
  the Finite Volume Method</title><categories>math.NA cs.NA</categories><comments>Portions of this article have been accepted for publication in IEEE's
  Transactions on Ultrasonics, Ferroelectrics, and Frequency. The authors need
  to get permission from the IEEE to reuse this copyrighted material</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Piezoelectric devices, such as piezoelectric traveling wave rotary ultrasonic
motors, have composite piezoelectric structures. A composite piezoelectric
structure consists of a combination of two or more bonded materials, where at
least one of them is a piezoelectric transducer. Numerical modeling of
piezoelectric structures has been done in the past mainly with the finite
element method. Alternatively, a finite volume based approach offers the
following advantages: (a) the ordinary differential equations resulting from
the discretization process can be interpreted directly as corresponding
circuits and (b) phenomena occurring at boundaries can be treated exactly. This
report extends the work of IEEE Transactions on UFFC 57(2010)7:1673-1691 by
presenting a method for implementing the boundary conditions between the bonded
materials in composite piezoelectric structures. The report concludes with one
modeling example of a unimorph structure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1257</identifier>
 <datestamp>2013-04-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1257</id><created>2011-08-05</created><updated>2013-04-22</updated><authors><author><keyname>Zhong</keyname><forenames>Yi</forenames></author><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author></authors><title>Multi-channel Hybrid Access Femtocells: A Stochastic Geometric Analysis</title><categories>cs.NI</categories><comments>This is the final version, which was accepted in IEEE Transactions on
  Communications</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  For two-tier networks consisting of macrocells and femtocells, the channel
access mechanism can be configured to be open access, closed access, or hybrid
access. Hybrid access arises as a compromise between open and closed access
mechanisms, in which a fraction of available spectrum resource is shared to
nonsubscribers while the remaining reserved for subscribers. This paper focuses
on a hybrid access mechanism for multi-channel femtocells which employ
orthogonal spectrum access schemes. Considering a randomized channel assignment
strategy, we analyze the performance in the downlink. Using stochastic geometry
as technical tools, we model the distribution of femtocells as Poisson point
process or Neyman-Scott cluster process and derive the distributions of
signal-to-interference-plus-noise ratios, and mean achievable rates, of both
nonsubscribers and subscribers. The established expressions are amenable to
numerical evaluation, and shed key insights into the performance tradeoff
between subscribers and nonsubscribers. The analytical results are corroborated
by numerical simulations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1262</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1262</id><created>2011-08-05</created><authors><author><keyname>Guerv&#xf3;s</keyname><forenames>Juan Juli&#xe1;n Merelo</forenames></author><author><keyname>Cotta</keyname><forenames>Carlos</forenames></author><author><keyname>Mora</keyname><forenames>Antonio M.</forenames></author></authors><title>1st International Workshop on Complex Systems in Sports - Proceedings</title><categories>cs.SI physics.soc-ph</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Online proceedings for the first workshop on complex systems in sports; index
pointing to the papers that will be presented and discussed in that workshop.
The papers deal with sports from a complex systems point of view, and include
papers on a network analysis of the performance of the Spanish team in the 2010
world cup and basketball scoring, study of populations of sports fans, try to
select attributes for sports forecasting and finally try to analyze the
physical condition from the perspective of complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1275</identifier>
 <datestamp>2015-05-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1275</id><created>2011-08-05</created><authors><author><keyname>Blythe</keyname><forenames>R. A.</forenames></author></authors><title>Neutral evolution: A null model for language dynamics</title><categories>physics.soc-ph cs.SI</categories><comments>20 pages, 2 figures. To appear in a special issue of ACS - Advances
  in Complex Systems on language dynamics</comments><journal-ref>ACS - Advances in Complex Systems (2012) 15 1150015</journal-ref><doi>10.1142/S0219525911003414</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review the task of aligning simple models for language dynamics with
relevant empirical data, motivated by the fact that this is rarely attempted in
practice despite an abundance of abstract models. We propose that one way to
meet this challenge is through the careful construction of null models. We
argue in particular that rejection of a null model must have important
consequences for theories about language dynamics if modelling is truly to be
worthwhile. Our main claim is that the stochastic process of neutral evolution
(also known as genetic drift or random copying) is a viable null model for
language dynamics. We survey empirical evidence in favour and against neutral
evolution as a mechanism behind historical language changes, highlighting the
theoretical implications in each case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1301</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1301</id><created>2011-08-05</created><authors><author><keyname>Sun</keyname><forenames>Yao</forenames></author><author><keyname>Wang</keyname><forenames>Dingkang</forenames></author></authors><title>Solving Detachability Problem for the Polynomial Ring by Signature-based
  Groebner Basis Algorithms</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Signature-based algorithms are a popular kind of algorithms for computing
Groebner basis, including the famous F5 algorithm, F5C, extended F5, G2V and
the GVW algorithm. In this paper, an efficient method is proposed to solve the
detachability problem. The new method only uses the outputs of signature-based
algorithms, and no extra Groebner basis computations are needed. When a
Groebner basis is obtained by signature-based algorithms, the detachability
problem can be settled in polynomial time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1302</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1302</id><created>2011-08-05</created><authors><author><keyname>Das</keyname><forenames>Ashok Kumar</forenames></author></authors><title>A Key Establishment Scheme for Mobile Wireless Sensor Networks Using
  Post-Deployment Knowledge</title><categories>cs.CR</categories><comments>Published in International Journal of Computer Networks &amp;
  Communications (IJCNC) Vol.3, No.4, July 2011</comments><doi>10.5121/ijcnc.2011.3405</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Establishment of pairwise keys between sensor nodes in a sensor network is a
difficult problem due to resource limitations of sensor nodes as well as
vulnerability to physical captures of sensor nodes by the enemy. Public-key
cryptosystems are not much suited for most resource-constrained sensor
networks. Recently, elliptic curve cryptographic techniques show that public
key cryptosystem is also feasible for resource-constrained sensor networks.
However, most researchers accept that the symmetric key cryptosystems are
viable options for resource-constrained sensor networks. In this paper, we
first develop a basic principle to address the key pre-distribution problem in
mobile sensor networks. Then, using this developed basic principle, we propose
a scheme which takes the advantage of the post-deployment knowledge. Our scheme
is a modified version of the key prioritization technique proposed by Liu and
Ning. Our improved scheme provides reasonable network connectivity and
security. Moreover, the proposed scheme works for any deployment topology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1314</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1314</id><created>2011-08-05</created><authors><author><keyname>Karimi</keyname><forenames>Oldooz</forenames></author></authors><title>Security Model For Service-Oriented Architecture</title><categories>cs.SE</categories><comments>11 page,3 figures</comments><journal-ref>Advanced Computing: An International Journal (ACIJ), Vol.2, No.4,
  July 2011, 48-58</journal-ref><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  In this article, we examine how security applies to Service Oriented
Architecture (SOA). Before we discuss security for SOA, lets take a step back
and examine what SOA is. SOA is an architectural approach which involves
applications being exposed as &quot;services&quot;. Originally, services in SOA were
associated with a stack of technologies which included SOAP, WSDL, and UDDI.
This article addresses the defects of traditional enterprise application
integration by combining service oriented-architecture and web service
technology. Application integration is then simplified to development and
integration of services to tackle connectivity of isomerous enterprise
application integration, security, loose coupling between systems and process
refactoring and optimization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1320</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1320</id><created>2011-08-05</created><updated>2011-11-28</updated><authors><author><keyname>Pagh</keyname><forenames>Rasmus</forenames></author></authors><title>Compressed Matrix Multiplication</title><categories>cs.DS math.NA stat.CO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by the problems of computing sample covariance matrices, and of
transforming a collection of vectors to a basis where they are sparse, we
present a simple algorithm that computes an approximation of the product of two
n-by-n real matrices A and B. Let ||AB||_F denote the Frobenius norm of AB, and
b be a parameter determining the time/accuracy trade-off. Given 2-wise
independent hash functions $_1,h_2: [n] -&gt; [b], and s_1,s_2: [n] -&gt; {-1,+1} the
algorithm works by first &quot;compressing&quot; the matrix product into the polynomial
p(x) = sum_{k=1}^n (sum_{i=1}^n A_{ik} s_1(i) x^{h_1(i)}) (sum_{j=1}^n B_{kj}
s_2(j) x^{h_2(j)})
  Using FFT for polynomial multiplication, we can compute c_0,...,c_{b-1} such
that sum_i c_i x^i = (p(x) mod x^b) + (p(x) div x^b) in time \~O(n^2+ n b).
  An unbiased estimator of (AB)_{ij} with variance at most ||AB||_F^2 / b can
then be computed as:
  C_{ij} = s_1(i) s_2(j) c_{(h_1(i)+h_2(j)) mod b.
  Our approach also leads to an algorithm for computing AB exactly, whp., in
time \~O(N + nb) in the case where A and B have at most N nonzero entries, and
AB has at most b nonzero entries.
  Also, we use error-correcting codes in a novel way to recover significant
entries of AB in near-linear time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1321</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1321</id><created>2011-08-05</created><authors><author><keyname>Semwal</keyname><forenames>Vijay Bhaskar</forenames></author><author><keyname>Kumar</keyname><forenames>K Susheel</forenames></author><author><keyname>Bhaskar</keyname><forenames>Vinay S</forenames></author><author><keyname>Sati</keyname><forenames>Meenakshi</forenames></author></authors><title>Accurate location estimation of moving object with energy constraint &amp;
  adaptive update algorithms to save data</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In research paper &quot;Accurate estimation of the target location of object with
energy constraint &amp; Adaptive Update Algorithms to Save Data&quot; one of the central
issues in sensor networks is track the location, of moving object which have
overhead of saving data, an accurate estimation of the target location of
object with energy constraint .We do not have any mechanism which control and
maintain data .The wireless communication bandwidth is also very limited. Some
field which is using this technique are flood and typhoon detection, forest
fire detection, temperature and humidity and ones we have these information use
these information back to a central air conditioning and ventilation system. In
this research paper, we propose protocol based on the prediction and adaptive
based algorithm which is using less sensor node reduced by an accurate
estimation of the target location. we are using minimum three sensor node to
get the accurate position .We can extend it upto four or five to find more
accurate location but we have energy constraint so we are using three with
accurate estimation of location help us to reduce sensor node..We show that our
tracking method performs well in terms of energy saving regardless of mobility
pattern of the mobile target .We extends the life time of network with less
sensor node. Once a new object is detected, a mobile agent will be initiated to
track the roaming path of the object. The agent is mobile since it will choose
the sensor closest to the object to stay. The agent may invite some nearby
slave sensors to cooperatively position the object and inhibit other irrelevant
(i.e., farther) sensors from tracking the object. As a result, the
communication and sensing overheads are greatly reduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1325</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1325</id><created>2011-08-05</created><authors><author><keyname>Gualdi</keyname><forenames>S.</forenames></author><author><keyname>Yeung</keyname><forenames>C. H.</forenames></author><author><keyname>Zhang</keyname><forenames>Y. -C.</forenames></author></authors><title>Tracing the Evolution of Physics on the Backbone of Citation Networks</title><categories>physics.soc-ph cs.DL</categories><comments>6 pages, 5 figures</comments><journal-ref>Phys. Rev. E 84, 046104 (2011)</journal-ref><doi>10.1103/PhysRevE.84.046104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many innovations are inspired by past ideas in a non-trivial way. Tracing
these origins and identifying scientific branches is crucial for research
inspirations. In this paper, we use citation relations to identify the
descendant chart, i.e. the family tree of research papers. Unlike other
spanning trees which focus on cost or distance minimization, we make use of the
nature of citations and identify the most important parent for each
publication, leading to a tree-like backbone of the citation network. Measures
are introduced to validate the backbone as the descendant chart. We show that
citation backbones can well characterize the hierarchical and fractal structure
of scientific development, and lead to accurate classification of fields and
sub-fields.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1331</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1331</id><created>2011-08-05</created><updated>2011-08-13</updated><authors><author><keyname>Miki</keyname><forenames>Masaaki</forenames></author></authors><title>Three-term Method and Dual Estimate on Static Problems of Continuum
  Bodies</title><categories>cs.CE math.OC</categories><comments>This work explains the method to generate the animations uploaded
  to:http://www.flickr.com/photos/mikity/sets/72157623397071718/ and
  http://www.flickr.com/photos/mikity/sets/72157625847736003/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work aims to provide standard formulations for direct minimization
approaches on various types of static problems of continuum mechanics.
Particularly, form-finding problems of tension structures are discussed in the
first half and the large deformation problems of continuum bodies are discussed
in the last half. In the first half, as the standards of iterative direct
minimization strategies, two types of simple recursive methods are presented,
namely the two-term method and the three-term method. The dual estimate is also
introduced as a powerful means of involving equally constraint conditions into
minimization problems. As examples of direct minimization approaches on usual
engineering issues, some form finding problems of tension structures which can
be solved by the presented strategies are illustrated. Additionally, it is
pointed out that while the two-term method sometimes becomes useless, the
three-term method always provides remarkable rate of global convergence
efficiency. Then, to show the potential ability of the three-term method, in
the last part of this work, some principle of virtual works which usually
appear in the continuum mechanics are approximated and discretized in a common
manner, which are suitable to be solved by the three-term method. Finally, some
large deformation analyses of continuum bodies which can be solved by the
three-term method are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1334</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1334</id><created>2011-08-05</created><authors><author><keyname>Slimane</keyname><forenames>Zohra</forenames></author><author><keyname>Abdelmalek</keyname><forenames>Abdelhafid</forenames></author><author><keyname>Feham</keyname><forenames>Mohamed</forenames></author><author><keyname>Taleb-Ahmed</keyname><forenames>Abdelmalik</forenames></author></authors><title>Secure and Robust IPV6 Autoconfiguration Protocol For Mobile Adhoc
  Networks Under Strong Adversarial Model</title><categories>cs.NI cs.CR</categories><journal-ref>IJCNC, pp.208-227, Vol.3, No.4, July 2011</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Automatic IP address assignment in Mobile Ad hoc Networks (MANETs) enables
nodes to obtain routable addresses without any infrastructure. Different
protocols have been developed throughout the last years to achieve this
service. However, research primarily focused on correctness, efficiency and
scalability; much less attention has been given to the security issues. The
lack of security in the design of such protocols opens the possibility of many
real threats leading to serious attacks in potentially hostile environments.
Recently, few schemes have been proposed to solve this problem, but none of
them has brought satisfactory solutions. Auto-configuration security issues are
still an open problem. In this paper, a robust and secure stateful IP address
allocation protocol for standalone MANETs is specified and evaluated within
NS2. Our solution is based on mutual authentication, and a fully distributed
Autoconfiguration and CA model, in conjunction with threshold cryptography. By
deploying a new concept of joint IP address and public key certificate, we show
that, instead of earlier approaches, our solution solves the problem of all
possible attacks associated with dynamic IP address assignment in MANETs. The
resulting protocol incurs low latency and control overhead
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1341</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1341</id><created>2011-08-05</created><authors><author><keyname>Zhao</keyname><forenames>Bingxuan</forenames></author><author><keyname>Shimamoto</keyname><forenames>Shigeru</forenames></author></authors><title>Two-stage coordination multi-radio multi-channel mac protocol for
  wireless mesh networks</title><categories>cs.NI</categories><comments>18 pages 9 figures</comments><journal-ref>International Journal of Computer Networks &amp; Communications
  (IJCNC), Vol.3, No.4, July 2011, pp.99-116</journal-ref><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Within the wireless mesh network, a bottleneck problem arises as the number
of concurrent traffic flows (NCTF) increases over a single common control
channel, as it is for most conventional networks. To alleviate this problem,
this paper proposes a two-stage coordination multi-radio multi-channel MAC
(TSC-M2MAC) protocol that designates all available channels as both control
channels and data channels in a time division manner through a two-stage
coordination. At the first stage, a load balancing breadth-first-search-based
vertex coloring algorithm for multi-radio conflict graph is proposed to
intelligently allocate multiple control channels. At the second stage, a
REQ/ACK/RES mechanism is proposed to realize dynamical channel allocation for
data transmission. At this stage, the Channel-and-Radio Utilization Structure
(CRUS) maintained by each node is able to alleviate the hidden nodes problem;
also, the proposed adaptive adjustment algorithm for the Channel Negotiation
and Allocation (CNA) sub-interval is able to cope with the variation of NCTF.
In addition, we design a power saving mechanism for the TSC-M2MAC to decrease
its energy consumption. Simulation results show that the proposed protocol is
able to achieve higher throughput and lower end-to-end packet delay than
conventional schemes. They also show that the TSC-M2MAC can achieve load
balancing, save energy, and remain stable when the network becomes saturated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1343</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1343</id><created>2011-08-05</created><authors><author><keyname>Chen</keyname><forenames>Ruichuan</forenames></author><author><keyname>Lua</keyname><forenames>Eng Keong</forenames></author><author><keyname>Cai</keyname><forenames>Zhuhua</forenames></author><author><keyname>Crowcroft</keyname><forenames>Jon</forenames></author><author><keyname>Chen</keyname><forenames>Zhong</forenames></author></authors><title>Green: Towards a Pollution-Free Peer-to-Peer Content Sharing Service</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-Peer (P2P) content sharing systems are susceptible to the content
pollution attack, in which attackers aggressively inject polluted contents into
the systems to reduce the availability of authentic contents, thus decreasing
the confidence of participating users.
  In this paper, we design a pollution-free P2P content sharing system, Green,
by exploiting the inherent content-based information and the social-based
reputation. In Green, a content provider (i.e., creator or sharer) publishes
the information of his shared contents to a group of content maintainers
self-organized in a security overlay for providing the mechanisms of redundancy
and reliability, so that a content requestor can obtain and filter the
information of his requested content from the associated maintainers. We employ
a reputation model to help the requestor better identify the polluted contents,
and then utilize the social (friend-related) information to enhance the
effectiveness and efficiency of our reputation model. Now, the requestor could
easily select an authentic content version for downloading. While downloading,
each requestor performs a realtime integrity verification and takes prompt
protection to handle the content pollution. To further improve the system
performance, we devise a scalable probabilistic verification scheme.
  Green is broadly applicable for both structured and unstructured overlay
applications, and moreover, it is able to defeat various kinds of content
pollution attacks without incurring significant overhead on the participating
users. The evaluation in massive-scale networks validates the success of Green
against the content pollution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1344</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1344</id><created>2011-08-05</created><authors><author><keyname>Stojanovski</keyname><forenames>Nenad</forenames></author><author><keyname>Gusev</keyname><forenames>Marjan</forenames></author></authors><title>Architecture Of A Identity Based Firewall System</title><categories>cs.CR</categories><comments>9 pages, 3 figures, 1 table; (ISSN: 0975- 2307); International
  Journal of Network Security &amp; Its Applications July 2011, Volume 3, Number 4</comments><doi>10.5121/ijnsa</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classic firewall systems are built to filter traffic based on IP addresses,
source and destination ports and protocol types. The modern networks have grown
to a level where the possibility for users' mobility is a must. In such
networks, modern firewalls may introduce such complexity where administration
can become very frustrating since it needs the intervention of a firewall
administrator. The solution for this problem is an identity based firewall
system. In this paper we will present a new design of a firewall system that
uses the user's identity to filter the traffic. In the design phase we will
define key points which have to be satisfied as a crucial milestone for the
functioning of the whole Identity based firewall system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1350</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1350</id><created>2011-08-05</created><authors><author><keyname>Chen</keyname><forenames>Ruichuan</forenames></author><author><keyname>Lua</keyname><forenames>Eng Keong</forenames></author><author><keyname>Crowcroft</keyname><forenames>Jon</forenames></author><author><keyname>Tang</keyname><forenames>Liyong</forenames></author><author><keyname>Chen</keyname><forenames>Zhong</forenames></author></authors><title>Phagocytes: A Holistic Defense and Protection Against Active P2P Worms</title><categories>cs.NI cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Active Peer-to-Peer (P2P) worms present serious threats to the global
Internet by exploiting popular P2P applications to perform rapid topological
self-propagation. Active P2P worms pose more deadly threats than normal
scanning worms because they do not exhibit easily detectable anomalies, thus
many existing defenses are no longer effective.
  We propose an immunity system with Phagocytes --- a small subset of elected
P2P hosts that are immune with high probability and specialized in finding and
&quot;eating&quot; worms in the P2P overlay. The Phagocytes will monitor their managed
P2P hosts' connection patterns and traffic volume in an attempt to detect
active P2P worm attacks. Once detected, local isolation, alert propagation and
software patching will take place for containment. The Phagocytes further
provide the access control and filtering mechanisms for communication
establishment between the internal P2P overlay and the external hosts. We
design a novel adaptive and interaction-based computational puzzle scheme at
the Phagocytes to restrain external worms attacking the P2P overlay, without
influencing legitimate hosts' experiences significantly. We implement a
prototype system, and evaluate its performance based on realistic massive-scale
P2P network traces. The evaluation results illustrate that our Phagocytes are
capable of achieving a total defense against active P2P worms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1351</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1351</id><created>2011-08-05</created><authors><author><keyname>Salman</keyname><forenames>Raied</forenames></author><author><keyname>Kecman</keyname><forenames>Vojislav</forenames></author><author><keyname>Li</keyname><forenames>Qi</forenames></author><author><keyname>Strack</keyname><forenames>Robert</forenames></author><author><keyname>Test</keyname><forenames>Erik</forenames></author></authors><title>Fast k-means algorithm clustering</title><categories>cs.DS</categories><comments>16 pages, Wimo2011; International Journal of Computer Networks &amp;
  Communications (IJCNC) Vol.3, No.4, July 2011</comments><doi>10.5121/ijcnc.2011.3402</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  k-means has recently been recognized as one of the best algorithms for
clustering unsupervised data. Since k-means depends mainly on distance
calculation between all data points and the centers, the time cost will be high
when the size of the dataset is large (for example more than 500millions of
points). We propose a two stage algorithm to reduce the time cost of distance
calculation for huge datasets. The first stage is a fast distance calculation
using only a small portion of the data to produce the best possible location of
the centers. The second stage is a slow distance calculation in which the
initial centers used are taken from the first stage. The fast and slow stages
represent the speed of the movement of the centers. In the slow stage, the
whole dataset can be used to get the exact location of the centers. The time
cost of the distance calculation for the fast stage is very low due to the
small size of the training data chosen. The time cost of the distance
calculation for the slow stage is also minimized due to small number of
iterations. Different initial locations of the clusters have been used during
the test of the proposed algorithms. For large datasets, experiments show that
the 2-stage clustering method achieves better speed-up (1-9 times).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1352</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1352</id><created>2011-08-05</created><authors><author><keyname>Sasirekha</keyname><forenames>N.</forenames></author><author><keyname>Robert</keyname><forenames>A. Edwin</forenames></author><author><keyname>Hemalatha</keyname><forenames>Dr. M.</forenames></author></authors><title>Program slicing techniques and its applications</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Program understanding is an important aspect in Software Maintenance and
Reengineering. Understanding the program is related to execution behaviour and
relationship of variable involved in the program. The task of finding all
statements in a program that directly or indirectly influence the value for an
occurrence of a variable gives the set of statements that can affect the value
of a variable at some point in a program is called a program slice. Program
slicing is a technique for extracting parts of computer programs by tracing the
programs' control and data flow related to some data item. This technique is
applicable in various areas such as debugging, program comprehension and
understanding, program integration, cohesion measurement, re-engineering,
maintenance, testing where it is useful to be able to focus on relevant parts
of large programs. This paper focuses on the various slicing techniques (not
limited to) like static slicing, quasi static slicing, dynamic slicing and
conditional slicing. This paper also includes various methods in performing the
slicing like forward slicing, backward slicing, syntactic slicing and semantic
slicing. The slicing of a program is carried out using Java which is a object
oriented programming language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1353</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1353</id><created>2011-08-05</created><authors><author><keyname>Kumar</keyname><forenames>K. Susheel</forenames></author><author><keyname>Semwal</keyname><forenames>Vijay Bhaskar</forenames></author><author><keyname>Tripathi</keyname><forenames>R C</forenames></author></authors><title>Real time face recognition using adaboost improved fast PCA algorithm</title><categories>cs.CV</categories><comments>14 pages; ISSN : 0975-900X (Online), 0976-2191 (Print)</comments><journal-ref>International Journal of Artificial Intelligence &amp; Applications
  (IJAIA), Vol.2, No.3, July 2011, 45-58</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an automated system for human face recognition in a real
time background world for a large homemade dataset of persons face. The task is
very difficult as the real time background subtraction in an image is still a
challenge. Addition to this there is a huge variation in human face image in
terms of size, pose and expression. The system proposed collapses most of this
variance. To detect real time human face AdaBoost with Haar cascade is used and
a simple fast PCA and LDA is used to recognize the faces detected. The matched
face is then used to mark attendance in the laboratory, in our case. This
biometric system is a real time attendance system based on the human face
recognition with a simple and fast algorithms and gaining a high accuracy
rate..
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1361</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1361</id><created>2011-08-05</created><authors><author><keyname>Martin</keyname><forenames>E</forenames></author><author><keyname>Bajcsy</keyname><forenames>R</forenames></author></authors><title>Variability of location management costs with different mobilities and
  timer periods to update locations</title><categories>cs.SI</categories><comments>ijcnc 2011, 3, 4</comments><doi>10.5121/ijcnc</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we examine the Location Management costs in mobile
communication networks utilizing the timer-based method. From the study of the
probabilities that a mobile terminal changes a number of Location Areas between
two calls, we identify a threshold value of 0.7 for the Call-to-Mobility Ratio
(CMR) below which the application of the timer-based method is most
appropriate. We characterize the valley appearing in the evolution of the costs
with the timeout period, showing that the time interval required to reach 90%
of the stabilized costs grows with the mobility index, the paging cost per
Location Area and the movement dimension, in opposition to the behavior
presented by the time interval that achieves the minimum of the costs. The
results obtained for CMRs below the suggested 0.7 threshold show that the
valley appearing in the costs tends to disappear for CMRs within [0.001, 0.7]
in onedimensional movements and within [0.2, 0.7] in two-dimensional ones, and
when the normalized paging cost per Location Area is below 0.3.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1367</identifier>
 <datestamp>2014-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1367</id><created>2011-08-05</created><authors><author><keyname>Martin</keyname><forenames>E</forenames></author><author><keyname>Bajcsy</keyname><forenames>R</forenames></author></authors><title>Savings in location management costs leveraging user statistics</title><categories>cs.NI cs.SI</categories><comments>IJU, 2011, 2, 3</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The growth in the number of users in mobile communications networks and the
rise in the traffic generated by each user, are responsible for the increasing
importance of Mobility Management. Within Mobility Management, the main
objective of Location Management is to enable the roaming of the user in the
coverage area. In this paper, we analyze the savings in Location Management
costs obtained leveraging the users' statistics, in comparison with the
classical strategy. In particular, we introduce two novel algorithms to obtain
the Beta parameters (useful terms in the calculation of location update costs
for different Location Management strategies), utilizing a geographical study
of relative positions of the cells within the location areas. Eventually, we
discuss the influence of the different network parameters on the total Location
Management costs savings for both the radio interface and the fixed network
part, providing useful guidelines for the optimum design of the networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1377</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1377</id><created>2011-08-05</created><updated>2012-03-03</updated><authors><author><keyname>Arya</keyname><forenames>Vijay</forenames></author><author><keyname>Veitch</keyname><forenames>Darryl</forenames></author></authors><title>Sparsity without the Complexity: Loss Localisation using Tree
  Measurements</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study network loss tomography based on observing average loss rates over a
set of paths forming a tree -- a severely underdetermined linear problem for
the unknown link loss probabilities. We examine in detail the role of sparsity
as a regularising principle, pointing out that the problem is technically
distinct from others in the compressed sensing literature. While sparsity has
been applied in the context of tomography, key questions regarding uniqueness
and recovery remain unanswered. Our work exploits the tree structure of path
measurements to derive sufficient conditions for sparse solutions to be unique
and the condition that $\ell_1$ minimization recovers the true underlying
solution. We present a fast single-pass linear algorithm for $\ell_1$
minimization and prove that a minimum $\ell_1$ solution is both unique and
sparsest for tree topologies. By considering the placement of lossy links
within trees, we show that sparse solutions remain unique more often than is
commonly supposed. We prove similar results for a noisy version of the problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1378</identifier>
 <datestamp>2011-08-08</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1378</id><created>2011-08-05</created><authors><author><keyname>Ismail</keyname><forenames>Anis</forenames></author><author><keyname>Quafafou</keyname><forenames>Mohamed</forenames></author><author><keyname>Durand</keyname><forenames>Nicolas</forenames></author><author><keyname>Hajjar</keyname><forenames>Mohammad</forenames></author></authors><title>An Efficient Architecture for Information Retrieval in P2P Context Using
  Hypergraph</title><categories>cs.DB cs.PF</categories><comments>2o pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Peer-to-peer (P2P) Data-sharing systems now generate a significant portion of
Internet traffic. P2P systems have emerged as an accepted way to share enormous
volumes of data. Needs for widely distributed information systems supporting
virtual organizations have given rise to a new category of P2P systems called
schema-based. In such systems each peer is a database management system in
itself, ex-posing its own schema. In such a setting, the main objective is the
efficient search across peer databases by processing each incoming query
without overly consuming bandwidth. The usability of these systems depends on
successful techniques to find and retrieve data; however, efficient and
effective routing of content-based queries is an emerging problem in P2P
networks. This work was attended as an attempt to motivate the use of mining
algorithms in the P2P context may improve the significantly the efficiency of
such methods. Our proposed method based respectively on combination of
clustering with hypergraphs. We use ECCLAT to build approximate clustering and
discovering meaningful clusters with slight overlapping. We use an algorithm
MTMINER to extract all minimal transversals of a hypergraph (clusters) for
query routing. The set of clusters improves the robustness in queries routing
mechanism and scalability in P2P Network. We compare the performance of our
method with the baseline one considering the queries routing problem. Our
experimental results prove that our proposed methods generate impressive levels
of performance and scalability with with respect to important criteria such as
response time, precision and recall.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1410</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1410</id><created>2011-08-05</created><authors><author><keyname>Jakovetic</keyname><forenames>Dusan</forenames></author><author><keyname>Moura</keyname><forenames>Jose M. F.</forenames></author><author><keyname>Xavier</keyname><forenames>Joao</forenames></author></authors><title>Distributed Detection over Noisy Networks: Large Deviations Analysis</title><categories>cs.IT math.IT</categories><comments>30 pages, journal, submitted August 2nd, 2011</comments><doi>10.1109/TSP.2012.2197395</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the large deviations performance of consensus+innovations
distributed detection over noisy networks, where sensors at a time step k
cooperate with immediate neighbors (consensus) and assimilate their new
observations (innovation.) We show that, even under noisy communication,
\emph{all sensors} can achieve exponential decay e^{-k C_{\mathrm{dis}}} of the
detection error probability, even when certain (or most) sensors cannot detect
the event of interest in isolation. We achieve this by designing a single time
scale stochastic approximation type distributed detector with the optimal
weight sequence {\alpha_k}, by which sensors weigh their neighbors' messages.
The optimal design of {\alpha_k} balances the opposing effects of communication
noise and information flow from neighbors: larger, slowly decaying \alpha_k
improves information flow but injects more communication noise. Further, we
quantify the best achievable C_{\mathrm{dis}} as a function of the sensing
signal and noise, communication noise, and network connectivity. Finally, we
find a threshold on the communication noise power below which a sensor that can
detect the event in isolation still improves its detection by cooperation
through noisy links.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1417</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1417</id><created>2011-08-05</created><authors><author><keyname>Alia</keyname><forenames>Mohammad A.</forenames></author><author><keyname>Hnaif</keyname><forenames>Adnan A.</forenames></author><author><keyname>Al-Anie</keyname><forenames>Hayam K.</forenames></author><author><keyname>Maria</keyname><forenames>Khulood Abu</forenames></author><author><keyname>Manasrah</keyname><forenames>Ahmed M.</forenames></author><author><keyname>Sarwar</keyname><forenames>M. Imran</forenames></author></authors><title>A Novel Header Matching Algorithm for Intrusion Detection Systems</title><categories>cs.CR</categories><comments>15 pages, 7 Figures, 2 Tables</comments><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.4, July 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The evolving necessity of the Internet increases the demand on the bandwidth.
Therefore, this demand opens the doors for the hackers' community to develop
new methods and techniques to gain control over networking systems. Hence, the
intrusion detection systems (IDS) are insufficient to prevent/detect
unauthorized access the network. Network Intrusion Detection System (NIDS) is
one example that still suffers from performance degradation due the increase of
the link speed in today's networks. In This paper we proposed a novel algorithm
to detect the intruders, who's trying to gain access to the network using the
packets header parameters such as; source/destination address,
source/destination port, and protocol without the need to inspect each packet
content looking for signatures/patterns. However, the &quot;Packet Header Matching&quot;
algorithm enhances the overall speed of the matching process between the
incoming packet headers against the rule set. We ran the proposed algorithm to
proof the proposed concept in coping with the traffic arrival speeds and the
various bandwidth demands. The achieved results were of significant enhancement
of the overall performance in terms of detection speed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1419</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1419</id><created>2011-08-05</created><authors><author><keyname>Provillard</keyname><forenames>Julien</forenames></author><author><keyname>Formenti</keyname><forenames>Enrico</forenames></author><author><keyname>Dennunzio</keyname><forenames>Alberto</forenames></author></authors><title>Non-uniform cellular automata and distributions of rules</title><categories>cs.FL nlin.CG</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In this paper we study $\nu$-CA on one-dimensional lattice defined over a
finite set of local rules. The main goal is to determine how the local rules
can be mixed to ensure the produced $\nu$-CA has some properties. In a first
part, we give some background for the study of $\nu$-CA. Then surjectivity and
injectivity are studied using a variant of DeBruijn graphs. The next part is
dedicated to the number-conserving property.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1421</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1421</id><created>2011-08-05</created><authors><author><keyname>Yang</keyname><forenames>Sheng</forenames><affiliation>Shitz</affiliation></author><author><keyname>Piantanida</keyname><forenames>Pablo</forenames><affiliation>Shitz</affiliation></author><author><keyname>Kobayashi</keyname><forenames>Mari</forenames><affiliation>Shitz</affiliation></author><author><keyname>Shamai</keyname><forenames>Shlomo</forenames><affiliation>Shitz</affiliation></author></authors><title>On the Secrecy Degrees of Freedom of Multi-Antenna Wiretap Channels with
  Delayed CSIT</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure, 1 table. This work has been presented at ISIT
  2011. The current version fixes several bugs in the Proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The secrecy degrees of freedom (SDoF) of the Gaussian multiple-input and
single-output (MISO) wiretap channel is studied under the assumption that
delayed channel state information (CSI) is available at the transmitter and
each receiver knows its own instantaneous channel. We first show that a
strictly positive SDoF can be guaranteed whenever the transmitter has delayed
CSI (either on the legitimate channel or/and the eavesdropper channel). In
particular, in the case with delayed CSI on both channels, it is shown that the
optimal SDoF is 2/3. We then generalize the result to the two-user Gaussian
MISO broadcast channel with confidential messages and characterize the SDoF
region when the transmitter has delayed CSI of both receivers. Interestingly,
the artificial noise schemes exploiting several time instances are shown to
provide the optimal SDoF region by masking the confidential message to the
unintended receiver while aligning the interference at each receiver.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1425</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1425</id><created>2011-08-05</created><authors><author><keyname>abujassar</keyname><forenames>Radwan</forenames></author><author><keyname>ghanbari</keyname><forenames>Mohammed</forenames></author></authors><title>A Driven Backup Routing Table to Find Alternative Dijoint Path in Ad Hoc
  Wireless</title><categories>cs.NI</categories><comments>10pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The performances of the routing protocols are important since they compute
the primary path between source and destination. In addition, routing protocols
need to detect failure within a short period of time when nodes move to start
updating the routing table in order to find a new primary path to the
destination. Meantime, loss of packets and end-to- end delays will increase
thereby reducing throughput and degrading the performance of the network. This
paper proposes a new algorithm, DBRT (Driven Backup Routing Table), to improve
the existing proactive protocols such as DSDV (Destination Sequenced Distance
Vector) protocol by creating a backup routing table to provide multiple
alternative routes. The DBRT algorithm identifies adjacent nodes for each node
in the same range and then selects one of these as a backup next hop according
to the available path to the destination. The results show that loss of data
packets, throughput and end-to-end delay times between source and destination
are improved. The results show that the new protocol does not degrade the
network's performance despite sending extra messages to construct and update
the new backup routing table. Simulations (using an NS2 simulator) are
undertaken to demonstrate the difference between using a DSDV protocol with or
without the proposed schema.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1426</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1426</id><created>2011-08-05</created><authors><author><keyname>Abujassar</keyname><forenames>Radwan</forenames></author><author><keyname>Ghanbari</keyname><forenames>Mohammed</forenames></author></authors><title>Efficient Algorithms to Enhance Recovery Schema in Link State Protocols</title><categories>cs.NI</categories><comments>15 pages</comments><doi>10.5121/iju.2011.2304</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing demands for real-time applications traffic in net- works
such as video and voice a high convergence time for the existing routing
protocols when failure occurred is required. These applications can be very
sensitive to packet loss when link/node goes down. In this paper, we propose
two algorithms schemas for the link state protocol to reroute the traffic in
two states; first, pre-calculated an alternative and disjoint path with the
primary one from the source to the destination by re-routing traffic through
it, regardless of the locations of failure and the number of failed links.
Second, rerouting the traffic via an alternative path from a node whose local
link is down without the need to wait until the source node knows about the
failure. This is achieved by creating a new backup routing table based on the
original routing table which is computed by the dijkstra algorithm. The goal of
these algorithms is to reduce loss of packets, end-to-end delay time, improve
throughput and avoiding local loop when nodes re-converge the topology in case
of failure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1434</identifier>
 <datestamp>2012-07-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1434</id><created>2011-08-05</created><authors><author><keyname>Chakravarthy</keyname><forenames>ASN</forenames></author><author><keyname>Avadhani</keyname><forenames>P S</forenames></author><author><keyname>Prasad</keyname><forenames>P. E. S. N Krishna</forenames></author><author><keyname>Rajeevand</keyname><forenames>N.</forenames></author><author><keyname>Reddy</keyname><forenames>D. Rajasekhar</forenames></author></authors><title>A Novel Approach for Authenticating Textual or Graphical Passwords Using
  Hopfield Neural Network</title><categories>cs.CR cs.NE</categories><comments>14 pages, 18 figures, published in Advanced Computing: An
  International Journal (ACIJ)</comments><journal-ref>Advanced Computing: An International Journal ( ACIJ ), Vol.2,
  No.4, July 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Password authentication using Hopfield Networks is presented in this paper.
In this paper we discussed the Hopfield Network Scheme for Textual and
graphical passwords, for which input Password will be converted in to
probabilistic values. We observed how to get password authentication using
Probabilistic values for Textual passwords and Graphical passwords. This study
proposes the use of a Hopfield neural network technique for password
authentication. In comparison to existing layered neural network techniques,
the proposed method provides better accuracy and quicker response time to
registration and password changes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1439</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1439</id><created>2011-08-05</created><authors><author><keyname>Kornaropoulos</keyname><forenames>Evgenios M.</forenames></author><author><keyname>Tollis</keyname><forenames>Ioannis G.</forenames></author></authors><title>Weak Dominance Drawings and Linear Extension Diameter</title><categories>cs.DS math.CO</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce the problem of Weak Dominance Drawing for general directed
acyclic graphs and we show the connection with the linear extension diameter of
a partial order P. We present complexity results and bounds.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1440</identifier>
 <datestamp>2011-10-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1440</id><created>2011-08-05</created><updated>2011-10-07</updated><authors><author><keyname>Masuda</keyname><forenames>Naoki</forenames></author></authors><title>Clustering in large networks does not promote upstream reciprocity</title><categories>physics.soc-ph cs.SI</categories><comments>5 figures</comments><journal-ref>PLoS ONE, 6(10), e25190 (2011)</journal-ref><doi>10.1371/journal.pone.0025190</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Upstream reciprocity (also called generalized reciprocity) is a putative
mechanism for cooperation in social dilemma situations with which players help
others when they are helped by somebody else. It is a type of indirect
reciprocity. Although upstream reciprocity is often observed in experiments,
most theories suggest that it is operative only when players form short cycles
such as triangles, implying a small population size, or when it is combined
with other mechanisms that promote cooperation on their own. An expectation is
that real social networks, which are known to be full of triangles and other
short cycles, may accommodate upstream reciprocity. In this study, I extend the
upstream reciprocity game proposed for a directed cycle by Boyd and Richerson
to the case of general networks. The model is not evolutionary and concerns the
conditions under which the unanimity of cooperative players is a Nash
equilibrium. I show that an abundance of triangles or other short cycles in a
network does little to promote upstream reciprocity. Cooperation is less likely
for a larger population size even if triangles are abundant in the network. In
addition, in contrast to the results for evolutionary social dilemma games on
networks, scale-free networks lead to less cooperation than networks with a
homogeneous degree distribution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1441</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1441</id><created>2011-08-05</created><authors><author><keyname>Kim</keyname><forenames>Taejoon</forenames></author><author><keyname>Love</keyname><forenames>David J.</forenames></author><author><keyname>Clerckx</keyname><forenames>Bruno</forenames></author><author><keyname>Hwang</keyname><forenames>Duckdong</forenames></author></authors><title>Spatial Degrees of Freedom of the Multicell MIMO Multiple Access Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, to appear in Globecom 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a homogeneous multiple cellular scenario with multiple users per
cell, i.e., $K\geq 1$ where $K$ denotes the number of users in a cell. In this
scenario, a degrees of freedom outer bound as well as an achievable scheme that
attains the degrees of freedom outer bound of the multicell multiple access
channel (MAC) with constant channel coefficients are investigated. The users
have $M$ antennas, and the base stations are equipped with $N$ antennas. The
found outer bound is general in that it characterizes a degrees of freedom
upper bound for $K\geq 1$ and $L&gt;1$ where $L$ denotes the number of cells. The
achievability of the degrees of freedom outer bound is studied for two cell
case (i.e., L=2). The achievable schemes that attains the degrees of freedom
outer bound for L=2 are based on two approaches. The first scheme is a simple
zero forcing with $M=K\beta+\beta$ and $N=K\beta$, and the second approach is
null space interference alignment with $M=K\beta$ and $N=K\beta+\beta$ where
$\beta&gt;0$ is a positive integer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1445</identifier>
 <datestamp>2012-11-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1445</id><created>2011-08-05</created><updated>2012-11-05</updated><authors><author><keyname>de Brecht</keyname><forenames>Matthew</forenames></author></authors><title>Quasi-Polish Spaces</title><categories>math.LO cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate some basic descriptive set theory for countably based
completely quasi-metrizable topological spaces, which we refer to as
quasi-Polish spaces. These spaces naturally generalize much of the classical
descriptive set theory of Polish spaces to the non-Hausdorff setting. We show
that a subspace of a quasi-Polish space is quasi-Polish if and only if it is
level \Pi_2 in the Borel hierarchy. Quasi-Polish spaces can be characterized
within the framework of Type-2 Theory of Effectivity as precisely the countably
based spaces that have an admissible representation with a Polish domain. They
can also be characterized domain theoretically as precisely the spaces that are
homeomorphic to the subspace of all non-compact elements of an
\omega-continuous domain. Every countably based locally compact sober space is
quasi-Polish, hence every \omega-continuous domain is quasi-Polish. A
metrizable space is quasi-Polish if and only if it is Polish. We show that the
Borel hierarchy on an uncountable quasi-Polish space does not collapse, and
that the Hausdorff-Kuratowski theorem generalizes to all quasi-Polish spaces.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1447</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1447</id><created>2011-08-06</created><authors><author><keyname>Thakurta</keyname><forenames>Rahul</forenames></author><author><keyname>Dasgupta</keyname><forenames>Subhajit</forenames></author></authors><title>Impact of Software Requirement Volatility Pattern on Project Dynamics:
  Evidences from a Case Study</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Requirements are found to change in various ways during the course of a
project. This can affect the process in widely different manner and extent.
Here we present a case study where-in we investigate the impact of requirement
volatility pattern on project performance. The project setting described in the
case is emulated on a validated system dynamics model representing the
waterfall model. The findings indicate deviations in project outcome from the
estimated thereby corroborating to previous findings. The results reinforce the
applicability of system dynamics approach to analyze project performance under
requirement volatility, which is expected to speed up adoption of the same in
organizations and in the process contribute to more project successes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1452</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1452</id><created>2011-08-06</created><authors><author><keyname>Aceto</keyname><forenames>Luca</forenames><affiliation>Reykjavik University</affiliation></author><author><keyname>Mousavi</keyname><forenames>Mohammad Reza</forenames><affiliation>Eindhoven University of Technology</affiliation></author></authors><title>Proceedings First International Workshop on Process Algebra and
  Coordination</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 60, 2011</journal-ref><doi>10.4204/EPTCS.60</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Process algebra provides abstract and rigorous means for studying
communicating concurrent systems. Coordination languages also provide abstract
means for the specifying and programming communication of components. Hence,
the two fields seem to have very much in common and the link between these two
research areas have been established formally by means of several translations,
mainly from coordination languages to process algebras. There have also been
proposals of process algebras whose communication policy is inspired by the one
underlying coordination languages.
  The aim of this workshop was to push the state of the art in the study of the
connections between process algebra and coordination languages by bringing
together experts as well as young researchers from the two fields to
communicate their ideas and findings. It includes both contributed and invited
papers that have been presented during the one day meeting on Process Algebra
and Coordination (PACO 2011) which took place on June 9, 2011 in Reykjavik,
Iceland.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1456</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1456</id><created>2011-08-06</created><authors><author><keyname>Zhang</keyname><forenames>Feng</forenames></author><author><keyname>Zhang</keyname><forenames>Wenyi</forenames></author><author><keyname>Ling</keyname><forenames>Qiang</forenames></author></authors><title>Non-cooperative Game For Capacity Offload</title><categories>cs.NI cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the blasting increase of wireless data traffic, incumbent wireless
service providers (WSPs) face critical challenges in provisioning spectrum
resource. Given the permission of unlicensed access to TV white spaces, WSPs
can alleviate their burden by exploiting the concept of &quot;capacity offload&quot; to
transfer part of their traffic load to unlicensed spectrum. For such use cases,
a central problem is for WSPs to coexist with others, since all of them may
access the unlicensed spectrum without coordination thus interfering each
other. Game theory provides tools for predicting the behavior of WSPs, and we
formulate the coexistence problem under the framework of non-cooperative games
as a capacity offload game (COG). We show that a COG always possesses at least
one pure-strategy Nash equilibrium (NE), and does not have any mixed-strategy
NE. The analysis provides a full characterization of the structure of the NEs
in two-player COGs. When the game is played repeatedly and each WSP
individually updates its strategy based on its best-response function, the
resulting process forms a best-response dynamic. We establish that, for
two-player COGs, alternating-move best-response dynamics always converge to an
NE, while simultaneous-move best-response dynamics does not always converge to
an NE when multiple NEs exist. When there are more than two players in a COG,
if the network configuration satisfies certain conditions so that the resulting
best-response dynamics become linear, both simultaneous-move and
alternating-move best-response dynamics are guaranteed to converge to the
unique NE.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1461</identifier>
 <datestamp>2015-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1461</id><created>2011-08-06</created><updated>2012-02-08</updated><authors><author><keyname>Vasantrao</keyname><forenames>Kardile Vilas</forenames></author></authors><title>Understanding need of &quot;Uncertainty Analysis&quot; in the system Design
  process</title><categories>cs.SE</categories><comments>11 pages, 2 figures,1 tables</comments><journal-ref>International Journal of Software Engineering &amp; Applications
  (IJSEA), Vol.2, No.3, July 2011, 95-104</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Software project development process is requiring accurate software cost and
schedule estimation for achieve goal or success. A lot it referred to as the
&quot;Intricate brainteaser&quot; because of its conscience attribute which is impact by
complexity and uncertainty, Generally estimation is not as difficult or
puzzling as people think. In fact, generating accurate estimates is
straightforward-once you understand the intensity of uncertainty and module
which contribute itself process. In our everyday life, we enhance our
estimation based on past experience in which problem solve by which method and
in which condition and which opportune provide that method to produce better
result . So, Instead of unexplained treatises and inflexible modeling
techniques, this will guide highlights a proven set of procedures,
understandable formulas, and heuristics that individuals and complete team can
apply to their projects to help achieve estimation ability with choose
appropriate development approaches In the early stage of software life cycle
project manager are inefficient to estimate the effort, schedule, cost
estimation and its development approach .This in turn, confuses the manager to
bid effectively on software project and choose incorrect development approach.
That will directly effect on productivity cycle and increase level of
uncertainty. This becomes a strong cause of project failure. So to avoid such
problem if we know level and sources of uncertainty in model design, It will
directive the developer to design accurate software cost and schedule
estimation. which are require l for software project success. This paper
demonstrates need of uncertainty analysis module at the modeling process for
assist to recognize modular uncertainty system development process and the role
of uncertainty at different stages in the modeling
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1462</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1462</id><created>2011-08-06</created><authors><author><keyname>Tripathy</keyname><forenames>Chitta Ranjan</forenames></author><author><keyname>Adhikari</keyname><forenames>Nibedita</forenames></author></authors><title>On a New Multicomputer Interconnection Topology for Massively Parallel
  Systems</title><categories>cs.DC</categories><comments>16 pages, 11 figures</comments><journal-ref>International Journal of Distributed and Parallel Systems,Vol2,
  No.4,July2011</journal-ref><doi>10.5121/ijdps.2011.2414</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces a new interconnection network topology called Balanced
Varietal Hypercube (BVH), suitable for massively parallel systems. The proposed
topology being a hybrid structure retains almost all the attractive properties
of Balanced Hypercube and Varietal Hypercube. The topology, various parameters,
routing and broadcasting of Balanced Varietal Hypercube are presented. The
performance of the Balanced Varietal Hypercube is compared with other networks.
In terms of diameter, cost and average distance and reliability the proposed
network is found to be better than the Hypercube, Balanced Hypercube and
Varietal Hypercube. Also it is more reliable and cost-effective than Hypercube
and Balanced Hypercube.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1464</identifier>
 <datestamp>2012-11-28</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1464</id><created>2011-08-06</created><updated>2012-11-27</updated><authors><author><keyname>Prattichizzo</keyname><forenames>Domenico</forenames></author><author><keyname>Pacchierotti</keyname><forenames>Claudio</forenames></author><author><keyname>Rosati</keyname><forenames>Giulio</forenames></author></authors><title>Cutaneous Force Feedback as a Sensory Subtraction Technique in Haptics</title><categories>cs.RO</categories><journal-ref>D. Prattichizzo, C. Pacchierotti, G. Rosati. Cutaneous force
  feedback as a sensory subtraction technique in haptics. IEEE Transactions on
  Haptics, 5(4):289-300, 2012</journal-ref><doi>10.1109/TOH.2012.15</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A novel sensory substitution technique is presented. Kinesthetic and
cutaneous force feedback are substituted by cutaneous feedback (CF) only,
provided by two wearable devices able to apply forces to the index finger and
the thumb, while holding a handle during a teleoperation task. The force
pattern, fed back to the user while using the cutaneous devices, is similar, in
terms of intensity and area of application, to the cutaneous force pattern
applied to the finger pad while interacting with a haptic device providing both
cutaneous and kinesthetic force feedback. The pattern generated using the
cutaneous devices can be thought as a subtraction between the complete haptic
feedback (HF) and the kinesthetic part of it. For this reason, we refer to this
approach as sensory subtraction instead of sensory substitution. A needle
insertion scenario is considered to validate the approach. The haptic device is
connected to a virtual environment simulating a needle insertion task.
Experiments show that the perception of inserting a needle using the
cutaneous-only force feedback is nearly indistinguishable from the one felt by
the user while using both cutaneous and kinesthetic feedback. As most of the
sensory substitution approaches, the proposed sensory subtraction technique
also has the advantage of not suffering from stability issues of teleoperation
systems due, for instance, to communication delays. Moreover, experiments show
that the sensory subtraction technique outperforms sensory substitution with
more conventional visual feedback (VF).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1472</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1472</id><created>2011-08-06</created><authors><author><keyname>Das</keyname><forenames>Lachhman</forenames></author><author><keyname>Arfat</keyname><forenames>Yasir</forenames></author><author><keyname>Shah</keyname><forenames>Azhar</forenames></author><author><keyname>Khoumbati</keyname><forenames>Khalil</forenames></author></authors><title>System Support for Managing Invalid Bindings</title><categories>cs.OH</categories><journal-ref>Lachhman Das Dhomeja, Yasir Arfat Malkani, Azhar Ali Shah and
  Khalil Khoumbati, &quot;System Support For Managing Invalid Bindings&quot;,
  International Journal of UbiComp (IJU), Vol.2, No.3, July 2011</journal-ref><doi>10.5121/iju.2011.2303</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Context-aware adaptation is a central aspect of pervasive computing
applications, enabling them to adapt and perform tasks based on contextual
information. One of the aspects of context-aware adaptation is reconfiguration
in which bindings are created between application component and remote services
in order to realize new behaviour in response to contextual information.
Various research efforts provide reconfiguration support and allow the
development of adaptive context-aware applications from high-level
specifications, but don't consider failure conditions that might arise during
execution of such applications, making bindings between application and remote
services invalid. To this end, we propose and implement our design approach to
reconfiguration to manage invalid bindings. The development and modification of
adaptive context-aware applications is a complex task, and an issue of an
invalidity of bindings further complicates development efforts. To reduce the
development efforts, our approach provides an application-transparent solution
where the issue of the invalidity of bindings is handled by our system,
Policy-Based Contextual Reconfiguration and Adaptation (PCRA), not by an
application developer. In this paper, we present and describe our approach to
managing invalid bindings and compare it with other approaches to this problem.
We also provide performance evaluation of our approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1478</identifier>
 <datestamp>2011-11-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1478</id><created>2011-08-06</created><updated>2011-09-19</updated><authors><author><keyname>Ndoundam</keyname><forenames>Rene</forenames></author><author><keyname>Sadie</keyname><forenames>Juvet Karnel</forenames></author></authors><title>Collision-resistant hash function based on composition of functions</title><categories>cs.CR</categories><comments>18 pages, 1 figure. The preliminary version of this paper was
  published in the Conference CARI'10, pages 141-148, Yamoussoukro, Ivory
  Coast. The preliminary version was also published in the arXiv August 6, 2011
  under number arXiv:1108.1478v1. This version was submittted to the journal
  ARIMA (January 2011)</comments><msc-class>11T71</msc-class><acm-class>D.4.6</acm-class><journal-ref>ARIMA, Vol. 14 - pp. 167-183, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  cryptographic hash function is a deterministic procedure that compresses an
arbitrary block of numerical data and returns a fixed-size bit string. There
exist many hash functions: MD5, HAVAL, SHA, ... It was reported that these hash
functions are not longer secure. Our work is focused in the construction of a
new hash function based on composition of functions. The construction used the
NP-completeness of Three-dimensional contingency tables and the relaxation of
the constraint that a hash function should also be a compression function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1482</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1482</id><created>2011-08-06</created><authors><author><keyname>Triantafyllou</keyname><forenames>Nikolaos</forenames></author><author><keyname>Ksystra</keyname><forenames>Katerina</forenames></author><author><keyname>Stefaneas</keyname><forenames>Petros</forenames></author><author><keyname>Frangos</keyname><forenames>Panayiotis</forenames></author></authors><title>Applying Algebraic Specifications on Digital Right Management Systems</title><categories>cs.LO</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Digital Right Management (DRM) Systems have been created to meet the need for
digital content protection and distribution. In this paper we present some of
the directions of our ongoing research to apply algebraic specification
techniques on mobile DRM systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1486</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1486</id><created>2011-08-06</created><authors><author><keyname>Jin</keyname><forenames>Meng</forenames></author><author><keyname>Li</keyname><forenames>Xiaoliang</forenames></author><author><keyname>Wang</keyname><forenames>Dongming</forenames></author></authors><title>A New Algorithmic Scheme for Computing Characteristic Sets</title><categories>cs.SC math.AC</categories><comments>25 pages, 3 algorithms and 6 tables</comments><msc-class>33F10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ritt-Wu's algorithm of characteristic sets is the most representative for
triangularizing sets of multivariate polynomials. Pseudo-division is the main
operation used in this algorithm. In this paper we present a new algorithmic
scheme for computing generalized characteristic sets by introducing other
admissible reductions than pseudo-division. A concrete subalgorithm is designed
to triangularize polynomial sets using selected admissible reductions and
several effective elimination strategies and to replace the algorithm of basic
sets (used in Ritt-Wu's algorithm). The proposed algorithm has been implemented
and experimental results show that it performs better than Ritt-Wu's algorithm
in terms of computing time and simplicity of output for a number of non-trivial
test examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1488</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1488</id><created>2011-08-06</created><authors><author><keyname>Di Maio</keyname><forenames>P.</forenames></author></authors><title>'Just Enough' Ontology Engineering</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper introduces 'just enough' principles and 'systems engineering'
approach to the practice of ontology development to provide a minimal yet
complete, lightweight, agile and integrated development process, supportive of
stakeholder management and implementation independence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1490</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1490</id><created>2011-08-06</created><authors><author><keyname>Di Maio</keyname><forenames>P.</forenames></author></authors><title>Knowledge Audit Framework</title><categories>cs.OH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  KAF consists of a process and some templates to guide the planning and
execution of audits of knowledge resources, with emphasis on sharing. KAF is
based on methodological blueprint provided by the Data Audit Framework
(DAF)conceived by the JISC-funded DAFD project.KAF enables organisations to
find out what knowledge resources are associated with the project, and how they
are shared.KAF is available in two versionsKAF-g (generic, domain independent)
KAF-se (targets systems enegineering knowledge)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1500</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1500</id><created>2011-08-06</created><authors><author><keyname>Yousefi</keyname><forenames>Sahar</forenames></author><author><keyname>Zahedi</keyname><forenames>Morteza</forenames></author></authors><title>Gender Recognition Based on Sift Features</title><categories>cs.AI cs.CV</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  This paper proposes a robust approach for face detection and gender
classification in color images. Previous researches about gender recognition
suppose an expensive computational and time-consuming pre-processing step in
order to alignment in which face images are aligned so that facial landmarks
like eyes, nose, lips, chin are placed in uniform locations in image. In this
paper, a novel technique based on mathematical analysis is represented in three
stages that eliminates alignment step. First, a new color based face detection
method is represented with a better result and more robustness in complex
backgrounds. Next, the features which are invariant to affine transformations
are extracted from each face using scale invariant feature transform (SIFT)
method. To evaluate the performance of the proposed algorithm, experiments have
been conducted by employing a SVM classifier on a database of face images which
contains 500 images from distinct people with equal ratio of male and female.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1502</identifier>
 <datestamp>2012-02-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1502</id><created>2011-08-06</created><updated>2012-02-10</updated><authors><author><keyname>De Meo</keyname><forenames>Pasquale</forenames></author><author><keyname>Ferrara</keyname><forenames>Emilio</forenames></author><author><keyname>Fiumara</keyname><forenames>Giacomo</forenames></author><author><keyname>Provetti</keyname><forenames>Alessandro</forenames></author></authors><title>Generalized Louvain Method for Community Detection in Large Networks</title><categories>cs.SI physics.soc-ph</categories><comments>6 pages, 1 figure, ISDA '11: 11th International Conference On
  Intelligent Systems Design And Applications, 2011</comments><journal-ref>Proceedings of the 11th International Conference On Intelligent
  Systems Design And Applications, pp. 88-93, 2011</journal-ref><doi>10.1109/ISDA.2011.6121636</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we present a novel strategy to discover the community structure
of (possibly, large) networks. This approach is based on the well-know concept
of network modularity optimization. To do so, our algorithm exploits a novel
measure of edge centrality, based on the k-paths. This technique allows to
efficiently compute a edge ranking in large networks in near linear time. Once
the centrality ranking is calculated, the algorithm computes the pairwise
proximity between nodes of the network. Finally, it discovers the community
structure adopting a strategy inspired by the well-known state-of-the-art
Louvain method (henceforth, LM), efficiently maximizing the network modularity.
The experiments we carried out show that our algorithm outperforms other
techniques and slightly improves results of the original LM, providing reliable
results. Another advantage is that its adoption is naturally extended even to
unweighted networks, differently with respect to the LM.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1510</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1510</id><created>2011-08-06</created><authors><author><keyname>Mahoney</keyname><forenames>John R.</forenames></author><author><keyname>Ellison</keyname><forenames>Christopher J.</forenames></author><author><keyname>James</keyname><forenames>Ryan G.</forenames></author><author><keyname>Crutchfield</keyname><forenames>James P.</forenames></author></authors><title>How Hidden are Hidden Processes? A Primer on Crypticity and Entropy
  Convergence</title><categories>physics.data-an cond-mat.stat-mech cs.IT math.DS math.IT math.ST nlin.CD stat.TH</categories><comments>18 pages, 18 figures;
  http://csc.ucdavis.edu/~cmg/compmech/pubs/iacp2.htm</comments><doi>10.1063/1.3637502</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate a stationary process's crypticity---a measure of the
difference between its hidden state information and its observed
information---using the causal states of computational mechanics. Here, we
motivate crypticity and cryptic order as physically meaningful quantities that
monitor how hidden a hidden process is. This is done by recasting previous
results on the convergence of block entropy and block-state entropy in a
geometric setting, one that is more intuitive and that leads to a number of new
results. For example, we connect crypticity to how an observer synchronizes to
a process. We show that the block-causal-state entropy is a convex function of
block length. We give a complete analysis of spin chains. We present a
classification scheme that surveys stationary processes in terms of their
possible cryptic and Markov orders. We illustrate related entropy convergence
behaviors using a new form of foliated information diagram. Finally, along the
way, we provide a variety of interpretations of crypticity and cryptic order to
establish their naturalness and pervasiveness. Hopefully, these will inspire
new applications in spatially extended and network dynamical systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1522</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1522</id><created>2011-08-06</created><updated>2012-06-17</updated><authors><author><keyname>Wang</keyname><forenames>Fanggang</forenames></author><author><keyname>Liew</keyname><forenames>Soung Chang</forenames></author><author><keyname>Guo</keyname><forenames>Dongning</forenames></author></authors><title>Wireless MIMO Switching with Zero-forcing Relaying and Network-coded
  Relaying</title><categories>cs.IT cs.NI math.IT</categories><comments>This version is to appear in IEEE Journal on Selected Areas in
  Communications later in 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A wireless relay with multiple antennas is called a
multiple-input-multiple-output (MIMO) switch if it maps its input links to its
output links using &quot;precode-and-forward.&quot; Namely, the MIMO switch precodes the
received signal vector in the uplink using some matrix for transmission in the
downlink. This paper studies the scenario of $K$ stations and a MIMO switch,
which has full channel state information. The precoder at the MIMO switch is
either a zero-forcing matrix or a network-coded matrix. With the zero-forcing
precoder, each destination station receives only its desired signal with
enhanced noise but no interference. With the network-coded precoder, each
station receives not only its desired signal and noise, but possibly also
self-interference, which can be perfectly canceled. Precoder design for
optimizing the received signal-to-noise ratios at the destinations is
investigated. For zero-forcing relaying, the problem is solved in closed form
in the two-user case, whereas in the case of more users, efficient algorithms
are proposed and shown to be close to what can be achieved by extensive random
search. For network-coded relaying, we present efficient iterative algorithms
that can boost the throughput further.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1530</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1530</id><created>2011-08-07</created><authors><author><keyname>Orr</keyname><forenames>Ewan</forenames></author><author><keyname>Martin</keyname><forenames>Ben</forenames></author></authors><title>Evolving A-Type Artificial Neural Networks</title><categories>cs.NE</categories><comments>21 pages. To appear in Evolutionary Intelligence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate Turing's notion of an A-type artificial neural network. We
study a refinement of Turing's original idea, motivated by work of Teuscher,
Bull, Preen and Copeland. Our A-types can process binary data by accepting and
outputting sequences of binary vectors; hence we can associate a function to an
A-type, and we say the A-type {\em represents} the function. There are two
modes of data processing: clamped and sequential. We describe an evolutionary
algorithm, involving graph-theoretic manipulations of A-types, which searches
for A-types representing a given function. The algorithm uses both mutation and
crossover operators. We implemented the algorithm and applied it to three
benchmark tasks. We found that the algorithm performed much better than a
random search. For two out of the three tasks, the algorithm with crossover
performed better than a mutation-only version.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1535</identifier>
 <datestamp>2012-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1535</id><created>2011-08-07</created><updated>2012-04-18</updated><authors><author><keyname>Ahmadi</keyname><forenames>Behzad</forenames></author><author><keyname>Simeone</keyname><forenames>Osvaldo</forenames></author></authors><title>Robust Coding for Lossy Computing with Receiver-Side Observation Costs</title><categories>cs.IT math.IT</categories><comments>presented at ISIT 2011, with corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An encoder wishes to minimize the bit rate necessary to guarantee that a
decoder is able to calculate a symbolwise function of a sequence available only
at the encoder and a sequence that can be measured only at the decoder. This
classical problem, first studied by Yamamoto, is addressed here by including
two new aspects: (i) The decoder obtains noisy measurements of its sequence,
where the quality of such measurements can be controlled via a cost-constrained
&quot;action&quot; sequence; (ii) Measurement at the decoder may fail in a way that is
unpredictable to the encoder, thus requiring robust encoding. The considered
scenario generalizes known settings such as the Heegard-Berger-Kaspi and the
&quot;source coding with a vending machine&quot; problems. The rate-distortion-cost
function is derived and numerical examples are also worked out to obtain
further insight into the optimal system design.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1548</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1548</id><created>2011-08-07</created><updated>2013-05-08</updated><authors><author><keyname>Lin</keyname><forenames>Zhouchen</forenames></author></authors><title>Some Software Packages for Partial SVD Computation</title><categories>math.OC cs.MS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This technical report introduces some software packages for partial SVD
computation, including optimized PROPACK, modified PROPACK for computing
singular values above a threshold and the corresponding singular vectors, and
block Lanczos with warm start (BLWS). The current version is preliminary. The
details will be enriched soon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1549</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1549</id><created>2011-08-07</created><authors><author><keyname>Innocenti</keyname><forenames>Giacomo</forenames></author></authors><title>A frequency approach to topological identification and graphical
  modeling</title><categories>cs.SY cs.SI math.OC</categories><comments>Paper presented at the AUTOMATICA_IT 2011 conference, Pisa, Italy,
  September 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This works explores and illustrates recent results developed by the author in
field of dynamical network analysis. The considered approach is blind, i.e., no
a priori assumptions on the interconnected systems are available. Moreover, the
perspective is that of a simple &quot;observer&quot; who can perform no kind of test on
the network in order to study the related response, that is no action or
forcing input aimed to reveal particular responses of the system can be
performed. In such a scenario a frequency based method of investigation is
developed to obtain useful insights on the network. The information thus
derived can be fruitfully exploited to build acyclic graphical models, which
can be seen as extension of Bayesian Networks or Markov Chains. Moreover, it is
shown that the topology of polytree linear networks can be exactly identified
via the same mathematical tools. In this respect, it is worth observing that
important real systems, such as all the transportation networks, fit this
class.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1554</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1554</id><created>2011-08-07</created><authors><author><keyname>Wu</keyname><forenames>Kui</forenames></author><author><keyname>Jiang</keyname><forenames>Yuming</forenames></author><author><keyname>Marinakis</keyname><forenames>Dimitri</forenames></author></authors><title>A Stochastic Calculus for Network Systems with Renewable Energy Sources</title><categories>cs.PF math.PR</categories><comments>10 pages, 1 figure</comments><report-no>DCS342-IR</report-no><acm-class>C.4; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the performance modeling and evaluation of network systems
powered with renewable energy sources such as solar and wind energy. Such
energy sources largely depend on environmental conditions, which are hard to
predict accurately. As such, it may only make sense to require the network
systems to support a soft quality of service (QoS) guarantee, i.e., to
guarantee a service requirement with a certain high probability. In this paper,
we intend to build a solid mathematical foundation to help better understand
the stochastic energy constraint and the inherent correlation between QoS and
the uncertain energy supply. We utilize a calculus approach to model the
cumulative amount of charged energy and the cumulative amount of consumed
energy. We derive upper and lower bounds on the remaining energy level based on
a stochastic energy charging rate and a stochastic energy discharging rate. By
building the bridge between energy consumption and task execution (i.e.,
service), we study the QoS guarantee under the constraint of uncertain energy
sources. We further show how performance bounds can be improved if some strong
assumptions can be made.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1561</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1561</id><created>2011-08-07</created><authors><author><keyname>Bopardikar</keyname><forenames>Shaunak D.</forenames></author><author><keyname>Suri</keyname><forenames>Subhash</forenames></author></authors><title>k-Capture in Multiagent Pursuit Evasion, or the Lion and the Hyenas</title><categories>cs.GT</categories><comments>16 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following generalization of the classical pursuit-evasion
problem, which we call k-capture. A group of n pursuers (hyenas) wish to
capture an evader (lion) who is free to move in an m-dimensional Euclidean
space, the pursuers and the evader can move with the same maximum speed, and at
least k pursuers must simultaneously reach the evader's location to capture it.
If fewer than k pursuers reach the evader, then those pursuers get destroyed by
the evader. Under what conditions can the evader be k-captured? We study this
problem in the discrete time, continuous space model and prove that k-capture
is possible if and only there exists a time when the evader lies in the
interior of the pursuers' k-Hull. When the pursuit occurs inside a compact,
convex subset of the Euclidean space, we show through an easy constructive
strategy that k-capture is always possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1572</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1572</id><created>2011-08-07</created><authors><author><keyname>Tavakoli</keyname><forenames>H.</forenames></author><author><keyname>Attari</keyname><forenames>M. Ahmadian</forenames></author><author><keyname>Peyghami</keyname><forenames>M. Reza</forenames></author></authors><title>Optimal Rate for Irregular LDPC Codes in Binary Erasure Channel</title><categories>cs.IT math.IT</categories><comments>5 pages, to be presented at the 2011 IEEE Information Theory Workshop
  (ITW 2011), Paraty, Brazil, October, 2011</comments><msc-class>94A15</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce a new practical and general method for solving
the main problem of designing the capacity approaching, optimal rate, irregular
low-density parity-check (LDPC) code ensemble over binary erasure channel
(BEC). Compared to some new researches, which are based on application of
asymptotic analysis tools out of optimization process, the proposed method is
much simpler, faster, accurate and practical. Because of not using any
relaxation or any approximate solution like previous works, the found answer
with this method is optimal. We can construct optimal variable node degree
distribution for any given binary erasure rate, {\epsilon}, and any check node
degree distribution. The presented method is implemented and works well in
practice. The time complexity of this method is of polynomial order. As a
result, we obtain some degree distribution which their rates are close to the
capacity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1589</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1589</id><created>2011-08-07</created><authors><author><keyname>Sperl</keyname><forenames>Thomas</forenames></author></authors><title>Imitation of Life: Advanced system for native Artificial Evolution</title><categories>cs.NE q-bio.PE</categories><comments>22 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A model for artificial evolution in native x86 Windows systems has been
developed at the end of 2010. In this text, further improvements and additional
analogies to natural microbiologic processes are presented. Several experiments
indicate the capability of the system - and raise the question of possible
countermeasures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1593</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1593</id><created>2011-08-07</created><authors><author><keyname>Dhinakaran</keyname><forenames>Cynthia</forenames></author><author><keyname>Nagamalai</keyname><forenames>Dhinaharan</forenames></author><author><keyname>Lee</keyname><forenames>Jae Kwang</forenames></author></authors><title>Multilayer Approach to Defend Phishing Attacks</title><categories>cs.CR</categories><comments>8 Pages, Journal of Internet Technology (JIT) 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Spam messes up users inbox, consumes resources and spread attacks like DDoS,
MiM, phishing etc. Phishing is a byproduct of email and causes financial loss
to users and loss of reputation to financial institutions. In this paper we
examine the characteristics of phishing and technology used by Phishers. In
order to counter anti-phishing technology, phishers change their mode of
operation; therefore a continuous evaluation of phishing only helps us combat
phisher effectiveness. In our study, we collected seven hundred thousand spam
from a corporate server for a period of 13 months from February 2008 to
February 2009. From the collected data, we identified different kinds of
phishing scams and mode of operation. Our observation shows that phishers are
dynamic and depend more on social engineering techniques rather than software
vulnerabilities. We believe that this study will develop more efficient
anti-phishing methodologies. Based on our analysis, we developed an
anti-phishing methodology and implemented in our network. The results show that
this approach is highly effective to prevent phishing attacks. The proposed
approach reduced more than 80% of the false negatives and more than 95% of
phishing attacks in our network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1597</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1597</id><created>2011-08-07</created><authors><author><keyname>Deng</keyname><forenames>Ke</forenames></author><author><keyname>Hu</keyname><forenames>Ke</forenames></author><author><keyname>Tang</keyname><forenames>Yi</forenames></author></authors><title>Evolving network models under a dynamic growth rule</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Evolving network models under a dynamic growth rule which comprises the
addition and deletion of nodes are investigated. By adding a node with a
probability $P_a$ or deleting a node with the probability $P_d=1-P_a$ at each
time step, where $P_a$ and $P_d$ are determined by the Logistic population
equation, topological properties of networks are studied. All the fat-tailed
degree distributions observed in real systems are obtained, giving the evidence
that the mechanism of addition and deletion can lead to the diversity of degree
distribution of real systems. Moreover, it is found that the networks exhibit
nonstationary degree distributions, changing from the power-law to the
exponential one or from the exponential to the Gaussian one. These results can
be expected to shed some light on the formation and evolution of real complex
real-world networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1631</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1631</id><created>2011-08-08</created><authors><author><keyname>Kolb</keyname><forenames>Lars</forenames></author><author><keyname>Thor</keyname><forenames>Andreas</forenames></author><author><keyname>Rahm</keyname><forenames>Erhard</forenames></author></authors><title>Load Balancing for MapReduce-based Entity Resolution</title><categories>cs.DC</categories><acm-class>H.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The effectiveness and scalability of MapReduce-based implementations of
complex data-intensive tasks depend on an even redistribution of data between
map and reduce tasks. In the presence of skewed data, sophisticated
redistribution approaches thus become necessary to achieve load balancing among
all reduce tasks to be executed in parallel. For the complex problem of entity
resolution, we propose and evaluate two approaches for such skew handling and
load balancing. The approaches support blocking techniques to reduce the search
space of entity resolution, utilize a preprocessing MapReduce job to analyze
the data distribution, and distribute the entities of large blocks among
multiple reduce tasks. The evaluation on a real cloud infrastructure shows the
value and effectiveness of the proposed load balancing approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1636</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1636</id><created>2011-08-08</created><authors><author><keyname>Zhang</keyname><forenames>Peng</forenames></author><author><keyname>Ren</keyname><forenames>Yuanyuan</forenames></author><author><keyname>Zhang</keyname><forenames>Bo</forenames></author></authors><title>A new embedding quality assessment method for manifold learning</title><categories>cs.CV cs.LG</categories><comments>16 pages, 8 figures, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Manifold learning is a hot research topic in the field of computer science. A
crucial issue with current manifold learning methods is that they lack a
natural quantitative measure to assess the quality of learned embeddings, which
greatly limits their applications to real-world problems. In this paper, a new
embedding quality assessment method for manifold learning, named as
Normalization Independent Embedding Quality Assessment (NIEQA), is proposed.
Compared with current assessment methods which are limited to isometric
embeddings, the NIEQA method has a much larger application range due to two
features. First, it is based on a new measure which can effectively evaluate
how well local neighborhood geometry is preserved under normalization, hence it
can be applied to both isometric and normalized embeddings. Second, it can
provide both local and global evaluations to output an overall assessment.
Therefore, NIEQA can serve as a natural tool in model selection and evaluation
tasks for manifold learning. Experimental results on benchmark data sets
validate the effectiveness of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1645</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1645</id><created>2011-08-08</created><authors><author><keyname>Kim</keyname><forenames>Cheulsoon</forenames></author><author><keyname>Sung</keyname><forenames>Youngchul</forenames></author><author><keyname>Lee</keyname><forenames>Yong H.</forenames></author></authors><title>A joint time-invariant filtering approach to the linear Gaussian relay
  problem</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures</comments><acm-class>E.4; H.1.1</acm-class><doi>10.1109/TSP.2012.2197750</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, the linear Gaussian relay problem is considered. Under the
linear time-invariant (LTI) model the problem is formulated in the frequency
domain based on the Toeplitz distribution theorem. Under the further assumption
of realizable input spectra, the LTI Gaussian relay problem is converted to a
joint design problem of source and relay filters under two power constraints,
one at the source and the other at the relay, and a practical solution to this
problem is proposed based on the projected subgradient method. Numerical
results show that the proposed method yields a noticeable gain over the
instantaneous amplify-and-forward (AF) scheme in inter-symbol interference
(ISI) channels. Also, the optimality of the AF scheme within the class of
one-tap relay filters is established in flat-fading channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1656</identifier>
 <datestamp>2011-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1656</id><created>2011-08-08</created><updated>2011-09-27</updated><authors><author><keyname>Del Genio</keyname><forenames>Charo I.</forenames></author><author><keyname>Gross</keyname><forenames>Thilo</forenames></author></authors><title>Emergent bipartiteness in a society of knights and knaves</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>12 pages, 5 figures</comments><journal-ref>New J. Phys. 13, 103038 (2011)</journal-ref><doi>10.1088/1367-2630/13/10/103038</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a simple model of a social network based on so-called
knights-and-knaves puzzles. The model describes the formation of networks
between two classes of agents where links are formed by agents introducing
their neighbours to others of their own class. We show that if the proportion
of knights and knaves is within a certain range, the network self-organizes to
a perfectly bipartite state. However, if the excess of one of the two classes
is greater than a threshold value, bipartiteness is not observed. We offer a
detailed theoretical analysis for the behaviour of the model, investigate its
behaviou r in the thermodynamic limit, and argue that it provides a simple
example of a topology-driven model whose behaviour is strongly reminiscent of a
first-order phase transitions far from equilibrium.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1676</identifier>
 <datestamp>2011-12-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1676</id><created>2011-08-08</created><updated>2011-12-14</updated><authors><author><keyname>Vaze</keyname><forenames>Rahul</forenames></author><author><keyname>Ganapathy</keyname><forenames>Harish</forenames></author></authors><title>Sub-modularity and Antenna Selection in MIMO systems</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we show that the optimal receive antenna subset selection
problem for maximizing the mutual information in a point-to-point MIMO system
is sub-modular. Consequently, a greedy step-wise optimization approach, where
at each step an antenna that maximizes the incremental gain is added to the
existing antenna subset, is guaranteed to be within a (1 - 1/e) fraction of the
global optimal value. For a single antenna equipped source and destination with
multiple relays, we show that the relay antenna selection problem to maximize
the mutual information is modular, when complete channel state information is
available at the relays. As a result a greedy step-wise optimization approach
leads to an optimal solution for the relay antenna selection problem with
linear complexity in comparison to the brute force search that incurs
exponential complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1689</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1689</id><created>2011-08-08</created><authors><author><keyname>Mommer</keyname><forenames>M. S.</forenames></author><author><keyname>Sommer</keyname><forenames>A.</forenames></author><author><keyname>Schl&#xf6;der</keyname><forenames>J. P.</forenames></author><author><keyname>Bock</keyname><forenames>H. G.</forenames></author></authors><title>A nonlinear preconditioner for experimental design problems</title><categories>math.OC cs.SY</categories><comments>11 pages, 5 figures</comments><msc-class>90C30, 90C55, 62K99</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We address the slow convergence and poor stability of quasi-newton sequential
quadratic programming (SQP) methods that is observed when solving experimental
design problems, in particular when they are large. Our findings suggest that
this behavior is due to the fact that these problems often have bad absolute
condition numbers. To shed light onto the structure of the problem close to the
solution, we formulate a model problem (based on the $A$-criterion), that is
defined in terms of a given initial design that is to be improved. We prove
that the absolute condition number of the model problem grows without bounds as
the quality of the initial design improves. Additionally, we devise a
preconditioner that ensures that the condition number will instead stay
uniformly bounded. Using numerical experiments, we study the effect of this
reformulation on relevant cases of the general problem, and find that it leads
to significant improvements in stability and convergence behavior.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1695</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1695</id><created>2011-08-08</created><updated>2013-07-03</updated><authors><author><keyname>Feng</keyname><forenames>Chen</forenames></author><author><keyname>Silva</keyname><forenames>Danilo</forenames></author><author><keyname>Kschischang</keyname><forenames>Frank R.</forenames></author></authors><title>Algebraic Approach to Physical-Layer Network Coding</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, July 21, 2011.
  Revised version submitted Sept. 17, 2012. Final version submitted July 3,
  2013</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of designing physical-layer network coding (PNC) schemes via
nested lattices is considered. Building on the compute-and-forward (C&amp;F)
relaying strategy of Nazer and Gastpar, who demonstrated its asymptotic gain
using information-theoretic tools, an algebraic approach is taken to show its
potential in practical, non-asymptotic, settings. A general framework is
developed for studying nested-lattice-based PNC schemes---called lattice
network coding (LNC) schemes for short---by making a direct connection between
C&amp;F and module theory. In particular, a generic LNC scheme is presented that
makes no assumptions on the underlying nested lattice code. C&amp;F is
re-interpreted in this framework, and several generalized constructions of LNC
schemes are given. The generic LNC scheme naturally leads to a linear network
coding channel over modules, based on which non-coherent network coding can be
achieved. Next, performance/complexity tradeoffs of LNC schemes are studied,
with a particular focus on hypercube-shaped LNC schemes. The error probability
of this class of LNC schemes is largely determined by the minimum inter-coset
distances of the underlying nested lattice code. Several illustrative
hypercube-shaped LNC schemes are designed based on Construction A and D,
showing that nominal coding gains of 3 to 7.5 dB can be obtained with
reasonable decoding complexity. Finally, the possibility of decoding multiple
linear combinations is considered and related to the shortest independent
vectors problem. A notion of dominant solutions is developed together with a
suitable lattice-reduction-based algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1718</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1718</id><created>2011-08-08</created><authors><author><keyname>Hjelme</keyname><forenames>Dag Roar</forenames></author><author><keyname>Lydersen</keyname><forenames>Lars</forenames></author><author><keyname>Makarov</keyname><forenames>Vadim</forenames></author></authors><title>Quantum cryptography</title><categories>quant-ph cs.CR</categories><comments>16 pages, 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This is a chapter on quantum cryptography for the book &quot;A Multidisciplinary
Introduction to Information Security&quot; to be published by CRC Press in
2011/2012. The chapter aims to introduce the topic to undergraduate-level and
continuing-education students specializing in information and communication
technology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1730</identifier>
 <datestamp>2012-03-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1730</id><created>2011-08-08</created><updated>2012-03-23</updated><authors><author><keyname>Kreitmeier</keyname><forenames>Wolfgang</forenames></author><author><keyname>Linder</keyname><forenames>Tamas</forenames></author></authors><title>Entropy Density and Mismatch in High-Rate Scalar Quantization with Renyi
  Entropy Constraint</title><categories>cs.IT math.IT</categories><comments>25 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Properties of scalar quantization with $r$th power distortion and constrained
R\'enyi entropy of order $\alpha\in (0,1)$ are investigated. For an
asymptotically (high-rate) optimal sequence of quantizers, the contribution to
the R\'enyi entropy due to source values in a fixed interval is identified in
terms of the &quot;entropy density&quot; of the quantizer sequence. This extends results
related to the well-known point density concept in optimal fixed-rate
quantization. A dual of the entropy density result quantifies the distortion
contribution of a given interval to the overall distortion. The distortion loss
resulting from a mismatch of source densities in the design of an
asymptotically optimal sequence of quantizers is also determined. This extends
Bucklew's fixed-rate ($\alpha=0$) and Gray \emph{et al.}'s variable-rate
($\alpha=1$) mismatch results to general values of the entropy order parameter
$\alpha$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1751</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1751</id><created>2011-08-08</created><authors><author><keyname>Benabbas</keyname><forenames>Siavosh</forenames></author><author><keyname>Lee</keyname><forenames>Hyun Chul</forenames></author><author><keyname>Oren</keyname><forenames>Joel</forenames></author><author><keyname>Ye</keyname><forenames>Yuli</forenames></author></authors><title>Efficient Sum-Based Hierarchical Smoothing Under \ell_1-Norm</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a new regression problem which we call the Sum-Based
Hierarchical Smoothing problem. Given a directed acyclic graph and a
non-negative value, called target value, for each vertex in the graph, we wish
to find non-negative values for the vertices satisfying a certain constraint
while minimizing the distance of these assigned values and the target values in
the lp-norm. The constraint is that the value assigned to each vertex should be
no less than the sum of the values assigned to its children. We motivate this
problem with applications in information retrieval and web mining. While our
problem can be solved in polynomial time using linear programming, given the
input size in these applications such a solution might be too slow. We mainly
study the \ell_1-norm case restricting the underlying graphs to rooted trees.
For this case we provide an efficient algorithm, running in O(n^2) time. While
the algorithm is purely combinatorial, its proof of correctness is an elegant
use of linear programming duality. We believe that our approach may be
applicable to similar problems, where comparable hierarchical constraints are
involved, e.g. considering the average of the values assigned to the children
of each vertex. While similar in flavor to other smoothing problems like
Isotonic Regression (see for example [Angelov et al. SODA'06]), our problem is
arguably richer and theoretically more challenging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1762</identifier>
 <datestamp>2013-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1762</id><created>2011-08-08</created><updated>2013-10-26</updated><authors><author><keyname>Feldman</keyname><forenames>Michal</forenames></author><author><keyname>Wilf</keyname><forenames>Yoav</forenames></author></authors><title>Randomized Strategyproof Mechanisms for Facility Location and the
  Mini-Sum-of-Squares Objective</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of locating a public facility on a line, where a set
of $n$ strategic agents report their \emph{locations} and a mechanism
determines, either deterministically or randomly, the location of the facility.
Game theoretic perspectives of the facility location problem advanced in two
main directions. The first direction is concerned with the characterization of
\emph{strategyproof} (SP) mechanisms; i.e., mechanisms that induce truthful
reporting as a dominant strategy; and the second direction quantifies how well
various objective functions can be approximated when restricted to SP
mechanisms. The current paper provides contributions in both directions. First,
we construct a parameterized randomized SP mechanism, and show that all of the
previously proposed deterministic and randomized SP mechanisms for the current
settings can be formalized as special cases of this mechanism. Second, we give
tight results for the approximation ratio of SP mechanisms with respect to the
objective of minimizing the sum of squares of distances to the agents
(\emph{miniSOS}). Holzman \cite{Holzman1990} provided an axiomatic foundation
for this function, showing that it is the unique function that satisfies
unanimity, continuity and invariance. We devise a randomized mechanism that
gives a 1.5-approximation for the miniSOS function, and show that no other
randomized SP mechanism can provide a better approximation. This mechanism
chooses the average location with probability 1/2 and a \emph{random dictator}
with probability 1/2. For deterministic mechanisms, we show that the median
mechanism provides a 2-approximation, and this is tight. Together, our study
provides fundamental understanding of the miniSOS objective function and makes
a step toward the characterization of randomized SP facility location
mechanisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1766</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1766</id><created>2011-08-08</created><authors><author><keyname>Hanneke</keyname><forenames>Steve</forenames></author></authors><title>Activized Learning: Transforming Passive to Active with Improved Label
  Complexity</title><categories>stat.ML cs.LG math.ST stat.TH</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the theoretical advantages of active learning over passive learning.
Specifically, we prove that, in noise-free classifier learning for VC classes,
any passive learning algorithm can be transformed into an active learning
algorithm with asymptotically strictly superior label complexity for all
nontrivial target functions and distributions. We further provide a general
characterization of the magnitudes of these improvements in terms of a novel
generalization of the disagreement coefficient. We also extend these results to
active learning in the presence of label noise, and find that even under broad
classes of noise distributions, we can typically guarantee strict improvements
over the known results for passive learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1780</identifier>
 <datestamp>2012-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1780</id><created>2011-08-08</created><updated>2011-12-15</updated><authors><author><keyname>Holme</keyname><forenames>Petter</forenames></author><author><keyname>Saram&#xe4;ki</keyname><forenames>Jari</forenames></author></authors><title>Temporal Networks</title><categories>nlin.AO cs.SI physics.data-an physics.soc-ph</categories><journal-ref>Phys. Rep. 519, 97-125 (2012)</journal-ref><doi>10.1016/j.physrep.2012.03.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A great variety of systems in nature, society and technology -- from the web
of sexual contacts to the Internet, from the nervous system to power grids --
can be modeled as graphs of vertices coupled by edges. The network structure,
describing how the graph is wired, helps us understand, predict and optimize
the behavior of dynamical systems. In many cases, however, the edges are not
continuously active. As an example, in networks of communication via email,
text messages, or phone calls, edges represent sequences of instantaneous or
practically instantaneous contacts. In some cases, edges are active for
non-negligible periods of time: e.g., the proximity patterns of inpatients at
hospitals can be represented by a graph where an edge between two individuals
is on throughout the time they are at the same ward. Like network topology, the
temporal structure of edge activations can affect dynamics of systems
interacting through the network, from disease contagion on the network of
patients to information diffusion over an e-mail network. In this review, we
present the emergent field of temporal networks, and discuss methods for
analyzing topological and temporal structure and models for elucidating their
relation to the behavior of dynamical systems. In the light of traditional
network theory, one can see this framework as moving the information of when
things happen from the dynamical system on the network, to the network itself.
Since fundamental properties, such as the transitivity of edges, do not
necessarily hold in temporal networks, many of these methods need to be quite
different from those for static networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1781</identifier>
 <datestamp>2012-10-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1781</id><created>2011-08-08</created><updated>2012-10-25</updated><authors><author><keyname>Bohman</keyname><forenames>Tom</forenames></author><author><keyname>Frieze</keyname><forenames>Alan</forenames></author><author><keyname>Lubetzky</keyname><forenames>Eyal</forenames></author></authors><title>Random greedy triangle-packing beyond the 7/4 barrier</title><categories>math.CO cs.DS</categories><comments>20 pages. Superceded by arXiv:1203.4223</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The random greedy algorithm for constructing a large partial
Steiner-Triple-System is defined as follows. Begin with a complete graph on $n$
vertices and proceed to remove the edges of triangles one at a time, where each
triangle removed is chosen uniformly at random out of all remaining triangles.
This stochastic process terminates once it arrives at a triangle-free graph,
and a longstanding open problem is to estimate the final number of edges, or
equivalently the time it takes the process to conclude. The intuition that the
edge distribution is roughly uniform at all times led to a folklore conjecture
that the final number of edges is $n^{3/2+o(1)}$ with high probability, whereas
the best known upper bound is $n^{7/4+o(1)}$. It is no coincidence that various
methods break precisely at the exponent 7/4 as it corresponds to the inherent
barrier where co-degrees become comparable to the variations in their values
that arose earlier in the process.
  In this work we significantly improve upon the previous bounds by
establishing that w.h.p. the number of edges in the final graph is at most $
n^{5/3+o(1)} $. Our approach relies on a system of martingales used to control
key graph parameters, where the crucial new idea is to harness the
self-correcting nature of the process in order to control these parameters well
beyond the point where their early variation matches the order of their
expectation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1785</identifier>
 <datestamp>2011-08-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1785</id><created>2011-08-08</created><authors><author><keyname>Wu</keyname><forenames>Wenji</forenames></author><author><keyname>DeMar</keyname><forenames>Phil</forenames></author><author><keyname>Holmgren</keyname><forenames>Don</forenames></author><author><keyname>Singh</keyname><forenames>Amitoj</forenames></author><author><keyname>Pordes</keyname><forenames>Ruth</forenames></author></authors><title>G-NetMon: A GPU-accelerated Network Performance Monitoring System for
  Large Scale Scientific Collaborations</title><categories>cs.NI</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  Network traffic is difficult to monitor and analyze, especially in
high-bandwidth networks. Performance analysis, in particular, presents extreme
complexity and scalability challenges. GPU (Graphics Processing Unit)
technology has been utilized recently to accelerate general purpose scientific
and engineering computing. GPUs offer extreme thread-level parallelism with
hundreds of simple cores. Their data-parallel execution model can rapidly solve
large problems with inherent data parallelism. At Fermilab, we have prototyped
a GPU-accelerated network performance monitoring system, called G-NetMon, to
support large-scale scientific collaborations. In this work, we explore new
opportunities in network traffic monitoring and analysis with GPUs. Our system
exploits the data parallelism that exists within network flow data to provide
fast analysis of bulk data movement between Fermilab and collaboration sites.
Experiments demonstrate that our G-NetMon can rapidly detect sub-optimal bulk
data movements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1791</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1791</id><created>2011-08-08</created><updated>2011-08-13</updated><authors><author><keyname>Aaronson</keyname><forenames>Scott</forenames></author></authors><title>Why Philosophers Should Care About Computational Complexity</title><categories>cs.CC quant-ph</categories><comments>58 pages, to appear in &quot;Computability: G\&quot;odel, Turing, Church, and
  beyond,&quot; MIT Press, 2012. Some minor clarifications and corrections; new
  references added</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One might think that, once we know something is computable, how efficiently
it can be computed is a practical question with little further philosophical
importance. In this essay, I offer a detailed case that one would be wrong. In
particular, I argue that computational complexity theory---the field that
studies the resources (such as time, space, and randomness) needed to solve
computational problems---leads to new perspectives on the nature of
mathematical knowledge, the strong AI debate, computationalism, the problem of
logical omniscience, Hume's problem of induction, Goodman's grue riddle, the
foundations of quantum mechanics, economic rationality, closed timelike curves,
and several other topics of philosophical interest. I end by discussing aspects
of complexity theory itself that could benefit from philosophical analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1824</identifier>
 <datestamp>2013-01-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1824</id><created>2011-08-08</created><updated>2013-01-17</updated><authors><author><keyname>de Castro</keyname><forenames>Alexandre</forenames></author></authors><title>The Thinking machine: a psychological view of Mawxwell's demon mind</title><categories>cs.IT math.IT</categories><comments>This paper has been withdrawn by the author</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, in a letter to Nature, del Rio et al.8 exploited the quantum
viewpoint of the old but well-known thought experiment of Maxwell's demon, a
tiny &quot;man-machine&quot; that processes only a single unit of information. In their
work, they showed that the thermodynamic cost for Maxwell's demon to erase
quantum information decreases as the amount it &quot;knows&quot; increases. Indeed, as
the authors themselves concluded, that finding has the ability to strengthen
the link between information theory and statistical physics. However, the
factual link between information theory and psychology remains unknown. There
may be no better way to investigate to this issue than to subject this dual
natured creature to psychological treatment! In this work, we propose an
Ausubel-inspired ansatz to map the thermodynamic mind of Maxwell's demon,
addressing information processing from a cognitive perspective9-12. The main
calculation presented in this short report shows that the Ausubelian
assimilation theory13-15 leads to a Shannon-Hartley-like model1,2 that, in
turn, converges exactly to the Landauer limit16-18 when one single information
is discarded from the demon's memory. This result indicates that both a
thermodynamic device and an intelligent being &quot;think&quot; in the same way when one
bit of information is processed. Consequently, this finding links information
theory to the &quot;psychological features&quot; of the thermodynamic engine through the
Landauer limit, which opens a new path towards the conception of a multi-bit
reasoning machine.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1841</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1841</id><created>2011-08-08</created><authors><author><keyname>Wu</keyname><forenames>Zhi-Xi</forenames></author><author><keyname>Holme</keyname><forenames>Petter</forenames></author></authors><title>Onion structure and network robustness</title><categories>physics.soc-ph cs.SI</categories><comments>6 pages, 5 figures</comments><journal-ref>PhysRevE.84.026106 (2011)</journal-ref><doi>10.1103/PhysRevE.84.026106</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a recent work [Proc. Natl. Acad. Sci. USA 108, 3838 (2011)], Schneider et
al. proposed a new measure for network robustness and investigated optimal
networks with respect to this quantity. For networks with a power-law degree
distribution, the optimized networks have an onion structure-high-degree
vertices forming a core with radially decreasing degrees and an
over-representation of edges within the same radial layer. In this paper we
relate the onion structure to graphs with good expander properties (another
characterization of robust network) and argue that networks of skewed degree
distributions with large spectral gaps (and thus good expander properties) are
typically onion structured. Furthermore, we propose a generative algorithm
producing synthetic scale-free networks with onion structure, circumventing the
optimization procedure of Schneider et al. We validate the robustness of our
generated networks against malicious attacks and random removals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1861</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1861</id><created>2011-08-09</created><authors><author><keyname>Andova</keyname><forenames>Suzana</forenames><affiliation>Eindhoven University of Technology</affiliation></author><author><keyname>Groenewegen</keyname><forenames>Luuk</forenames><affiliation>Leiden University</affiliation></author><author><keyname>de Vink</keyname><forenames>Erik</forenames><affiliation>Eindhoven University of Technology</affiliation></author></authors><title>Towards reduction of Paradigm coordination models</title><categories>cs.LO</categories><comments>In Proceedings PACO 2011, arXiv:1108.1452</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 60, 2011, pp. 1-18</journal-ref><doi>10.4204/EPTCS.60.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The coordination modelling language Paradigm addresses collaboration between
components in terms of dynamic constraints. Within a Paradigm model, component
dynamics are consistently specified at a detailed and a global level of
abstraction. To enable automated verification of Paradigm models, a translation
of Paradigm into process algebra has been defined in previous work. In this
paper we investigate, guided by a client-server example, reduction of Paradigm
models based on a notion of global inertness. Representation of Paradigm models
as process algebraic specifications helps to establish a property-preserving
equivalence relation between the original and the reduced Paradigm model.
Experiments indicate that in this way larger Paradigm models can be analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1862</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1862</id><created>2011-08-09</created><authors><author><keyname>Kokash</keyname><forenames>Natallia</forenames><affiliation>Centrum Wiskunde en Informatica</affiliation></author><author><keyname>Arbab</keyname><forenames>Farhad</forenames><affiliation>Centrum Wiskunde en Informatica</affiliation></author><author><keyname>Changizi</keyname><forenames>Behnaz</forenames><affiliation>Centrum Wiskunde en Informatica</affiliation></author><author><keyname>Makhnist</keyname><forenames>Leonid</forenames><affiliation>Brest State Technical University</affiliation></author></authors><title>Input-output Conformance Testing for Channel-based Service Connectors</title><categories>cs.SE</categories><comments>In Proceedings PACO 2011, arXiv:1108.1452</comments><proxy>EPTCS</proxy><acm-class>D.2.4;D.2.5</acm-class><journal-ref>EPTCS 60, 2011, pp. 19-35</journal-ref><doi>10.4204/EPTCS.60.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Service-based systems are software systems composed of autonomous components
or services provided by different vendors, deployed on remote machines and
accessible through the web. One of the challenges of modern software
engineering is to ensure that such a system behaves as intended by its
designer. The Reo coordination language is an extensible notation for formal
modeling and execution of service compositions. Services that have no prior
knowledge about each other communicate through advanced channel connectors
which guarantee that each participant, service or client, receives the right
data at the right time. Each channel is a binary relation that imposes
synchronization and data constraints on input and output messages. Furthermore,
channels are composed together to realize arbitrarily complex behavioral
protocols. During this process, a designer may introduce errors into the
connector model or the code for their execution, and thus affect the behavior
of a composed service. In this paper, we present an approach for model-based
testing of coordination protocols designed in Reo. Our approach is based on the
input-output conformance (ioco) testing theory and exploits the mapping of
automata-based semantic models for Reo to equivalent process algebra
specifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1863</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1863</id><created>2011-08-09</created><authors><author><keyname>Baeten</keyname><forenames>Jos</forenames><affiliation>Department of Mechanical Engineering, Eindhoven University of Technology</affiliation></author><author><keyname>van Beek</keyname><forenames>Bert</forenames><affiliation>Department of Mechanical Engineering, Eindhoven University of Technology</affiliation></author><author><keyname>van Hulst</keyname><forenames>Allan</forenames><affiliation>Department of Mechanical Engineering, Eindhoven University of Technology</affiliation></author><author><keyname>Markovski</keyname><forenames>Jasen</forenames><affiliation>Department of Mechanical Engineering, Eindhoven University of Technology</affiliation></author></authors><title>A Process Algebra for Supervisory Coordination</title><categories>cs.LO cs.PL</categories><comments>In Proceedings PACO 2011, arXiv:1108.1452</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 60, 2011, pp. 36-55</journal-ref><doi>10.4204/EPTCS.60.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A supervisory controller controls and coordinates the behavior of different
components of a complex machine by observing their discrete behaviour.
Supervisory control theory studies automated synthesis of controller models,
known as supervisors, based on formal models of the machine components and a
formalization of the requirements. Subsequently, code generation can be used to
implement this supervisor in software, on a PLC, or embedded microprocessor. In
this article, we take a closer look at the control loop that couples the
supervisory controller and the machine. We model both event-based and
state-based observations using process algebra and bisimulation-based
semantics. The main application area of supervisory control that we consider is
coordination, referred to as supervisory coordination, and we give an academic
and an industrial example, discussing the process-theoretic concepts employed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1864</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1864</id><created>2011-08-09</created><authors><author><keyname>Delzanno</keyname><forenames>Giorgio</forenames></author><author><keyname>Sangnier</keyname><forenames>Arnaud</forenames></author><author><keyname>Zavattaro</keyname><forenames>Gianluigi</forenames></author></authors><title>Parameterized Verification of Safety Properties in Ad Hoc Network
  Protocols</title><categories>cs.LO</categories><comments>In Proceedings PACO 2011, arXiv:1108.1452</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 60, 2011, pp. 56-65</journal-ref><doi>10.4204/EPTCS.60.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We summarize the main results proved in recent work on the parameterized
verification of safety properties for ad hoc network protocols. We consider a
model in which the communication topology of a network is represented as a
graph. Nodes represent states of individual processes. Adjacent nodes represent
single-hop neighbors. Processes are finite state automata that communicate via
selective broadcast messages. Reception of a broadcast is restricted to
single-hop neighbors. For this model we consider a decision problem that can be
expressed as the verification of the existence of an initial topology in which
the execution of the protocol can lead to a configuration with at least one
node in a certain state. The decision problem is parametric both on the size
and on the form of the communication topology of the initial configurations. We
draw a complete picture of the decidability and complexity boundaries of this
problem according to various assumptions on the possible topologies.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1865</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1865</id><created>2011-08-09</created><authors><author><keyname>Bernardo</keyname><forenames>Marco</forenames><affiliation>Dipartimento di Scienze di Base e Fondamenti -- Universita' di Urbino -- Italy</affiliation></author><author><keyname>De Nicola</keyname><forenames>Rocco</forenames><affiliation>IMT -- Institute for Advanced Studies Lucca -- Italy and Dipartimento di Sistemi e Informatica -- Universita' di Firenze -- Italy</affiliation></author><author><keyname>Loreti</keyname><forenames>Michele</forenames><affiliation>Dipartimento di Sistemi e Informatica -- Universita' di Firenze -- Italy</affiliation></author></authors><title>Uniform Labeled Transition Systems for Nondeterministic, Probabilistic,
  and Stochastic Process Calculi</title><categories>cs.DC cs.LO cs.SE</categories><comments>In Proceedings PACO 2011, arXiv:1108.1452</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 60, 2011, pp. 66-75</journal-ref><doi>10.4204/EPTCS.60.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Labeled transition systems are typically used to represent the behavior of
nondeterministic processes, with labeled transitions defining a one-step state
to-state reachability relation. This model has been recently made more general
by modifying the transition relation in such a way that it associates with any
source state and transition label a reachability distribution, i.e., a function
mapping each possible target state to a value of some domain that expresses the
degree of one-step reachability of that target state. In this extended
abstract, we show how the resulting model, called ULTraS from Uniform Labeled
Transition System, can be naturally used to give semantics to a fully
nondeterministic, a fully probabilistic, and a fully stochastic variant of a
CSP-like process language.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1873</identifier>
 <datestamp>2012-10-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1873</id><created>2011-08-09</created><updated>2012-09-27</updated><authors><author><keyname>Sakzad</keyname><forenames>Amin</forenames></author><author><keyname>Sadeghi</keyname><forenames>Mohammad-Reza</forenames></author><author><keyname>Panario</keyname><forenames>Daniel</forenames></author></authors><title>Turbo Lattices: Construction and Error Decoding Performance</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. on Inform. Theory since Dec 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper a new class of lattices called turbo lattices is introduced and
established. We use the lattice Construction D to produce turbo lattices. This
method needs a set of nested linear codes as its underlying structure. We
benefit from turbo codes as our basis codes. Therefore, a set of nested turbo
codes based on nested interleavers (block interleavers) and nested
convolutional codes is built. To this end, we employ both tail-biting and
zero-tail convolutional codes. Using these codes, along with construction D,
turbo lattices are created. Several properties of Construction D lattices and
fundamental characteristics of turbo lattices including the minimum distance,
coding gain and kissing number are investigated. Furthermore, a multi-stage
turbo lattice decoding algorithm based on iterative turbo decoding algorithm is
given. We show, by simulation, that turbo lattices attain good error
performance within $\sim1.25 dB$ from capacity at block length of $n=1035$.
Also an excellent performance of only $\sim.5 dB$ away from capacity at SER of
$10^{-5}$ is achieved for size $n=10131$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1897</identifier>
 <datestamp>2014-07-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1897</id><created>2011-08-09</created><authors><author><keyname>Kachhvah</keyname><forenames>Ajay Deep</forenames></author><author><keyname>Gupte</keyname><forenames>Neelima</forenames></author></authors><title>Avalanche transmission and critical behavior in load bearing
  hierarchical networks</title><categories>cond-mat.stat-mech cs.SI physics.soc-ph</categories><comments>7 pages, 10 figures, To appear in the Proceedings of &quot;Perspectives in
  Nonlinear Dynamics 2010&quot;, Accepted in a special issue of Pramana - journal of
  physics</comments><journal-ref>Pramana - Journal of Physics 77, 873 (2011)</journal-ref><doi>10.1007/s12043-011-0189-x</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The strength and stability properties of hierarchical load bearing networks
and their strengthened variants have been discussed in recent work. Here, we
study the avalanche time distributions on these load bearing networks. The
avalanche time distributions of the V- lattice, a unique realization of the
networks, show power-law behavior when tested with certain fractions of its
trunk weights. All other avalanche distributions show Gaussian peaked behavior.
Thus the V- lattice is the critical case of the network. We discuss the
implications of this result.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1914</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1914</id><created>2011-08-09</created><updated>2011-09-07</updated><authors><author><keyname>Bader</keyname><forenames>Ahmed</forenames></author><author><keyname>Abed-Meraim</keyname><forenames>Karim</forenames></author><author><keyname>Alouini</keyname><forenames>Mohamed-Slim</forenames></author></authors><title>Technical Report: Multi-Carrier Position-Based Packet Forwarding
  Protocol For Wireless Sensor Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Beaconless position-based forwarding protocols have recently evolved as a
promising solution for packet forwarding in wireless sensor networks. However,
as the node density grows, the overhead incurred in the process of relay
selection grows significantly. As such, end-to-end performance in terms of
energy and latency is adversely impacted. With the motivation of developing a
packet forwarding mechanism that is tolerant to node density, an alternative
position-based protocol is proposed in this paper. In contrast to existing
beaconless protocols, the proposed protocol is designed such that it eliminates
the need for potential relays to undergo a relay selection process. Rather, any
eligible relay may decide to forward the packet ahead, thus significantly
reducing the underlying overhead. The operation of the proposed protocol is
empowered by exploiting favorable features of orthogonal frequency division
multiplexing (OFDM) at the physical layer. The end-to-end performance of the
proposed protocol is evaluated against existing beaconless position-based
protocols analytically and as well by means of simulations. The proposed
protocol is demonstrated in this paper to be more efficient. In particular, it
is shown that for the same amount of energy the proposed protocol transports
one bit from source to destination much quicker.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1915</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1915</id><created>2011-08-09</created><authors><author><keyname>Gawron</keyname><forenames>Piotr</forenames></author><author><keyname>Klamka</keyname><forenames>Jerzy</forenames></author><author><keyname>Winiarczyk</keyname><forenames>Ryszard</forenames></author></authors><title>Noise effects in the quantum search algorithm from the computational
  complexity point of view</title><categories>quant-ph cs.CC</categories><comments>7 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyse the resilience of the quantum search algorithm in the presence of
quantum noise modelled as trace preserving completely positive maps. We study
the influence of noise on computational complexity of the quantum search
algorithm. We show that only for small amounts of noise the quantum search
algorithm is still more efficient than any classical algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1925</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1925</id><created>2011-08-09</created><authors><author><keyname>Peukert</keyname><forenames>Eric</forenames></author><author><keyname>Eberius</keyname><forenames>Julian</forenames></author><author><keyname>Rahm</keyname><forenames>Erhard</forenames></author></authors><title>Rule-based Construction of Matching Processes</title><categories>cs.DB</categories><comments>10 Pages</comments><acm-class>D.2.12</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mapping complex metadata structures is crucial in a number of domains such as
data integration, ontology alignment or model management. To speed up that
process automatic matching systems were developed to compute mapping
suggestions that can be corrected by a user. However, constructing and tuning
match strategies still requires a high manual effort by matching experts as
well as correct mappings to evaluate generated mappings. We therefore propose a
self-configuring schema matching system that is able to automatically adapt to
the given mapping problem at hand. Our approach is based on analyzing the input
schemas as well as intermediate matching results. A variety of matching rules
use the analysis results to automatically construct and adapt an underlying
matching process for a given match task. We comprehensively evaluate our
approach on different mapping problems from the schema, ontology and model
management domains. The evaluation shows that our system is able to robustly
return good quality mappings across different mapping problems and domains.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1926</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1926</id><created>2011-08-09</created><authors><author><keyname>Cornejo</keyname><forenames>Alejandro</forenames></author><author><keyname>Haeupler</keyname><forenames>Bernhard</forenames></author><author><keyname>Kuhn</keyname><forenames>Fabian</forenames></author></authors><title>Computing a Maximal Independent Set Using Beeps</title><categories>cs.DC cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding a maximal independent set (MIS) in the
discrete beeping model. At each time, a node in the network can either beep
(i.e., emit a signal) or be silent. Silent nodes can only differentiate between
no neighbor beeping, or at least one neighbor beeping. This basic communication
model relies only on carrier-sensing. Furthermore, we assume nothing about the
underlying communication graph and allow nodes to wake up (and crash)
arbitrarily.
  We show that if a polynomial upper bound on the size of the network n is
known, then with high probability every node becomes stable in O(\log^3 n) time
after it is woken up. To contrast this, we establish a polynomial lower bound
when no a priori upper bound on the network size is known. This holds even in
the much stronger model of local message broadcast with collision detection.
  Finally, if we assume nodes have access to synchronized clocks or we consider
a somewhat restricted wake up, we can solve the MIS problem in O(\log^2 n) time
without requiring an upper bound on the size of the network, thereby achieving
the same bit complexity as Luby's MIS algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1928</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1928</id><created>2011-08-09</created><authors><author><keyname>Fu</keyname><forenames>Yongquan</forenames></author><author><keyname>Wang</keyname><forenames>Yijie</forenames></author><author><keyname>Biersack</keyname><forenames>Ernst</forenames></author></authors><title>HybridNN: Supporting Network Location Service on Generalized Delay
  Metrics</title><categories>cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Distributed Nearest Neighbor Search (DNNS) locates service nodes that have
shortest interactive delay towards requesting hosts. DNNS provides an important
service for large-scale latency sensitive networked applications, such as VoIP,
online network games, or interactive network services on the cloud. Existing
work assumes the delay to be symmetric, which does not generalize to
applications that are sensitive to one-way delays, such as the multimedia video
delivery from the servers to the hosts. We propose a relaxed inframetric model
for the network delay space that does not assume the triangle inequality and
delay symmetry to hold. We prove that the DNNS requests can be completed
efficiently if the delay space exhibits modest inframetric dimensions, which we
can observe empirically. Finally, we propose a DNNS method named HybridNN
(\textit{Hybrid} \textit{N}earest \textit{N}eighbor search) based on the
inframetric model for fast and accurate DNNS. For DNNS requests, HybridNN
chooses closest neighbors accurately via the inframetric modelling, and
scalably by combining delay predictions with direct probes to a pruned set of
neighbors. Simulation results show that HybridNN locates nearly optimally the
nearest neighbor. Experiments on PlanetLab show that HybridNN can provide
accurate nearest neighbors that are close to optimal with modest query overhead
and maintenance traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1933</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1933</id><created>2011-08-09</created><updated>2011-08-10</updated><authors><author><keyname>Monemizadeh</keyname><forenames>Mostafa</forenames></author><author><keyname>Hodtani</keyname><forenames>Ghosheh Abed</forenames></author><author><keyname>Fehri</keyname><forenames>Hamed</forenames></author></authors><title>An Achievable Rate Region for Cognitive Radio Channel With Common
  Message</title><categories>cs.IT math.IT</categories><comments>5 pages, 2 figures, accepted for publication and presentation at
  ISWCS 2011, Aachen, Germany, 6th - 9th November, 2011</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  The cognitive radio channel with common message (CRCC) is considered. In this
channel, similar to the cognitive radio channel (CRC), we have a cognitive user
which has full non-causal knowledge of the primary message, and like the
interference channel with common message (ICC), the information sources at the
two transmitters are statistically dependent and the senders need to transmit
not only the private message but also certain common message to their
corresponding receivers. By using a specific combination of superposition
coding, binning scheme and simultaneous decoding, we propose a unified
achievable rate region for the CRCC which subsumes the several existing results
for the CRC, ICC, interference channel without common message (IC), strong
interference channel and compound multiple access channel with common
information (SICC and CMACC).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1940</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1940</id><created>2011-08-09</created><authors><author><keyname>Sha</keyname><forenames>Daohang</forenames></author><author><keyname>Thomas</keyname><forenames>James S</forenames></author></authors><title>An Optimization-Based Model for Full-body Reaching Movements</title><categories>cs.SY math.OC</categories><comments>27 pages, 3 tables and 6 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Background The development of a simulation model of full body reaching tasks
that can predict endeffector trajectories and joint excursions consistent with
experimental data is a non-trivial task. Because of the kinematic redundancy
inherent in these multi-joint tasks there are an infinite number of postures
that could be adopted to complete them. By developing models to simulate
full-body reaching movements in 3D space we can begin to explore cost functions
that may be used by the central nervous system to plan and execute these
movements. Methods A robust simulation model was developed using 1)
graphic-based modeling tools to generate an inverse dynamics controller
(SimMechanics), 2) controller parameterization methods, and 3) cost function
criteria. An adaptive weight coefficient based on the final motor task error
(i.e. distance between end-effector and target at the end of movement) was
proposed to balance motor task error and physiological cost terms (e.g. joint
power). The output of the simulation models using different cost controller
functions based on motor task error or motor task error and various
physiological cost terms (e.g. joint power, center of mass displacement) were
compared to experimental data from 15 healthy participants performing full body
reaching movements. Results In sum, the best fit to the experimental data was
obtained by minimizing motor task error, joint power, and center of mass
displacement. Simulation and experimental results demonstrated that the
proposed method is effective for the simulation of large-scale human skeletal
systems. Conclusions This method can reasonably predict the whole body reaching
movements including final postures, joint power and movement of COM using
simple algebraic calculations of inverse dynamics and forward kinematics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1956</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1956</id><created>2011-08-09</created><authors><author><keyname>Beskales</keyname><forenames>George</forenames></author><author><keyname>Fontoura</keyname><forenames>Marcus</forenames></author><author><keyname>Gurevich</keyname><forenames>Maxim</forenames></author><author><keyname>Vassilvitskii</keyname><forenames>Sergei</forenames></author><author><keyname>Josifovski</keyname><forenames>Vanja</forenames></author></authors><title>Factorization-based Lossless Compression of Inverted Indices</title><categories>cs.IR</categories><comments>To Appear as a short paper in CIKM'11</comments><acm-class>H.3.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many large-scale Web applications that require ranked top-k retrieval such as
Web search and online advertising are implemented using inverted indices. An
inverted index represents a sparse term-document matrix, where non-zero
elements indicate the strength of term-document association. In this work, we
present an approach for lossless compression of inverted indices. Our approach
maps terms in a document corpus to a new term space in order to reduce the
number of non-zero elements in the term-document matrix, resulting in a more
compact inverted index. We formulate the problem of selecting a new term space
that minimizes the resulting index size as a matrix factorization problem, and
prove that finding the optimal factorization is an NP-hard problem. We develop
a greedy algorithm for finding an approximate solution. A side effect of our
approach is increasing the number of terms in the index, which may negatively
affect query evaluation performance. To eliminate such effect, we develop a
methodology for modifying query evaluation algorithms by exploiting specific
properties of our compression approach. Our experimental evaluation
demonstrates that our approach achieves an index size reduction of 20%, while
maintaining the same query response times. Higher compression ratios up to 35%
are achievable, however at the cost of slightly longer query response times.
Furthermore, combining our approach with other lossless compression techniques,
namely variable-byte encoding, leads to index size reduction of up to 50%.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1966</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1966</id><created>2011-08-09</created><authors><author><keyname>Singh</keyname><forenames>Anil Kumar</forenames></author></authors><title>A Concise Query Language with Search and Transform Operations for
  Corpora with Multiple Levels of Annotation</title><categories>cs.CL</categories><comments>10 pages, 1 figure</comments><acm-class>H.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The usefulness of annotated corpora is greatly increased if there is an
associated tool that can allow various kinds of operations to be performed in a
simple way. Different kinds of annotation frameworks and many query languages
for them have been proposed, including some to deal with multiple layers of
annotation. We present here an easy to learn query language for a particular
kind of annotation framework based on 'threaded trees', which are somewhere
between the complete order of a tree and the anarchy of a graph. Through
'typed' threads, they can allow multiple levels of annotation in the same
document. Our language has a simple, intuitive and concise syntax and high
expressive power. It allows not only to search for complicated patterns with
short queries but also allows data manipulation and specification of arbitrary
return values. Many of the commonly used tasks that otherwise require writing
programs, can be performed with one or more queries. We compare the language
with some others and try to evaluate it.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1977</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1977</id><created>2011-08-09</created><authors><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author><author><keyname>Tehrani</keyname><forenames>Arash Saber</forenames></author><author><keyname>Zhang</keyname><forenames>Zhen</forenames></author></authors><title>Dynamic Index Coding for Wireless Broadcast Networks</title><categories>cs.IT math.IT</categories><comments>13 pages, 8 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a wireless broadcast station that transmits packets to multiple
users. The packet requests for each user may overlap, and some users may
already have certain packets. This presents a problem of broadcasting in the
presence of side information, and is a generalization of the well known (and
unsolved) index coding problem of information theory. Rather than achieving the
full capacity region, we develop a code-constrained capacity region, which
restricts attention to a pre-specified set of coding actions. We develop a
dynamic max-weight algorithm that allows for random packet arrivals and
supports any traffic inside the code-constrained capacity region. Further, we
provide a simple set of codes based on cycles in the underlying demand graph.
We show these codes are optimal for a class of broadcast relay problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1983</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1983</id><created>2011-08-09</created><authors><author><keyname>Munro</keyname><forenames>J. Ian</forenames></author><author><keyname>Raman</keyname><forenames>Rajeev</forenames></author><author><keyname>Raman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Rao</keyname><forenames>S. Srinivasa</forenames></author></authors><title>Succinct Representations of Permutations and Functions</title><categories>cs.DS</categories><comments>Preliminary versions of these results have appeared in the
  Proceedings of ICALP 2003 and 2004. However, all results in this version are
  improved over the earlier conference version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the problem of succinctly representing an arbitrary
permutation, \pi, on {0,...,n-1} so that \pi^k(i) can be computed quickly for
any i and any (positive or negative) integer power k. A representation taking
(1+\epsilon) n lg n + O(1) bits suffices to compute arbitrary powers in
constant time, for any positive constant \epsilon &lt;= 1. A representation taking
the optimal \ceil{\lg n!} + o(n) bits can be used to compute arbitrary powers
in O(lg n / lg lg n) time.
  We then consider the more general problem of succinctly representing an
arbitrary function, f: [n] \rightarrow [n] so that f^k(i) can be computed
quickly for any i and any integer power k. We give a representation that takes
(1+\epsilon) n lg n + O(1) bits, for any positive constant \epsilon &lt;= 1, and
computes arbitrary positive powers in constant time. It can also be used to
compute f^k(i), for any negative integer k, in optimal O(1+|f^k(i)|) time.
  We place emphasis on the redundancy, or the space beyond the
information-theoretic lower bound that the data structure uses in order to
support operations efficiently. A number of lower bounds have recently been
shown on the redundancy of data structures. These lower bounds confirm the
space-time optimality of some of our solutions. Furthermore, the redundancy of
one of our structures &quot;surpasses&quot; a recent lower bound by Golynski [Golynski,
SODA 2009], thus demonstrating the limitations of this lower bound.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1986</identifier>
 <datestamp>2011-08-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1986</id><created>2011-08-09</created><authors><author><keyname>Acharjya</keyname><forenames>D. P.</forenames></author><author><keyname>Ezhilarasi</keyname><forenames>L.</forenames></author></authors><title>A Knowledge Mining Model for Ranking Institutions using Rough Computing
  with Ordering Rules and Formal Concept analysis</title><categories>cs.AI cs.IR</categories><comments>9 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Emergences of computers and information technological revolution made
tremendous changes in the real world and provides a different dimension for the
intelligent data analysis. Well formed fact, the information at right time and
at right place deploy a better knowledge.However, the challenge arises when
larger volume of inconsistent data is given for decision making and knowledge
extraction. To handle such imprecise data certain mathematical tools of greater
importance has developed by researches in recent past namely fuzzy set,
intuitionistic fuzzy set, rough Set, formal concept analysis and ordering
rules. It is also observed that many information system contains numerical
attribute values and therefore they are almost similar instead of exact
similar. To handle such type of information system, in this paper we use two
processes such as pre process and post process. In pre process we use rough set
on intuitionistic fuzzy approximation space with ordering rules for finding the
knowledge whereas in post process we use formal concept analysis to explore
better knowledge and vital factors affecting decisions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.1989</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.1989</id><created>2011-08-09</created><authors><author><keyname>Liu</keyname><forenames>Jia</forenames></author><author><keyname>Sherali</keyname><forenames>Hanif D.</forenames></author></authors><title>A Distributed Newton Approach for Joint Multi-Hop Routing and Flow
  Control: Theory and Algorithm</title><categories>cs.NI cs.IT cs.SY math.IT math.OC</categories><comments>A short version of this work has been submitted to IEEE INFOCOM 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The fast growing scale and heterogeneity of current communication networks
necessitate the design of distributed cross-layer optimization algorithms. So
far, the standard approach of distributed cross-layer design is based on dual
decomposition and the subgradient algorithm, which is a first-order method that
has a slow convergence rate. In this paper, we focus on solving a joint
multi-path routing and flow control (MRFC) problem by designing a new
distributed Newton's method, which is a second-order method and enjoys a
quadratic rate of convergence. The major challenges in developing a distributed
Newton's method lie in decentralizing the computation of the Hessian matrix and
its inverse for both the primal Newton direction and dual variable updates. By
appropriately reformulating, rearranging, and exploiting the special problem
structures, we show that it is possible to decompose such computations into
source nodes and links in the network, thus eliminating the need for global
information. Furthermore, we derive closed-form expressions for both the primal
Newton direction and dual variable updates, thus significantly reducing the
computational complexity. The most attractive feature of our proposed
distributed Newton's method is that it requires almost the same scale of
information exchange as in first-order methods, while achieving a quadratic
rate of convergence as in centralized Newton methods. We provide extensive
numerical results to demonstrate the efficacy of our proposed algorithm. Our
work contributes to the advanced paradigm shift in cross-layer network design
that is evolving from first-order to second-order methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2018</identifier>
 <datestamp>2016-03-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2018</id><created>2011-08-09</created><updated>2016-03-01</updated><authors><author><keyname>Kakhbod</keyname><forenames>Ali</forenames></author></authors><title>Resource allocation with costly participation</title><categories>cs.GT math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new all-pay auction format in which risk-loving bidders pay a
constant fee each time they bid for an object whose monetary value is common
knowledge among the bidders, and bidding fees are the only source of benefit
for the seller. We show that for the proposed model there exists a {unique}
Symmetric Subgame Perfect Equilibrium (SSPE). The characterized SSPE is
stationary when re-entry in the auction is allowed, and it is Markov perfect
when re-entry is forbidden. Furthermore, we fully characterize the expected
revenue of the seller. Generally, with or without re-entry, it is more
beneficial for the seller to choose $v$ (value of the object), $s$ (sale
price), and $c$ (bidding fee) such that $\frac{v-s}{c}$ becomes sufficiently
large. In particular, when re-entry is permitted: the expected revenue of the
seller is \emph{independent} of the number of bidders, decreasing in the sale
price, increasing in the value of the object, and decreasing in the bidding
fee; Moreover, the seller's revenue is equal to the value of the object when
players are risk neutral, and it is strictly greater than the value of the
object when bidders are risk-loving. We further show that allowing re-entry can
be important in practice. Because, if the seller were to run such an auction
without allowing re-entry, the auction would last a long time, and for almost
all of its duration have only two remaining players. Thus, the seller's revenue
relies on those two players being willing to participate, without any breaks,
in an auction that might last for thousands of rounds
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2038</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2038</id><created>2011-08-09</created><authors><author><keyname>Frauendiener</keyname><forenames>J.</forenames></author><author><keyname>Klein</keyname><forenames>C.</forenames></author><author><keyname>Shramchenko</keyname><forenames>V.</forenames></author></authors><title>Efficient computation of the branching structure of an algebraic curve</title><categories>cs.CG math.AG</categories><comments>18 pages, 7 figures</comments><msc-class>14Q05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An efficient algorithm for computing the branching structure of a compact
Riemann surface defined via an algebraic curve is presented. Generators of the
fundamental group of the base of the ramified covering punctured at the
discriminant points of the curve are constructed via a minimal spanning tree of
the discriminant points. This leads to paths of minimal length between the
points, which is important for a later stage where these paths are used as
integration contours to compute periods of the surface. The branching structure
of the surface is obtained by analytically continuing the roots of the equation
defining the algebraic curve along the constructed generators of the
fundamental group.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2045</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2045</id><created>2011-08-09</created><authors><author><keyname>Becerra-Sagredo</keyname><forenames>Julian</forenames></author><author><keyname>Malaga</keyname><forenames>Carlos</forenames></author><author><keyname>Mandujano</keyname><forenames>Francisco</forenames></author></authors><title>A novel and scalable Multigrid algorithm for many-core architectures</title><categories>cs.NA math.NA physics.comp-ph</categories><comments>9 pages, 5 figures</comments><msc-class>65F10, 65N22, 65N55, 65Y05, 65Y10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multigrid algorithms are among the fastest iterative methods known today for
solving large linear and some non-linear systems of equations. Greatly
optimized for serial operation, they still have a great potential for
parallelism not fully realized. In this work, we present a novel multigrid
algorithm designed to work entirely inside many-core architectures like the
graphics processing units (GPUs), without memory transfers between the GPU and
the central processing unit (CPU), avoiding low bandwitdth communications. The
algorithm is denoted as the high occupancy multigrid (HOMG) because it makes
use of entire grid operations with interpolations and relaxations fused into
one task, providing useful work for every thread in the grid. For a given
accuracy, its number of operations scale linearly with the total number of
nodes in the grid. Perfect scalability is observed for a large number of
processors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2054</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2054</id><created>2011-08-09</created><authors><author><keyname>Angiulli</keyname><forenames>Fabrizio</forenames></author><author><keyname>Fassetti</keyname><forenames>Fabio</forenames></author></authors><title>Uncertain Nearest Neighbor Classification</title><categories>cs.LG cs.AI</categories><acm-class>H.2.8</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work deals with the problem of classifying uncertain data. With this aim
the Uncertain Nearest Neighbor (UNN) rule is here introduced, which represents
the generalization of the deterministic nearest neighbor rule to the case in
which uncertain objects are available. The UNN rule relies on the concept of
nearest neighbor class, rather than on that of nearest neighbor object. The
nearest neighbor class of a test object is the class that maximizes the
probability of providing its nearest neighbor. It is provided evidence that the
former concept is much more powerful than the latter one in the presence of
uncertainty, in that it correctly models the right semantics of the nearest
neighbor decision rule when applied to the uncertain scenario. An effective and
efficient algorithm to perform uncertain nearest neighbor classification of a
generic (un)certain test object is designed, based on properties that greatly
reduce the temporal cost associated with nearest neighbor class probability
computation. Experimental results are presented, showing that the UNN rule is
effective and efficient in classifying uncertain data.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2058</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2058</id><created>2011-08-09</created><authors><author><keyname>Aronov</keyname><forenames>Boris</forenames></author><author><keyname>Dulieu</keyname><forenames>Muriel</forenames></author><author><keyname>Hurtado</keyname><forenames>Ferran</forenames></author></authors><title>Witness Rectangle Graphs</title><categories>cs.CG</categories><comments>In Proceedings of the 12th International Symposium on Algorithms and
  Data Structures (WADS), p.73-85, August 2011, New York, NY, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a witness rectangle graph (WRG) on vertex point set P with respect to
witness points set W in the plane, two points x, y in P are adjacent whenever
the open isothetic rectangle with x and y as opposite corners contains at least
one point in W. WRGs are representative of a a larger family of witness
proximity graphs introduced in two previous papers. We study graph-theoretic
properties of WRGs. We prove that any WRG has at most two non-trivial connected
components. We bound the diameter of the non-trivial connected components of a
WRG in both the one-component and two-component cases. In the latter case, we
prove that a graph is representable as a WRG if and only if each component is a
connected co-interval graph, thereby providing a complete characterization of
WRGs of this type. We also completely characterize trees drawable as WRGs. In
addition, we prove that a WRG with no isolated vertices has domination number
at most four. Moreover, we show that any combinatorial graph can be drawn as a
WRG using a combination of positive and negative witnesses. Finally we conclude
with some related results on the number of points required to stab all the
rectangles defined by a set of n point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2063</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2063</id><created>2011-08-09</created><authors><author><keyname>Aronov</keyname><forenames>Boris</forenames></author><author><keyname>Dulieu</keyname><forenames>Muriel</forenames></author></authors><title>How to Cover a Point Set with a V-Shape of Minimum Width</title><categories>cs.CG cs.DS</categories><comments>In Proceedings of the 12th International Symposium on Algorithms and
  Data Structures (WADS), p.61-72, August 2011, New York, NY, USA</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A balanced V-shape is a polygonal region in the plane contained in the union
of two crossing equal-width strips. It is delimited by two pairs of parallel
rays that emanate from two points x, y, are contained in the strip boundaries,
and are mirror-symmetric with respect to the line xy. The width of a balanced
V-shape is the width of the strips. We first present an O(n^2 log n) time
algorithm to compute, given a set of n points P, a minimum-width balanced
V-shape covering P. We then describe a PTAS for computing a
(1+epsilon)-approximation of this V-shape in time O((n/epsilon)log
n+(n/epsilon^(3/2))log^2(1/epsilon)). A much simpler constant-factor
approximation algorithm is also described.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2070</identifier>
 <datestamp>2011-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2070</id><created>2011-08-09</created><updated>2011-09-01</updated><authors><author><keyname>Kanuparthy</keyname><forenames>Partha</forenames></author><author><keyname>Dovrolis</keyname><forenames>Constantine</forenames></author><author><keyname>Papagiannaki</keyname><forenames>Konstantina</forenames></author><author><keyname>Seshan</keyname><forenames>Srinivasan</forenames></author><author><keyname>Steenkiste</keyname><forenames>Peter</forenames></author></authors><title>Can User-Level Probing Detect and Diagnose Common Home-WLAN Pathologies?</title><categories>cs.NI</categories><acm-class>C.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Common WLAN pathologies include low signal-to-noise ratio, congestion, hidden
terminals or interference from non-802.11 devices and phenomena. Prior work has
focused on the detection and diagnosis of such problems using layer-2
information from 802.11 devices and special-purpose access points and monitors,
which may not be generally available. Here, we investigate a userlevel
approach: is it possible to detect and diagnose 802.11 pathologies with
strictly user-level active probing, without any cooperation from, and without
any visibility in, layer-2 devices? In this paper, we present preliminary but
promising results indicating that such diagnostics are feasible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2080</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2080</id><created>2011-08-09</created><authors><author><keyname>Popa</keyname><forenames>Raluca Ada</forenames></author><author><keyname>Chiesa</keyname><forenames>Alessandro</forenames></author><author><keyname>Badirkhanli</keyname><forenames>Tural</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Going Beyond Pollution Attacks: Forcing Byzantine Clients to Code
  Correctly</title><categories>cs.NI cs.CR</categories><comments>A shorter version is in submission to IEEE INFOCOM 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network coding achieves optimal throughput in multicast networks. However,
throughput optimality \emph{relies} on the network nodes or routers to code
\emph{correctly}. A Byzantine node may introduce junk packets in the network
(thus polluting downstream packets and causing the sinks to receive the wrong
data) or may choose coding coefficients in a way that significantly reduces the
throughput of the network.
  Most prior work focused on the problem of Byzantine nodes polluting packets.
However, even if a Byzantine node does not pollute packets, he can still affect
significantly the throughput of the network by not coding correctly. No
previous work attempted to verify if a certain node \emph{coded correctly using
random coefficients} over \emph{all} of the packets he was supposed to code
over.
  We provide two novel protocols (which we call PIP and Log-PIP) for detecting
whether a node coded correctly over all the packets received (i.e., according
to a random linear network coding algorithm). Our protocols enable any node in
the network to examine a packet received from another node by running a
&quot;verification test&quot;. With our protocols, the worst an adversary can do and
still pass the packet verification test is in fact equivalent to random linear
network coding, which has been shown to be optimal in multicast networks. Our
protocols resist collusion among nodes and are applicable to a variety of
settings.
  Our topology simulations show that the throughput in the worst case for our
protocol is two to three times larger than the throughput in various
adversarial strategies allowed by prior work. We implemented our protocols in
C/C++ and Java, as well as incorporated them on the Android platform (Nexus
One). Our evaluation shows that our protocols impose modest overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2085</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2085</id><created>2011-08-09</created><authors><author><keyname>Kovacs</keyname><forenames>Laura</forenames><affiliation>TU Vienna, Austria</affiliation></author><author><keyname>Pugliese</keyname><forenames>Rosario</forenames><affiliation>DSI Univ. of Florence, Italy</affiliation></author><author><keyname>Tiezzi</keyname><forenames>Francesco</forenames><affiliation>IMT Lucca, Italy</affiliation></author></authors><title>Proceedings 7th International Workshop on Automated Specification and
  Verification of Web Systems</title><categories>cs.SE cs.LO</categories><comments>EPTCS 61, 2011</comments><proxy>EPTCS</proxy><doi>10.4204/EPTCS.61</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the final and revised versions of the papers presented
at the 7th International Workshop on Automated Specification and Verification
of Web Systems (WWV 2011). The workshop was held in Reykjavik, Iceland, on June
9, 2011, as part of DisCoTec 2011. The aim of the WWV workshop series is to
provide an interdisciplinary forum to facilitate the cross-fertilization and
the advancement of hybrid methods that exploit concepts and tools drawn from
Rule-based programming, Software engineering, Formal methods and Web-oriented
research. Nowadays, indeed, many companies and institutions have diverted their
Web sites into interactive, completely-automated, Web-based applications for,
e.g., e-business, e-learning, e-government, and e-health. The increased
complexity and the explosive growth of Web systems have made their design and
implementation a challenging task. Systematic, formal approaches to their
specification and verification can permit to address the problems of this
specific domain by means of automated and effective techniques and tools. In
response to this year's call for papers, we received 9 paper submissions. The
Program Committee of WWV 2011 collected three reviews for each paper and held
an electronic discussion leading to the selection of 7 papers for presentation
at the workshop. In addition to the selected papers, the scientific programme
included an invited lecture by Elie Najm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2092</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2092</id><created>2011-08-10</created><authors><author><keyname>Fabrikant</keyname><forenames>Alex</forenames></author><author><keyname>Jaggard</keyname><forenames>Aaron D.</forenames></author><author><keyname>Schapira</keyname><forenames>Michael</forenames></author></authors><title>On the Structure of Weakly Acyclic Games</title><categories>cs.GT</categories><comments>17 pages. Revised and expanded version of a paper that appeared in
  the Proceedings of SAGT 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The class of weakly acyclic games, which includes potential games and
dominance-solvable games, captures many practical application domains. In a
weakly acyclic game, from any starting state, there is a sequence of
better-response moves that leads to a pure Nash equilibrium; informally, these
are games in which natural distributed dynamics, such as better-response
dynamics, cannot enter inescapable oscillations. We establish a novel link
between such games and the existence of pure Nash equilibria in subgames.
Specifically, we show that the existence of a unique pure Nash equilibrium in
every subgame implies the weak acyclicity of a game. In contrast, the possible
existence of multiple pure Nash equilibria in every subgame is insufficient for
weak acyclicity in general; here, we also systematically identify the special
cases (in terms of the number of players and strategies) for which this is
sufficient to guarantee weak acyclicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2094</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2094</id><created>2011-08-10</created><authors><author><keyname>Kumar</keyname><forenames>Rakesh</forenames></author><author><keyname>Dave</keyname><forenames>Mayank</forenames></author></authors><title>A Comparative Study of Various Routing Protocols in VANET</title><categories>cs.NI</categories><comments>6 pages, 1 figure and 2 tables</comments><journal-ref>International Journal of Computer Science Issues (IJCSI), Vol.
  8,Issue-4,No.-4,Jul 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular Ad Hoc Networks (VANET) is a subclass of Mobile ad hoc networks
which provides a distinguished approach for Intelligent Transport System (ITS).
The survey of routing protocols in VANET is important and necessary for smart
ITS. This paper discusses the advantages / disadvantages and the applications
of various routing protocols for vehicular ad hoc networks. It explores the
motivation behind the designed, and traces the evolution of these routing
protocols. F inally the paper concludes by a tabular comparison of the various
routing protocols for VANET.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2095</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2095</id><created>2011-08-10</created><authors><author><keyname>Kumar</keyname><forenames>Rakesh</forenames></author><author><keyname>Dave</keyname><forenames>Mayank</forenames></author></authors><title>Mobile Agent as an Approach to Improve QoS in Vehicular Ad Hoc Network</title><categories>cs.NI cs.SI</categories><comments>6 pages,5 figures; IJCA Special Issue on &quot;Mobile Ad-hoc Networks&quot;
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Vehicular traffic is a foremost problem in modern cities. Huge amount of time
and resources are wasted while traveling due to traffic congestion. With the
introduction of sophisticated traffic management systems, such as those
incorporating dynamic traffic assignments, more stringent demands are being
placed upon the available real time traffic data. In this paper we have
proposed mobile agent as a mechanism to handle the traffic problem on road.
Mobile software agents can be used to provide the better QoS (Quality of
Service) in vehicular ad hoc network to improve the safety application and
driver comfort.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2096</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2096</id><created>2011-08-10</created><authors><author><keyname>Zhang</keyname><forenames>Yu</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author></authors><title>Reputation-based Incentive Protocols in Crowdsourcing Applications</title><categories>cs.AI cs.GT cs.SI physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Crowdsourcing websites (e.g. Yahoo! Answers, Amazon Mechanical Turk, and
etc.) emerged in recent years that allow requesters from all around the world
to post tasks and seek help from an equally global pool of workers. However,
intrinsic incentive problems reside in crowdsourcing applications as workers
and requester are selfish and aim to strategically maximize their own benefit.
In this paper, we propose to provide incentives for workers to exert effort
using a novel game-theoretic model based on repeated games. As there is always
a gap in the social welfare between the non-cooperative equilibria emerging
when workers pursue their self-interests and the desirable Pareto efficient
outcome, we propose a novel class of incentive protocols based on social norms
which integrates reputation mechanisms into the existing pricing schemes
currently implemented on crowdsourcing websites, in order to improve the
performance of the non-cooperative equilibria emerging in such applications. We
first formulate the exchanges on a crowdsourcing website as a two-sided market
where requesters and workers are matched and play gift-giving games repeatedly.
Subsequently, we study the protocol designer's problem of finding an optimal
and sustainable (equilibrium) protocol which achieves the highest social
welfare for that website. We prove that the proposed incentives protocol can
make the website operate close to Pareto efficiency. Moreover, we also examine
an alternative scenario, where the protocol designer aims at maximizing the
revenue of the website and evaluate the performance of the optimal protocol.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2098</identifier>
 <datestamp>2013-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2098</id><created>2011-08-10</created><updated>2013-01-30</updated><authors><author><keyname>Chiesa</keyname><forenames>Alessandro</forenames></author><author><keyname>Forbes</keyname><forenames>Michael A.</forenames></author></authors><title>Improved Soundness for QMA with Multiple Provers</title><categories>quant-ph cs.CC</categories><comments>24 pages; comments welcome</comments><journal-ref>Chicago Journal of Theoretical Computer Science, Vol 2013, No 1</journal-ref><doi>10.4086/cjtcs.2013.001</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present three contributions to the understanding of QMA with multiple
provers:
  1) We give a tight soundness analysis of the protocol of [Blier and Tapp,
ICQNM '09], yielding a soundness gap Omega(1/N^2). Our improvement is achieved
without the use of an instance with a constant soundness gap (i.e., without
using a PCP).
  2) We give a tight soundness analysis of the protocol of [Chen and Drucker,
ArXiV '10], thereby improving their result from a monolithic protocol where
Theta(sqrt(N)) provers are needed in order to have any soundness gap, to a
protocol with a smooth trade-off between the number of provers k and a
soundness gap Omega(k^2/N), as long as k&gt;=Omega(log N). (And, when
k=Theta(sqrt(N)), we recover the original parameters of Chen and Drucker.)
  3) We make progress towards an open question of [Aaronson et al., ToC '09]
about what kinds of NP-complete problems are amenable to sublinear
multiple-prover QMA protocols, by observing that a large class of such examples
can easily be derived from results already in the PCP literature - namely, at
least the languages recognized by a non-deterministic RAMs in quasilinear time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2106</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2106</id><created>2011-08-10</created><authors><author><keyname>Ukil</keyname><forenames>Arijit</forenames></author></authors><title>Privacy Preserving Data Aggregation in Wireless Sensor Networks</title><categories>cs.CR cs.NI</categories><comments>6 Pages, 3 Figures, IEEE ICWMC 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Privacy preservation is an important issue in today's context of extreme
penetration of internet and mobile technologies. It is more important in the
case of Wireless Sensor Networks (WSNs) where collected data often requires
in-network processing and collaborative computing. Researches in this area are
mostly concentrated in applying data mining techniques to preserve the privacy
content of the data. These techniques are mostly computationally expensive and
not suitable for resource limited WSN nodes. In this paper, a scheme is
developed to provide privacy preservation in a much simpler way with the help
of a secure key management scheme and randomized data perturbation technique.
We consider a scenario in which two or more parties owning confidential data
need to share only for aggregation purpose to a third party, without revealing
the content of the data. Through simulation results the efficacy of our scheme
and compare the result with one of the established scheme [1].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2111</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2111</id><created>2011-08-10</created><authors><author><keyname>Ukil</keyname><forenames>Arijit</forenames></author></authors><title>Context Protecting Privacy Preservation in Ubiquitous Computing</title><categories>cs.CR cs.NI</categories><comments>6 pages, 7 Figures, IEEE CISIM 2010</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In ubiquitous computing domain context awareness is an important issue. So,
in ubiquitous computing, mere protection of message confidentiality is not
sufficient for most of the applications where context-awareness can lead to
near deterministic ideas. An adversary might deduce sensitive information by
observing the contextual data, which when correlated with prior information
about the people and the physical locations that are being monitored by a set
of sensors can reveal most of the sensitive information. So, it is obvious that
for security and privacy preservation in ubiquitous computing context
protection is of equal importance. In this paper, we propose a scheme which
provides two layer privacy protection of user's or application's context data.
Our proposed context protecting privacy preservation scheme focuses on
protecting spatial and temporal contextual information. We consider the
communication part of ubiquitous computing consists of tiny sensor nodes
forming Wireless Sensor Networks (WSNs). Through simulation we show the
efficacy of our scheme. We also demonstrate the capability of our scheme to
overcome the constraints of WSNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2115</identifier>
 <datestamp>2012-03-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2115</id><created>2011-08-10</created><updated>2012-03-21</updated><authors><author><keyname>van Ditmarsch</keyname><forenames>Hans</forenames></author></authors><title>The Ditmarsch Tale of Wonders - The Dynamics of Lying</title><categories>cs.AI cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a dynamic logic of lying, wherein a 'lie that phi' (where phi is a
formula in the logic) is an action in the sense of dynamic modal logic, that is
interpreted as a state transformer relative to the formula phi. The states that
are being transformed are pointed Kripke models encoding the uncertainty of
agents about their beliefs. Lies can be about factual propositions but also
about modal formulas, such as the beliefs of other agents or the belief
consequences of the lies of other agents. We distinguish (i) an outside
observer who is lying to an agent that is modelled in the system, from (ii) one
agent who is lying to another agent, and where both are modelled in the system.
For either case, we further distinguish (iii) the agent who believes everything
that it is told (even at the price of inconsistency), from (iv) the agent who
only believes what it is told if that is consistent with its current beliefs,
and from (v) the agent who believes everything that it is told by consistently
revising its current beliefs. The logics have complete axiomatizations, which
can most elegantly be shown by way of their embedding in what is known as
action model logic or the extension of that logic to belief revision.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2126</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2126</id><created>2011-08-10</created><authors><author><keyname>Kernbach</keyname><forenames>Serge</forenames></author><author><keyname>Dipper</keyname><forenames>Tobias</forenames></author><author><keyname>Sutantyo</keyname><forenames>Donny</forenames></author></authors><title>Multi-Modal Local Sensing and Communication for Collective Underwater
  Systems</title><categories>cs.RO cs.SY math.OC</categories><journal-ref>Proceedings of the 11th International Conference on Mobile Robots
  and Competitions, Robotica 2011, Lisbon, pp.96-101, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is devoted to local sensing and communication for collective
underwater systems used in networked and swarm modes. It is demonstrated that a
specific combination of modal and sub-modal communication, used simultaneously
for robot-robot and robot-object detection, can create a dedicated cooperation
between multiple AUVs. These technologies, platforms and experiments are
shortly described, and allow us to make a conclusion about useful combinations
of different signaling approaches for collective underwater systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2149</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2149</id><created>2011-08-10</created><authors><author><keyname>Mataracioglu</keyname><forenames>Tolga</forenames></author><author><keyname>Ozkan</keyname><forenames>Sevgi</forenames></author></authors><title>User Awareness Measurement Through Social Engineering</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  TUBITAK National Research Institute of Electronics and Cryptology (UEKAE)
Department of Information Systems Security makes social engineering attacks to
Turkish public agencies within the frame of &quot;Information Security Tests&quot; [19].
This paper will make an analysis of the social engineering tests that have been
carried out in several Turkish public agencies. The tests include phone calling
to sample employees by the social engineer and trying to seize employees'
sensitive information by exploiting their good faith. The aim of this research
is to figure that the employees in Turkish public agencies have a lack of
information security awareness and they compromise the information security
principles which should be necessarily applied for any public agencies. Social
engineering, both with its low cost and ability to take advantage of low
technology, has taken its place in the information security literature as a
very effective form of attack [8].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2150</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2150</id><created>2011-08-10</created><authors><author><keyname>Mataracioglu</keyname><forenames>Tolga</forenames></author><author><keyname>Ozkan</keyname><forenames>Sevgi</forenames></author></authors><title>Governing Information Security in Conjunction with COBIT and ISO 27001</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, after giving a brief definition of Information Security
Management Systems (ISMS), ISO 27001, IT governance and COBIT, pros and cons of
implementing only COBIT, implementing only IS0 27001 and implementing both
COBIT and ISO 27001 together when governing information security in enterprises
will be issued.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2151</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2151</id><created>2011-08-10</created><authors><author><keyname>Mataracioglu</keyname><forenames>Tolga</forenames></author><author><keyname>Tatar</keyname><forenames>Unal</forenames></author></authors><title>Digital Forensics Analysis of Spectral Estimation Methods</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Steganography is the art and science of writing hidden messages in such a way
that no one apart from the intended recipient knows of the existence of the
message. In today's world, it is widely used in order to secure the
information. In this paper, the traditional spectral estimation methods are
introduced. The performance analysis of each method is examined by comparing
all of the spectral estimation methods. Finally, from utilizing those
performance analyses, a brief pros and cons of the spectral estimation methods
are given. Also we give a steganography demo by hiding information into a sound
signal and manage to pull out the information (i.e, the true frequency of the
information signal) from the sound by means of the spectral estimation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2152</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2152</id><created>2011-08-10</created><authors><author><keyname>Mataracioglu</keyname><forenames>Tolga</forenames></author><author><keyname>Tatar</keyname><forenames>Unal</forenames></author></authors><title>Spectral Estimation Methods Comparison and Performance Analysis on a
  Steganalysis Application</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Steganography is the art and science of writing hidden messages in such a way
that no one apart from the intended recipient knows of the existence of the
message. In today's world, it is widely used in order to secure the
information. In this paper, the traditional spectral estimation methods are
introduced. The performance analysis of each method is examined by comparing
all of the spectral estimation methods. Finally, from utilizing those
performance analyses, a brief pros and cons of the spectral estimation methods
are given. Also we give a steganography demo by hiding information into a sound
signal and manage to pull out the information (i.e, the true frequency of the
information signal) from the sound by means of the spectral estimation methods.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2153</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2153</id><created>2011-08-10</created><authors><author><keyname>Tatar</keyname><forenames>Unal</forenames></author><author><keyname>Mataracioglu</keyname><forenames>Tolga</forenames></author></authors><title>Analysis and Implementation of Distinct Steganographic Methods</title><categories>cs.CR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, different steganographic methods have been analyzed and
implementations of those techniques have been performed. Those methods include
hiding in text, hiding in audio file, hiding in file system, and hiding in
image files.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2157</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2157</id><created>2011-08-10</created><authors><author><keyname>Golynski</keyname><forenames>Alexander</forenames></author><author><keyname>Orlandi</keyname><forenames>Alessio</forenames></author><author><keyname>Raman</keyname><forenames>Rajeev</forenames></author><author><keyname>Rao</keyname><forenames>S. Srinivasa</forenames></author></authors><title>Optimal Indexes for Sparse Bit Vectors</title><categories>cs.DS</categories><comments>Some of these results were published in preliminary form in the
  proceedings of SWAT 2008. There are new upper bounds not in the SWAT version,
  however</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of supporting Rank() and Select() operations on a bit
vector of length m with n 1 bits. The problem is considered in the succinct
index model, where the bit vector is stored in &quot;read-only&quot; memory and an
additional data structure, called the index, is created during pre-processing
to help answer the above queries. We give asymptotically optimal
density-sensitive trade-offs, involving both m and n, that relate the size of
the index to the number of accesses to the bit vector (and processing time)
needed to answer the above queries. The results are particularly interesting
for the case where n = o(m).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2162</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2162</id><created>2011-08-10</created><authors><author><keyname>Castiglione</keyname><forenames>Paolo</forenames></author><author><keyname>Savazzi</keyname><forenames>Stefano</forenames></author><author><keyname>Nicoli</keyname><forenames>Monica</forenames></author><author><keyname>Zemen</keyname><forenames>Thomas</forenames></author></authors><title>Partner selection in indoor-to-outdoor cooperative networks: an
  experimental study</title><categories>cs.NI</categories><comments>This work has been submitted to IEEE Journal on Selected Areas in
  Communications in August 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a partner selection protocol for enhancing the
network lifetime in cooperative wireless networks. The case-study is the
cooperative relayed transmission from fixed indoor nodes to a common outdoor
access point. A stochastic bivariate model for the spatial distribution of the
fading parameters that govern the link performance, namely the Rician K-factor
and the path-loss, is proposed and validated by means of real channel
measurements. The partner selection protocol is based on the real-time
estimation of a function of these fading parameters, i.e., the coding gain. To
reduce the complexity of the link quality assessment, a Bayesian approach is
proposed that uses the site-specific bivariate model as a-priori information
for the coding gain estimation. This link quality estimator allows network
lifetime gains almost as if all K-factor values were known. Furthermore, it
suits IEEE 802.15.4 compliant networks as it efficiently exploits the
information acquired from the receiver signal strength indicator. Extensive
numerical results highlight the trade-off between complexity, robustness to
model mismatches and network lifetime performance. We show for instance that
infrequent updates of the site-specific model through K-factor estimation over
a subset of links are sufficient to at least double the network lifetime with
respect to existing algorithms based on path loss information only.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2164</identifier>
 <datestamp>2013-03-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2164</id><created>2011-08-10</created><updated>2013-03-11</updated><authors><author><keyname>Koutschan</keyname><forenames>Christoph</forenames></author></authors><title>Lattice Green's Functions of the Higher-Dimensional Face-Centered Cubic
  Lattices</title><categories>math.CO cs.SC</categories><comments>16 pages, final version</comments><msc-class>82B41, 06B05, 33F10, 68W30, 05A15</msc-class><journal-ref>J. Phys. A: Math. Theor. 46 (2013) 125005</journal-ref><doi>10.1088/1751-8113/46/12/125005</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the face-centered cubic lattice (fcc) in up to six dimensions. In
particular, we are concerned with lattice Green's functions (LGF) and return
probabilities. Computer algebra techniques, such as the method of creative
telescoping, are used for deriving an ODE for a given LGF. For the four- and
five-dimensional fcc lattices, we give rigorous proofs of the ODEs that were
conjectured by Guttmann and Broadhurst. Additionally, we find the ODE of the
LGF of the six-dimensional fcc lattice, a result that was not believed to be
achievable with current computer hardware.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2187</identifier>
 <datestamp>2012-12-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2187</id><created>2011-08-10</created><updated>2012-12-05</updated><authors><author><keyname>Koch</keyname><forenames>Tobias</forenames></author><author><keyname>Kramer</keyname><forenames>Gerhard</forenames></author></authors><title>On Noncoherent Fading Relay Channels at High Signal-to-Noise Ratio</title><categories>cs.IT math.IT</categories><comments>19 pages, 2 figures. Replaced with version that will appear in the
  IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The capacity of noncoherent fading relay channels is studied where all
terminals are aware of the fading statistics but not of their realizations. It
is shown that if the fading coefficient of the channel between the transmitter
and the receiver can be predicted more accurately from its infinite past than
the fading coefficient of the channel between the relay and the receiver, then
at high signal-to-noise ratio (SNR) the relay does not increase capacity. It is
further shown that if the fading coefficient of the channel between the
transmitter and the relay can be predicted more accurately from its infinite
past than the fading coefficient of the channel between the relay and the
receiver, then at high SNR one can achieve communication rates that are within
one bit of the capacity of the multiple-input single-output fading channel that
results when the transmitter and the relay can cooperate.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2191</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2191</id><created>2011-08-10</created><authors><author><keyname>Bredereck</keyname><forenames>Robert</forenames></author></authors><title>Graph and Election Problems Parameterized by Feedback Set Numbers</title><categories>cs.CC cs.DS</categories><comments>A full-featured version can be found at http://robert.bredereck.info,
  where you can also find the complete abstract. (ArXiv allows only 1920
  characters.)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work investigates the parameterized complexity of three related graph
modification problems. Given a directed graph, a distinguished vertex, and a
positive integer k, Minimum Indegree Deletion asks for a vertex subset of size
at most k whose removal makes the distinguished vertex the only vertex with
minimum indegree. Minimum Degree Deletion is analogously defined, but deals
with undirected graphs. Bounded Degree Deletion is also defined on undirected
graphs, but has a positive integer d instead of a distinguished vertex as part
of the input. It asks for a vertex subset of size at most k whose removal
results in a graph in which every vertex has degree at most d. The first two
problems have applications in computational social choice whereas the third
problem is used in computational biology. We investigate the parameterized
complexity with respect to the parameters &quot;treewidth&quot;, &quot;size of a feedback
vertex set&quot; and &quot;size of a feedback edge set&quot; respectively &quot;size of a feedback
arc set&quot;. Each of these parameters measures the &quot;degree of acyclicity&quot; in
different ways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2201</identifier>
 <datestamp>2011-08-11</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2201</id><created>2011-08-10</created><authors><author><keyname>Tanaka</keyname><forenames>Yasuhito</forenames></author></authors><title>Brouwer's fixed point theorem with sequentially at most one fixed point</title><categories>math.LO cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a constructive proof of Brouwer's fixed point theorem with
sequentially at most one fixed point, and apply it to the mini-max theorem of
zero-sum games.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2234</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2234</id><created>2011-08-10</created><authors><author><keyname>Rajagopalan</keyname><forenames>S. Raj</forenames></author><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Mohajer</keyname><forenames>Soheil</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Smart Meter Privacy: A Utility-Privacy Framework</title><categories>cs.IT math.IT</categories><comments>Accepted for publication and presentation at the IEEE SmartGridComm.
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  End-user privacy in smart meter measurements is a well-known challenge in the
smart grid. The solutions offered thus far have been tied to specific
technologies such as batteries or assumptions on data usage. Existing solutions
have also not quantified the loss of benefit (utility) that results from any
such privacy-preserving approach. Using tools from information theory, a new
framework is presented that abstracts both the privacy and the utility
requirements of smart meter data. This leads to a novel privacy-utility
tradeoff problem with minimal assumptions that is tractable. Specifically for a
stationary Gaussian Markov model of the electricity load, it is shown that the
optimal utility-and-privacy preserving solution requires filtering out
frequency components that are low in power, and this approach appears to
encompass most of the proposed privacy approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2237</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2237</id><created>2011-08-10</created><authors><author><keyname>Sankar</keyname><forenames>Lalitha</forenames></author><author><keyname>Kar</keyname><forenames>Soummya</forenames></author><author><keyname>Tandon</keyname><forenames>Ravi</forenames></author><author><keyname>Poor</keyname><forenames>H. Vincent</forenames></author></authors><title>Competitive Privacy in the Smart Grid: An Information-theoretic Approach</title><categories>cs.IT math.IT</categories><comments>Accepted for publication and presentation at the IEEE SmartGridComm
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Advances in sensing and communication capabilities as well as power industry
deregulation are driving the need for distributed state estimation in the smart
grid at the level of the regional transmission organizations (RTOs). This leads
to a new competitive privacy problem amongst the RTOs since there is a tension
between sharing data to ensure network reliability (utility/benefit to all
RTOs) and withholding data for profitability and privacy reasons. The resulting
tradeoff between utility, quantified via fidelity of its state estimate at each
RTO, and privacy, quantified via the leakage of the state of one RTO at other
RTOs, is captured precisely using a lossy source coding problem formulation for
a two RTO network. For a two-RTO model, it is shown that the set of all
feasible utility-privacy pairs can be achieved via a single round of
communication when each RTO communicates taking into account the correlation
between the measured data at both RTOs. The lossy source coding problem and
solution developed here is also of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2283</identifier>
 <datestamp>2013-11-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2283</id><created>2011-08-10</created><updated>2013-11-20</updated><authors><author><keyname>Schl&#xfc;ter</keyname><forenames>Federico</forenames></author></authors><title>A survey on independence-based Markov networks learning</title><categories>cs.AI cs.LG</categories><comments>35 pages, 1 figure</comments><journal-ref>Schl\&quot;uter, F. (2011). A survey on independence-based Markov
  networks learning. Artificial Intelligence Review, 1-25</journal-ref><doi>10.1007/s10462-012-9346-y</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This work reports the most relevant technical aspects in the problem of
learning the \emph{Markov network structure} from data. Such problem has become
increasingly important in machine learning, and many other application fields
of machine learning. Markov networks, together with Bayesian networks, are
probabilistic graphical models, a widely used formalism for handling
probability distributions in intelligent systems. Learning graphical models
from data have been extensively applied for the case of Bayesian networks, but
for Markov networks learning it is not tractable in practice. However, this
situation is changing with time, given the exponential growth of computers
capacity, the plethora of available digital data, and the researching on new
learning technologies. This work stresses on a technology called
independence-based learning, which allows the learning of the independence
structure of those networks from data in an efficient and sound manner,
whenever the dataset is sufficiently large, and data is a representative
sampling of the target distribution. In the analysis of such technology, this
work surveys the current state-of-the-art algorithms for learning Markov
networks structure, discussing its current limitations, and proposing a series
of open problems where future works may produce some advances in the area in
terms of quality and efficiency. The paper concludes by opening a discussion
about how to develop a general formalism for improving the quality of the
structures learned, when data is scarce.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2290</identifier>
 <datestamp>2011-09-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2290</id><created>2011-08-10</created><updated>2011-09-06</updated><authors><author><keyname>Lee</keyname><forenames>James R.</forenames></author><author><keyname>de Mesmay</keyname><forenames>Arnaud</forenames></author><author><keyname>Moharrami</keyname><forenames>Mohammad</forenames></author></authors><title>Dimension reduction for finite trees in L_1</title><categories>math.MG cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that every n-point tree metric admits a (1+eps)-embedding into a
C(eps) log n-dimensional L_1 space, for every eps &gt; 0, where C(eps) =
O((1/eps)^4 log(1/eps)). This matches the natural volume lower bound up to a
factor depending only on eps. Previously, it was unknown whether even complete
binary trees on n nodes could be embedded in O(log n) dimensions with O(1)
distortion. For complete d-ary trees, our construction achieves C(eps) =
O(1/eps^2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2338</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2338</id><created>2011-08-11</created><authors><author><keyname>Canuto</keyname><forenames>Enrico</forenames></author><author><keyname>Acuna-Bravo</keyname><forenames>Wilber</forenames></author><author><keyname>Molano-Jimenez</keyname><forenames>Andr&#xe9;s</forenames></author><author><keyname>Ospina</keyname><forenames>Jos&#xe9;</forenames></author><author><keyname>Perez-Montenegro</keyname><forenames>Carlos</forenames></author></authors><title>Embedded Model Control approach to robust control</title><categories>cs.SY math.OC</categories><comments>Paper presented at the AUTOMATICA_IT 2011 conference, Pisa, Italy,
  September 2011. A simplified version has been presented at the 30th Chinese
  Control Conference, Yantai (China), July 22-24, 2011, 6267-6273, ISBN:
  9789881725592. A simplified version has been subimitted to ISA Transactions,
  2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Robust control design is mainly devoted to guarantee closed-loop stability of
a model-based control law in presence of parametric and structural
uncertainties. The control law is usually a complex feedback law which is
derived from a (nonlinear) model, possibly complemented with some mathematical
envelope of the model uncertainty. Stability may be guarantee with the help of
some ignorance coefficients and restricting the feedback control effort with
respect to the model-based design. Embedded Model Control shows that under
certain conditions, the model-based control law must and can be kept intact
under uncertainty, if the controllable dynamics is complemented by a suitable
disturbance dynamics capable of real-time encoding the different uncertainties
affecting the 'embedded model', i.e. the model which is both the design source
and the core of the control unit. To be real-time updated the disturbance state
is driven by an unpredictable input vector, called noise, which can be only
estimated from the model error. The uncertainty (or plant)-based design
concerns the noise estimator, as the model error may convey into the embedded
model uncertainty components (parametric, cross-coupling, neglected dynamics)
which are command-dependent and thus prone to destabilize the controlled plant.
Separation of the components into the low and high frequency domain by the
noise estimator allows to recover and guarantee stability, and to cancel the
low frequency ones from the plant. Among the advantages, control algorithms are
neatly and univocally related to the embedded model, the embedded model
provides a real-time image of the plant, all control gains are tuned by fixing
closed-loop eigenvalues. Last but not least, the resulting control unit has
modular structure and algorithms, thus facilitating coding. A simulated case
study helps to understand the key assets of the methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2348</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2348</id><created>2011-08-11</created><authors><author><keyname>Papapanagiotou</keyname><forenames>Petros</forenames><affiliation>University of Edinburgh</affiliation></author><author><keyname>Fleuriot</keyname><forenames>Jacques D.</forenames><affiliation>University of Edinburgh</affiliation></author></authors><title>A theorem proving framework for the formal verification of Web Services
  Composition</title><categories>cs.LO cs.NI</categories><comments>In Proceedings WWV 2011, arXiv:1108.2085</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 61, 2011, pp. 1-16</journal-ref><doi>10.4204/EPTCS.61.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a rigorous framework for the composition of Web Services within a
higher order logic theorem prover. Our approach is based on the
proofs-as-processes paradigm that enables inference rules of Classical Linear
Logic (CLL) to be translated into pi-calculus processes. In this setting,
composition is achieved by representing available web services as CLL
sentences, proving the requested composite service as a conjecture, and then
extracting the constructed pi-calculus term from the proof. Our framework,
implemented in HOL Light, not only uses an expressive logic that allows us to
incorporate multiple Web Services properties in the composition process, but
also provides guarantees of soundness and correctness for the composition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2349</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2349</id><created>2011-08-11</created><authors><author><keyname>Ibrahim</keyname><forenames>Naseem</forenames><affiliation>Concordia University</affiliation></author><author><keyname>Alagar</keyname><forenames>Vangalur</forenames><affiliation>Concordia University</affiliation></author><author><keyname>Mohammad</keyname><forenames>Mubarak</forenames><affiliation>Concordia University</affiliation></author></authors><title>Specification and Verification of Context-dependent Services</title><categories>cs.SE</categories><comments>In Proceedings WWV 2011, arXiv:1108.2085</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 61, 2011, pp. 17-33</journal-ref><doi>10.4204/EPTCS.61.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Current approaches for the discovery, specification, and provision of
services ignore the relationship between the service contract and the
conditions in which the service can guarantee its contract. Moreover, they do
not use formal methods for specifying services, contracts, and compositions.
Without a formal basis it is not possible to justify through formal
verification the correctness conditions for service compositions and the
satisfaction of contractual obligations in service provisions. We remedy this
situation in this paper. We present a formal definition of services with
context-dependent contracts. We define a composition theory of services with
context-dependent contracts taking into consideration functional,
nonfunctional, legal and contextual information. Finally, we present a formal
verification approach that transforms the formal specification of service
composition into extended timed automata that can be verified using the model
checking tool UPPAAL.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2350</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2350</id><created>2011-08-11</created><authors><author><keyname>ter Beek</keyname><forenames>Maurice H.</forenames><affiliation>ISTI-CNR</affiliation></author><author><keyname>Gnesi</keyname><forenames>Stefania</forenames><affiliation>ISTI-CNR</affiliation></author><author><keyname>Njima</keyname><forenames>Mercy N.</forenames><affiliation>IMT Lucca</affiliation></author></authors><title>Product Lines for Service Oriented Applications - PL for SOA</title><categories>cs.SE</categories><comments>In Proceedings WWV 2011, arXiv:1108.2085</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 61, 2011, pp. 34-48</journal-ref><doi>10.4204/EPTCS.61.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PL for SOA proposes, formally, a software engineering methodology,
development techniques and support tools for the provision of service product
lines. We propose rigorous modeling techniques for the specification and
verification of formal notations and languages for service computing with
inclinations of variability. Through these cutting-edge technologies, increased
levels of flexibility and adaptivity can be achieved. This will involve
developing semantics of variability over behavioural models of services. Such
tools will assist organizations to plan, optimize and control the quality of
software service provision, both at design and at run time by making it
possible to develop flexible and cost-effective software systems that support
high levels of reuse. We tackle this challenge from two levels. We use feature
modeling from product line engineering and, from a services point of view, the
orchestration language Orc. We introduce the Smart Grid as the service product
line to apply the techniques to.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2357</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2357</id><created>2011-08-11</created><authors><author><keyname>Garc&#xed;a</keyname><forenames>Boni</forenames><affiliation>UPM</affiliation></author><author><keyname>Due&#xf1;as</keyname><forenames>Juan Carlos</forenames><affiliation>UPM</affiliation></author></authors><title>Automated Functional Testing based on the Navigation of Web Applications</title><categories>cs.SE</categories><comments>In Proceedings WWV 2011, arXiv:1108.2085</comments><proxy>EPTCS</proxy><acm-class>D.2.5; I.2.2; G.2.2</acm-class><journal-ref>EPTCS 61, 2011, pp. 49-65</journal-ref><doi>10.4204/EPTCS.61.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web applications are becoming more and more complex. Testing such
applications is an intricate hard and time-consuming activity. Therefore,
testing is often poorly performed or skipped by practitioners. Test automation
can help to avoid this situation. Hence, this paper presents a novel approach
to perform automated software testing for web applications based on its
navigation. On the one hand, web navigation is the process of traversing a web
application using a browser. On the other hand, functional requirements are
actions that an application must do. Therefore, the evaluation of the correct
navigation of web applications results in the assessment of the specified
functional requirements. The proposed method to perform the automation is done
in four levels: test case generation, test data derivation, test case
execution, and test case reporting. This method is driven by three kinds of
inputs: i) UML models; ii) Selenium scripts; iii) XML files. We have
implemented our approach in an open-source testing framework named Automatic
Testing Platform. The validation of this work has been carried out by means of
a case study, in which the target is a real invoice management system developed
using a model-driven approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2358</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2358</id><created>2011-08-11</created><authors><author><keyname>Alpuente</keyname><forenames>Mar&#xed;a</forenames><affiliation>Universidad Polit&#xe9;cnica de Valencia</affiliation></author><author><keyname>Ballis</keyname><forenames>Demis</forenames><affiliation>University of Udine</affiliation></author><author><keyname>Espert</keyname><forenames>Javier</forenames><affiliation>Universidad Polit&#xe9;cnica de Valencia</affiliation></author><author><keyname>Frechina</keyname><forenames>Francisco</forenames><affiliation>Universidad Polit&#xe9;cnica de Valencia</affiliation></author><author><keyname>Romero</keyname><forenames>Daniel</forenames><affiliation>Universidad Polit&#xe9;cnica de Valencia</affiliation></author></authors><title>Debugging of Web Applications with Web-TLR</title><categories>cs.LO cs.SE</categories><comments>In Proceedings WWV 2011, arXiv:1108.2085</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 61, 2011, pp. 66-80</journal-ref><doi>10.4204/EPTCS.61.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web-TLR is a Web verification engine that is based on the well-established
Rewriting Logic--Maude/LTLR tandem for Web system specification and
model-checking. In Web-TLR, Web applications are expressed as rewrite theories
that can be formally verified by using the Maude built-in LTLR model-checker.
Whenever a property is refuted, a counterexample trace is delivered that
reveals an undesired, erroneous navigation sequence. Unfortunately, the
analysis (or even the simple inspection) of such counterexamples may be
unfeasible because of the size and complexity of the traces under examination.
In this paper, we endow Web-TLR with a new Web debugging facility that supports
the efficient manipulation of counterexample traces. This facility is based on
a backward trace-slicing technique for rewriting logic theories that allows the
pieces of information that we are interested to be traced back through inverse
rewrite sequences. The slicing process drastically simplifies the computation
trace by dropping useless data that do not influence the final result. By using
this facility, the Web engineer can focus on the relevant fragments of the
failing application, which greatly reduces the manual debugging effort and also
decreases the number of iterative verifications.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2359</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2359</id><created>2011-08-11</created><authors><author><keyname>Galletta</keyname><forenames>Letterio</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Pisa</affiliation></author><author><keyname>Levi</keyname><forenames>Giorgio</forenames><affiliation>Dipartimento di Informatica, Universit&#xe0; di Pisa</affiliation></author></authors><title>An Abstract Semantics for Inference of Types and Effects in a Multi-Tier
  Web Language</title><categories>cs.LO cs.PL</categories><comments>In Proceedings WWV 2011, arXiv:1108.2085</comments><proxy>EPTCS</proxy><acm-class>D.2.4;F.3.1;F.3.2</acm-class><journal-ref>EPTCS 61, 2011, pp. 81-95</journal-ref><doi>10.4204/EPTCS.61.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Types-and-effects are type systems, which allow one to express general
semantic properties and to statically reason about program's execution. They
have been widely exploited to specify static analyses, for example to track
computational side effects, exceptions and communications in concurrent
programs. In this paper we adopt abstract interpretation techniques to
reconstruct (following the Cousot's methodology) a types-and-effects system
developed to handle security problems of a multi-tier web language. Our
reconstruction allows us to show that this types-and-effects system is not
sound with respect to the semantics of the language. In addition, we correct
the soundness issues in the analysis and systematically construct a correct
analyser.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2360</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2360</id><created>2011-08-11</created><authors><author><keyname>Giunti</keyname><forenames>Marco</forenames><affiliation>INRIA and LIX, Ecole Polytechnique, France</affiliation></author></authors><title>A type checking algorithm for qualified session types</title><categories>cs.PL cs.LO</categories><comments>In Proceedings WWV 2011, arXiv:1108.2085</comments><proxy>EPTCS</proxy><acm-class>F.3</acm-class><journal-ref>EPTCS 61, 2011, pp. 96-114</journal-ref><doi>10.4204/EPTCS.61.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a type checking algorithm for establishing a session-based
discipline in the pi calculus of Milner, Parrow and Walker. Our session types
are qualified as linear or unrestricted. Linearly typed communication channels
are guaranteed to occur in exactly one thread, possibly multiple times;
afterwards they evolve as unrestricted channels. Session protocols are
described by a type constructor that denotes the two ends of one and the same
communication channel. We ensure the soundness of the algorithm by showing that
processes consuming all linear resources are accepted by a type system
preserving typings during the computation and that type checking is consistent
w.r.t. structural congruence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2376</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2376</id><created>2011-08-11</created><authors><author><keyname>Lopez-Ruiz</keyname><forenames>Ricardo</forenames></author><author><keyname>Sanudo</keyname><forenames>Jaime</forenames></author></authors><title>Heisenberg uncertainty relation and statistical measures in the square
  well</title><categories>nlin.AO cs.IT math.IT quant-ph</categories><comments>7 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A non stationary state in the one-dimensional infinite square well formed by
a combination of the ground state and the first excited one is considered. The
statistical complexity and the Fisher-Shannon entropy in position and momentum
are calculated with time for this system. These measures are compared with the
Heisenberg uncertainty relation, \Delta x\Delta p. It is observed that the
extreme values of \Delta x\Delta p coincide in time with extreme values of the
other two statistical magnitudes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2384</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2384</id><created>2011-08-11</created><authors><author><keyname>Polyvyanyy</keyname><forenames>Artem</forenames></author><author><keyname>Garc&#xed;a-Ba&#xf1;uelos</keyname><forenames>Luciano</forenames></author><author><keyname>Fahland</keyname><forenames>Dirk</forenames></author><author><keyname>Weske</keyname><forenames>Mathias</forenames></author></authors><title>Maximal Structuring of Acyclic Process Models</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper contributes to the solution of the problem of transforming a
process model with an arbitrary topology into an equivalent structured process
model. In particular, this paper addresses the subclass of process models that
have no equivalent well-structured representation but which, nevertheless, can
be partially structured into their maximally-structured representation. The
structuring is performed under a behavioral equivalence notion that preserves
observed concurrency of tasks in equivalent process models. The paper gives a
full characterization of the subclass of acyclic process models that have no
equivalent well-structured representation but do have an equivalent
maximally-structured one, as well as proposes a complete structuring method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2385</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2385</id><created>2011-08-11</created><authors><author><keyname>Chen</keyname><forenames>Shiteng</forenames></author><author><keyname>Lou</keyname><forenames>Tiancheng</forenames></author><author><keyname>Papakonstantinou</keyname><forenames>Periklis</forenames></author><author><keyname>Tang</keyname><forenames>Bangsheng</forenames></author></authors><title>Width-parameterized SAT: Time-Space Tradeoffs</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Width parameterizations of SAT, such as tree-width and path-width, enable the
study of computationally more tractable and practical SAT instances. We give
two simple algorithms. One that runs simultaneously in time-space
$(O^*(2^{2tw(\phi)}), O^*(2^{tw(\phi)}))$ and another that runs in time-space
$(O^*(3^{tw(\phi)\log{|\phi|}}),|\phi|^{O(1)})$, where $tw(\phi)$ is the
tree-width of a formula $\phi$ with $|\phi|$ many clauses and variables. This
partially answers the question of Alekhnovitch and Razborov, who also gave
algorithms exponential both in time and space, and asked whether the space can
be made smaller. We conjecture that every algorithm for this problem that runs
in time $2^{tw(\phi)\mathbf{o(\log{|\phi|})}}$ necessarily blows up the space
to exponential in $tw(\phi)$.
  We introduce a novel way to combine the two simple algorithms that allows us
to trade \emph{constant} factors in the exponents between running time and
space. Our technique gives rise to a family of algorithms controlled by two
parameters. By fixing one parameter we obtain an algorithm that runs in
time-space $(O^*(3^{1.441(1-\epsilon)tw(\phi)\log{|\phi|}}), O^*(2^{2\epsilon
tw(\phi)}))$, for every $0&lt;\epsilon&lt;1$. We systematically study the limitations
of this technique, and show that these algorithmic results are the best
achievable using this technique.
  We also study further the computational complexity of width parameterizations
of SAT. We prove non-sparsification lower bounds for formulas of path-width
$\omega(\log|\phi|)$, and a separation between the complexity of path-width and
tree-width parametrized SAT modulo plausible complexity assumptions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2389</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2389</id><created>2011-08-05</created><authors><author><keyname>Ismail</keyname><forenames>Anis</forenames></author><author><keyname>Hajjar</keyname><forenames>Abd El Salam Al</forenames></author><author><keyname>Ismail</keyname><forenames>Ziad</forenames></author></authors><title>A New System Architecture for Pervasive Computing</title><categories>cs.OH</categories><comments>15 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new system architecture, a distributed framework designed to
support pervasive computing applications. We propose a new architecture
consisting of a search engine and peripheral clients that addresses issues in
scalability, data sharing, data transformation and inherent platform
heterogeneity. Key features of our application are a type-aware data transport
that is capable of extract data, and present data through handheld devices (PDA
(personal digital assistant), mobiles, etc). Pervasive computing uses web
technology, portable devices, wireless communications and nomadic or ubiquitous
computing systems. The web and the simple standard HTTP protocol that it is
based on, facilitate this kind of ubiquitous access. This can be implemented on
a variety of devices - PDAs, laptops, information appliances such as digital
cameras and printers. Mobile users get transparent access to resources outside
their current environment. We discuss our system's architecture and its
implementation. Through experimental study, we show reasonable performance and
adaptation for our system's implementation for the mobile devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2393</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2393</id><created>2011-08-11</created><updated>2011-08-14</updated><authors><author><keyname>Wang</keyname><forenames>Qiwen</forenames></author><author><keyname>Jaggi</keyname><forenames>Sidharth</forenames></author><author><keyname>Li</keyname><forenames>Shuo-Yen Robert</forenames></author></authors><title>Binary Error Correcting Network Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider network coding for networks experiencing worst-case bit-flip
errors, and argue that this is a reasonable model for highly dynamic wireless
network transmissions. We demonstrate that in this setup prior network
error-correcting schemes can be arbitrarily far from achieving the optimal
network throughput. We propose a new metric for errors under this model. Using
this metric, we prove a new Hamming-type upper bound on the network capacity.
We also show a commensurate lower bound based on GV-type codes that can be used
for error-correction. The codes used to attain the lower bound are non-coherent
(do not require prior knowledge of network topology). The end-to-end nature of
our design enables our codes to be overlaid on classical distributed random
linear network codes. Further, we free internal nodes from having to implement
potentially computationally intensive link-by-link error-correction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2427</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2427</id><created>2011-08-11</created><authors><author><keyname>Diekert</keyname><forenames>Volker</forenames></author><author><keyname>Kopecki</keyname><forenames>Steffen</forenames></author><author><keyname>Mitrana</keyname><forenames>Victor</forenames></author></authors><title>Deciding Regularity of Hairpin Completions of Regular Languages in
  Polynomial Time</title><categories>cs.FL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The hairpin completion is an operation on formal languages that has been
inspired by the hairpin formation in DNA biochemistry and by DNA computing. In
this paper we investigate the hairpin completion of regular languages.
  It is well known that hairpin completions of regular languages are linear
context-free and not necessarily regular. As regularity of a (linear)
context-free language is not decidable, the question arose whether regularity
of a hairpin completion of regular languages is decidable. We prove that this
problem is decidable and we provide a polynomial time algorithm.
  Furthermore, we prove that the hairpin completion of regular languages is an
unambiguous linear context-free language and, as such, it has an effectively
computable growth function. Moreover, we show that the growth of the hairpin
completion is exponential if and only if the growth of the underlying languages
is exponential and, in case the hairpin completion is regular, then the hairpin
completion and the underlying languages have the same growth indicator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2452</identifier>
 <datestamp>2011-12-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2452</id><created>2011-08-11</created><updated>2011-12-28</updated><authors><author><keyname>Leme</keyname><forenames>Renato Paes</forenames></author><author><keyname>Syrgkanis</keyname><forenames>Vasilis</forenames></author><author><keyname>Tardos</keyname><forenames>Eva</forenames></author></authors><title>Sequential Auctions and Externalities</title><categories>cs.GT</categories><comments>Accepted to SODA'12</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In many settings agents participate in multiple different auctions that are
not necessarily implemented simultaneously. Future opportunities affect
strategic considerations of the players in each auction, introducing
externalities. Motivated by this consideration, we study a setting of a market
of buyers and sellers, where each seller holds one item, bidders have
combinatorial valuations and sellers hold item auctions sequentially.
  Our results are qualitatively different from those of simultaneous auctions,
proving that simultaneity is a crucial aspect of previous work. We prove that
if sellers hold sequential first price auctions then for unit-demand bidders
(matching market) every subgame perfect equilibrium achieves at least half of
the optimal social welfare, while for submodular bidders or when second price
auctions are used, the social welfare can be arbitrarily worse than the
optimal. We also show that a first price sequential auction for buying or
selling a base of a matroid is always efficient, and implements the VCG
outcome.
  An important tool in our analysis is studying first and second price auctions
with externalities (bidders have valuations for each possible winner outcome),
which can be of independent interest. We show that a Pure Nash Equilibrium
always exists in a first price auction with externalities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2462</identifier>
 <datestamp>2014-05-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2462</id><created>2011-08-11</created><updated>2014-05-20</updated><authors><author><keyname>Baldi</keyname><forenames>Marco</forenames></author><author><keyname>Bianchi</keyname><forenames>Marco</forenames></author><author><keyname>Chiaraluce</keyname><forenames>Franco</forenames></author><author><keyname>Rosenthal</keyname><forenames>Joachim</forenames></author><author><keyname>Schipani</keyname><forenames>Davide</forenames></author></authors><title>Enhanced public key security for the McEliece cryptosystem</title><categories>cs.IT cs.CR math.IT</categories><comments>31 pages, 1 figure. Accepted for publication in the Journal of
  Cryptology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies a variant of the McEliece cryptosystem able to ensure that
the code used as the public key is no longer permutation-equivalent to the
secret code. This increases the security level of the public key, thus opening
the way for reconsidering the adoption of classical families of codes, like
Reed-Solomon codes, that have been longly excluded from the McEliece
cryptosystem for security reasons. It is well known that codes of these classes
are able to yield a reduction in the key size or, equivalently, an increased
level of security against information set decoding; so, these are the main
advantages of the proposed solution. We also describe possible vulnerabilities
and attacks related to the considered system, and show what design choices are
best suited to avoid them.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2464</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2464</id><created>2011-08-11</created><authors><author><keyname>Khot</keyname><forenames>Subhash</forenames></author><author><keyname>Naor</keyname><forenames>Assaf</forenames></author></authors><title>Grothendieck-type inequalities in combinatorial optimization</title><categories>cs.DS cs.CC math.CO math.FA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We survey connections of the Grothendieck inequality and its variants to
combinatorial optimization and computational complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2475</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2475</id><created>2011-08-10</created><authors><author><keyname>Asha</keyname><forenames>V.</forenames></author></authors><title>Undithering using linear filtering and non-linear diffusion techniques</title><categories>cs.CV cs.IT math.IT</categories><comments>14 pages, 15 figures. International Journal of Artificial
  Intelligence, Spring 2009, Volume 2, Number S09</comments><report-no>ISSN: 0974-0635</report-no><msc-class>34A34, 60JC, 62H10, 15A99</msc-class><acm-class>G.3; I.4.2; I.4.5</acm-class><journal-ref>International Journal of Artificial Intelligence, Spring 2009,
  Volume 2, Number S09</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data compression is a method of improving the efficiency of transmission and
storage of images. Dithering, as a method of data compression, can be used to
convert an 8-bit gray level image into a 1-bit / binary image. Undithering is
the process of reconstruction of gray image from binary image obtained from
dithering of gray image. In the present paper, I propose a method of
undithering using linear filtering followed by anisotropic diffusion which
brings the advantage of smoothing and edge enhancement. First-order statistical
parameters, second-order statistical parameters, mean-squared error (MSE)
between reconstructed image and the original image before dithering, and peak
signal to noise ratio (PSNR) are evaluated at each step of diffusion. Results
of the experiments show that the reconstructed image is not as sharp as the
image before dithering but a large number of gray values are reproduced with
reference to those of the original image prior to dithering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2479</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2479</id><created>2011-08-11</created><authors><author><keyname>Yonge-Mallo</keyname><forenames>David</forenames></author></authors><title>Adversary lower bounds in the Hamiltonian oracle model</title><categories>quant-ph cs.CC</categories><comments>6 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note, we show that quantum lower bounds obtained using the adversary
method hold in the Hamiltonian oracle model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2482</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2482</id><created>2011-08-11</created><authors><author><keyname>Shivale</keyname><forenames>Saurabh Anandrao</forenames></author></authors><title>Cryptovirology: Virus Approach</title><categories>cs.CR</categories><journal-ref>International Journal of Network Security &amp; Its Applications
  (IJNSA), Vol.3, No.4, July 2011</journal-ref><doi>10.5121/ijnsa.2011.3404</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Traditionally, &quot;Cryptography&quot; is a benediction to information processing and
communications, it helps people to store information securely and the private
communications over long distances. Cryptovirology is the study of applications
of cryptography to build the malicious software. It is an investigation, how
modern cryptographic tools and paradigms can be used to strengthen, develop and
improve new malicious software attacks. Cryptovirology attacks have been
categorized as : give malware enhanced privacy and be more robust against
reverse-engineering, secondly give the attacker enhanced anonymity while
communicating with deployed malware. This paper presents the idea of
&quot;Cryptovirology&quot; which introduce a twist on how cryptography can also be used
offensively. Being offensive means, it can be used to mount extortion based
attacks that cause loss of access to information, loss of confidentiality, and
information leakage, tasks which cryptography usually prevents. Also analyze
threats and attacks that misuse of cryptography can cause when combined with
fraudulent software (viruses, Trojans). Public-key cryptography is very
essential for the attacks that based on cryptovirology. This paper also suggest
some of the countermeasures, mechanisms to cope with and prevent such attacks.
Even if the attackers actions on the host machine are being monitored, it still
cannot be proven beyond reasonable doubt that he or she is the attacker; and it
is an &quot;originator-concealing attack&quot;. Evidence should be collected from the
&quot;author's own system which was used for the attack&quot;. These attacks have
implications on how the use of cryptographic tools and techniques should be
audited and managed in general purpose computing environments, and imply that
access to the cryptographic tools should be in well control of the system(such
as API routines).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2486</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2486</id><created>2011-08-11</created><authors><author><keyname>Blythe</keyname><forenames>Duncan</forenames></author><author><keyname>von B&#xfc;nau</keyname><forenames>Paul</forenames></author><author><keyname>Meinecke</keyname><forenames>Frank</forenames></author><author><keyname>M&#xfc;ller</keyname><forenames>Klaus-Robert</forenames></author></authors><title>Feature Extraction for Change-Point Detection using Stationary Subspace
  Analysis</title><categories>cs.LG</categories><comments>24 pages, 20 figures, journal preprint</comments><doi>10.1109/TNNLS.2012.2185811</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting changes in high-dimensional time series is difficult because it
involves the comparison of probability densities that need to be estimated from
finite samples. In this paper, we present the first feature extraction method
tailored to change point detection, which is based on an extended version of
Stationary Subspace Analysis. We reduce the dimensionality of the data to the
most non-stationary directions, which are most informative for detecting state
changes in the time series. In extensive simulations on synthetic data we show
that the accuracy of three change point detection algorithms is significantly
increased by a prior feature extraction step. These findings are confirmed in
an application to industrial fault monitoring.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2489</identifier>
 <datestamp>2011-08-12</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2489</id><created>2011-08-11</created><authors><author><keyname>Blasiak</keyname><forenames>Anna</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Lubetzky</keyname><forenames>Eyal</forenames></author></authors><title>Lexicographic products and the power of non-linear network coding</title><categories>cs.IT math.CO math.IT</categories><comments>29 pages</comments><msc-class>94A29, 68P30, 90C35</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a technique for establishing and amplifying gaps between
parameters of network coding and index coding. The technique uses linear
programs to establish separations between combinatorial and coding-theoretic
parameters and applies hypergraph lexicographic products to amplify these
separations. This entails combining the dual solutions of the lexicographic
multiplicands and proving that they are a valid dual of the product. Our result
is general enough to apply to a large family of linear programs. This blend of
linear programs and lexicographic products gives a recipe for constructing hard
instances in which the gap between combinatorial or coding-theoretic parameters
is polynomially large. We find polynomial gaps in cases in which the largest
previously known gaps were only small constant factors or entirely unknown.
Most notably, we show a polynomial separation between linear and non-linear
network coding rates. This involves exploiting a connection between matroids
and index coding to establish a previously unknown separation between linear
and non-linear index coding rates. We also construct index coding problems with
a polynomial gap between the broadcast rate and the trivial lower bound for
which no gap was previously known.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2498</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2498</id><created>2011-08-11</created><updated>2012-05-25</updated><authors><author><keyname>Baryshnikov</keyname><forenames>Yuliy</forenames></author><author><keyname>Zharnitsky</keyname><forenames>Vadim</forenames></author></authors><title>Search on the Brink of Chaos</title><categories>math.CA cs.DS math.DS math.OC</categories><comments>27 pages, 8 figures</comments><doi>10.1088/0951-7715/25/11/3023</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The classical linear search problem is studied from the view point of
Hamiltonian dynamics. For the specific, yet representative case of
exponentially distributed position of the hidden object, we show that the
optimal plan follows an unstable separatrix which is present in the associated
Hamiltonian system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2514</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2514</id><created>2011-08-11</created><authors><author><keyname>Cloud</keyname><forenames>Jason</forenames></author><author><keyname>Zeger</keyname><forenames>Linda</forenames></author><author><keyname>M&#xe9;dard</keyname><forenames>Muriel</forenames></author></authors><title>Effects of MAC Approaches on Non-Monotonic Saturation with COPE - A
  Simple Case Study</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We construct a simple network model to provide insight into network design
strategies. We show that the model can be used to address various approaches to
network coding, MAC, and multi-packet reception so that their effects on
network throughput can be evaluated. We consider several topology components
which exhibit the same non-monotonic saturation behavior found within the Katti
et. al. COPE experiments. We further show that fairness allocation by the MAC
can seriously impact performance and cause this non-monotonic saturation. Using
our model, we develop a MAC that provides monotonic saturation, higher
saturation throughput gains and fairness among flows rather than nodes. The
proposed model provides an estimate of the achievable gains for the cross-layer
design of network coding, multi-packet reception, and MAC showing that
super-additive throughput gains on the order of six times that of routing are
possible.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2559</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2559</id><created>2011-08-12</created><authors><author><keyname>Weston</keyname><forenames>Stuart</forenames></author><author><keyname>Natusch</keyname><forenames>Timothy</forenames></author><author><keyname>Gulyaev</keyname><forenames>Sergei</forenames></author></authors><title>Radio Astronomy Data Transfer and eVLBI using KAREN</title><categories>astro-ph.IM cs.NI</categories><comments>5 pages, 2 tables, 1 figure, Accepted for The XXX General Assembly
  and Scientific Symposium of the International Union of Radio Science (Union
  Radio Scientifique Internationale-URSI)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Kiwi Advanced Research and Education Network (KAREN) has been used to
transfer large volumes of radio astronomical data between the Radio
Astronomical Observatory at Warkworth, New Zealand and various international
organizations involved in joint projects and VLBI observations. Here we report
on the current status of connectivity and on the results of testing different
data transfer protocols. We investigate new UDP protocols such as 'tsunami' and
UDT and demonstrate that the UDT protocol is more efficient than 'tsunami' and
'ftp'. We also report on the tests on direct data streaming from the radio
telescope receiving system to the correlation centre without intermediate
buffering or recording (real-time eVLBI).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2562</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2562</id><created>2011-08-12</created><authors><author><keyname>Dmitry</keyname><forenames>Khlopin</forenames></author></authors><title>The transversality conditions in infinite horizon problems and the
  stability of adjoint variable</title><categories>math.OC cs.SY</categories><msc-class>49K15, 49J45, 37N40, 34D05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the necessary conditions of optimality for uni-
formly overtaking optimal control on infinite horizon with free right endpoint.
Clarke's form of the Pontryagin Maximum Principle is proved without the as-
sumption on boundedness of total variation of adjoint variable. The
transversality condition for adjoint variable is shown to become necessary if
the adjoint variable is partially Lyapunov stable. The modifications of this
condition are proposed for the case of unbounded adjoint variable. The
Cauchy-type formula for the adjoint variable proposed by S. M. Aseev and A. V.
Kryazhimskii is shown to complement relations of the Pontryagin Maximum
Principle up to the complete set of necessary conditions of optimality if the
improper integral in the formula converges conditionally and continuously
depends on the original position. The results are extended to an unbounded
objective functional (described by a non- convergent improper integral),
unbounded constraint on the control, and uniformly sporadically catching up
optimal control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2568</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2568</id><created>2011-08-12</created><authors><author><keyname>Rehman</keyname><forenames>Obaid ur</forenames></author><author><keyname>Petersen</keyname><forenames>Ian R.</forenames></author><author><keyname>Fidan</keyname><forenames>Baris</forenames></author></authors><title>A Minimax Linear Quadratic Gaussian Method for Antiwindup Control
  Synthesis</title><categories>cs.SY math.OC</categories><comments>Australian control conference paper, 7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a dynamic antiwindup compensator design is proposed which
augments the main controller and guarantees robust performance in the event of
input saturation. This is a two stage process in which first a robust optimal
controller is designed for an uncertain linear system which guarantees the
internal stability of the closed loop system and provides robust performance in
the absence of input saturation. Then a minimax linear quadratic Gaussian (LQG)
compensator is designed to guarantee the performance in certain domain of
attraction, in the presence of input saturation. This antiwindup augmentation
only comes into action when plant is subject to input saturation. In order to
illustrate the effectiveness of this approach, the proposed method is applied
to a tracking control problem for an air-breathing hypersonic flight vehicle
(AHFV).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2580</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2580</id><created>2011-08-12</created><updated>2011-08-17</updated><authors><author><keyname>Wu</keyname><forenames>Yao</forenames></author><author><keyname>Yan</keyname><forenames>Qiang</forenames></author><author><keyname>Bickson</keyname><forenames>Danny</forenames></author><author><keyname>Low</keyname><forenames>Yucheng</forenames></author><author><keyname>Yang</keyname><forenames>Qing</forenames></author></authors><title>Efficient Multicore Collaborative Filtering</title><categories>cs.LG cs.DC</categories><comments>In ACM KDD CUP Workshop 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper describes the solution method taken by LeBuSiShu team for track1
in ACM KDD CUP 2011 contest (resulting in the 5th place). We identified two
main challenges: the unique item taxonomy characteristics as well as the large
data set size.To handle the item taxonomy, we present a novel method called
Matrix Factorization Item Taxonomy Regularization (MFITR). MFITR obtained the
2nd best prediction result out of more then ten implemented algorithms. For
rapidly computing multiple solutions of various algorithms, we have implemented
an open source parallel collaborative filtering library on top of the GraphLab
machine learning framework. We report some preliminary performance results
obtained using the BlackLight supercomputer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2585</identifier>
 <datestamp>2012-05-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2585</id><created>2011-08-12</created><updated>2012-05-24</updated><authors><author><keyname>Lemmen</keyname><forenames>Carsten</forenames></author></authors><title>Malthusian assumptions, Boserupian response in models of the transitions
  to agriculture</title><categories>q-bio.PE cs.MA nlin.AO</categories><comments>Chapter in: &quot;Society, Nature and History: The Legacy of Ester
  Boserup&quot;, Springer, Vienna (in press)</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the many transitions from foraging to agropastoralism it is debated
whether the primary drivers are innovations in technology or increases of
population. The driver discussion traditionally separates Malthusian
(technology driven) from Boserupian (population driven) theories. I present a
numerical model of the transitions to agriculture and discuss this model in the
light of the population versus technology debate and in Boserup's analytical
framework in development theory. Although my model is based on ecological
-Neomalthusian- principles, the coevolutionary positive feedback relationship
between technology and population results in a seemingly Boserupian response:
innovation is greatest when population pressure is highest. This outcome is not
only visible in the theory-driven reduced model, but is also present in a
corresponding &quot;real world&quot; simulator which was tested against archaeological
data, demonstrating the relevance and validity of the coevolutionary model. The
lesson to be learned is that not all that acts Boserupian needs Boserup at its
core.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2590</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2590</id><created>2011-08-12</created><updated>2012-04-19</updated><authors><author><keyname>Caldarelli</keyname><forenames>Guido</forenames></author><author><keyname>Cristelli</keyname><forenames>Matthieu</forenames></author><author><keyname>Gabrielli</keyname><forenames>Andrea</forenames></author><author><keyname>Pietronero</keyname><forenames>Luciano</forenames></author><author><keyname>Scala</keyname><forenames>Antonio</forenames></author><author><keyname>Tacchella</keyname><forenames>Andrea</forenames></author></authors><title>A network analysis of countries' export flows: firm grounds for the
  building blocks of the economy</title><categories>physics.soc-ph cs.SI physics.comp-ph physics.data-an</categories><comments>17 pages, 5 figures</comments><journal-ref>PLoS ONE 7(10): e47278 2012</journal-ref><doi>10.1371/journal.pone.0047278</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we analyze the bipartite network of countries and products from
UN data on country production. We define the country-country and
product-product projected networks and introduce a novel method of filtering
information based on elements' similarity. As a result we find that country
clustering reveals unexpected socio-geographic links among the most competing
countries. On the same footings the products clustering can be efficiently used
for a bottom-up classification of produced goods. Furthermore we mathematically
reformulate the &quot;reflections method&quot; introduced by Hidalgo and Hausmann as a
fixpoint problem; such formulation highlights some conceptual weaknesses of the
approach. To overcome such an issue, we introduce an alternative methodology
(based on biased Markov chains) that allows to rank countries in a conceptually
consistent way. Our analysis uncovers a strong non-linear interaction between
the diversification of a country and the ubiquity of its products, thus
suggesting the possible need of moving towards more efficient and direct
non-linear fixpoint algorithms to rank countries and products in the global
market.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2606</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2606</id><created>2011-08-12</created><authors><author><keyname>Zayani</keyname><forenames>Mohamed-Haykel</forenames></author><author><keyname>Gauthier</keyname><forenames>Vincent</forenames></author><author><keyname>Slama</keyname><forenames>Ines</forenames></author><author><keyname>Zeghlache</keyname><forenames>Djamal</forenames></author></authors><title>Tensor-Based Link Prediction in Intermittently Connected Wireless
  Networks</title><categories>cs.NI</categories><comments>13 pages, 9 figures, 8 tables, submitted to the International Journal
  of Computer and Telecommunications Networking (COMNET)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Through several studies, it has been highlighted that mobility patterns in
mobile networks are driven by human behaviors. This effect has been
particularly observed in intermittently connected networks like DTN (Delay
Tolerant Networks). Given that common social intentions generate similar human
behavior, it is relevant to exploit this knowledge in the network protocols
design, e.g. to identify the closeness degree between two nodes. In this paper,
we propose a temporal link prediction technique for DTN which quantifies the
behavior similarity between each pair of nodes and makes use of it to predict
future links. Our prediction method keeps track of the spatio-temporal aspects
of nodes behaviors organized as a third-order tensor that aims to records the
evolution of the network topology. After collapsing the tensor information, we
compute the degree of similarity for each pair of nodes using the Katz measure.
This metric gives us an indication on the link occurrence between two nodes
relying on their closeness. We show the efficiency of this method by applying
it on three mobility traces: two real traces and one synthetic trace. Through
several simulations, we demonstrate the effectiveness of the technique
regarding another approach based on a similarity metric used in DTN. The
validity of this method is proven when the computation of score is made in a
distributed way (i.e. with local information). We attest that the tensor-based
technique is effective for temporal link prediction applied to the
intermittently connected networks. Furthermore, we think that this technique
can go beyond the realm of DTN and we believe this can be further applied on
every case of figure in which there is a need to derive the underlying social
structure of a network of mobile users.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2613</identifier>
 <datestamp>2013-05-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2613</id><created>2011-08-12</created><updated>2013-05-08</updated><authors><author><keyname>Yakaryilmaz</keyname><forenames>Abuzer</forenames></author><author><keyname>Say</keyname><forenames>A. C. Cem</forenames></author></authors><title>Tight bounds for the space complexity of nonregular language recognition
  by real-time machines</title><categories>cs.CC cs.FL</categories><comments>13 pages. A revised version with some corrections (we omitted Fact 2
  and two subsequent proofs (of Theorems 11 and 12 in the previous version))</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We examine the minimum amount of memory for real-time, as opposed to one-way,
computation accepting nonregular languages. We consider deterministic,
nondeterministic and alternating machines working within strong, middle and
weak space, and processing general or unary inputs. In most cases, we are able
to show that the lower bounds for one-way machines remain tight in the
real-time case. Memory lower bounds for nonregular acceptance on other devices
are also addressed. It is shown that increasing the number of stacks of
real-time pushdown automata can result in exponential improvement in the total
amount of space usage for nonregular language recognition.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2632</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2632</id><created>2011-08-12</created><authors><author><keyname>Som</keyname><forenames>Subhojit</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>Compressive Imaging using Approximate Message Passing and a Markov-Tree
  Prior</title><categories>cs.CV</categories><doi>10.1109/TSP.2012.2191780</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a novel algorithm for compressive imaging that exploits both the
sparsity and persistence across scales found in the 2D wavelet transform
coefficients of natural images. Like other recent works, we model wavelet
structure using a hidden Markov tree (HMT) but, unlike other works, ours is
based on loopy belief propagation (LBP). For LBP, we adopt a recently proposed
&quot;turbo&quot; message passing schedule that alternates between exploitation of HMT
structure and exploitation of compressive-measurement structure. For the
latter, we leverage Donoho, Maleki, and Montanari's recently proposed
approximate message passing (AMP) algorithm. Experiments with a large image
database suggest that, relative to existing schemes, our turbo LBP approach
yields state-of-the-art reconstruction performance with substantial reduction
in complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2634</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2634</id><created>2011-08-12</created><authors><author><keyname>Muench</keyname><forenames>Mathieu</forenames></author></authors><title>Classification of Emergency Scenarios</title><categories>cs.OH</categories><comments>10 pages. TU Darmstadt ProSeminar</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In most of today's emergency scenarios information plays a crucial role.
Therefore, information has to be constantly collected and shared among all
rescue team members and this requires new innovative technologies. In this
paper a classification of emergency scenarios is presented, describing their
special characteristics and common strategies employed by rescue units to
handle them. Based on interviews with professional firefighters, requirements
for new systems are listed. The goal of this article is to support developers
designing new systems by providing them a deeper look into the work of first
responders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2644</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2644</id><created>2011-08-12</created><authors><author><keyname>Karjee</keyname><forenames>Jyotirmoy</forenames></author><author><keyname>Jamadagni</keyname><forenames>H. S</forenames></author></authors><title>Data Accuracy Model for Distributed Clustering Algorithm based on
  Spatial Data Correlation in Wireless Sensor Networks</title><categories>cs.NI</categories><comments>18 pages</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Objective: The main objective of this paper is to construct a distributed
clustering algorithm based upon spatial data correlation among sensor nodes and
perform data accuracy for each distributed cluster at their respective cluster
head node. Design Procedure/Approach: We investigate that due to deployment of
high density of sensor nodes in the sensor field, spatial data are highly
correlated among sensor nodes in spatial domain. Based on high data correlation
among sensor nodes, we propose a non -overlapping irregular distributed
clustering algorithm with different sizes to collect most accurate or precise
data at the cluster head node for each respective distributed cluster. To
collect the most accurate data at the cluster head node for each distributed
cluster in sensor field, we propose a Data accuracy model and compare the
results with Information accuracy model. Finding: Simulation results shows that
our propose Data accuracy model collects more accurate data and gives better
performance than Information accuracy model at the cluster head node for each
respective distributed cluster in our propose distributed clustering
algorithm.Morover there exist a optimal cluster of sensor nodes which is
adequate to perform approximately the same data accuracy achieve by a cluster.
Practical Implementation: Measuring humidity and moisture content in an
agricultural field, measuring temperature in physical environment. Inventive
/Novel Idea: A distributed clustering algorithm is proposed based on spatial
data correlation among sensor nodes with Data accuracy model.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2656</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2656</id><created>2011-08-12</created><authors><author><keyname>Sedjelmaci</keyname><forenames>Hichem</forenames></author><author><keyname>Feham</keyname><forenames>Mohamed</forenames></author></authors><title>Novel hybrid intrusion detection system for clustered wireless sensor
  network</title><categories>cs.CR</categories><comments>14 pages</comments><doi>10.5121/ijnsa.2011.3401</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless sensor network (WSN) is regularly deployed in unattended and hostile
environments. The WSN is vulnerable to security threats and susceptible to
physical capture. Thus, it is necessary to use effective mechanisms to protect
the network. It is widely known, that the intrusion detection is one of the
most efficient security mechanisms to protect the network against malicious
attacks or unauthorized access. In this paper, we propose a hybrid intrusion
detection system for clustered WSN. Our intrusion framework uses a combination
between the Anomaly Detection based on support vector machine (SVM) and the
Misuse Detection. Experiments results show that most of routing attacks can be
detected with low false alarm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2664</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2664</id><created>2011-08-12</created><updated>2013-05-02</updated><authors><author><keyname>Whidden</keyname><forenames>Chris</forenames></author><author><keyname>Beiko</keyname><forenames>Robert G.</forenames></author><author><keyname>Zeh</keyname><forenames>Norbert</forenames></author></authors><title>Fixed-Parameter and Approximation Algorithms for Maximum Agreement
  Forests</title><categories>q-bio.PE cs.DS</categories><comments>36 pages, 9 figures. Removed the Approximation and TBR sections and
  simplified the Hybridization section. To appear in SIAM Journal on Computing</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new and improved fixed-parameter algorithms for computing maximum
agreement forests (MAFs) of pairs of rooted binary phylogenetic trees. The size
of such a forest for two trees corresponds to their subtree prune-and-regraft
distance and, if the agreement forest is acyclic, to their hybridization
number. These distance measures are essential tools for understanding
reticulate evolution. Our algorithm for computing maximum acyclic agreement
forests is the first depth-bounded search algorithm for this problem. Our
algorithms substantially outperform the best previous algorithms for these
problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2683</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2683</id><created>2011-08-12</created><authors><author><keyname>Toussi</keyname><forenames>Hamid A.</forenames></author><author><keyname>Khademzadeh</keyname><forenames>Ahmed</forenames></author></authors><title>Improving bit-vector representation of points-to sets using class
  hierarchy</title><categories>cs.PL</categories><journal-ref>Proceeding of ICSCT 2010, Kunming, China, November 2010</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Points-to analysis is the problem of approximating run-time values of
pointers statically or at compile-time. Points-to sets are used to store the
approximated values of pointers during points-to analysis. Memory usage and
running time limit the ability of points-to analysis to analyze large programs.
  To our knowledge, works which have implemented a bit-vector representation of
points-to sets so far, allocates bits for each pointer without considering
pointer's type. By considering the type, we are able to allocate bits only for
a subset of all abstract objects which are of compatible type with the
pointer's type and as a consequence improve the memory usage and running time.
To achieve this goal, we number abstract objects in a way that all the abstract
objects of a type and all of its sub-types be consecutive in order.
  Our most efficient implementation uses about 2.5 times less memory than
hybrid points-to set (default points-to set in Spark) and also improves the
analysis time for sufficiently large programs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2684</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2684</id><created>2011-08-12</created><authors><author><keyname>Lyubarskii</keyname><forenames>Yurii</forenames></author><author><keyname>Nes</keyname><forenames>Preben Gr&#xe5;berg</forenames></author></authors><title>Gabor frames with rational density</title><categories>cs.IT math.IT</categories><comments>13 pages, 2 figures</comments><msc-class>33C90, 42C15, 94A12</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the frame property of the Gabor system G(g, {\alpha}, {\beta}) =
{e2{\pi}i{\beta}nt g(t - {\alpha}m) : m, n \in Z} for the case of rational
oversampling, i.e. {\alpha}, {\beta} \in Q. A 'rational' analogue of the
Ron-Shen Gramian is constructed, and prove that for any odd window function g
the system G(g, {\alpha}, {\beta}) does not generate a frame if {\alpha}{\beta}
= (n-1)/n. Special attention is paid to the first Hermite function h_1(t) =
te^(-{\pi}t^2).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2685</identifier>
 <datestamp>2011-08-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2685</id><created>2011-08-12</created><authors><author><keyname>Gollapudi</keyname><forenames>Sreenivas</forenames></author><author><keyname>Ieong</keyname><forenames>Samuel</forenames></author><author><keyname>Ntoulas</keyname><forenames>Alexandros</forenames></author><author><keyname>Paparizos</keyname><forenames>Stelios</forenames></author></authors><title>Efficient Query Rewrite for Structured Web Queries</title><categories>cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Web search engines and specialized online verticals are increasingly
incorporating results from structured data sources to answer semantically rich
user queries. For example, the query \WebQuery{Samsung 50 inch led tv} can be
answered using information from a table of television data. However, the users
are not domain experts and quite often enter values that do not match precisely
the underlying data. Samsung makes 46- or 55- inch led tvs, but not 50-inch
ones. So a literal execution of the above mentioned query will return zero
results. For optimal user experience, a search engine would prefer to return at
least a minimum number of results as close to the original query as possible.
Furthermore, due to typical fast retrieval speeds in web-search, a search
engine query execution is time-bound.
  In this paper, we address these challenges by proposing algorithms that
rewrite the user query in a principled manner, surfacing at least the required
number of results while satisfying the low-latency constraint. We formalize
these requirements and introduce a general formulation of the problem. We show
that under a natural formulation, the problem is NP-Hard to solve optimally,
and present approximation algorithms that produce good rewrites. We empirically
validate our algorithms on large-scale data obtained from a commercial search
engine's shopping vertical.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2700</identifier>
 <datestamp>2011-09-14</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2700</id><created>2011-08-14</created><updated>2011-09-12</updated><authors><author><keyname>Ginsparg</keyname><forenames>Paul</forenames><affiliation>Cornell University</affiliation></author></authors><title>It was twenty years ago today ...</title><categories>cs.DL astro-ph.IM cond-mat.other gr-qc hep-ph hep-th math.HO physics.soc-ph quant-ph</categories><comments>9 pages. v2: additional edifying comments interspersed throughout</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  To mark the 20th anniversary of the (14 Aug 1991) commencement of
hep-th@xxx.lanl.gov (now arXiv.org), I've adapted this article from one that
first appeared in Physics World (2008), was later reprinted (with permission)
in Learned Publishing (2009), but never appeared in arXiv. I trace some
historical context and early development of the resource, its later trajectory,
and close with some thoughts about the future.
  This version is closer to my original draft, with some updates for this
occasion, plus an astounding $2^5$ added footnotes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2704</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2704</id><created>2011-08-12</created><authors><author><keyname>Nielson</keyname><forenames>Seth James</forenames></author><author><keyname>Fogarty</keyname><forenames>Seth J.</forenames></author><author><keyname>Wallach</keyname><forenames>Dan S.</forenames></author></authors><title>Attacks on Local Searching Tools</title><categories>cs.CR</categories><comments>Previously unpublished technical report from December 2004</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Google Desktop Search is an indexing tool, currently in beta testing,
designed to allow users fast, intuitive, searching for local files. The
principle interface is provided through a local web server which supports an
interface similar to Google.com's normal web page. Indexing of local files
occurs when the system is idle, and understands a number of common file types.
A optional feature is that Google Desktop can integrate a short summary of a
local search results with Google.com web searches. This summary includes 30-40
character snippets of local files. We have uncovered a vulnerability that would
release private local data to an unauthorized remote entity. Using two
different attacks, we expose the small snippets of private local data to a
remote third party.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2714</identifier>
 <datestamp>2012-03-15</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2714</id><created>2011-08-12</created><updated>2012-03-13</updated><authors><author><keyname>Cohn</keyname><forenames>Henry</forenames></author><author><keyname>Heninger</keyname><forenames>Nadia</forenames></author></authors><title>Approximate common divisors via lattices</title><categories>math.NT cs.CR cs.IT math.IT</categories><comments>17 pages</comments><proxy>Henry Cohn</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the multivariate generalization of Howgrave-Graham's algorithm for
the approximate common divisor problem. In the m-variable case with modulus N
and approximate common divisor of size N^beta, this improves the size of the
error tolerated from N^(beta^2) to N^(beta^((m+1)/m)), under a commonly used
heuristic assumption. This gives a more detailed analysis of the hardness
assumption underlying the recent fully homomorphic cryptosystem of van Dijk,
Gentry, Halevi, and Vaikuntanathan. While these results do not challenge the
suggested parameters, a 2^(n^epsilon) approximation algorithm with epsilon&lt;2/3
for lattice basis reduction in n dimensions could be used to break these
parameters. We have implemented our algorithm, and it performs better in
practice than the theoretical analysis suggests.
  Our results fit into a broader context of analogies between cryptanalysis and
coding theory. The multivariate approximate common divisor problem is the
number-theoretic analogue of multivariate polynomial reconstruction, and we
develop a corresponding lattice-based algorithm for the latter problem. In
particular, it specializes to a lattice-based list decoding algorithm for
Parvaresh-Vardy and Guruswami-Rudra codes, which are multivariate extensions of
Reed-Solomon codes. This yields a new proof of the list decoding radii for
these codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2716</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2716</id><created>2011-08-12</created><authors><author><keyname>Nielson</keyname><forenames>Seth James</forenames></author><author><keyname>Spare</keyname><forenames>Caleb E.</forenames></author><author><keyname>Wallach</keyname><forenames>Dan S.</forenames></author></authors><title>Building Better Incentives for Robustness in BitTorrent</title><categories>cs.GT cs.NI</categories><comments>14 pages, 11 figures, technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  BitTorrent is a widely-deployed, peer-to-peer file transfer protocol
engineered with a &quot;tit for tat&quot; mechanism that encourages cooperation.
Unfortunately, there is little incentive for nodes to altruistically provide
service to their peers after they finish downloading a file, and what altruism
there is can be exploited by aggressive clients like Bit- Tyrant. This
altruism, called seeding, is always beneficial and sometimes essential to
BitTorrent's real-world performance. We propose a new long-term incentives
mechanism in BitTorrent to encourage peers to seed and we evaluate its
effectiveness via simulation. We show that when nodes running our algorithm
reward one another for good behavior in previous swarms, they experience as
much as a 50% improvement in download times over unrewarded nodes. Even when
aggressive clients, such as BitTyrant, participate in the swarm, our rewarded
nodes still outperform them, although by smaller margins.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2718</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2718</id><created>2011-08-12</created><authors><author><keyname>Nielson</keyname><forenames>Seth James</forenames></author><author><keyname>Wallach</keyname><forenames>Dan S.</forenames></author></authors><title>The BitTorrent Anonymity Marketplace</title><categories>cs.CR</categories><comments>15 page, 6 figure, technical report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The very nature of operations in peer-to-peer systems such as BitTorrent
exposes information about participants to their peers. Nodes desiring
anonymity, therefore, often chose to route their peer-to-peer traffic through
anonymity relays, such as Tor. Unfortunately, these relays have little
incentive for contribution and struggle to scale with the high loads that P2P
traffic foists upon them. We propose a novel modification for BitTorrent that
we call the BitTorrent Anonymity Marketplace. Peers in our system trade in k
swarms obscuring the actual intent of the participants. But because peers can
cross-trade torrents, the k-1 cover traffic can actually serve a useful
purpose. This creates a system wherein a neighbor cannot determine if a node
actually wants a given torrent, or if it is only using it as leverage to get
the one it really wants. In this paper, we present our design, explore its
operation in simulation, and analyze its effectiveness. We demonstrate that the
upload and download characteristics of cover traffic and desired torrents are
statistically difficult to distinguish.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2728</identifier>
 <datestamp>2012-02-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2728</id><created>2011-08-12</created><updated>2012-02-09</updated><authors><author><keyname>Kakhbod</keyname><forenames>Ali</forenames></author></authors><title>Market Mechanisms with Non-Price-Taking Agents</title><categories>math.OC cs.SY</categories><comments>&quot;IEEE Transactions on Automatic Control (TAC)&quot;, 27 pages (one column)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper develops a decentralized resource allocation mechanism for
allocating divisible goods with capacity constraints to non-price-taking agents
with general concave utilities. The proposed mechanism is always budget
balanced, individually rational, and it converges to an optimal solution of the
corresponding centralized problem. Such a mechanism is very useful in a network
with general topology and no auctioneer where the competitive agents/users want
different type of services.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2741</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2741</id><created>2011-08-12</created><authors><author><keyname>Gad</keyname><forenames>Eyal En</forenames><affiliation>Andrew</affiliation></author><author><keyname>Anxiao</keyname><affiliation>Andrew</affiliation></author><author><keyname>Jiang</keyname></author><author><keyname>Bruck</keyname><forenames>Jehoshua</forenames></author></authors><title>Compressed Encoding for Rank Modulation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rank modulation has been recently proposed as a scheme for storing
information in flash memories. While rank modulation has advantages in
improving write speed and endurance, the current encoding approach is based on
the &quot;push to the top&quot; operation that is not efficient in the general case. We
propose a new encoding procedure where a cell level is raised to be higher than
the minimal necessary subset - instead of all - of the other cell levels. This
new procedure leads to a significantly more compressed (lower charge levels)
encoding. We derive an upper bound for a family of codes that utilize the
proposed encoding procedure, and consider code constructions that achieve that
bound for several special cases.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2754</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2754</id><created>2011-08-12</created><authors><author><keyname>Raman</keyname><forenames>Karthik</forenames></author><author><keyname>Joachims</keyname><forenames>Thorsten</forenames></author><author><keyname>Shivaswamy</keyname><forenames>Pannaga</forenames></author></authors><title>Structured Learning of Two-Level Dynamic Rankings</title><categories>cs.IR</categories><comments>10 Pages (Longer Version of CIKM 2011 paper containing more details
  and experiments)</comments><acm-class>H.3.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For ambiguous queries, conventional retrieval systems are bound by two
conflicting goals. On the one hand, they should diversify and strive to present
results for as many query intents as possible. On the other hand, they should
provide depth for each intent by displaying more than a single result. Since
both diversity and depth cannot be achieved simultaneously in the conventional
static retrieval model, we propose a new dynamic ranking approach. Dynamic
ranking models allow users to adapt the ranking through interaction, thus
overcoming the constraints of presenting a one-size-fits-all static ranking. In
particular, we propose a new two-level dynamic ranking model for presenting
search results to the user. In this model, a user's interactions with the
first-level ranking are used to infer this user's intent, so that second-level
rankings can be inserted to provide more results relevant for this intent.
Unlike for previous dynamic ranking models, we provide an algorithm to
efficiently compute dynamic rankings with provable approximation guarantees for
a large family of performance measures. We also propose the first principled
algorithm for learning dynamic ranking functions from training data. In
addition to the theoretical results, we provide empirical evidence
demonstrating the gains in retrieval quality that our method achieves over
conventional approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2755</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2755</id><created>2011-08-12</created><authors><author><keyname>Yeung</keyname><forenames>E.</forenames></author><author><keyname>Goncalves</keyname><forenames>J.</forenames></author><author><keyname>Sandberg</keyname><forenames>H.</forenames></author><author><keyname>Warnick</keyname><forenames>S.</forenames></author></authors><title>The Meaning of Structure in Interconnected Dynamic Systems</title><categories>cs.SY cs.SI math.DS math.OC physics.soc-ph</categories><comments>21 pages, to appear in IEEE Control Systems Magazine 2012 Special
  Invited Issue: Designing Controls for Modern Infrastructure Networks</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Interconnected dynamic systems are a pervasive component of our modern
infrastructures. The complexity of such systems can be staggering, which
motivates simplified representations for their manipulation and analysis. This
work introduces the complete computational structure of a system as a common
baseline for comparing different simplified representations. Linear systems are
then used as a vehicle for comparing and contrasting distinct partial structure
representations. Such representations simplify the description of a system's
complete computational structure at various levels of fidelity while retaining
a full description of the system's input-output dynamic behavior. Relationships
between these various partial structure representations are detailed, and the
landscape of new realization, minimality, and model reduction problems
introduced by these representations is briefly surveyed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2758</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2758</id><created>2011-08-13</created><authors><author><keyname>Seki</keyname><forenames>Shinnosuke</forenames></author></authors><title>Absoluteness of subword inequality is undecidable</title><categories>cs.FL</categories><msc-class>68Q17, 68Q45</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mateescu, Salomaa, and Yu asked: is it decidable whether a given subword
history assumes only non-negative values for all words over a given alphabet.
In this paper, we solve this open problem by proving that this problem is
undecidable even under stronger conditions than supposed originally.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2769</identifier>
 <datestamp>2012-05-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2769</id><created>2011-08-13</created><updated>2012-01-26</updated><authors><author><keyname>Foucaud</keyname><forenames>Florent</forenames><affiliation>LaBRI</affiliation></author><author><keyname>Honkala</keyname><forenames>Iiro</forenames><affiliation>IF</affiliation></author><author><keyname>Laihonen</keyname><forenames>Tero</forenames><affiliation>IF</affiliation></author><author><keyname>Parreau</keyname><forenames>Aline</forenames><affiliation>IF</affiliation></author><author><keyname>Perarnau</keyname><forenames>Guillem</forenames><affiliation>UPC</affiliation></author></authors><title>Locally identifying colourings for graphs with given maximum degree</title><categories>math.CO cs.DM</categories><proxy>ccsd</proxy><journal-ref>Discrete Mathematics 312, 10 (2012) 1832--1837</journal-ref><doi>10.1016/j.disc.2012.01.034</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A proper vertex-colouring of a graph G is said to be locally identifying if
for any pair u,v of adjacent vertices with distinct closed neighbourhoods, the
sets of colours in the closed neighbourhoods of u and v are different. We show
that any graph G has a locally identifying colouring with $2\Delta^2-3\Delta+3$
colours, where $\Delta$ is the maximum degree of G, answering in a positive way
a question asked by Esperet et al. We also provide similar results for locally
identifying colourings which have the property that the colours in the
neighbourhood of each vertex are all different and apply our method to the
class of chordal graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2776</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2776</id><created>2011-08-13</created><authors><author><keyname>Piran</keyname><forenames>Mohammad Jalil</forenames></author><author><keyname>Murthy</keyname><forenames>G. Rama</forenames></author><author><keyname>Babu</keyname><forenames>G. Praveen</forenames></author></authors><title>Vehicular Ad Hoc and Sensor Networks; Principles and Challenges</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The rapid increase of vehicular traffic and congestion on the highways began
hampering the safe and efficient movement of traffic. Consequently, year by
year, we see the ascending rate of car accidents and casualties in most of the
countries. Therefore, exploiting the new technologies, e.g. wireless sensor
networks, is required as a solution of reduction of these saddening and
reprehensible statistics. This has motivated us to propose a novel and
comprehensive system to utilize Wireless Sensor Networks for vehicular
networks. We coin the vehicular network employing wireless Sensor networks as
Vehicular Ad Hoc and Sensor Network, or VASNET in short. The proposed VASNET is
particularly for highway traffic .VASNET is a self-organizing Ad Hoc and sensor
network comprised of a large number of sensor nodes. In VASNET there are two
kinds of sensor nodes, some are embedded on the vehicles-vehicular nodes- and
others are deployed in predetermined distances besides the highway road, known
as Road Side Sensor nodes (RSS). The vehicular nodes are used to sense the
velocity of the vehicle for instance. We can have some Base Stations (BS) such
as Police Traffic Station, Firefighting Group and Rescue Team. The base
stations may be stationary or mobile. VASNET provides capability of wireless
communication between vehicular nodes and stationary nodes, to increase safety
and comfort for vehicles on the highway roads. In this paper we explain main
fundamentals and challenges of VASNET.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2777</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2777</id><created>2011-08-13</created><authors><author><keyname>Ahvar</keyname><forenames>Ehsan</forenames></author><author><keyname>Pourmoslemi</keyname><forenames>Alireza</forenames></author><author><keyname>Piran</keyname><forenames>Mohammad Jalil</forenames></author></authors><title>Fear: A Fuzzy-based Energy-aware Routing Protocol for Wireless Sensor
  Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many energy-aware routing protocols have been proposed for wireless sensor
networks. Most of them are only energy savers and do not take care about energy
balancing. The energy saver protocols try to decrease the energy consumption of
the network as a whole; however the energy manager protocols balance the energy
consumption in the network to avoid network partitioning. This means that
energy saver protocols are not necessarily energy balancing and vice versa.
However, the lifetime of wireless sensor network is strictly depending on
energy consumption; therefore, energy management is an essential task to be
considered. This paper proposes an energy aware routing protocol, named FEAR,
which considers energy balancing and energy saving. It finds a fair trade-off
between energy balancing and energy saving by fuzzy set concept. FEAR routing
protocol is simulated and evaluated by Glomosim simulator.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2783</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2783</id><created>2011-08-13</created><updated>2011-09-10</updated><authors><author><keyname>Donkers</keyname><forenames>M. C. F.</forenames></author><author><keyname>Tabuada</keyname><forenames>P.</forenames></author><author><keyname>Heemels</keyname><forenames>W. P. M. H.</forenames></author></authors><title>On the Minimum Attention and the Anytime Attention Control Problems for
  Linear Systems: A Linear Programming Approach</title><categories>math.OC cs.SY</categories><comments>Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present two control laws that are tailored for control
applications in which computational and/or communication resources are scarce.
Namely, we consider minimum attention control, where the `attention' that a
control task requires is minimised given certain performance requirements, and
anytime attention control, where the performance under the `attention' given by
a scheduler is maximised. Here, we interpret `attention' as the inverse of the
time elapsed between two consecutive executions of a control task. By focussing
on linear plants, by allowing for only a finite number of possible intervals
between two subsequent executions of the control task, by making a novel
extension to the notion of control Lyapunov functions and taking these novel
extended control Lyapunov function to be infinity-norm-based, we can formulate
the aforementioned control problems as online linear programs, which can be
solved efficiently. Furthermore, we provide techniques to construct suitable
infinity-norm-based extended control Lyapunov functions for our purposes.
Finally, we illustrate the resulting control laws using numerical examples. In
particular, we show that minimum attention control outperforms an alternative
implementation-aware control law available in the literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2796</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2796</id><created>2011-08-13</created><authors><author><keyname>Reniers</keyname><forenames>M. A.</forenames><affiliation>Eindhoven University of Technology, The Netherlands</affiliation></author><author><keyname>Sobocinski</keyname><forenames>P.</forenames><affiliation>University of Southampton, United Kingdom</affiliation></author></authors><title>Proceedings Eight Workshop on Structural Operational Semantics 2011</title><categories>cs.LO cs.PL</categories><proxy>EPTCS</proxy><journal-ref>EPTCS 62, 2011</journal-ref><doi>10.4204/EPTCS.62</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of SOS 2011, the Eight Workshop on
Structural Operational Semantics, held on the 5th of September 2011 in Aachen,
Germany as an affiliated workshop of CONCUR 2011, the 22nd International
Conference on Concurrency Theory.
  Structural operational semantics (SOS) provides a framework for giving
operational semantics to programming and specification languages. A growing
number of programming languages from commercial and academic spheres have been
given usable semantic descriptions by means of structural operational
semantics. Because of its intuitive appeal and flexibility, structural
operational semantics has found considerable application in the study of the
semantics of concurrent processes. It is also a viable alternative to
denotational semantics in the static analysis of programs, and in proving
compiler correctness. Moreover, it has found application in emerging areas of
computing such as probabilistic systems and systems biology.
  Structural operational semantics has been successfully applied as a formal
tool to establish results that hold for classes of process description
languages. This has allowed for the generalization of well-known results in the
field of process algebra, and for the development of a meta-theory for process
calculi based on the realization that many of the results in this field only
depend upon general semantic properties of language constructs.
  The workshop is a forum for researchers, students and practitioners
interested in new developments and directions for future investigations. One of
the specific goals of the workshop is to provide a meeting point for the
concurrency and programming language communities. Another goal is the
dissemination of the theory and practice of SOS amongst postgraduate students
and young researchers worldwide.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2805</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2805</id><created>2011-08-13</created><authors><author><keyname>Leibon</keyname><forenames>Greg</forenames></author><author><keyname>Pauls</keyname><forenames>Scott</forenames></author><author><keyname>Rockmore</keyname><forenames>Daniel N.</forenames></author><author><keyname>Savell</keyname><forenames>Robert</forenames></author></authors><title>Partition Decomposition for Roll Call Data</title><categories>stat.AP cs.SI stat.ML</categories><comments>45 pages, 6 Figures, 2 Tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we bring to bear some new tools from statistical learning on
the analysis of roll call data. We present a new data-driven model for roll
call voting that is geometric in nature. We construct the model by adapting the
&quot;Partition Decoupling Method,&quot; an unsupervised learning technique originally
developed for the analysis of families of time series, to produce a multiscale
geometric description of a weighted network associated to a set of roll call
votes. Central to this approach is the quantitative notion of a &quot;motivation,&quot; a
cluster-based and learned basis element that serves as a building block in the
representation of roll call data. Motivations enable the formulation of a
quantitative description of ideology and their data-dependent nature makes
possible a quantitative analysis of the evolution of ideological factors. This
approach is generally applicable to roll call data and we apply it in
particular to the historical roll call voting of the U.S. House and Senate.
This methodology provides a mechanism for estimating the dimension of the
underlying action space. We determine that the dominant factors form a low-
(one- or two-) dimensional representation with secondary factors adding
higher-dimensional features. In this way our work supports and extends the
findings of both Poole-Rosenthal and Heckman-Snyder concerning the
dimensionality of the action space. We give a detailed analysis of several
individual Senates and use the AdaBoost technique from statistical learning to
determine those votes with the most powerful discriminatory value. When used as
a predictive model, this geometric view significantly outperforms spatial
models such as the Poole-Rosenthal DW-NOMINATE model and the Heckman-Snyder
6-factor model, both in raw accuracy as well as Aggregate Proportional Reduced
Error (APRE).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2815</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2815</id><created>2011-08-13</created><updated>2011-12-02</updated><authors><author><keyname>Li</keyname><forenames>Chong</forenames></author><author><keyname>Elia</keyname><forenames>Nicola</forenames></author></authors><title>The Information Flow and Capacity of Channels with Noisy Feedback</title><categories>cs.IT math.IT</categories><comments>Updated due to an error in Theorem 6 in the previous version. The
  definition of typical closed-loop encoder is also refined in the current
  version</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider some long-standing problems in communication
systems with access to noisy feedback. We introduce a new notion, the residual
directed information, to capture the effective information flow (i.e. mutual
information between the message and the channel outputs) in the forward
channel. In light of this new concept, we investigate discrete memoryless
channels (DMC) with noisy feedback and prove that the noisy feedback capacity
is not achievable by using any typical closed-loop encoder (non-trivially
taking feedback information to produce channel inputs). We then show that the
residual directed information can be used to characterize the capacity of
channels with noisy feedback. Finally, we provide computable bounds on the
noisy feedback capacity, which are characterized by the causal conditional
directed information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2816</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2816</id><created>2011-08-13</created><authors><author><keyname>Li</keyname><forenames>Chong</forenames></author><author><keyname>Elia</keyname><forenames>Nicola</forenames></author></authors><title>Bounds on the Achievable Rate of Noisy feedback Gaussian Channels under
  Linear Feedback Coding Scheme</title><categories>cs.IT math.IT</categories><comments>5 pages, 6 figures. Published in Proc. of International Symposium on
  Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the additive Gaussian noise channel with noisy
feedback. We consider the setup of linear coding of the feedback information
and Gaussian signaling of the message (i.e. Cover-Pombra Scheme). Then, we
derive the upper and lower bounds on the largest achievable rate for this
setup. We show that these two bounds can be obtained by solving two convex
optimization problems. Finally, we present some simulations and discussion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2820</identifier>
 <datestamp>2012-01-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2820</id><created>2011-08-13</created><updated>2012-01-28</updated><authors><author><keyname>Sapir</keyname><forenames>Marina</forenames></author></authors><title>Ensemble Risk Modeling Method for Robust Learning on Scarce Data</title><categories>cs.LG stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In medical risk modeling, typical data are &quot;scarce&quot;: they have relatively
small number of training instances (N), censoring, and high dimensionality (M).
We show that the problem may be effectively simplified by reducing it to
bipartite ranking, and introduce new bipartite ranking algorithm, Smooth Rank,
for robust learning on scarce data. The algorithm is based on ensemble learning
with unsupervised aggregation of predictors. The advantage of our approach is
confirmed in comparison with two &quot;gold standard&quot; risk modeling methods on 10
real life survival analysis datasets, where the new approach has the best
results on all but two datasets with the largest ratio N/M. For systematic
study of the effects of data scarcity on modeling by all three methods, we
conducted two types of computational experiments: on real life data with
randomly drawn training sets of different sizes, and on artificial data with
increasing number of features. Both experiments demonstrated that Smooth Rank
has critical advantage over the popular methods on the scarce data; it does not
suffer from overfitting where other methods do.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2822</identifier>
 <datestamp>2011-09-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2822</id><created>2011-08-13</created><updated>2011-09-10</updated><authors><author><keyname>Wang</keyname><forenames>Cheng</forenames></author><author><keyname>Strathman</keyname><forenames>Anthony</forenames></author><author><keyname>Lizardo</keyname><forenames>Omar</forenames></author><author><keyname>Hachen</keyname><forenames>David</forenames></author><author><keyname>Toroczkai</keyname><forenames>Zoltan</forenames></author><author><keyname>Chawla</keyname><forenames>Nitesh V.</forenames></author></authors><title>Weighted reciprocity in human communication networks</title><categories>cs.SI physics.soc-ph</categories><comments>14 pages, 5 figures, 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we define a metric for reciprocity---the degree of balance in a
social relationship---appropriate for weighted social networks in order to
investigate the distribution of this dyadic feature in a large-scale system
built from trace-logs of over a billion cell-phone communication events across
millions of actors. We find that dyadic relations in this network are
characterized by much larger degrees of imbalance than we would expect if
persons kept only those relationships that exhibited close to full reciprocity.
We point to two structural features of human communication behavior and
relationship formation---the division of contacts into strong and weak ties and
the tendency to form relationships with similar others---that either help or
hinder the ability of persons to obtain communicative balance in their
relationships. We examine the extent to which deviations from reciprocity in
the observed network are partially traceable to these characteristics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2829</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2829</id><created>2011-08-13</created><updated>2013-03-19</updated><authors><author><keyname>Parzysz</keyname><forenames>Fanny</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author><author><keyname>Gagnon</keyname><forenames>Fran&#xe7;ois</forenames></author></authors><title>Energy Minimization for the Half-Duplex Relay Channel with
  Decode-Forward Relaying</title><categories>cs.IT math.IT</categories><comments>To appear on IEEE Trans. on Communications</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze coding for energy efficiency in relay channels at a fixed source
rate. We first propose a half-duplex decode-forward coding scheme for the
Gaussian relay channel. We then derive three optimal sets of power allocation,
which respectively minimize the network, the relay and the source energy
consumption. These optimal power allocations are given in closed-form, which
have so far remained implicit for maximum-rate schemes. Moreover, analysis
shows that minimizing the network energy consumption at a given rate is not
equivalent to maximizing the rate given energy, since it only covers part of
all rates achievable by decode-forward. We thus combine the optimized schemes
for network and relay energy consumptions into a generalized one, which then
covers all achievable rates. This generalized scheme is not only energy-optimal
for the desired source rate but also rate-optimal for the consumed energy. The
results also give a detailed understanding of the power consumption regimes and
allow a comprehensive description of the optimal message coding and resource
allocation for each desired source rate and channel realization. Finally, we
simulate the proposed schemes in a realistic environment, considering path-loss
and shadowing as modelled in the 3GPP standard. Significant energy gain can be
obtained over both direct and two-hop transmissions, particularly when the
source is far from relay and destination.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2830</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2830</id><created>2011-08-13</created><updated>2011-08-19</updated><authors><author><keyname>Courtois</keyname><forenames>Nicolas T.</forenames></author><author><keyname>Bard</keyname><forenames>Gregory V.</forenames></author><author><keyname>Hulme</keyname><forenames>Daniel</forenames></author></authors><title>A New General-Purpose Method to Multiply 3x3 Matrices Using Only 23
  Multiplications</title><categories>cs.SC cs.CC math.NA math.RT</categories><comments>This work was supported by the UK Technology Strategy Board under
  Project No: 9626-58525</comments><msc-class>65F05</msc-class><acm-class>G.1.3; F.2.1; I.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the most famous conjectures in computer algebra is that matrix
multiplication might be feasible in not much more than quadratic time. The best
known exponent is 2.376, due to Coppersmith and Winograd. Many attempts to
solve this problems in the literature work by solving, fixed-size problems and
then apply the solution recursively. This leads to pure combinatorial
optimisation problems with fixed size. These problems are unlikely to be
solvable in polynomial time.
  In 1976 Laderman published a method to multiply two 3x3 matrices using only
23 multiplications. This result is non-commutative, and therefore can be
applied recursively to smaller sub-matrices. In 35 years nobody was able to do
better and it remains an open problem if this can be done with 22
multiplications. We proceed by solving the so called Brent equations [7]. We
have implemented a method to converting this very hard problem to a SAT
problem, and we have attempted to solve it, with our portfolio of some 500 SAT
solvers. With this new method we were able to produce new solutions to the
Laderman's problem. We present a new fully general non-commutative solution
with 23 multiplications and show that this solution is new and is NOT an
equivalent variant of the Laderman's original solution. This result
demonstrates that the space of solutions to Laderman's problem is larger than
expected, and therefore it becomes now more plausible that a solution with 22
multiplications exists. If it exists, we might be able to find it soon just by
running our algorithms longer, or due to further improvements in the SAT solver
algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2840</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2840</id><created>2011-08-13</created><authors><author><keyname>Carreira-Perpi&#xf1;&#xe1;n</keyname><forenames>Miguel &#xc1;.</forenames></author><author><keyname>Goodhill</keyname><forenames>Geoffrey J.</forenames></author></authors><title>Generalised elastic nets</title><categories>q-bio.NC cs.LG stat.ML</categories><comments>52 pages, 16 figures. Original manuscript dated August 14, 2003 and
  not updated since. Current authors' email addresses:
  mcarreira-perpinan@ucmerced.edu, g.goodhill@uq.edu.au</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The elastic net was introduced as a heuristic algorithm for combinatorial
optimisation and has been applied, among other problems, to biological
modelling. It has an energy function which trades off a fitness term against a
tension term. In the original formulation of the algorithm the tension term was
implicitly based on a first-order derivative. In this paper we generalise the
elastic net model to an arbitrary quadratic tension term, e.g. derived from a
discretised differential operator, and give an efficient learning algorithm. We
refer to these as generalised elastic nets (GENs). We give a theoretical
analysis of the tension term for 1D nets with periodic boundary conditions, and
show that the model is sensitive to the choice of finite difference scheme that
represents the discretised derivative. We illustrate some of these issues in
the context of cortical map models, by relating the choice of tension term to a
cortical interaction function. In particular, we prove that this interaction
takes the form of a Mexican hat for the original elastic net, and of
progressively more oscillatory Mexican hats for higher-order derivatives. The
results apply not only to generalised elastic nets but also to other methods
using discrete differential penalties, and are expected to be useful in other
areas, such as data analysis, computer graphics and optimisation problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2846</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2846</id><created>2011-08-14</created><authors><author><keyname>Chang</keyname><forenames>Hyunseok</forenames></author><author><keyname>Chung</keyname><forenames>Sae-Young</forenames></author></authors><title>Capacity of Strong and Very Strong Gaussian Interference
  Relay-without-delay Channels</title><categories>cs.IT math.IT</categories><comments>19 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we study the interference relay-without-delay channel which is
an interference channel with a relay helping the communication. We assume the
relay's transmit symbol depends not only on its past received symbols but also
on its current received symbol, which is an appropriate model for studying
amplify-and-forward type relaying when the overall delay spread is much smaller
than the inverse of the bandwidth. For the discrete memoryless interference
relay-without-delay channel, we show an outer bound using genie-aided outer
bounding. For the Gaussian interference relay-without-delay channel, we define
strong and very strong interference relay-without-delay channels and propose an
achievable scheme based on instantaneous amplify-and-forward (AF) relaying. We
also propose two outer bounds for the strong and very strong cases. Using the
proposed achievable scheme and outer bounds, we show that our scheme can
achieve the capacity exactly when the relay's transmit power is greater than a
certain threshold. This is surprising since the conventional AF relaying is
usually only asymptotically optimal, not exactly optimal. The proposed scheme
can be useful in many practical scenarios due to its optimality as well as its
simplicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2854</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2854</id><created>2011-08-14</created><updated>2014-08-10</updated><authors><author><keyname>Kachhvah</keyname><forenames>Ajay Deep</forenames></author><author><keyname>Gupte</keyname><forenames>Neelima</forenames></author></authors><title>Transmission of packets on a hierarchical network: Statistics and
  explosive percolation</title><categories>cond-mat.stat-mech cs.NI physics.data-an</categories><comments>24 pages, 41 figures</comments><journal-ref>Physical Review E 86, 026104 (2012)</journal-ref><doi>10.1103/PhysRevE.86.026104</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze an idealized model for the transmission or flow of particles, or
discrete packets of information, in a weight bearing branching hierarchical 2-D
networks, and its variants. The capacities add hierarchically down the
clusters. Each node can accommodate a limited number of packets, depending on
its capacity and the packets hop from node to node, following the links between
the nodes. The statistical properties of this system are given by the Maxwell -
Boltzmann distribution. We obtain analytical expressions for the mean
occupation numbers as functions of capacity, for different network topologies.
The analytical results are shown to be in agreement with the numerical
simulations. The traffic flow in these models can be represented by the site
percolation problem. It is seen that the percolation transitions in the 2-D
model and in its variant lattices are continuous transitions, whereas the
transition is found to be explosive (discontinuous) for the V- lattice, the
critical case of the 2-D lattice. We discuss the implications of our analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2858</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2858</id><created>2011-08-14</created><authors><author><keyname>Qin</keyname><forenames>Haohao</forenames></author><author><keyname>Sun</keyname><forenames>Yin</forenames></author><author><keyname>Chen</keyname><forenames>Xiang</forenames></author><author><keyname>Zhao</keyname><forenames>Ming</forenames></author><author><keyname>Wang</keyname><forenames>Jing</forenames></author></authors><title>Optimal Power Allocation for OFDM-Based Wire-Tap Channels with
  Arbitrarily Distributed Inputs</title><categories>cs.IT math.IT</categories><comments>13 pages, 6 figures. The paper was submitted to WiCON on March 31,
  2011, and has been accepted for publication</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate power allocation that maximizes the secrecy
rate of orthogonal frequency division multiplexing (OFDM) systems under
arbitrarily distributed inputs. Considering commonly assumed Gaussian inputs
are unrealistic, we focus on secrecy systems with more practical discrete
distributed inputs, such as PSK, QAM, etc. While the secrecy rate achieved by
Gaussian distributed inputs is concave with respect to the transmit power, we
have found and rigorously proved that the secrecy rate is non-concave under any
discrete inputs. Hence, traditional convex optimization methods are not
applicable any more. To address this non-concave power allocation problem, we
propose an efficient algorithm. Its gap from optimality vanishes asymptotically
at the rate of $O(1/\sqrt{N})$, and its complexity grows in the order of O(N),
where $N$ is the number of sub-carriers. Numerical results are provided to
illustrate the efficacy of the proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2861</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2861</id><created>2011-08-14</created><updated>2012-04-20</updated><authors><author><keyname>Natarajan</keyname><forenames>Lakshmi Prasad</forenames></author><author><keyname>Rajan</keyname><forenames>B. Sundar</forenames></author></authors><title>Generalized Distributive Law for ML Decoding of Space-Time Block Codes</title><categories>cs.IT math.IT</categories><comments>18 pages, 25 figures. Corrected a few minor errors</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The problem of designing good Space-Time Block Codes (STBCs) with low
maximum-likelihood (ML) decoding complexity has gathered much attention in the
literature. All the known low ML decoding complexity techniques utilize the
same approach of exploiting either the multigroup decodable or the
fast-decodable (conditionally multigroup decodable) structure of a code. We
refer to this well known technique of decoding STBCs as Conditional ML (CML)
decoding. In this paper we introduce a new framework to construct ML decoders
for STBCs based on the Generalized Distributive Law (GDL) and the Factor-graph
based Sum-Product Algorithm. We say that an STBC is fast GDL decodable if the
order of GDL decoding complexity of the code is strictly less than M^l, where l
is the number of independent symbols in the STBC, and M is the constellation
size. We give sufficient conditions for an STBC to admit fast GDL decoding, and
show that both multigroup and conditionally multigroup decodable codes are fast
GDL decodable. For any STBC, whether fast GDL decodable or not, we show that
the GDL decoding complexity is strictly less than the CML decoding complexity.
For instance, for any STBC obtained from Cyclic Division Algebras which is not
multigroup or conditionally multigroup decodable, the GDL decoder provides
about 12 times reduction in complexity compared to the CML decoder. Similarly,
for the Golden code, which is conditionally multigroup decodable, the GDL
decoder is only half as complex as the CML decoder.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2864</identifier>
 <datestamp>2012-02-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2864</id><created>2011-08-14</created><authors><author><keyname>Finkel</keyname><forenames>Olivier</forenames><affiliation>ELM</affiliation></author></authors><title>Some Problems in Automata Theory Which Depend on the Models of Set
  Theory</title><categories>cs.FL cs.CC cs.LO math.LO</categories><comments>To appear in the journal RAIRO-Theoretical Informatics and
  Applications</comments><proxy>ccsd</proxy><journal-ref>RAIRO - Theoretical Informatics and Applications 45, 4 (2011) 383
  - 397</journal-ref><doi>10.1051/ita/2011113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We prove that some fairly basic questions on automata reading infinite words
depend on the models of the axiomatic system ZFC. It is known that there are
only three possibilities for the cardinality of the complement of an
omega-language $L(A)$ accepted by a B\&quot;uchi 1-counter automaton $A$. We prove
the following surprising result: there exists a 1-counter B\&quot;uchi automaton $A$
such that the cardinality of the complement $L(A)^-$ of the omega-language
$L(A)$ is not determined by ZFC: (1). There is a model $V_1$ of ZFC in which
$L(A)^-$ is countable. (2). There is a model $V_2$ of ZFC in which $L(A)^-$ has
cardinal $2^{\aleph_0}$. (3). There is a model $V_3$ of ZFC in which $L(A)^-$
has cardinal $\aleph_1$ with $\aleph_0&lt;\aleph_1&lt;2^{\aleph_0}$. We prove a very
similar result for the complement of an infinitary rational relation accepted
by a 2-tape B\&quot;uchi automaton $B$. As a corollary, this proves that the
Continuum Hypothesis may be not satisfied for complements of 1-counter
omega-languages and for complements of infinitary rational relations accepted
by 2-tape B\&quot;uchi automata. We infer from the proof of the above results that
basic decision problems about 1-counter omega-languages or infinitary rational
relations are actually located at the third level of the analytical hierarchy.
In particular, the problem to determine whether the complement of a 1-counter
omega-language (respectively, infinitary rational relation) is countable is in
$\Sigma_3^1 \setminus (\Pi_2^1 \cup \Sigma_2^1)$. This is rather surprising if
compared to the fact that it is decidable whether an infinitary rational
relation is countable (respectively, uncountable).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2865</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2865</id><created>2011-08-14</created><authors><author><keyname>B&#xe1;tfai</keyname><forenames>Norbert</forenames></author></authors><title>Conscious Machines and Consciousness Oriented Programming</title><categories>cs.AI</categories><comments>25 pages, 8 figures</comments><msc-class>68T35</msc-class><acm-class>I.2.5; F.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we investigate the following question: how could you write
such computer programs that can work like conscious beings? The motivation
behind this question is that we want to create such applications that can see
the future. The aim of this paper is to provide an overall conceptual framework
for this new approach to machine consciousness. So we introduce a new
programming paradigm called Consciousness Oriented Programming (COP).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2874</identifier>
 <datestamp>2012-06-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2874</id><created>2011-08-14</created><updated>2012-06-04</updated><authors><author><keyname>Marcolli</keyname><forenames>Matilde</forenames></author><author><keyname>Thorngren</keyname><forenames>Ryan</forenames></author></authors><title>Thermodynamic Semirings</title><categories>math.QA cs.IT math.IT</categories><comments>47 pages, LaTeX, 9 eps figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Witt construction describes a functor from the category of Rings to the
category of characteristic 0 rings. It is uniquely determined by a few
associativity constraints which do not depend on the types of the variables
considered, in other words, by integer polynomials. This universality allowed
Alain Connes and Caterina Consani to devise an analogue of the Witt ring for
characteristic one, an attractive endeavour since we know very little about the
arithmetic in this exotic characteristic and its corresponding field with one
element. Interestingly, they found that in characteristic one, the Witt
construction depends critically on the Shannon entropy. In the current work, we
examine this surprising occurrence, defining a Witt operad for an arbitrary
information measure and a corresponding algebra we call a thermodynamic
semiring. This object exhibits algebraically many of the familiar properties of
information measures, and we examine in particular the Tsallis and Renyi
entropy functions and applications to nonextensive thermodynamics and
multifractals. We find that the arithmetic of the thermodynamic semiring is
exactly that of a certain guessing game played using the given information
measure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2879</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2879</id><created>2011-08-14</created><updated>2012-04-02</updated><authors><author><keyname>Kent</keyname><forenames>Adrian</forenames><affiliation>Centre for Quantum Information and Foundations, DAMTP, University of Cambridge and Perimeter Institute for Theoretical Physics</affiliation></author></authors><title>Unconditionally Secure Bit Commitment by Transmitting Measurement
  Outcomes</title><categories>quant-ph cs.CR</categories><comments>Discussion expanded pedagogically in response to referee comments</comments><journal-ref>Phys. Rev. Lett.109, 130501 (2012)</journal-ref><doi>10.1103/PhysRevLett.109.130501</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new unconditionally secure bit commitment scheme based on
Minkowski causality and the properties of quantum information. The receiving
party sends a number of randomly chosen BB84 qubits to the committer at a given
point in space-time. The committer carries out measurements in one of the two
BB84 bases, depending on the committed bit value, and transmits the outcomes
securely at light speed in opposite directions to remote agents. These agents
unveil the bit by returning the outcomes to adjacent agents of the receiver.
The security proofs rely only on simple properties of quantum information and
the impossibility of superluminal signalling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2881</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2881</id><created>2011-08-14</created><authors><author><keyname>Kaspi</keyname><forenames>Yonatan</forenames></author><author><keyname>Merhav</keyname><forenames>Neri</forenames></author></authors><title>Structure Theorems for Real-Time Variable-Rate Coding With and Without
  Side Information</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The output of a discrete Markov source is to be encoded instantaneously by a
variable-rate encoder and decoded by a finite-state decoder. Our performance
measure is a linear combination of the distortion and the instantaneous rate.
Structure theorems, pertaining to the encoder and next-state functions are
derived for every given finite-state decoder, which can have access to side
information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2886</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2886</id><created>2011-08-14</created><authors><author><keyname>Fetaya</keyname><forenames>Ethan</forenames></author></authors><title>Homological Error Correcting Codes and Systolic Geometry</title><categories>math.DG cs.CG cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In my masters thesis I prove a square root bound on the distance of
homological codes that come from two dimensional surfaces, as a result of the
systolic inequality. I also give a detailed version of M.H. Freedman's proof
that due to systolic freedom, this bound does not hold in higher dimensions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2889</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2889</id><created>2011-08-14</created><authors><author><keyname>Muraviev</keyname><forenames>Roman</forenames></author></authors><title>Additive habits with power utility: Estimates, asymptotics and
  equilibrium</title><categories>q-fin.PM cs.SY math.OC</categories><comments>Submitted</comments><msc-class>91B16, 91B50</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a power utility maximization problem with additive habits in a
framework of discrete-time markets and random endowments. For certain classes
of incomplete markets, we establish estimates for the optimal consumption
stream in terms of the aggregate state price density, investigate the
asymptotic behaviour of the propensity to consume (ratio of the consumption to
the wealth), as the initial endowment tends to infinity, and show that the
limit is the corresponding quantity in an artificial market. For complete
markets, we concentrate on proving the existence of an Arrow-Debreu equilibrium
in an economy inhabited by heterogeneous individuals who differ with respect to
their risk-aversion coefficient, impatience rate and endowments stream, but
possess the same degree of habit-formation. Finally, in a representative agent
equilibrium, we compute explicitly the price of a zero coupon bond and the
Lucas tree equity, and study its dependence on the habit-formation parameter.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2893</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2893</id><created>2011-08-14</created><authors><author><keyname>Wu</keyname><forenames>Xuebin</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Reduced-Complexity Decoder of Long Reed-Solomon Codes Based on Composite
  Cyclotomic Fourier Transforms</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure</comments><doi>10.1109/TSP.2012.2192435</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Long Reed-Solomon (RS) codes are desirable for digital communication and
storage systems due to their improved error performance, but the high
computational complexity of their decoders is a key obstacle to their adoption
in practice. As discrete Fourier transforms (DFTs) can evaluate a polynomial at
multiple points, efficient DFT algorithms are promising in reducing the
computational complexities of syndrome based decoders for long RS codes. In
this paper, we first propose partial composite cyclotomic Fourier transforms
(CCFTs) and then devise syndrome based decoders for long RS codes over large
finite fields based on partial CCFTs. The new decoders based on partial CCFTs
achieve a significant saving of computational complexities for long RS codes.
Since partial CCFTs have modular and regular structures, the new decoders are
suitable for hardware implementations. To further verify and demonstrate the
advantages of partial CCFTs, we implement in hardware the syndrome computation
block for a $(2720, 2550)$ shortened RS code over GF$(2^{12})$. In comparison
to previous results based on Horner's rule, our hardware implementation not
only has a smaller gate count, but also achieves much higher throughputs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2903</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2903</id><created>2011-08-14</created><updated>2011-08-16</updated><authors><author><keyname>Bouvrie</keyname><forenames>Jake</forenames></author><author><keyname>Hamzi</keyname><forenames>Boumediene</forenames></author></authors><title>Model Reduction for Nonlinear Control Systems using Kernel Subspace
  Methods</title><categories>math.OC cs.SY math.DS stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a data-driven order reduction method for nonlinear control
systems, drawing on recent progress in machine learning and statistical
dimensionality reduction. The method rests on the assumption that the nonlinear
system behaves linearly when lifted into a high (or infinite) dimensional
feature space where balanced truncation may be carried out implicitly. This
leads to a nonlinear reduction map which can be combined with a representation
of the system belonging to a reproducing kernel Hilbert space to give a closed,
reduced order dynamical system which captures the essential input-output
characteristics of the original model.
  Empirical simulations illustrating the approach are also provided.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2905</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2905</id><created>2011-08-14</created><authors><author><keyname>Yi</keyname><forenames>Xinping</forenames></author><author><keyname>Au</keyname><forenames>Edward</forenames></author></authors><title>User Scheduling for Heterogeneous Multiuser MIMO Systems: A Subspace
  Viewpoint</title><categories>cs.IT math.IT</categories><comments>33 pages, 8 figures; accepted for publication in IEEE Transactions on
  Vehicular Technology</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In downlink multiuser multiple-input multiple-output (MU-MIMO) systems, users
are practically heterogeneous in nature. However, most of the existing user
scheduling algorithms are designed with an implicit assumption that the users
are homogeneous. In this paper, we revisit the problem by exploring the
characteristics of heterogeneous users from a subspace point of view. With an
objective of minimizing interference non-orthogonality among users, three new
angular-based user scheduling criteria that can be applied in various user
scheduling algorithms are proposed. While the first criterion is heuristically
determined by identifying the incapability of largest principal angle to
characterize the subspace correlation and hence the interference
non-orthogonality between users, the second and third ones are derived by
using, respectively, the sum rate capacity bounds with block diagonalization
and the change in capacity by adding a new user into an existing user subset.
Aiming at capturing fairness among heterogeneous users while maintaining
multiuser diversity gain, two new hybrid user scheduling algorithms are also
proposed whose computational complexities are only linearly proportional to the
number of users. We show by simulations that the effectiveness of our proposed
user scheduling criteria and algorithms with respect to those commonly used in
homogeneous environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2960</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2960</id><created>2011-08-15</created><authors><author><keyname>Kaufman</keyname><forenames>Tali</forenames></author><author><keyname>Lubotzky</keyname><forenames>Alexander</forenames></author></authors><title>Edge Transitive Ramanujan Graphs and Highly Symmetric LDPC Good Codes</title><categories>cs.IT math.CO math.GR math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a symmetric LDPC code with constant rate and constant distance
(i.e. good LDPC code) that its constraint space is generated by the orbit of
one constant weight constraint under a group action. Our construction provides
the first symmetric LDPC good codes. This solves the main open problem raised
by Kaufman and Wigderson in [4].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2989</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2989</id><created>2011-08-15</created><authors><author><keyname>Mukherjee</keyname><forenames>Indraneel</forenames></author><author><keyname>Schapire</keyname><forenames>Robert E.</forenames></author></authors><title>A theory of multiclass boosting</title><categories>stat.ML cs.AI</categories><comments>A preliminary version appeared in NIPS 2010</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Boosting combines weak classifiers to form highly accurate predictors.
Although the case of binary classification is well understood, in the
multiclass setting, the &quot;correct&quot; requirements on the weak classifier, or the
notion of the most efficient boosting algorithms are missing. In this paper, we
create a broad and general framework, within which we make precise and identify
the optimal requirements on the weak-classifier, as well as design the most
effective, in a certain sense, boosting algorithms that assume such
requirements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.2996</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.2996</id><created>2011-08-15</created><authors><author><keyname>Emad</keyname><forenames>Amin</forenames></author><author><keyname>Shen</keyname><forenames>Jun</forenames></author><author><keyname>Milenkovic</keyname><forenames>Olgica</forenames></author></authors><title>Symmetric Group Testing and Superimposed Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We describe a generalization of the group testing problem termed symmetric
group testing. Unlike in classical binary group testing, the roles played by
the input symbols zero and one are &quot;symmetric&quot; while the outputs are drawn from
a ternary alphabet. Using an information-theoretic approach, we derive
sufficient and necessary conditions for the number of tests required for
noise-free and noisy reconstructions. Furthermore, we extend the notion of
disjunct (zero-false-drop) and separable (uniquely decipherable) codes to the
case of symmetric group testing. For the new family of codes, we derive bounds
on their size based on probabilistic methods, and provide construction methods
based on coding theoretic ideas.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3019</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3019</id><created>2011-08-15</created><authors><author><keyname>Siebers</keyname><forenames>Peer-Olaf</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>A First Approach on Modelling Staff Proactiveness in Retail Simulation
  Models</title><categories>cs.AI</categories><comments>25 pages, 3 figures, 10 tables</comments><journal-ref>Journal of Artificial Societies and Social Simulation, 14 (2),
  pages 1-25, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There has been a noticeable shift in the relative composition of the industry
in the developed countries in recent years; manufacturing is decreasing while
the service sector is becoming more important. However, currently most
simulation models for investigating service systems are still built in the same
way as manufacturing simulation models, using a process-oriented world view,
i.e. they model the flow of passive entities through a system. These kinds of
models allow studying aspects of operational management but are not well suited
for studying the dynamics that appear in service systems due to human
behaviour. For these kinds of studies we require tools that allow modelling the
system and entities using an object-oriented world view, where intelligent
objects serve as abstract &quot;actors&quot; that are goal directed and can behave
proactively. In our work we combine process-oriented discrete event simulation
modelling and object-oriented agent based simulation modelling to investigate
the impact of people management practices on retail productivity. In this
paper, we reveal in a series of experiments what impact considering proactivity
can have on the output accuracy of simulation models of human centric systems.
The model and data we use for this investigation are based on a case study in a
UK department store. We show that considering proactivity positively influences
the validity of these kinds of models and therefore allows analysts to make
better recommendations regarding strategies to apply people management
practises.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3025</identifier>
 <datestamp>2011-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3025</id><created>2011-08-15</created><authors><author><keyname>Rodrigues</keyname><forenames>Helena Sofia</forenames></author><author><keyname>Monteiro</keyname><forenames>M. Teresa T.</forenames></author><author><keyname>Torres</keyname><forenames>Delfim F. M.</forenames></author></authors><title>Optimal control of a dengue epidemic model with vaccination</title><categories>math.OC cs.SY q-bio.PE</categories><comments>This is a preprint of a paper accepted for presentation at ICNAAM
  2011, Halkidiki, Greece, 19-25 September 2011, and to appear in AIP
  Conference Proceedings, volume 1389</comments><msc-class>49K15, 92D30</msc-class><journal-ref>AIP Conf. Proc. 1389 (2011), 1232--1235</journal-ref><doi>10.1063/1.3637839</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a SIR+ASI epidemic model to describe the interaction between human
and dengue fever mosquito populations. A control strategy in the form of
vaccination, to decrease the number of infected individuals, is used. An
optimal control approach is applied in order to find the best way to fight the
disease.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3033</identifier>
 <datestamp>2012-04-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3033</id><created>2011-08-15</created><updated>2012-04-25</updated><authors><author><keyname>Gabbay</keyname><forenames>Dov</forenames></author><author><keyname>Schlechta</keyname><forenames>Karl</forenames></author></authors><title>Equilibria und weiteres Heiteres II</title><categories>cs.LO</categories><comments>arXiv admin note: incorporates entirety of text from arXiv:0907.4017</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate several technical and conceptual questions.
  Our main subject is the investigation of independence as a ternary relation
in the context of non-monotonic logic. In the context of probability, this
investigation was started by W.Spohn et al., and then followed by J.Pearl. We
look at products of function sets, and thus continue our own investigation of
independence in non-monotonic logic. We show that a finite characterization of
this relation in our context is impossible, and indicate how to construct all
valid rules.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3048</identifier>
 <datestamp>2013-12-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3048</id><created>2011-08-15</created><updated>2013-12-03</updated><authors><author><keyname>Kallitsis</keyname><forenames>Michael</forenames></author><author><keyname>Stoev</keyname><forenames>Stilian</forenames></author><author><keyname>Michailidis</keyname><forenames>George</forenames></author></authors><title>Fast Approximation Algorithms for Near-optimal Large-scale Network
  Monitoring</title><categories>cs.DS</categories><comments>Paper withdrawn since the official journal paper is now available</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the problem of optimal traffic prediction and monitoring in
large-scale networks. Our goal is to determine which subset of K links to
monitor in order to &quot;best&quot; predict the traffic on the remaining links in the
network. We consider several optimality criteria. This can be formulated as a
combinatorial optimization problem, belonging to the family of subset selection
problems. Similar NP-hard problems arise in statistics, machine learning and
signal processing. Some include subset selection for regression, variable
selection, and sparse approximation. Exact solutions are computationally
prohibitive. We present both new heuristics as well as new efficient algorithms
implementing the classical greedy heuristic - commonly used to tackle such
combinatorial problems. Our approach exploits connections to principal
component analysis (PCA), and yields new types of performance lower bounds
which do not require submodularity of the objective functions. We show that an
ensemble method applied to our new randomized heuristic algorithm, often
outperforms the classical greedy heuristic in practice. We evaluate our
algorithms under several large-scale networks, including real life networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3054</identifier>
 <datestamp>2012-04-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3054</id><created>2011-08-15</created><updated>2012-04-23</updated><authors><author><keyname>Granger</keyname><forenames>Robert</forenames></author><author><keyname>Moss</keyname><forenames>Andrew</forenames></author></authors><title>Generalised Mersenne Numbers Revisited</title><categories>math.NT cs.CR</categories><comments>32 pages. Accepted to Mathematics of Computation</comments><msc-class>12Y05, 11T71, 11Y16</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Generalised Mersenne Numbers (GMNs) were defined by Solinas in 1999 and
feature in the NIST (FIPS 186-2) and SECG standards for use in elliptic curve
cryptography. Their form is such that modular reduction is extremely efficient,
thus making them an attractive choice for modular multiplication
implementation. However, the issue of residue multiplication efficiency seems
to have been overlooked. Asymptotically, using a cyclic rather than a linear
convolution, residue multiplication modulo a Mersenne number is twice as fast
as integer multiplication; this property does not hold for prime GMNs, unless
they are of Mersenne's form. In this work we exploit an alternative
generalisation of Mersenne numbers for which an analogue of the above property
--- and hence the same efficiency ratio --- holds, even at bitlengths for which
schoolbook multiplication is optimal, while also maintaining very efficient
reduction. Moreover, our proposed primes are abundant at any bitlength, whereas
GMNs are extremely rare. Our multiplication and reduction algorithms can also
be easily parallelised, making our arithmetic particularly suitable for
hardware implementation. Furthermore, the field representation we propose also
naturally protects against side-channel attacks, including timing attacks,
simple power analysis and differential power analysis, which is essential in
many cryptographic scenarios, in constrast to GMNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3061</identifier>
 <datestamp>2014-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3061</id><created>2011-08-15</created><updated>2011-08-29</updated><authors><author><keyname>Baryshnikov</keyname><forenames>Yuliy</forenames></author><author><keyname>Bubenik</keyname><forenames>Peter</forenames></author><author><keyname>Kahle</keyname><forenames>Matthew</forenames></author></authors><title>Min-type Morse theory for configuration spaces of hard spheres</title><categories>math.AT cs.RO math-ph math.MP</categories><comments>Minor changes, new title</comments><journal-ref>Int Math Res Notices (2014) 2014 (9): 2577-2592</journal-ref><doi>10.1093/imrn/rnt012</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  We study configuration spaces of hard spheres in a bounded region. We develop
a general Morse-theoretic framework, and show that mechanically balanced
configurations play the role of critical points. As an application, we find the
precise threshold radius for a configuration space to be homotopy equivalent to
the configuration space of points.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3072</identifier>
 <datestamp>2011-08-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3072</id><created>2011-08-15</created><authors><author><keyname>Li</keyname><forenames>Ping</forenames></author><author><keyname>Shrivastava</keyname><forenames>Anshumali</forenames></author><author><keyname>Konig</keyname><forenames>Christian</forenames></author></authors><title>Training Logistic Regression and SVM on 200GB Data Using b-Bit Minwise
  Hashing and Comparisons with Vowpal Wabbit (VW)</title><categories>cs.LG stat.ME stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We generated a dataset of 200 GB with 10^9 features, to test our recent b-bit
minwise hashing algorithms for training very large-scale logistic regression
and SVM. The results confirm our prior work that, compared with the VW hashing
algorithm (which has the same variance as random projections), b-bit minwise
hashing is substantially more accurate at the same storage. For example, with
merely 30 hashed values per data point, b-bit minwise hashing can achieve
similar accuracies as VW with 2^14 hashed values per data point.
  We demonstrate that the preprocessing cost of b-bit minwise hashing is
roughly on the same order of magnitude as the data loading time. Furthermore,
by using a GPU, the preprocessing cost can be reduced to a small fraction of
the data loading time.
  Minwise hashing has been widely used in industry, at least in the context of
search. One reason for its popularity is that one can efficiently simulate
permutations by (e.g.,) universal hashing. In other words, there is no need to
store the permutation matrix. In this paper, we empirically verify this
practice, by demonstrating that even using the simplest 2-universal hashing
does not degrade the learning performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3074</identifier>
 <datestamp>2011-08-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3074</id><created>2011-08-15</created><updated>2011-08-27</updated><authors><author><keyname>Dzhafarov</keyname><forenames>Ehtibar N.</forenames></author><author><keyname>Kujala</keyname><forenames>Janne V.</forenames></author></authors><title>Selectivity in Probabilistic Causality: Drawing Arrows from Inputs to
  Stochastic Outputs</title><categories>cs.AI math.PR physics.data-an q-bio.QM</categories><comments>25 pages; minor corrections with respect to the first version</comments><msc-class>91E45 (Primary), 60A05 (Secondary)</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a set of several inputs into a system (e.g., independent variables
characterizing stimuli) and a set of several stochastically non-independent
outputs (e.g., random variables describing different aspects of responses), how
can one determine, for each of the outputs, which of the inputs it is
influenced by? The problem has applications ranging from modeling pairwise
comparisons to reconstructing mental processing architectures to conjoint
testing. A necessary and sufficient condition for a given pattern of selective
influences is provided by the Joint Distribution Criterion, according to which
the problem of &quot;what influences what&quot; is equivalent to that of the existence of
a joint distribution for a certain set of random variables. For inputs and
outputs with finite sets of values this criterion translates into a test of
consistency of a certain system of linear equations and inequalities (Linear
Feasibility Test) which can be performed by means of linear programming. The
Joint Distribution Criterion also leads to a metatheoretical principle for
generating a broad class of necessary conditions (tests) for diagrams of
selective influences. Among them is the class of distance-type tests based on
the observation that certain functionals on jointly distributed random
variables satisfy triangle inequality.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3092</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3092</id><created>2011-08-15</created><authors><author><keyname>Kaufmann</keyname><forenames>Michael</forenames></author><author><keyname>Mchedlidze</keyname><forenames>Tamara</forenames></author><author><keyname>Symvonis</keyname><forenames>Antonios</forenames></author></authors><title>Upward Point Set Embeddability for Convex Point Sets is in $P$</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present a polynomial dynamic programming algorithm that
tests whether a $n$-vertex directed tree $T$ has an upward planar embedding
into a convex point-set $S$ of size $n$. Further, we extend our approach to the
class of outerplanar digraphs. This nontrivial and surprising result implies
that any given digraph can be efficiently tested for an upward planar embedding
into a given convex point set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3097</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3097</id><created>2011-08-15</created><authors><author><keyname>Liu</keyname><forenames>Yanpei</forenames></author><author><keyname>Yang</keyname><forenames>Jing</forenames></author><author><keyname>Draper</keyname><forenames>Stark. C.</forenames></author></authors><title>Cooperative Packet Routing using Mutual Information Accumulation</title><categories>cs.IT cs.NI math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the resource allocation problem in cooperative wireless networks
wherein nodes perform mutual information accumulation. We consider a unicast
setting and arbitrary arrival processes at the source node. Source arrivals can
be broken down into numerous packets to better exploit the spatial and temporal
diversity of the routes available in the network. We devise a
linear-program-based algorithm which allocates network resource to meet a
certain transmission objective. Given a network, a source with multiple
arriving packets and a destination, our algorithm generates a policy that
regulates which nodes should participate in transmitting which packets, when
and with what resource. By routing different packets through different nodes
the policy exploits spatial route diversity, and by sequencing packet
transmissions along the same route it exploits temporal route diversity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3112</identifier>
 <datestamp>2012-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3112</id><created>2011-08-15</created><updated>2012-11-29</updated><authors><author><keyname>Mossel</keyname><forenames>Elchanan</forenames></author><author><keyname>Roch</keyname><forenames>Sebastien</forenames></author></authors><title>Phylogenetic mixtures: Concentration of measure in the large-tree limit</title><categories>math.PR cs.DS math.ST q-bio.PE stat.TH</categories><comments>Published in at http://dx.doi.org/10.1214/11-AAP837 the Annals of
  Applied Probability (http://www.imstat.org/aap/) by the Institute of
  Mathematical Statistics (http://www.imstat.org)</comments><proxy>vtex</proxy><report-no>IMS-AAP-AAP837</report-no><journal-ref>Annals of Applied Probability 2012, Vol. 22, No. 6, 2429-2459</journal-ref><doi>10.1214/11-AAP837</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The reconstruction of phylogenies from DNA or protein sequences is a major
task of computational evolutionary biology. Common phenomena, notably
variations in mutation rates across genomes and incongruences between gene
lineage histories, often make it necessary to model molecular data as
originating from a mixture of phylogenies. Such mixed models play an
increasingly important role in practice. Using concentration of measure
techniques, we show that mixtures of large trees are typically identifiable. We
also derive sequence-length requirements for high-probability reconstruction.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3124</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3124</id><created>2011-08-15</created><authors><author><keyname>Aceto</keyname><forenames>Luca</forenames><affiliation>Reykjavik University, Iceland</affiliation></author><author><keyname>Caltais</keyname><forenames>Georgiana</forenames><affiliation>Reykjavik University, Iceland</affiliation></author><author><keyname>Goriac</keyname><forenames>Eugen-Ioan</forenames><affiliation>Reykjavik University, Iceland</affiliation></author><author><keyname>Ingolfsdottir</keyname><forenames>Anna</forenames><affiliation>Reykjavik University, Iceland</affiliation></author></authors><title>Axiomatizing GSOS with Predicates</title><categories>cs.LO</categories><comments>In Proceedings SOS 2011, arXiv:1108.2796</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 62, 2011, pp. 1-15</journal-ref><doi>10.4204/EPTCS.62.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we introduce an extension of the GSOS rule format with
predicates such as termination, convergence and divergence. For this format we
generalize the technique proposed by Aceto, Bloom and Vaandrager for the
automatic generation of ground-complete axiomatizations of bisimilarity over
GSOS systems. Our procedure is implemented in a tool that receives SOS
specifications as input and derives the corresponding axiomatizations
automatically. This paves the way to checking strong bisimilarity over process
terms by means of theorem-proving techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3125</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3125</id><created>2011-08-15</created><authors><author><keyname>Madlener</keyname><forenames>Ken</forenames><affiliation>Radboud University Nijmegen, The Netherlands</affiliation></author><author><keyname>Smetsers</keyname><forenames>Sjaak</forenames><affiliation>Radboud University Nijmegen, The Netherlands</affiliation></author><author><keyname>van Eekelen</keyname><forenames>Marko</forenames><affiliation>Radboud University Nijmegen, The Netherlands</affiliation></author></authors><title>Formal Component-Based Semantics</title><categories>cs.LO</categories><comments>In Proceedings SOS 2011, arXiv:1108.2796</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 62, 2011, pp. 17-29</journal-ref><doi>10.4204/EPTCS.62.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the proposed solutions for improving the scalability of semantics of
programming languages is Component-Based Semantics, introduced by Peter D.
Mosses. It is expected that this framework can also be used effectively for
modular meta theoretic reasoning. This paper presents a formalization of
Component-Based Semantics in the theorem prover Coq. It is based on Modular
SOS, a variant of SOS, and makes essential use of dependent types, while
profiting from type classes. This formalization constitutes a contribution
towards modular meta theoretic formalizations in theorem provers. As a small
example, a modular proof of determinism of a mini-language is developed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3126</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3126</id><created>2011-08-15</created><authors><author><keyname>Rathnayake</keyname><forenames>Asiri</forenames><affiliation>University of Birmingham, United Kingdom</affiliation></author><author><keyname>Thielecke</keyname><forenames>Hayo</forenames><affiliation>University of Birmingham, United Kingdom</affiliation></author></authors><title>Regular Expression Matching and Operational Semantics</title><categories>cs.LO</categories><comments>In Proceedings SOS 2011, arXiv:1108.2796</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 62, 2011, pp. 31-45</journal-ref><doi>10.4204/EPTCS.62.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many programming languages and tools, ranging from grep to the Java String
library, contain regular expression matchers. Rather than first translating a
regular expression into a deterministic finite automaton, such implementations
typically match the regular expression on the fly. Thus they can be seen as
virtual machines interpreting the regular expression much as if it were a
program with some non-deterministic constructs such as the Kleene star. We
formalize this implementation technique for regular expression matching using
operational semantics. Specifically, we derive a series of abstract machines,
moving from the abstract definition of matching to increasingly realistic
machines. First a continuation is added to the operational semantics to
describe what remains to be matched after the current expression. Next, we
represent the expression as a data structure using pointers, which enables
redundant searches to be eliminated via testing for pointer equality. From
there, we arrive both at Thompson's lockstep construction and a machine that
performs some operations in parallel, suitable for implementation on a large
number of cores, such as a GPU. We formalize the parallel machine using process
algebra and report some preliminary experiments with an implementation on a
graphics processor using CUDA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3127</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3127</id><created>2011-08-15</created><authors><author><keyname>Romero-Hern&#xe1;ndez</keyname><forenames>David</forenames><affiliation>Universidad Complutense de Madrid, Spain</affiliation></author><author><keyname>de Frutos-Escrig</keyname><forenames>David</forenames><affiliation>Universidad Complutense de Madrid, Spain</affiliation></author></authors><title>On the Unification of Process Semantics: Logical Semantics</title><categories>cs.LO</categories><comments>In Proceedings SOS 2011, arXiv:1108.2796</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 62, 2011, pp. 47-61</journal-ref><doi>10.4204/EPTCS.62.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We continue with the task of obtaining a unifying view of process semantics
by considering in this case the logical characterization of the semantics. We
start by considering the classic linear time-branching time spectrum developed
by R.J. van Glabbeek. He provided a logical characterization of most of the
semantics in his spectrum but, without following a unique pattern. In this
paper, we present a uniform logical characterization of all the semantics in
the enlarged spectrum. The common structure of the formulas that constitute all
the corresponding logics gives us a much clearer picture of the spectrum,
clarifying the relations between the different semantics, and allows us to
develop generic proofs of some general properties of the semantics.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3130</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3130</id><created>2011-08-15</created><authors><author><keyname>Zhu</keyname><forenames>Guimei</forenames></author><author><keyname>Yang</keyname><forenames>Huijie</forenames></author><author><keyname>Yin</keyname><forenames>Chuanyang</forenames></author><author><keyname>Li</keyname><forenames>Baowen</forenames></author></authors><title>Localizations on Complex Networks</title><categories>physics.soc-ph cs.SI physics.data-an</categories><comments>9 pages, 6 fugures, 1 table</comments><journal-ref>published on PhysRevE_77_066113 (2008)</journal-ref><doi>10.1103/PhysRevE.77.066113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the structural characteristics of complex networks using the
representative eigenvectors of the adjacent matrix. The probability
distribution function of the components of the representative eigenvectors are
proposed to describe the localization on networks where the Euclidean distance
is invalid. Several quantities are used to describe the localization properties
of the representative states, such as the participation ratio, the structural
entropy, and the probability distribution function of the nearest neighbor
level spacings for spectra of complex networks. Whole-cell networks in the real
world and the Watts-Strogatz small-world and Barabasi-Albert scale-free
networks are considered. The networks have nontrivial localization properties
due to the nontrivial topological structures. It is found that the
ascending-order-ranked series of the occurrence probabilities at the nodes
behave generally multifractally. This characteristic can be used as a
structural measure of complex networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3134</identifier>
 <datestamp>2011-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3134</id><created>2011-08-15</created><updated>2011-09-06</updated><authors><author><keyname>Korpela</keyname><forenames>Eric J.</forenames><affiliation>University of California, Berkeley</affiliation></author><author><keyname>Anderson</keyname><forenames>David P.</forenames><affiliation>University of California, Berkeley</affiliation></author><author><keyname>Bankay</keyname><forenames>Robert</forenames><affiliation>University of California, Berkeley</affiliation></author><author><keyname>Cobb</keyname><forenames>Jeff</forenames><affiliation>University of California, Berkeley</affiliation></author><author><keyname>Howard</keyname><forenames>Andrew</forenames><affiliation>University of California, Berkeley</affiliation></author><author><keyname>Lebofsky</keyname><forenames>Matt</forenames><affiliation>University of California, Berkeley</affiliation></author><author><keyname>Siemion</keyname><forenames>Andrew P. V.</forenames><affiliation>University of California, Berkeley</affiliation></author><author><keyname>von Korff</keyname><forenames>Joshua</forenames><affiliation>Kansas State University</affiliation></author><author><keyname>Werthimer</keyname><forenames>Dan</forenames><affiliation>University of California, Berkeley</affiliation></author></authors><title>Status of the UC-Berkeley SETI Efforts</title><categories>astro-ph.IM cs.DC</categories><comments>8 pages, including 1 figure. Presented at SPIE Conf. 8152, San Diego,
  CA, Aug 25, 2011</comments><journal-ref>Instruments, Methods, and Missions for Astrobiology XIV, Proc.
  SPIE 8152, pp. 815212--1--815212--8, 2011</journal-ref><doi>10.1117/12.894066</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We summarize radio and optical SETI programs based at the University of
California, Berkeley. The SEVENDIP optical pulse search looks for ns time scale
pulses at visible wavelengths using an automated 30 inch telescope. The ongoing
SERENDIP V.v sky survey searches for radio signals at the 300 meter Arecibo
Observatory. The currently installed configuration supports 128 million
channels over a 200 MHz bandwidth with ~1.6 Hz spectral resolution. SETI@home
uses the desktop computers of volunteers to analyze over 160 TB of data at
taken at Arecibo looking for two types of continuous wave signals and two types
of pulsed signals. A version to be released this summer adds autocorrelation
analysis to look for complex wave forms that have been repeated (and overlayed)
after a short delay. SETI@home will soon be processing data of Kepler exoplanet
systems collected at the GBT. The Astropulse project is the first SETI search
for $\mu$s time scale dispersed pulses in the radio spectrum. We recently
reobserved 114 sky locations where microsecond pulses were detected. This data
is in process of being transferred to Berkeley for analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3149</identifier>
 <datestamp>2013-07-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3149</id><created>2011-08-15</created><updated>2013-01-07</updated><authors><author><keyname>Gontier</keyname><forenames>David</forenames></author><author><keyname>Vetterli</keyname><forenames>Martin</forenames></author></authors><title>Sampling based on timing: Time encoding machines on shift-invariant
  subspaces</title><categories>cs.IT math.IT</categories><comments>submitted to Applied and Computationnal Harmonic Analysis</comments><msc-class>94A20</msc-class><doi>10.1016/j.acha.2013.02.002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sampling information using timing is a new approach in sampling theory. The
question is how to map amplitude information into the timing domain. One such
encoder, called time encoding machine, was introduced by Lazar and Toth in [23]
for the special case of band-limited functions. In this paper, we extend their
result to the general framework of shift-invariant subspaces. We prove that
time encoding machines may be considered as non-uniform sampling devices, where
time locations are unknown a priori. Using this fact, we show that perfect
representation and reconstruction of a signal with a time encoding machine is
possible whenever this device satisfies some density property. We prove that
this method is robust under timing quantization, and therefore can lead to the
design of simple and energy efficient sampling devices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3153</identifier>
 <datestamp>2015-10-09</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3153</id><created>2011-08-16</created><authors><author><keyname>Hui</keyname><forenames>Eddie C. M.</forenames></author><author><keyname>Xiao</keyname><forenames>Hua</forenames></author></authors><title>Differential games of partial information forward-backward doubly
  stochastic differential equations and applications</title><categories>math.OC cs.SY</categories><comments>29 pages</comments><msc-class>93E05, 90C39, 93E20</msc-class><journal-ref>ESAIM: Control, Optimisation and Calculus of Variations, 20(1)
  (2014) 78-94</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper is concerned with a new type of differential game problems of
forwardbackward stochastic systems. There are three distinguishing features:
Firstly, our game systems are forward-backward doubly stochastic differential
equations, which is a class of more general game systems than other
forward-backward stochastic game systems without doubly stochastic terms;
Secondly, forward equations are directly related to backward equations at
initial time, not terminal time; Thirdly, the admissible control is required to
be adapted to a sub-information of the full information generated by the
underlying Brownian motions. We give a necessary and a sufficient conditions
for both an equilibrium point of nonzero-sum games and a saddle point of
zero-sum games. Finally, we work out an example of linear-quadratic nonzero-sum
differential games to illustrate the theoretical applications. Applying some
stochastic filtering techniques, we obtain the explicit expression of the
equilibrium point.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3154</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3154</id><created>2011-08-16</created><updated>2011-08-17</updated><authors><author><keyname>Ross</keyname><forenames>Stephane</forenames></author><author><keyname>Bagnell</keyname><forenames>J. Andrew</forenames></author></authors><title>Stability Conditions for Online Learnability</title><categories>cs.LG stat.ML</categories><comments>16 pages. Earlier version of this work submitted (but rejected) to
  COLT 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Stability is a general notion that quantifies the sensitivity of a learning
algorithm's output to small change in the training dataset (e.g. deletion or
replacement of a single training sample). Such conditions have recently been
shown to be more powerful to characterize learnability in the general learning
setting under i.i.d. samples where uniform convergence is not necessary for
learnability, but where stability is both sufficient and necessary for
learnability. We here show that similar stability conditions are also
sufficient for online learnability, i.e. whether there exists a learning
algorithm such that under any sequence of examples (potentially chosen
adversarially) produces a sequence of hypotheses that has no regret in the
limit with respect to the best hypothesis in hindsight. We introduce online
stability, a stability condition related to uniform-leave-one-out stability in
the batch setting, that is sufficient for online learnability. In particular we
show that popular classes of online learners, namely algorithms that fall in
the category of Follow-the-(Regularized)-Leader, Mirror Descent, gradient-based
methods and randomized algorithms like Weighted Majority and Hedge, are
guaranteed to have no regret if they have such online stability property. We
provide examples that suggest the existence of an algorithm with such stability
condition might in fact be necessary for online learnability. For the more
restricted binary classification setting, we establish that such stability
condition is in fact both sufficient and necessary. We also show that for a
large class of online learnable problems in the general learning setting,
namely those with a notion of sub-exponential covering, no-regret online
algorithms that have such stability condition exists.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3198</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3198</id><created>2011-08-16</created><updated>2011-08-18</updated><authors><author><keyname>Li</keyname><forenames>Jiyou</forenames></author></authors><title>On the average sensitivity of laced Boolean functions</title><categories>cs.IT math.CO math.IT</categories><comments>8 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we obtain the average sensitivity of the laced Boolean
functions. This confirms a conjecture of Shparlinski. We also compute the
weights of the laced Boolean functions and show that they are almost balanced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3206</identifier>
 <datestamp>2011-12-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3206</id><created>2011-08-16</created><updated>2011-12-22</updated><authors><author><keyname>Carbajal</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Bayma</keyname><forenames>Rafael</forenames></author><author><keyname>Ziegler</keyname><forenames>Marc</forenames></author><author><keyname>Lang</keyname><forenames>Zi-Qiang</forenames></author></authors><title>Modeling and frequency domain analysis of nonlinear compliant joints for
  a passive dynamic swimmer</title><categories>cs.RO</categories><comments>12 p, 5 fig, work in progress, collaborative work</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper we present the study of the mathematical model of a real life
joint used in an underwater robotic fish. Fluid-structure interaction is
utterly simplified and the motion of the joint is approximated by D\&quot;uffing's
equation. We compare the quality of analytical harmonic solutions previously
reported, with the input-output relation obtained via truncated Volterra series
expansion. Comparisons show a trade-off between accuracy and flexibility of the
methods. The methods are discussed in detail in order to facilitate
reproduction of our results. The approach presented herein can be used to
verify results in nonlinear resonance applications and in the design of
bio-inspired compliant robots that exploit passive properties of their
dynamics. We focus on the potential use of this type of joint for energy
extraction from environmental sources, in this case a K\'arm\'an vortex street
shed by an obstacle in a flow. Open challenges and questions are mentioned
throughout the document.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3221</identifier>
 <datestamp>2011-10-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3221</id><created>2011-08-16</created><updated>2011-10-05</updated><authors><author><keyname>Cassandras</keyname><forenames>Christos G.</forenames></author><author><keyname>Ding</keyname><forenames>Xu Chu</forenames></author><author><keyname>Lin</keyname><forenames>Xuchao</forenames></author></authors><title>An Optimal Control Approach for the Persistent Monitoring Problem</title><categories>cs.SY cs.RO math.OC</categories><comments>Technical report accompanying the CDC2011 submission</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose an optimal control framework for persistent monitoring problems
where the objective is to control the movement of mobile agents to minimize an
uncertainty metric in a given mission space. For a single agent in a
one-dimensional space, we show that the optimal solution is obtained in terms
of a sequence of switching locations, thus reducing it to a parametric
optimization problem. Using Infinitesimal Perturbation Analysis (IPA) we obtain
a complete solution through a gradient-based algorithm. We also discuss a
receding horizon controller which is capable of obtaining a near-optimal
solution on-the-fly. We illustrate our approach with numerical examples.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3223</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3223</id><created>2011-08-16</created><updated>2012-03-18</updated><authors><author><keyname>Shi</keyname><forenames>Guodong</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author></authors><title>Randomized Optimal Consensus of Multi-agent Systems</title><categories>cs.MA cs.CG cs.DC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we formulate and solve a randomized optimal consensus problem
for multi-agent systems with stochastically time-varying interconnection
topology. The considered multi-agent system with a simple randomized iterating
rule achieves an almost sure consensus meanwhile solving the optimization
problem $\min_{z\in \mathds{R}^d}\ \sum_{i=1}^n f_i(z),$ in which the optimal
solution set of objective function $f_i$ can only be observed by agent $i$
itself. At each time step, simply determined by a Bernoulli trial, each agent
independently and randomly chooses either taking an average among its neighbor
set, or projecting onto the optimal solution set of its own optimization
component. Both directed and bidirectional communication graphs are studied.
Connectivity conditions are proposed to guarantee an optimal consensus almost
surely with proper convexity and intersection assumptions. The convergence
analysis is carried out using convex analysis. We compare the randomized
algorithm with the deterministic one via a numerical example. The results
illustrate that a group of autonomous agents can reach an optimal opinion by
each node simply making a randomized trade-off between following its neighbors
or sticking to its own opinion at each time step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3226</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3226</id><created>2011-08-16</created><updated>2012-02-28</updated><authors><author><keyname>Shi</keyname><forenames>Guodong</forenames></author><author><keyname>Johansson</keyname><forenames>Karl Henrik</forenames></author></authors><title>Multi-agent Robust Consensus: Convergence Analysis and Application</title><categories>cs.DC cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The paper investigates consensus problem for continuous-time multi-agent
systems with time-varying communication graphs subject to process noises.
Borrowing the ideas from input-to-state stability (ISS) and integral
input-to-state stability (iISS), robust consensus and integral robust consensus
are defined with respect to $L_\infty$ and $L_1$ norms of the disturbance
functions, respectively. Sufficient and/or necessary connectivity conditions
are obtained for the system to reach robust consensus or integral robust
consensus, which answer the question: how much communication capacity is
required for a multi-agent network to converge despite certain amount of
disturbance. The $\epsilon$-convergence time is then obtained for the network
as a special case of the robustness analysis. The results are based on quite
general assumptions on switching graph, weights rule and noise regularity. In
addition, as an illustration of the applicability of the results, distributed
event-triggered coordination is studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3235</identifier>
 <datestamp>2013-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3235</id><created>2011-08-16</created><authors><author><keyname>Figueredo</keyname><forenames>Grazziela P.</forenames></author><author><keyname>Aickelin</keyname><forenames>Uwe</forenames></author></authors><title>Comparing System Dynamics and Agent-Based Simulation for Tumour Growth
  and its Interactions with Effector Cells</title><categories>cs.CE cs.AI q-bio.CB</categories><comments>8 pages, 8 figures, 2 tables, International Summer Computer
  Simulation Conference 2011</comments><journal-ref>Proceedings of the International Summer Computer Simulation
  Conference 2011, p15-22, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is little research concerning comparisons and combination of System
Dynamics Simulation (SDS) and Agent Based Simulation (ABS). ABS is a paradigm
used in many levels of abstraction, including those levels covered by SDS. We
believe that the establishment of frameworks for the choice between these two
simulation approaches would contribute to the simulation research. Hence, our
work aims for the establishment of directions for the choice between SDS and
ABS approaches for immune system-related problems. Previously, we compared the
use of ABS and SDS for modelling agents' behaviour in an environment with
nomovement or interactions between these agents. We concluded that for these
types of agents it is preferable to use SDS, as it takes up less computational
resources and produces the same results as those obtained by the ABS model. In
order to move this research forward, our next research question is: if we
introduce interactions between these agents will SDS still be the most
appropriate paradigm to be used? To answer this question for immune system
simulation problems, we will use, as case studies, models involving
interactions between tumour cells and immune effector cells. Experiments show
that there are cases where SDS and ABS can not be used interchangeably, and
therefore, their comparison is not straightforward.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3239</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3239</id><created>2011-08-16</created><authors><author><keyname>Saleem</keyname><forenames>Muhammad Shoaib</forenames></author><author><keyname>Renault</keyname><forenames>Eric</forenames></author><author><keyname>Zeghlache</keyname><forenames>Djamal</forenames></author></authors><title>Information Centric Networking based Handover Support for QoS
  Maintenance in Cooperative Heterogeneous Wireless Networks</title><categories>cs.NI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Network of Information (NetInf) is a term coined for networks which unlike
contemporary network are not node centric. As the name indicates, information
supersedes nodes in the network. In this report, we propose an architecture of
mobile node for NetInf. We call it NetInf Mobile Node. It is an extension of
the basic node architecture proposed for NetInf. It is compatible to NetInf and
TCP/IP based networks. The Virtual Node Layer modules in the architecture
provide support for managing mobility, power consumption of the node as well
data relaying/storing services. In- ner/Outer Locator Construction Routers (I/O
LCTR) are two functions introduced in NetInf mobile nodes to operate between
NetInf and non- NetInf sites. The basic purpose of NetInf mobile node is to
maintain the QoS during mobility events. The handoff/handover are critical
situations during mobility where chances of QoS degradation of an ongoing
session are high. This report presents one such scenario in which QoS of an
appli- cation is maintained during a handoff situations in heterogeneous
wireless network environment through our proposed algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3240</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3240</id><created>2011-08-16</created><authors><author><keyname>Kloetzer</keyname><forenames>Marius</forenames></author><author><keyname>Ding</keyname><forenames>Xu Chu</forenames></author><author><keyname>Belta</keyname><forenames>Calin</forenames></author></authors><title>Multi-robot Deployment From LTL Specifications with Reduced
  Communication</title><categories>cs.RO cs.SY math.OC</categories><comments>CDC 2011 Technical Report</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we develop a computational framework for fully automatic
deployment of a team of unicycles from a global specification given as an LTL
formula over some regions of interest. Our hierarchical approach consists of
four steps: (i) the construction of finite abstractions for the motions of each
robot, (ii) the parallel composition of the abstractions, (iii) the generation
of a satisfying motion of the team; (iv) mapping this motion to individual
robot control and communication strategies. The main result of the paper is an
algorithm to reduce the amount of inter-robot communication during the fourth
step of the procedure.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3250</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3250</id><created>2011-08-12</created><authors><author><keyname>Al-Wassai</keyname><forenames>Firouz Abdullah</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author><author><keyname>Al-Zaky</keyname><forenames>Ali A.</forenames></author></authors><title>The Statistical methods of Pixel-Based Image Fusion Techniques</title><categories>cs.CV</categories><comments>Keywords: Data Fusion, Resolution Enhancement, Statistical fusion,
  Correlation Modeling, Matching, pixel based fusion</comments><journal-ref>International Journal of Artificial Intelligence and Knowledge
  Discovery Vol.1, Issue 3, July, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There are many image fusion methods that can be used to produce
high-resolution mutlispectral images from a high-resolution panchromatic (PAN)
image and low-resolution multispectral (MS) of remote sensed images. This paper
attempts to undertake the study of image fusion techniques with different
Statistical techniques for image fusion as Local Mean Matching (LMM), Local
Mean and Variance Matching (LMVM), Regression variable substitution (RVS),
Local Correlation Modeling (LCM) and they are compared with one another so as
to choose the best technique, that can be applied on multi-resolution satellite
images. This paper also devotes to concentrate on the analytical techniques for
evaluating the quality of image fusion (F) by using various methods including
Standard Deviation (SD), Entropy(En), Correlation Coefficient (CC), Signal-to
Noise Ratio (SNR), Normalization Root Mean Square Error (NRMSE) and Deviation
Index (DI) to estimate the quality and degree of information improvement of a
fused image quantitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3251</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3251</id><created>2011-08-15</created><authors><author><keyname>Migukin</keyname><forenames>Artem</forenames></author><author><keyname>Katkovnik</keyname><forenames>Vladimir</forenames></author><author><keyname>Astola</keyname><forenames>Jaakko</forenames></author></authors><title>Advanced phase retrieval: maximum likelihood technique with sparse
  regularization of phase and amplitude</title><categories>cs.CV</categories><comments>Submitted to the 10th IMEKO Symposium LMPMI (Laser Metrology for
  Precision Measurement and Inspection in Industry) on May 31, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sparse modeling is one of the efficient techniques for imaging that allows
recovering lost information. In this paper, we present a novel iterative
phase-retrieval algorithm using a sparse representation of the object amplitude
and phase. The algorithm is derived in terms of a constrained maximum
likelihood, where the wave field reconstruction is performed using a number of
noisy intensity-only observations with a zero-mean additive Gaussian noise. The
developed algorithm enables the optimal solution for the object wave field
reconstruction. Our goal is an improvement of the reconstruction quality with
respect to the conventional algorithms. Sparse regularization results in
advanced reconstruction accuracy, and numerical simulations demonstrate
significant enhancement of imaging.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3259</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3259</id><created>2011-08-16</created><authors><author><keyname>Taieb</keyname><forenames>Souhaib Ben</forenames></author><author><keyname>Bontempi</keyname><forenames>Gianluca</forenames></author><author><keyname>Atiya</keyname><forenames>Amir</forenames></author><author><keyname>Sorjamaa</keyname><forenames>Antti</forenames></author></authors><title>A review and comparison of strategies for multi-step ahead time series
  forecasting based on the NN5 forecasting competition</title><categories>stat.ML cs.AI cs.LG stat.AP</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-step ahead forecasting is still an open challenge in time series
forecasting. Several approaches that deal with this complex problem have been
proposed in the literature but an extensive comparison on a large number of
tasks is still missing. This paper aims to fill this gap by reviewing existing
strategies for multi-step ahead forecasting and comparing them in theoretical
and practical terms. To attain such an objective, we performed a large scale
comparison of these different strategies using a large experimental benchmark
(namely the 111 series from the NN5 forecasting competition). In addition, we
considered the effects of deseasonalization, input variable selection, and
forecast combination on these strategies and on multi-step ahead forecasting at
large. The following three findings appear to be consistently supported by the
experimental results: Multiple-Output strategies are the best performing
approaches, deseasonalization leads to uniformly improved forecast accuracy,
and input selection is more effective when performed in conjunction with
deseasonalization.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3260</identifier>
 <datestamp>2013-09-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3260</id><created>2011-08-16</created><authors><author><keyname>Eiter</keyname><forenames>Thomas</forenames></author><author><keyname>Erdem</keyname><forenames>Esra</forenames></author><author><keyname>Erdogan</keyname><forenames>Halit</forenames></author><author><keyname>Fink</keyname><forenames>Michael</forenames></author></authors><title>Finding Similar/Diverse Solutions in Answer Set Programming</title><categories>cs.AI cs.LO cs.PL</categories><comments>57 pages, 17 figures, 4 tables. To appear in Theory and Practice of
  Logic Programming (TPLP)</comments><journal-ref>Theory and Practice of Logic Programming, 13(3), 303-359, 2013</journal-ref><doi>10.1017/S1471068411000548</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For some computational problems (e.g., product configuration, planning,
diagnosis, query answering, phylogeny reconstruction) computing a set of
similar/diverse solutions may be desirable for better decision-making. With
this motivation, we studied several decision/optimization versions of this
problem in the context of Answer Set Programming (ASP), analyzed their
computational complexity, and introduced offline/online methods to compute
similar/diverse solutions of such computational problems with respect to a
given distance function. All these methods rely on the idea of computing
solutions to a problem by means of finding the answer sets for an ASP program
that describes the problem. The offline methods compute all solutions in
advance using the ASP formulation of the problem with an ASP solver, like
Clasp, and then identify similar/diverse solutions using clustering methods.
The online methods compute similar/diverse solutions following one of the three
approaches: by reformulating the ASP representation of the problem to compute
similar/diverse solutions at once using an ASP solver; by computing
similar/diverse solutions iteratively (one after other) using an ASP solver; by
modifying the search algorithm of an ASP solver to compute similar/diverse
solutions incrementally. We modified Clasp to implement the last online method
and called it Clasp-NK. In the first two online methods, the given distance
function is represented in ASP; in the last one it is implemented in C++. We
showed the applicability and the effectiveness of these methods on
reconstruction of similar/diverse phylogenies for Indo-European languages, and
on several planning problems in Blocks World. We observed that in terms of
computational efficiency the last online method outperforms the others; also it
allows us to compute similar/diverse solutions when the distance function
cannot be represented in ASP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3261</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3261</id><created>2011-08-16</created><authors><author><keyname>Gerdt</keyname><forenames>Vladimir P.</forenames></author><author><keyname>Hashemi</keyname><forenames>Amir</forenames></author><author><keyname>-Alizadeh</keyname><forenames>Benyamin M.</forenames></author></authors><title>A Variant of Gerdt's Algorithm for Computing Involutive Bases</title><categories>math.RA cs.SC math.AC</categories><comments>13 pages</comments><msc-class>13P10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Ihe first author presented an efficient algorithm for computing involutive
(and reduced Groebner) bases. In this paper, we consider a modification of this
algorithm which simplifies matters to understand it and to implement. We prove
correctness and termination of the modified algorithm and also correctness of
the used criteria. The proposed algorithm has been implemented in Maple. We
present experimental comparison, via some examples, of performance of the
modified algorithm with its original form which has been implemented in Maple
too. In doing so, we have taken care to provide uniform implementation details
for the both algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3265</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3265</id><created>2011-08-16</created><authors><author><keyname>Hammer</keyname><forenames>Matthew A.</forenames></author><author><keyname>Neis</keyname><forenames>Georg</forenames></author><author><keyname>Chen</keyname><forenames>Yan</forenames></author><author><keyname>Acar</keyname><forenames>Umut A.</forenames></author></authors><title>Self-Adjusting Stack Machines</title><categories>cs.PL</categories><comments>Full version of our OOPLSA 2011 paper. Contains a couple of
  additional sections as well as an appendix with our proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-adjusting computation offers a language-based approach to writing
programs that automatically respond to dynamically changing data. Recent work
made significant progress in developing sound semantics and associated
implementations of self-adjusting computation for high-level, functional
languages. These techniques, however, do not address issues that arise for
low-level languages, i.e., stack-based imperative languages that lack strong
type systems and automatic memory management.
  In this paper, we describe techniques for self-adjusting computation which
are suitable for low-level languages. Necessarily, we take a different approach
than previous work: instead of starting with a high-level language with
additional primitives to support self-adjusting computation, we start with a
low-level intermediate language, whose semantics is given by a stack-based
abstract machine. We prove that this semantics is sound: it always updates
computations in a way that is consistent with full reevaluation. We give a
compiler and runtime system for the intermediate language used by our abstract
machine. We present an empirical evaluation that shows that our approach is
efficient in practice, and performs favorably compared to prior proposals.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3268</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3268</id><created>2011-08-16</created><authors><author><keyname>Abdelgadir</keyname><forenames>Abdelgadir Tageldin</forenames></author><author><keyname>Pathan</keyname><forenames>Al-Sakib Khan</forenames></author><author><keyname>Ahmed</keyname><forenames>Mohiuddin</forenames></author></authors><title>On the Performance of MPI-OpenMP on a 12 nodes Multi-core Cluster</title><categories>cs.DC</categories><comments>11 pages, to appear in ICA3PP'11 conference</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  With the increasing number of Quad-Core-based clusters and the introduction
of compute nodes designed with large memory capacity shared by multiple cores,
new problems related to scalability arise. In this paper, we analyze the
overall performance of a cluster built with nodes having a dual Quad-Core
Processor on each node. Some benchmark results are presented and some
observations are mentioned when handling such processors on a benchmark test. A
Quad-Core-based cluster's complexity arises from the fact that both local
communication and network communications between the running processes need to
be addressed. The potentials of an MPI-OpenMP approach are pinpointed because
of its reduced communication overhead. At the end, we come to a conclusion that
an MPI-OpenMP solution should be considered in such clusters since optimizing
network communications between nodes is as important as optimizing local
communications between processors in a multi-core cluster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3278</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3278</id><created>2011-08-16</created><authors><author><keyname>Denecker</keyname><forenames>Marc</forenames></author><author><keyname>Marek</keyname><forenames>Victor W.</forenames></author><author><keyname>Truszczynski</keyname><forenames>Miroslaw</forenames></author></authors><title>Reiter's Default Logic Is a Logic of Autoepistemic Reasoning And a Good
  One, Too</title><categories>cs.AI</categories><comments>In G. Brewka, V.M. Marek, and M. Truszczynski, eds. Nonmonotonic
  Reasoning -- Essays Celebrating its 30th Anniversary, College Publications,
  2011 (a volume of papers presented at NonMOn at 30 meeting, Lexington, KY,
  USA, October 2010</comments><msc-class>I.2.4</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A fact apparently not observed earlier in the literature of nonmonotonic
reasoning is that Reiter, in his default logic paper, did not directly
formalize informal defaults. Instead, he translated a default into a certain
natural language proposition and provided a formalization of the latter. A few
years later, Moore noted that propositions like the one used by Reiter are
fundamentally different than defaults and exhibit a certain autoepistemic
nature. Thus, Reiter had developed his default logic as a formalization of
autoepistemic propositions rather than of defaults.
  The first goal of this paper is to show that some problems of Reiter's
default logic as a formal way to reason about informal defaults are directly
attributable to the autoepistemic nature of default logic and to the mismatch
between informal defaults and the Reiter's formal defaults, the latter being a
formal expression of the autoepistemic propositions Reiter used as a
representation of informal defaults.
  The second goal of our paper is to compare the work of Reiter and Moore.
While each of them attempted to formalize autoepistemic propositions, the modes
of reasoning in their respective logics were different. We revisit Moore's and
Reiter's intuitions and present them from the perspective of autotheoremhood,
where theories can include propositions referring to the theory's own theorems.
We then discuss the formalization of this perspective in the logics of Moore
and Reiter, respectively, using the unifying semantic framework for default and
autoepistemic logics that we developed earlier. We argue that Reiter's default
logic is a better formalization of Moore's intuitions about autoepistemic
propositions than Moore's own autoepistemic logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3279</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3279</id><created>2011-08-16</created><authors><author><keyname>Truszczynski</keyname><forenames>Miroslaw</forenames></author></authors><title>Revisiting Epistemic Specifications</title><categories>cs.AI</categories><comments>In Marcello Balduccini and Tran Cao Son, Editors, Essays Dedicated to
  Michael Gelfond on the Occasion of His 65th Birthday, Lexington, KY, USA,
  October 2010, LNAI 6565, Springer</comments><acm-class>I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In 1991, Michael Gelfond introduced the language of epistemic specifications.
The goal was to develop tools for modeling problems that require some form of
meta-reasoning, that is, reasoning over multiple possible worlds. Despite their
relevance to knowledge representation, epistemic specifications have received
relatively little attention so far. In this paper, we revisit the formalism of
epistemic specification. We offer a new definition of the formalism, propose
several semantics (one of which, under syntactic restrictions we assume, turns
out to be equivalent to the original semantics by Gelfond), derive some
complexity results and, finally, show the effectiveness of the formalism for
modeling problems requiring meta-reasoning considered recently by Faber and
Woltran. All these results show that epistemic specifications deserve much more
attention that has been afforded to them so far.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3281</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3281</id><created>2011-08-16</created><authors><author><keyname>Marek</keyname><forenames>Victor W.</forenames></author><author><keyname>Niemela</keyname><forenames>Ilkka</forenames></author><author><keyname>Truszczynski</keyname><forenames>Miroslaw</forenames></author></authors><title>Origins of Answer-Set Programming - Some Background And Two Personal
  Accounts</title><categories>cs.AI</categories><comments>In G. Brewka, V.M. Marek, and M. Truszczynski, eds. Nonmonotonic
  Reasoning -- Essays Celebrating its 30th Anniversary, College Publications,
  2011 (a volume of papers presented at NonMon at 30 meeting, Lexington, KY,
  USA, October 2010)</comments><msc-class>I.2.4</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the evolution of aspects of nonmonotonic reasoning towards the
computational paradigm of answer-set programming (ASP). We give a general
overview of the roots of ASP and follow up with the personal perspective on
research developments that helped verbalize the main principles of ASP and
differentiated it from the classical logic programming.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3285</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3285</id><created>2011-08-16</created><authors><author><keyname>Suthisopapan</keyname><forenames>Puripong</forenames></author><author><keyname>Kasai</keyname><forenames>Kenta</forenames></author><author><keyname>Meesomboon</keyname><forenames>Anupap</forenames></author><author><keyname>Imtawil</keyname><forenames>Virasit</forenames></author><author><keyname>Sakaniwa</keyname><forenames>Kohichi</forenames></author></authors><title>Simple Low-Rate Non-Binary LDPC Coding for Relay Channels</title><categories>cs.IT math.IT</categories><comments>submitted to IEEE JSAC</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Binary LDPC coded relay systems have been well studied previously with the
assumption of infinite codeword length. In this paper, we deal with non-binary
LDPC codes which can outperform their binary counterpart especially for
practical codeword length. We utilize non-binary LDPC codes and recently
invented non-binary coding techniques known as multiplicative repetition to
design the low-rate coding strategy for the decode-and-forward half-duplex
relay channel. We claim that the proposed strategy is simple since the
destination and the relay can decode with almost the same computational
complexity by sharing the same structure of decoder. Numerical experiments are
carried out to show that the performances obtained by non-binary LDPC coded
relay systems surpass the capacity of direct transmission and also approach
within less than 1.5 dB from the achievable rate of the relay channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3286</identifier>
 <datestamp>2012-07-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3286</id><created>2011-08-16</created><updated>2012-07-11</updated><authors><author><keyname>Vignesh</keyname><forenames>B</forenames></author><author><keyname>S</keyname><forenames>Siddharth</forenames></author><author><keyname>Ramachandran</keyname><forenames>Shridhar</forenames></author><author><keyname>Iyengar</keyname><forenames>Dr. Sudarshan</forenames></author><author><keyname>Rangan</keyname><forenames>Dr. C Pandu</forenames></author></authors><title>A Lookahead algorithm to compute Betweenness Centrality</title><categories>cs.SI physics.soc-ph</categories><comments>12 pages, 5 figures The paper has been withdrawn due to the need for
  more extensive experimentation to provide further backing to the result</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Betweenness Centrality index is a very important centrality measure in
the analysis of a large number of networks. Despite its significance in a lot
of interdisciplinary applications, its computation is very expensive. The
fastest known algorithm presently is by Brandes which takes O(|V || E|) time
for computation. In real life scenarios, it happens very frequently that a
single vertex or a set of vertices is sequentially removed from a network. The
recomputation of Betweenness Centrality on removing a single vertex becomes
expensive when the Brandes algorithm is repeated. It is to be understood that
as the size of the network increases, Betweenness Centrality calculation
becomes more and more expensive and even a decrease in running time by a small
fraction results in a phenomenal decrease in the actual running time. The
algorithm introduced in this paper achieves the same in a significantly lesser
time than repetition of the Brandes algorithm. The algorithm can also be
extended to a general case.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3298</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3298</id><created>2011-08-16</created><authors><author><keyname>Knoll</keyname><forenames>Byron</forenames></author><author><keyname>de Freitas</keyname><forenames>Nando</forenames></author></authors><title>A Machine Learning Perspective on Predictive Coding with PAQ</title><categories>cs.LG cs.AI cs.CV cs.IR stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  PAQ8 is an open source lossless data compression algorithm that currently
achieves the best compression rates on many benchmarks. This report presents a
detailed description of PAQ8 from a statistical machine learning perspective.
It shows that it is possible to understand some of the modules of PAQ8 and use
this understanding to improve the method. However, intuitive statistical
explanations of the behavior of other modules remain elusive. We hope the
description in this report will be a starting point for discussions that will
increase our understanding, lead to improvements to PAQ8, and facilitate a
transfer of knowledge from PAQ8 to other machine learning methods, such a
recurrent neural networks and stochastic memoizers. Finally, the report
presents a broad range of new applications of PAQ to machine learning tasks
including language modeling and adaptive text prediction, adaptive game
playing, classification, and compression using features from the field of deep
learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3299</identifier>
 <datestamp>2011-08-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3299</id><created>2011-08-16</created><authors><author><keyname>Park</keyname><forenames>Myoungkuk</forenames></author><author><keyname>Kalyanam</keyname><forenames>Krishnamoorthy</forenames></author><author><keyname>Darbha</keyname><forenames>Swaroop</forenames></author><author><keyname>Chandler</keyname><forenames>Phil</forenames></author><author><keyname>Pachter</keyname><forenames>Meir</forenames></author></authors><title>Bounding Procedures for Stochastic Dynamic Programs with Application to
  the Perimeter Patrol Problem</title><categories>cs.SY math.OC</categories><comments>41 pages, 6 figures and 1 table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One often encounters the curse of dimensionality in the application of
dynamic programming to determine optimal policies for controlled Markov chains.
In this paper, we provide a method to construct sub-optimal policies along with
a bound for the deviation of such a policy from the optimum via a linear
programming approach. The state-space is partitioned and the optimal cost-to-go
or value function is approximated by a constant over each partition. By
minimizing a non-negative cost function defined on the partitions, one can
construct an approximate value function which also happens to be an upper bound
for the optimal value function of the original Markov Decision Process (MDP).
As a key result, we show that this approximate value function is {\it
independent} of the non-negative cost function (or state dependent weights as
it is referred to in the literature) and moreover, this is the least upper
bound that one can obtain once the partitions are specified. Furthermore, we
show that the restricted system of linear inequalities also embeds a family of
MDPs of lower dimension, one of which can be used to construct a lower bound on
the optimal value function. The construction of the lower bound requires the
solution to a combinatorial problem. We apply the linear programming approach
to a perimeter surveillance stochastic optimal control problem and obtain
numerical results that corroborate the efficacy of the proposed methodology.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3329</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3329</id><created>2011-08-16</created><updated>2012-04-13</updated><authors><author><keyname>Vempala</keyname><forenames>Santosh S.</forenames></author><author><keyname>Xiao</keyname><forenames>Ying</forenames></author></authors><title>Structure from Local Optima: Learning Subspace Juntas via Higher Order
  PCA</title><categories>cs.CC math.OC math.PR</categories><msc-class>68Q32, 15A69, 90C26</msc-class><acm-class>F.2; G.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a generalization of the well-known problem of learning k-juntas in
R^n, and a novel tensor algorithm for unraveling the structure of
high-dimensional distributions. Our algorithm can be viewed as a higher-order
extension of Principal Component Analysis (PCA).
  Our motivating problem is learning a labeling function in R^n, which is
determined by an unknown k-dimensional subspace. This problem of learning a
k-subspace junta is a common generalization of learning a k-junta (a function
of k coordinates in R^n) and learning intersections of k halfspaces. In this
context, we introduce an irrelevant noisy attributes model where the
distribution over the &quot;relevant&quot; k-dimensional subspace is independent of the
distribution over the (n-k)-dimensional &quot;irrelevant&quot; subspace orthogonal to it.
  We give a spectral tensor algorithm which identifies the relevant subspace,
and thereby learns k-subspace juntas under some additional assumptions. We do
this by exploiting the structure of local optima of higher moment tensors over
the unit sphere; PCA finds the global optima of the second moment tensor
(covariance matrix). Our main result is that when the distribution in the
irrelevant (n-k)-dimensional subspace is any Gaussian, the complexity of our
algorithm is T(k,\epsilon) + \poly(n), where T is the complexity of learning
the concept in k dimensions, and the polynomial is a function of the
k-dimensional concept class being learned. This substantially generalizes
existing results on learning low-dimensional concepts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3342</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3342</id><created>2011-08-16</created><authors><author><keyname>Yuan</keyname><forenames>Xiaohong</forenames></author><author><keyname>Fernandez</keyname><forenames>Eduardo B.</forenames></author></authors><title>Patterns for Business-to-consumer E-Commerce Applications</title><categories>cs.SE</categories><comments>20 pages, 17 figures</comments><journal-ref>International Journal of Software Engineering and Applications,
  Vol. 2, No. 3, July, 2011, pp. 1-20</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  E-commerce is one of the most important web applications. We present here a
set of patterns that describe shopping carts, products, catalogue, customer
accounts, shipping, and invoices. We combine them in the form of composite
patterns, which in turn make up a domain model for business-to-consumer
e-commerce. We also indicate how to add security constraints to this model.
This domain model can be used as a computation-independent model from which
specific applications can be produced using a model-driven architecture
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3347</identifier>
 <datestamp>2014-11-04</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3347</id><created>2011-08-16</created><updated>2014-11-03</updated><authors><author><keyname>Gasarch</keyname><forenames>William</forenames></author></authors><title>Proving programs terminate using well orderings, Ramsey Theory, and
  Matrices</title><categories>math.CO cs.LO</categories><comments>While this is classified under Combinatorics (to tell combinatorists
  that someone is using their stuff) it should also be of interest to Logicians
  and Computer Scientists</comments><msc-class>68N30, 05D10, 03F35</msc-class><acm-class>B.7.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many programs allow the user to input data several times during its
execution. If the program runs forever the user may input data infinitely
often. A program terminates if it terminates no matter what the user does.
  We discuss various ways to prove that program terminates. The proofs use well
orderings, Ramsey Theory, and Matrices. These techniques are used by real
program checkers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3350</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3350</id><created>2011-08-16</created><updated>2012-03-27</updated><authors><author><keyname>Lu</keyname><forenames>Wei</forenames></author><author><keyname>Vaswani</keyname><forenames>Namrata</forenames></author></authors><title>Exact Reconstruction Conditions for Regularized Modified Basis Pursuit</title><categories>cs.IT math.IT stat.ML</categories><comments>17 pages</comments><journal-ref>IEEE Transactions on Signal Processing, May 2012</journal-ref><doi>10.1109/TSP.2012.2186445</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this correspondence, we obtain exact recovery conditions for regularized
modified basis pursuit (reg-mod-BP) and discuss when the obtained conditions
are weaker than those for modified-CS or for basis pursuit (BP). The discussion
is also supported by simulation comparisons. Reg-mod-BP provides a solution to
the sparse recovery problem when both an erroneous estimate of the signal's
support, denoted by $T$, and an erroneous estimate of the signal values on $T$
are available.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3365</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3365</id><created>2011-08-16</created><authors><author><keyname>Osmani-Bojd</keyname><forenames>Mohammad</forenames></author><author><keyname>Sahebalam</keyname><forenames>Assadallah</forenames></author><author><keyname>Hodtani</keyname><forenames>Ghosheh Abed</forenames></author></authors><title>A General Achievable Rate Region for Multiple-Access Relay Channels and
  Some Certain Capacity Theorems</title><categories>cs.IT math.IT</categories><comments>5 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we obtain a general achievable rate region and some certain
capacity theorems for multiple-access relay channel (MARC), using decode and
forward (DAF) strategy at the relay, superposition coding at the transmitters.
Our general rate region (i) generalizes the achievability part of Slepian-Wolf
multiple-access capacity theorem to the MARC, (ii) extends the Cover-El Gamal
best achievable rate for the relay channel with DAF strategy to the MARC, (iii)
gives the Kramer-Wijengaarden rate region for the MARC, (iv) meets max-flow
min-cut upper bound and leads to the capacity regions of some important classes
of the MARC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3367</identifier>
 <datestamp>2012-03-06</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3367</id><created>2011-08-16</created><updated>2012-03-04</updated><authors><author><keyname>Nowak</keyname><forenames>Rafa&#x142;</forenames></author></authors><title>On the convergence acceleration of some continued fractions</title><categories>math.NA cs.NA</categories><comments>English improved</comments><msc-class>65B99, 33F05</msc-class><acm-class>G.1.0; G.1.2; G.1.10</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A well known method for convergence acceleration of continued fraction
$\K(a_n/b_n)$ is to use the modified approximants $S_n(\omega_n)$ in place of
the classical approximants $S_n(0)$, where $\omega_n$ are close to tails
$f^{(n)}$ of continued fraction. Recently, author proposed a method of
iterative character producing tail approximations whose asymptotic expansion's
accuracy is improving in each step. This method can be applied to continued
fractions $\K(a_n/b_n)$, where $a_n$, $b_n$ are polynomials in $n$ ($\deg
a_n=2$, $\deg b_n\leq 1$) for sufficiently large $n$. The purpose of this paper
is to extend this idea for the class of continued fractions $\K(a_n/b_n +
a_n'/b_n')$, where $a_n$, $a_n'$, $b_n$, $b_n'$ are polynomials in $n$ ($\deg
a_n=\deg a_n', \deg b_n=\deg b_n'$). We give examples involving such continued
fraction expansions of some mathematical constants, as well as elementary and
special functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3372</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3372</id><created>2011-08-16</created><authors><author><keyname>L&#xe1;zaro-Gredilla</keyname><forenames>Miguel</forenames></author><author><keyname>Van Vaerenbergh</keyname><forenames>Steven</forenames></author><author><keyname>Lawrence</keyname><forenames>Neil</forenames></author></authors><title>Overlapping Mixtures of Gaussian Processes for the Data Association
  Problem</title><categories>stat.ML cs.AI cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we introduce a mixture of GPs to address the data association
problem, i.e. to label a group of observations according to the sources that
generated them. Unlike several previously proposed GP mixtures, the novel
mixture has the distinct characteristic of using no gating function to
determine the association of samples and mixture components. Instead, all the
GPs in the mixture are global and samples are clustered following
&quot;trajectories&quot; across input space. We use a non-standard variational Bayesian
algorithm to efficiently recover sample labels and learn the hyperparameters.
We show how multi-object tracking problems can be disambiguated and also
explore the characteristics of the model in traditional regression settings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3383</identifier>
 <datestamp>2011-11-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3383</id><created>2011-08-16</created><updated>2011-11-28</updated><authors><author><keyname>Cai</keyname><forenames>Jin-Yi</forenames></author><author><keyname>Kowalczyk</keyname><forenames>Michael</forenames></author><author><keyname>Williams</keyname><forenames>Tyson</forenames></author></authors><title>Gadgets and Anti-Gadgets Leading to a Complexity Dichotomy</title><categories>cs.CC cs.DS</categories><comments>26 pages, 14 figures, To appear at ITCS 2012, New version changes:
  minor copy edits, workaround for arXiv bug that made subscript references too
  large</comments><msc-class>68Q17 (Primary) 68W99 (Secondary)</msc-class><acm-class>F.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce an idea called anti-gadgets in complexity reductions. These
combinatorial gadgets have the effect of erasing the presence of some other
graph fragment, as if we had managed to include a negative copy of a graph
gadget. We use this idea to prove a complexity dichotomy theorem for the
partition function $Z(G)$ on 3-regular directed graphs $G$, where each edge is
given a complex-valued binary function $f: \{0,1\}^2 \rightarrow \mathbb{C}$.
We show that \[Z(G) = \sum_{\sigma: V(G) \to \{0,1\}} \prod_{(u,v) \in E(G)}
f(\sigma(u), \sigma(v)),\] is either computable in polynomial time or #P-hard,
depending explicitly on $f$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3387</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3387</id><created>2011-08-16</created><authors><author><keyname>Tanimoto</keyname><forenames>Shinji</forenames></author></authors><title>Natural growth model of weighted complex networks</title><categories>physics.soc-ph cs.SI</categories><comments>5 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a natural model of evolving weighted networks in which new links
are not necessarily connected to new nodes. The model allows a newly added link
to connect directly two nodes already present in the network. This is plausible
in modeling many real-world networks. Such a link is called an inner link,
while a link connected to a new node is called an outer link. In view of
interrelations between inner and outer links, we investigate power-laws for the
strength, degree and weight distributions of weighted complex networks. This
model enables us to predict some features of weighted networks such as the
worldwide airport network and the scientific collaboration network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3405</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3405</id><created>2011-08-17</created><authors><author><keyname>Karimoddini</keyname><forenames>A.</forenames></author><author><keyname>Lin</keyname><forenames>H.</forenames></author><author><keyname>Chen</keyname><forenames>B. M.</forenames></author><author><keyname>Lee</keyname><forenames>T. H.</forenames></author></authors><title>Hybrid 3-D Formation Control for Unmanned Helicopters</title><categories>cs.SY cs.MA cs.RO math.OC</categories><comments>Submitted for publication</comments><report-no>NUS-ACT-11-005</report-no><msc-class>93C85</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Teams of Unmanned Aerial Vehicles (UAVs) form typical networked
cyber-physical systems that involve the interaction of discrete logic and
continuous dynamics. This paper presents a hybrid supervisory control framework
for the three-dimensional leader follower formation control of unmanned
helicopters. The proposed hybrid control framework captures internal
interactions between the decision making unit and the path planner continuous
dynamics of the system, and hence improves the system's overall reliability. To
design such a hybrid controller, a spherical abstraction of the state space is
proposed as a new method of abstraction. Utilizing the properties of
multi-affine functions over the partitioned space leads to a finite state
Discrete Event System (DES) model, which is shown to be bisimilar to the
original continuous-variable dynamical system. Then, in the discrete domain, a
logic supervisor is modularly designed for the abstracted model. Due to the
bisimilarity between the abstracted DES model and the original UAV dynamics,
the designed logic supervisor can be implemented as a hybrid controller through
an interface layer. This supervisor drives the UAV dynamics to satisfy the
design requirements. In other words, the hybrid controller is able to bring the
UAVs to the desired formation starting from any initial state inside the
control horizon and then, maintain the formation. Moreover, a collision
avoidance mechanism is embedded in the designed supervisor. Finally, the
algorithm has been verified by a hardware-in-the-loop simulation platform,
which is developed for unmanned helicopters. The presented results show the
effectiveness of the algorithm.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3412</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3412</id><created>2011-08-17</created><authors><author><keyname>Ambro&#x17e;</keyname><forenames>Petr</forenames><affiliation>FNSPE, Czech Technical University in Prague</affiliation></author><author><keyname>Holub</keyname><forenames>&#x160;t&#x11b;p&#xe1;n</forenames><affiliation>FMP, Charles University in Prague</affiliation></author><author><keyname>Mas&#xe1;kov&#xe1;</keyname><forenames>Zuzana</forenames><affiliation>FNSPE, Czech Technical University in Prague</affiliation></author></authors><title>Proceedings 8th International Conference Words 2011</title><categories>cs.FL</categories><comments>EPTCS 63, 2011</comments><proxy>EPTCS</proxy><doi>10.4204/EPTCS.63</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  WORDS is the main international event in Combinatorics on Words. It is a
biannual conference devoted to research of words (i.e., finite or infinite
sequences of symbols over a finite alphabet) from combinatorial, algebraic and
algorithmic points of view. The emphasis of the conference is on mathematical
theory of words but the conference is also open to applications, mainly in
computer science, biology, linguistics and physics, gaining from the fact that
words arise as a natural object in many areas.
  The eighth edition of the conference was organized in Prague from 12th to
16th September 2011 as a joint undertaking of the Czech Technical University
and the Charles University. This volume consists of contributed papers accepted
for presentation at the conference and summaries of invited lectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3413</identifier>
 <datestamp>2011-12-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3413</id><created>2011-08-17</created><updated>2011-12-02</updated><authors><author><keyname>Huang</keyname><forenames>Zengfeng</forenames></author><author><keyname>Yi</keyname><forenames>Ke</forenames></author><author><keyname>Zhang</keyname><forenames>Qin</forenames></author></authors><title>Randomized Algorithms for Tracking Distributed Count, Frequencies, and
  Ranks</title><categories>cs.DS</categories><comments>19 pages, 1 figure</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that randomization can lead to significant improvements for a few
fundamental problems in distributed tracking. Our basis is the {\em
count-tracking} problem, where there are $k$ players, each holding a counter
$n_i$ that gets incremented over time, and the goal is to track an
$\eps$-approximation of their sum $n=\sum_i n_i$ continuously at all times,
using minimum communication. While the deterministic communication complexity
of the problem is $\Theta(k/\eps \cdot \log N)$, where $N$ is the final value
of $n$ when the tracking finishes, we show that with randomization, the
communication cost can be reduced to $\Theta(\sqrt{k}/\eps \cdot \log N)$. Our
algorithm is simple and uses only O(1) space at each player, while the lower
bound holds even assuming each player has infinite computing power. Then, we
extend our techniques to two related distributed tracking problems: {\em
frequency-tracking} and {\em rank-tracking}, and obtain similar improvements
over previous deterministic algorithms. Both problems are of central importance
in large data monitoring and analysis, and have been extensively studied in the
literature.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3415</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3415</id><created>2011-08-17</created><authors><author><keyname>Chung</keyname><forenames>Jin-Ho</forenames></author><author><keyname>Yang</keyname><forenames>Kyeongcheol</forenames></author></authors><title>Frequency-Hopping Sequence Sets With Low Average and Maximum Hamming
  Correlation</title><categories>cs.IT math.IT</categories><comments>7 pages, submitted to IEEE Transactions on Information Theory (July
  27, 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In frequency-hopping multiple-access (FHMA) systems, the average Hamming
correlation (AHC) among frequency-hopping sequences (FHSs) as well as the
maximum Hamming correlation (MHC) is an important performance measure.
Therefore, it is a challenging problem to design FHS sets with good AHC and MHC
properties for application. In this paper, we analyze the AHC properties of an
FHS set, and present new constructions for FHS sets with optimal AHC. We first
calculate the AHC of some known FHS sets with optimal MHC, and check their
optimalities. We then prove that any uniformly distributed FHS set has optimal
AHC. We also present two constructions of FHS sets with optimal AHC based on
cyclotomy. Finally, we show that if an FHS set is obtained from another FHS set
with optimal AHC by an interleaving, it has optimal AHC.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3417</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3417</id><created>2011-08-17</created><authors><author><keyname>Lee</keyname><forenames>Myung-Kyu</forenames></author><author><keyname>Yang</keyname><forenames>Kyeongcheol</forenames></author></authors><title>The Exponent of a Polarizing Matrix Constructed from the Kronecker
  Product</title><categories>cs.IT math.IT</categories><comments>7 pages, 1 figure, submitted to IEEE Transactions on Information
  Theory (July 27, 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The asymptotic performance of a polar code under successive cancellation
decoding is determined by the exponent of its polarizing matrix. We first prove
that the partial distances of a polarizing matrix constructed from the
Kronecker product are simply expressed as a product of those of its component
matrices. We then show that the exponent of the polarizing matrix is shown to
be a weighted sum of the exponents of its component matrices. These results may
be employed in the design of a large polarizing matrix with high exponent.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3418</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3418</id><created>2011-08-17</created><authors><author><keyname>Ciobanu</keyname><forenames>Gabriel</forenames></author></authors><title>Biologically Inspired Process Calculi, Petri Nets and Membrane Computing</title><categories>cs.DC cs.FL</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/01</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume represents the proceedings of the 5th Workshop on Membrane
Computing and Biologically Inspired Process Calculi (MeCBIC 2011), held
together with the 12th International Conference on Membrane Computing on 23rd
August 2011 in Fontainebleau, France.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3419</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3419</id><created>2011-08-17</created><authors><author><keyname>Cardelli</keyname><forenames>Luca</forenames></author><author><keyname>Laneve</keyname><forenames>Cosimo</forenames></author></authors><title>Reversibility in Massive Concurrent Systems</title><categories>cs.DC cs.FL</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/02</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reversing a (forward) computation history means undoing the history. In
concurrent systems, undoing the history is not performed in a deterministic way
but in a causally consistent fashion, where states that are reached during a
backward computation are states that could have been reached during the
computation history by just performing independent actions in a different
order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3422</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3422</id><created>2011-08-17</created><authors><author><keyname>Kleijn</keyname><forenames>Jetty</forenames></author><author><keyname>Koutny</keyname><forenames>Maciej</forenames></author><author><keyname>Rozenberg</keyname><forenames>Grzegorz</forenames></author></authors><title>Petri Nets and Bio-Modelling - and how to benefit from their synergy</title><categories>cs.DC cs.FL</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/03</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this talk we are concerned with the intrinsic similarities and differences
between Petri nets on the one hand, and membrane systems and reaction systems
on the other hand.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3424</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3424</id><created>2011-08-17</created><authors><author><keyname>Barbuti</keyname><forenames>Roberto</forenames></author><author><keyname>Cacciagrano</keyname><forenames>Diletta Romana</forenames></author><author><keyname>Maggiolo-Schettini</keyname><forenames>Andrea</forenames></author><author><keyname>Milazzo</keyname><forenames>Paolo</forenames></author><author><keyname>Tesei</keyname><forenames>Luca</forenames></author></authors><title>A Testing Framework for P Systems</title><categories>cs.LO cs.FL</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/04</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Testing equivalence was originally defined by De Nicola and Hennessy in a
process algebraic setting (CCS) with the aim of defining an equivalence
relation between processes being less discriminating than bisimulation and with
a natural interpretation in the practice of system development. Finite
characterizations of the defined preorders and relations led to the possibility
of verification by comparing an implementation with a specification in a
setting where systems were seen as black boxes with input and output
capabilities, thus neglecting internal undetectable behaviours.
  In this paper, we start defining a porting of the well-established testing
theory into membrane computing, in order to investigate possible benefits in
terms of inherited analysis/verification techniques and interesting biological
applications. P Algebra, a process algebra for describing P Systems, is used as
a natural candidate for the porting since it enjoys the desirable property of
being compositional and comes with other observational equivalences already
defined and studied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3426</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3426</id><created>2011-08-17</created><authors><author><keyname>Bioglio</keyname><forenames>Livio</forenames></author><author><keyname>Calcagno</keyname><forenames>Cristina</forenames></author><author><keyname>Coppo</keyname><forenames>Mario</forenames></author><author><keyname>Damiani</keyname><forenames>Ferruccio</forenames></author><author><keyname>Sciacca</keyname><forenames>Eva</forenames></author><author><keyname>Spinella</keyname><forenames>Salvatore</forenames></author><author><keyname>Troina</keyname><forenames>Angelo</forenames></author></authors><title>A Spatial Calculus of Wrapped Compartments</title><categories>cs.LO cs.CE cs.ET q-bio.QM</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/05</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Calculus of Wrapped Compartments (CWC) is a recently proposed modelling
language for the representation and simulation of biological systems behaviour.
Although CWC has no explicit structure modelling a spatial geometry, its
compartment labelling feature can be exploited to model various examples of
spatial interactions in a natural way. However, specifying large networks of
compartments may require a long modelling phase. In this work we present a
surface language for CWC that provides basic constructs for modelling spatial
interactions. These constructs can be compiled away to obtain a standard CWC
model, thus exploiting the existing CWC simulation tool. A case study
concerning the modelling of Arbuscular Mychorrizal fungi growth is discussed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3429</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3429</id><created>2011-08-17</created><authors><author><keyname>Bodei</keyname><forenames>Chiara</forenames></author><author><keyname>Brodo</keyname><forenames>Linda</forenames></author></authors><title>Brane Calculi Systems: A Static Preview of their Possible Behaviour</title><categories>cs.LO cs.ET</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/06</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We improve the precision of a previous Control Flow Analysis for Brane
Calculi, by adding information on the context and introducing causality
information on the membranes. This allows us to prove some biological
properties on the behaviour of systems specified in Brane Calculi.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3430</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3430</id><created>2011-08-17</created><authors><author><keyname>Ipate</keyname><forenames>Florentin</forenames></author><author><keyname>Nicolescu</keyname><forenames>Radu</forenames></author><author><keyname>Niculescu</keyname><forenames>Ionut-Mihai</forenames></author><author><keyname>Stefan</keyname><forenames>Cristian</forenames></author></authors><title>Synchronization of P Systems with Simplex Channels</title><categories>cs.DC cs.ET cs.FL</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/07</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We solve the Firing Squad Synchronization Problem (FSSP), for P systems based
on digraphs with simplex channels, where communication is restricted by the
direction of structural arcs. Previous work on FSSP for P systems focused
exclusively on P systems with duplex channels, where communication between
parents and children is bidirectional. Our P solution, the first for simplex
channels, requires cell IDs, strongly connected digraphs and some awareness of
the local topology (such as each cell's outdegree)---we argue that these
requirements are necessary. Compared to the known solutions for cellular
automata, our solution is substantially simpler and faster.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3431</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3431</id><created>2011-08-17</created><authors><author><keyname>Raghavan</keyname><forenames>Rama</forenames></author><author><keyname>Ramesh</keyname><forenames>H.</forenames></author><author><keyname>Gheorghe</keyname><forenames>Marian</forenames></author><author><keyname>Krishna</keyname><forenames>Shankara Narayanan</forenames></author></authors><title>Further Results on Languages of Membrane Structures</title><categories>cs.DC cs.FL</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/08</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  P systems with active membranes were used to generate languages, in the sense
of languages associated with the structure of membrane systems. Here, we
analyze the power of P systems with membrane creation and dissolution
restricted to elementary membranes, P systems without membrane dissolution
operating according to certain output modes. This leads us to characterizations
of recursively enumerable languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3432</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3432</id><created>2011-08-17</created><authors><author><keyname>Spicher</keyname><forenames>Antoine</forenames></author><author><keyname>Verlan</keyname><forenames>Sergey</forenames></author></authors><title>Generalized Communicating P Systems Working in Fair Sequential Model</title><categories>cs.DC cs.ET cs.FL</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/09</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we consider a new derivation mode for generalized
communicating P systems (GCPS) corresponding to the functioning of population
protocols (PP) and based on the sequential derivation mode and a fairness
condition. We show that PP can be seen as a particular variant of GCPS. We also
consider a particular stochastic evolution satisfying the fairness condition
and obtain that it corresponds to the run of a Gillespie's SSA. This permits to
further describe the dynamics of GCPS by a system of ODEs when the population
size goes to the infinity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3433</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3433</id><created>2011-08-17</created><authors><author><keyname>Steggles</keyname><forenames>L. Jason</forenames></author></authors><title>Abstracting Asynchronous Multi-Valued Networks: An Initial Investigation</title><categories>cs.DC cs.FL</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/10</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Multi-valued networks provide a simple yet expressive qualitative state based
modelling approach for biological systems. In this paper we develop an
abstraction theory for asynchronous multi-valued network models that allows the
state space of a model to be reduced while preserving key properties of the
model. The abstraction theory therefore provides a mechanism for coping with
the state space explosion problem and supports the analysis and comparison of
multi-valued networks. We take as our starting point the abstraction theory for
synchronous multi-valued networks which is based on the finite set of traces
that represent the behaviour of such a model. The problem with extending this
approach to the asynchronous case is that we can now have an infinite set of
traces associated with a model making a simple trace inclusion test infeasible.
To address this we develop a decision procedure for checking asynchronous
abstractions based on using the finite state graph of an asynchronous
multi-valued network to reason about its trace semantics. We illustrate the
abstraction techniques developed by considering a detailed case study based on
a multi-valued network model of the regulation of tryptophan biosynthesis in
Escherichia coli.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3434</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3434</id><created>2011-08-17</created><authors><author><keyname>Buti</keyname><forenames>Federico</forenames></author><author><keyname>De Donato</keyname><forenames>Massimo Callisto</forenames></author><author><keyname>Corradini</keyname><forenames>Flavio</forenames></author><author><keyname>Merelli</keyname><forenames>Emanuela</forenames></author><author><keyname>Tesei</keyname><forenames>Luca</forenames></author></authors><title>Multiscale Modelling: A Mobile Membrane Approach</title><categories>cs.FL cs.ET q-bio.QM</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/11</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Nowadays, multiscale modelling is recognized as the most suitable way to
study biological processes. Indeed, almost every phenomenon in nature exhibits
a multiscale behaviour, i.e., it is the outcome of interactions that occur at
different spatial and temporal scales. Although several ways to provide
&quot;multilayer&quot; models have been proposed, only Complex Automata naturally embed
spatial information and realize the multiscale approach with well-established
inter-scale integration schemas. Recently, such approach has been restated in
terms of Spatial P systems - a variant of P systems with a more geometric
concept of space.
  In this work we discuss how mobile membranes, a variant of membrane systems
inspired by the biological movements of endocytosis and exocytosis, can be
efficaciously exploited to define a uniform multiscale coupling scheme relying
only on the features of the formalism itself.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3436</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3436</id><created>2011-08-17</created><authors><author><keyname>Sedlmajer</keyname><forenames>Nicolas</forenames></author><author><keyname>Buchs</keyname><forenames>Didier</forenames></author><author><keyname>Hostettler</keyname><forenames>Steve</forenames></author><author><keyname>Linard</keyname><forenames>Alban</forenames></author><author><keyname>Lopez</keyname><forenames>Edmundo</forenames></author><author><keyname>Marechal</keyname><forenames>Alexis</forenames></author></authors><title>Modelling of Genetic Regulatory Mechanisms with GReg</title><categories>cs.LO cs.CE</categories><comments>Presented at MeCBIC 2011</comments><report-no>MeCBIC/2011/12</report-no><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most available tools propose simulation frameworks to study models of
biological systems, but simulation only explores a few of the most probable
behaviours of the system. On the contrary, techniques such as model checking,
coming from IT-systems analysis, explore all the possible behaviours of the
modelled systems, thus helping to identify emergent properties. A main drawback
from most model checking tools in the life sciences domain is that they take as
input a language designed for computer scientists, that is not easily
understood by non-expert users. We propose in this article an approach based on
DSL. It provides a comprehensible language to describe the system while
allowing the use of complex and powerful underlying model checking techniques.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3446</identifier>
 <datestamp>2014-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3446</id><created>2011-08-17</created><updated>2012-04-12</updated><authors><author><keyname>Alama</keyname><forenames>Jesse</forenames></author><author><keyname>Heskes</keyname><forenames>Tom</forenames></author><author><keyname>K&#xfc;hlwein</keyname><forenames>Daniel</forenames></author><author><keyname>Tsivtsivadze</keyname><forenames>Evgeni</forenames></author><author><keyname>Urban</keyname><forenames>Josef</forenames></author></authors><title>Premise Selection for Mathematics by Corpus Analysis and Kernel Methods</title><categories>cs.LG cs.AI</categories><comments>26 pages</comments><msc-class>68T05</msc-class><acm-class>I.2.6; I.2.3</acm-class><doi>10.1007/s10817-013-9286-5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Smart premise selection is essential when using automated reasoning as a tool
for large-theory formal proof development. A good method for premise selection
in complex mathematical libraries is the application of machine learning to
large corpora of proofs. This work develops learning-based premise selection in
two ways. First, a newly available minimal dependency analysis of existing
high-level formal mathematical proofs is used to build a large knowledge base
of proof dependencies, providing precise data for ATP-based re-verification and
for training premise selection algorithms. Second, a new machine learning
algorithm for premise selection based on kernel methods is proposed and
implemented. To evaluate the impact of both techniques, a benchmark consisting
of 2078 large-theory mathematical problems is constructed,extending the older
MPTP Challenge benchmark. The combined effect of the techniques results in a
50% improvement on the benchmark over the Vampire/SInE state-of-the-art system
for automated reasoning in large theories.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3462</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3462</id><created>2011-08-17</created><authors><author><keyname>Filipiak</keyname><forenames>Patryk</forenames></author></authors><title>A Multiagent Simulation for Traffic Flow Management with Evolutionary
  Optimization</title><categories>cs.MA nlin.AO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A traffic flow is one of the main transportation issues in nowadays
industrialized agglomerations. Configuration of traffic lights is among the key
aspects in traffic flow management. This paper proposes an evolutionary
optimization tool that utilizes multiagent simulator in order to obtain
accurate model. Even though more detailed studies are still necessary, a
preliminary research gives an expectation for promising results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3476</identifier>
 <datestamp>2012-08-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3476</id><created>2011-08-17</created><updated>2011-09-02</updated><authors><author><keyname>Maurer</keyname><forenames>Andreas</forenames></author><author><keyname>Pontil</keyname><forenames>Massimiliano</forenames></author></authors><title>Structured Sparsity and Generalization</title><categories>cs.LG stat.ML</categories><journal-ref>Journal of Machine Learning Research, 13:671-690, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a data dependent generalization bound for a large class of
regularized algorithms which implement structured sparsity constraints. The
bound can be applied to standard squared-norm regularization, the Lasso, the
group Lasso, some versions of the group Lasso with overlapping groups, multiple
kernel learning and other regularization schemes. In all these cases
competitive results are obtained. A novel feature of our bound is that it can
be applied in an infinite dimensional setting such as the Lasso in a separable
Hilbert space or multiple kernel learning with a countable number of kernels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3489</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3489</id><created>2011-08-17</created><authors><author><keyname>Gao</keyname><forenames>Yifeng</forenames></author><author><keyname>Gong</keyname><forenames>Shuhong</forenames></author><author><keyname>Zhao</keyname><forenames>Ge</forenames></author></authors><title>A Novel and Robust Evolution Algorithm for Optimizing Complicated
  Functions</title><categories>cs.NE</categories><comments>4papers</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, a novel mutation operator of differential evolution algorithm
is proposed. A new algorithm called divergence differential evolution algorithm
(DDEA) is developed by combining the new mutation operator with divergence
operator and assimilation operator (divergence operator divides population,
and, assimilation operator combines population), which can detect multiple
solutions and robustness in noisy environment. The new algorithm is applied to
optimize Michalewicz Function and to track changing of rain-induced-attenuation
process. The results based on DDEA are compared with those based on
Differential Evolution Algorithm (DEA). It shows that DDEA algorithm gets
better results than DEA does in the same premise. The new algorithm is
significant for optimizing and tracking the characteristics of MIMO (Multiple
Input Multiple Output) channel at millimeter waves.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3494</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3494</id><created>2011-08-17</created><authors><author><keyname>Ambainis</keyname><forenames>Andris</forenames></author><author><keyname>Sun</keyname><forenames>Xiaoming</forenames></author></authors><title>New separation between $s(f)$ and $bs(f)$</title><categories>cs.CC</categories><comments>7 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this note we give a new separation between sensitivity and block
sensitivity of Boolean functions: $bs(f)=(2/3)s(f)^2-(1/3)s(f)$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3516</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3516</id><created>2011-08-17</created><updated>2012-06-16</updated><authors><author><keyname>Rodis</keyname><forenames>Panteleimon</forenames></author></authors><title>Model for networks of spatial objects and simulation of geographical
  phenomena propagation</title><categories>cs.DS</categories><comments>19 pages, 4 figures; theoretical substantiation corrections</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The topic of this paper is the presentation of a new network model designed
for networks consisting of spatial objects. This model allows the development
of more advance representations of systems of networked objects and the study
of geographical phenomena propagated through networks. The capabilities of the
model in simulation of geographical phenomena propagation are also studied and
relevant algorithms are presented. As examples of use, modeling of water supply
network and the simulation of traffic flow in road networks are presented.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3524</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3524</id><created>2011-08-17</created><updated>2012-06-25</updated><authors><author><keyname>Wu</keyname><forenames>Rongjun</forenames></author><author><keyname>Hong</keyname><forenames>Shaofang</forenames></author></authors><title>On deep holes of standard Reed-Solomon codes</title><categories>math.NT cs.IT math.IT</categories><comments>10 pages. To appear in SCIENCE CHINA Mathematics</comments><journal-ref>Sci. China Math. 55 (2012), 2447-2455</journal-ref><doi>10.1007/s11425-012-4499-3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Determining deep holes is an important open problem in decoding Reed-Solomon
codes. It is well known that the received word is trivially a deep hole if the
degree of its Lagrange interpolation polynomial equals the dimension of the
Reed-Solomon code. For the standard Reed-Solomon codes $[p-1, k]_p$ with $p$ a
prime, Cheng and Murray conjectured in 2007 that there is no other deep holes
except the trivial ones. In this paper, we show that this conjecture is not
true. In fact, we find a new class of deep holes for standard Reed-Solomon
codes $[q-1, k]_q$ with $q$ a prime power of $p$. Let $q \geq 4$ and $2 \leq
k\leq q-2$. We show that the received word $u$ is a deep hole if its Lagrange
interpolation polynomial is the sum of monomial of degree $q-2$ and a
polynomial of degree at most $k-1$. So there are at least $2(q-1)q^k$ deep
holes if $k \leq q-3$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3525</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3525</id><created>2011-08-17</created><authors><author><keyname>Miao</keyname><forenames>Yingjie</forenames></author><author><keyname>Corso</keyname><forenames>Jason J.</forenames></author></authors><title>Hamiltonian Streamline Guided Feature Extraction with Applications to
  Face Detection</title><categories>cs.CV math.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new feature extraction method based on two dynamical systems
induced by intensity landscape: the negative gradient system and the
Hamiltonian system. We build features based on the Hamiltonian streamlines.
These features contain nice global topological information about the intensity
landscape, and can be used for object detection. We show that for training
images of same size, our feature space is much smaller than that generated by
Haar-like features. The training time is extremely short, and detection speed
and accuracy is similar to Haar-like feature based classifiers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3529</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3529</id><created>2011-08-17</created><authors><author><keyname>Saucan</keyname><forenames>Emil</forenames></author></authors><title>Fat Triangulations and Differential Geometry</title><categories>math.DG cs.GR</categories><comments>29 pages</comments><msc-class>Primary: 53C23, 83C27, 57Q15, Secondary: 30C65, 68U05</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the differential geometric consequences of our previous result on
the existence of fat triangulations, in conjunction with a result of Cheeger,
M\&quot;{u}ller and Schrader, regarding the convergence of Lipschitz-Killing
curvatures of piecewise-flat approximations of smooth Riemannian manifolds. A
further application to the existence of quasiconformal mappings between
manifolds, as well as an extension of the triangulation result to the case of
almost Riemannian manifolds, are also given. In addition, the notion of fatness
of triangulations and its relation to metric curvature and to excess is
explored. Moreover, applications of the main results, and in particular a
purely metric approach to Regge calculus, are also investigated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3540</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3540</id><created>2011-08-17</created><authors><author><keyname>Majumdar</keyname><forenames>Rupak</forenames></author><author><keyname>Render</keyname><forenames>Elaine</forenames></author><author><keyname>Tabuada</keyname><forenames>Paulo</forenames></author></authors><title>A theory of robust software synthesis</title><categories>cs.SY cs.FL math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A key property for systems subject to uncertainty in their operating
environment is robustness, ensuring that unmodelled, but bounded, disturbances
have only a proportionally bounded effect upon the behaviours of the system.
Inspired by ideas from robust control and dissipative systems theory, we
present a formal definition of robustness and algorithmic tools for the design
of optimally robust controllers for omega-regular properties on discrete
transition systems. Formally, we define metric automata - automata equipped
with a metric on states - and strategies on metric automata which guarantee
robustness for omega-regular properties. We present fixed point algorithms to
construct optimally robust strategies in polynomial time. In contrast to
strategies computed by classical graph theoretic approaches, the strategies
computed by our algorithm ensure that the behaviours of the controlled system
gracefully degrade under the action of disturbances; the degree of degradation
is parameterized by the magnitude of the disturbance. We show an application of
our theory to the design of controllers that tolerate infinitely many transient
errors provided they occur infrequently enough.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3544</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3544</id><created>2011-08-17</created><authors><author><keyname>Ekrem</keyname><forenames>Ersen</forenames></author><author><keyname>Ulukus</keyname><forenames>Sennur</forenames></author></authors><title>Secure Lossy Transmission of Vector Gaussian Sources</title><categories>cs.IT cs.CR math.IT</categories><comments>Submitted to IEEE Transactions on Information Theory, Aug. 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the secure lossy transmission of a vector Gaussian source to a
legitimate user in the presence of an eavesdropper, where both the legitimate
user and the eavesdropper have vector Gaussian side information. The aim of the
transmitter is to describe the source to the legitimate user in a way that the
legitimate user can reconstruct the source within a certain distortion level
while the eavesdropper is kept ignorant of the source as much as possible as
measured by the equivocation. We obtain an outer bound for the rate,
equivocation and distortion region of this secure lossy transmission problem.
This outer bound is tight when the transmission rate constraint is removed. In
other words, we obtain the maximum equivocation at the eavesdropper when the
legitimate user needs to reconstruct the source within a fixed distortion level
while there is no constraint on the transmission rate. This characterization of
the maximum equivocation involves two auxiliary random variables. We show that
a non-trivial selection for both random variables may be necessary in general.
The necessity of two auxiliary random variables also implies that, in general,
Wyner-Ziv coding is suboptimal in the presence of an eavesdropper. In addition,
we show that, even when there is no rate constraint on the legitimate link,
uncoded transmission (deterministic or stochastic) is suboptimal; the presence
of an eavesdropper necessitates the use of a coded scheme to attain the maximum
equivocation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3545</identifier>
 <datestamp>2011-08-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3545</id><created>2011-08-17</created><authors><author><keyname>Tausz</keyname><forenames>Andrew</forenames></author><author><keyname>Carlsson</keyname><forenames>Gunnar</forenames></author></authors><title>Applications of Zigzag Persistence to Topological Data Analysis</title><categories>cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The theory of zigzag persistence is a substantial extension of persistent
homology, and its development has enabled the investigation of several
unexplored avenues in the area of topological data analysis. In this paper, we
discuss three applications of zigzag persistence: topological bootstrapping,
parameter thresholding, and the comparison of witness complexes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3556</identifier>
 <datestamp>2013-01-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3556</id><created>2011-08-17</created><updated>2013-01-09</updated><authors><author><keyname>Ye</keyname><forenames>Chengxi</forenames></author><author><keyname>Cannon</keyname><forenames>Charles H.</forenames></author><author><keyname>Ma</keyname><forenames>Zhanshan Sam</forenames></author><author><keyname>Yu</keyname><forenames>Douglas W.</forenames></author><author><keyname>Pop</keyname><forenames>Mihai</forenames></author></authors><title>SparseAssembler2: Sparse k-mer Graph for Memory Efficient Genome
  Assembly</title><categories>cs.DS q-bio.GN</categories><comments>Corresponding authors: Zhanshan (Sam) Ma, ma@vandals.uidaho.edu;
  Mihai Pop, mpop@umiacs.umd.edu || Availability: Programs in both Windows and
  Linux are available at: https://sites.google.com/site/sparseassembler/</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The formal version of our work has been published in BMC Bioinformatics and
can be found here: http://www.biomedcentral.com/1471-2105/13/S6/S1 Motivation:
To tackle the problem of huge memory usage associated with de Bruijn
graph-based algorithms, upon which some of the most widely used de novo genome
assemblers have been built, we released SparseAssembler1. SparseAssembler1 can
save as much as 90% memory consumption in comparison with the state-of-art
assemblers, but it requires rounds of denoising to accurately assemble genomes.
In this paper, we introduce a new general model for genome assembly that uses
only sparse k-mers. The new model replaces the idea of the de Bruijn graph from
the beginning, and achieves similar memory efficiency and much better
robustness compared with our previous SparseAssembler1. Results: We demonstrate
that the decomposition of reads of all overlapping k-mers, which is used in
existing de Bruijn graph genome assemblers, is overly cautious. We introduce a
sparse k-mer graph structure for saving sparse k-mers, which greatly reduces
memory space requirements necessary for de novo genome assembly. In contrast
with the de Bruijn graph approach, we devise a simple but powerful strategy,
i.e., finding links between the k-mers in the genome and traversing following
the links, which can be done by saving only a few k-mers. To implement the
strategy, we need to only select some k-mers that may not even be overlapping
ones, and build the links between these k-mers indicated by the reads. We can
traverse through this sparse k-mer graph to build the contigs, and ultimately
complete the genome assembly. Since the new sparse k-mers graph shares almost
all advantages of de Bruijn graph, we are able to adapt a Dijkstra-like
breadth-first search algorithm to circumvent sequencing errors and resolve
polymorphisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3558</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3558</id><created>2011-08-17</created><updated>2011-08-18</updated><authors><author><keyname>Ciobanu</keyname><forenames>Gabriel</forenames></author></authors><title>Proceedings of the 5th Workshop on Membrane Computing and Biologically
  Inspired Process Calculi (MeCBIC 2011)</title><categories>cs.DC cs.CE cs.ET cs.FL cs.LO</categories><comments>Papers presented at MeCBIC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume represents the proceedings of the 5th Workshop on Membrane
Computing and Biologically Inspired Process Calculi (MeCBIC 2011), held
together with the 12th International Conference on Membrane Computing on 23rd
August 2011 in Fontainebleau, France.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3571</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3571</id><created>2011-08-17</created><authors><author><keyname>Xiang</keyname><forenames>Yu</forenames></author><author><keyname>Kim</keyname><forenames>Young-Han</forenames></author></authors><title>Gaussian Channel with Noisy Feedback and Peak Energy Constraint</title><categories>cs.IT math.IT</categories><comments>Submitted to the IEEE Transactions on Information Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Optimal coding over the additive white Gaussian noise channel under the peak
energy constraint is studied when there is noisy feedback over an orthogonal
additive white Gaussian noise channel. As shown by Pinsker, under the peak
energy constraint, the best error exponent for communicating an M-ary message,
M &gt;= 3, with noise-free feedback is strictly larger than the one without
feedback. This paper extends Pinsker's result and shows that if the noise power
in the feedback link is sufficiently small, the best error exponent for
conmmunicating an M-ary message can be strictly larger than the one without
feedback. The proof involves two feedback coding schemes. One is motivated by a
two-stage noisy feedback coding scheme of Burnashev and Yamamoto for binary
symmetric channels, while the other is a linear noisy feedback coding scheme
that extends Pinsker's noise-free feedback coding scheme. When the feedback
noise power $\alpha$ is sufficiently small, the linear coding scheme
outperforms the two-stage (nonlinear) coding scheme, and is asymptotically
optimal as $\alpha$ tends to zero. By contrast, when $\alpha$ is relatively
larger, the two-stage coding scheme performs better.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3599</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3599</id><created>2011-08-17</created><authors><author><keyname>Zhong</keyname><forenames>Peng</forenames></author><author><keyname>Vu</keyname><forenames>Mai</forenames></author></authors><title>Decode-forward and Compute-forward Coding Schemes for the Two-Way Relay
  Channel</title><categories>cs.IT math.IT</categories><comments>To appear in Information Theory Workshop (ITW) 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the full-duplex two-way relay channel with direct link between
two users and propose two coding schemes: a partial decode-forward scheme, and
a combined decode-forward and compute-forward scheme. Both schemes use
rate-splitting and superposition coding at each user and generate codewords for
each node independently. When applied to the Gaussian channel, partial
decode-forward can strictly increase the rate region over decode-forward, which
is opposite to the one-way relay channel. The combined scheme uses
superposition coding of both Gaussian and lattice codes to allow the relay to
decode the Gaussian parts and compute the lattice parts. This scheme can also
achieve new rates and outperform both decode-forward and compute-forward
separately. These schemes are steps towards understanding the optimal coding.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3605</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3605</id><created>2011-08-17</created><updated>2012-09-15</updated><authors><author><keyname>Barbu</keyname><forenames>Adrian</forenames></author></authors><title>Hierarchical Object Parsing from Structured Noisy Point Clouds</title><categories>cs.CV</categories><comments>13 pages, 16 figures</comments><doi>10.1109/TPAMI.2012.262</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Object parsing and segmentation from point clouds are challenging tasks
because the relevant data is available only as thin structures along object
boundaries or other features, and is corrupted by large amounts of noise. To
handle this kind of data, flexible shape models are desired that can accurately
follow the object boundaries. Popular models such as Active Shape and Active
Appearance models lack the necessary flexibility for this task, while recent
approaches such as the Recursive Compositional Models make model
simplifications in order to obtain computational guarantees. This paper
investigates a hierarchical Bayesian model of shape and appearance in a
generative setting. The input data is explained by an object parsing layer,
which is a deformation of a hidden PCA shape model with Gaussian prior. The
paper also introduces a novel efficient inference algorithm that uses informed
data-driven proposals to initialize local searches for the hidden variables.
Applied to the problem of object parsing from structured point clouds such as
edge detection images, the proposed approach obtains state of the art parsing
errors on two standard datasets without using any intensity information.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3614</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3614</id><created>2011-08-17</created><authors><author><keyname>Nguyen</keyname><forenames>Phuong</forenames></author><author><keyname>Sunehag</keyname><forenames>Peter</forenames></author><author><keyname>Hutter</keyname><forenames>Marcus</forenames></author></authors><title>Feature Reinforcement Learning In Practice</title><categories>cs.AI cs.RO</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Following a recent surge in using history-based methods for resolving
perceptual aliasing in reinforcement learning, we introduce an algorithm based
on the feature reinforcement learning framework called PhiMDP. To create a
practical algorithm we devise a stochastic search procedure for a class of
context trees based on parallel tempering and a specialized proposal
distribution. We provide the first empirical evaluation for PhiMDP. Our
proposed algorithm achieves superior performance to the classical U-tree
algorithm and the recent active-LZ algorithm, and is competitive with
MC-AIXI-CTW that maintains a bayesian mixture over all context trees up to a
chosen depth.We are encouraged by our ability to compete with this
sophisticated method using an algorithm that simply picks one single model, and
uses Q-learning on the corresponding MDP. Our PhiMDP algorithm is much simpler,
yet consumes less time and memory. These results show promise for our future
work on attacking more complex and larger problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3615</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3615</id><created>2011-08-17</created><authors><author><keyname>Brlek</keyname><forenames>Sre&#x10d;ko</forenames><affiliation>LaCIM, Universit&#xe9; du Qu&#xe9;bec &#xe0; Montr&#xe9;al</affiliation></author></authors><title>Interactions between Digital Geometry and Combinatorics on Words</title><categories>cs.CG cs.FL</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 1-12</journal-ref><doi>10.4204/EPTCS.63.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We review some recent results in digital geometry obtained by using a
combinatorics on words approach to discrete geometry. Motivated on the one hand
by the well-known theory of Sturmian words which model conveniently discrete
lines in the plane, and on the other hand by the development of digital
geometry, this study reveals strong links between the two fields. Discrete
figures are identified with polyominoes encoded by words. The combinatorial
tools lead to elegant descriptions of geometrical features and efficient
algorithms. Among these, radix-trees are useful for efficiently detecting path
intersection, Lyndon and Christoffel words appear as the main tools for
describing digital convexity; equations on words allow to better understand
tilings by translations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3616</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3616</id><created>2011-08-17</created><authors><author><keyname>Frid</keyname><forenames>Anna E.</forenames><affiliation>Sobolev Institute of Mathematics</affiliation></author></authors><title>Infinite permutations vs. infinite words</title><categories>cs.FL</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 13-19</journal-ref><doi>10.4204/EPTCS.63.2</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  I am going to compare well-known properties of infinite words with those of
infinite permutations, a new object studied since middle 2000s. Basically, it
was Sergey Avgustinovich who invented this notion, although in an early study
by Davis et al. permutations appear in a very similar framework as early as in
1977. I am going to tell about periodicity of permutations, their complexity
according to several definitions and their automatic properties, that is, about
usual parameters of words, now extended to permutations and behaving sometimes
similarly to those for words, sometimes not. Another series of results concerns
permutations generated by infinite words and their properties. Although this
direction of research is young, many people, including two other speakers of
this meeting, have participated in it, and I believe that several more topics
for further study are really promising.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3617</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3617</id><created>2011-08-17</created><authors><author><keyname>Kortelainen</keyname><forenames>Juha</forenames><affiliation>Department of Information Processing Science, University of Oulu, Finland</affiliation></author></authors><title>Combinatorics on words in information security: Unavoidable regularities
  in the construction of multicollision attacks on iterated hash functions</title><categories>cs.FL</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 22-29</journal-ref><doi>10.4204/EPTCS.63.4</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Classically in combinatorics on words one studies unavoidable regularities
that appear in sufficiently long strings of symbols over a fixed size alphabet.
In this paper we take another viewpoint and focus on combinatorial properties
of long words in which the number of occurrences of any symbol is restritced by
a fixed constant. We then demonstrate the connection of these properties to
constructing multicollision attacks on so called generalized iterated hash
functions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3618</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3618</id><created>2011-08-17</created><authors><author><keyname>Rittaud</keyname><forenames>Beno&#xee;t</forenames><affiliation>Laboratoire Analyse, G&#xe9;om&#xe9;trie et Applications, Institut Galil&#xe9;e, Universit&#xe9; Paris-13</affiliation></author><author><keyname>Vivier</keyname><forenames>Laurent</forenames><affiliation>Laboratoire de Didactique Andr&#xe9; Revuz, Universit&#xe9; Paris Diderot</affiliation></author></authors><title>Circular words and applications</title><categories>cs.FL math.CO</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 31-36</journal-ref><doi>10.4204/EPTCS.63.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We define the notion of circular words, then consider on such words a
constraint derived from the Fibonacci condition. We give several results on the
structure of these circular words, then mention possible applications to
various situations: periodic expansion of numbers in numeration systems,
&quot;gcd-property&quot; of integer sequences, partition of the prefix of the fixed point
of the Fibonacci substitution, spanning trees of a wheel. Eventually, we
mention some open questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3619</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3619</id><created>2011-08-17</created><authors><author><keyname>Badkobeh</keyname><forenames>Golnaz</forenames><affiliation>King's College London</affiliation></author><author><keyname>Crochemore</keyname><forenames>Maxime</forenames><affiliation>King's College London</affiliation></author></authors><title>Finite-Repetition threshold for infinite ternary words</title><categories>cs.FL cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><acm-class>68515</acm-class><journal-ref>EPTCS 63, 2011, pp. 37-43</journal-ref><doi>10.4204/EPTCS.63.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The exponent of a word is the ratio of its length over its smallest period.
The repetitive threshold r(a) of an a-letter alphabet is the smallest rational
number for which there exists an infinite word whose finite factors have
exponent at most r(a). This notion was introduced in 1972 by Dejean who gave
the exact values of r(a) for every alphabet size a as it has been eventually
proved in 2009.
  The finite-repetition threshold for an a-letter alphabet refines the above
notion. It is the smallest rational number FRt(a) for which there exists an
infinite word whose finite factors have exponent at most FRt(a) and that
contains a finite number of factors with exponent r(a). It is known from
Shallit (2008) that FRt(2)=7/3.
  With each finite-repetition threshold is associated the smallest number of
r(a)-exponent factors that can be found in the corresponding infinite word. It
has been proved by Badkobeh and Crochemore (2010) that this number is 12 for
infinite binary words whose maximal exponent is 7/3.
  We show that FRt(3)=r(3)=7/4 and that the bound is achieved with an infinite
word containing only two 7/4-exponent words, the smallest number.
  Based on deep experiments we conjecture that FRt(4)=r(4)=7/5. The question
remains open for alphabets with more than four letters.
  Keywords: combinatorics on words, repetition, repeat, word powers, word
exponent, repetition threshold, pattern avoidability, word morphisms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3620</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3620</id><created>2011-08-17</created><authors><author><keyname>Berth&#xe9;</keyname><forenames>Val&#xe9;rie</forenames><affiliation>CNRS- Univ. Paris 7</affiliation></author><author><keyname>Labb&#xe9;</keyname><forenames>S&#xe9;bastien</forenames><affiliation>LACIM-UQAM</affiliation></author></authors><title>Uniformly balanced words with linear complexity and prescribed letter
  frequencies</title><categories>cs.FL cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><acm-class>11A55; 68R15</acm-class><journal-ref>EPTCS 63, 2011, pp. 44-52</journal-ref><doi>10.4204/EPTCS.63.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the following problem. Let us fix a finite alphabet A; for any
given d-uple of letter frequencies, how to construct an infinite word u over
the alphabet A satisfying the following conditions: u has linear complexity
function, u is uniformly balanced, the letter frequencies in u are given by the
given d-uple. This paper investigates a construction method for such words
based on the use of mixed multidimensional continued fraction algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3621</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3621</id><created>2011-08-17</created><authors><author><keyname>Bilotta</keyname><forenames>Stefano</forenames><affiliation>University of Florence</affiliation></author><author><keyname>Pergola</keyname><forenames>Elisa</forenames><affiliation>University of Florence</affiliation></author><author><keyname>Pinzani</keyname><forenames>Renzo</forenames><affiliation>University of Florence</affiliation></author></authors><title>Pattern 1^j0^i avoiding binary words</title><categories>cs.FL cs.DM math.CO</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 53-64</journal-ref><doi>10.4204/EPTCS.63.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study the enumeration and the construction, according to the
number of ones, of particular binary words avoiding a fixed pattern. The growth
of such words can be described by particular jumping and marked succession
rules. This approach enables us to obtain an algorithm which constructs all
binary words having a fixed number of ones and then kills those containing the
forbidden pattern.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3622</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3622</id><created>2011-08-17</created><authors><author><keyname>Bischoff</keyname><forenames>Bastian</forenames><affiliation>Institute for Formal Methods in Computer Science, Universit&#xe4;t Stuttgart</affiliation></author><author><keyname>Nowotka</keyname><forenames>Dirk</forenames><affiliation>Institute for Formal Methods in Computer Science, Universit&#xe4;t Stuttgart</affiliation></author></authors><title>Pattern Avoidability with Involution</title><categories>cs.FL cs.DM math.CO</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><acm-class>F.4.3; G.2.1</acm-class><journal-ref>EPTCS 63, 2011, pp. 65-70</journal-ref><doi>10.4204/EPTCS.63.10</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An infinte word w avoids a pattern p with the involution t if there is no
substitution for the variables in p and no involution t such that the resulting
word is a factor of w. We investigate the avoidance of patterns with respect to
the size of the alphabet. For example, it is shown that the pattern a t(a) a
can be avoided over three letters but not two letters, whereas it is well known
that a a a is avoidable over two letters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3623</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3623</id><created>2011-08-17</created><authors><author><keyname>Blanchet-Sadri</keyname><forenames>Francine</forenames><affiliation>University of North Carolina at Greensboro</affiliation></author><author><keyname>Chakarov</keyname><forenames>Aleksandar</forenames><affiliation>University of Colorado at Boulder</affiliation></author><author><keyname>Manuelli</keyname><forenames>Lucas</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Schwartz</keyname><forenames>Jarett</forenames><affiliation>Princeton University</affiliation></author><author><keyname>Stich</keyname><forenames>Slater</forenames><affiliation>Princeton University</affiliation></author></authors><title>Recurrent Partial Words</title><categories>cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 71-82</journal-ref><doi>10.4204/EPTCS.63.11</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Partial words are sequences over a finite alphabet that may contain wildcard
symbols, called holes, which match or are compatible with all letters; partial
words without holes are said to be full words (or simply words). Given an
infinite partial word w, the number of distinct full words over the alphabet
that are compatible with factors of w of length n, called subwords of w, refers
to a measure of complexity of infinite partial words so-called subword
complexity. This measure is of particular interest because we can construct
partial words with subword complexities not achievable by full words. In this
paper, we consider the notion of recurrence over infinite partial words, that
is, we study whether all of the finite subwords of a given infinite partial
word appear infinitely often, and we establish connections between subword
complexity and recurrence in this more general framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3624</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3624</id><created>2011-08-17</created><authors><author><keyname>Burderi</keyname><forenames>Fabio</forenames><affiliation>Dipartimento di Matematica ed Applicazioni, Universit&#xe0; Degli Studi di Palermo</affiliation></author></authors><title>Monoids and Maximal Codes</title><categories>cs.FL math.CO</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 83-92</journal-ref><doi>10.4204/EPTCS.63.12</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In recent years codes that are not Uniquely Decipherable (UD) are been
studied partitioning them in classes that localize the ambiguities of the code.
A natural question is how we can extend the notion of maximality to codes that
are not UD. In this paper we give an answer to this question. To do this we
introduce a partial order in the set of submonoids of a monoid showing the
existence, in this poset, of maximal elements that we call full monoids. Then a
set of generators of a full monoid is, by definition, a maximal code. We show
how this definition extends, in a natural way, the existing definition
concerning UD codes and we find a characteristic property of a monoid generated
by a maximal UD code.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3625</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3625</id><created>2011-08-17</created><authors><author><keyname>Cadilhac</keyname><forenames>Micha&#xeb;l</forenames><affiliation>DIRO, Universit&#xe9; de Montr&#xe9;al</affiliation></author><author><keyname>Finkel</keyname><forenames>Alain</forenames><affiliation>LSV, ENS Cachan &amp; CNRS</affiliation></author><author><keyname>McKenzie</keyname><forenames>Pierre</forenames><affiliation>DIRO, Universit&#xe9; de Montr&#xe9;al</affiliation></author></authors><title>Bounded Parikh Automata</title><categories>cs.FL</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 93-102</journal-ref><doi>10.4204/EPTCS.63.13</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Parikh finite word automaton model (PA) was introduced and studied by
Klaedtke and Ruess in 2003. Here, by means of related models, it is shown that
the bounded languages recognized by PA are the same as those recognized by
deterministic PA. Moreover, this class of languages is the class of bounded
languages whose set of iterations is semilinear.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3626</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3626</id><created>2011-08-17</created><authors><author><keyname>Reghizzi</keyname><forenames>Stefano Crespi</forenames><affiliation>Dipartimento di Elettronica e Informazione, Politecnico di Milano</affiliation></author><author><keyname>Pietro</keyname><forenames>Pierluigi San</forenames><affiliation>Dipartimento di Elettronica e Informazione, Politecnico di Milano</affiliation></author></authors><title>From Regular to Strictly Locally Testable Languages</title><categories>cs.FL</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><acm-class>F.4.3;G.2.1</acm-class><journal-ref>EPTCS 63, 2011, pp. 103-111</journal-ref><doi>10.4204/EPTCS.63.14</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A classical result (often credited to Y. Medvedev) states that every language
recognized by a finite automaton is the homomorphic image of a local language,
over a much larger so-called local alphabet, namely the alphabet of the edges
of the transition graph. Local languages are characterized by the value k=2 of
the sliding window width in the McNaughton and Papert's infinite hierarchy of
strictly locally testable languages (k-slt). We generalize Medvedev's result in
a new direction, studying the relationship between the width and the alphabetic
ratio telling how much larger the local alphabet is. We prove that every
regular language is the image of a k-slt language on an alphabet of doubled
size, where the width logarithmically depends on the automaton size, and we
exhibit regular languages for which any smaller alphabetic ratio is
insufficient. More generally, we express the trade-off between alphabetic ratio
and width as a mathematical relation derived from a careful encoding of the
states. At last we mention some directions for theoretical development and
application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3627</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3627</id><created>2011-08-17</created><authors><author><keyname>Dombek</keyname><forenames>Daniel</forenames><affiliation>FNSPE, Czech Technical University in Prague</affiliation></author></authors><title>Substitutions over infinite alphabet generating (-\beta)-integers</title><categories>cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 115-121</journal-ref><doi>10.4204/EPTCS.63.16</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This contribution is devoted to the study of positional numeration systems
with negative base introduced by Ito and Sadahiro in 2009, called
(-\beta)-expansions. We give an admissibility criterion for more general case
of (-\beta)-expansions and discuss the properties of the set of
(-\beta)-integers. We give a description of distances within this set and show
that this set can be coded by an infinite word over an infinite alphabet, which
is a fixed point of a non-erasing non-trivial morphism.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3628</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3628</id><created>2011-08-17</created><authors><author><keyname>Ferenczi</keyname><forenames>S&#xe9;bastien</forenames><affiliation>Institut de Math&#xe9;matiques de Luminy</affiliation></author></authors><title>Dynamical generalizations of the Lagrange spectrum</title><categories>cs.FL math.DS</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 122-128</journal-ref><doi>10.4204/EPTCS.63.17</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We compute two invariants of topological conjugacy, the upper and lower
limits of the inverse of Boshernitzan's ne_n, where e_n is the smallest measure
of a cylinder of length n, for three families of symbolic systems, the natural
codings of rotations and three-interval exchanges and the Arnoux-Rauzy systems.
The sets of values of these invariants for a given family of systems generalize
the Lagrange spectrum, which is what we get for the family of rotations with
the upper limit of 1/ne_n.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3629</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3629</id><created>2011-08-17</created><authors><author><keyname>Fici</keyname><forenames>Gabriele</forenames><affiliation>Laboratoire I3S, CNRS and Universit&#xe9; de Nice-Sophia Antipolis</affiliation></author></authors><title>A Classification of Trapezoidal Words</title><categories>cs.FL math.CO</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><acm-class>F.4.3</acm-class><journal-ref>EPTCS 63, 2011, pp. 129-137</journal-ref><doi>10.4204/EPTCS.63.18</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Trapezoidal words are finite words having at most n+1 distinct factors of
length n, for every n&gt;=0. They encompass finite Sturmian words. We distinguish
trapezoidal words into two disjoint subsets: open and closed trapezoidal words.
A trapezoidal word is closed if its longest repeated prefix has exactly two
occurrences in the word, the second one being a suffix of the word. Otherwise
it is open. We show that open trapezoidal words are all primitive and that
closed trapezoidal words are all Sturmian. We then show that trapezoidal
palindromes are closed (and therefore Sturmian). This allows us to characterize
the special factors of Sturmian palindromes. We end with several open problems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3630</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3630</id><created>2011-08-17</created><authors><author><keyname>Gorbunova</keyname><forenames>Irina A.</forenames><affiliation>Ural Federal University</affiliation></author><author><keyname>Shur</keyname><forenames>Arseny M.</forenames><affiliation>Ural Federal University</affiliation></author></authors><title>On Pansiot Words Avoiding 3-Repetitions</title><categories>cs.FL</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 138-146</journal-ref><doi>10.4204/EPTCS.63.19</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The recently confirmed Dejean's conjecture about the threshold between
avoidable and unavoidable powers of words gave rise to interesting and
challenging problems on the structure and growth of threshold words. Over any
finite alphabet with k &gt;= 5 letters, Pansiot words avoiding 3-repetitions form
a regular language, which is a rather small superset of the set of all
threshold words. Using cylindric and 2-dimensional words, we prove that, as k
approaches infinity, the growth rates of complexity for these regular languages
tend to the growth rate of complexity of some ternary 2-dimensional language.
The numerical estimate of this growth rate is about 1.2421.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3631</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3631</id><created>2011-08-17</created><authors><author><keyname>Halava</keyname><forenames>Vesa</forenames><affiliation>Department of Mathematics, University of Turku</affiliation></author><author><keyname>Harju</keyname><forenames>Tero</forenames><affiliation>Department of Mathematics, University of Turku</affiliation></author><author><keyname>K&#xe4;rki</keyname><forenames>Tomi</forenames><affiliation>Department of Mathematics and 2Department of Teacher Education, University of Turku</affiliation></author></authors><title>A new proof for the decidability of D0L ultimate periodicity</title><categories>cs.FL cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><acm-class>68R15</acm-class><journal-ref>EPTCS 63, 2011, pp. 147-151</journal-ref><doi>10.4204/EPTCS.63.20</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give a new proof for the decidability of the D0L ultimate periodicity
problem based on the decidability of p-periodicity of morphic words adapted to
the approach of Harju and Linna.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3632</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3632</id><created>2011-08-17</created><authors><author><keyname>Monteil</keyname><forenames>Thierry</forenames><affiliation>CNRS - Universit&#xe9; Montpellier 2</affiliation></author></authors><title>The complexity of tangent words</title><categories>cs.DM cs.CG cs.FL</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><acm-class>G.2.1;F.4.3;I.3.5,I.4.10;I.4.6</acm-class><journal-ref>EPTCS 63, 2011, pp. 152-157</journal-ref><doi>10.4204/EPTCS.63.21</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a previous paper, we described the set of words that appear in the coding
of smooth (resp. analytic) curves at arbitrary small scale. The aim of this
paper is to compute the complexity of those languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3633</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3633</id><created>2011-08-17</created><authors><author><keyname>Nevisi</keyname><forenames>Hossein</forenames><affiliation>Loughborough University</affiliation></author><author><keyname>Reidenbach</keyname><forenames>Daniel</forenames><affiliation>Loughborough University</affiliation></author></authors><title>Unambiguous 1-Uniform Morphisms</title><categories>cs.FL cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 158-167</journal-ref><doi>10.4204/EPTCS.63.22</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A morphism h is unambiguous with respect to a word w if there is no other
morphism g that maps w to the same image as h. In the present paper we study
the question of whether, for any given word, there exists an unambiguous
1-uniform morphism, i.e., a morphism that maps every letter in the word to an
image of length 1.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3634</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3634</id><created>2011-08-17</created><authors><author><keyname>Petrova</keyname><forenames>Elena A.</forenames><affiliation>Ural Federal University</affiliation></author><author><keyname>Shur</keyname><forenames>Arseny M.</forenames><affiliation>Ural Federal University</affiliation></author></authors><title>Constructing Premaximal Binary Cube-free Words of Any Level</title><categories>cs.FL</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 168-178</journal-ref><doi>10.4204/EPTCS.63.23</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the structure of the language of binary cube-free words. Namely, we
are interested in the cube-free words that cannot be infinitely extended
preserving cube-freeness. We show the existence of such words with arbitrarily
long finite extensions, both to one side and to both sides.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3635</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3635</id><created>2011-08-17</created><authors><author><keyname>Puzynina</keyname><forenames>Svetlana</forenames><affiliation>University of Turku, Finland, and Sobolev Institute of Mathematics, Novosibirsk, Russia</affiliation></author><author><keyname>Zamboni</keyname><forenames>Luca Q.</forenames><affiliation>Universite de Lyon, France, and University of Turku, Finland</affiliation></author></authors><title>Abelian returns in Sturmian words</title><categories>cs.FL cs.DM math.CO</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 179-188</journal-ref><doi>10.4204/EPTCS.63.24</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we study an abelian version of the notion of return word. Our
main result is a new characterization of Sturmian words via abelian returns.
Namely, we prove that a word is Sturmian if and only if each of its factors has
two or three abelian returns. In addition, we describe the structure of abelian
returns in Sturmian words, and discuss connections between abelian returns and
periodicity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3636</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3636</id><created>2011-08-17</created><authors><author><keyname>Roux</keyname><forenames>Mathieu</forenames><affiliation>LMNO and GREYC, CNRS and University of Caen, France</affiliation></author><author><keyname>Vall&#xe9;e</keyname><forenames>Brigitte</forenames><affiliation>GREYC, CNRS and University of Caen, France</affiliation></author></authors><title>Information theory: Sources, Dirichlet series, and realistic analyses of
  data structures</title><categories>cs.IT cs.DM cs.DS math.IT</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><acm-class>E1, E4, G3, G2.1</acm-class><journal-ref>EPTCS 63, 2011, pp. 199-214</journal-ref><doi>10.4204/EPTCS.63.26</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most of the text algorithms build data structures on words, mainly trees, as
digital trees (tries) or binary search trees (bst). The mechanism which
produces symbols of the words (one symbol at each unit time) is called a
source, in information theory contexts. The probabilistic behaviour of the
trees built on words emitted by the same source depends on two factors: the
algorithmic properties of the tree, together with the information-theoretic
properties of the source. Very often, these two factors are considered in a too
simplified way: from the algorithmic point of view, the cost of the Bst is only
measured in terms of the number of comparisons between words --from the
information theoretic point of view, only simple sources (memoryless sources or
Markov chains) are studied.
  We wish to perform here a realistic analysis, and we choose to deal together
with a general source and a realistic cost for data structures: we take into
account comparisons between symbols, and we consider a general model of source,
related to a dynamical system, which is called a dynamical source. Our methods
are close to analytic combinatorics, and our main object of interest is the
generating function of the source Lambda(s), which is here of Dirichlet type.
Such an object transforms probabilistic properties of the source into analytic
properties. The tameness of the source, which is defined through analytic
properties of Lambda(s), appears to be central in the analysis, and is
precisely studied for the class of dynamical sources. We focus here on
arithmetical conditions, of diophantine type, which are sufficient to imply
tameness on a domain with hyperbolic shape.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3637</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3637</id><created>2011-08-17</created><authors><author><keyname>Saarela</keyname><forenames>Aleksi</forenames><affiliation>Turku Centre for Computer Science TUCS and Department of Mathematics, University of Turku</affiliation></author></authors><title>Systems of Word Equations and Polynomials: a New Approach</title><categories>cs.FL</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 215-225</journal-ref><doi>10.4204/EPTCS.63.27</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We develop new polynomial methods for studying systems of word equations. We
use them to improve some earlier results and to analyze how sizes of systems of
word equations satisfying certain independence properties depend on the lengths
of the equations. These methods give the first nontrivial upper bounds for the
sizes of the systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3638</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3638</id><created>2011-08-17</created><authors><author><keyname>Samuel</keyname><forenames>Matthew J.</forenames><affiliation>Rutgers, the State University of New Jersey</affiliation></author></authors><title>Word posets, with applications to Coxeter groups</title><categories>cs.DM cs.CC</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 226-230</journal-ref><doi>10.4204/EPTCS.63.28</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We discuss the theory of certain partially ordered sets that capture the
structure of commutation classes of words in monoids. As a first application,
it follows readily that counting words in commutation classes is #P-complete.
We then apply the partially ordered sets to Coxeter groups. Some results are a
proof that enumerating the reduced words of elements of Coxeter groups is
#P-complete, a recursive formula for computing the number of commutation
classes of reduced words, as well as stronger bounds on the maximum number of
commutation classes than were previously known. This also allows us to improve
the known bounds on the number of primitive sorting networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3639</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3639</id><created>2011-08-17</created><authors><author><keyname>Sidorov</keyname><forenames>Nikita</forenames><affiliation>Manchester, UK</affiliation></author></authors><title>Optimizing Properties of Balanced Words</title><categories>cs.DM cs.CC</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 240-246</journal-ref><doi>10.4204/EPTCS.63.30</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the past few decades there has been a good deal of papers which are
concerned with optimization problems in different areas of mathematics (along
0-1 words, finite or infinite) and which yield - sometimes quite unexpectedly -
balanced words as optimal. In this note we list some key results along these
lines known to date.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3640</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3640</id><created>2011-08-17</created><authors><author><keyname>Steiner</keyname><forenames>Wolfgang</forenames><affiliation>LIAFA</affiliation></author></authors><title>On the Delone property of (-\beta)-integers</title><categories>cs.FL cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 247-256</journal-ref><doi>10.4204/EPTCS.63.31</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The (-\beta)-integers are natural generalisations of the \beta-integers, and
thus of the integers, for negative real bases. They can be described by
infinite words which are fixed points of anti-morphisms. We show that they are
not necessarily uniformly discrete and relatively dense in the real numbers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3641</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3641</id><created>2011-08-17</created><authors><author><keyname>Valyuzhenich</keyname><forenames>Alexander</forenames><affiliation>Novosibirsk State University</affiliation></author></authors><title>Permutation complexity of the fixed points of some uniform binary
  morphisms</title><categories>cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 63, 2011, pp. 257-264</journal-ref><doi>10.4204/EPTCS.63.32</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  An infinite permutation is a linear order on the set N. We study the
properties of infinite permutations generated by fixed points of some uniform
binary morphisms, and find the formula for their complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3642</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3642</id><created>2011-08-17</created><authors><author><keyname>Widmer</keyname><forenames>Steven</forenames><affiliation>University of North Texas</affiliation></author></authors><title>Permutation Complexity Related to the Letter Doubling Map</title><categories>cs.DM</categories><comments>In Proceedings WORDS 2011, arXiv:1108.3412</comments><proxy>EPTCS</proxy><acm-class>G.2.1</acm-class><journal-ref>EPTCS 63, 2011, pp. 265-276</journal-ref><doi>10.4204/EPTCS.63.33</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a countable set X (usually taken to be the natural numbers or
integers), an infinite permutation, \pi, of X is a linear ordering of X. This
paper investigates the combinatorial complexity of infinite permutations on the
natural numbers associated with the image of uniformly recurrent aperiodic
binary words under the letter doubling map. An upper bound for the complexity
is found for general words, and a formula for the complexity is established for
the Sturmian words and the Thue-Morse word.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3652</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3652</id><created>2011-08-18</created><authors><author><keyname>Cuff</keyname><forenames>Paul</forenames></author><author><keyname>Zhao</keyname><forenames>Lei</forenames></author></authors><title>Coordination using Implicit Communication</title><categories>cs.IT math.IT</categories><comments>ITW 2011, 5 pages, 1 eps figure, uses IEEEtran.cls</comments><msc-class>94A15</msc-class><acm-class>H.1.1</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We explore a basic noise-free signaling scenario where coordination and
communication are naturally merged. A random signal X_1,...,X_n is processed to
produce a control signal or action sequence A_1,...,A_n, which is observed and
further processed (without access to X_1,...,X_n) to produce a third sequence
B_1,...,B_n. The object of interest is the set of empirical joint distributions
p(x,a,b) that can be achieved in this setting. We show that H(A) &gt;= I(X;A,B) is
the necessary and sufficient condition for achieving p(x,a,b) when no causality
constraints are enforced on the encoders. We also give results for various
causality constraints.
  This setting sheds light on the embedding of digital information in analog
signals, a concept that is exploited in digital watermarking, steganography,
cooperative communication, and strategic play in team games such as bridge.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3653</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3653</id><created>2011-08-18</created><authors><author><keyname>Kelk</keyname><forenames>Steven</forenames></author><author><keyname>Scornavacca</keyname><forenames>Celine</forenames></author></authors><title>Constructing minimal phylogenetic networks from softwired clusters is
  fixed parameter tractable</title><categories>cs.CC q-bio.PE</categories><comments>Submitted</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we show that, given a set of clusters C on a set of taxa X, where |X|=n,
it is possible to determine in time f(k).poly(n) whether there exists a
level-&lt;= k network (i.e. a network where each biconnected component has
reticulation number at most k) that represents all the clusters in C in the
softwired sense, and if so to construct such a network. This extends a
polynomial time result from &quot;On the elusiveness of clusters&quot; by Kelk,
Scornavacca and Van Iersel(2011). By generalizing the concept of &quot;level-k
generator&quot; to general networks, we then extend this fixed parameter
tractability result to the problem where k refers not to the level but to the
reticulation number of the whole network.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3655</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3655</id><created>2011-08-18</created><authors><author><keyname>Brazil</keyname><forenames>M.</forenames></author><author><keyname>Ras</keyname><forenames>C. J.</forenames></author><author><keyname>Thomas</keyname><forenames>D. A.</forenames></author></authors><title>The bottleneck 2-connected $k$-Steiner network problem for $k\leq 2$</title><categories>math.CO cs.DS</categories><journal-ref>Discrete Applied Mathematics 160 (2012) 1028-1038</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The geometric bottleneck Steiner network problem on a set of vertices $X$
embedded in a normed plane requires one to construct a graph $G$ spanning $X$
and a variable set of $k\geq 0$ additional points, such that the length of the
longest edge is minimised. If no other constraints are placed on $G$ then a
solution always exists which is a tree. In this paper we consider the Euclidean
bottleneck Steiner network problem for $k\leq 2$, where $G$ is constrained to
be 2-connected. By taking advantage of relative neighbourhood graphs, Voronoi
diagrams, and the tree structure of block cut-vertex decompositions of graphs,
we produce exact algorithms of complexity $O(n^2)$ and $O(n^2\log n)$ for the
cases $k=1$ and $k=2$ respectively. Our algorithms can also be extended to
other norms such as the $L_p$ planes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3675</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3675</id><created>2011-08-18</created><authors><author><keyname>Li</keyname><forenames>Nan</forenames></author><author><keyname>Dubrova</keyname><forenames>Elena</forenames></author></authors><title>AIG Rewriting Using 5-Input Cuts</title><categories>cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Rewriting is a common approach to logic optimization based on local
transformations. Most commercially available logic synthesis tools include a
rewriting engine that may be used multiple times on the same netlist during
optimization. This paper presents an And-Inverter graph based rewriting
algorithm using 5-input cuts. The best circuits are pre-computed for a subset
of NPN classes of 5-variable functions. Cut enumeration and Boolean matching
are used to identify replacement candidates. The presented approach is expected
to complement existing rewriting approaches which are usually based on 4-input
cuts. The experimental results show that, by adding the new rewriting algorithm
to ABC synthesis tool, we can further reduce the area of heavily optimized
large circuits by 5.57% on average.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3683</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3683</id><created>2011-08-18</created><authors><author><keyname>Bille</keyname><forenames>Philip</forenames></author><author><keyname>Goertz</keyname><forenames>Inge Li</forenames></author></authors><title>Substring Range Reporting</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We revisit various string indexing problems with range reporting features,
namely, position-restricted substring searching, indexing substrings with gaps,
and indexing substrings with intervals. We obtain the following main results.
{itemize} We give efficient reductions for each of the above problems to a new
problem, which we call \emph{substring range reporting}. Hence, we unify the
previous work by showing that we may restrict our attention to a single problem
rather than studying each of the above problems individually. We show how to
solve substring range reporting with optimal query time and little space.
Combined with our reductions this leads to significantly improved time-space
trade-offs for the above problems. In particular, for each problem we obtain
the first solutions with optimal time query and $O(n\log^{O(1)} n)$ space,
where $n$ is the length of the indexed string. We show that our techniques for
substring range reporting generalize to \emph{substring range counting} and
\emph{substring range emptiness} variants. We also obtain non-trivial
time-space trade-offs for these problems. {itemize} Our bounds for substring
range reporting are based on a novel combination of suffix trees and range
reporting data structures. The reductions are simple and general and may apply
to other combinations of string indexing with range reporting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3691</identifier>
 <datestamp>2011-10-10</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3691</id><created>2011-08-18</created><authors><author><keyname>Gualdi</keyname><forenames>Stanislao</forenames></author><author><keyname>Medo</keyname><forenames>Matus</forenames></author><author><keyname>Zhang</keyname><forenames>Yi-Cheng</forenames></author></authors><title>Influence, originality and similarity in directed acyclic graphs</title><categories>physics.soc-ph cs.DL cs.SI</categories><comments>6 pages, 4 figures</comments><journal-ref>EPL 96, 18004, 2011</journal-ref><doi>10.1209/0295-5075/96/18004</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce a framework for network analysis based on random walks on
directed acyclic graphs where the probability of passing through a given node
is the key ingredient. We illustrate its use in evaluating the mutual influence
of nodes and discovering seminal papers in a citation network. We further
introduce a new similarity metric and test it in a simple personalized
recommendation process. This metric's performance is comparable to that of
classical similarity metrics, thus further supporting the validity of our
framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3702</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3702</id><created>2011-08-18</created><authors><author><keyname>Sikora</keyname><forenames>W.</forenames></author><author><keyname>Malinowski</keyname><forenames>J.</forenames></author><author><keyname>Kupczak</keyname><forenames>A.</forenames></author></authors><title>Model of skyscraper evacuation with the use of space symmetry and fluid
  dynamic approximation</title><categories>cs.MA</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The simulation of evacuation of pedestrians from skyscraper is a situation
where the symmetry analysis method and equations of fluid dynamics finds to be
very useful. When applied, they strongly reduce the number of free parameters
used in simulations and in such a way speed up the calculations and make them
easier to manage by the programmer and what is even more important, they can
give a fresh insight into a problem of evacuation and help with incorporation
of &quot;Ambient Intelligent Devices&quot; into future real buildings. We have analyzed
various, simplified, cases of evacuation from skyscraper by employing improved
&quot;Social Force Model&quot;. For each of them we obtained the average force acting on
the pedestrian as a function of the evacuation time. The results clearly show
that both methods mentioned above, can be successfully implemented in the
simulation process and return with satisfactory conclusions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3703</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3703</id><created>2011-08-18</created><authors><author><keyname>Javaid</keyname><forenames>Nadeem</forenames></author><author><keyname>Bibi</keyname><forenames>Ayesha</forenames></author><author><keyname>Javaid</keyname><forenames>Akmal</forenames></author><author><keyname>Malik</keyname><forenames>Shahzad A.</forenames></author></authors><title>Modeling Routing Overhead Generated by Wireless Reactive Routing
  Protocols</title><categories>cs.NI</categories><journal-ref>17th Asia-Pacific Conference on Communications (APCC2011)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we have modeled the routing over- head generated by three
reactive routing protocols; Ad-hoc On-demand Distance Vector (AODV), Dynamic
Source Routing (DSR) and DYnamic MANET On-deman (DYMO). Routing performed by
reactive protocols consists of two phases; route discovery and route
maintenance. Total cost paid by a protocol for efficient routing is sum of the
cost paid in the form of energy consumed and time spent. These protocols
majorly focus on the optimization performed by expanding ring search algorithm
to control the flooding generated by the mechanism of blind flooding. So, we
have modeled the energy consumed and time spent per packet both for route
discovery and route maintenance. The proposed framework is evaluated in NS-2 to
compare performance of the chosen routing protocols.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3706</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3706</id><created>2011-08-18</created><authors><author><keyname>Javaid</keyname><forenames>Nadeem</forenames></author><author><keyname>Ullah</keyname><forenames>Muti</forenames></author><author><keyname>Djouani</keyname><forenames>Karim</forenames></author></authors><title>Identifying Design Requirements for Wireless Routing Link Metrics</title><categories>cs.NI</categories><journal-ref>IEEE Globecome USA 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we identify and analyze the requirements to design a new
routing link metric for wireless multihop networks. Considering these
requirements, when a link metric is proposed, then both the design and
implementation of the link metric with a routing protocol become easy.
Secondly, the underlying network issues can easily be tackled. Thirdly, an
appreciable performance of the network is guaranteed. Along with the existing
implementation of three link metrics Expected Transmission Count (ETX), Minimum
Delay (MD), and Minimum Loss (ML), we implement inverse ETX; invETX with
Optimized Link State Routing (OLSR) using NS-2.34. The simulation results show
that how the computational burden of a metric degrades the performance of the
respective protocol and how a metric has to trade-off between different
performance parameters.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3708</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3708</id><created>2011-08-18</created><authors><author><keyname>Javaid</keyname><forenames>N.</forenames></author><author><keyname>Yousaf</keyname><forenames>M.</forenames></author><author><keyname>Ahmad</keyname><forenames>A.</forenames></author><author><keyname>Naveed</keyname><forenames>A.</forenames></author><author><keyname>Djouani</keyname><forenames>K.</forenames></author></authors><title>Evaluating Impact of Mobility on Wireless Routing Protocols</title><categories>cs.NI</categories><journal-ref>IEEE Symposium on Wireless Telecommunications Applications (ISWTA)
  2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we evaluate, analyze, and compare the impact of mobility on
the behavior of three reactive protocols (AODV, DSR, DYMO) and three proactive
protocols (DSDV, FSR, OLSR) in multi-hop wireless networks. We take into
account throughput, end-to-end delay, and normalized routing load as
performance parameters. Based upon the extensive simulation results in NS-2, we
rank all of six protocols according to the performance parameters. Besides
providing the interesting facts regarding the response of each protocol on
varying mobilities and speeds, we also study the trade-offs, the routing
protocols have to make. Such as, to achieve throughput, a protocol has to pay
some cost in the form of increased end-to-end delay or routing overhead.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3711</identifier>
 <datestamp>2012-07-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3711</id><created>2011-08-18</created><updated>2012-07-24</updated><authors><author><keyname>Tolpin</keyname><forenames>David</forenames></author><author><keyname>Shimony</keyname><forenames>Solomon Eyal</forenames></author></authors><title>Doing Better Than UCT: Rational Monte Carlo Sampling in Trees</title><categories>cs.AI</categories><comments>Withdrawn: &quot;MCTS Based on Simple Regret&quot; (arXiv:1207.5589) is the
  final corrected version published in AAAI 2012 proceedings</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  UCT, a state-of-the art algorithm for Monte Carlo tree sampling (MCTS), is
based on UCB, a sampling policy for the Multi-armed Bandit Problem (MAB) that
minimizes the accumulated regret. However, MCTS differs from MAB in that only
the final choice, rather than all arm pulls, brings a reward, that is, the
simple regret, as opposite to the cumulative regret, must be minimized. This
ongoing work aims at applying meta-reasoning techniques to MCTS, which is
non-trivial. We begin by introducing policies for multi-armed bandits with
lower simple regret than UCB, and an algorithm for MCTS which combines
cumulative and simple regret minimization and outperforms UCT. We also develop
a sampling scheme loosely based on a myopic version of perfect value of
information. Finite-time and asymptotic analysis of the policies is provided,
and the algorithms are compared empirically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3716</identifier>
 <datestamp>2011-10-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3716</id><created>2011-08-18</created><updated>2011-10-16</updated><authors><author><keyname>Kavehei</keyname><forenames>Omid</forenames></author><author><keyname>Al-Sarawi</keyname><forenames>Said</forenames></author><author><keyname>Sriram</keyname><forenames>Sharath</forenames></author><author><keyname>Bhaskaran</keyname><forenames>Madhu</forenames></author><author><keyname>Cho</keyname><forenames>Kyoung-Rok</forenames></author><author><keyname>Eshraghian</keyname><forenames>Kamran</forenames></author><author><keyname>Abbott</keyname><forenames>Derek</forenames></author></authors><title>Non-volatile Complementary Resistive Switch-based Content Addressable
  Memory</title><categories>cond-mat.mtrl-sci cs.ET</categories><comments>4 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents a novel resistive-only Binary and Ternary Content
Addressable Memory (B/TCAM) cell that consists of two Complementary Resistive
Switches (CRSs). The operation of such a cell relies on a logic$\rightarrow$ON
state transition that enables this novel CRS application.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3728</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3728</id><created>2011-08-18</created><authors><author><keyname>Li</keyname><forenames>Minyue</forenames></author><author><keyname>Klejsa</keyname><forenames>Janusz</forenames></author><author><keyname>Kleijn</keyname><forenames>W. Bastiaan</forenames></author></authors><title>On Distribution Preserving Quantization</title><categories>cs.IT math.IT</categories><comments>29 pages, 4 figures, submitted to IEEE Transactions on Information
  Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Upon compressing perceptually relevant signals, conventional quantization
generally results in unnatural outcomes at low rates. We propose distribution
preserving quantization (DPQ) to solve this problem. DPQ is a new quantization
concept that confines the probability space of the reconstruction to be
identical to that of the source. A distinctive feature of DPQ is that it
facilitates a seamless transition between signal synthesis and quantization. A
theoretical analysis of DPQ leads to a distribution preserving rate-distortion
function (DP-RDF), which serves as a lower bound on the rate of any DPQ scheme,
under a constraint on distortion. In general situations, the DP-RDF approaches
the classic rate-distortion function for the same source and distortion
measure, in the limit of an increasing rate. A practical DPQ scheme based on a
multivariate transformation is also proposed. This scheme asymptotically
achieves the DP-RDF for i.i.d. Gaussian sources and the mean squared error.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3732</identifier>
 <datestamp>2012-04-17</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3732</id><created>2011-08-18</created><updated>2012-04-15</updated><authors><author><keyname>Vo</keyname><forenames>Phuong L.</forenames></author><author><keyname>Tran</keyname><forenames>Nguyen H.</forenames></author><author><keyname>Hong</keyname><forenames>Choong Seon</forenames></author></authors><title>The Successive Approximation Approach for NUM Frameworks with Elastic
  and Inelastic Traffic</title><categories>cs.SY</categories><comments>The authors would like to withdraw the paper because we must change
  the statements Theorem 1 and Theorem 2 more correctly. We also want to change
  the structure of the paper (the NUM problems) to be more readable</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The concave utility in the Network Utility Maximization (NUM) problem is only
suitable for elastic flows. However, the networks with the multiclass traffic,
the utility of inelastic traffic is usually represented by the sigmoidal
function which is a nonconcave function. Hence, the basic NUM problem becomes a
nonconvex optimization problem. Solving the nonconvex NUM distributively is a
difficult problem. The current works utilize the standard dual-based algorithm
for the convex NUM and find the criteria for the global optimal convergence of
the algorithm. It turns out that the link capacity must higher than a certain
value to achieve the global optimum.
  We propose a new distributed algorithm that converges to the suboptimal
solution of the nonconvex NUM for all of link capacity. We approximate the
logarithm of the original problem to the convex problem which is solved
efficiently by the standard dual-base distributed algorithm. After a sequence
of approximations, the solutions converge to the KKT solution of the original
problem. In many of our experiments, it also converges to the global optimal
solution of the NUM. Moreover, we extend our work to solve the joint rate and
power NUM problem with elastic and inelastic traffic in a wireless network. Our
techniques can be applied to any log-concave utilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3736</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3736</id><created>2011-08-18</created><updated>2011-10-25</updated><authors><author><keyname>Pourmahdian</keyname><forenames>Massoud</forenames></author><author><keyname>Ali-Akbari</keyname><forenames>Mahdi</forenames></author></authors><title>Computational Models of Certain Hyperspaces of Quasi-metric Spaces</title><categories>cs.LO</categories><comments>25 pages</comments><proxy>LMCS</proxy><acm-class>F.1.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 4 (October
  26, 2011) lmcs:886</journal-ref><doi>10.2168/LMCS-7(4:1)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, for a given sequentially Yoneda-complete T_1 quasi-metric
space (X,d), the domain theoretic models of the hyperspace K_0(X) of nonempty
compact subsets of (X,d) are studied. To this end, the $\omega$-Plotkin domain
of the space of formal balls BX, denoted by CBX is considered. This domain is
given as the chain completion of the set of all finite subsets of BX with
respect to the Egli-Milner relation. Further, a map $\phi:K_0(X)\rightarrow
CBX$ is established and proved that it is an embedding whenever K_0(X) is
equipped with the Vietoris topology and respectively CBX with the Scott
topology. Moreover, if any compact subset of (X,d) is d^{-1}-precompact, \phi
is an embedding with respect to the topology of Hausdorff quasi-metric H_d on
K_0(X). Therefore, it is concluded that (CBX,\sqsubseteq,\phi) is an
$\omega$-computational model for the hyperspace K_0(X) endowed with the
Vietoris and respectively the Hausdorff topology. Next, an algebraic
sequentially Yoneda-complete quasi-metric D on CBX$ is introduced in such a way
that the specialization order $\sqsubseteq_D$ is equivalent to the usual
partial order of CBX and, furthermore, $\phi:({\cal
K}_0(X),H_d)\rightarrow({\bf C}{\bf B}X,D)$ is an isometry. This shows that
(CBX,\sqsubseteq,\phi,D) is a quantitative $\omega$-computational model for
(K_(X),H_d).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3742</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3742</id><created>2011-08-18</created><updated>2012-06-22</updated><authors><author><keyname>de Kerret</keyname><forenames>Paul</forenames></author><author><keyname>Gesbert</keyname><forenames>David</forenames></author></authors><title>Degrees of Freedom of the Network MIMO Channel With Distributed CSI</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work, we discuss the joint precoding with finite rate feedback in the
so-called network MIMO where the TXs share the knowledge of the data symbols to
be transmitted. We introduce a distributed channel state information (DCSI)
model where each TX has its own local estimate of the overall multi-user MIMO
channel and must make a precoding decision solely based on the available local
CSI. We refer to this channel as the DCSI-MIMO channel and the precoding
problem as distributed precoding. We extend to the DCSI setting the work from
Jindal for the conventional MIMO Broadcast Channel (BC) in which the number of
Degrees of Freedom (DoFs) achieved by Zero Forcing (ZF) was derived as a
function of the scaling in the logarithm of the Signal-to-Noise Ratio (SNR) of
the number of quantizing bits. Particularly, we show the seemingly pessimistic
result that the number of DoFs at each user is limited by the worst CSI across
all users and across all TXs. This is in contrast to the conventional MIMO BC
where the number of DoFs at one user is solely dependent on the quality of the
estimation of his own feedback. Consequently, we provide precoding schemes
improving on the achieved number of DoFs. For the two-user case, the derived
novel precoder achieves a number of DoFs limited by the best CSI accuracy
across the TXs instead of the worst with conventional ZF. We also advocate the
use of hierarchical quantization of the CSI, for which we show that
considerable gains are possible. Finally, we use the previous analysis to
derive the DoFs optimal allocation of the feedback bits to the various TXs
under a constraint on the size of the aggregate feedback in the network, in the
case where conventional ZF is used.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3754</identifier>
 <datestamp>2012-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3754</id><created>2011-08-18</created><updated>2012-05-25</updated><authors><author><keyname>Barbier</keyname><forenames>Morgan</forenames><affiliation>INRIA Saclay - Ile de France, LIX</affiliation></author><author><keyname>Chabot</keyname><forenames>Christophe</forenames><affiliation>LJK</affiliation></author><author><keyname>Quintin</keyname><forenames>Guillaume</forenames><affiliation>INRIA Saclay - Ile de France, LIX</affiliation></author></authors><title>On Quasi-Cyclic Codes as a Generalization of Cyclic Codes</title><categories>cs.IT math.IT</categories><comments>(18/08/2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article we see quasi-cyclic codes as block cyclic codes. We
generalize some properties of cyclic codes to quasi-cyclic ones such as
generator polynomials and ideals. Indeed we show a one-to-one correspondence
between l-quasi-cyclic codes of length m and ideals of M_l(Fq)[X]/(X^m-1). This
permits to construct new classes of codes, namely quasi-BCH and
quasi-evaluation codes. We study the parameters of such codes and propose a
decoding algorithm up to half the designed minimum distance. We even found one
new quasi-cyclic code with better parameters than known [189, 11, 125]_F4 and
48 derivated codes beating the known bounds as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3756</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3756</id><created>2011-08-18</created><authors><author><keyname>Levit</keyname><forenames>Vadim E.</forenames></author><author><keyname>Mandrescu</keyname><forenames>Eugen</forenames></author></authors><title>On the Intersection of All Critical Sets of a Unicyclic Graph</title><categories>cs.DM math.CO</categories><comments>8 pages, 5 figures</comments><msc-class>05C69, 05C38 (Primary) 05C70, 05C05(Secondary)</msc-class><acm-class>G.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A set S is independent in a graph G if no two vertices from S are adjacent.
The independence number alpha(G) is the cardinality of a maximum independent
set, while mu(G) is the size of a maximum matching in G. If alpha(G)+mu(G)=|V|,
then G=(V,E) is called a Konig-Egervary graph. The number
d_{c}(G)=max{|A|-|N(A)|} is called the critical difference of G (Zhang, 1990).
By core(G) (corona(G)) we denote the intersection (union, respectively) of all
maximum independent sets, while by ker(G) we mean the intersection of all
critical independent sets. A connected graph having only one cycle is called
unicyclic. It is known that ker(G) is a subset of core(G) for every graph G,
while the equality is true for bipartite graphs (Levit and Mandrescu, 2011).
For Konig-Egervary unicyclic graphs, the difference |core(G)|-|ker(G)| may
equal any non-negative integer. In this paper we prove that if G is a
non-Konig-Egervary unicyclic graph, then: (i) ker(G)= core(G) and (ii)
|corona(G)|+|core(G)|=2*alpha(G)+1. Pay attention that
|corona(G)|+|core(G)|=2*alpha(G) holds for every Konig-Egervary graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3757</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3757</id><created>2011-08-18</created><authors><author><keyname>Filipiak</keyname><forenames>Patryk</forenames></author></authors><title>Self-Organizing Mixture Networks for Representation of Grayscale Digital
  Images</title><categories>cs.AI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Self-Organizing Maps are commonly used for unsupervised learning purposes.
This paper is dedicated to the certain modification of SOM called SOMN
(Self-Organizing Mixture Networks) used as a mechanism for representing
grayscale digital images. Any grayscale digital image regarded as a
distribution function can be approximated by the corresponding Gaussian
mixture. In this paper, the use of SOMN is proposed in order to obtain such
approximations for input grayscale images in unsupervised manner.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3768</identifier>
 <datestamp>2015-02-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3768</id><created>2011-08-18</created><updated>2015-02-25</updated><authors><author><keyname>Ouyang</keyname><forenames>Wenzhuo</forenames></author><author><keyname>Eryilmaz</keyname><forenames>Atilla</forenames></author><author><keyname>Shroff</keyname><forenames>Ness B.</forenames></author></authors><title>Downlink Scheduling over Markovian Fading Channels</title><categories>cs.NI</categories><comments>A shorter version of this paper will appear in INFOCOM 2012, Orlando,
  FL</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the scheduling problem in downlink wireless networks with
heterogeneous, Markov-modulated, ON/OFF channels. It is well-known that the
performance of scheduling over fading channels relies heavily on the accuracy
of the available Channel State Information (CSI), which is costly to acquire.
Thus, we consider the CSI acquisition via a practical ARQ-based feedback
mechanism whereby channel states are revealed at the end of only scheduled
users' transmissions. In the assumed presence of temporally-correlated channel
evolutions, the desired scheduler must optimally balance the
exploitation-exploration trade-off, whereby it schedules transmissions both to
exploit those channels with up-to-date CSI and to explore the current state of
those with outdated CSI.
  In earlier works, Whittle's Index Policy had been suggested as a
low-complexity and high-performance solution to this problem. However,
analyzing its performance in the typical scenario of statistically
heterogeneous channel state processes has remained elusive and challenging,
mainly because of the highly-coupled and complex dynamics it possesses. In this
work, we overcome these difficulties to rigorously establish the asymptotic
optimality properties of Whittle's Index Policy in the limiting regime of many
users. More specifically: (1) we prove the local optimality of Whittle's Index
Policy, provided that the initial state of the system is within a certain
neighborhood of a carefully selected state; (2) we then establish the global
optimality of Whittle's Index Policy under a recurrence assumption that is
verified numerically for our problem. These results establish that Whittle's
Index Policy possesses analytically provable optimality characteristics for
scheduling over heterogeneous and temporally-correlated channels.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3779</identifier>
 <datestamp>2011-08-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3779</id><created>2011-08-18</created><authors><author><keyname>Hollanders</keyname><forenames>Romain</forenames></author><author><keyname>Delvenne</keyname><forenames>Jean-Charles</forenames></author><author><keyname>Jungers</keyname><forenames>Rapha&#xeb;l</forenames></author></authors><title>Policy Iteration is well suited to optimize PageRank</title><categories>cs.GT cs.DM</categories><comments>Submitted to SODA 2012 (Symposium On Discrete Algorithms, Kyoto)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The question of knowing whether the policy Iteration algorithm (PI) for
solving Markov Decision Processes (MDPs) has exponential or (strongly)
polynomial complexity has attracted much attention in the last 50 years.
Recently, Fearnley proposed an example on which PI needs an exponential number
of iterations to converge. Though, it has been observed that Fearnley's example
leaves open the possibility that PI behaves well in many particular cases, such
as in problems that involve a fixed discount factor, or that are restricted to
deterministic actions. In this paper, we analyze a large class of MDPs and we
argue that PI is efficient in that case. The problems in this class are
obtained when optimizing the PageRank of a particular node in the Markov chain.
They are motivated by several practical applications.
  We show that adding natural constraints to this PageRank Optimization problem
(PRO) makes it equivalent to the problem of optimizing the length of a
stochastic path, which is a widely studied family of MDPs. Finally, we
conjecture that PI runs in a polynomial number of iterations when applied to
PRO. We give numerical arguments as well as the proof of our conjecture in a
number of particular cases of practical importance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3780</identifier>
 <datestamp>2012-01-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3780</id><created>2011-08-18</created><updated>2012-01-12</updated><authors><author><keyname>Aggarwal</keyname><forenames>Rohit</forenames></author><author><keyname>Koksal</keyname><forenames>C. Emre</forenames></author><author><keyname>Schniter</keyname><forenames>Philip</forenames></author></authors><title>Performance Bounds and Associated Design Principles for Multi-Cellular
  Wireless OFDMA Systems (with Detailed Proofs)</title><categories>cs.IT math.IT</categories><comments>Paper to be published in IEEE INFOCOM 2012 + detailed proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we consider the downlink of large-scale multi-cellular
OFDMA-based networks and study performance bounds of the system as a function
of the number of users $K$, the number of base-stations $B$, and the number of
resource-blocks $N$. Here, a resource block is a collection of subcarriers such
that all such collections, that are disjoint have associated independently
fading channels. We derive novel upper and lower bounds on the sum-utility for
a general spatial geometry of base stations, a truncated path loss model, and a
variety of fading models (Rayleigh, Nakagami-$m$, Weibull, and LogNormal). We
also establish the associated scaling laws and show that, in the special case
of fixed number of resource blocks, a grid-based network of base stations, and
Rayleigh-fading channels, the sum information capacity of the system scales as
$\Theta(B \log\log K/B)$ for extended networks, and as $O(B \log\log K)$ and
$\Omega(\log \log K)$ for dense networks. Interpreting these results, we
develop some design principles for the service providers along with some
guidelines for the regulators in order to achieve provisioning of various QoS
guarantees for the end users and, at the same time, maximize revenue for the
service providers.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3790</identifier>
 <datestamp>2012-10-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3790</id><created>2011-08-18</created><updated>2012-10-25</updated><authors><author><keyname>Bibak</keyname><forenames>Khodakhast</forenames></author></authors><title>Additive combinatorics with a view towards computer science and
  cryptography: An exposition</title><categories>math.CO cs.CR math.NT</categories><comments>37 pages. In Proceedings of the International Number Theory
  Conference in Memory of Alf van der Poorten, to appear</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, additive combinatorics has blossomed into a vibrant area in
mathematical sciences. But it seems to be a difficult area to define - perhaps
because of a blend of ideas and techniques from several seemingly unrelated
contexts which are used there. One might say that additive combinatorics is a
branch of mathematics concerning the study of combinatorial properties of
algebraic objects, for instance, Abelian groups, rings, or fields. This
emerging field has seen tremendous advances over the last few years, and has
recently become a focus of attention among both mathematicians and computer
scientists. This fascinating area has been enriched by its formidable links to
combinatorics, number theory, harmonic analysis, ergodic theory, and some other
branches; all deeply cross-fertilize each other, holding great promise for all
of them! In this exposition, we attempt to provide an overview of some
breakthroughs in this field, together with a number of seminal applications to
sundry parts of mathematics and some other disciplines, with emphasis on
computer science and cryptography.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3832</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3832</id><created>2011-08-17</created><authors><author><keyname>Firer</keyname><forenames>Marcelo</forenames></author><author><keyname>Panek</keyname><forenames>Luciano</forenames></author><author><keyname>Rifo</keyname><forenames>Laura</forenames></author></authors><title>Coding in the Presence of Semantic Value of Information: Unequal Error
  Protection Using Poset Decoders</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this work we explore possibilities for coding when information worlds have
different (semantic) values. We introduce a loss function that expresses the
overall performance of a coding scheme for discrete channels and exchange the
usual goal of minimizing the error probability to that of minimizing the
expected loss. In this environment we explore the possibilities of using
poset-decoders to make a message-wise unequal error protection (UEP), where the
most valuable information is protected by placing in its proximity information
words that differ by small valued information. Similar definitions and results
are shortly presented also for signal constellations in Euclidean space.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3843</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3843</id><created>2011-08-18</created><authors><author><keyname>Baral</keyname><forenames>Chitta</forenames></author><author><keyname>Dzifcak</keyname><forenames>Juraj</forenames></author><author><keyname>Gonzalez</keyname><forenames>Marcos Alvarez</forenames></author><author><keyname>Zhou</keyname><forenames>Jiayu</forenames></author></authors><title>Using Inverse lambda and Generalization to Translate English to Formal
  Languages</title><categories>cs.CL</categories><journal-ref>Proceedings of International Conference on Computational Semantics
  (IWCS) 2011, Oxford, pp:35-44</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a system to translate natural language sentences to formulas in a
formal or a knowledge representation language. Our system uses two inverse
lambda-calculus operators and using them can take as input the semantic
representation of some words, phrases and sentences and from that derive the
semantic representation of other words and phrases. Our inverse lambda operator
works on many formal languages including first order logic, database query
languages and answer set programming. Our system uses a syntactic combinatorial
categorial parser to parse natural language sentences and also to construct the
semantic meaning of the sentences as directed by their parsing. The same parser
is used for both. In addition to the inverse lambda-calculus operators, our
system uses a notion of generalization to learn semantic representation of
words from the semantic representation of other words that are of the same
category. Together with this, we use an existing statistical learning approach
to assign weights to deal with multiple meanings of words. Our system produces
improved results on standard corpora on natural language interfaces for robot
command and control and database queries.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3848</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3848</id><created>2011-08-18</created><authors><author><keyname>Baral</keyname><forenames>Chitta</forenames></author><author><keyname>Dzifcak</keyname><forenames>Juraj</forenames></author></authors><title>Language understanding as a step towards human level intelligence -
  automatizing the construction of the initial dictionary from example
  sentences</title><categories>cs.CL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  For a system to understand natural language, it needs to be able to take
natural language text and answer questions given in natural language with
respect to that text; it also needs to be able to follow instructions given in
natural language. To achieve this, a system must be able to process natural
language and be able to capture the knowledge within that text. Thus it needs
to be able to translate natural language text into a formal language. We
discuss our approach to do this, where the translation is achieved by composing
the meaning of words in a sentence. Our initial approach uses an inverse lambda
method that we developed (and other methods) to learn meaning of words from
meaning of sentences and an initial lexicon. We then present an improved method
where the initial lexicon is also learned by analyzing the training sentence
and meaning pairs. We evaluate our methods and compare them with other existing
methods on a corpora of database querying and robot command and control.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3850</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3850</id><created>2011-08-18</created><authors><author><keyname>Baral</keyname><forenames>Chitta</forenames></author><author><keyname>Dzifcak</keyname><forenames>Juraj</forenames></author></authors><title>Solving puzzles described in English by automated translation to answer
  set programming and learning how to do that translation</title><categories>cs.CL cs.AI cs.LO</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a system capable of automatically solving combinatorial logic
puzzles given in (simplified) English. It involves translating the English
descriptions of the puzzles into answer set programming(ASP) and using ASP
solvers to provide solutions of the puzzles. To translate the descriptions, we
use a lambda-calculus based approach using Probabilistic Combinatorial
Categorial Grammars (PCCG) where the meanings of words are associated with
parameters to be able to distinguish between multiple meanings of the same
word. Meaning of many words and the parameters are learned. The puzzles are
represented in ASP using an ontology which is applicable to a large set of
logic puzzles.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3860</identifier>
 <datestamp>2015-07-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3860</id><created>2011-08-18</created><updated>2015-07-01</updated><authors><author><keyname>Petersen</keyname><forenames>Holger</forenames></author></authors><title>A SWAR Approach to Counting Ones</title><categories>cs.CC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the complexity of algorithms counting ones in different sets
of operations. With addition and logical operations (but no shift)
$O(\log^2(n))$ steps suffice to count ones. Parity can be computed with
complexity $O(\log(n))$, which is the same bound as for methods using
shift-operations. If multiplication is available, a solution of time complexity
$O(\log^*(n))$ is possible improving the known bound $O(\log\log(n))$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3873</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3873</id><created>2011-08-18</created><authors><author><keyname>Michalopoulos</keyname><forenames>Diomidis S.</forenames></author><author><keyname>Chatzidiamantis</keyname><forenames>Nestor D.</forenames></author><author><keyname>Schober</keyname><forenames>Robert</forenames></author><author><keyname>Karagiannidis</keyname><forenames>George K.</forenames></author></authors><title>The Diversity Potential of Relay Selection with Practical Channel
  Estimation</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We investigate the diversity order of decode-and-forward relay selection in
Nakagami-m fading, in cases where practical channel estimation techniques are
applied. In this respect, we introduce a unified model for the imperfect
channel estimates, where the effects of noise, time-varying channels, and
feedback delays are jointly considered. Based on this model, the correlation
between the actual and the estimated channel values, \rho, is expressed as a
function of the signal-to-noise ratio (SNR), yielding closed-form expressions
for the overall outage probability as a function of \rho. The resulting
diversity order and power gain reveal a high dependence of the performance of
relay selection on the high SNR behavior of \rho, thus shedding light onto the
effect of channel estimation on the overall performance. It is shown that when
the channel estimates are not frequently updated in applications involving
time-varying channels, or when the amount of power allocated for channel
estimation is not sufficiently high, the diversity potential of relay selection
is severely degraded. In short, the main contribution of this paper lies in
answering the following question: How fast should \rho tend to one, as the SNR
tends to infinity, so that relay selection does not experience any diversity
loss?
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3877</identifier>
 <datestamp>2011-10-20</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3877</id><created>2011-08-18</created><updated>2011-10-19</updated><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Guizhen</forenames></author><author><keyname>Wu</keyname><forenames>Jian-Liang</forenames></author></authors><title>Edge covering pseudo-outerplanar graphs with forests</title><categories>math.CO cs.DM</categories><comments>This paper was done in the winter of 2009 and has already been
  submitted to Discrete Mathematics for 3rd round of peer review</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is called pseudo-outerplanar if each block has an embedding on the
plane in such a way that the vertices lie on a fixed circle and the edges lie
inside the disk of this circle with each of them crossing at most one another.
In this paper, we prove that each pseudo-outerplanar graph admits edge
decompositions into a linear forest and an outerplanar graph, or a star forest
and an outerplanar graph, or two forests and a matching, or
$\max\{\Delta(G),4\}$ matchings, or $\max\{\lceil\Delta(G)/2\rceil,3\}$ linear
forests. These results generalize some ones on outerplanar graphs and
$K_{2,3}$-minor-free graphs, since the class of pseudo-outerplanar graphs is a
larger class than the one of $K_{2,3}$-minor-free graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3883</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3883</id><created>2011-08-18</created><authors><author><keyname>Han</keyname><forenames>Yunghsiang S.</forenames></author><author><keyname>Zheng</keyname><forenames>Rong</forenames></author><author><keyname>Mow</keyname><forenames>Wai Ho</forenames></author></authors><title>Exact Regenerating Codes for Byzantine Fault Tolerance in Distributed
  Storage</title><categories>cs.IT math.IT</categories><comments>Submitted to INFOCOM 2012 on 28 July 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Due to the use of commodity software and hardware, crash-stop and Byzantine
failures are likely to be more prevalent in today's large-scale distributed
storage systems. Regenerating codes have been shown to be a more efficient way
to disperse information across multiple nodes and recover crash-stop failures
in the literature. In this paper, we present the design of regeneration codes
in conjunction with integrity check that allows exact regeneration of failed
nodes and data reconstruction in presence of Byzantine failures. A progressive
decoding mechanism is incorporated in both procedures to leverage computation
performed thus far. The fault-tolerance and security properties of the schemes
are also analyzed.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3887</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3887</id><created>2011-08-18</created><authors><author><keyname>Ding</keyname><forenames>Cunsheng</forenames></author><author><keyname>Yang</keyname><forenames>Jing</forenames></author></authors><title>Hamming Weights in Irreducible Cyclic Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Irreducible cyclic codes are an interesting type of codes and have
applications in space communications. They have been studied for decades and a
lot of progress has been made. The objectives of this paper are to survey and
extend earlier results on the weight distributions of irreducible cyclic codes,
present a divisibility theorem and develop bounds on the weights in irreducible
cyclic codes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3901</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3901</id><created>2011-08-19</created><authors><author><keyname>Waltman</keyname><forenames>Ludo</forenames></author><author><keyname>van Eck</keyname><forenames>Nees Jan</forenames></author></authors><title>The inconsistency of the h-index</title><categories>cs.DL physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The h-index is a popular bibliometric indicator for assessing individual
scientists. We criticize the h-index from a theoretical point of view. We argue
that for the purpose of measuring the overall scientific impact of a scientist
(or some other unit of analysis) the h-index behaves in a counterintuitive way.
In certain cases, the mechanism used by the h-index to aggregate publication
and citation statistics into a single number leads to inconsistencies in the
way in which scientists are ranked. Our conclusion is that the h-index cannot
be considered an appropriate indicator of a scientist's overall scientific
impact. Based on recent theoretical insights, we discuss what kind of
indicators can be used as an alternative to the h-index. We pay special
attention to the highly cited publications indicator. This indicator has a lot
in common with the h-index, but unlike the h-index it does not produce
inconsistent rankings.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3915</identifier>
 <datestamp>2011-09-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3915</id><created>2011-08-19</created><updated>2011-09-21</updated><authors><author><keyname>Anh</keyname><forenames>Dinh Tien Tuan</forenames></author><author><keyname>Wenqiang</keyname><forenames>Wang</forenames></author><author><keyname>Datta</keyname><forenames>Anwitaman</forenames></author></authors><title>City on the Sky: Flexible, Secure Data Sharing on the Cloud</title><categories>cs.DB cs.NI</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Sharing data from various sources and of diverse kinds, and fusing them
together for sophisticated analytics and mash-up applications are emerging
trends, and are prerequisites for grand visions such as that of cyber-physical
systems enabled smart cities. Cloud infrastructure can enable such data sharing
both because it can scale easily to an arbitrary volume of data and computation
needs on demand, as well as because of natural collocation of diverse such data
sets within the infrastructure. However, in order to convince data owners that
their data are well protected while being shared among cloud users, the cloud
platform needs to provide flexible mechanisms for the users to express the
constraints (access rules) subject to which the data should be shared, and
likewise, enforce them effectively. We study a comprehensive set of practical
scenarios where data sharing needs to be enforced by methods such as
aggregation, windowed frame, value constrains, etc., and observe that existing
basic access control mechanisms do not provide adequate flexibility to enable
effective data sharing in a secure and controlled manner. In this paper, we
thus propose a framework for cloud that extends popular XACML model
significantly by integrating flexible access control decisions and data access
in a seamless fashion. We have prototyped the framework and deployed it on
commercial cloud environment for experimental runs to test the efficacy of our
approach and evaluate the performance of the implemented prototype.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3970</identifier>
 <datestamp>2012-08-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3970</id><created>2011-08-19</created><updated>2012-08-04</updated><authors><author><keyname>Sharma</keyname><forenames>Hrishikesh</forenames></author><author><keyname>Patkar</keyname><forenames>Sachin</forenames></author></authors><title>A Design Methodology for Folded, Pipelined Architectures in VLSI
  Applications using Projective Space Lattices</title><categories>cs.AR</categories><comments>Submitted to Elsevier Journal of Microprocessors and Microsystems:
  Embedded Hardware Design</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Semi-parallel, or folded, VLSI architectures are used whenever hardware
resources need to be saved at design time. Most recent applications that are
based on Projective Geometry (PG) based balanced bipartite graph also fall in
this category. In this paper, we provide a high-level, top-down design
methodology to design optimal semi-parallel architectures for applications,
whose Data Flow Graph (DFG) is based on PG bipartite graph. Such applications
have been found e.g. in error-control coding and matrix computations. Unlike
many other folding schemes, the topology of connections between physical
elements does not change in this methodology. Another advantage is the ease of
implementation. To lessen the throughput loss due to folding, we also
incorporate a multi-tier pipelining strategy in the design methodology. The
design methodology has been verified by implementing a synthesis tool in C++,
which has been verified as well. The tool is publicly available. Further, a
complete decoder was manually protototyped before the synthesis tool design, to
verify all the algorithms evolved in this paper, towards various steps of
refinement. Another specific high-performance design of an LDPC decoder based
on this methodology was worked out in past, and has been patented as well.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3973</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3973</id><created>2011-08-19</created><authors><author><keyname>Sha</keyname><forenames>Daohang</forenames></author><author><keyname>Patton</keyname><forenames>James L.</forenames></author><author><keyname>Mussa-Ivaldi</keyname><forenames>Ferdinando A.</forenames></author></authors><title>Implicit learning of object geometry by reducing contact forces and
  increasing smoothness</title><categories>cs.SY math.OC</categories><comments>7 pages, 5 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Moving our hands smoothly is essential to execute ordinary tasks, such as
carrying a glass of water without spilling. Past studies have revealed a
natural tendency to generate smooth trajectories when moving the hand from one
point to another in free space. Here we provide a new perspective on movement
smoothness by showing that smoothness is also enforced when the hand maintains
contact with a curved surface. Maximally smooth motions over curved surfaces
occur along geodesic lines that depend on fundamental features of the surface,
such as its radius and center of curvature. Subjects were requested to execute
movements of the hand while in contact with a virtual sphere that they could
not see. We found that with practice, subjects tended to move their hand along
smooth trajectories, near geodesic pathways joining start to end positions, to
reduce contact forces with constrained boundary, variance of contact force,
tangential velocity profile error and sum of square jerk along the time span of
movement. Furthermore, after practicing movements in a region of the sphere,
subjects executed near-geodesic movements, less contact forces, less contact
force variance, less tangential velocity profile error and less sum of square
jerk in a different region. These findings suggest that the execution of smooth
movements while the hand is in contact with a surface is a means for extracting
information about the surface's geometrical features.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.3980</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.3980</id><created>2011-08-19</created><authors><author><keyname>Clayton</keyname><forenames>H. M.</forenames></author><author><keyname>Sha</keyname><forenames>D. H.</forenames></author><author><keyname>Mullineaux</keyname><forenames>D. R.</forenames></author></authors><title>Three-dimensional Torques and Power of Horse Forelimb Joints at Trot</title><categories>cs.RO</categories><comments>18 pages, 4 figures, 15 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Reasons for Performing Study: Equine gait analysis has focused on 2D analysis
in the sagittal plane, while descriptions of 3D kinetics and ground reaction
force could provide more information on the Equine gait analysis. Hypothesis or
Objectives: The aim of this study was to characterize the 3D torques and powers
of the forelimb joints at trotting. Methods: Eight sound horses were used in
the study. A full 3D torque and power for elbow, carpus, fetlock, pastern and
coffin joints of right forelimb in horses at trot were obtained by calculating
the inverse kinetics of simplified link segmental model. Results: Over two
third of energy (70%) generated by all joints come from stance phase, and most
of energy generated was by elbow joint both in stance (77%) and sway (88%)
phases. Energy absorbed by all joints during stance (40%) and sway (60%) phases
respectively is not a big difference. During stance phase, all most two third
of energy (65%) absorbed was by fetlock joint, while over two third of energy
(74%) absorbed was by carpus joint during sway phase. Conclusions &amp; Clinical
Relevance: This study presents a full 3D kinetic analysis of the relative
motion of the humerus, radius, cannon, pastern and coffin segments of the
forelimb at the trot. The results could provide for a more sensitive measure
for kinetic analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4032</identifier>
 <datestamp>2012-10-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4032</id><created>2011-08-19</created><updated>2011-09-12</updated><authors><author><keyname>Lucyshyn-Wright</keyname><forenames>Rory B. B.</forenames></author></authors><title>Totally distributive toposes</title><categories>math.CT cs.LO math.GN</categories><comments>Now includes extended result: The lex totally distributive categories
  with a small set of generators are exactly the injective Grothendieck
  toposes; Made changes to abstract and intro to reflect the enhanced result;
  Changed formatting of diagrams</comments><journal-ref>Journal of Pure and Applied Algebra 216 (2012) 2425-2431</journal-ref><doi>10.1016/j.jpaa.2012.03.018</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A locally small category E is totally distributive (as defined by
Rosebrugh-Wood) if there exists a string of adjoint functors t -| c -| y, where
y : E --&gt; E^ is the Yoneda embedding. Saying that E is lex totally distributive
if, moreover, the left adjoint t preserves finite limits, we show that the lex
totally distributive categories with a small set of generators are exactly the
injective Grothendieck toposes, studied by Johnstone and Joyal. We characterize
the totally distributive categories with a small set of generators as exactly
the essential subtoposes of presheaf toposes, studied by Kelly-Lawvere and
Kennett-Riehl-Roy-Zaks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4034</identifier>
 <datestamp>2011-08-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4034</id><created>2011-08-19</created><authors><author><keyname>Dinh</keyname><forenames>Thang N.</forenames></author><author><keyname>Thai</keyname><forenames>My T.</forenames></author></authors><title>Finding Community Structure with Performance Guarantees in Complex
  Networks</title><categories>cs.SI cs.DS physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Many networks including social networks, computer networks, and biological
networks are found to divide naturally into communities of densely connected
individuals. Finding community structure is one of fundamental problems in
network science. Since Newman's suggestion of using \emph{modularity} as a
measure to qualify the goodness of community structures, many efficient methods
to maximize modularity have been proposed but without a guarantee of
optimality. In this paper, we propose two polynomial-time algorithms to the
modularity maximization problem with theoretical performance guarantees. The
first algorithm comes with a \emph{priori guarantee} that the modularity of
found community structure is within a constant factor of the optimal modularity
when the network has the power-law degree distribution. Despite being mainly of
theoretical interest, to our best knowledge, this is the first approximation
algorithm for finding community structure in networks. In our second algorithm,
we propose a \emph{sparse metric}, a substantially faster linear programming
method for maximizing modularity and apply a rounding technique based on this
sparse metric with a \emph{posteriori approximation guarantee}. Our experiments
show that the rounding algorithm returns the optimal solutions in most cases
and are very scalable, that is, it can run on a network of a few thousand nodes
whereas the LP solution in the literature only ran on a network of at most 235
nodes.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4035</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4035</id><created>2011-08-19</created><authors><author><keyname>Abbas</keyname><forenames>Ash Mohammad</forenames></author></authors><title>Multihop Adjustment for the Number of Nodes in Contention-Based MAC
  Protocols for Wireless Ad hoc Networks</title><categories>cs.NI</categories><comments>12 pages, 4 figures</comments><msc-class>68M10, 68M12</msc-class><acm-class>C.2.1; C.2.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The number of contending neighbors of a node in a multihop ad hoc network has
to be adjusted while analyzing the performance of the network such as computing
the end-to-end delays along a path from a given source to a destination. In
this paper, we describe a method to adjust the number of contending neighbors
of a node in a multihop wireless ad hoc network. Our method is based on the
minimum number of neighbors that has to be common between two consecutive nodes
along a path. We derive an analytical expression for the adjustment factor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4041</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4041</id><created>2011-08-19</created><updated>2011-08-22</updated><authors><author><keyname>Lemire</keyname><forenames>Daniel</forenames></author><author><keyname>Vellino</keyname><forenames>Andre</forenames></author></authors><title>Extracting, Transforming and Archiving Scientific Data</title><categories>cs.DL</categories><comments>8 pages, Fourth Workshop on Very Large Digital Libraries, 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  It is becoming common to archive research datasets that are not only large
but also numerous. In addition, their corresponding metadata and the software
required to analyse or display them need to be archived. Yet the manual
curation of research data can be difficult and expensive, particularly in very
large digital repositories, hence the importance of models and tools for
automating digital curation tasks. The automation of these tasks faces three
major challenges: (1) research data and data sources are highly heterogeneous,
(2) future research needs are difficult to anticipate, (3) data is hard to
index. To address these problems, we propose the Extract, Transform and Archive
(ETA) model for managing and mechanizing the curation of research data.
Specifically, we propose a scalable strategy for addressing the research-data
problem, ranging from the extraction of legacy data to its long-term storage.
We review some existing solutions and propose novel avenues of research.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4048</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4048</id><created>2011-08-19</created><authors><author><keyname>Wang</keyname><forenames>Timothy</forenames></author><author><keyname>Jobredeaux</keyname><forenames>Romain</forenames></author><author><keyname>Feron</keyname><forenames>E.</forenames></author></authors><title>A graphical environment to express the semantics of control systems</title><categories>cs.SY cs.PL math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present the concept of a unified graphical environment for expressing the
semantics of control systems. The graphical control system design environment
in Simulink already allows engineers to insert a variety of assertions aimed
the verification and validation of the control software. We propose extensions
to a Simulink-like environment's annotation capabilities to include formal
control system stability, performance properties and their proofs. We provide a
conceptual description of a tool, that takes in a Simulink-like diagram of the
control system as the input, and generates a graphically annotated control
system diagram as the output. The annotations can either be inserted by the
user or generated automatically by a third party control analysis software such
as IQC$\beta$ or $\mu$-tool. We finally describe how the graphical
representation of the system and its properties can be translated to annotated
programs in a programming language used in verification and validation such as
Lustre or C.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4052</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4052</id><created>2011-08-19</created><authors><author><keyname>Klyuev</keyname><forenames>Vitaly</forenames></author><author><keyname>Haralambous</keyname><forenames>Yannis</forenames></author></authors><title>Query Expansion: Term Selection using the EWC Semantic Relatedness
  Measure</title><categories>cs.CL</categories><comments>5 pages, 1 figure, accepted at ASIR'11
  &lt;http://fedcsis.org/?q=node/62&gt;</comments><journal-ref>Proceedings of 1st International Workshop on Advances in Semantic
  Information Retrieval (ASIR'11), Szczecin, Poland, September 18-21, 2011</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper investigates the efficiency of the EWC semantic relatedness
measure in an ad-hoc retrieval task. This measure combines the Wikipedia-based
Explicit Semantic Analysis measure, the WordNet path measure and the mixed
collocation index. In the experiments, the open source search engine Terrier
was utilised as a tool to index and retrieve data. The proposed technique was
tested on the NTCIR data collection. The experiments demonstrated promising
results.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4056</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4056</id><created>2011-08-19</created><authors><author><keyname>Lynch</keyname><forenames>Thomas W.</forenames></author></authors><title>More Jabber about the Collatz Conjecture and a Closed Form for Detecting
  Cycles on Special Subsequences [Assertion: Collatz cycles]</title><categories>cs.DM</categories><comments>Write me if you would like a copy of the Mathematica program I used
  to search against the constraint. There are some variations for the closed
  form on other cases, write if you would like those. This work was done while
  I was visiting at the University of the West Indies this summer. I truly
  enjoyed meeting Dr. Cadogan and studying his Collatz conjecture proofs</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Professor Cadogan at the University of the West Indies identified special
starting points that yield long subsequences where the normalization constant,
k, is always one. I studied these special sequences and found an implicit mixed
integer equation in closed form which if solved would produce seed values in
cycling subsequences. Such cycles only occur among extremely large numbers,
causing the equation to be difficult to solve numerically.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4063</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4063</id><created>2011-08-19</created><authors><author><keyname>Alresaini</keyname><forenames>Majed</forenames></author><author><keyname>Sathiamoorthy</keyname><forenames>Maheswaran</forenames></author><author><keyname>Krishnamachari</keyname><forenames>Bhaskar</forenames></author><author><keyname>Neely</keyname><forenames>Michael J.</forenames></author></authors><title>Backpressure with Adaptive Redundancy (BWAR)</title><categories>cs.NI cs.SY math.OC</categories><comments>9 pages, 4 figures, submitted to IEEE INFOCOM 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Backpressure scheduling and routing, in which packets are preferentially
transmitted over links with high queue differentials, offers the promise of
throughput-optimal operation for a wide range of communication networks.
However, when the traffic load is low, due to the corresponding low queue
occupancy, backpressure scheduling/routing experiences long delays. This is
particularly of concern in intermittent encounter-based mobile networks which
are already delay-limited due to the sparse and highly dynamic network
connectivity. While state of the art mechanisms for such networks have proposed
the use of redundant transmissions to improve delay, they do not work well when
the traffic load is high. We propose in this paper a novel hybrid approach that
we refer to as backpressure with adaptive redundancy (BWAR), which provides the
best of both worlds. This approach is highly robust and distributed and does
not require any prior knowledge of network load conditions. We evaluate BWAR
through both mathematical analysis and simulations based on cell-partitioned
model. We prove theoretically that BWAR does not perform worse than traditional
backpressure in terms of the maximum throughput, while yielding a better delay
bound. The simulations confirm that BWAR outperforms traditional backpressure
at low load, while outperforming a state of the art encounter-routing scheme
(Spray and Wait) at high load.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4076</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4076</id><created>2011-08-19</created><authors><author><keyname>He</keyname><forenames>Debiao</forenames></author></authors><title>Weakness in a Mutual Authentication Scheme for Session Initiation
  Protocol using Elliptic Curve Cryptography</title><categories>cs.CR</categories><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The session initiation protocol (SIP) is a powerful signaling protocol that
controls communication on the Internet, establishing, maintaining, and
terminating the sessions. The services that are enabled by SIP are equally
applicable in the world of mobile and ubiquitous computing. In 2009, Tsai
proposed an authenticated key agreement scheme as an enhancement to SIP. Very
recently, Arshad et al. demonstrated that Tsai's scheme was vulnerable to
offline password guessing attack and stolen-verifier attack. They also pointed
that Tsai's scheme did not provide known-key secrecy and perfect forward
secrecy. In order to overcome the weaknesses, Arshad et al. also proposed an
improved mutual authentication scheme based on elliptic curve discrete
logarithm problem for SIP and claimed that their scheme can withstand various
attacks. In this paper, we do a cryptanalysis of Arshad et al.'s scheme and
show that Arshad et al.'s scheme is vulnerable to the password guessing attack.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4077</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4077</id><created>2011-08-19</created><authors><author><keyname>Luttik</keyname><forenames>Bas</forenames><affiliation>Eindhoven University of Technology</affiliation></author><author><keyname>Valencia</keyname><forenames>Frank</forenames><affiliation>CNRS and LIX &#xc9;cole Polytechnique</affiliation></author></authors><title>Proceedings 18th International Workshop on Expressiveness in Concurrency</title><categories>cs.LO cs.FL</categories><proxy>EPTCS</proxy><acm-class>F.1.1; F.1.2; F.3.0; F.4.0</acm-class><journal-ref>EPTCS 64, 2011</journal-ref><doi>10.4204/EPTCS.64</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This volume contains the proceedings of the 18th International Workshop on
Expressiveness in Concurrency (EXPRESS 2011), which took place on 5th September
2011 in Aachen, as a satellite workshop of CONCUR 2011. The EXPRESS workshop
series aim at bringing together researchers who are interested in the
expressiveness and comparison of formal models that broadly relate to
concurrency. In particular, this also includes emergent fields such as logic
and interaction, game-theoretic models, and service-oriented computing.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4079</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4079</id><created>2011-08-19</created><authors><author><keyname>Corso</keyname><forenames>Jason J.</forenames></author></authors><title>Toward Parts-Based Scene Understanding with Pixel-Support Parts-Sparse
  Pictorial Structures</title><categories>cs.CV stat.ML</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Scene understanding remains a significant challenge in the computer vision
community. The visual psychophysics literature has demonstrated the importance
of interdependence among parts of the scene. Yet, the majority of methods in
computer vision remain local. Pictorial structures have arisen as a fundamental
parts-based model for some vision problems, such as articulated object
detection. However, the form of classical pictorial structures limits their
applicability for global problems, such as semantic pixel labeling. In this
paper, we propose an extension of the pictorial structures approach, called
pixel-support parts-sparse pictorial structures, or PS3, to overcome this
limitation. Our model extends the classical form in two ways: first, it defines
parts directly based on pixel-support rather than in a parametric form, and
second, it specifies a space of plausible parts-based scene models and permits
one to be used for inference on any given image. PS3 makes strides toward
unifying object-level and pixel-level modeling of scene elements. In this
report, we implement the first half of our model and rely upon external
knowledge to provide an initial graph structure for a given image. Our
experimental results on benchmark datasets demonstrate the capability of this
new parts-based view of scene modeling.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4080</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4080</id><created>2011-08-19</created><authors><author><keyname>Ter-Sarkisov</keyname><forenames>Aram</forenames></author><author><keyname>Marsland</keyname><forenames>Stephen</forenames></author></authors><title>Convergence Properties of Two ({\mu} + {\lambda}) Evolutionary
  Algorithms On OneMax and Royal Roads Test Functions</title><categories>cs.NE</categories><comments>accepted for ECTA 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a number of bounds on convergence time for two elitist
population-based Evolutionary Algorithms using a recombination operator
k-Bit-Swap and a mainstream Randomized Local Search algorithm. We study the
effect of distribution of elite species and population size.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4083</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4083</id><created>2011-08-19</created><updated>2011-08-24</updated><authors><author><keyname>Ter-Sarkisov</keyname><forenames>Aram</forenames></author><author><keyname>Marsland</keyname><forenames>Stephen</forenames></author></authors><title>Convergence of a Recombination-Based Elitist Evolutionary Algorithm on
  the Royal Roads Test Function</title><categories>cs.NE</categories><comments>accepted for AI 2011: 24th Australasian Joint Conference on
  Artificial Intelligence</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an analysis of the performance of an elitist Evolutionary
algorithm using a recombination operator known as 1-Bit-Swap on the Royal Roads
test function based on a population. We derive complete, approximate and
asymptotic convergence rates for the algorithm. The complete model shows the
benefit of the size of the population and re- combination pool.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4094</identifier>
 <datestamp>2011-09-02</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4094</id><created>2011-08-20</created><authors><author><keyname>Ray</keyname><forenames>Partha Pratim</forenames></author></authors><title>OSD: A Source Level Bug Localization Technique Incorporating Control
  Flow and State Information in Object Oriented Program</title><categories>cs.SE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Bug localization in object oriented program ha s always been an important
issue in softeware engineering. In this paper, I propose a source level bug
localization technique for object oriented embedded programs. My proposed
technique, presents the idea of debugging an object oriented program in class
level, incorporating the object state information into the Class Dependence
Graph (ClDG). Given a program (having buggy statement) and an input that fails
and others pass, my approach uses concrete as well as symbolic execution to
synthesize the passing inputs that marginally from the failing input in their
control flow behavior. A comparison of the execution traces of the failing
input and the passing input provides necessary clues to the root-cause of the
failure. A state trace difference, regarding the respective nodes of the ClDG
is obtained, which leads to detect the bug in the program.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4096</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4096</id><created>2011-08-20</created><authors><author><keyname>Wen</keyname><forenames>Chao-Kai</forenames></author><author><keyname>Pan</keyname><forenames>Guangming</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author><author><keyname>Guo</keyname><forenames>Mei-Hui</forenames></author><author><keyname>Chen</keyname><forenames>Jung-Chieh</forenames></author></authors><title>A Deterministic Equivalent for the Analysis of Non-Gaussian Correlated
  MIMO Multiple Access Channels</title><categories>cs.IT math.IT</categories><comments>This paper is the revision of the original manuscript titled &quot;A
  Deterministic Equivalent for the Analysis of Small Cell Networks&quot;. We have
  revised the original manuscript and reworked on the organization to improve
  the presentation as well as readability</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Large dimensional random matrix theory (RMT) has provided an efficient
analytical tool to understand multiple-input multiple-output (MIMO) channels
and to aid the design of MIMO wireless communication systems. However, previous
studies based on large dimensional RMT rely on the assumption that the transmit
correlation matrix is diagonal or the propagation channel matrix is Gaussian.
There is an increasing interest in the channels where the transmit correlation
matrices are generally nonnegative definite and the channel entries are
non-Gaussian. This class of channel models appears in several applications in
MIMO multiple access systems, such as small cell networks (SCNs). To address
these problems, we use the generalized Lindeberg principle to show that the
Stieltjes transforms of this class of random matrices with Gaussian or
non-Gaussian independent entries coincide in the large dimensional regime. This
result permits to derive the deterministic equivalents (e.g., the Stieltjes
transform and the ergodic mutual information) for non-Gaussian MIMO channels
from the known results developed for Gaussian MIMO channels, and is of great
importance in characterizing the spectral efficiency of SCNs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4098</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4098</id><created>2011-08-20</created><authors><author><keyname>Al-Wassai</keyname><forenames>Firouz Abdullah</forenames></author><author><keyname>Kalyankar</keyname><forenames>N. V.</forenames></author><author><keyname>Al-Zaky</keyname><forenames>Ali A.</forenames></author></authors><title>Multisensor Images Fusion Based on Feature-Level</title><categories>cs.CV</categories><comments>Keywords: Image fusion, Feature, Edge Fusion, Segment Fusion, IHS,
  PCA</comments><journal-ref>International Journal of Latest Technology in
  Engineering,Management &amp; Applied Science (IJLTEMAS),Vol. I, Issue V, 2012,
  124-138</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Until now, of highest relevance for remote sensing data processing and
analysis have been techniques for pixel level image fusion. So, This paper
attempts to undertake the study of Feature-Level based image fusion. For this
purpose, feature based fusion techniques, which are usually based on empirical
or heuristic rules, are employed. Hence, in this paper we consider feature
extraction (FE) for fusion. It aims at finding a transformation of the original
space that would produce such new features, which preserve or improve as much
as possible. This study introduces three different types of Image fusion
techniques including Principal Component Analysis based Feature Fusion (PCA),
Segment Fusion (SF) and Edge fusion (EF). This paper also devotes to
concentrate on the analytical techniques for evaluating the quality of image
fusion (F) by using various methods including (SD), (En), (CC), (SNR), (NRMSE)
and (DI) to estimate the quality and degree of information improvement of a
fused image quantitatively.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4100</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4100</id><created>2011-08-20</created><authors><author><keyname>Pal</keyname><forenames>Shantanu</forenames></author><author><keyname>Khatua</keyname><forenames>Sunirmal</forenames></author><author><keyname>Chaki</keyname><forenames>Nabendu</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>A New Trusted and Collaborative Agent Based Approach for Ensuring Cloud
  Security</title><categories>cs.CR</categories><comments>12 pages, 5 Figures, 1 Table</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In order to determine the user's trust is a growing concern for ensuring
privacy and security in a cloud computing environment. In cloud, user's data is
stored in one or more remote server(s) which poses more security challenges for
the system. One of the most important concerns is to protect user's sensitive
information from other users and hackers that may cause data leakage in cloud
storage. Having this security challenge in mind, this paper focuses on the
development of a more secure cloud environment, to determine the trust of the
service requesting authorities by using a novel VM (Virtual Machine) monitoring
system. Moreover, this research aims towards proposing a new trusted and
collaborative agent-based two-tier framework, titled WAY (Who Are You?), to
protect cloud resources. The framework can be used to provide security in
network, infrastructure, as well as data storage in a heterogeneous cloud
platform. If the trust updating policy is based on network activities, then the
framework can provide network security. Similarly, it provides storage security
by monitoring unauthorized access activities by the Cloud Service Users (CSU).
Infrastructure security can be provided by monitoring the use of privileged
instructions within the isolated VMs. The uniqueness of the proposed security
solution lies in the fact that it ensures security and privacy both at the
service provider level as well as at the user level in a cloud environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4114</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4114</id><created>2011-08-20</created><authors><author><keyname>Lichter</keyname><forenames>Shaun</forenames></author><author><keyname>Friesz</keyname><forenames>Terry</forenames></author><author><keyname>Griffin</keyname><forenames>Christopher</forenames></author></authors><title>Collaborative Network Formation in Spatial Oligopolies</title><categories>math.OC cs.SY</categories><comments>20 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, it has been shown that networks with an arbitrary degree sequence
may be a stable solution to a network formation game. Further, in recent years
there has been a rise in the number of firms participating in collaborative
efforts. In this paper, we show conditions under which a graph with an
arbitrary degree sequence is admitted as a stable firm collaboration graph.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4115</identifier>
 <datestamp>2012-01-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4115</id><created>2011-08-20</created><updated>2012-01-25</updated><authors><author><keyname>Lichter</keyname><forenames>Shaun</forenames></author><author><keyname>Griffin</keyname><forenames>Christopher</forenames></author><author><keyname>Friesz</keyname><forenames>Terry</forenames></author></authors><title>The Calculation and Simulation of the Price of Anarchy for Network
  Formation Games</title><categories>math.OC cs.SY</categories><comments>Submitted to the MORS Journal</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We model the formation of networks as the result of a game where by players
act selfishly to get the portfolio of links they desire most. The integration
of player strategies into the network formation model is appropriate for
organizational networks because in these smaller networks, dynamics are not
random, but the result of intentional actions carried through by players
maximizing their own objectives. This model is a better framework for the
analysis of influences upon a network because it integrates the strategies of
the players involved. We present an Integer Program that calculates the price
of anarchy of this game by finding the worst stable graph and the best
coordinated graph for this game. We simulate the formation of the network and
calculated the simulated price of anarchy, which we find tends to be rather
low.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4129</identifier>
 <datestamp>2012-06-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4129</id><created>2011-08-20</created><updated>2012-06-18</updated><authors><author><keyname>Baccelli</keyname><forenames>Fran&#xe7;ois</forenames><affiliation>INRIA Rocquencourt, LINCS</affiliation></author><author><keyname>Mathieu</keyname><forenames>Fabien</forenames><affiliation>LINCS, INRIA Rocquencourt</affiliation></author><author><keyname>Norros</keyname><forenames>Ilkka</forenames></author></authors><title>Spatial Interactions of Peers and Performance of File Sharing Systems</title><categories>cs.NI</categories><comments>No. RR-7713 (2012)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new model for peer-to-peer networking which takes the network
bottlenecks into account beyond the access. This model allows one to cope with
key features of P2P networking like degree or locality constraints or the fact
that distant peers often have a smaller rate than nearby peers. We show that
the spatial point process describing peers in their steady state then exhibits
an interesting repulsion phenomenon. We analyze two asymptotic regimes of the
peer-to-peer network: the fluid regime and the hard--core regime. We get closed
form expressions for the mean (and in some cases the law) of the peer latency
and the download rate obtained by a peer as well as for the spatial density of
peers in the steady state of each regime, as well as an accurate approximation
that holds for all regimes. The analytical results are based on a mix of
mathematical analysis and dimensional analysis and have important design
implications. The first of them is the existence of a setting where the
equilibrium mean latency is a decreasing function of the load, a phenomenon
that we call super-scalability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4133</identifier>
 <datestamp>2011-09-05</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4133</id><created>2011-08-20</created><authors><author><keyname>Kent</keyname><forenames>Robert E.</forenames></author></authors><title>The Information Flow Framework: A Descriptive Category Metatheory</title><categories>cs.NI cs.DL math.CT</categories><comments>Presented at the International Category Theory Conference (CT'04)
  July 18-24, 2004 at the University of British Columbia, Vancouver BC, Canada</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Information Flow Framework (IFF) is a descriptive category metatheory. It
is an experiment in foundations, which follows a bottom-up approach to logical
description. The IFF forms the structural aspect of the IEEE P1600.1 Standard
Upper Ontology (SUO) project. The categorical approach of the IFF provides a
principled framework for the modular design of object-level ontologies. The IFF
represents meta-logic, and as such operates at the structural level of
ontologies. In the IFF, there is a precise boundary between the metalevel and
the object level. The modular architecture of the IFF consists of metalevels,
namespaces and meta-ontologies. Each metalevel services the levels below by
providing a metalanguage used to declare and axiomatize those levels.
Corresponding to the metalevels are nested metalanguages, where each
metalanguage axiomatization includes specialization of the one immediately
above. Within each metalevel, the terminology is partitioned into namespaces,
and various namespaces are collected together into meaningful composites called
meta-ontologies. All of the various meta-ontologies in the IFF are anchored to
the IFF metastack. The IFF development is largely driven by the principles of
conceptual warrant, categorical design and institutional logic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4135</identifier>
 <datestamp>2014-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4135</id><created>2011-08-20</created><updated>2014-03-18</updated><authors><author><keyname>Baldi</keyname><forenames>Pierre</forenames></author><author><keyname>Lu</keyname><forenames>Zhiqin</forenames></author></authors><title>Complex-Valued Autoencoders</title><categories>cs.NE math.RA</categories><comments>Final version, journal ref added</comments><journal-ref>Neural Networks, 33, (2012), 136-147</journal-ref><doi>10.1016/j.neunet.2012.04.011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Autoencoders are unsupervised machine learning circuits whose learning goal
is to minimize a distortion measure between inputs and outputs. Linear
autoencoders can be defined over any field and only real-valued linear
autoencoder have been studied so far. Here we study complex-valued linear
autoencoders where the components of the training vectors and adjustable
matrices are defined over the complex field with the $L_2$ norm. We provide
simpler and more general proofs that unify the real-valued and complex-valued
cases, showing that in both cases the landscape of the error function is
invariant under certain groups of transformations. The landscape has no local
minima, a family of global minima associated with Principal Component Analysis,
and many families of saddle points associated with orthogonal projections onto
sub-space spanned by sub-optimal subsets of eigenvectors of the covariance
matrix. The theory yields several iterative, convergent, learning algorithms, a
clear understanding of the generalization properties of the trained
autoencoders, and can equally be applied to the hetero-associative case when
external targets are provided. Partial results on deep architecture as well as
the differential geometry of autoencoders are also presented. The general
framework described here is useful to classify autoencoders and identify
general common properties that ought to be investigated for each class,
illuminating some of the connections between information theory, unsupervised
learning, clustering, Hebbian learning, and autoencoders.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4138</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4138</id><created>2011-08-20</created><authors><author><keyname>Banik</keyname><forenames>Suman</forenames></author><author><keyname>Roy</keyname><forenames>Bibhash</forenames></author><author><keyname>Dey</keyname><forenames>Parthi</forenames></author><author><keyname>Chaki</keyname><forenames>Nabendu</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>QoS Routing using OLSR with Optimization for Flooding</title><categories>cs.NI</categories><comments>4 Pages, 3 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mobile Ad-hoc Network (MANET) is the self organizing collection of mobile
nodes. The communication in MANET is done via a wireless media. Ad hoc wireless
networks have massive commercial and military potential because of their
mobility support. Due to demanding real time multimedia applications, Quality
of Services (QoS) support in such infrastructure less networks have become
essential. QoS routing in mobile Ad-Hoc networks is challenging due to rapid
change in network topology. Consequently, the available state information for
routing is inherently imprecise. QoS routing may suffer badly due to several
factors including radio interference on available bandwidth, and inefficient
flooding of information to the adjacent nodes. As a result the performance of
the network degrades substantially. This paper aims at the solution for energy
efficient QoS routing by best utilization of network resources such as energy
and bandwidth. A comparative study shows that despite the overhead due to QoS
management, this solution performs better than classical OLSR protocol in terms
of QoS and efficient utilization of energy.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4139</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4139</id><created>2011-08-20</created><authors><author><keyname>Dey</keyname><forenames>Amrita</forenames></author><author><keyname>Chaki</keyname><forenames>Nabendu</forenames></author><author><keyname>Sanyal</keyname><forenames>Sugata</forenames></author></authors><title>Modeling Smart Grid using Generalized Stochastic Petri Net</title><categories>cs.OH</categories><comments>10 Pages, 10 Figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Building smart grid for power system is a major challenge for safe, automated
and energy efficient usage of electricity. The full implementation of the smart
grid will evolve over time. However, before a new set of infrastructures are
invested to build the smart grid, proper modeling and analysis is needed to
avoid wastage of resources. Modeling also helps to identify and prioritize
appropriate systems parameters. In this paper, an all comprehensive model of
smart grid have been proposed using Generalized Stochastic Petri Nets (GSPN).
The model is used to analyze the constraints and deliverables of the smart
power grid of future.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4142</identifier>
 <datestamp>2013-11-27</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4142</id><created>2011-08-20</created><updated>2013-11-26</updated><authors><author><keyname>Babaioff</keyname><forenames>Moshe</forenames></author><author><keyname>Dughmi</keyname><forenames>Shaddin</forenames></author><author><keyname>Kleinberg</keyname><forenames>Robert</forenames></author><author><keyname>Slivkins</keyname><forenames>Aleksandrs</forenames></author></authors><title>Dynamic Pricing with Limited Supply</title><categories>cs.GT cs.DS cs.LG</categories><acm-class>J.4; K.4.4; F.2.2; F.1.2</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of dynamic pricing with limited supply. A seller has
$k$ identical items for sale and is facing $n$ potential buyers (&quot;agents&quot;) that
are arriving sequentially. Each agent is interested in buying one item. Each
agent's value for an item is an IID sample from some fixed distribution with
support $[0,1]$. The seller offers a take-it-or-leave-it price to each arriving
agent (possibly different for different agents), and aims to maximize his
expected revenue.
  We focus on &quot;prior-independent&quot; mechanisms -- ones that do not use any
information about the distribution. They are desirable because knowing the
distribution is unrealistic in many practical scenarios. We study how the
revenue of such mechanisms compares to the revenue of the optimal offline
mechanism that knows the distribution (&quot;offline benchmark&quot;).
  We present a prior-independent dynamic pricing mechanism whose revenue is at
most $O((k \log n)^{2/3})$ less than the offline benchmark, for every
distribution that is regular. In fact, this guarantee holds without *any*
assumptions if the benchmark is relaxed to fixed-price mechanisms. Further, we
prove a matching lower bound. The performance guarantee for the same mechanism
can be improved to $O(\sqrt{k} \log n)$, with a distribution-dependent
constant, if $k/n$ is sufficiently small. We show that, in the worst case over
all demand distributions, this is essentially the best rate that can be
obtained with a distribution-specific constant.
  On a technical level, we exploit the connection to multi-armed bandits (MAB).
While dynamic pricing with unlimited supply can easily be seen as an MAB
problem, the intuition behind MAB approaches breaks when applied to the setting
with limited supply. Our high-level conceptual contribution is that even the
limited supply setting can be fruitfully treated as a bandit problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4152</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4152</id><created>2011-08-20</created><authors><author><keyname>Sardari</keyname><forenames>Mohsen</forenames></author><author><keyname>Beirami</keyname><forenames>Ahmad</forenames></author><author><keyname>Fekri</keyname><forenames>Faramarz</forenames></author></authors><title>On the Network-Wide Gain of Memory-Assisted Source Coding</title><categories>cs.IT math.IT</categories><comments>To appear in 2011 IEEE Information Theory Workshop (ITW 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Several studies have identified a significant amount of redundancy in the
network traffic. For example, it is demonstrated that there is a great amount
of redundancy within the content of a server over time. This redundancy can be
leveraged to reduce the network flow by the deployment of memory units in the
network. The question that arises is whether or not the deployment of memory
can result in a fundamental improvement in the performance of the network. In
this paper, we answer this question affirmatively by first establishing the
fundamental gains of memory-assisted source compression and then applying the
technique to a network. Specifically, we investigate the gain of
memory-assisted compression in random network graphs consisted of a single
source and several randomly selected memory units. We find a threshold value
for the number of memories deployed in a random graph and show that if the
number of memories exceeds the threshold we observe network-wide reduction in
the traffic.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4168</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4168</id><created>2011-08-21</created><authors><author><keyname>Wu</keyname><forenames>Xuebin</forenames></author><author><keyname>Yan</keyname><forenames>Zhiyuan</forenames></author></authors><title>Computational Complexity of Cyclotomic Fast Fourier Transforms over
  Characteristic-2 Fields</title><categories>cs.IT math.IT</categories><comments>6 pages, 4 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Cyclotomic fast Fourier transforms (CFFTs) are efficient implementations of
discrete Fourier transforms over finite fields, which have widespread
applications in cryptography and error control codes. They are of great
interest because of their low multiplicative and overall complexities. However,
their advantages are shown by inspection in the literature, and there is no
asymptotic computational complexity analysis for CFFTs. Their high additive
complexity also incurs difficulties in hardware implementations. In this paper,
we derive the bounds for the multiplicative and additive complexities of CFFTs,
respectively. Our results confirm that CFFTs have the smallest multiplicative
complexities among all known algorithms while their additive complexities
render them asymptotically suboptimal. However, CFFTs remain valuable as they
have the smallest overall complexities for most practical lengths. Our additive
complexity analysis also leads to a structured addition network, which not only
has low complexity but also is suitable for hardware implementations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4172</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4172</id><created>2011-08-21</created><authors><author><keyname>Sun</keyname><forenames>Cong</forenames></author><author><keyname>Tang</keyname><forenames>Liyong</forenames></author><author><keyname>Chen</keyname><forenames>Zhong</forenames></author></authors><title>A New Enforcement on Declassification with Reachability Analysis</title><categories>cs.CR</categories><comments>7 pages, this is a full version of the work presented on 2011 IEEE
  INFOCOM Workshops</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Language-based information flow security aims to decide whether an
action-observable program can unintentionally leak confidential information if
it has the authority to access confidential data. Recent concerns about
declassification polices have provided many choices for practical intended
information release, but more precise enforcement mechanism for these policies
is insufficiently studied. In this paper, we propose a security property on the
where-dimension of declassification and present an enforcement based on
automated verification. The approach automatically transforms the abstract
model with a variant of self-composition, and checks the reachability of
illegal-flow state of the model after transformation. The self-composition is
equipped with a store-match pattern to reduce the state space and to model the
equivalence of declassified expressions in the premise of property. The
evaluation shows that our approach is more precise than type-based enforcement.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4182</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4182</id><created>2011-08-21</created><authors><author><keyname>Kavehei</keyname><forenames>Omid</forenames></author><author><keyname>Al-Sarawi</keyname><forenames>Said</forenames></author><author><keyname>Cho</keyname><forenames>Kyoung-Rok</forenames></author><author><keyname>Iannella</keyname><forenames>Nicolangelo</forenames></author><author><keyname>Kim</keyname><forenames>Sung-Jin</forenames></author><author><keyname>Eshraghian</keyname><forenames>Kamran</forenames></author><author><keyname>Abbott</keyname><forenames>Derek</forenames></author></authors><title>Memristor-based Synaptic Networks and Logical Operations Using In-Situ
  Computing</title><categories>cond-mat.mtrl-sci cs.ET</categories><comments>18 pages, 7 figures, 2 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present new computational building blocks based on memristive devices.
These blocks, can be used to implement either supervised or unsupervised
learning modules. This is achieved using a crosspoint architecture which is an
efficient array implementation for nanoscale two-terminal memristive devices.
Based on these blocks and an experimentally verified SPICE macromodel for the
memristor, we demonstrate that firstly, the Spike-Timing-Dependent Plasticity
(STDP) can be implemented by a single memristor device and secondly, a
memristor-based competitive Hebbian learning through STDP using a $1\times
1000$ synaptic network. This is achieved by adjusting the memristor's
conductance values (weights) as a function of the timing difference between
presynaptic and postsynaptic spikes. These implementations have a number of
shortcomings due to the memristor's characteristics such as memory decay,
highly nonlinear switching behaviour as a function of applied voltage/current,
and functional uniformity. These shortcomings can be addressed by utilising a
mixed gates that can be used in conjunction with the analogue behaviour for
biomimetic computation. The digital implementations in this paper use in-situ
computational capability of the memristor.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4191</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4191</id><created>2011-08-21</created><authors><author><keyname>Feintuch</keyname><forenames>Avraham</forenames></author><author><keyname>Francis</keyname><forenames>Bruce</forenames></author></authors><title>Chains of Kinematic Points</title><categories>math.OC cs.SY</categories><comments>Provisionally accepted in Automatica</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In formulating the stability problem for an infinite chain of cars, state
space is traditionally taken to be the Hilbert space $\ell^2$, wherein the
displacements of cars from their equilibria, or the velocities from their
equilibria, are taken to be square summable. But this obliges the displacements
or velocity perturbations of cars that are far down the chain to be vanishingly
small and leads to anomalous behaviour. In this paper an alternative
formulation is proposed wherein state space is the Banach space $\ell^\infty$,
allowing the displacements or velocity perturbations of cars from their
equilibria to be merely bounded.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4199</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4199</id><created>2011-08-21</created><authors><author><keyname>Dessalles</keyname><forenames>Jean-Louis</forenames><affiliation>INFRES, LTCI</affiliation></author></authors><title>Biomimetic use of genetic algorithms</title><categories>cs.AI cs.NE q-bio.PE</categories><comments>jld-92062501; Proceedings of the Conference on Parallel Problem
  Solving from Nature, Amsterdam : Belgium (1992)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Genetic algorithms are considered as an original way to solve problems,
probably because of their generality and of their &quot;blind&quot; nature. But GAs are
also unusual since the features of many implementations (among all that could
be thought of) are principally led by the biological metaphor, while efficiency
measurements intervene only afterwards. We propose here to examine the
relevance of these biomimetic aspects, by pointing out some fundamental
similarities and divergences between GAs and the genome of living beings shaped
by natural selection. One of the main differences comes from the fact that GAs
rely principally on the so-called implicit parallelism, while giving to the
mutation/selection mechanism the second role. Such differences could suggest
new ways of employing GAs on complex problems, using complex codings and
starting from nearly homogeneous populations.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4216</identifier>
 <datestamp>2013-01-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4216</id><created>2011-08-21</created><updated>2012-04-08</updated><authors><author><keyname>De Persis</keyname><forenames>Claudio</forenames></author><author><keyname>Jayawardhana</keyname><forenames>Bayu</forenames></author></authors><title>Coordination of passive systems under quantized measurements</title><categories>math.OC cs.SY</categories><comments>40 pages, 1 figure, submitted to journal, second round of review</comments><journal-ref>SIAM Journal on Control and Optimization, 2012</journal-ref><doi>10.1137/110844994</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper we investigate a passivity approach to collective coordination
and synchronization problems in the presence of quantized measurements and show
that coordination tasks can be achieved in a practical sense for a large class
of passive systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4217</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4217</id><created>2011-08-21</created><authors><author><keyname>Kawahara</keyname><forenames>Yoshinobu</forenames></author><author><keyname>Washio</keyname><forenames>Takashi</forenames></author></authors><title>Prismatic Algorithm for Discrete D.C. Programming Problems</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we propose the first exact algorithm for minimizing the
difference of two submodular functions (D.S.), i.e., the discrete version of
the D.C. programming problem. The developed algorithm is a
branch-and-bound-based algorithm which responds to the structure of this
problem through the relationship between submodularity and convexity. The D.S.
programming problem covers a broad range of applications in machine learning
because this generalizes the optimization of a wide class of set functions. We
empirically investigate the performance of our algorithm, and illustrate the
difference between exact and approximate solutions respectively obtained by the
proposed and existing algorithms in feature selection and discriminative
structure learning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4220</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4220</id><created>2011-08-21</created><authors><author><keyname>Wolf</keyname><forenames>Thomas</forenames></author></authors><title>A Dynamical Systems Approach for Static Evaluation in Go</title><categories>cs.AI math.DS</categories><comments>IEEE Transactions on Computational Intelligence and AI in Games, vol
  3 (2011), no 2</comments><msc-class>37N99</msc-class><acm-class>I.2.1</acm-class><doi>10.1109/TCIAIG.2011.2141669</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the paper arguments are given why the concept of static evaluation has the
potential to be a useful extension to Monte Carlo tree search. A new concept of
modeling static evaluation through a dynamical system is introduced and
strengths and weaknesses are discussed. The general suitability of this
approach is demonstrated.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4224</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4224</id><created>2011-08-21</created><updated>2011-08-22</updated><authors><author><keyname>Norton</keyname><forenames>Graham H.</forenames></author></authors><title>On Sequences with a Perfect Linear Complexity Profile</title><categories>cs.IT math.IT</categories><comments>19 pages, 3 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive B\'ezout identities for the minimal polynomials of a finite
sequence and use them to prove a theorem of Wang and Massey on binary sequences
with a perfect linear complexity profile. We give a new proof of Rueppel's
conjecture and simplify Dai's original proof. We obtain short proofs of results
of Niederreiter relating the linear complexity of a sequence s and K(s), which
was defined using continued fractions. We give an upper bound for the sum of
the linear complexities of any sequence. This bound is tight for sequences with
a perfect linear complexity profile and we apply it to characterise these
sequences in two new ways.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4226</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4226</id><created>2011-08-21</created><authors><author><keyname>Mao</keyname><forenames>Guoqiang</forenames></author></authors><title>Research on Wireless Multi-hop Networks: Current State and Challenges</title><categories>cs.NI cs.IT math.IT</categories><comments>invited position paper to International Conference on Computing,
  Networking and Communications, Hawaii, USA, 2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Wireless multi-hop networks, in various forms and under various names, are
being increasingly used in military and civilian applications. Studying
connectivity and capacity of these networks is an important problem. The
scaling behavior of connectivity and capacity when the network becomes
sufficiently large is of particular interest. In this position paper, we
briefly overview recent development and discuss research challenges and
opportunities in the area, with a focus on the network connectivity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4244</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4244</id><created>2011-08-22</created><authors><author><keyname>Xiang</keyname><forenames>Ju</forenames></author><author><keyname>Hu</keyname><forenames>Ke</forenames></author></authors><title>Limitation of multi-resolution methods in community detection</title><categories>physics.soc-ph cs.SI</categories><comments>10 pages, 4 figures</comments><doi>10.1016/j.physa.2012.05.006</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Recently, a type of multi-resolution methods in community detection was
introduced, which can adjust the resolution of modularity by modifying the
modularity function with tunable resolution parameters, such as those proposed
by Arenas, Fernandez and Gomez and by Reichardt and Bornholdt. In this paper,
we show that these methods still have the intrinsic limitation-large
communities may have been split before small communities become visible-because
it is at the cost of the community stability that the enhancement of the
modularity resolution is obtained. The theoretical results indicated that the
limitation depends on the degree of interconnectedness of small communities and
the difference between the sizes of small communities and of large communities,
while independent of the size of the whole network. These findings have been
confirmed in several example networks, where communities even are
full-completed sub-graphs.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4250</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4250</id><created>2011-08-22</created><authors><author><keyname>Ravonimanantsoa</keyname><forenames>Ndaohialy Manda-Vy</forenames><affiliation>LISTA</affiliation></author><author><keyname>Randriamitantsoa</keyname><forenames>Paul Auguste Rpa</forenames><affiliation>LISTA</affiliation></author></authors><title>Comparison Of The Consumption Of Resources Between HTTP And SIP</title><categories>cs.NI</categories><comments>4pages</comments><proxy>ccsd</proxy><journal-ref>Advanced Engineering Forum 1 (2011) 330</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Currently, the development of research around VoIP experience a tremendous
growth. In the community of open source Asterisk represents a reliable
alternative for a lower cost solution. In this same community as the SIP
protocol is a supplement to the more asterisk PBX. to share the benefits
claimed by proponents of free software co-existence with other Asterisk server
is not yet proven. In this context this paper we show a comparison of the use
of simplified resource material for the apache server using the HTTP protocol
and server that uses the asterisk SIP.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4253</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4253</id><created>2011-08-22</created><authors><author><keyname>Braibant</keyname><forenames>Thomas</forenames><affiliation>LIG</affiliation></author></authors><title>Coquet: a Coq library for verifying hardware</title><categories>cs.LO</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We propose a new library to model and verify hardware circuits in the Coq
proof assistant. This library allows one to easily build circuits by following
the usual pen-and-paper diagrams. We define a deep-embedding: we use a
(dependently typed) data-type that models the architecture of circuits, and a
meaning function. We propose tactics that ease the reasoning about the behavior
of the circuits, and we demonstrate that our approach is practicable by proving
the correctness of various circuits: a text-book divide and conquer adder of
parametric size, some higher-order combinators of circuits, and some sequential
circuits: a buffer, and a register.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4257</identifier>
 <datestamp>2014-10-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4257</id><created>2011-08-22</created><updated>2014-02-26</updated><authors><author><keyname>Yang</keyname><forenames>Shenghao</forenames></author><author><keyname>Ho</keyname><forenames>Siu-Wai</forenames></author><author><keyname>Meng</keyname><forenames>Jin</forenames></author><author><keyname>Yeung</keyname><forenames>En-hui</forenames></author></authors><title>Capacity Analysis of Linear Operator Channels over Finite Fields</title><categories>cs.IT math.IT</categories><comments>To appear in IEEE Transactions on Information Theory</comments><journal-ref>Information Theory, IEEE Transactions on , vol.60, no.8,
  pp.4880-4901, Aug. 2014</journal-ref><doi>10.1109/TIT.2013.2262454</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Motivated by communication through a network employing linear network coding,
capacities of linear operator channels (LOCs) with arbitrarily distributed
transfer matrices over finite fields are studied. Both the Shannon capacity $C$
and the subspace coding capacity $C_{\text{SS}}$ are analyzed. By establishing
and comparing lower bounds on $C$ and upper bounds on $C_{\text{SS}}$, various
necessary conditions and sufficient conditions such that $C=C_{\text{SS}}$ are
obtained. A new class of LOCs such that $C=C_{\text{SS}}$ is identified, which
includes LOCs with uniform-given-rank transfer matrices as special cases. It is
also demonstrated that $C_{\text{SS}}$ is strictly less than $C$ for a broad
class of LOCs. In general, an optimal subspace coding scheme is difficult to
find because it requires to solve the maximization of a non-concave function.
However, for a LOC with a unique subspace degradation, $C_{\text{SS}}$ can be
obtained by solving a convex optimization problem over rank distribution.
Classes of LOCs with a unique subspace degradation are characterized. Since
LOCs with uniform-given-rank transfer matrices have unique subspace
degradations, some existing results on LOCs with uniform-given-rank transfer
matrices are explained from a more general way.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4272</identifier>
 <datestamp>2014-04-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4272</id><created>2011-08-22</created><updated>2014-04-29</updated><authors><author><keyname>Bonifas</keyname><forenames>Nicolas</forenames></author><author><keyname>Di Summa</keyname><forenames>Marco</forenames></author><author><keyname>Eisenbrand</keyname><forenames>Friedrich</forenames></author><author><keyname>H&#xe4;hnle</keyname><forenames>Nicolai</forenames></author><author><keyname>Niemeier</keyname><forenames>Martin</forenames></author></authors><title>On sub-determinants and the diameter of polyhedra</title><categories>math.CO cs.CG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive a new upper bound on the diameter of a polyhedron P = {x \in R^n :
Ax &lt;= b}, where A \in Z^{m\timesn}. The bound is polynomial in n and the
largest absolute value of a sub-determinant of A, denoted by \Delta. More
precisely, we show that the diameter of P is bounded by O(\Delta^2 n^4 log
n\Delta). If P is bounded, then we show that the diameter of P is at most
O(\Delta^2 n^3.5 log n\Delta).
  For the special case in which A is a totally unimodular matrix, the bounds
are O(n^4 log n) and O(n^3.5 log n) respectively. This improves over the
previous best bound of O(m^16 n^3 (log mn)^3) due to Dyer and Frieze.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4279</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4279</id><created>2011-08-22</created><authors><author><keyname>Bonabeau</keyname><forenames>Eric</forenames><affiliation>INFRES, LTCI</affiliation></author><author><keyname>Dessalles</keyname><forenames>Jean-Louis</forenames><affiliation>INFRES, LTCI</affiliation></author></authors><title>Detection and emergence</title><categories>cs.AI</categories><comments>jld-98072401</comments><proxy>ccsd</proxy><journal-ref>Intellectica 25, 2 (1997) 85-94</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Two different conceptions of emergence are reconciled as two instances of the
phenomenon of detection. In the process of comparing these two conceptions, we
find that the notions of complexity and detection allow us to form a unified
definition of emergence that clearly delineates the role of the observer.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4297</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4297</id><created>2011-08-22</created><authors><author><keyname>Dessalles</keyname><forenames>Jean-Louis</forenames><affiliation>INFRES, LTCI</affiliation></author></authors><title>Why is language well-designed for communication? (Commentary on
  Christiansen and Chater: 'Language as shaped by the brain')</title><categories>cs.CL q-bio.NC</categories><comments>jld-08041101</comments><proxy>ccsd</proxy><journal-ref>Behavioral and Brain Sciences 31, 5 (2008) 518-519</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Selection through iterated learning explains no more than other
non-functional accounts, such as universal grammar, why language is so
well-designed for communicative efficiency. It does not predict several
distinctive features of language like central embedding, large lexicons or the
lack of iconicity, that seem to serve communication purposes at the expense of
learnability.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4306</identifier>
 <datestamp>2012-04-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4306</id><created>2011-08-22</created><updated>2012-04-15</updated><authors><author><keyname>Gall</keyname><forenames>Francois Le</forenames></author><author><keyname>Nakagawa</keyname><forenames>Shota</forenames></author><author><keyname>Nishimura</keyname><forenames>Harumichi</forenames></author></authors><title>On QMA Protocols with Two Short Quantum Proofs</title><categories>quant-ph cs.CC</categories><comments>12pages</comments><journal-ref>Quantum Information &amp; Computation 12(7&amp;8) pp.0589-0600 (2012)</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives a QMA (Quantum Merlin-Arthur) protocol for 3-SAT with two
logarithmic-size quantum proofs (that are not entangled with each other) such
that the gap between the completeness and the soundness is Omega(1/n
polylog(n)). This improves the best completeness/soundness gaps known for
NP-complete problems in this setting.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4315</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4315</id><created>2011-08-22</created><authors><author><keyname>Lee</keyname><forenames>Won Yeol</forenames></author><author><keyname>Kim</keyname><forenames>Young Woo</forenames></author><author><keyname>Kim</keyname><forenames>Se Yun</forenames></author><author><keyname>Lim</keyname><forenames>Jae Young</forenames></author><author><keyname>Lim</keyname><forenames>Dong Hoon</forenames></author></authors><title>Edge detection based on morphological amoebas</title><categories>cs.CV</categories><comments>To appear in The Imaging Science Journal</comments><doi>10.1179/1743131X11Y.0000000013</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Detecting the edges of objects within images is critical for quality image
processing. We present an edge-detecting technique that uses morphological
amoebas that adjust their shape based on variation in image contours. We
evaluate the method both quantitatively and qualitatively for edge detection of
images, and compare it to classic morphological methods. Our amoeba-based
edge-detection system performed better than the classic edge detectors.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4327</identifier>
 <datestamp>2012-11-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4327</id><created>2011-08-22</created><updated>2012-02-10</updated><authors><author><keyname>Hante</keyname><forenames>Falk</forenames><affiliation>IWR</affiliation></author><author><keyname>Sigalotti</keyname><forenames>Mario</forenames><affiliation>INRIA Saclay - Ile de France / CMAP Centre de Math&#xe9;matiques Appliqu&#xe9;es, CMAP</affiliation></author><author><keyname>Tucsnak</keyname><forenames>Marius</forenames><affiliation>IECN, INRIA Lorraine / IECN / MMAS</affiliation></author></authors><title>On conditions for asymptotic stability of dissipative
  infinite-dimensional systems with intermittent damping</title><categories>math.OC cs.SY</categories><proxy>ccsd</proxy><journal-ref>Journal of Differential Equations, Vol. 252, Nr. 10, pp.
  5569--5593, 2012</journal-ref><doi>10.1016/j.jde.2012.01.037</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the asymptotic stability of a dissipative evolution in a Hilbert
space subject to intermittent damping. We observe that, even if the
intermittence satisfies a persistent excitation condition, if the Hilbert space
is infinite-dimensional then the system needs not being asymptotically stable
(not even in the weak sense). Exponential stability is recovered under a
generalized observability inequality, allowing for time-domains that are not
intervals. Weak asymptotic stability is obtained under a similarly generalized
unique continuation principle. Finally, strong asymptotic stability is proved
for intermittences that do not necessarily satisfy some persistent excitation
condition, evaluating their total contribution to the decay of the trajectories
of the damped system. Our results are discussed using the example of the wave
equation, Schr\&quot;odinger's equation and, for strong stability, also the special
case of finite-dimensional systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4336</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4336</id><created>2011-08-22</created><authors><author><keyname>Aronov</keyname><forenames>Boris</forenames></author><author><keyname>Drusvyatskiy</keyname><forenames>Dmitriy</forenames></author></authors><title>Complexity of a Single Face in an Arrangement of s-Intersecting Curves</title><categories>cs.CG math.CO</categories><comments>9 pages, 5 figures</comments><msc-class>52C30, 52C45</msc-class><acm-class>I.3.5</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Consider a face F in an arrangement of n Jordan curves in the plane, no two
of which intersect more than s times. We prove that the combinatorial
complexity of F is O(\lambda_s(n)), O(\lambda_{s+1}(n)), and
O(\lambda_{s+2}(n)), when the curves are bi-infinite, semi-infinite, or
bounded, respectively; \lambda_k(n) is the maximum length of a
Davenport-Schinzel sequence of order k on an alphabet of n symbols.
  Our bounds asymptotically match the known worst-case lower bounds. Our proof
settles the still apparently open case of semi-infinite curves. Moreover, it
treats the three cases in a fairly uniform fashion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4358</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4358</id><created>2011-08-22</created><authors><author><keyname>El-Kebir</keyname><forenames>Mohammed</forenames></author><author><keyname>Heringa</keyname><forenames>Jaap</forenames></author><author><keyname>Klau</keyname><forenames>Gunnar W.</forenames></author></authors><title>Lagrangian Relaxation Applied to Sparse Global Network Alignment</title><categories>cs.DS q-bio.QM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Data on molecular interactions is increasing at a tremendous pace, while the
development of solid methods for analyzing this network data is lagging behind.
This holds in particular for the field of comparative network analysis, where
one wants to identify commonalities between biological networks. Since
biological functionality primarily operates at the network level, there is a
clear need for topology-aware comparison methods.
  In this paper we present a method for global network alignment that is fast
and robust, and can flexibly deal with various scoring schemes taking both
node-to-node correspondences as well as network topologies into account. It is
based on an integer linear programming formulation, generalizing the
well-studied quadratic assignment problem. We obtain strong upper and lower
bounds for the problem by improving a Lagrangian relaxation approach and
introduce the software tool natalie 2.0, a publicly available implementation of
our method. In an extensive computational study on protein interaction networks
for six different species, we find that our new method outperforms alternative
state-of-the-art methods with respect to quality and running time.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4361</identifier>
 <datestamp>2011-10-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4361</id><created>2011-08-22</created><authors><author><keyname>Pepe</keyname><forenames>Alberto</forenames></author></authors><title>The relationship between acquaintanceship and coauthorship in scientific
  collaboration networks</title><categories>cs.CY cs.DL cs.SI physics.soc-ph</categories><journal-ref>Journal of the American Society for Information Science and
  Technology 62(11): 2121--2132 (2011)</journal-ref><doi>10.1002/asi.21629</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This article examines the relationship between acquaintanceship and
coauthorship patterns in a multi-disciplinary, multi-institutional,
geographically distributed research center. Two social networks are constructed
and compared: a network of coauthorship, representing how researchers write
articles with one another, and a network of acquaintanceship, representing how
those researchers know each other on a personal level, based on their responses
to an online survey. Statistical analyses of the topology and community
structure of these networks point to the importance of small-scale, local,
personal networks predicated upon acquaintanceship for accomplishing
collaborative work in scientific communities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4368</identifier>
 <datestamp>2015-07-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4368</id><created>2011-08-22</created><updated>2011-09-27</updated><authors><author><keyname>Maric</keyname><forenames>Filip</forenames><affiliation>Faculty of Mathematics, University of Belgrade</affiliation></author><author><keyname>Janicic</keyname><forenames>Predrag</forenames><affiliation>Faculty of Mathematics, University of Belgrade</affiliation></author></authors><title>Formalization of Abstract State Transition Systems for SAT</title><categories>cs.LO</categories><proxy>LMCS</proxy><acm-class>F.3.1, F.4.1</acm-class><journal-ref>Logical Methods in Computer Science, Volume 7, Issue 3 (September
  28, 2011) lmcs:843</journal-ref><doi>10.2168/LMCS-7(3:19)2011</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a formalization of modern SAT solvers and their properties in a
form of abstract state transition systems. SAT solving procedures are described
as transition relations over states that represent the values of the solver's
global variables. Several different SAT solvers are formalized, including both
the classical DPLL procedure and its state-of-the-art successors. The
formalization is made within the Isabelle/HOL system and the total correctness
(soundness, termination, completeness) is shown for each presented system (with
respect to a simple notion of satisfiability that can be manually checked). The
systems are defined in a general way and cover procedures used in a wide range
of modern SAT solvers. Our formalization builds up on the previous work on
state transition systems for SAT, but it gives machine-verifiable proofs,
somewhat more general specifications, and weaker assumptions that ensure the
key correctness properties. The presented proofs of formal correctness of the
transition systems can be used as a key building block in proving correctness
of SAT solvers by using other verification approaches.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4380</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4380</id><created>2011-08-22</created><authors><author><keyname>Netzer</keyname><forenames>Tim</forenames></author><author><keyname>Plaumann</keyname><forenames>Daniel</forenames></author><author><keyname>Thom</keyname><forenames>Andreas</forenames></author></authors><title>Determinantal Representations and the Hermite Matrix</title><categories>math.AG cs.SY math.OC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of writing real polynomials as determinants of
symmetric linear matrix polynomials. This problem of algebraic geometry, whose
roots go back to the nineteenth century, has recently received new attention
from the viewpoint of convex optimization. We relate the question to sums of
squares decompositions of a certain Hermite matrix. If some power of a
polynomial admits a definite determinantal representation, then its Hermite
matrix is a sum of squares. Conversely, we show how a determinantal
representation can sometimes be constructed from a sums-of-squares
decomposition of the Hermite matrix. We finally show that definite
determinantal representations always exist, if one allows for denominators.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4386</identifier>
 <datestamp>2011-12-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4386</id><created>2011-08-22</created><updated>2011-12-15</updated><authors><author><keyname>Witt</keyname><forenames>Carsten</forenames><affiliation>DTU Informatics, Technical University of Denmark</affiliation></author></authors><title>Tight Bounds on the Optimization Time of the (1+1) EA on Linear
  Functions</title><categories>cs.NE</categories><comments>27 pages; an extended abstract of this paper will appear in the
  proceedings of STACS 2012. Changes in version 2: a monotonicity condition
  implicitly used before has been added to Theorem 2</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The analysis of randomized search heuristics on classes of functions is
fundamental for the understanding of the underlying stochastic process and the
development of suitable proof techniques. Recently, remarkable progress has
been made in bounding the expected optimization time of the simple (1+1) EA on
the class of linear functions. We improve the best known bound in this setting
from $(1.39+o(1))en\ln n$ to $en\ln n+O(n)$ in expectation and with high
probability, which is tight up to lower-order terms. Moreover, upper and lower
bounds for arbitrary mutations probabilities $p$ are derived, which imply
expected polynomial optimization time as long as $p=O((\ln n)/n)$ and which are
tight if $p=c/n$ for a constant $c$. As a consequence, the standard mutation
probability $p=1/n$ is optimal for all linear functions, and the (1+1) EA is
found to be an optimal mutation-based algorithm. The proofs are based on
adaptive drift functions and the recent multiplicative drift theorem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4408</identifier>
 <datestamp>2011-08-23</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4408</id><created>2011-08-22</created><authors><author><keyname>Barbay</keyname><forenames>J&#xe9;r&#xe9;my</forenames></author><author><keyname>Navarro</keyname><forenames>Gonzalo</forenames></author></authors><title>On Compressing Permutations and Adaptive Sorting</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Previous compact representations of permutations have focused on adding a
small index on top of the plain data $&lt;\pi(1), \pi(2),...\pi(n)&gt;$, in order to
efficiently support the application of the inverse or the iterated permutation.
  In this paper we initiate the study of techniques that exploit the
compressibility of the data itself, while retaining efficient computation of
$\pi(i)$ and its inverse.
  In particular, we focus on exploiting {\em runs}, which are subsets
(contiguous or not) of the domain where the permutation is monotonic.
  Several variants of those types of runs arise in real applications such as
inverted indexes and suffix arrays.
  Furthermore, our improved results on compressed data structures for
permutations also yield better adaptive sorting algorithms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4432</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4432</id><created>2011-08-22</created><authors><author><keyname>Salazar</keyname><forenames>Harold Roberto Martinez</forenames></author><author><keyname>Carbajal</keyname><forenames>Juan Pablo</forenames></author></authors><title>Exploiting the Passive Dynamics of a Compliant Leg to Develop Gait
  Transitions</title><categories>cs.RO cs.SY math.OC physics.comp-ph</categories><journal-ref>Phys. Rev. E 6(83),pp 066707, Jun 2011</journal-ref><doi>10.1103/PhysRevE.83.066707</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In the area of bipedal locomotion, the spring loaded inverted pendulum (SLIP)
model has been proposed as a unified framework to explain the dynamics of a
wide variety of gaits. In this paper, we present a novel analysis of the
mathematical model and its dynamical properties. We use the perspective of
hybrid dynamical systems to study the dynamics and define concepts such as
partial stability and viability. With this approach, on the one hand, we
identified stable and unstable regions of locomotion. On the other hand, we
found ways to exploit the unstable regions of locomotion to induce gait
transitions at a constant energy regime. Additionally, we show that simple
non-constant angle of attack control policies can render the system almost
always stable.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4436</identifier>
 <datestamp>2011-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4436</id><created>2011-08-22</created><updated>2011-11-28</updated><authors><author><keyname>Baumeister</keyname><forenames>Dorothea</forenames></author><author><keyname>Rothe</keyname><forenames>Joerg</forenames></author></authors><title>Taking the Final Step to a Full Dichotomy of the Possible Winner Problem
  in Pure Scoring Rules</title><categories>cs.CC</categories><comments>9 pages, to appear in Information Processing Letters</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Possible Winner problem asks, given an election where the voters'
preferences over the candidates are specified only partially, whether a
designated candidate can become a winner by suitably extending all the votes.
Betzler and Dorn [1] proved a result that is only one step away from a full
dichotomy of this problem for the important class of pure scoring rules in the
case of unweighted voters and an unbounded number of candidates: Possible
Winner is NP-complete for all pure scoring rules except plurality, veto, and
the scoring rule with vector (2,1,...,1,0), but is solvable in polynomial time
for plurality and veto. We take the final step to a full dichotomy by showing
that Possible Winner is NP-complete also for the scoring rule with vector
(2,1,...,1,0).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4439</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4439</id><created>2011-08-22</created><authors><author><keyname>Menton</keyname><forenames>Curtis</forenames></author><author><keyname>Singh</keyname><forenames>Preetjot</forenames></author></authors><title>Manipulation Can Be Hard in Tractable Voting Systems Even for
  Constant-Sized Coalitions</title><categories>cs.GT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Voting theory has become increasingly integrated with computational social
choice and multiagent systems. Computational complexity has been extensively
used as a shield against manipulation of voting systems, however for several
voting schemes this complexity may cause calculating the winner to be
computationally difficult. Of the many voting systems that have been studied
with regard to election manipulation, a few have been found to have an
unweighted coalitional manipulation problem that is NP-hard for a constant
number of manipulators despite having a winner problem that is in P. We survey
this interesting class of voting systems and the work that has analyzed their
complexity.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4440</identifier>
 <datestamp>2012-05-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4440</id><created>2011-08-22</created><authors><author><keyname>Carbajal</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Assaf</keyname><forenames>Dorit</forenames></author><author><keyname>Benker</keyname><forenames>Emanuel</forenames></author></authors><title>Promoting scientific thinking with robots</title><categories>physics.ed-ph cs.AI cs.RO</categories><comments>Conference paper, 2 figures</comments><journal-ref>Journal: Proceedings of the 2nd International Conference on
  Robotics in Education (RIE 2011), Year: 2011, Pages: 59 - 61, ISBN:
  978-3-200-02273-7</journal-ref><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  This article describes an exemplary robot exercise which was conducted in a
class for mechatronics students. The goal of this exercise was to engage
students in scientific thinking and reasoning, activities which do not always
play an important role in their curriculum. The robotic platform presented here
is simple in its construction and is customizable to the needs of the teacher.
Therefore, it can be used for exercises in many different fields of science,
not necessarily related to robotics. Here we present a situation where the
robot is used like an alien creature from which we want to understand its
behavior, resembling an ethological research activity. This robot exercise is
suited for a wide range of courses, from general introduction to science, to
hardware oriented lectures.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4443</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4443</id><created>2011-08-22</created><authors><author><keyname>Hoffmann</keyname><forenames>Matej</forenames></author><author><keyname>Carbajal</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Ziegler</keyname><forenames>Marc</forenames></author></authors><title>SNF Project Locomotion: Final report 2009-2010</title><categories>cs.RO</categories><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Summary of results in last project period (1. 10. 2009 - 30. 9. 2010) of SNFS
Project &quot;From locomotion to cognition&quot;
  The research that we have been involved in, and will continue to do, starts
from the insight that in order to understand and design intelligent behavior,
we must adopt an embodied perspective, i.e. we must take the entire agent,
including its shape or morphology, the materials out of which it is built, and
its interaction with the environment into account, in addition to the neural
control. A lot of our research in the past has been on relatively low-level
sensory-motor tasks such as locomotion (e.g. walking, running, jumping),
navigation, and grasping. While this research is of interest in itself, in the
context of artificial intelligence and cognitive science, this leads to the
question of what these kinds of tasks have to do with higher levels of
cognition, or to put it more provocatively, &quot;What does walking have to do with
thinking?&quot; This question is of course reminiscent of the notorious &quot;symbol
grounding problem&quot;. In contrast to most of the research on symbol grounding, we
propose to exploit the dynamic interaction between the embodied agent and the
environment as the basis for grounding. We use the term &quot;morphological
computation&quot; to designate the fact that some of the control or computation can
be taken over by the dynamic interaction derived from morphological properties
(e.g. the passive forward swing of the leg in walking, the spring-like
properties of the muscles, and the weight distribution). By taking
morphological computation into account, an agent will be able to achieve not
only faster, more robust, and more energy-efficient behavior, but also more
situated exploration by the agent for the comprehensive understanding of the
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4445</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4445</id><created>2011-08-22</created><authors><author><keyname>Hoffmann</keyname><forenames>Matej</forenames></author><author><keyname>Carbajal</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Ziegler</keyname><forenames>Marc</forenames></author></authors><title>SNF Project Locomotion: Progress report 2008-2009</title><categories>cs.RO</categories><comments>progress report</comments><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Summary of results (project period 1. 10. 2008 - 30. 9. 2009) of SNFS Project
&quot;From locomotion to cognition&quot;
  The research that we have been involved in, and will continue to do, starts
from the insight that in order to understand and design intelligent behavior,
we must adopt an embodied perspective, i.e. we must take the entire agent,
including its shape or morphology, the materials out of which it is built, and
its interaction with the environment into account, in addition to the neural
control. A lot of our research in the past has been on relatively low-level
sensory-motor tasks such as locomotion (e.g. walking, running, jumping),
navigation, and grasping. While this research is of interest in itself, in the
context of artificial intelligence and cognitive science, this leads to the
question of what these kinds of tasks have to do with higher levels of
cognition, or to put it more provocatively, &quot;What does walking have to do with
thinking?&quot; This question is of course reminiscent of the notorious &quot;symbol
grounding problem&quot;. In contrast to most of the research on symbol grounding, we
propose to exploit the dynamic interaction between the embodied agent and the
environment as the basis for grounding. We use the term &quot;morphological
computation&quot; to designate the fact that some of the control or computation can
be taken over by the dynamic interaction derived from morphological properties
(e.g. the passive forward swing of the leg in walking, the spring-like
properties of the muscles, and the weight distribution). By taking
morphological computation into account, an agent will be able to achieve not
only faster, more robust, and more energy-efficient behavior, but also more
situated exploration by the agent for the comprehensive understanding of the
environment.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4448</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4448</id><created>2011-08-22</created><authors><author><keyname>Carbajal</keyname><forenames>Juan Pablo</forenames></author><author><keyname>Kuppuswamy</keyname><forenames>Naveen</forenames></author></authors><title>Magneto-mechanical actuation model for fin-based locomotion</title><categories>cs.RO</categories><comments>Conference paper, 2010</comments><journal-ref>Design and Nature V 2010, WIT Transactions on Ecology and the
  Environment, ISBN 978-1-84564-454-3</journal-ref><doi>10.2495/DN100331</doi><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  In this paper, we report the results from the analysis of a numerical model
used for the design of a magnetic linear actuator with applications to
fin-based locomotion. Most of the current robotic fish generate bending motion
using rotary motors which implies at least one mechanical conversion of the
motion. We seek a solution that directly bends the fin and, at the same time,
is able to exploit the magneto-mechanical properties of the fin material. This
strong fin-actuator coupling blends the actuator and the body of the robot,
allowing cross optimization of the system's elements.
  We study a simplified model of an elastic element, a spring-mass system
representing a flexible fin, subjected to nonlinear forcing, emulating magnetic
interaction. The dynamics of the system is studied under unforced and periodic
forcing conditions. The analysis is focused on the limit cycles present in the
system, which allows the periodic bending of the fin and the generation of
thrust. The frequency, maximum amplitude and center of the periodic orbits
(offset of the bending) depend directly on the stiffness of the fin and the
intensity of the forcing; we use this dependency to sketch a simple parameter
controller. Although the model is strongly simplified, it provides means to
estimate first values of the parameters for this kind of actuator and it is
useful to evaluate the feasibility of minimal actuation control of such
systems.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4450</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4450</id><created>2011-08-22</created><authors><author><keyname>Yan</keyname><forenames>Tongjiang</forenames></author></authors><title>Linear Complexity of Ding-Helleseth Generalized Cyclotomic Binary
  Sequences of Any Order</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper gives the linear complexity of binary Ding-Helleseth generalized
cyclotomic sequences of any order.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4464</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4464</id><created>2011-08-22</created><authors><author><keyname>Aceto</keyname><forenames>Luca</forenames></author><author><keyname>F&#xe1;bregas</keyname><forenames>Ignacio</forenames></author><author><keyname>de Frutos-Escrig</keyname><forenames>David</forenames></author><author><keyname>Ing&#xf3;lfsd&#xf3;ttir</keyname><forenames>Anna</forenames></author><author><keyname>Palomino</keyname><forenames>Miguel</forenames></author></authors><title>Graphical representation of covariant-contravariant modal formulae</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS 2011, arXiv:1108.4077</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 64, 2011, pp. 1-15</journal-ref><doi>10.4204/EPTCS.64.1</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Covariant-contravariant simulation is a combination of standard (covariant)
simulation, its contravariant counterpart and bisimulation. We have previously
studied its logical characterization by means of the covariant-contravariant
modal logic. Moreover, we have investigated the relationships between this
model and that of modal transition systems, where two kinds of transitions (the
so-called may and must transitions) were combined in order to obtain a simple
framework to express a notion of refinement over state-transition models. In a
classic paper, Boudol and Larsen established a precise connection between the
graphical approach, by means of modal transition systems, and the logical
approach, based on Hennessy-Milner logic without negation, to system
specification. They obtained a (graphical) representation theorem proving that
a formula can be represented by a term if, and only if, it is consistent and
prime. We show in this paper that the formulae from the covariant-contravariant
modal logic that admit a &quot;graphical&quot; representation by means of processes,
modulo the covariant-contravariant simulation preorder, are also the consistent
and prime ones. In order to obtain the desired graphical representation result,
we first restrict ourselves to the case of covariant-contravariant systems
without bivariant actions. Bivariant actions can be incorporated later by means
of an encoding that splits each bivariant action into its covariant and its
contravariant parts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4465</identifier>
 <datestamp>2015-01-07</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4465</id><created>2011-08-22</created><authors><author><keyname>Capecchi</keyname><forenames>Sara</forenames><affiliation>University of Torino</affiliation></author><author><keyname>Castellani</keyname><forenames>Ilaria</forenames><affiliation>INRIA Sophia Antipolis M&#xe9;diterran&#xe9;e</affiliation></author><author><keyname>Dezani-Ciancaglini</keyname><forenames>Mariangiola</forenames><affiliation>University of Torino</affiliation></author></authors><title>Information Flow Safety in Multiparty Sessions</title><categories>cs.CR</categories><comments>In Proceedings EXPRESS 2011, arXiv:1108.4077</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 64, 2011, pp. 16-30</journal-ref><doi>10.1017/S0960129514000619</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider a calculus for multiparty sessions enriched with security levels
for messages. We propose a monitored semantics for this calculus, which blocks
the execution of processes as soon as they attempt to leak information. We
illustrate the use of our monitored semantics with various examples, and show
that the induced safety property implies a noninterference property studied
previously.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4466</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4466</id><created>2011-08-22</created><authors><author><keyname>Corradini</keyname><forenames>Flavio</forenames><affiliation>University of Camerino</affiliation></author><author><keyname>Di Berardini</keyname><forenames>Maria Rita</forenames><affiliation>University of Camerino</affiliation></author><author><keyname>Vogler</keyname><forenames>Walter</forenames><affiliation>University of Augsburg</affiliation></author></authors><title>Read Operators and their Expressiveness in Process Algebras</title><categories>cs.LO cs.DC cs.PF</categories><comments>In Proceedings EXPRESS 2011, arXiv:1108.4077</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 64, 2011, pp. 31-43</journal-ref><doi>10.4204/EPTCS.64.3</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study two different ways to enhance PAFAS, a process algebra for modelling
asynchronous timed concurrent systems, with non-blocking reading actions. We
first add reading in the form of a read-action prefix operator. This operator
is very flexible, but its somewhat complex semantics requires two types of
transition relations. We also present a read-set prefix operator with a simpler
semantics, but with syntactic restrictions. We discuss the expressiveness of
read prefixes; in particular, we compare them to read-arcs in Petri nets and
justify the simple semantics of the second variant by showing that its
processes can be translated into processes of the first with timed-bisimilar
behaviour. It is still an open problem whether the first algebra is more
expressive than the second; we give a number of laws that are interesting in
their own right, and can help to find a backward translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4467</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4467</id><created>2011-08-22</created><authors><author><keyname>Lago</keyname><forenames>Ugo Dal</forenames></author><author><keyname>Di Giamberardino</keyname><forenames>Paolo</forenames></author></authors><title>Soft Session Types</title><categories>cs.LO cs.PL</categories><comments>In Proceedings EXPRESS 2011, arXiv:1108.4077</comments><proxy>EPTCS</proxy><acm-class>F.3.2; F.4.1</acm-class><journal-ref>EPTCS 64, 2011, pp. 59-73</journal-ref><doi>10.4204/EPTCS.64.5</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show how systems of session types can enforce interactions to be bounded
for all typable processes. The type system we propose is based on Lafont's soft
linear logic and is strongly inspired by recent works about session types as
intuitionistic linear logic formulas. Our main result is the existence, for
every typable process, of a polynomial bound on the length of any reduction
sequence starting from it and on the size of any of its reducts.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4468</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4468</id><created>2011-08-22</created><authors><author><keyname>Agut</keyname><forenames>Damian Nadales</forenames><affiliation>Eindhoven University of Technology</affiliation></author><author><keyname>Reniers</keyname><forenames>Michel</forenames><affiliation>Eindhoven University of Technology</affiliation></author></authors><title>Linearization of CIF Through SOS</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS 2011, arXiv:1108.4077</comments><proxy>EPTCS</proxy><acm-class>F.3.2; D.3.1;</acm-class><journal-ref>EPTCS 64, 2011, pp. 74-88</journal-ref><doi>10.4204/EPTCS.64.6</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Linearization is the procedure of rewriting a process term into a linear
form, which consist only of basic operators of the process language. This
procedure is interesting both from a theoretical and a practical point of view.
In particular, a linearization algorithm is needed for the Compositional
Interchange Format (CIF), an automaton based modeling language.
  The problem of devising efficient linearization algorithms is not trivial,
and has been already addressed in literature. However, the linearization
algorithms obtained are the result of an inventive process, and the proof of
correctness comes as an afterthought. Furthermore, the semantic specification
of the language does not play an important role on the design of the algorithm.
  In this work we present a method for obtaining an efficient linearization
algorithm, through a step-wise refinement of the SOS rules of CIF. As a result,
we show how the semantic specification of the language can guide the
implementation of such a procedure, yielding a simple proof of correctness.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4469</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4469</id><created>2011-08-22</created><authors><author><keyname>Peters</keyname><forenames>Kirstin</forenames></author><author><keyname>Schicke</keyname><forenames>Jens-Wolfhard</forenames></author><author><keyname>Nestmann</keyname><forenames>Uwe</forenames></author></authors><title>Synchrony vs Causality in the Asynchronous Pi-Calculus</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS 2011, arXiv:1108.4077</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 64, 2011, pp. 89-103</journal-ref><doi>10.4204/EPTCS.64.7</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the relation between process calculi that differ in their either
synchronous or asynchronous interaction mechanism. Concretely, we are
interested in the conditions under which synchronous interaction can be
implemented using just asynchronous interactions in the pi-calculus. We assume
a number of minimal conditions referring to the work of Gorla: a &quot;good&quot;
encoding must be compositional and preserve and reflect computations,
deadlocks, divergence, and success. Under these conditions, we show that it is
not possible to encode synchronous interactions without introducing additional
causal dependencies in the translation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4470</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4470</id><created>2011-08-22</created><authors><author><keyname>Phillips</keyname><forenames>Iain</forenames><affiliation>Imperial College London</affiliation></author><author><keyname>Ulidowski</keyname><forenames>Irek</forenames><affiliation>University of Leicester</affiliation></author></authors><title>A Logic with Reverse Modalities for History-preserving Bisimulations</title><categories>cs.LO</categories><comments>In Proceedings EXPRESS 2011, arXiv:1108.4077</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 64, 2011, pp. 104-118</journal-ref><doi>10.4204/EPTCS.64.8</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We introduce event identifier logic (EIL) which extends Hennessy-Milner logic
by the addition of (1) reverse as well as forward modalities, and (2)
identifiers to keep track of events. We show that this logic corresponds to
hereditary history-preserving (HH) bisimulation equivalence within a particular
true-concurrency model, namely stable configuration structures. We furthermore
show how natural sublogics of EIL correspond to coarser equivalences. In
particular we provide logical characterisations of weak history-preserving (WH)
and history-preserving (H) bisimulation. Logics corresponding to HH and H
bisimulation have been given previously, but not to WH bisimulation (when
autoconcurrency is allowed), as far as we are aware. We also present
characteristic formulas which characterise individual structures with respect
to history-preserving equivalences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4471</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4471</id><created>2011-08-22</created><authors><author><keyname>Schicke</keyname><forenames>Jens-Wolfhard</forenames><affiliation>TU Braunschweig</affiliation></author><author><keyname>Peters</keyname><forenames>Kirstin</forenames><affiliation>TU Berlin</affiliation></author><author><keyname>Goltz</keyname><forenames>Ursula</forenames><affiliation>TU Braunschweig</affiliation></author></authors><title>Synchrony vs. Causality in Asynchronous Petri Nets</title><categories>cs.DC</categories><comments>In Proceedings EXPRESS 2011, arXiv:1108.4077</comments><proxy>EPTCS</proxy><journal-ref>EPTCS 64, 2011, pp. 119-131</journal-ref><doi>10.4204/EPTCS.64.9</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a synchronous system, we study the question whether the behaviour of
that system can be exhibited by a (non-trivially) distributed and hence
asynchronous implementation. In this paper we show, by counterexample, that
synchronous systems cannot in general be implemented in an asynchronous fashion
without either introducing an infinite implementation or changing the causal
structure of the system behaviour.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4475</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4475</id><created>2011-08-22</created><updated>2012-11-22</updated><authors><author><keyname>Li</keyname><forenames>Wei-Chiang</forenames></author><author><keyname>Chang</keyname><forenames>Tsung-Hui</forenames></author><author><keyname>Lin</keyname><forenames>Che</forenames></author><author><keyname>Chi</keyname><forenames>Chong-Yung</forenames></author></authors><title>Coordinated Beamforming for Multiuser MISO Interference Channel under
  Rate Outage Constraints</title><categories>cs.IT math.IT</categories><comments>30 pages, 10 figures, accepted by IEEE Trans. Signal Process</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies the coordinated beamforming design problem for the
multiple-input single-output (MISO) interference channel, assuming only channel
distribution information (CDI) at the transmitters. Under a given requirement
on the rate outage probability for receivers, we aim to maximize the system
utility (e.g., the weighted sum rate, weighted geometric mean rate, and the
weighed harmonic mean rate) subject to the rate outage constraints and
individual power constraints. The outage constraints, however, lead to a
complicated, nonconvex structure for the considered beamforming design problem
and make the optimization problem difficult to handle. {Although} this
nonconvex optimization problem can be solved in an exhaustive search manner,
this brute-force approach is only feasible when the number of
transmitter-receiver pairs is small. For a system with a large number of
transmitter-receiver pairs, computationally efficient alternatives are
necessary. The focus of this paper is hence on the design of such efficient
approximation methods. In particular, by employing semidefinite relaxation
(SDR) and first-order approximation techniques, we propose an efficient
successive convex approximation (SCA) algorithm that provides high-quality
approximate beamforming solutions via solving a sequence of convex
approximation problems. The solution thus obtained is further shown to be a
stationary point for the SDR of the original outage constrained beamforming
design problem. {Furthermore}, we propose a distributed SCA algorithm where
each transmitter optimizes its own beamformer using local CDI and information
obtained from limited message exchange with the other transmitters. Our
simulation results demonstrate that the proposed SCA algorithm and its
distributed counterpart indeed converge, and near-optimal performance can be
achieved for all the considered system utilities.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4478</identifier>
 <datestamp>2012-04-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4478</id><created>2011-08-22</created><updated>2012-04-13</updated><authors><author><keyname>Karimi</keyname><forenames>Mehdi</forenames></author><author><keyname>Banihashemi</keyname><forenames>Amir H.</forenames></author></authors><title>An Efficient Algorithm for Finding Dominant Trapping Sets of LDPC Codes</title><categories>cs.IT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper presents an efficient algorithm for finding the dominant trapping
sets of a low-density parity-check (LDPC) code. The algorithm can be used to
estimate the error floor of LDPC codes or to be part of the apparatus to design
LDPC codes with low error floors. For regular codes, the algorithm is initiated
with a set of short cycles as the input. For irregular codes, in addition to
short cycles, variable nodes with low degree and cycles with low approximate
cycle extrinsic message degree (ACE) are also used as the initial inputs. The
initial inputs are then expanded recursively to dominant trapping sets of
increasing size. At the core of the algorithm lies the analysis of the
graphical structure of dominant trapping sets and the relationship of such
structures to short cycles, low-degree variable nodes and cycles with low ACE.
The algorithm is universal in the sense that it can be used for an arbitrary
graph and that it can be tailored to find other graphical objects, such as
absorbing sets and Zyablov-Pinsker (ZP) trapping sets, known to dominate the
performance of LDPC codes in the error floor region over different channels and
for different iterative decoding algorithms. Simulation results on several LDPC
codes demonstrate the accuracy and efficiency of the proposed algorithm. In
particular, the algorithm is significantly faster than the existing search
algorithms for dominant trapping sets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4487</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4487</id><created>2011-08-22</created><authors><author><keyname>Wolf</keyname><forenames>Thomas</forenames></author></authors><title>The Parametric Solution of Underdetermined linear ODEs</title><categories>cs.SC math.CA</categories><comments>14 pages</comments><msc-class>33F10, 34H05</msc-class><acm-class>I.1.2</acm-class><journal-ref>Programming and Computer Software, 37 (2011), Number 2, 62-70</journal-ref><doi>10.1134/S0361768811020113</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The purpose of this paper is twofold. An immediate practical use of the
presented algorithm is its applicability to the parametric solution of
underdetermined linear ordinary differential equations (ODEs) with coefficients
that are arbitrary analytic functions in the independent variable. A second
conceptual aim is to present an algorithm that is in some sense dual to the
fundamental Euclids algorithm, and thus an alternative to the special case of a
Groebner basis algorithm as it is used for solving linear ODE-systems. In the
paper Euclids algorithm and the new `dual version' are compared and their
complementary strengths are analysed on the task of solving underdetermined
ODEs. An implementation of the described algorithm is interactively accessible
under http://lie.math.brocku.ca/crack/demo.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4494</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4494</id><created>2011-08-23</created><authors><author><keyname>Sunic</keyname><forenames>Zoran</forenames></author></authors><title>Twin Towers of Hanoi</title><categories>math.CO cs.DM math.GR</categories><comments>Dedicated to Antonio Machi on the occasion of his retirement</comments><msc-class>05C12, 05C57, 20E08, 68Q25, 68R10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In the Twin Towers of Hanoi version of the well known Towers of Hanoi Problem
there are two coupled sets of pegs. In each move, one chooses a pair of pegs in
one of the sets and performs the only possible legal transfer of a disk between
the chosen pegs (the smallest disk from one of the pegs is moved to the other
peg), but also, simultaneously, between the corresponding pair of pegs in the
coupled set (thus the same sequence of moves is always used in both sets). We
provide upper and lower bounds on the length of the optimal solutions to
problems of the following type. Given an initial and a final position of N
disks in each of the coupled sets, what is the smallest number of moves needed
to simultaneously obtain the final position from the initial one in each set?
Our analysis is based on the use of a group, called Hanoi Towers group, of
rooted ternary tree automorphisms, which models the original problem in such a
way that the configurations on N disks are the vertices at level N of the tree
and the action of the generators of the group represents the three possible
moves between the three pegs. The twin version of the problem is analyzed by
considering the action of Hanoi Towers group on pairs of vertices.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4499</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4499</id><created>2011-08-23</created><authors><author><keyname>Karafyllis</keyname><forenames>Iasson</forenames></author><author><keyname>Krstic</keyname><forenames>Miroslav</forenames></author></authors><title>Predictor-Based Output Feedback for Nonlinear Delay Systems</title><categories>math.OC cs.SY</categories><comments>31 pages, 2 figures. To be submitted to Automatica</comments><msc-class>93B52, 93C23, 93D15, 93C10</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide two solutions to the heretofore open problem of stabilization of
systems with arbitrarily long delays at the input and output of a nonlinear
system using output feedback only. Both of our solutions are global, employ the
predictor approach over the period that combines the input and output delays,
address nonlinear systems with sampled measurements and with control applied
using a zero-order hold, and require that the sampling/holding periods be
sufficiently short, though not necessarily constant. Our first approach
considers general nonlinear systems for which the solution map is available
explicitly and whose one-sample-period predictor-based discrete-time model
allows state reconstruction, in a finite number of steps, from the past values
of inputs and output measurements. Our second approach considers a class of
globally Lipschitz strict-feedback systems with disturbances and employs an
appropriately constructed successive approximation of the predictor map, a
high-gain sampled-data observer, and a linear stabilizing feedback for the
delay-free system. We specialize the second approach to linear systems, where
the predictor is available explicitly. We provide two illustrative examples-one
analytical for the first approach and one numerical for the second approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4501</identifier>
 <datestamp>2011-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4501</id><created>2011-08-23</created><updated>2011-12-20</updated><authors><author><keyname>Crowston</keyname><forenames>Robert</forenames></author><author><keyname>Gutin</keyname><forenames>Gregory</forenames></author><author><keyname>Jones</keyname><forenames>Mark</forenames></author><author><keyname>Raman</keyname><forenames>Venkatesh</forenames></author><author><keyname>Saurabh</keyname><forenames>Saket</forenames></author></authors><title>Parameterized Complexity of MaxSat Above Average</title><categories>cs.CC cs.DM cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In MaxSat, we are given a CNF formula $F$ with $n$ variables and $m$ clauses
and asked to find a truth assignment satisfying the maximum number of clauses.
Let $r_1,..., r_m$ be the number of literals in the clauses of $F$. Then
$asat(F)=\sum_{i=1}^m (1-2^{-r_i})$ is the expected number of clauses satisfied
by a random truth assignment (the truth values to the variables are distributed
uniformly and independently). It is well-known that, in polynomial time, one
can find a truth assignment satisfying at least $asat(F)$ clauses. In the
parameterized problem MaxSat-AA, we are to decide whether there is a truth
assignment satisfying at least $asat(F)+k$ clauses, where $k$ is the parameter.
We prove that MaxSat-AA is para-NP-complete and, thus, MaxSat-AA is not
fixed-parameter tractable unless P$=$NP. This is in sharp contrast to
MaxLin2-AA which was recently proved to be fixed-parameter tractable by
Crowston et al. (arXiv:1104.1135v3). In fact, we consider a more refined
version of {\sc MaxSat-AA}, {\sc Max-$r(n)$-Sat-AA}, where $r_j\le r(n)$ for
each $j$. Alon {\em et al.} (SODA 2010) proved that if $r=r(n)$ is a constant,
then {\sc Max-$r$-Sat-AA} is fixed-parameter tractable. We prove that {\sc
Max-$r(n)$-Sat-AA} is para-NP-complete for $r(n)=\lceil \log n\rceil.$ We also
prove that assuming the exponential time hypothesis, {\sc Max-$r(n)$-Sat-AA} is
not in XP already for any $r(n)\ge \log \log n +\phi(n)$, where $\phi(n)$ is
any unbounded strictly increasing function. This lower bound on $r(n)$ cannot
be decreased much further as we prove that {\sc Max-$r(n)$-Sat-AA} is (i) in XP
for any $r(n)\le \log \log n - \log \log \log n$ and (ii) fixed-parameter
tractable for any $r(n)\le \log \log n - \log \log \log n - \phi(n)$, where
$\phi(n)$ is any unbounded strictly increasing function. The proof uses some
results on {\sc MaxLin2-AA}.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4508</identifier>
 <datestamp>2012-02-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4508</id><created>2011-08-23</created><updated>2012-01-31</updated><authors><author><keyname>Chen</keyname><forenames>Shaoshi</forenames></author><author><keyname>Kauers</keyname><forenames>Manuel</forenames></author></authors><title>Trading Order for Degree in Creative Telescoping</title><categories>cs.SC</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We analyze the differential equations produced by the method of creative
telescoping applied to a hyperexponential term in two variables. We show that
equations of low order have high degree, and that higher order equations have
lower degree. More precisely, we derive degree bounding formulas which allow to
estimate the degree of the output equations from creative telescoping as a
function of the order. As an application, we show how the knowledge of these
formulas can be used to improve, at least in principle, the performance of
creative telescoping implementations, and we deduce bounds on the asymptotic
complexity of creative telescoping for hyperexponential terms.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4516</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4516</id><created>2011-08-23</created><authors><author><keyname>XU</keyname><forenames>Yanwei</forenames></author></authors><title>Scalable Continual Top-k Keyword Search in Relational Databases</title><categories>cs.DB cs.IR</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Keyword search in relational databases has been widely studied in recent
years because it does not require users neither to master a certain structured
query language nor to know the complex underlying database schemas. Most of
existing methods focus on answering snapshot keyword queries in static
databases. In practice, however, databases are updated frequently, and users
may have long-term interests on specific topics. To deal with such a situation,
it is necessary to build effective and efficient facility in a database system
to support continual keyword queries.
  In this paper, we propose an efficient method for answering continual top-$k$
keyword queries over relational databases. The proposed method is built on an
existing scheme of keyword search on relational data streams, but incorporates
the ranking mechanisms into the query processing methods and makes two
improvements to support efficient top-$k$ keyword search in relational
databases. Compared to the existing methods, our method is more efficient both
in computing the top-$k$ results in a static database and in maintaining the
top-$k$ results when the database continually being updated. Experimental
results validate the effectiveness and efficiency of the proposed method.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4531</identifier>
 <datestamp>2013-05-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4531</id><created>2011-08-23</created><updated>2013-05-10</updated><authors><author><keyname>He</keyname><forenames>Jun</forenames></author><author><keyname>Chen</keyname><forenames>Tianshi</forenames></author><author><keyname>Mitavskiy</keyname><forenames>Boris</forenames></author></authors><title>Novel Analysis of Population Scalability in Evolutionary Algorithms</title><categories>cs.NE</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Population-based evolutionary algorithms (EAs) have been widely applied to
solve various optimization problems. The question of how the performance of a
population-based EA depends on the population size arises naturally. The
performance of an EA may be evaluated by different measures, such as the
average convergence rate to the optimal set per generation or the expected
number of generations to encounter an optimal solution for the first time.
Population scalability is the performance ratio between a benchmark EA and
another EA using identical genetic operators but a larger population size.
Although intuitively the performance of an EA may improve if its population
size increases, currently there exist only a few case studies for simple
fitness functions. This paper aims at providing a general study for discrete
optimisation. A novel approach is introduced to analyse population scalability
using the fundamental matrix. The following two contributions summarize the
major results of the current article. (1) We demonstrate rigorously that for
elitist EAs with identical global mutation, using a lager population size
always increases the average rate of convergence to the optimal set; and yet,
sometimes, the expected number of generations needed to find an optimal
solution (measured by either the maximal value or the average value) may
increase, rather than decrease. (2) We establish sufficient and/or necessary
conditions for the superlinear scalability, that is, when the average
convergence rate of a $(\mu+\mu)$ EA (where $\mu\ge2$) is bigger than $\mu$
times that of a $(1+1)$ EA.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4545</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4545</id><created>2011-08-23</created><authors><author><keyname>Perez</keyname><forenames>Meir</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>The fuzzy gene filter: A classifier performance assesment</title><categories>cs.LG cs.CE</categories><comments>Intelligent Systems and Control / 742: Computational Bioscience (ISC
  2011) July 11 - 13, 2011 Cambridge, United Kingdom Editor(s): J.F. Whidborne,
  P. Willis, G. Montana</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Fuzzy Gene Filter (FGF) is an optimised Fuzzy Inference System designed
to rank genes in order of differential expression, based on expression data
generated in a microarray experiment. This paper examines the effectiveness of
the FGF for feature selection using various classification architectures. The
FGF is compared to three of the most common gene ranking algorithms: t-test,
Wilcoxon test and ROC curve analysis. Four classification schemes are used to
compare the performance of the FGF vis-a-vis the standard approaches: K Nearest
Neighbour (KNN), Support Vector Machine (SVM), Naive Bayesian Classifier (NBC)
and Artificial Neural Network (ANN). A nested stratified Leave-One-Out Cross
Validation scheme is used to identify the optimal number top ranking genes, as
well as the optimal classifier parameters. Two microarray data sets are used
for the comparison: a prostate cancer data set and a lymphoma data set.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4547</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4547</id><created>2011-08-23</created><authors><author><keyname>Harrison</keyname><forenames>William</forenames></author></authors><title>Language Support for Declarative Future Commitments</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Sequential programming and work-flow programming are two useful, but
radically different, ways of describing computational processing. Of the two,
it is sequential programming that we teach all programmers and support by
programming languages, whether in procedural, objectoriented, or functional
paradigms. We teach workflow as a secondary style of problem decomposition for
use in special situations, like distributed or networked processing. Both
styles offer complementary advantages, but the fact that they employ radically
different models for ownership of continuations interferes with our ability to
integrate them in a way that allows them to be taught and used in a single
programming language. This paper describes a programming language construct,
declarative future commitments, that permit better integration of the two.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4548</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4548</id><created>2011-08-23</created><authors><author><keyname>Mpanza</keyname><forenames>J. L.</forenames></author><author><keyname>Marwala</keyname><forenames>T.</forenames></author></authors><title>Ant Colony Optimization of Rough Set for HV Bushings Fault Detection</title><categories>cs.NE</categories><comments>Fourth International Workshop on Advanced Computational Intelligence
  (IWACI 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most transformer failures are attributed to bushings failures. Hence it is
necessary to monitor the condition of bushings. In this paper three methods are
developed to monitor the condition of oil filled bushing. Multi-layer
perceptron (MLP), Radial basis function (RBF) and Rough Set (RS) models are
developed and combined through majority voting to form a committee. The MLP
performs better that the RBF and the RS is terms of classification accuracy.
The RBF is the fasted to train. The committee performs better than the
individual models. The diversity of models is measured to evaluate their
similarity when used in the committee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4551</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4551</id><created>2011-08-23</created><authors><author><keyname>Duma</keyname><forenames>Mlungisi</forenames></author><author><keyname>Twala</keyname><forenames>Bhekisipho</forenames></author><author><keyname>Marwala</keyname><forenames>Tshilidzi</forenames></author></authors><title>Improving the performance of the ripper in insurance risk classification
  : A comparitive study using feature selection</title><categories>cs.LG cs.CE</categories><comments>ICINCO 2011: 8th International Conference on Informatics in Control,
  Automation and Robotics</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The Ripper algorithm is designed to generate rule sets for large datasets
with many features. However, it was shown that the algorithm struggles with
classification performance in the presence of missing data. The algorithm
struggles to classify instances when the quality of the data deteriorates as a
result of increasing missing data. In this paper, a feature selection technique
is used to help improve the classification performance of the Ripper model.
Principal component analysis and evidence automatic relevance determination
techniques are used to improve the performance. A comparison is done to see
which technique helps the algorithm improve the most. Training datasets with
completely observable data were used to construct the model and testing
datasets with missing values were used for measuring accuracy. The results
showed that principal component analysis is a better feature selection for the
Ripper in improving the classification performance.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4559</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4559</id><created>2011-08-23</created><updated>2012-11-27</updated><authors><author><keyname>Hazan</keyname><forenames>Elad</forenames></author><author><keyname>Koren</keyname><forenames>Tomer</forenames></author></authors><title>Optimal Algorithms for Ridge and Lasso Regression with Partially
  Observed Attributes</title><categories>cs.LG</categories><comments>This is a full version of the paper arXiv:1206.4678 appearing in ICML
  2012</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the most common variants of linear regression, including Ridge,
Lasso and Support-vector regression, in a setting where the learner is allowed
to observe only a fixed number of attributes of each example at training time.
We present simple and efficient algorithms for these problems: for Lasso and
Ridge regression they need the same total number of attributes (up to
constants) as do full-information algorithms, for reaching a certain accuracy.
For Support-vector regression, we require exponentially less attributes
compared to the state of the art. By that, we resolve an open problem recently
posed by Cesa-Bianchi et al. (2010). Experiments show the theoretical bounds to
be justified by superior performance compared to the state of the art.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4572</identifier>
 <datestamp>2012-11-22</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4572</id><created>2011-08-23</created><authors><author><keyname>Wuhrer</keyname><forenames>Stefanie</forenames></author><author><keyname>Shu</keyname><forenames>Chang</forenames></author><author><keyname>Bose</keyname><forenames>Prosenjit</forenames></author></authors><title>Automatically Creating Design Models from 3D Anthropometry Data</title><categories>cs.CG</categories><journal-ref>Journal of Computing and Information Science in Engineering,
  12(4):041007, 2012</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  When designing a product that needs to fit the human shape, designers often
use a small set of 3D models, called design models, either in physical or
digital form, as representative shapes to cover the shape variabilities of the
population for which the products are designed. Until recently, the process of
creating these models has been an art involving manual interaction and
empirical guesswork. The availability of the 3D anthropometric databases
provides an opportunity to create design models optimally. In this paper, we
propose a novel way to use 3D anthropometric databases to generate design
models that represent a given population for design applications such as the
sizing of garments and gear. We generate the representative shapes by solving a
covering problem in a parameter space. Well-known techniques in computational
geometry are used to solve this problem. We demonstrate the method using
examples in designing glasses and helmets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4585</identifier>
 <datestamp>2013-02-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4585</id><created>2011-08-22</created><authors><author><keyname>Gambra</keyname><forenames>Marta Balb&#xe1;s</forenames></author><author><keyname>Frey</keyname><forenames>Erwin</forenames></author></authors><title>Social dynamics with peer support on heterogeneous networks: The &quot;mafia
  model&quot;</title><categories>physics.soc-ph cond-mat.stat-mech cs.SI</categories><comments>12 pages, 13 figures</comments><journal-ref>Eur. Phys. J. B. 83, 507-518 (2011)</journal-ref><doi>10.1140/epjb/e2011-10359-0</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Human behavior often exhibit a scheme in which individuals adopt indifferent,
neutral, or radical positions on a given topic. The mechanisms leading to
community formation are strongly related with social pressure and the topology
of the contact network. Here, we discuss an approach to model social behavior
which accounts for the protection by alike peers proportional to their relative
abundance in the closest neighborhood. We explore the ensuing non-linear
dynamics emphasizing the role of the specific structure of the social network,
modeled by scale-free graphs. We find that both coexistence of opinions and
consensus on the default position are possible stationary states of the model.
In particular, we show how these states critically depend on the heterogeneity
of the social network and the specific distribution of external control
elements.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4596</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4596</id><created>2011-08-23</created><authors><author><keyname>Nguyen</keyname><forenames>Benjamin</forenames><affiliation>PRISM, INRIA Rocquencourt</affiliation></author><author><keyname>Vion</keyname><forenames>Antoine</forenames><affiliation>LEST</affiliation></author><author><keyname>Dudouet</keyname><forenames>Fran&#xe7;ois-Xavier</forenames><affiliation>IRISES</affiliation></author><author><keyname>Colazzo</keyname><forenames>Dario</forenames><affiliation>LRI, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Manolescu</keyname><forenames>Ioana</forenames><affiliation>LRI, INRIA Saclay - Ile de France</affiliation></author><author><keyname>Senellart</keyname><forenames>Pierre</forenames></author></authors><title>XML content warehousing: Improving sociological studies of mailing lists
  and web data</title><categories>cs.DB</categories><proxy>ccsd</proxy><journal-ref>Bulletin de M\'ethodologie Sociologique (BMS) (2011) 27p</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this paper, we present the guidelines for an XML-based approach for the
sociological study of Web data such as the analysis of mailing lists or
databases available online. The use of an XML warehouse is a flexible solution
for storing and processing this kind of data. We propose an implemented
solution and show possible applications with our case study of profiles of
experts involved in W3C standard-setting activity. We illustrate the
sociological use of semi-structured databases by presenting our XML Schema for
mailing-list warehousing. An XML Schema allows many adjunctions or crossings of
data sources, without modifying existing data sets, while allowing possible
structural evolution. We also show that the existence of hidden data implies
increased complexity for traditional SQL users. XML content warehousing allows
altogether exhaustive warehousing and recursive queries through contents, with
far less dependence on the initial storage. We finally present the possibility
of exporting the data stored in the warehouse to commonly-used advanced
software devoted to sociological analysis.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4606</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4606</id><created>2011-08-23</created><authors><author><keyname>Kao</keyname><forenames>Mong-Jen</forenames></author><author><keyname>Lee</keyname><forenames>D. T.</forenames></author></authors><title>Capacitated Domination: Constant Factor Approximation for Planar Graphs</title><categories>cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the capacitated domination problem, which models a
service-requirement assigning scenario and which is also a generalization of
the dominating set problem. In this problem, we are given a graph with three
parameters defined on the vertex set, which are cost, capacity, and demand. The
objective of this problem is to compute a demand assignment of least cost, such
that the demand of each vertex is fully-assigned to some of its closed
neighbours without exceeding the amount of capacity they provide.
  In this paper, we provide the first constant factor approximation for this
problem on planar graphs, based on a new perspective on the hierarchical
structure of outer-planar graphs. We believe that this new perspective and
technique can be applied to other capacitated covering problems to help tackle
vertices of large degrees.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4607</identifier>
 <datestamp>2015-03-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4607</id><created>2011-08-23</created><updated>2015-03-23</updated><authors><author><keyname>Lin</keyname><forenames>Tianrong</forenames></author></authors><title>Simple characterizations for commutativity of quantum weakest
  preconditions</title><categories>cs.LO quant-ph</categories><comments>Re-written, comments are welcome</comments><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  In a recent letter [Information Processing Letters~104 (2007) 152-158], it
has shown some sufficient conditions for commutativity of quantum weakest
preconditions. This paper provides some alternative and simple
characterizations for the commutativity of quantum weakest preconditions, i.e.,
Theorem 3.1, Theorem 3.2 and Proposition 3.3 in what follows. We also show that
to characterize the commutativity of quantum weakest preconditions in terms of
$[M,N]$ ($=MN-NM$) is hard in the sense of Proposition 4.1 and Proposition 4.2.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4618</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4618</id><created>2011-08-23</created><authors><author><keyname>Mpanza</keyname><forenames>LJ</forenames></author><author><keyname>Marwala</keyname><forenames>T.</forenames></author></authors><title>Artificial Neural Network and Rough Set for HV Bushings Condition
  Monitoring</title><categories>cs.NE</categories><comments>IEEE INES 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Most transformer failures are attributed to bushings failures. Hence it is
necessary to monitor the condition of bushings. In this paper three methods are
developed to monitor the condition of oil filled bushing. Multi-layer
perceptron (MLP), Radial basis function (RBF) and Rough Set (RS) models are
developed and combined through majority voting to form a committee. The MLP
performs better that the RBF and the RS is terms of classification accuracy.
The RBF is the fasted to train. The committee performs better than the
individual models. The diversity of models is measured to evaluate their
similarity when used in the committee.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4642</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4642</id><created>2011-08-23</created><authors><author><keyname>Kelk</keyname><forenames>Steven</forenames></author></authors><title>A note on efficient computation of hybridization number via softwired
  clusters</title><categories>q-bio.PE cs.DS</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Here we present a new fixed parameter tractable algorithm to compute the
hybridization number r of two rooted binary phylogenetic trees on taxon set X
in time (6r)^r.poly(n), where n=|X|. The novelty of this approach is that it
avoids the use of Maximum Acyclic Agreement Forests (MAAFs) and instead
exploits the equivalence of the problem with a related problem from the
softwired clusters literature. This offers an alternative perspective on the
underlying combinatorial structure of the hybridization number problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4658</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4658</id><created>2011-08-23</created><authors><author><keyname>Freeman</keyname><forenames>Linton C.</forenames></author></authors><title>A Well-Behaved Alternative to the Modularity Index</title><categories>physics.soc-ph cs.SI</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper reviews the modularity index and suggests an alternative index of
the quality of a division of a network into subsets.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4664</identifier>
 <datestamp>2011-11-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4664</id><created>2011-08-23</created><updated>2011-11-28</updated><authors><author><keyname>Civril</keyname><forenames>Ali</forenames></author></authors><title>Sparse Approximation is Hard</title><categories>cs.CC cs.IT math.IT</categories><comments>This paper has been withdrawn by the author as the results are
  subsumed by another straightforward reduction</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Given a redundant dictionary $\Phi$, represented by an $M \times N$ matrix
($\Phi \in \mathbb{R}^{M \times N}$) and a target signal $y \in \mathbb{R}^M$,
the \emph{sparse approximation problem} asks to find an approximate
representation of $y$ using a linear combination of at most $k$ atoms. In this
paper, a new complexity theoretic hardness result for sparse approximation
problem is presented via considering a different measure of quality for the
solution. It is argued that, from an algorithmic standpoint, the problem is
more meaningful if it asks to maximize the norm of the target signal's
projection onto the selected atoms which are represented by column vectors.
Then, a multiplicative inapproximability result is established with this new
measure, under a reasonable complexity theoretic assumption. This result in
turn implies additive inapproximability for the problem with the standard
measure. Specifically, if $ZPP \neq NP$, all polynomial time algorithms which
provide a $k$-sparse vector $x$ should satisfy
  $$ {\|y-\Phi x\|}_2^2 \geq (1-c){\|y-\Phi x^*\|}_2^2 + c {\|y\|}_2^2, $$
  \noindent for $1/4(1-1/e) &gt; c \geq 0$ where $x^*$ is the optimal $k$-sparse
solution. This result provides a quantification of the hardness for the case
$y-\Phi x^* = 0$, revealing more details about the inherent structure of the
problem.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4675</identifier>
 <datestamp>2011-08-24</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4675</id><created>2011-08-23</created><authors><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Goodrich</keyname><forenames>Michael T.</forenames></author><author><keyname>L&#xf6;ffler</keyname><forenames>Maarten</forenames></author><author><keyname>Strash</keyname><forenames>Darren</forenames></author><author><keyname>Trott</keyname><forenames>Lowell</forenames></author></authors><title>Category-Based Routing in Social Networks: Membership Dimension and the
  Small-World Phenomenon (Short)</title><categories>cs.SI cs.DS physics.soc-ph</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A classic experiment by Milgram shows that individuals can route messages
along short paths in social networks, given only simple categorical information
about recipients (such as &quot;he is a prominent lawyer in Boston&quot; or &quot;she is a
Freshman sociology major at Harvard&quot;). That is, these networks have very short
paths between pairs of nodes (the so-called small-world phenomenon); moreover,
participants are able to route messages along these paths even though each
person is only aware of a small part of the network topology. Some sociologists
conjecture that participants in such scenarios use a greedy routing strategy in
which they forward messages to acquaintances that have more categories in
common with the recipient than they do, and similar strategies have recently
been proposed for routing messages in dynamic ad-hoc networks of mobile
devices. In this paper, we introduce a network property called membership
dimension, which characterizes the cognitive load required to maintain
relationships between participants and categories in a social network. We show
that any connected network has a system of categories that will support greedy
routing, but that these categories can be made to have small membership
dimension if and only if the underlying network exhibits the small-world
phenomenon.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4698</identifier>
 <datestamp>2011-08-31</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4698</id><created>2011-08-23</created><updated>2011-08-30</updated><authors><author><keyname>Estanjini</keyname><forenames>Reza Moazzez</forenames></author><author><keyname>Ding</keyname><forenames>Xu Chu</forenames></author><author><keyname>Lahijanian</keyname><forenames>Morteza</forenames></author><author><keyname>Wang</keyname><forenames>Jing</forenames></author><author><keyname>Belta</keyname><forenames>Calin A.</forenames></author><author><keyname>Paschalidis</keyname><forenames>Ioannis Ch.</forenames></author></authors><title>Least Squares Temporal Difference Actor-Critic Methods with Applications
  to Robot Motion Control</title><categories>cs.RO cs.SY math.OC</categories><comments>Technical report accompanying an accepted paper to CDC 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of finding a control policy for a Markov Decision
Process (MDP) to maximize the probability of reaching some states while
avoiding some other states. This problem is motivated by applications in
robotics, where such problems naturally arise when probabilistic models of
robot motion are required to satisfy temporal logic task specifications. We
transform this problem into a Stochastic Shortest Path (SSP) problem and
develop a new approximate dynamic programming algorithm to solve it. This
algorithm is of the actor-critic type and uses a least-square temporal
difference learning method. It operates on sample paths of the system and
optimizes the policy within a pre-specified class parameterized by a
parsimonious set of parameters. We show its convergence to a policy
corresponding to a stationary point in the parameters' space. Simulation
results confirm the effectiveness of the proposed solution.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4705</identifier>
 <datestamp>2015-07-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4705</id><created>2011-08-23</created><updated>2012-02-26</updated><authors><author><keyname>Bannister</keyname><forenames>Michael J.</forenames></author><author><keyname>Eppstein</keyname><forenames>David</forenames></author><author><keyname>Simons</keyname><forenames>Joseph A.</forenames></author></authors><title>Inapproximability of Orthogonal Compaction</title><categories>cs.CG</categories><comments>Updated to the final version to appear in the Journal of Graph
  Algorithms and Applications</comments><journal-ref>J. Graph Algorithms &amp; Applications 16(3): 651-673, 2012</journal-ref><doi>10.7155/jgaa.00263</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We show that several problems of compacting orthogonal graph drawings to use
the minimum number of rows, area, length of longest edge or total edge length
cannot be approximated better than within a polynomial factor of optimal in
polynomial time unless P = NP. We also provide a fixed-parameter-tractable
algorithm for testing whether a drawing can be compacted to a small number of
rows.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4706</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4706</id><created>2011-08-23</created><authors><author><keyname>Chang</keyname><forenames>Stephen</forenames></author><author><keyname>Clements</keyname><forenames>John</forenames></author><author><keyname>Barzilay</keyname><forenames>Eli</forenames></author><author><keyname>Felleisen</keyname><forenames>Matthias</forenames></author></authors><title>Stepping Lazy Programs</title><categories>cs.PL</categories><comments>submitted to ICFP 2011</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Debugging lazy functional programs poses serious challenges. In support of
the &quot;stop, examine, and resume&quot; debugging style of imperative languages, some
debugging tools abandon lazy evaluation. Other debuggers preserve laziness but
present it in a way that may confuse programmers because the focus of
evaluation jumps around in a seemingly random manner.
  In this paper, we introduce a supplemental tool, the algebraic program
stepper. An algebraic stepper shows computation as a mathematical calculation.
Algebraic stepping could be particularly useful for novice programmers or
programmers new to lazy programming. Mathematically speaking, an algebraic
stepper renders computation as the standard rewriting sequence of a lazy
lambda-calculus. Our novel lazy semantics introduces lazy evaluation as a form
of parallel program rewriting. It represents a compromise between Launchbury's
store-based semantics and a simple, axiomatic description of lazy computation
as sharing-via-parameters. Finally, we prove that the stepper's run-time
machinery correctly reconstructs the standard rewriting sequence.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4709</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4709</id><created>2011-08-23</created><authors><author><keyname>Xie</keyname><forenames>Yao</forenames></author><author><keyname>Gunduz</keyname><forenames>Deniz</forenames></author><author><keyname>Goldsmith</keyname><forenames>Andrea J.</forenames></author></authors><title>The Diversity-Multiplexing-Delay Tradeoff in MIMO Multihop Networks with
  ARQ</title><categories>cs.IT math.IT</categories><comments>Submitted to IEEE Trans. Info. Theory</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We study the tradeoff between reliability, data rate, and delay for
half-duplex MIMO multihop networks that utilize the
automatic-retransmission-request (ARQ) protocol both in the asymptotic high
signal-to-noise ratio (SNR) regime and in the finite SNR regime. We propose
novel ARQ protocol designs that optimize these tradeoffs. We first derive the
diversity-multiplexing-delay tradeoff (DMDT) in the high SNR regime, where the
delay is caused only by retransmissions. This asymptotic DMDT shows that the
performance of an N node network is limited by the weakest three-node
sub-network, and the performance of a three-node sub-network is determined by
its weakest link, and, hence, the optimal ARQ protocol needs to equalize the
performance on each link by allocating ARQ window sizes optimally. This
equalization is captured through a novel Variable Block-Length (VBL) ARQ
protocol that we propose, which achieves the optimal DMDT.
  We then consider the DMDT in the finite SNR regime, where the delay is caused
by both the ARQ retransmissions and queueing. We characterize the finite SNR
DMDT of the fixed ARQ protocol, when an end-to-end delay constraint is imposed,
by deriving the probability of message error using an approach that couples the
information outage analysis with the queueing network analysis. The exponent of
the probability of deadline violation demonstrates that the system performance
is again limited by the weakest three-node sub-network. The queueing delay
changes the consideration for optimal ARQ design: more retransmissions reduce
decoding error by lowering the information outage probability, but may also
increase message drop rate due to delay deadline violations. Hence, the optimal
ARQ should balance link performance while avoiding significant delay.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4723</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4723</id><created>2011-08-23</created><authors><author><keyname>Ren</keyname><forenames>Jie</forenames></author><author><keyname>Wong</keyname><forenames>Kai-Kit</forenames></author><author><keyname>Hou</keyname><forenames>Jianjun</forenames></author></authors><title>Self-Optimized OFDMA via Multiple Stackelberg Leader Equilibrium</title><categories>cs.IT cs.GT math.IT math.OC nlin.AO</categories><comments>24 pages, 6 figures</comments><license>http://creativecommons.org/licenses/publicdomain/</license><abstract>  The challenge of self-optimization for orthogonal frequency-division
multiple-access (OFDMA) interference channels is that users inherently compete
harmfully and simultaneous water-filling (WF) would lead to a
Pareto-inefficient equilibrium. To overcome this, we first introduce the role
of environmental interference derivative in the WF optimization of the
interactive OFDMA game and then study the environmental interference derivative
properties of Stackelberg equilibrium (SE). Such properties provide important
insights to devise free OFDMA games for achieving various SEs, realizable by
simultaneous WF regulated by specifically chosen operational interference
derivatives. We also present a definition of all-Stackelberg-leader equilibrium
(ASE) where users are all foresighted to each other, albeit each with only
local channel state information (CSI), and can thus most effectively reconcile
their competition to maximize the user rates. We show that under certain
environmental conditions, the free games are both unique and optimal.
Simulation results reveal that our distributed ASE game achieves the
performance very close to the near-optimal centralized iterative spectrum
balancing (ISB) method in [5].
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4729</identifier>
 <datestamp>2015-05-30</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4729</id><created>2011-08-23</created><updated>2011-09-24</updated><authors><author><keyname>Hayashi</keyname><forenames>Yukio</forenames></author><author><keyname>Meguro</keyname><forenames>Yuki</forenames></author></authors><title>Self-organized network design by link survivals and shortcuts</title><categories>physics.soc-ph cs.SI</categories><comments>15 pages, 8 figures, 2 tables</comments><journal-ref>Physica A 391, pp.872-879, 2012</journal-ref><doi>10.1016/j.physa.2011.08.047</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  One of the challenges for future infrastructures is how to design a network
with high efficiency and strong connectivity at low cost. We propose
self-organized geographical networks beyond the vulnerable scale-free structure
found in many real systems. The networks with spatially concentrated nodes
emerge through link survival and path reinforcement on routing flows in a
wireless environment with a constant transmission range of a node. In
particular, we show that adding some shortcuts induces both the small-world
effect and a significant improvement of the robustness to the same level as in
the optimal bimodal networks. Such a simple universal mechanism will open
prospective ways for several applications in wide-area ad hoc networks, smart
grids, and urban planning.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4744</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4744</id><created>2011-08-23</created><authors><author><keyname>Ha</keyname><forenames>Bach Q.</forenames></author><author><keyname>Hartline</keyname><forenames>Jason D.</forenames></author></authors><title>Mechanism Design via Consensus Estimates, Cross Checking, and Profit
  Extraction</title><categories>cs.GT</categories><comments>12 pages, 2 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  There is only one technique for prior-free optimal mechanism design that
generalizes beyond the structurally benevolent setting of digital goods. This
technique uses random sampling to estimate the distribution of agent values and
then employs the Bayesian optimal mechanism for this estimated distribution on
the remaining players. Though quite general, even for digital goods, this
random sampling auction has a complicated analysis and is known to be
suboptimal. To overcome these issues we generalize the consensus technique from
Goldberg and Hartline (2003) to structurally rich environments that include,
e.g., single-minded combinatorial auctions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4753</identifier>
 <datestamp>2011-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4753</id><created>2011-08-24</created><updated>2011-08-25</updated><authors><author><keyname>Blondeau</keyname><forenames>C&#xe9;line</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Canteaut</keyname><forenames>Anne</forenames><affiliation>INRIA Rocquencourt</affiliation></author><author><keyname>Charpin</keyname><forenames>Pascale</forenames><affiliation>INRIA Rocquencourt</affiliation></author></authors><title>Differential properties of functions x -&gt; x^{2^t-1} -- extended version</title><categories>cs.CR cs.DM cs.IT math.IT</categories><comments>2011</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We provide an extensive study of the differential properties of the functions
$x\mapsto x^{2^t-1}$ over $\F$, for $2 \leq t \leq n-1$. We notably show that
the differential spectra of these functions are determined by the number of
roots of the linear polynomials $x^{2^t}+bx^2+(b+1)x$ where $b$ varies in
$\F$.We prove a strong relationship between the differential spectra of
$x\mapsto x^{2^t-1}$ and $x\mapsto x^{2^{s}-1}$ for $s= n-t+1$. As a direct
consequence, this result enlightens a connection between the differential
properties of the cube function and of the inverse function. We also determine
the complete differential spectra of $x \mapsto x^7$ by means of the value of
some Kloosterman sums, and of $x \mapsto x^{2^t-1}$ for $t \in \{\lfloor
n/2\rfloor, \lceil n/2\rceil+1, n-2\}$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4770</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4770</id><created>2011-08-24</created><authors><author><keyname>Zuzak</keyname><forenames>Ivan</forenames><affiliation>School of Electrical Engineering and Computing, University of Zagreb, Croatia</affiliation></author><author><keyname>Ivankovic</keyname><forenames>Marko</forenames><affiliation>Google Inc., Zurich, Switzerland</affiliation></author><author><keyname>Budiselic</keyname><forenames>Ivan</forenames><affiliation>School of Electrical Engineering and Computing, University of Zagreb, Croatia</affiliation></author></authors><title>A Classification Framework for Web Browser Cross-Context Communication</title><categories>cs.SE</categories><comments>23 pages, 5 figures. This paper contains a more systematic research
  of cross-context communication systems listed on the pmrpc project website,
  see http://code.google.com/p/pmrpc/wiki/IWCProjects</comments><acm-class>D.2.11; H.4.3; D.4.4</acm-class><license>http://creativecommons.org/licenses/by/3.0/</license><abstract>  Demand for more advanced Web applications is the driving force behind Web
browser evolution. Recent requirements for Rich Internet Applications, such as
mashing-up data and background processing, are emphasizing the need for
building and executing Web applications as a coordination of browser execution
contexts. Since development of such Web applications depends on cross-context
communication, many browser primitives and client-side frameworks have been
developed to support this communication. In this paper we present a
systematization of cross-context communication systems for Web browsers. Based
on an analysis of previous research, requirements for modern Web applications
and existing systems, we extract a framework for classifying cross-context
communica-tion systems. Using the framework, we evaluate the current ecosystem
of cross-context communication and outline directions for future Web research
and engineering.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4772</identifier>
 <datestamp>2013-12-03</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4772</id><created>2011-08-24</created><updated>2013-11-30</updated><authors><author><keyname>Johansson</keyname><forenames>Fredrik</forenames></author></authors><title>A fast algorithm for reversion of power series</title><categories>cs.SC</categories><comments>Updated version; accepted for publication in Mathematics of
  Computation; corrected a bibliography entry</comments><msc-class>68W30</msc-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We give an algorithm for reversion of formal power series, based on an
efficient way to implement the Lagrange inversion formula. Our algorithm
requires $O(n^{1/2}(M(n) + MM(n^{1/2})))$ operations where $M(n)$ and $MM(n)$
are the costs of polynomial and matrix multiplication respectively. This
matches the asymptotic complexity of an algorithm of Brent and Kung, but we
achieve a constant factor speedup whose magnitude depends on the polynomial and
matrix multiplication algorithms used. Benchmarks confirm that the algorithm
performs well in practice.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4785</identifier>
 <datestamp>2013-05-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4785</id><created>2011-08-24</created><authors><author><keyname>Lancaster</keyname><forenames>David</forenames></author></authors><title>Searching for Nodes in Random Graphs</title><categories>cond-mat.stat-mech cs.NI cs.SI physics.soc-ph</categories><comments>13 pages, 12 figures</comments><doi>10.1103/PhysRevE.84.056107</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of searching for a node on a labelled random graph
according to a greedy algorithm that selects a route to the desired node using
metric information on the graph. Motivated by peer-to-peer networks two types
of random graph are proposed with properties particularly amenable to this kind
of algorithm. We derive equations for the probability that the search is
successful and also study the number of hops required, finding both numerical
and analytic evidence of a transition as the number of links is varied.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4801</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4801</id><created>2011-08-24</created><authors><author><keyname>Subbian</keyname><forenames>Karthik</forenames></author><author><keyname>Melville</keyname><forenames>Prem</forenames></author></authors><title>Supervised Rank Aggregation for Predicting Influence in Networks</title><categories>cs.SI cs.GT cs.IR physics.soc-ph</categories><license>http://creativecommons.org/licenses/by-nc-sa/3.0/</license><abstract>  Much work in Social Network Analysis has focused on the identification of the
most important actors in a social network. This has resulted in several
measures of influence and authority. While most of such sociometrics (e.g.,
PageRank) are driven by intuitions based on an actors location in a network,
asking for the &quot;most influential&quot; actors in itself is an ill-posed question,
unless it is put in context with a specific measurable task. Constructing a
predictive task of interest in a given domain provides a mechanism to
quantitatively compare different measures of influence. Furthermore, when we
know what type of actionable insight to gather, we need not rely on a single
network centrality measure. A combination of measures is more likely to capture
various aspects of the social network that are predictive and beneficial for
the task. Towards this end, we propose an approach to supervised rank
aggregation, driven by techniques from Social Choice Theory. We illustrate the
effectiveness of this method through experiments on Twitter and citation
networks.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4803</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4803</id><created>2011-08-24</created><authors><author><keyname>Gutin</keyname><forenames>G.</forenames></author><author><keyname>Yeo</keyname><forenames>A.</forenames></author></authors><title>Constraint Satisfaction Problems Parameterized Above or Below Tight
  Bounds: A Survey</title><categories>cs.DS cs.CC cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider constraint satisfaction problems parameterized above or below
tight bounds. One example is MaxSat parameterized above $m/2$: given a CNF
formula $F$ with $m$ clauses, decide whether there is a truth assignment that
satisfies at least $m/2+k$ clauses, where $k$ is the parameter. Among other
problems we deal with are MaxLin2-AA (given a system of linear equations over
$\mathbb{F}_2$ in which each equation has a positive integral weight, decide
whether there is an assignment to the variables that satisfies equations of
total weight at least $W/2+k$, where $W$ is the total weight of all equations),
Max-$r$-Lin2-AA (the same as MaxLin2-AA, but each equation has at most $r$
variables, where $r$ is a constant) and Max-$r$-Sat-AA (given a CNF formula $F$
with $m$ clauses in which each clause has at most $r$ literals, decide whether
there is a truth assignment satisfying at least $\sum_{i=1}^m(1-2^{r_i})+k$
clauses, where $k$ is the parameter, $r_i$ is the number of literals in Clause
$i$, and $r$ is a constant). We also consider Max-$r$-CSP-AA, a natural
generalization of both Max-$r$-Lin2-AA and Max-$r$-Sat-AA, order (or,
permutation) constraint satisfaction problems of arities 2 and 3 parameterized
above the average value and some other problems related to MaxSat. We discuss
results, both polynomial kernels and parameterized algorithms, obtained for the
problems mainly in the last few years as well as some open questions.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4804</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4804</id><created>2011-08-24</created><authors><author><keyname>Dvo&#x159;&#xe1;k</keyname><forenames>Wolfgang</forenames></author><author><keyname>Morak</keyname><forenames>Michael</forenames></author><author><keyname>Nopp</keyname><forenames>Clemens</forenames></author><author><keyname>Woltran</keyname><forenames>Stefan</forenames></author></authors><title>dynPARTIX - A Dynamic Programming Reasoner for Abstract Argumentation</title><categories>cs.AI</categories><comments>The paper appears in the Proceedings of the 19th International
  Conference on Applications of Declarative Programming and Knowledge
  Management (INAP 2011)</comments><acm-class>I.2.3</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The aim of this paper is to announce the release of a novel system for
abstract argumentation which is based on decomposition and dynamic programming.
We provide first experimental evaluations to show the feasibility of this
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4816</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4816</id><created>2011-08-24</created><authors><author><keyname>Harrison</keyname><forenames>William</forenames></author><author><keyname>Walsh</keyname><forenames>Tim</forenames></author><author><keyname>Biggar</keyname><forenames>Paul</forenames></author></authors><title>Some Measurements of Nullable and Non-Nullable Parameter Declarations in
  Relation to Software Malleability</title><categories>cs.PL</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The usual advantages put forward for including nullability declarations in
the type systems of programming languages are that they improve program
reliability or performance. But there is another, entirely different, reason
for doing so. In the right context, this information enables the software
artifacts we produce, the objects and methods, to exhibit much greater
malleability. For declaratively typed languages, we can obtain greater software
malleability by extending the model of method call so that assurance of a
method's availability can be provided by any non-nullable parameter, not simply
the target parameter, and by allowing the method's implementation to reside in
classes or objects other than the target..
  This paper examines the question of whether this hypothetical improvement in
software malleability is consistent with existing programming practice by
examining the question of the extent to which methods in existing software have
multiplicities of non-nullable parameters. The circumstance occurs frequently
enough to provide an important reason to introduce declarations of nullability
into programming languages.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4828</identifier>
 <datestamp>2011-11-16</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4828</id><created>2011-08-24</created><authors><author><keyname>Vanclay</keyname><forenames>Jerome K</forenames></author></authors><title>Publication patterns of award-winning forest scientists and implications
  for the ERA journal ranking</title><categories>cs.DL</categories><comments>12 pages, 4 figures, 3 tables, 49 references; Journal of Informetrics
  (2011)</comments><journal-ref>Journal of Informetrics 6 (2012) 19-26</journal-ref><doi>10.1016/j.joi.2011.08.003</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Publication patterns of 79 forest scientists awarded major international
forestry prizes during 1990-2010 were compared with the journal classification
and ranking promoted as part of the 'Excellence in Research for Australia'
(ERA) by the Australian Research Council. The data revealed that these
scientists exhibited an elite publication performance during the decade before
and two decades following their first major award. An analysis of their 1703
articles in 431 journals revealed substantial differences between the journal
choices of these elite scientists and the ERA classification and ranking of
journals. Implications from these findings are that additional
cross-classifications should be added for many journals, and there should be an
adjustment to the ranking of several journals relevant to the ERA Field of
Research classified as 0705 Forestry Sciences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4843</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4843</id><created>2011-08-22</created><authors><author><keyname>Dessalles</keyname><forenames>Jean-Louis</forenames><affiliation>INFRES, LTCI</affiliation></author></authors><title>Simplicity Effects in the Experience of Near-Miss</title><categories>cs.OH cs.CC</categories><comments>jld-11040601; Proceedings of the 33rd Annual Conference of the
  Cognitive Science Society, Austin, TX : United States (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Near-miss experiences are one of the main sources of intense emotions.
Despite people's consistency when judging near-miss situations and when
communicating about them, there is no integrated theoretical account of the
phenomenon. In particular, individuals' reaction to near-miss situations is not
correctly predicted by rationality-based or probability-based optimization. The
present study suggests that emotional intensity in the case of near-miss is in
part predicted by Simplicity Theory.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4853</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4853</id><created>2011-08-24</created><updated>2011-10-28</updated><authors><author><keyname>Oaku</keyname><forenames>Toshinori</forenames></author></authors><title>Algorithms for integrals of holonomic functions over domains defined by
  polynomial inequalities</title><categories>cs.SC math.CA</categories><comments>corrected typos; Sections 5 and 6 were slightly revised with results
  unchanged</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present an algorithm for computing a holonomic system for a definite
integral of a holonomic function over a domain defined by polynomial
inequalities. If the integrand satisfies a holonomic difference-differential
system including parameters, then a holonomic difference-differential system
for the integral can also be computed. In the algorithm, holonomic
distributions (generalized functions in the sense of L. Schwartz) are
inevitably involved even if the integrand is a usual function.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4879</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4879</id><created>2011-08-24</created><authors><author><keyname>Tracey</keyname><forenames>Brendan</forenames></author><author><keyname>Wolpert</keyname><forenames>David</forenames></author><author><keyname>Alonso</keyname><forenames>Juan J.</forenames></author></authors><title>Using Supervised Learning to Improve Monte Carlo Integral Estimation</title><categories>stat.ML cs.CE cs.NA stat.CO</categories><comments>18 pages, 10 figures, originally published by AIAA at the 13th
  Non-Deterministic Approaches Conference</comments><journal-ref>13th AIAA Non-Deterministic Approaches Conference, Denver, CO,
  April 2011, AIAA Paper 2011-1843</journal-ref><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Monte Carlo (MC) techniques are often used to estimate integrals of a
multivariate function using randomly generated samples of the function. In
light of the increasing interest in uncertainty quantification and robust
design applications in aerospace engineering, the calculation of expected
values of such functions (e.g. performance measures) becomes important.
However, MC techniques often suffer from high variance and slow convergence as
the number of samples increases. In this paper we present Stacked Monte Carlo
(StackMC), a new method for post-processing an existing set of MC samples to
improve the associated integral estimate. StackMC is based on the supervised
learning techniques of fitting functions and cross validation. It should reduce
the variance of any type of Monte Carlo integral estimate (simple sampling,
importance sampling, quasi-Monte Carlo, MCMC, etc.) without adding bias. We
report on an extensive set of experiments confirming that the StackMC estimate
of an integral is more accurate than both the associated unprocessed Monte
Carlo estimate and an estimate based on a functional fit to the MC samples.
These experiments run over a wide variety of integration spaces, numbers of
sample points, dimensions, and fitting functions. In particular, we apply
StackMC in estimating the expected value of the fuel burn metric of future
commercial aircraft and in estimating sonic boom loudness measures. We compare
the efficiency of StackMC with that of more standard methods and show that for
negligible additional computational cost significant increases in accuracy are
gained.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4882</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4882</id><created>2011-08-22</created><authors><author><keyname>Dessalles</keyname><forenames>Jean-Louis</forenames><affiliation>INFRES, LTCI</affiliation></author></authors><title>Emotion in good luck and bad luck: predictions from simplicity theory</title><categories>cs.OH cs.CC</categories><comments>jld-10020801; Proceedings of the 32nd Annual Conference of the
  Cognitive Science Society, Austin, TX : United States (2010)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  The feeling of good or bad luck occurs whenever there is an emotion contrast
between an event and an easily accessible counterfactual alternative. This
study suggests that cognitive simplicity plays a key role in the human ability
to experience good and bad luck after the occurrence of an event.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4884</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4884</id><created>2011-08-22</created><authors><author><keyname>Dessalles</keyname><forenames>Jean-Louis</forenames><affiliation>INFRES, LTCI</affiliation></author></authors><title>A structural model of intuitive probability</title><categories>cs.OH cs.CC</categories><comments>jld-06020601; Proceedings of the seventh International Conference on
  Cognitive Modeling, Trieste, IT : Italy (2006)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Though the ability of human beings to deal with probabilities has been put
into question, the assessment of rarity is a crucial competence underlying much
of human decision-making and is pervasive in spontaneous narrative behaviour.
This paper proposes a new model of rarity and randomness assessment, designed
to be cognitively plausible. Intuitive randomness is defined as a function of
structural complexity. It is thus possible to assign probability to events
without being obliged to consider the set of alternatives. The model is tested
on Lottery sequences and compared with subjects' preferences.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4891</identifier>
 <datestamp>2011-08-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4891</id><created>2011-08-24</created><authors><author><keyname>Wernhard</keyname><forenames>Christoph</forenames></author></authors><title>Computing with Logic as Operator Elimination: The ToyElim System</title><categories>cs.AI cs.LO</categories><comments>Appears in the Proceedings of the 25th Workshop on Logic Programming
  (WLP 2011)</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A prototype system is described whose core functionality is, based on
propositional logic, the elimination of second-order operators, such as Boolean
quantifiers and operators for projection, forgetting and circumscription. This
approach allows to express many representational and computational tasks in
knowledge representation - for example computation of abductive explanations
and models with respect to logic programming semantics - in a uniform
operational system, backed by a uniform classical semantic framework.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4919</identifier>
 <datestamp>2012-09-18</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4919</id><created>2011-08-24</created><updated>2012-02-24</updated><authors><author><keyname>Vanderhoydonc</keyname><forenames>Ynte</forenames></author><author><keyname>Vanroose</keyname><forenames>Wim</forenames></author></authors><title>Numerical extraction of a macroscopic pde and a lifting operator from a
  lattice Boltzmann model</title><categories>cs.CE physics.comp-ph physics.flu-dyn</categories><comments>submitted to SIAM MMS</comments><journal-ref>SIAM Multiscale Modelling &amp; Simulation, Vol 10, No. 3 pp 766-791
  (2012)</journal-ref><doi>10.1137/110842739</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Lifting operators play an important role in starting a lattice Boltzmann
model from a given initial density. The density, a macroscopic variable, needs
to be mapped to the distribution functions, mesoscopic variables, of the
lattice Boltzmann model. Several methods proposed as lifting operators have
been tested and discussed in the literature. The most famous methods are an
analytically found lifting operator, like the Chapman-Enskog expansion, and a
numerical method, like the Constrained Runs algorithm, to arrive at an implicit
expression for the unknown distribution functions with the help of the density.
This paper proposes a lifting operator that alleviates several drawbacks of
these existing methods. In particular, we focus on the computational expense
and the analytical work that needs to be done. The proposed lifting operator, a
numerical Chapman-Enskog expansion, obtains the coefficients of the
Chapman-Enskog expansion numerically. Another important feature of the use of
lifting operators is found in hybrid models. There the lattice Boltzmann model
is spatially coupled with a model based on a more macroscopic description, for
example an advection-diffusion-reaction equation. In one part of the domain,
the lattice Boltzmann model is used, while in another part, the more
macroscopic model. Such a hybrid coupling results in missing data at the
interfaces between the different models. A lifting operator is then an
important tool since the lattice Boltzmann model is typically described by more
variables than a model based on a macroscopic partial differential equation.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4940</identifier>
 <datestamp>2012-12-21</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4940</id><created>2011-08-24</created><updated>2012-08-19</updated><authors><author><keyname>Datta</keyname><forenames>Nilanjana</forenames></author><author><keyname>Hsieh</keyname><forenames>Min-Hsiu</forenames></author><author><keyname>Wilde</keyname><forenames>Mark M.</forenames></author></authors><title>Quantum rate distortion, reverse Shannon theorems, and source-channel
  separation</title><categories>quant-ph cs.IT math.IT</categories><comments>15 pages, 4 figures; v2: proof that the entanglement-assisted quantum
  rate distortion function is a single-letter lower bound on the unassisted
  quantum rate distortion function; v3: accepted into IEEE Transactions on
  Information Theory</comments><journal-ref>IEEE Transactions on Information Theory vol. 59, no. 1, pp.
  615-630 (January 2013)</journal-ref><doi>10.1109/TIT.2012.2215575</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We derive quantum counterparts of two key theorems of classical information
theory, namely, the rate distortion theorem and the source-channel separation
theorem. The rate-distortion theorem gives the ultimate limits on lossy data
compression, and the source-channel separation theorem implies that a two-stage
protocol consisting of compression and channel coding is optimal for
transmitting a memoryless source over a memoryless channel. In spite of their
importance in the classical domain, there has been surprisingly little work in
these areas for quantum information theory. In the present paper, we prove that
the quantum rate distortion function is given in terms of the regularized
entanglement of purification. We also determine a single-letter expression for
the entanglement-assisted quantum rate distortion function, and we prove that
it serves as a lower bound on the unassisted quantum rate distortion function.
This implies that the unassisted quantum rate distortion function is
non-negative and generally not equal to the coherent information between the
source and distorted output (in spite of Barnum's conjecture that the coherent
information would be relevant here). Moreover, we prove several quantum
source-channel separation theorems. The strongest of these are in the
entanglement-assisted setting, in which we establish a necessary and sufficient
codition for transmitting a memoryless source over a memoryless quantum channel
up to a given distortion.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4942</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4942</id><created>2011-08-24</created><authors><author><keyname>Dvo&#x159;&#xe1;k</keyname><forenames>Wolfgang</forenames></author><author><keyname>Gaggl</keyname><forenames>Sarah Alice</forenames></author><author><keyname>Wallner</keyname><forenames>Johannes</forenames></author><author><keyname>Woltran</keyname><forenames>Stefan</forenames></author></authors><title>Making Use of Advances in Answer-Set Programming for Abstract
  Argumentation Systems</title><categories>cs.AI</categories><comments>Paper appears in the Proceedings of the 19th International Conference
  on Applications of Declarative Programming and Knowledge Management (INAP
  2011)</comments><acm-class>I.2.3; I.2.4</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Dung's famous abstract argumentation frameworks represent the core formalism
for many problems and applications in the field of argumentation which
significantly evolved within the last decade. Recent work in the field has thus
focused on implementations for these frameworks, whereby one of the main
approaches is to use Answer-Set Programming (ASP). While some of the
argumentation semantics can be nicely expressed within the ASP language, others
required rather cumbersome encoding techniques. Recent advances in ASP systems,
in particular, the metasp optimization frontend for the ASP-package
gringo/claspD provides direct commands to filter answer sets satisfying certain
subset-minimality (or -maximality) constraints. This allows for much simpler
encodings compared to the ones in standard ASP language. In this paper, we
experimentally compare the original encodings (for the argumentation semantics
based on preferred, semi-stable, and respectively, stage extensions) with new
metasp encodings. Moreover, we provide novel encodings for the recently
introduced resolution-based grounded semantics. Our experimental results
indicate that the metasp approach works well in those cases where the
complexity of the encoded problem is adequately mirrored within the metasp
approach.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4953</identifier>
 <datestamp>2011-08-29</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4953</id><created>2011-08-24</created><updated>2011-08-25</updated><authors><author><keyname>Fox</keyname><forenames>Jacob</forenames></author></authors><title>Constructing dense graphs with sublinear Hadwiger number</title><categories>math.CO cs.DM</categories><comments>10 pages</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Mader asked to explicitly construct dense graphs for which the size of the
largest clique minor is sublinear in the number of vertices. Such graphs exist
as a random graph almost surely has this property. This question and variants
were popularized by Thomason over several articles. We answer these questions
by showing how to explicitly construct such graphs using blow-ups of small
graphs with this property. This leads to the study of a fractional variant of
the clique minor number, which may be of independent interest.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4956</identifier>
 <datestamp>2012-06-25</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4956</id><created>2011-08-24</created><authors><author><keyname>Adamatzky</keyname><forenames>Andrew</forenames></author></authors><title>Slime mould solves maze in one pass ... assisted by gradient of
  chemo-attractants</title><categories>nlin.PS cs.ET q-bio.CB</categories><journal-ref>IEEE Trans on NanoBioscience Volume: 11 , Issue: 2, 2012, Page(s):
  131 - 134</journal-ref><doi>10.1109/TNB.2011.2181978</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Plasmodium of Physarum polycephalum is a large cell, visible by unaided eye,
which exhibits sophisticated patterns of foraging behaviour. The plasmodium's
behaviour is well interpreted in terms of computation, where data are spatially
extended configurations of nutrients and obstacles, and results of computation
are networks of protoplasmic tubes formed by the plasmodium. In laboratory
experiments and numerical simulation we show that if plasmodium of Physarum is
inoculated in a maze's peripheral channel and an oat flake (source of
attractants) in a the maze's central chamber then the plasmodium grows toward
target oat flake and connects the flake with the site of original inoculation
with a pronounced protoplasmic tube. The protoplasmic tube represents a path in
the maze. The plasmodium solves maze in one pass because it is assisted by a
gradient of chemo-attractants propagating from the target oat flake.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4961</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4961</id><created>2011-08-24</created><authors><author><keyname>Antos</keyname><forenames>Andr&#xe1;s</forenames></author><author><keyname>Bart&#xf3;k</keyname><forenames>G&#xe1;bor</forenames></author><author><keyname>Szepesv&#xe1;ri</keyname><forenames>Csaba</forenames></author></authors><title>Non-trivial two-armed partial-monitoring games are bandits</title><categories>cs.LG</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider online learning in partial-monitoring games against an oblivious
adversary. We show that when the number of actions available to the learner is
two and the game is nontrivial then it is reducible to a bandit-like game and
thus the minimax regret is $\Theta(\sqrt{T})$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4972</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4972</id><created>2011-08-24</created><authors><author><keyname>Alam</keyname><forenames>Md. Shafiul</forenames></author><author><keyname>Mukhopadhyay</keyname><forenames>Asish</forenames></author></authors><title>Algorithms for the Problems of Length-Constrained Heaviest Segments</title><categories>cs.CG</categories><comments>21 pages, 12 figures</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present algorithms for length-constrained maximum sum segment and maximum
density segment problems, in particular, and the problem of finding
length-constrained heaviest segments, in general, for a sequence of real
numbers. Given a sequence of n real numbers and two real parameters L and U (L
&lt;= U), the maximum sum segment problem is to find a consecutive subsequence,
called a segment, of length at least L and at most U such that the sum of the
numbers in the subsequence is maximum. The maximum density segment problem is
to find a segment of length at least L and at most U such that the density of
the numbers in the subsequence is the maximum. For the first problem with
non-uniform width there is an algorithm with time and space complexities in
O(n). We present an algorithm with time complexity in O(n) and space complexity
in O(U). For the second problem with non-uniform width there is a combinatorial
solution with time complexity in O(n) and space complexity in O(U). We present
a simple geometric algorithm with the same time and space complexities.
  We extend our algorithms to respectively solve the length-constrained k
maximum sum segments problem in O(n+k) time and O(max{U, k}) space, and the
length-constrained $k$ maximum density segments problem in O(n min{k, U-L})
time and O(U+k) space. We present extensions of our algorithms to find all the
length-constrained segments having user specified sum and density in O(n+m) and
O(nlog (U-L)+m) times respectively, where m is the number of output.
Previously, there was no known algorithm with non-trivial result for these
problems. We indicate the extensions of our algorithms to higher dimensions.
All the algorithms can be extended in a straight forward way to solve the
problems with non-uniform width and non-uniform weight.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4973</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4973</id><created>2011-08-24</created><updated>2013-10-16</updated><authors><author><keyname>Levada</keyname><forenames>Alexandre L. M.</forenames></author></authors><title>Learning from Complex Systems: On the Roles of Entropy and Fisher
  Information in Pairwise Isotropic Gaussian Markov Random Fields</title><categories>cs.IT cs.AI cs.CV math.IT stat.CO</categories><comments>46 pages, 16 Figures</comments><journal-ref>Entropy, v. 16, n. 2, Special Issue on Information Geometry, 2014</journal-ref><doi>10.3390/e16021002</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  Markov Random Field models are powerful tools for the study of complex
systems. However, little is known about how the interactions between the
elements of such systems are encoded, especially from an information-theoretic
perspective. In this paper, our goal is to enlight the connection between
Fisher information, Shannon entropy, information geometry and the behavior of
complex systems modeled by isotropic pairwise Gaussian Markov random fields. We
propose analytical expressions to compute local and global versions of these
measures using Besag's pseudo-likelihood function, characterizing the system's
behavior through its \emph{Fisher curve}, a parametric trajectory accross the
information space that provides a geometric representation for the study of
complex systems. Computational experiments show how the proposed tools can be
useful in extrating relevant information from complex patterns. The obtained
results quantify and support our main conclusion, which is: in terms of
information, moving towards higher entropy states (A --&gt; B) is different from
moving towards lower entropy states (B --&gt; A), since the \emph{Fisher curves}
are not the same given a natural orientation (the direction of time).
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4982</identifier>
 <datestamp>2015-03-19</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4982</id><created>2011-08-24</created><updated>2011-11-06</updated><authors><author><keyname>Tchaikovsky</keyname><forenames>Michael M.</forenames></author><author><keyname>Kurdyukov</keyname><forenames>Alexander P.</forenames></author><author><keyname>Timin</keyname><forenames>Victor N.</forenames></author></authors><title>Synthesis of anisotropic suboptimal controllers by convex optimization</title><categories>cs.SY math.OC</categories><comments>38 pages, 11 figures, 4 tables</comments><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper considers a disturbance attenuation problem for a linear discrete
time invariant system under random disturbances with imprecisely known
probability distributions. The statistical uncertainty is measured in terms of
relative entropy using the mean anisotropy functional. The disturbance
attenuation capabilities of the system are quantified by the anisotropic norm
which is a stochastic counterpart of the H-infinity norm. The designed
anisotropic suboptimal controller generally is a dynamic fixed-order
output-feedback compensator which is required to stabilize the closed-loop
system and keep its anisotropic norm below a prescribed threshold value.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.4983</identifier>
 <datestamp>2012-03-13</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.4983</id><created>2011-08-24</created><updated>2011-09-27</updated><authors><author><keyname>Ward</keyname><forenames>Justin</forenames></author></authors><title>A $(k + 3)/2$-approximation algorithm for monotone submodular
  maximization over a $k$-exchange system</title><categories>cs.DS</categories><journal-ref>29th Symp. on Theoretical Aspects of Comp. Sci. (STACS 2012) 42-53</journal-ref><doi>10.4230/LIPIcs.STACS.2012.42</doi><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We consider the problem of maximizing a monotone submodular function in a
$k$-exchange system. These systems, introduced by Feldman et al., generalize
the matroid k-parity problem in a wide class of matroids and capture many other
combinatorial optimization problems. Feldman et al. show that a simple
non-oblivious local search algorithm attains a $(k + 1)/2$ approximation ratio
for the problem of linear maximization in a $k$-exchange system. Here, we
extend this approach to the case of monotone submodular objective functions. We
give a deterministic, non-oblivious local search algorithm that attains an
approximation ratio of $(k + 3)/2$ for the problem of maximizing a monotone
submodular function in a $k$-exchange system.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.5002</identifier>
 <datestamp>2011-09-01</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.5002</id><created>2011-08-24</created><updated>2011-08-30</updated><authors><author><keyname>Kameya</keyname><forenames>Yoshitaka</forenames></author><author><keyname>Nakamura</keyname><forenames>Satoru</forenames></author><author><keyname>Iwasaki</keyname><forenames>Tatsuya</forenames></author><author><keyname>Sato</keyname><forenames>Taisuke</forenames></author></authors><title>Verbal Characterization of Probabilistic Clusters using Minimal
  Discriminative Propositions</title><categories>cs.AI</categories><comments>13 pages including 3 figures. This is the full version of a paper at
  ICTAI-2011 (http://www.cse.fau.edu/ictai2011/)</comments><acm-class>I.2.6</acm-class><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In a knowledge discovery process, interpretation and evaluation of the mined
results are indispensable in practice. In the case of data clustering, however,
it is often difficult to see in what aspect each cluster has been formed. This
paper proposes a method for automatic and objective characterization or
&quot;verbalization&quot; of the clusters obtained by mixture models, in which we collect
conjunctions of propositions (attribute-value pairs) that help us interpret or
evaluate the clusters. The proposed method provides us with a new, in-depth and
consistent tool for cluster interpretation/evaluation, and works for various
types of datasets including continuous attributes and missing values.
Experimental results with a couple of standard datasets exhibit the utility of
the proposed method, and the importance of the feedbacks from the
interpretation/evaluation step.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.5009</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.5009</id><created>2011-08-25</created><authors><author><keyname>Zhang</keyname><forenames>Xin</forenames></author><author><keyname>Liu</keyname><forenames>Guizhen</forenames></author></authors><title>Total coloring of pseudo-outerplanar graphs</title><categories>math.CO cs.DM</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  A graph is pseudo-outerplanar if each of its blocks has an embedding in the
plane so that the vertices lie on a fixed circle and the edges lie inside the
disk of this circle with each of them crossing at most one another. In this
paper, the total coloring conjecture is completely confirmed for
pseudo-outerplanar graphs. In particular, it is proved that the total chromatic
number of every pseudo-outerplanar graph with maximum degree $\Delta\geq 5$ is
$\Delta+1$.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.5016</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.5016</id><created>2011-08-25</created><authors><author><keyname>Amblard</keyname><forenames>Maxime</forenames><affiliation>LORIA</affiliation></author><author><keyname>Michel</keyname><forenames>Musiol</forenames><affiliation>LABPSYLOR</affiliation></author><author><keyname>Manuel</keyname><forenames>Rebuschi</forenames><affiliation>LHSP</affiliation></author></authors><title>Une analyse bas\'ee sur la S-DRT pour la mod\'elisation de dialogues
  pathologiques</title><categories>cs.CL cs.AI</categories><comments>Traitement Automatique des Langues, Montpellier : France (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  In this article, we present a corpus of dialogues between a schizophrenic
speaker and an interlocutor who drives the dialogue. We had identified specific
discontinuities for paranoid schizophrenics. We propose a modeling of these
discontinuities with S-DRT (its pragmatic part)
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.5017</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.5017</id><created>2011-08-25</created><authors><author><keyname>Qian</keyname><forenames>Sai</forenames><affiliation>LORIA</affiliation></author><author><keyname>Amblard</keyname><forenames>Maxime</forenames><affiliation>LORIA</affiliation></author></authors><title>Event in Compositional Dynamic Semantics</title><categories>cs.CL cs.AI cs.LO</categories><comments>16 pages; Logical Aspect of Computational Linguistic, Montpellier :
  France (2011)</comments><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We present a framework which constructs an event-style dis- course semantics.
The discourse dynamics are encoded in continuation semantics and various
rhetorical relations are embedded in the resulting interpretation of the
framework. We assume discourse and sentence are distinct semantic objects, that
play different roles in meaning evalua- tion. Moreover, two sets of composition
functions, for handling different discourse relations, are introduced. The
paper first gives the necessary background and motivation for event and dynamic
semantics, then the framework with detailed examples will be introduced.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.5019</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.5019</id><created>2011-08-25</created><authors><author><keyname>Glass</keyname><forenames>Olivier</forenames><affiliation>CEREMADE</affiliation></author><author><keyname>Horsin</keyname><forenames>Thierry</forenames><affiliation>LM-Versailles</affiliation></author></authors><title>Prescribing the motion of a set of particles in a 3D perfect fluid</title><categories>math.AP cs.SY math.OC</categories><proxy>ccsd</proxy><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  We establish a result concerning the so-called Lagrangian controllability of
the Euler equation for incompressible perfect fluids in dimension 3. More
precisely we consider a connected bounded domain of R^3 and two smooth
contractible sets of fluid particles, surrounding the same volume. We prove
that given any initial velocity field, one can find a boundary control and a
time interval such that the corresponding solution of the Euler equation makes
the first of the two sets approximately reach the second one.
</abstract></arXiv>
</metadata>
</record>
<record>
<header>
 <identifier>oai:arXiv.org:1108.5025</identifier>
 <datestamp>2011-08-26</datestamp>
 <setSpec>cs</setSpec>
</header>
<metadata>
 <arXiv xmlns="http://arxiv.org/OAI/arXiv/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://arxiv.org/OAI/arXiv/ http://arxiv.org/OAI/arXiv.xsd">
 <id>1108.5025</id><created>2011-08-25</created><authors><author><keyname>parsaeefard</keyname><forenames>saeedeh</forenames></author><author><keyname>van der Schaar</keyname><forenames>Mihaela</forenames></author><author><keyname>Sharafat</keyname><forenames>Ahmad R.</forenames></author></authors><title>Robust Stackelberg game in communication systems</title><categories>cs.IT cs.GT math.IT</categories><license>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</license><abstract>  This paper studies multi-user communication systems with two groups of users:
leaders which possess system information, and followers which have no system
information using the formulation of Stackelberg games. In such games, the
leaders play and choose their actions based on their information about the
system and the followers choose their actions myopically according to their
observations of the aggregate impact of other users. However, obtaining the
exact value of these parameters is not practical in communication systems. To
study the effect of uncertainty and preserve the players' utilities in these
conditions, we introduce a robust equilibrium for Stackelberg games. In this
framework, the leaders' information and the followers' observations are
uncertain parameters, and the leaders and the followers choose their actions by
solving the worst-case robust optimizations. We show that the followers'
uncertain parameters always increase the leaders' utilities and decrease the
followers' utilities. Conversely, the leaders' uncertain information reduces
the leaders' utilities and increases the followers' utilities. We illustrate
our theoretical results with the numerical results obtained based on the power
control games in the interference channels.
</abstract></arXiv>
</metadata>
</record>
<resumptionToken cursor="23000" completeListSize="102538">1122234|24001</resumptionToken>
</ListRecords>
</OAI-PMH>
